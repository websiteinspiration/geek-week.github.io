<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ï ü§Ø üçç How do we count people using computer vision üåø üî® üõê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Photos from open sources
 
 Mass gatherings of people create problems in various fields (retail, public services, banks, developers). Customers need t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>How do we count people using computer vision</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/496616/"><img src="https://habrastorage.org/webt/b2/gt/vy/b2gtvy54vvgxucterhxudpe5y58.png" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Photos from open sources</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Mass gatherings of people create problems in various fields (retail, </font><i><font style="vertical-align: inherit;">public</font></i><font style="vertical-align: inherit;"> services, banks, developers). Customers need to combine and monitor information about the number of people in many places: in service offices, administrative buildings, on construction sites, etc. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
People counting tasks have ready-made solutions, for example, using cameras with built-in analytics. However, in many cases it is important to use a large number of cameras previously installed in different departments. In addition, a solution that takes into account the specifics of a particular customer will be better for him.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Our names are Tatyana Voronova and Elvira Dyaminova, we are engaged in data analysis at Center 2M. Although the topic seems to be the simplest of what is currently being considered in computer vision problems, even in this problem, when it comes to practice (implementation), many complex and non-trivial subtasks have to be solved. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The purpose of our article is to show the complexity and basic approaches to computer vision problems using the example of solving one of the basic problems.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> For the following materials, we want to attract colleagues: devops, engineer, project managers on video analytics, so that they talk about the involved computing resources, speed measurements, the nuances of communicating with customers and project implementation stories. We will focus on some of the data analysis methods used.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's start with the following statement: you need to display the number of people in the queue at the service office. </font><font style="vertical-align: inherit;">If the queue, according to the internal rules of the customer company, is deemed critical, the internal scenario will begin to be worked out:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notification of the need to open an additional entrance / cash desk;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">manager call;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">informing about the need to redirect flows of people to other (more free) cash desks.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thus, our work will save customers a lot of nerves.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Machine Learning Models Used</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">People silhouettes detection</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Initially, we decided to use an already trained model for detecting people (silhouettes), since such tasks have fairly good solutions, for example, the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">definition of silhouettes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, in the TensorFlow library there are a large number of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pre-trained models</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After conducting the tests, we first settled on two architectures: Faster R-CNN and YOLO v2. Later, after the new version appeared, we added YOLO v3. </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Description of models</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An example of a recognition result for YOLO v2 (hereinafter, images are taken from free sources - we cannot publish frames from customer cameras): </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7d/7t/ci/7d7tciq9yzbof4hsrp00ckrbh7o.jpeg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An example of a recognition result for Faster R-CNN:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lg/qg/gq/lgqggq6y-hq6bbkmpkynivfy1co.jpeg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The advantage of YOLO is that the model responds faster, and in some tasks this is important. However, in practice, we found out that if it is not possible to use a pre-trained version of the model, and retraining is required on your specialized training set, it is more correct to use Faster R-CNN. If the camera was installed far enough away from people (the height of the silhouette is less than 100 pixels for a resolution of 1920 by 1080) or it was required to additionally recognize personal protective equipment on a person: helmets, fasteners, protective clothing elements, in such situations the quality of the training result on your own dataset (up to 10 thousand different objects) for YOLO v2 we were not satisfied.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLO v3 showed acceptable results, however, speed tests did not give a significant advantage for YOLO v3 compared to Faster R-CNN. In addition, we found a way to increase recognition speed by using batch (group processing of images), selective analysis of images (more on this below).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For all types of models, we improved accuracy using post-processing of results: we removed outliers in values, took the most common values ‚Äã‚Äãfor a set of consecutive frames. One second from one camera usually corresponds to 25-50 frames. Of course, to improve performance (with an increasing number of cameras), we analyze not every frame, but it is often possible to give a final answer over an interval of several seconds, that is, use several frames. This decision can be made dynamically, taking into account the total number of cameras (video streams for processing) and available computing power. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An example of using the Faster R-CNN model, trained on our own dataset: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/cn/b9/8i/cnb98ihri3ztp_kd6eanszvv2g4.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now we are conducting tests with the </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">SSD-300</font></a><font style="vertical-align: inherit;"> model</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">We hope that it will give us an increase in productivity while maintaining an acceptable quality of recognition.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creating your own training dataset</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In cases where you want to create your own learning set, we have developed for ourselves the following procedure:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">we collect video clips with the required objects: customers‚Äôs videos, videos in the public domain (laid out videos, surveillance cameras);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">we cut and filter video fragments so that the resulting dataset is balanced across various recognition objects;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We distribute frames between markers to highlight the necessary objects. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An example of a markup tool</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">selectively check the results of the markers;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">if necessary, we perform augmentation: usually we add turns, reflection, change the sharpness (form an extended marked dataset).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Using detection zones</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
One of the problems with counting people in line is the intersection of the visibility areas of several cameras. </font><font style="vertical-align: inherit;">More than one camera can be installed in the room, therefore it is important to maintain the area of ‚Äã‚Äãoverlapping images, and when a person enters the scope of several cameras, he should be taken into account once. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In some situations, people need to be detected only in a certain area of ‚Äã‚Äãthe room (near the service windows) or platform (near the equipment).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For obvious reasons, it is wrong to verify that the border-rectangle (box / frame), restricting the whole person, falls into the zone (polygon). </font><font style="vertical-align: inherit;">In this situation, the bottom (third / half) of the rectangle is divided into points - nodes (a grid of 10 by 10 nodes is taken) and the falling into the zone of the individual selected nodes is checked. </font><font style="vertical-align: inherit;">‚ÄúSignificant‚Äù nodes are allocated by the system administrator based on the geometry of the room (the default values ‚Äã‚Äãare also selected - if the setting for a particular room is not entered). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fl/ck/6w/flck6wqyyr5ojbwpeuqebuidzoe.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, the application of the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mask R-CNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> architecture </font><font style="vertical-align: inherit;">for our tasks is </font><font style="vertical-align: inherit;">being tested </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">The method allows you to determine the silhouette outline - this will make it possible </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to get away from using a border-rectangle when analyzing the intersection with a zone</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<img src="https://habrastorage.org/webt/et/wy/oq/etwyoqwuuebhqh4jyxmf8j509-0.jpeg" alt="image"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another approach: head detection (model training)</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quality is not always achieved by choosing a model, increasing / changing the training set, and other, purely ML methods. Sometimes a decisive improvement can only be obtained by changing the entire formulation of the problem (for example, in our problem). In these queues, people crowd and therefore overlap each other, so the quality of recognition is often insufficient to use only this method in real conditions. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Take the image below. We close our eyes to the fact that the picture was taken on the phone, and the angle of its inclination does not correspond to the angle of inclination of CCTV cameras. There are 18 people on the frame, and the silhouette detection model identified 11 people: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tw/qe/lr/twqelrrbt5dsacykfcb_2vm1zwe.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To improve the results, we moved from defining silhouettes to defining goals. For this, the Faster R-CNN model was trained on a dataset taken from</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">link</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (the dataset includes frames with a different number of people, including large clusters, among which there are people of different races and ages). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Plus, we enriched the dataset with frames from the material (from the cameras) of the customer by about a third (mainly due to the fact that the original dataset had few heads in hats). A </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tutorial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was useful for self-learning a model </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main problems we encountered are image quality and the scale of objects. The heads have different sizes (as can be seen from the image above), and the frames from the customer‚Äôs cameras had a resolution of 640x480, because of this, interesting objects (hoods, Christmas balls, backs of chairs) are sometimes detected as heads. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For example, in the training dataset, we have labeled heads:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/q6/u6/di/q6u6di-qwgmrlotfsyxeynpx-1q.png" alt="image"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- these are heads in a dataset; </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rn/2r/es/rn2resr7gorbgtezqs7jhoozzhs.jpeg" alt="image"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- and this is the back of the chair, but the model wants to believe that this is the head. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, in general, this model copes quite well in cases where there is a massive concentration of people. So, in the frame above, our model identified 15 people: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/b2/gt/vy/b2gtvy54vvgxucterhxudpe5y58.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thus, in this image, the model could not find only three heads, which were significantly blocked by foreign objects. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To improve the quality of the model, you can replace the current cameras with cameras with a higher resolution and additionally collect and mark the training dataset.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nevertheless, it should be borne in mind that with a small number of people, the method of detecting by silhouettes rather than by heads is more suitable, since the silhouette is more difficult to completely overlap or confuse with foreign objects. </font><font style="vertical-align: inherit;">However, if there is a crowd, there is no way out, so for counting people in line, it was decided to use two models in parallel - for heads and silhouettes - and combine the answer. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Silhouettes and heads, an example of a recognition result:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ku/rf/jt/kurfjth3rdirwguzsqnsrgnketg.png" alt="image"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Accuracy rating</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When testing the model, frames were selected that did not participate in the training (dataset with a different number of people on the frame, in different angles and different sizes), to assess the quality of the model, we used recall and precision. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recall</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - completeness shows what proportion of objects that </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">actually</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> belong to the positive class, we predicted correctly. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Precision</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - accuracy shows what proportion of objects </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recognized</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> as objects of a positive class, we predicted correctly. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On frames from cameras on test sites (images in these rooms were on the dataset) metrics: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9k/dc/to/9kdctoymo_ibp2pyhzxhnllrtkk.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On frames from new cameras (these rooms were not on the dataset):</font></font><br>
<br>
<img src="https://habrastorage.org/webt/wn/pc/a0/wnpca03c5bbmnermgoiuh9zegzy.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When the customer needed one digit, a combination of accuracy and completeness, we provided a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">harmonic mean</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , or </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F-measure</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<img src="https://habrastorage.org/webt/ye/3o/aw/ye3oawilyj5rh_cvzpxr0c0sx3w.png" alt="image"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reporting</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An important part of the service is statistics. Together with individual frames (and dedicated people counted by them), customers want to see the results in the form of ready-made reports (dashboards) with average / maximum occupancy for different time intervals. The result is often interesting in the form of graphs and charts characterizing the distribution of the number of people over time. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For example, in our solution for the frame, the number of people for both models (silhouettes and heads) is calculated and the maximum is selected. If there are several cameras in the room, the image overlap zone (pre-set via the interface) is saved, and when a person enters the scope of several cameras, he is taken into account once.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, the value of the number of people in the queue is formed for several consecutive frames - for the interval </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œît</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Within an hour, values ‚Äã‚Äãfor several such intervals are unloaded for each room. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The size of the time interval and the number of intervals are determined based on the number of rooms and used computing power. For each interval, an array of values ‚Äã‚Äãis formed with the number of people in the room. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The most common value (mode) is selected. If there are several values ‚Äã‚Äãwith the same frequency, the maximum is selected. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The resulting value is the number of people in the queue at time </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">immediately following the interval in question. </font><font style="vertical-align: inherit;">In just an hour, a set of values ‚Äã‚Äãis obtained for different intervals - that is, values ‚Äã‚Äãat time instants </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t_1, t_2 .... </font><font style="vertical-align: inherit;">t_n</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Further for </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t_1, t_2 .... </font><font style="vertical-align: inherit;">t_n, the</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> maximum and average values ‚Äã‚Äãof the number of people are calculated ‚Äî these values ‚Äã‚Äãare displayed in the report as peak and average loads for a given hour. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diagram of the distribution of people by time for maximum load (simple example): </font></font><br>
<br>
<img src="https://habrastorage.org/webt/um/nb/zp/umnbzpjh1aj_0gdt1qhwywj8niu.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diagram of the distribution of people by time for average load (simple example):</font></font><br>
<br>
<img src="https://habrastorage.org/webt/rj/h4/rx/rjh4rxxkyftekb8tspvwylamwu8.png" alt="image"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Crowds</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In conclusion, for completeness of the topic, I would like to mention cases of very large crowds, for example, crowds in stadiums, in places of intense human traffic. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
These tasks are about estimating the size of the crowd: if it is a crowd of 300 people, an answer of 312 or 270 is considered acceptable. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In practice, we did not have to solve such problems with the help of video analytics (if this is an organized event, then it is easier for each person to issue a label). However, we conducted testing. For such tasks, separate methods are used, an </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">overview of the methods</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The result of the model from the review (model pre-trained on CSRNet) was reproduced:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vq/ks/-k/vqks-kmt4kykj1vuls2t9dr18sc.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The angle is important for the settings of this model, that is, if the shooting location is fixed, the result will be better than when applied to diverse images. </font><font style="vertical-align: inherit;">Generally speaking, there is an opportunity to retrain this model - the quality can be improved during the model‚Äôs operation when real video from installed cameras is on. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Authors of the article: Tatyana Voronova (</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tvoronova</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), Elvira Dyaminova (</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">elviraa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en496600/index.html">As part of import substitution, Moscow buys Microsoft software for 90 million rubles</a></li>
<li><a href="../en496608/index.html">Food Design Digest, March 2020</a></li>
<li><a href="../en496610/index.html">Router Banana Pi R64 - Debian, Wireguard, ILV</a></li>
<li><a href="../en496612/index.html">Yes, my old laptop is several times more powerful than your production server</a></li>
<li><a href="../en496614/index.html">How have the Habrachians changed in 5 years? Or "280 weeks later"</a></li>
<li><a href="../en496620/index.html">Popular errors in English among IT professionals</a></li>
<li><a href="../en496626/index.html">Journeyman and Dragons: how to help the intern to adapt as a team</a></li>
<li><a href="../en496630/index.html">Interface Bikes Toxic Grandfather. ‚ÄúArtifacts my ass!‚Äù (s1 e5)</a></li>
<li><a href="../en496634/index.html">School 21 for the applicant</a></li>
<li><a href="../en496638/index.html">F #, marking algorithm for connected image components</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
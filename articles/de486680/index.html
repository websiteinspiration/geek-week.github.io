<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì¨ üë©üèæ‚Äç‚öïÔ∏è ü§æüèø ML, VR & Robots (und ein bisschen Cloud) ü§üüèª üß† ‚ô®Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo alle zusammen! 
 
 Ich m√∂chte √ºber ein sehr langweiliges Projekt sprechen, bei dem sich Robotik, maschinelles Lernen (und zusammen ist dies Robo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ML, VR & Robots (und ein bisschen Cloud)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/486680/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo alle zusammen! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich m√∂chte √ºber ein sehr langweiliges Projekt sprechen, bei dem sich Robotik, maschinelles Lernen (und zusammen ist dies Roboterlernen), virtuelle Realit√§t und ein bisschen Cloud-Technologie kreuzten. </font><font style="vertical-align: inherit;">Und das alles macht tats√§chlich Sinn. </font><font style="vertical-align: inherit;">Schlie√ülich ist es sehr praktisch, in einen Roboter einzusteigen, zu zeigen, was zu tun ist, und dann anhand der gespeicherten Daten Gewichte auf dem ML-Server zu trainieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unter dem Schnitt werden wir erz√§hlen, wie es jetzt funktioniert, und einige Details zu jedem der Aspekte, die entwickelt werden mussten.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/t0/kx/wi/t0kxwiicqakswvomnrwz-iycc2o.jpeg"><br>
<a name="habracut"></a><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wozu</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
F√ºr den Anfang lohnt es sich, ein wenig zu enth√ºllen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es scheint, dass mit Deep Learning bewaffnete Roboter Menschen √ºberall von ihren Jobs verdr√§ngen werden. </font><font style="vertical-align: inherit;">In der Tat ist nicht alles so glatt. </font><font style="vertical-align: inherit;">Wo Aktionen streng wiederholt werden, sind Prozesse bereits sehr gut automatisiert. </font><font style="vertical-align: inherit;">Wenn es sich um ‚Äûintelligente Roboter‚Äú handelt, dh um Anwendungen, bei denen Computer Vision und Algorithmen bereits ausreichen. </font><font style="vertical-align: inherit;">Es gibt aber auch viele √§u√üerst komplizierte Geschichten. </font><font style="vertical-align: inherit;">Roboter k√∂nnen mit der Vielfalt der Objekte, mit denen sie umgehen m√ºssen, und der Vielfalt der Umgebung kaum fertig werden.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wichtige Punkte</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt drei wichtige Dinge in Bezug auf die Implementierung, die noch nicht √ºberall zu finden sind: </font></font><br>
<br>
<ul>
<li>       (data-driven learning). ..   ,    ,     ,    . ,     .</li>
<li>   ()    </li>
<li>  -  (Human-machine collaboration) </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das zweite ist ebenfalls wichtig, da wir im Moment eine √Ñnderung der Lernans√§tze, der dahinter stehenden Algorithmen und der Computerwerkzeuge beobachten werden. </font><font style="vertical-align: inherit;">Wahrnehmungs- und Steuerungsalgorithmen werden flexibler. </font><font style="vertical-align: inherit;">Ein Roboter-Upgrade kostet Geld. </font><font style="vertical-align: inherit;">Und der Rechner kann effizienter eingesetzt werden, wenn mehrere Roboter gleichzeitig bedient werden. </font><font style="vertical-align: inherit;">Dieses Konzept nennt man ‚ÄûCloud Robotics‚Äú. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit letzterem ist alles einfach - AI ist derzeit nicht ausreichend entwickelt, um 100% Zuverl√§ssigkeit und Genauigkeit in allen Situationen zu bieten, die vom Unternehmen gefordert werden. </font><font style="vertical-align: inherit;">Daher wird der Supervisor-Bediener, der manchmal Robotern helfen kann, nicht verletzt.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Planen</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zun√§chst zu einer Software- / Netzwerkplattform, die alle beschriebenen Funktionen bietet: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fd/6y/fi/fd6yfi2svby-3l7hkn9lxxt3neo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Komponenten:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Roboter sendet einen 3D-Videostream an den Server und erh√§lt als Antwort die Kontrolle. </font></font></li>
<li>    :  - ,      (, , , )</li>
<li>  ML  ( ),        ,   ,  .      ‚Äî  3D   ,     . </li>
<li> -  ,  3D       ,   UI   .   ‚Äî . </li>
</ol><br>
<h4> </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt zwei Funktionsmodi des Roboters: automatisch und manuell. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im manuellen Modus arbeitet der Roboter, wenn der ML-Dienst noch nicht geschult ist. </font><font style="vertical-align: inherit;">Dann wechselt der Roboter entweder auf Wunsch des Bedieners von automatisch zu manuell (ich habe beim Beobachten des Roboters merkw√ºrdige Verhaltensweisen festgestellt) oder wenn ML-Dienste selbst eine Anomalie feststellen. </font><font style="vertical-align: inherit;">√úber die Erkennung von Anomalien wird sp√§ter berichtet - dies ist ein sehr wichtiger Teil, ohne den es unm√∂glich ist, den vorgeschlagenen Ansatz anzuwenden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Entwicklung der Kontrolle ist wie folgt:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Aufgabe f√ºr den Roboter wird in lesbaren Begriffen formuliert und Leistungsindikatoren beschrieben.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Bediener stellt in VR eine Verbindung zum Roboter her und f√ºhrt die Aufgabe f√ºr einige Zeit innerhalb des vorhandenen Workflows aus</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der ML-Teil wird auf die empfangenen Daten trainiert</font></font><br>
</li>
<li>      ,     ML             <br>
</li>
<li>              <br>
</li>
</ol><br>
<h4>       3D</h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sehr oft verwenden Roboter die ROS-Umgebung (Robot Operating System), die in der Tat ein Framework f√ºr die Verwaltung von ‚ÄûKnoten‚Äú (Knoten) ist, von denen jeder einen Teil der Funktionalit√§t des Roboters bereitstellt. Im Allgemeinen ist dies eine relativ bequeme Methode zum Programmieren von Robotern, die in gewisser Weise der Microservice-Architektur von Webanwendungen √§hnelt. Der Hauptvorteil von ROS ist der Industriestandard, und es wird bereits eine gro√üe Anzahl von Modulen ben√∂tigt, um einen Roboter zu erstellen. Sogar Industrieroboterarme k√∂nnen ein ROS-Schnittstellenmodul haben. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Am einfachsten ist es, ein Br√ºckenmodell zwischen unserem Serverteil und ROS zu erstellen. Zum Beispiel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wie z</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Jetzt verwendet unser Projekt eine weiterentwickelte Version des ROS- ‚ÄûKnotens‚Äú, der sich anmeldet und den Mikrodienst des Registers abfragt, mit dem ein Relay-Server ein bestimmter Roboter verbinden kann. Der Quellcode dient nur als Beispiel f√ºr Anweisungen zur Installation des ROS-Moduls. Wenn Sie dieses Framework (ROS) beherrschen, sieht zun√§chst alles ziemlich unfreundlich aus, aber die Dokumentation ist ziemlich gut, und nach ein paar Wochen beginnen Entwickler, seine Funktionalit√§t recht sicher zu nutzen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Interessant - das Problem der Komprimierung des 3D-Datenstroms, der direkt auf dem Roboter erzeugt werden muss.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es ist nicht so einfach, die Tiefenkarte zu komprimieren. </font><font style="vertical-align: inherit;">Selbst bei einer geringen Komprimierung des RGB-Streams ist eine sehr schwerwiegende lokale Helligkeitsverzerrung von wahr in Pixel an den R√§ndern oder beim Bewegen von Objekten zul√§ssig. </font><font style="vertical-align: inherit;">Das Auge merkt das fast nicht, aber sobald die gleichen Verzerrungen in der Tiefenkarte erlaubt sind, wird beim Rendern von 3D alles sehr schlecht: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/kv/1l/6-/kv1l6-qgxaqxhsf1a-zl67hymtk.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(aus dem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Defekte an den R√§ndern verderben die 3D-Szene stark, weil </font><font style="vertical-align: inherit;">Es liegt nur viel M√ºll in der Luft.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben begonnen, Frame-f√ºr-Frame-Komprimierung zu verwenden - JPEG f√ºr RGB und PNG f√ºr eine Tiefenkarte mit kleinen Hacks. </font><font style="vertical-align: inherit;">Diese Methode komprimiert den 30-FPS-Stream f√ºr eine 3D-Scanneraufl√∂sung von 640 x 480 bei 25 Mbit / s. </font><font style="vertical-align: inherit;">Eine bessere Komprimierung kann auch bereitgestellt werden, wenn der Datenverkehr f√ºr die Anwendung kritisch ist. </font><font style="vertical-align: inherit;">Es gibt kommerzielle 3D-Stream-Codecs, mit denen dieser Stream auch komprimiert werden kann.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kontrolle der virtuellen Realit√§t</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir den Referenzrahmen der Kamera und des Roboters </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kalibriert haben</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (und bereits </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">einen Artikel √ºber die Kalibrierung geschrieben haben</font></a><font style="vertical-align: inherit;"> ), kann der Roboterarm in der virtuellen Realit√§t gesteuert werden. </font><font style="vertical-align: inherit;">Der Controller stellt sowohl die Position in 3D XYZ als auch die Ausrichtung ein. </font><font style="vertical-align: inherit;">F√ºr einige Roboruk sind nur 3 Koordinaten ausreichend, aber bei einer gro√üen Anzahl von Freiheitsgraden muss auch die Ausrichtung des von der Steuerung festgelegten Werkzeugs √ºbertragen werden. </font><font style="vertical-align: inherit;">Dar√ºber hinaus gibt es gen√ºgend Steuerungen an den Steuerungen, um Roboterbefehle auszuf√ºhren, z. B. das Ein- und Ausschalten der Pumpe, die Steuerung des Greifers und andere. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zun√§chst wurde beschlossen, das JavaScript-Framework f√ºr Virtual-Reality-A-Frames zu verwenden, das auf der WebVR-Engine basiert. </font><font style="vertical-align: inherit;">Die ersten Ergebnisse (Videodemonstration am Ende des Artikels f√ºr den 4-Koordinaten-Arm) wurden auf dem A-Rahmen erzielt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tats√§chlich stellte sich heraus, dass WebVR (oder A-Frame) aus mehreren Gr√ºnden eine erfolglose L√∂sung war:</font></font><br>
<br>
<ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kompatibilit√§t haupts√§chlich mit FireFox</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , w√§hrend das A-Frame-Framework in FireFox keine Texturressourcen freigab (der Rest der Browser wurde damit fertig), bis der Speicherverbrauch 16 GB erreichte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">begrenzte Interaktion mit VR-Controllern und Helm. </font><font style="vertical-align: inherit;">So war es beispielsweise nicht m√∂glich, zus√§tzliche Markierungen hinzuzuf√ºgen, mit denen Sie beispielsweise die Position der Ellbogen des Bedieners festlegen k√∂nnen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Anwendung erforderte Multithreading oder mehrere Prozesse. </font><font style="vertical-align: inherit;">In einem Thread / Prozess war es notwendig, die Videobilder zu entpacken, in einem anderen - Zeichnen. </font><font style="vertical-align: inherit;">Infolgedessen wurde alles durch Arbeiter organisiert, aber die Auspackzeit erreichte 30 ms, und das Rendern in VR sollte mit einer Frequenz von 90 FPS erfolgen.</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All diese M√§ngel f√ºhrten dazu, dass das Rendern des Rahmens in den zugewiesenen 10 ms keine Zeit hatte und es in VR sehr unangenehme Zuckungen gab. Wahrscheinlich konnte alles √ºberwunden werden, aber die Identit√§t jedes Browsers war etwas nervig. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt haben wir uns entschlossen, zum C # -, OpenTK- und C # -Port der OpenVR-Bibliothek zu wechseln. Es gibt noch eine Alternative - Einheit. Sie schreiben, dass Unity f√ºr Anf√§nger ist ... aber schwierig. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Wichtigste, was gefunden und bekannt sein musste, um Freiheit zu erlangen:</font></font><br>
<br>
<pre><code class="cs hljs">VRTextureBounds_t bounds = <span class="hljs-keyword">new</span> VRTextureBounds_t() { uMin = <span class="hljs-number">0</span>, vMin = <span class="hljs-number">0</span>, uMax = <span class="hljs-number">1f</span>, vMax = <span class="hljs-number">1f</span> }; <font></font>
OpenVR.Compositor.Submit(EVREye.Eye_Left, <span class="hljs-keyword">ref</span> leftTexture, <span class="hljs-keyword">ref</span> bounds, EVRSubmitFlags.Submit_Default);<font></font>
OpenVR.Compositor.Submit(EVREye.Eye_Right, <span class="hljs-keyword">ref</span> rightTexture, <span class="hljs-keyword">ref</span> bounds, EVRSubmitFlags.Submit_Default);
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(Dies ist der Code zum Senden von zwei Texturen an das linke und rechte Auge des Helms) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
d.h. </font><font style="vertical-align: inherit;">Zeichnen Sie OpenGL in die Textur, die verschiedene Augen sehen, und senden Sie es an eine Brille. </font><font style="vertical-align: inherit;">Joy kannte keine Grenzen, als sich herausstellte, dass das linke Auge mit Rot und das rechte mit Blau gef√ºllt war. </font><font style="vertical-align: inherit;">Nur ein paar Tage und jetzt wurde die √ºber webSocket kommende Tiefen- und RGB-Karte in 10 ms anstelle von 30 in JS auf das polygonale Modell √ºbertragen. </font><font style="vertical-align: inherit;">Und dann fragen Sie einfach die Koordinaten und Tasten der Controller ab, geben Sie das Ereignissystem f√ºr die Tasten ein, verarbeiten Sie Benutzerklicks, geben Sie die Zustandsmaschine f√ºr die Benutzeroberfl√§che ein und jetzt k√∂nnen Sie ein Glas vom Espresso nehmen:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/EuBNaGZctf8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt ist die Qualit√§t des Realsense D435 etwas deprimierend, aber sie wird vergehen, sobald wir mindestens </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einen so interessanten 3D-Scanner von Microsoft</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> installieren </font><font style="vertical-align: inherit;">, dessen Punktwolke viel genauer ist.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Serverseite</font></font></h4><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Relay-Server</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Das Hauptfunktionselement ist das Server-Relay (Server in der Mitte), das vom Roboter einen Videostream mit 3D-Bildern und Sensorablesungen sowie dem Zustand des Roboters empf√§ngt und unter den Verbrauchern verteilt. Eingabedaten - gepackte Frames und Sensorwerte √ºber TCP / IP. Die Verteilung an Verbraucher erfolgt √ºber Web-Sockets (ein sehr praktischer Mechanismus f√ºr das Streaming an mehrere Verbraucher, einschlie√ülich eines Browsers). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dar√ºber hinaus speichert der Staging-Server den Datenstrom im S3-Cloud-Speicher, damit er sp√§ter f√ºr Schulungen verwendet werden kann. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Relay-Server unterst√ºtzt die http-API, mit der Sie den aktuellen Status ermitteln k√∂nnen. Dies ist praktisch, um aktuelle Verbindungen zu √ºberwachen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Weiterleitungsaufgabe ist sowohl aus rechnerischer als auch aus verkehrstechnischer Sicht recht schwierig. Daher folgten wir hier der Logik, dass Relay-Server auf einer Vielzahl von Cloud-Servern bereitgestellt werden. Und das bedeutet, dass Sie nachverfolgen m√ºssen, wer wo eine Verbindung herstellt (insbesondere wenn sich Roboter und Bediener in verschiedenen Regionen befinden). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Registrieren</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Die zuverl√§ssigste Version ist jetzt f√ºr jeden Roboter schwer festzulegen, mit welchen Servern er eine Verbindung herstellen kann (Redundanz schadet nicht). Der ML-Verwaltungsdienst ist dem Roboter zugeordnet. Er fragt den Relay-Server ab, um festzustellen, mit welchem ‚Äã‚Äãder Roboter verbunden ist, und stellt eine Verbindung mit dem entsprechenden Server her, wenn er nat√ºrlich √ºber gen√ºgend Rechte daf√ºr verf√ºgt. Die Anwendung des Bedieners funktioniert auf √§hnliche Weise.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das angenehmste! Aufgrund der Tatsache, dass die Ausbildung von Robotern ein Dienst ist, ist der Dienst nur f√ºr uns im Inneren sichtbar. So kann sein Frontend f√ºr uns so bequem wie m√∂glich sein! Jene. Es handelt sich um eine Konsole im Browser (es gibt eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TerminalJS-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Bibliothek </font><font style="vertical-align: inherit;">, die </font><font style="vertical-align: inherit;">in ihrer Einfachheit </font><font style="vertical-align: inherit;">sehr </font><font style="vertical-align: inherit;">sch√∂n </font><font style="vertical-align: inherit;">ist und sehr einfach zu √§ndern ist, wenn Sie zus√§tzliche Funktionen wie die automatische TAB-Vervollst√§ndigung oder das Abspielen des Anrufverlaufs w√ºnschen). Sie sieht folgenderma√üen aus: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/wl/vl/yo/wlvlyojuytiepjvhzexlxr-ixcq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies ist nat√ºrlich ein separates Diskussionsthema, warum die Befehlszeile so gem√ºtlich. √úbrigens ist es besonders praktisch, Unit-Tests eines solchen Frontends durchzuf√ºhren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zus√§tzlich zur http-API implementiert dieser Dienst einen Mechanismus zum Registrieren von Benutzern mit tempor√§ren Token, Anmelde- / Abmeldeoperatoren, Administratoren und Robotern, Sitzungsunterst√ºtzung und Sitzungsverschl√ºsselungsschl√ºsseln f√ºr die Verkehrsverschl√ºsselung zwischen dem Relay-Server und dem Roboter. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All dies geschieht in Python mit Flask - ein sehr enger Stapel f√ºr ML-Entwickler (d. H. Uns). </font><font style="vertical-align: inherit;">Ja, au√üerdem ist die vorhandene CI / CD-Infrastruktur f√ºr Microservices mit Flask befreundet.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verz√∂gerungsproblem</font></font></h4> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir die Manipulatoren in Echtzeit steuern m√∂chten, ist die minimale Verz√∂gerung √§u√üerst n√ºtzlich. </font><font style="vertical-align: inherit;">Wenn die Verz√∂gerung zu gro√ü wird (mehr als 300 ms), ist es sehr schwierig, die Manipulatoren basierend auf dem Bild im virtuellen Helm zu steuern. </font><font style="vertical-align: inherit;">In unserer L√∂sung betr√§gt die Verz√∂gerung aufgrund der Frame-f√ºr-Frame-Komprimierung (dh ohne Pufferung) und ohne Verwendung von Standardtools wie GStreamer selbst unter Ber√ºcksichtigung des Zwischenservers etwa 150 bis 200 ms. </font><font style="vertical-align: inherit;">Die √úbertragungszeit √ºber das Netzwerk von ihnen betr√§gt etwa 80 ms. </font><font style="vertical-align: inherit;">Der Rest der Verz√∂gerung wird durch die Realsense D435-Kamera und die begrenzte Aufnahmefrequenz verursacht.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies ist nat√ºrlich ein Problem in voller H√∂he, das im Verfolgungsmodus auftritt, wenn der Manipulator in seiner Realit√§t in der virtuellen Realit√§t st√§ndig der Steuerung des Bedieners folgt. </font><font style="vertical-align: inherit;">In der Art, sich zu einem bestimmten Punkt XYZ zu bewegen, verursacht die Verz√∂gerung keine Probleme f√ºr den Bediener.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ML Teil</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt zwei Arten von Dienstleistungen: Management und Schulung. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Trainingsdienst sammelt die im S3-Speicher gespeicherten Daten und beginnt mit dem erneuten Training der Modellgewichte. </font><font style="vertical-align: inherit;">Am Ende des Trainings werden Gewichte an den Managementdienst gesendet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Verwaltungsdienst unterscheidet sich in Bezug auf Eingabe- und Ausgabedaten nicht von der Anwendung des Bedieners. </font><font style="vertical-align: inherit;">Ebenso der Eingangs-RGBD-Stream (RGB + Depth), die Sensorwerte und der Roboterstatus, die Ausgangssteuerbefehle. </font><font style="vertical-align: inherit;">Aufgrund dieser Identit√§t erscheint es m√∂glich, im Rahmen des Konzepts des ‚Äûdatengesteuerten Trainings‚Äú zu trainieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Zustand des Roboters (und die Sensorwerte) sind eine Schl√ºsselgeschichte f√ºr ML. Es definiert den Kontext. Beispielsweise verf√ºgt ein Roboter √ºber eine Zustandsmaschine, die f√ºr seinen Betrieb charakteristisch ist und weitgehend bestimmt, welche Art von Steuerung erforderlich ist. Diese 2 Werte werden zusammen mit jedem Frame √ºbertragen: der Betriebsmodus und der Zustandsvektor des Roboters. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und ein wenig zum Training:</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In der Demonstration am Ende des Artikels ging es </font><i><font style="vertical-align: inherit;">darum</font></i><font style="vertical-align: inherit;"> , ein Objekt (einen Kinderw√ºrfel) in einer 3D-Szene zu finden. Dies ist eine grundlegende Aufgabe f√ºr Best√ºckungsanwendungen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Training basierte auf einem Paar von Vorher-Nachher-Bildern und der Zielbezeichnung, die mit manueller Steuerung erhalten wurden: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/n6/v2/s3/n6v2s3v59u7eumxhdh3gxucngxq.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aufgrund des Vorhandenseins von zwei Tiefenkarten war es einfach, die Maske des im Bild bewegten Objekts zu berechnen: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/6a/vm/k-/6avmk-ue2jfndgwzy08zdb0qtqe.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au√üerdem werden xyz auf die Kameraebene projiziert und Sie k√∂nnen die Nachbarschaft des erfassten Objekts ausw√§hlen:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ha/_s/o-/ha_so-yh4xmxwsp4dkoo42tct9i.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eigentlich mit dieser Nachbarschaft und wird funktionieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zuerst erhalten wir XY durch Training. Unet ein Faltungsnetzwerk f√ºr die W√ºrfelsegmentierung. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann m√ºssen wir die Tiefe bestimmen und verstehen, ob das Bild vor uns abnormal ist. </font><font style="vertical-align: inherit;">Dies erfolgt mit einem Auto-Encoder in RGB und einem bedingten Auto-Encoder in der Tiefe. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modellarchitektur f√ºr das Training von Auto-Encodern: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xf/q4/ex/xfq4exzon5b63cucrz6aqi8kflm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Logik der Arbeit:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suchen Sie auf der ‚ÄûW√§rmekarte‚Äú nach einem Maximum (bestimmen Sie die Winkelkoordinaten u = x / zv = y / z des Objekts), das den Schwellenwert √ºberschreitet</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dann rekonstruiert der Auto-Encoder die Nachbarschaft des gefundenen Punktes f√ºr alle Hypothesen in der Tiefe (mit einem gegebenen Schritt von min_depth bis max_depth) und w√§hlt die Tiefe aus, bei der die Diskrepanz zwischen Rekonstruktion und Eingabe minimal ist</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit den Winkelkoordinaten u, v und der Tiefe k√∂nnen Sie die Koordinaten x, y, z erhalten</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Beispiel f√ºr die Auto-Encoder-Rekonstruktion einer Karte von W√ºrfeltiefen mit einer korrekt definierten Tiefe: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/av/1t/bu/av1tbu5dyvflda-_-lpbdw0t0qs.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Teil basiert die Idee einer Tiefensuchmethode auf einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artikel √ºber S√§tze von Auto-Encodern</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dieser Ansatz eignet sich gut f√ºr Objekte mit verschiedenen Formen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Allgemeinen gibt es jedoch viele verschiedene Ans√§tze, um ein XYZ-Objekt aus einem RGBD-Bild zu finden. Nat√ºrlich ist es in der Praxis und bei einer gro√üen Datenmenge erforderlich, die genaueste Methode zu w√§hlen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gab auch die Aufgabe, Anomalien zu erkennen. Dazu ben√∂tigen wir ein Segmentierungs-Faltungsnetzwerk, um aus den verf√ºgbaren Masken zu lernen. Anhand dieser Maske k√∂nnen Sie dann die Genauigkeit der Auto-Encoder-Rekonstruktion in der Tiefenkarte und im RGB bewerten. Aufgrund dieser Diskrepanz kann man √ºber das Vorhandensein einer Anomalie entscheiden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aufgrund dieser Methode ist es m√∂glich, das Auftreten von zuvor nicht sichtbaren Objekten im Rahmen zu erkennen, die dennoch vom prim√§ren Suchalgorithmus erkannt werden.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Demonstration</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das √úberpr√ºfen und Debuggen der gesamten erstellten Softwareplattform wurde am Stand durchgef√ºhrt:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3D-Kamera Realsense D435</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 koordinieren Dobot Magier</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VR Helm HTC Vive</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Server in der Yandex Cloud (reduziert die Latenz im Vergleich zur AWS Cloud)</font></font></li>
</ul><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/G5rBhaxHL_E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In dem Video lernen wir, wie man einen W√ºrfel in einer 3D-Szene findet, indem man eine Aufgabe in VR Pick &amp; Place ausf√ºhrt. </font><font style="vertical-align: inherit;">Etwa 50 Beispiele reichten f√ºr das Training auf einem W√ºrfel. </font><font style="vertical-align: inherit;">Dann √§ndert sich das Objekt und es werden ungef√§hr 30 weitere Beispiele gezeigt. </font><font style="vertical-align: inherit;">Nach der Umschulung kann der Roboter ein neues Objekt finden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der gesamte Vorgang dauerte ungef√§hr 15 Minuten, von denen ungef√§hr die H√§lfte das Gewicht des Modells trainierte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und in diesem Video steuert YuMi in VR. </font><font style="vertical-align: inherit;">Um zu lernen, wie Objekte bearbeitet werden, m√ºssen Sie die Ausrichtung und Position des Werkzeugs bewerten. </font><font style="vertical-align: inherit;">Die Mathematik basiert auf einem √§hnlichen Prinzip, befindet sich jedoch derzeit in der Test- und Entwicklungsphase.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Q0yTey1srBM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fazit</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Big Data und Deep Learning sind nicht alles. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir √§ndern den Lernansatz und bewegen uns dahin, wie Menschen neue Dinge lernen - indem wir wiederholen, was sie sehen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der mathematische Apparat ‚Äûunter der Haube‚Äú, den wir f√ºr reale Anwendungen entwickeln werden, zielt auf das Problem der kontextsensitiven Interpretation und Kontrolle ab. </font><font style="vertical-align: inherit;">Der Kontext hier sind nat√ºrliche Informationen, die von Robotersensoren verf√ºgbar sind, oder externe Informationen √ºber den aktuellen Prozess. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und je mehr technologische Prozesse wir beherrschen, desto mehr wird die Struktur des ‚ÄûGehirns in den Wolken‚Äú entwickelt und seine Einzelteile trainiert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
St√§rken dieses Ansatzes:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die M√∂glichkeit zu lernen, wie man variable Objekte manipuliert </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lernen in einer sich √§ndernden Umgebung (z. B. mobile Roboter)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">schlecht strukturierte Aufgaben</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kurze Markteinf√ºhrungszeit; </font><font style="vertical-align: inherit;">Sie k√∂nnen das Ziel auch im manuellen Modus mit den Operatoren ausf√ºhren</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Verj√§hrung:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bedarf an zuverl√§ssigem und gutem Internet</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zus√§tzliche Methoden sind erforderlich, um eine hohe Genauigkeit zu erzielen, z. B. Kameras im Manipulator selbst</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir arbeiten derzeit daran, unseren Ansatz auf die Standard-Best√ºckungsaufgabe verschiedener Objekte anzuwenden. </font><font style="vertical-align: inherit;">Aber es scheint uns (nat√ºrlich!), Dass er zu mehr f√§hig ist. </font><font style="vertical-align: inherit;">Irgendwelche Ideen, wo Sie sich sonst noch versuchen k√∂nnen? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vielen Dank f√ºr Ihre Aufmerksamkeit!</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de486680/">https://habr.com/ru/post/de486680/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de486670/index.html">–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –ø–∞—Å–ø–æ—Ä—Ç –†–§, 2020-–∞—è —á–∞—Å—Ç—å –º–∞—Ä–ª–µ–∑–æ–Ω—Å–∫–æ–≥–æ –±–∞–ª–µ—Ç–∞</a></li>
<li><a href="../de486672/index.html">OpenVINO Hackathon: Erkennen von Stimme und Emotion auf dem Raspberry Pi</a></li>
<li><a href="../de486674/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 400 (27. Januar - 2. Februar 2020)</a></li>
<li><a href="../de486676/index.html">Unvermeidlichkeit der FPGA-Penetration in Rechenzentren</a></li>
<li><a href="../de486678/index.html">Quarz in ASP.NET Core</a></li>
<li><a href="../de486682/index.html">Docker Compose: Mit Makefile vereinfachen</a></li>
<li><a href="../de486684/index.html">Meine Antwort an diejenigen, die glauben, dass der Wert von TDD √ºbertrieben ist</a></li>
<li><a href="../de486686/index.html">Informationen zum Implementieren einer Deep-Learning-Bibliothek in Python</a></li>
<li><a href="../de486688/index.html">Node.js, Tor, Puppenspieler und Cheerio: anonymes Web-Scraping</a></li>
<li><a href="../de486690/index.html">5 Tipps zum Schreiben von Qualit√§tspfeilfunktionen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
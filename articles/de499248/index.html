<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏾 🛰️ 🔳 Wie wir persönliche Schutzausrüstung erkennen 🤫 🙋 🕰️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wahrscheinlich haben Sie sich Ihr ganzes Leben lang gefragt, wie Sie ein neuronales Netzwerk trainieren können, um Menschen in Helmen und orangefarben...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Wie wir persönliche Schutzausrüstung erkennen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/499248/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wahrscheinlich haben Sie sich Ihr ganzes Leben lang gefragt, wie Sie ein neuronales Netzwerk trainieren können, um Menschen in Helmen und orangefarbenen Westen zu erkennen! Nein? Aber wir werden es dir trotzdem sagen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unser Name ist Tatyana Voronova und Elvira Dyaminova. Wir beschäftigen uns mit Datenanalysen im Unternehmen Center 2M und arbeiten viel mit den realsten Fabriken und Unternehmen zusammen. Aufgrund von Sicherheitsverletzungen erleiden sie Verluste in Höhe von mehreren Millionen Dollar, Mitarbeiter werden verletzt, daher wäre es schön, solche Verstöße systematisch und so früh wie möglich erkennen zu können. Das Beste von allem - automatisch. Wir haben also Probleme mit der Erkennung persönlicher Schutzausrüstung (PSA) auf Video und der Identifizierung von Personen oder Ausrüstungen in der Gefahrenzone.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/2u/-q/gv2u-qjuorn0awf-hlwjbuu3dc4.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum größten Teil erhalten wir Aufträge zur Bestimmung von Helmen (genauer gesagt deren Abwesenheit) und Arbeitskleidung. </font><font style="vertical-align: inherit;">Wir haben bereits Erfahrungen mit der Ausführung solcher Aufgaben gesammelt und können nun die aufgetretenen Probleme und deren Lösung beschreiben.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da wir im Rahmen der Zusammenarbeit nicht das Recht haben, Filmmaterial von den Objekten des Kunden zu veröffentlichen, werden wir den Artikel mit Bildern aus dem Internet illustrieren, auf denen Menschen in Helmen oft lächeln und gut aussehen. </font><font style="vertical-align: inherit;">Leider finden Sie im öffentlichen Bereich nicht für alle Merkmale der Aufgaben, denen wir in der Realität gegenüberstehen, gute Beispiele. </font><font style="vertical-align: inherit;">Insbesondere im Leben lächeln Menschen in Helmen seltener, und das Problem der Glatzköpfigen (wir werden etwas später darüber sprechen) im Internet wurde nicht wirklich aufgedeckt! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bild aus dem Internet (Größe 1920x1280):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/f9/9q/nb/f99qnblemmbik0caykgir0zfiag.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Erkennung von PSA kann auf eines von zwei klassischen Problemen des Computer-Sehens reduziert werden: Klassifizierung von Bildern und Erkennung von Objekten. In der Praxis stellte sich heraus, dass es besser war, keinen dieser Ansätze zu verwenden, sondern den für den jeweiligen Fall am besten geeigneten auszuwählen und flexibel zu kombinieren. Zum Beispiel können wir zuerst bestimmen, wo sich Personen auf dem Bild befinden, dann die durch die Silhouette geschnittenen Bilder in Klassen „in Arbeitskleidung“ und „ohne“ klassifizieren und das Vorhandensein eines Helms beim zweiten Durchgang erkennen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei vorgeschnittenen Personenfiguren sieht die Klassifizierung des Vorhandenseins von Helmen und Overalls folgendermaßen aus (Ansicht des Originalbildes): </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Ergebnis der Arbeit der Modelle zur Klassifizierung von Overalls und Helmen</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/su/ad/lg/suadlgvrpviurbpxflbg6y3bm8s.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auf den gleichen zuvor ausgewählten menschlichen Figuren erfolgt diesmal die Anwendung des Ansatzes mit Erkennung für Helme. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Ergebnis des Modells zur Klassifizierung von Arbeitskleidung und eines Modells zur Erkennung von Helmen:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/jb/8l/qjjb8lebwt3t-6xttueihk2gaqw.jpeg" alt="Bild"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stufe eins: menschliche Entdeckung</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Qualität der Definition kleiner Objekte (Helme / Brillen / Handschuhe) auf großen Rahmen ist mittelmäßig. Für einen Computer wie eine Person ist es viel einfacher, zuerst zu verstehen, wo sich Menschen befinden, und erst dann herauszufinden, was sie tragen. Alles beginnt also mit der Identifizierung der Personen im Rahmen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis der Experimente haben wir herausgefunden, dass das schnellere neuronale R-CNN-Netzwerk mit Inception v2 als Merkmalsextraktion gut zur Erkennung von Personen geeignet ist. TensorFlow verfügt bereits über </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vorab</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> trainierte </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">neuronale Netze</font></a><font style="vertical-align: inherit;"> zur Erkennung von Objekten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für uns ist Faster R-CNN Inception v2 (trainiert im COCO-Datensatz) die grundlegende Methode, die wir zuerst versuchen, um solche Probleme zu lösen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zunächst erkennen wir Personen auf dem Rahmen (und dann auf den gefundenen Personen, die wir PSA finden):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/xp/gy/ukxpgyllgs-olfg9xgbpmzkuwly.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beachten Sie, dass wir den Begrenzungsrahmen „mit einer Person“ entlang </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">der y-Achse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vergrößert haben </font><font style="vertical-align: inherit;">:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/8x/dp/ad8xdpfnx8f1fke9afg9u5q-9xs.jpeg" alt="Bild"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf diesem Foto wurde der Arbeiter in gutem Licht und vor einem kontrastierenden Hintergrund aufgenommen (bei Bildern im Internet passiert dies ständig). </font><font style="vertical-align: inherit;">Daher war der Begrenzungsrahmen mit der Person gut gebaut. </font><font style="vertical-align: inherit;">In unserer Praxis gibt es jedoch häufig Fälle (insbesondere bei unzureichender Sicht), in denen das Erkennungsmodell einen Helm bei einer Person abschneidet. Danach ist es sinnlos, auf einem beschnittenen Bild danach zu suchen. </font><font style="vertical-align: inherit;">In dieser Hinsicht erhöhen wir entlang der y-Achse den vorhergesagten Begrenzungsrahmen um 15%, bevor wir zur zweiten Stufe übergehen.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beim Erkennen von Personen stoßen wir auf kleine unangenehme Probleme. Erstens, wenn zwei Personen hintereinander gehen oder stehen, werden sie häufig als eine Person erkannt. Zweitens tritt ein statisches Objekt in das Sichtfeld der Kamera ein, in dem das Modell eine Person wie einen Hydranten erkennen kann. Diese Probleme können auf verschiedene Arten gelöst werden. Zum Beispiel, wie wir es gemacht haben: Versöhnen und akzeptieren Sie sie, da das Modell im Allgemeinen in Bezug auf Produktivität und Qualität für uns geeignet ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein grundlegenderes Problem ist, dass Industrieräume, in denen es eine „Gefahrenzone“ gibt, oft riesig sind und dementsprechend die Personen in den Rahmen sehr klein sind. Unsere auf Faster R-CNN Inception v2 basierende Basismethode zeigte in solchen Fällen schlechte Ergebnisse, und am Ende haben wir es versucht</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schneller R-CNN Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Die Ergebnisse waren beeindruckend, die Leute waren auch in der Ferne gut bekannt, aber die Geschwindigkeit war viel niedriger als beim Basismodell. </font><font style="vertical-align: inherit;">Mit ausreichenden Ressourcen und der Notwendigkeit einer hohen Genauigkeit können Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster R-CNN Nas verwenden</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zweite Stufe: Ermittlung böswilliger Verstöße</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je nach Aufgabe werden häufig folgende verwendet:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bildklassifizierungsmodell - Inception v3</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Objekterkennungsmodell - Schnellerer R-CNN-Beginn v2</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Klassifizierung von Arbeitskleidung und Helmen</font></font></h3> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben verschiedene neuronale Netzwerkarchitekturen getestet, um Bilder zu klassifizieren, und uns schließlich für Inception v3 entschieden, um die Tatsache zu nutzen, dass es für die Arbeit mit variablen Bildgrößen ausgelegt ist. Wir hatten bereits viele ausgeschnittene Bilder mit Menschen, und es war nicht schwierig, die Medianwerte für Höhe und Breite zu berechnen. So kamen wir zu dem Schluss, dass für das Training von Klassifikatoren begonnen wurde, Bilder auf eine Größe von 150x400 zu bringen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um das Netzwerk für die Erkennung von PSA zu schulen, muss zunächst ein Datensatz aus beschrifteten Beispielen gesammelt werden. </font><font style="vertical-align: inherit;">In diesem Prozess gibt es Feinheiten, deren Verwirklichung mit Erfahrung einhergeht. </font><font style="vertical-align: inherit;">Zum Beispiel ist es besser, Personen, die über den Hüften geschnitten sind, aus dem Datensatz zu entfernen. </font><font style="vertical-align: inherit;">Dadurch wird der Datensatz den tatsächlichen Bedingungen näher gebracht, da die meisten Personen auf Video von Überwachungskameras in voller Höhe gesehen werden. </font><font style="vertical-align: inherit;">Natürlich kommt es auch zu Überlappungsfällen, aber vollständige Silhouetten für die Zielprobe sind viel charakteristischer. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beispiele aus unserem Workwear-Datensatz:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k8/22/sh/k822shy7m4ddtteqqjp1mfs09b8.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben nichts Spezifisches als Metrik erfunden, wir verwenden Rückruf und Präzision. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modell zur Klassifizierung des Vorhandenseins / Nichtvorhandenseins von Arbeitskleidung: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ergebnisse einer Validierungsstichprobe</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/lw/ql/hu/lwqlhu_7-efmfxzrxug-d64pafq.jpeg" alt="Bild"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PSA-Erkennung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Klassifizierungsmodell arbeitet schneller als das Modell zum Erkennen von Objekten. Aufgrund der Tatsache, dass Schutzbrillen und Handschuhe im Bild klein sind, ist es schwierig, einen guten Klassifizierer für eine solche PSA zu erstellen. </font><font style="vertical-align: inherit;">Daher haben wir das schnellere neuronale R-CNN-Netzwerk auf einem Datensatz mit sechs Klassen trainiert:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gläser / not_glasses</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Handschuhe / not_gloves</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Helm / nicht_Helm</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/pw/iy/i_/pwiyi_nep5v7k8wlrz6yxvz8ug4.jpeg" alt="Bild"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datenerfassung und Markup</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Hauptprobleme betrafen den Helmdatensatz. Es war ein faszinierender Weg: Wir gingen durch Glatzköpfige, Menschen mit Helmen in den Händen und sogar durch Glatzköpfige mit Helmen in den Händen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da wir zu Beginn der Reise nicht viele Bilder unter realen Bedingungen hatten, haben wir den Datensatz so gut wie möglich gesammelt: uns selbst gefilmt, Bilder aus dem Internet oder von Baustellen aufgenommen. Wenig später erhielten wir viele Videos von verschiedenen Unternehmen, sodass wir den Datensatz nur mit Frames realer Bedingungen anreicherten. Irgendwann überschritt die Anzahl der mit Tags versehenen Bilder 5 KB, und die Qualität durch Hinzufügen neuer Beispiele verbesserte sich nicht mehr. In dieser Hinsicht haben wir den Ansatz für das Markup überarbeitet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir werden die Phasen der Verbesserung des Helmdatensatzes am Beispiel von Bildern aus dem Internet beschreiben, sodass Winkel und Qualität nicht ganz mit denen übereinstimmen, die wir hatten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zusätzlich zu dem obigen Bild, das über den Hüften zugeschnitten ist, haben wir Bilder entfernt, in denen die Helme mehr als zur Hälfte zugeschnitten sind, um Verwechslungen mit Kappen zu vermeiden.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/zh/eu/dlzheusrhwz0grtyrxdxalkkupq.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben uns auch der Tatsache gestellt, dass wenn eine Person einen Helm in der Hand hat, das Modell oft keine Verstöße sah: Gibt es einen Helm? Es gibt. Daher haben wir alle Rahmen aus dem Trainingsdatensatz entfernt, in denen eine Person einen Helm mit der Hand hält, auch wenn sich der Helm gerade auf dem Kopf befindet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Allgemeinen haben wir versucht, Bilder mit beleuchtetem Hintergrund oder in dunklen Räumen zu entfernen, und dann haben wir die Anzahl der von uns aufgenommenen Fotos minimiert, wobei hauptsächlich Filmmaterial aus der Produktion übrig blieb. Infolgedessen haben wir den Datensatz um die Hälfte reduziert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zusätzlich haben wir den Datensatz mit Glatzköpfigen angereichert, ansonsten sind sie immer in Helmen, auch wenn dies nicht der Fall ist, und mit Blondinen mit Quadraten, für die der Detektor mit einem bestimmten Winkel auch den Helm bestimmt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir ungeeignete Bilder entfernt hatten, gingen wir direkt zum Markup (zum Erkennen von Objekten). Es stellte sich heraus, dass es nicht so einfach war. Es stellt sich heraus, dass die Qualität des Enddetektors weitgehend davon abhängt, was genau der Bereich im Bild als "Helm" oder "Handschuhe" markiert ist. Zunächst verteilten wir Helme und Schutzbrillen, ohne die Gesichter zu greifen, und Handschuhe mit den Händen. Mit der Erfahrung haben wir unseren Ansatz jedoch schrittweise verbessert, indem wir uns Fehler der ersten und zweiten Art angesehen haben, bei denen Menschen Helme in den Händen halten und etwas Rundes an etwas Langem sich als „Handschuh“ herausstellt. Beim Markieren von Helmen und Brillen versuchen wir nun, das Gesicht bis zur Nasenspitze zu greifen, und beim Markieren von Handschuhen beschränken wir uns im Gegenteil auf einen Pinsel.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/us/re/kausredcadkqks_cn012broh2qq.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis unserer Manipulationen am Datensatz haben wir die folgenden Ergebnisse erhalten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modell zum Erkennen des Vorhandenseins / Nichtvorhandenseins von PSA am Beispiel von Helmen: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ergebnisse einer Validierungsprobe vor Beginn der „globalen Arbeit“ am Datensatz</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/oo/rx/k-/oorxk-v05lijjyljtrp5lvtbsq4.jpeg" alt="Bild"></div><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Endergebnisse der Validierungsprobe</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/y1/nn/0u/y1nn0uy66v5qmwji-zk2rwotnle.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Vollständigkeit der Erkennung von Helmen ließ leicht nach, gleichzeitig verbesserten sich die Metriken zur Erkennung von Verstößen, und dies wollten wir erreichen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modell zur Klassifizierung des Vorhandenseins / Nichtvorhandenseins von Helmen: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ergebnisse einer Validierungsstichprobe vor Beginn der „globalen Arbeit“ am Datensatz</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wi/eu/fp/wieufpwnxltfvgf1kvkvisr3fk4.jpeg" alt="Bild"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Endergebnisse der Validierungsprobe</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ct/d1/etctd1ymh_9jmjvc3lgaz_mw47o.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es sollte beachtet werden, dass wir keine Unterteilung in Schutzbrillen und Brillen für das Sehen haben, sie fallen unter das gleiche Etikett „Brille“ und Handschuhe mit hellen Farbtönen können als bloßer Pinsel wahrgenommen werden. </font><font style="vertical-align: inherit;">Wir haben versucht, den Farbumfang von Helmen und Arbeitskleidung in unseren Datensätzen zu maximieren. Aus Gründen der Zuverlässigkeit haben wir dies jedoch mit der einfachsten und zuverlässigsten Technik ergänzt: Um Handschuhe zu erkennen, teilen wir unseren Kunden bei Bedarf mit, dass helle Farben zur Erhöhung der Genauigkeit beitragen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Moment haben wir universelle Modelle, die wir für die erste Show für den Kunden verwenden. </font><font style="vertical-align: inherit;">Es versteht sich jedoch, dass es unmöglich ist, ein universelles Modell für alle zu erstellen. Es ist notwendig, sich an jeden Kunden anzupassen, neue Nuancen zu identifizieren und zu berücksichtigen, Datensätze anzureichern oder neu zu erstellen, um bestimmte Anforderungen zu erfüllen.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kl/-l/9t/kl-l9tfsjdr528i4xgl5flmtqjk.jpeg" alt="Bild"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonus</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In der Regel möchten Kunden so viele Kameras wie möglich mit möglichst wenigen Ressourcen verarbeiten. </font><font style="vertical-align: inherit;">Butch ist natürlich eine gute Sache, aber zusätzliche Tricks zur Optimierung des Prozesses sind nicht verboten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Beispiel hatten meine Kollegen und ich vom Moskauer IBM-Kundencenter die Hypothese, dass das Zusammenfügen mehrerer Personen zur weiteren Erkennung von Helmen die Anzahl der Kameras pro Server mit einem prinzipienlosen Genauigkeitsverlust erhöhen würde. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Grundlage haben wir beschlossen, die Größe von 1000 x 600 für die Leinwand zu verwenden, auf die Personen "angewendet" werden. </font><font style="vertical-align: inherit;">Zunächst wurden zwei Layoutoptionen in Betracht gezogen:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feste Breite und Höhe (200x600), bei diesem Ansatz befinden sich 5 Personen auf dem Rahmen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feste Breite und Höhe (125x600), 8 Personen.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Entscheidung beruhte auf der Tatsache, dass wir mit festen Daten genau die Anzahl der Personen auf dem Foto kennen, was uns eine Prognose der Belastung gibt. </font><font style="vertical-align: inherit;">Während der Entwicklung haben wir jedoch eine solche Option in Betracht gezogen:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feste Höhe und proportionale Breite (*** x600), unterschiedliche Anzahl von Personen.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es wurde angenommen, dass mit zunehmender Größe und Beibehaltung der Proportionen die Ergebnisse im Vergleich zu anderen Layoutoptionen besser sind. </font><font style="vertical-align: inherit;">Die Anzahl der Personen lag zwischen 3 und 5 (+/–). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis haben wir festgestellt, dass die Option mit einer festen Breite und Höhe (200 x 600) die beste unter den in Betracht gezogenen ist. </font><font style="vertical-align: inherit;">Natürlich ist diese Methode nicht zum Erkennen von Brillen und Handschuhen geeignet, da die Objekte klein sind, aber zum Erkennen von Helmen / fehlenden Helmen zeigte diese Methode gute Ergebnisse. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zum Beispiel in einem Validierungsbeispiel:</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/wg/zy/arwgzypgxzuk6ykdrj57p851-co.jpeg" alt="Bild"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lw/y5/iilwy5ihzrc57ezgdnjp3gs646s.jpeg" alt="Bild"></div><br>
<i> :   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">tvoronova</a>),  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">elviraa</a>)</i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de499238/index.html">Löten zu Hause: Stream-Aufnahme</a></li>
<li><a href="../de499240/index.html">Durch Dornen zu den Sternen oder Datenanalyse in den Angelegenheiten des Himmels</a></li>
<li><a href="../de499242/index.html">Die Forscher übertrugen Daten von einem Desktop-PC durch Vibrationen über einen Tisch</a></li>
<li><a href="../de499244/index.html">Synergetische Organisationen. Teil II</a></li>
<li><a href="../de499246/index.html">Untersuchung der logistischen Funktion als Gesetz der Industrieentwicklung</a></li>
<li><a href="../de499252/index.html">Erstellen eines pseudo-dreidimensionalen Rennspiels</a></li>
<li><a href="../de499254/index.html">Das Mitglied des PyConRu 2020-Programmkomitees beantwortet Fragen zu Python: ein aktuelles Aussehen und ein bisschen Parseltang</a></li>
<li><a href="../de499262/index.html">Letzter Online-Hackathon für selbstständige SMZhack: Projekte, die die Menschen treffen werden</a></li>
<li><a href="../de499268/index.html">Raumbewusstsein: Was kann eine Hololens-Brille?</a></li>
<li><a href="../de499274/index.html">Wir haben die neue Kapsel zerlegt. Wir wissen, wie viele Mikrofone und wie es funktioniert</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
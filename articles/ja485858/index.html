<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👈🏾 🔞 👩🏾‍🤝‍👩🏼 美しさを見るために電話を教える方法 👨‍🏫 🌷 🔉</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="最近、私は数学と人々の美しさについての本を読み、10年前のこと、人間の美しさはかなり原始的であったものを理解する方法の考えについて考えました。数学の観点からどの顔が美しいと考えられるかについての推論は、それが対称であるべきであるという事実に帰着しました。また、ルネサンス以降、顔のある点における距離の...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>美しさを見るために電話を教える方法</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485858/"><img src="https://habrastorage.org/webt/-f/0z/on/-f0zonxrb_qtnmaxp2bt34gu-d4.png" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最近、私は数学と人々の美しさについての本を読み、10年前のこと、人間の美しさはかなり原始的であったものを理解する方法の考えについて考えました。数学の観点からどの顔が美しいと考えられるかについての推論は、それが対称であるべきであるという事実に帰着しました。また、ルネサンス以降、顔のある点における距離の関係を用いて美しい顔を描き、例えば美しい顔は黄金比に近い何らかの関係があることを示す試みがなされてきました。ポイントの位置についての同様のアイデアが、顔を識別する方法の1つとして使用されています（顔のランドマーク検索）。ただし、経験上、特徴のセットを顔の特定のポイントの位置に限定しない場合、多くのタスクでより良い結果を得ることができることが示されています。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">年齢、性別、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">さらには</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">性的指向の</font></font></a><font style="vertical-align: inherit;"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">判断も含まれ</font></a><font style="vertical-align: inherit;">ます。そのような研究の結果を公表することの倫理の問題が深刻なものであるかもしれないことは、ここですでに明らかです。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
人々の美しさとその評価のテーマは、倫理的にも物議を醸す可能性があります。</font><font style="vertical-align: inherit;">アプリケーションを開発するとき、私の友人の多くは写真をテストに使用することを拒否したか、結果を知りたくなかっただけです（ほとんどの女の子が結果を知ることを拒否したのはおかしいです）。</font><font style="vertical-align: inherit;">また、美しさの評価を自動化するという目標は、興味深い哲学的問題を提起する可能性があります。</font><font style="vertical-align: inherit;">美しさの概念は、文化によってどの程度決定されますか？</font><font style="vertical-align: inherit;">「見る人の目の美しさ」はどのくらい本当ですか？</font><font style="vertical-align: inherit;">客観的な美しさを強調することは可能ですか？</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらの質問に答えるには、一部の人による他の人の評価に関する統計を調査する必要があります。</font><font style="vertical-align: inherit;">美しさを評価するニューラルネットワークモデルを設計してトレーニングし、Androidスマートフォンで実行してみました。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パート0.パイプライン</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のステップが互いにどのように関連しているかを理解するために、プロジェクトの図を描きました：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/cy/jp/zh/cyjpzhhy_hiczxqefjp9qgaohf0.png" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
青-重要なライブラリと外部データ。</font><font style="vertical-align: inherit;">黄色-アプリケーションのコントロール。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パート1. Python</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
美しさの評価はかなりデリケートなトピックであるため、評価付きの写真を含むパブリックドメインのデータセットはそれほど多くありません（火口のようなオンラインの出会い系サービスには、はるかに大きな統計セットがあると思います）。</font><font style="vertical-align: inherit;">中国の大学の1つで編集され</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">たデータベース</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を見つけまし</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">た</font></a><font style="vertical-align: inherit;">。5500枚の写真があり、それぞれ中国人学生の7人の評価者が評価しました。 5,500枚の写真のうち、2,000枚はアジアの男性（AM）、2000枚はアジアの女性（AF）、750枚のユーロピオイドの男性（CM）と女性（CF）です。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/fcf/1db/f9b/fcf1dbf9b67fee5543fdc9833d429676.jpg" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Python pandasモジュールを使用してデータを読み取り、片目でデータを見てみましょう。性別と人種ごとの推定分布：</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
ratingDS=pd.read_excel(<span class="hljs-string">'../input/faces-scut/scut-fbp5500_v2/SCUT-FBP5500_v2/All_Ratings.xlsx'</span>)<font></font>
Answer=ratingDS.groupby(<span class="hljs-string">'Filename'</span>).mean()[<span class="hljs-string">'Rating'</span>]<font></font>
ratingDS[<span class="hljs-string">'race'</span>]=ratingDS[<span class="hljs-string">'Filename'</span>].apply(<span class="hljs-keyword">lambda</span> x:x[:<span class="hljs-number">2</span>])<font></font>
fig, ax = plt.subplots(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, sharex=<span class="hljs-string">'col'</span>)
<span class="hljs-keyword">for</span> i, race <span class="hljs-keyword">in</span> enumerate([<span class="hljs-string">'CF'</span>,<span class="hljs-string">'CM'</span>,<span class="hljs-string">'AF'</span>,<span class="hljs-string">'AM'</span>]):<font></font>
    sbp=ax[i%<span class="hljs-number">2</span>,i//<span class="hljs-number">2</span>]<font></font>
    ratingDS[ratingDS[<span class="hljs-string">'race'</span>]==race].groupby(<span class="hljs-string">'Filename'</span>)[<span class="hljs-string">'Rating'</span>].mean().hist(alpha=<span class="hljs-number">0.5</span>, bins=<span class="hljs-number">20</span>,label=race,grid=<span class="hljs-literal">False</span>,rwidth=<span class="hljs-number">0.9</span>,ax=sbp)<font></font>
    sbp.set_title(race)<font></font>
</code></pre><br>
<img src="https://habrastorage.org/webt/fz/1q/fo/fz1qfoby_-ijefbbl4ifctz3llo.png" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一般に、男性は女性ほど美しくないと見なされ、分布は二峰性です-それらがあります。美しく、「平均的」と見なされている人。低い評価はほとんどないため、データを再正規化できます。とりあえず、そのままにしておきましょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
推定値の標準偏差を見てみましょう。</font></font><br>
<br>
<pre><code class="python hljs">ratingDS.groupby(<span class="hljs-string">'Filename'</span>)[<span class="hljs-string">'Rating'</span>].std().mean()
</code></pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは0.64です。これは、さまざまな評価者の評価の差が5点満点で1ポイント未満であることを意味します。これは、美しさの評価における全会一致を示します。</font><font style="vertical-align: inherit;">「美は見る人の目にはない」と合理的に言える。</font><font style="vertical-align: inherit;">平均化するときは、データを確実に使用してモデルをトレーニングでき、プログラムによる評価の基本的な不可能性について心配する必要はありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、推定値の標準偏差の値が小さいにもかかわらず、一部の評価者の意見は「通常の」意見とは大きく異なる場合があります。</font><font style="vertical-align: inherit;">推定値と中央値の差の分布を作成してみましょう。</font></font><br>
<br>
<pre><code class="python hljs">R2=ratingDS.join(ratingDS.groupby(<span class="hljs-string">'Filename'</span>)[<span class="hljs-string">'Rating'</span>].median(), on=<span class="hljs-string">'Filename'</span>, how=<span class="hljs-string">'inner'</span>,rsuffix =<span class="hljs-string">' median'</span>)<font></font>
R2[<span class="hljs-string">'ratingdiff'</span>]=(R2[<span class="hljs-string">'Rating median'</span>]-R2[<span class="hljs-string">'Rating'</span>]).astype(int)<font></font>
print(set(R2[<span class="hljs-string">'ratingdiff'</span>]))<font></font>
R2[<span class="hljs-string">'ratingdiff'</span>].hist(label=<span class="hljs-string">'difference of raings'</span>,bins=[<span class="hljs-number">-3.5</span>,<span class="hljs-number">-2.5</span>,<span class="hljs-number">-1.5</span>,<span class="hljs-number">-0.5</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">1.5</span>,<span class="hljs-number">2.5</span>,<span class="hljs-number">3.5</span>,<span class="hljs-number">4.5</span>],grid=<span class="hljs-literal">False</span>,rwidth=<span class="hljs-number">0.5</span>)
</code></pre><br>
<img src="https://habrastorage.org/webt/ww/qb/7w/wwqb7wdyk_neg_semros1qthb_g.png" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
興味深いパターンが見つかりました。</font><font style="vertical-align: inherit;">スコアが中央値と1ポイント以上異なる人</font></font><br>
<br>
<pre><code class="python hljs">len(R2[R2[<span class="hljs-string">'ratingdiff'</span>].abs()&gt;<span class="hljs-number">1</span>])/len(R2)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
0.02943333333333333332 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3％未満。</font><font style="vertical-align: inherit;">つまり、美しさを評価することで、印象的な全会一致が再び確認されます。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
必要な平均評価で表を作成します</font></font><br>
<br>
<pre><code class="python hljs">Answer=ratingDS.groupby(<span class="hljs-string">'Filename'</span>).mean()[<span class="hljs-string">'Rating'</span>]
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちのデータベースは小さいです。また、すべての写真に顔全体の画像が含まれているので、顔のどの位置でも確実な結果が欲しいです。少量のデータの問題を解決するために、転移学習手法がよく使用されます。これは、類似のタスクとその修正のために事前トレーニングされたモデルの使用です。私の仕事に近いのが顔認識の仕事です。これは通常、3段階で解決されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1.画像とそのスケーリングに顔検出があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2.畳み込みニューラルネットワークを使用して、顔の画像を特徴ベクトルに変換します。このような変換の特性は、顔の回転、髪型の変化に対して変換が不変であることです。感情の現れと一時的なイメージ。そのようなネットワークを学習すること自体は、興味深い作業であり、長時間書くことができます。さらに、この追跡を改善して質量追跡および識別アルゴリズムを改善するために、常に新しい開発が行われています。ネットワークアーキテクチャとトレーニング方法の両方を最適化します（例：トリプレット損失-cosface-arcface損失）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3.特徴ベクトルとデータベースに保存されている特徴ベクトルの比較。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちのタスクでは、1〜2ポイントの既製のソリューションを使用しました。顔を検出するタスクは一般に多くの方法で解決されます。さらに、ほとんどすべてのモバイルデバイスに顔検出器があり（Androidでは標準のGooglePlayサービスパッケージの一部です）、顔の検出に使用されます。面のベクトル形式への変換に関しては、1つの明白でない微妙な点があります。事実はその兆候です。認識問題を解決するために抽出された-人間にとって典型的ですが、美しさとはまったく相関しない場合があります。さらに。畳み込みニューラルネットワークの特殊性により、これらの兆候は主に局所的であり、一般に、これは多くの問題を引き起こす可能性があります（単一ピクセル攻撃）。それにもかかわらず、結果はベクトルの次元に大きく依存していることを発見しました。128の符号では美しさを決定するのに十分でない場合、512で十分です。これに基づいて、選択されました</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ResnetベースのinsightFace事前トレーニング済みネットワーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">機械学習のフレームワークとしてケラスを使用します。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
事前トレーニング済みモデルをダウンロードするための詳細なコードは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こちらにあります。</font></font></a><br>
<br>
<pre><code class="python hljs">model=LResNet100E_IR() 
</code></pre><br><font style="vertical-align: inherit;"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">mtcnn顔</font></a><font style="vertical-align: inherit;"> 
検出器は、前処理の顔検出器として使用されました</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></a><br>
<br>
<pre><code class="python hljs">detector = MtcnnDetector(model_folder=mtcnn_path, ctx=ctx, num_worker=<span class="hljs-number">1</span>, accurate_landmark = <span class="hljs-literal">True</span>, threshold=det_threshold)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データセットから画像を整列、トリミング、ベクトル化します。</font></font><br>
<br>
<pre><code class="python hljs">imgpath=<span class="hljs-string">'../input/faces-scut/scut-fbp5500_v2/SCUT-FBP5500_v2/Images/'</span>
<span class="hljs-comment">#   </span><font></font>
facevecs=[]<font></font>
<span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> tqdm.tqdm(Answer.index):
<span class="hljs-comment">#  </span><font></font>
    img1 = cv2.imread(imgpath+name)<font></font>
<span class="hljs-comment"># ,    </span>
    pre1 = np.moveaxis(get_input(detector,img1),<span class="hljs-number">0</span>,<span class="hljs-number">-1</span>)
<span class="hljs-comment"># </span><font></font>
    vec = model.predict(np.stack([pre1]))<font></font>
<span class="hljs-comment">#  </span><font></font>
    facevecs.append(vec)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データをトレーニング（90％、それらについて研究する）と検証（モデルでの作業をチェックする）ベクトルに分割することでデータを準備します。</font><font style="vertical-align: inherit;">データを0〜1の範囲に正規化します。</font></font><br>
<br>
<pre><code class="python hljs">X=np.stack(facevecs)[:,<span class="hljs-number">0</span>,:]<font></font>
Y=(Answer[:])/<span class="hljs-number">5</span><font></font>
Indicies=np.arange(len(Answer))<font></font>
X,Y,Indicies=sklearn.utils.shuffle(X,Y,Indicies)<font></font>
Xtrain=X[:int(len(facevecs)*<span class="hljs-number">0.9</span>)]<font></font>
Ytrain=Y[:int(len(facevecs)*<span class="hljs-number">0.9</span>)]<font></font>
Indtrain=Indicies[:int(len(facevecs)*<span class="hljs-number">0.9</span>)]<font></font>
Xval=X[int(len(facevecs)*<span class="hljs-number">0.9</span>):]<font></font>
Yval=Y[int(len(facevecs)*<span class="hljs-number">0.9</span>):]<font></font>
Indval=Indicies[int(len(facevecs)*<span class="hljs-number">0.9</span>):]
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それではモデルに移りましょう。</font><font style="vertical-align: inherit;">美しさを説明します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Createheadmodel</span>():</span>
    inp=keras.layers.Input((<span class="hljs-number">512</span>,))<font></font>
    x=keras.layers.Dense(<span class="hljs-number">32</span>,activation=<span class="hljs-string">'elu'</span>)(inp)<font></font>
    x=keras.layers.Dropout(<span class="hljs-number">0.1</span>)(x)<font></font>
    out=keras.layers.Dense(<span class="hljs-number">1</span>,activation=<span class="hljs-string">'hard_sigmoid'</span>,use_bias=<span class="hljs-literal">False</span>,kernel_initializer=keras.initializers.Ones())(x)<font></font>
    model=keras.models.Model(input=inp,output=out)<font></font>
    model.layers[<span class="hljs-number">-1</span>].trainable=<span class="hljs-literal">False</span>
    model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number">0.0001</span>), loss=<span class="hljs-string">'mse'</span>)
    <span class="hljs-keyword">return</span> model<font></font>
modelhead=Createheadmodel()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このモデルは、32個のニューロンと512個の入力ノードを備えた、単一層の完全に接続されたニューラルネットワークです。ただし、最も単純なアーキテクチャの1つですが、十分にトレーニングされています。</font></font><br>
<br>
<pre><code class="python hljs">hist=modelhead.fit(Xtrain,Ytrain,<font></font>
    epochs=<span class="hljs-number">4000</span>,<font></font>
    batch_size=<span class="hljs-number">5000</span>,<font></font>
    validation_data=(Xval,Yval)<font></font>
    )<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4950/4950 [===============================]-0s 3us /ステップ-損失：0.0069-val_loss：0.0071 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
曲線を作成し</font><font style="vertical-align: inherit;">ましょう</font><font style="vertical-align: inherit;">学習する</font></font><br>
<br>
<pre><code class="python hljs">plt.plot(hist.history[<span class="hljs-string">'loss'</span>][<span class="hljs-number">100</span>:], label=<span class="hljs-string">'loss'</span>)<font></font>
plt.plot(hist.history[<span class="hljs-string">'val_loss'</span>][<span class="hljs-number">100</span>:],label=<span class="hljs-string">'validation_loss'</span>)<font></font>
plt.legend(bbox_to_anchor=(<span class="hljs-number">0.95</span>, <span class="hljs-number">0.95</span>), loc=<span class="hljs-string">'upper right'</span>, borderaxespad=<span class="hljs-number">0.</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
検証データの損失（平均二乗偏差）は0.0071であることがわかります。したがって、標準偏差= 5ポイントスケールで0.084または0.42ポイントであり、これは人によって与えられた推定値の広がり（0.6ポイント）よりも小さくなっています。</font><font style="vertical-align: inherit;">私たちのモデルは機能しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルがどのように機能するかを視覚化するには、散布図を使用できます。検証データの各写真について、座標の1つが顔の平均評価に対応し、2番目が平均の予測評価に対応する点を作成します。</font></font><br>
<br>
<pre><code class="python hljs">Answer2=Answer.to_frame()[:<span class="hljs-number">5500</span>]<font></font>
Answer2[<span class="hljs-string">'ans'</span>]=<span class="hljs-number">0</span>
Answer2[<span class="hljs-string">'race'</span>]=Answer2.index<font></font>
Answer2[<span class="hljs-string">'race'</span>]=Answer2[<span class="hljs-string">'race'</span>].apply(<span class="hljs-keyword">lambda</span> x: x[:<span class="hljs-number">2</span>])<font></font>
Answer2[<span class="hljs-string">'ans'</span>]=modelhead.predict(np.stack(facevecs)[:,<span class="hljs-number">0</span>,:])*<span class="hljs-number">5</span>
xy=np.array(Answer2.iloc[Indval][[<span class="hljs-string">'ans'</span>,<span class="hljs-string">'Rating'</span>]])<font></font>
plt.scatter(xy[:,<span class="hljs-number">1</span>],xy[:,<span class="hljs-number">0</span>])
</code></pre><br>
<img src="https://habrastorage.org/webt/w2/t9/dd/w2t9ddnfyzjpx-xp7q3_wmsubzk.png" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y軸はモデルによって予測された値であり、X軸は人々の推定値の平均値です。</font><font style="vertical-align: inherit;">高い相関が見られます（図は対角線に沿って細長くなっています）。</font><font style="vertical-align: inherit;">結果を視覚的に確認することもできます-1から5までの予測評価で各カテゴリの顔を見てください</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> matplotlib.image <span class="hljs-keyword">as</span> mpimg<font></font>
f, axarr = plt.subplots(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>))
<span class="hljs-keyword">for</span> i, race <span class="hljs-keyword">in</span> enumerate([<span class="hljs-string">'AF'</span>,<span class="hljs-string">'CF'</span>, <span class="hljs-string">"AM"</span>, <span class="hljs-string">'CM'</span>]):
    <span class="hljs-keyword">for</span> rating <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>):
        <span class="hljs-comment">#axarr[i,rating-1].axis('off')</span>
        axarr[i,rating<span class="hljs-number">-1</span>].tick_params(<span class="hljs-comment"># changes apply to the x-axis</span>
        which=<span class="hljs-string">'both'</span>,      <span class="hljs-comment"># both major and minor ticks are affected</span>
        bottom=<span class="hljs-literal">False</span>,      <span class="hljs-comment"># ticks along the bottom edge are off</span>
        top=<span class="hljs-literal">False</span>,         <span class="hljs-comment"># ticks along the top edge are off</span>
        right=<span class="hljs-literal">False</span>,<font></font>
        left=<span class="hljs-literal">False</span>,<font></font>
        labelbottom=<span class="hljs-literal">False</span>,<font></font>
        labelleft=<span class="hljs-literal">False</span><font></font>
        )<font></font>
        picname=(Answer2[Answer2[<span class="hljs-string">'race'</span>]==race][<span class="hljs-string">'ans'</span>]-rating).abs().argmin()<font></font>
        axarr[i,rating<span class="hljs-number">-1</span>].set_xlabel(Answer2.loc[picname][<span class="hljs-string">'ans'</span>])<font></font>
        axarr[i,rating<span class="hljs-number">-1</span>].imshow(mpimg.imread(imgpath+picname))
</code></pre><br>
<img src="https://habrastorage.org/webt/i4/az/pe/i4azpe-biju4pozojrgpiyxkoag.png" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
美しさで並べ替えた結果は妥当に見えます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、入力に顔を送信する完全なモデルを作成します。出力で0から1までの評価を取得し、電話に適したtflite形式に変換します</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
finmodel=Model(input=model.input, output=modelhead(model.output))<font></font>
finmodel.save(<span class="hljs-string">'finmodel.h5'</span>)<font></font>
converter = tf.lite.TFLiteConverter.from_keras_model_file(<span class="hljs-string">'finmodel.h5'</span>)<font></font>
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]<font></font>
tflite_quant_model = converter.convert()<font></font>
open (<span class="hljs-string">"modelquant.tflite"</span> , <span class="hljs-string">"wb"</span>).write(tflite_quant_model)
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> FileLink<font></font>
FileLink(<span class="hljs-string">r'modelquant.tflite'</span>) 
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このモデルは、入力で112 * 112 * 3のサイズの顔の画像を受け取り、出力で0から1までの単一の数値を与えます。これは、顔の美しさを意味します（ただし、データセットでは評価が0から5まで変化せず、1から5まで変化しなかったことを覚えておく必要があります）。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パート2. JAVA</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Androidフォン用の簡単なアプリケーションを書いてみましょう。 Java言語は私にとって新しいものであり、Androidの開発に携わったことがないため、プロジェクトでは作業の最適化を使用せず、フロー制御など、初心者にとって労働集約的なものを使用していません。 Javaコードはかなり扱いにくいので、ここではプログラムが機能するために最も重要な部分のみを示します。完全なアプリケーションコードは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こちらから</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">入手でき</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。アプリケーションは写真を開き、以前に保存したネットワークを使用して顔を検出して評価し、結果を提供します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7s/si/a-/7ssia-98n-lxqpitskjaudyohpc.png" alt="画像"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
開発の観点から、次の機能が重要</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
です。1。アセットフォルダーのmodel.tfliteファイルからインタープリターオブジェクトにニューラルネットワークをロードする機能</font></font><br>
<br>
<pre><code class="java hljs"><span class="hljs-keyword">import</span> org.tensorflow.lite.Interpreter;<font></font>
Interpreter interpreter;<font></font>
<span class="hljs-keyword">try</span> {<font></font>
            interpreter=<span class="hljs-keyword">new</span> Interpreter(loadModelFile(MainActivity.<span class="hljs-keyword">this</span>));<font></font>
            Log.e(<span class="hljs-string">"TIME"</span>, <span class="hljs-string">"Interpreter_started "</span>);<font></font>
        } <span class="hljs-keyword">catch</span> (IOException e) {<font></font>
            e.printStackTrace();<font></font>
            Log.e(<span class="hljs-string">"TIME"</span>, <span class="hljs-string">"Interpreter NOT started "</span>);<font></font>
        }<font></font>
<span class="hljs-function"><span class="hljs-keyword">private</span> MappedByteBuffer <span class="hljs-title">loadModelFile</span><span class="hljs-params">(Activity activity)</span> <span class="hljs-keyword">throws</span> IOException </span>{<font></font>
        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(<span class="hljs-string">"model.tflite"</span>);<font></font>
        FileInputStream inputStream = <span class="hljs-keyword">new</span> FileInputStream(fileDescriptor.getFileDescriptor());<font></font>
        FileChannel fileChannel = inputStream.getChannel();<font></font>
        <span class="hljs-keyword">long</span> startOffset = fileDescriptor.getStartOffset();
        <span class="hljs-keyword">long</span> declaredLength = fileDescriptor.getDeclaredLength();
        <span class="hljs-keyword">return</span> fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);<font></font>
    }<font></font>
<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2. Googleの標準ライブラリパッケージの一部であるFaceDetectorモジュールを使用して顔を検出し、ニューラルネットワークを使用して結果を表示します。</font></font><br>
<br>
<pre><code class="java hljs"><span class="hljs-keyword">import</span> com.google.android.gms.vision.face.Face;
<span class="hljs-keyword">import</span> com.google.android.gms.vision.face.FaceDetector;
<span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">detectFace</span><span class="hljs-params">()</span></span>{
        <span class="hljs-comment">//Create a Paint object for drawing with</span>
        Paint myRectPaint = <span class="hljs-keyword">new</span> Paint();<font></font>
        myRectPaint.setStrokeWidth(<span class="hljs-number">5</span>);<font></font>
        myRectPaint.setColor(Color.GREEN);<font></font>
        myRectPaint.setStyle(Paint.Style.STROKE);<font></font>
        Paint fontPaint = <span class="hljs-keyword">new</span> Paint();<font></font>
        fontPaint.setStrokeWidth(<span class="hljs-number">3</span>);<font></font>
        fontPaint.setTextSize(<span class="hljs-number">70</span>);<font></font>
        fontPaint.setColor(Color.BLUE);<font></font>
        fontPaint.setStyle(Paint.Style.FILL_AND_STROKE);<font></font>
        <span class="hljs-comment">//Create a Canvas object for drawing on</span><font></font>
        tempBitmap = Bitmap.createBitmap(myBitmap.getWidth(), myBitmap.getHeight(), Bitmap.Config.RGB_565);<font></font>
        Canvas tempCanvas = <span class="hljs-keyword">new</span> Canvas(tempBitmap);<font></font>
        tempCanvas.drawBitmap(myBitmap, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-keyword">null</span>);
        <span class="hljs-comment">//Detect the Faces</span>
        FaceDetector faceDetector = <span class="hljs-keyword">new</span> FaceDetector.Builder(getApplicationContext()).build();<font></font>
        Frame frame = <span class="hljs-keyword">new</span> Frame.Builder().setBitmap(myBitmap).build();<font></font>
        SparseArray&lt;Face&gt; faces = faceDetector.detect(frame);<font></font>
        Face face;<font></font>
        <span class="hljs-keyword">float</span>[][] labelProbArray = <span class="hljs-keyword">new</span> <span class="hljs-keyword">float</span>[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>];<font></font>
        imgData.order(ByteOrder.nativeOrder());<font></font>
        <span class="hljs-comment">//Draw Rectangles on the Faces</span>
        <span class="hljs-keyword">if</span> (faces.size()&gt;<span class="hljs-number">0</span>){
            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; faces.size(); i++) {<font></font>
                face = faces.valueAt(i);<font></font>
                isFaceFound=<span class="hljs-keyword">true</span>;
                <span class="hljs-keyword">float</span> x1 = Math.max(face.getPosition().x,<span class="hljs-number">0</span>);
                <span class="hljs-keyword">float</span> y1 = Math.max(face.getPosition().y,<span class="hljs-number">0</span>);
                <span class="hljs-keyword">float</span> x2 = Math.min(x1 + face.getWidth(),frame.getBitmap().getWidth());
                <span class="hljs-keyword">float</span> y2 = Math.min(y1 + face.getHeight(),frame.getBitmap().getHeight());<font></font>
                Bitmap tempbitmap2 = Bitmap.createBitmap(tempBitmap, (<span class="hljs-keyword">int</span>)x1, (<span class="hljs-keyword">int</span>)y1, (<span class="hljs-keyword">int</span>) (x2-x1), (<span class="hljs-keyword">int</span>) (y2-y1));<font></font>
                tempbitmap2 = Bitmap.createScaledBitmap(tempbitmap2, <span class="hljs-number">112</span>, <span class="hljs-number">112</span>, <span class="hljs-keyword">true</span>);<font></font>
                convertBitmapToByteBuffer(tempbitmap2);<font></font>
                interpreter.run(imgData, labelProbArray);<font></font>
                String textToShow = String.format(<span class="hljs-string">"%.1f"</span>, (Answer[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]*<span class="hljs-number">5</span>-<span class="hljs-number">1</span>)/<span class="hljs-number">4</span> * <span class="hljs-number">10</span>);<font></font>
                textToShow = textToShow + <span class="hljs-string">"/10"</span>;
                <span class="hljs-keyword">int</span> width= tempCanvas.getWidth();
                <span class="hljs-comment">//int height=tempCanvas.getHeight();</span>
                <span class="hljs-keyword">int</span> fontsize=Math.max(width/<span class="hljs-number">20</span>,imgView.getWidth()/<span class="hljs-number">20</span>);<font></font>
                fontPaint.setTextSize(fontsize);<font></font>
                tempCanvas.drawText(textToShow, x1, y1-<span class="hljs-number">10</span>, fontPaint);<font></font>
                tempCanvas.drawRoundRect(<span class="hljs-keyword">new</span> RectF(x1, y1, x2, y2), <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, myRectPaint) }<font></font>
            imgView.setImageDrawable(<span class="hljs-keyword">new</span> BitmapDrawable(getResources(),tempBitmap));<font></font>
        }<font></font>
    }<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スマートフォンでグレーディングを試してみたい場合</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、GooglePlayマーケットからアプリケーションを</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ダウンロードできます</font><font style="vertical-align: inherit;">。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja485848/index.html">OpenHABを1000日間使用してからHome Assistantに切り替えた方法</a></li>
<li><a href="../ja485850/index.html">クリックハウスが太陽銀河で選ばれた方法</a></li>
<li><a href="../ja485852/index.html">ユーザビリティ監査オンラインストアを注文しない10の理由</a></li>
<li><a href="../ja485854/index.html">C ++コンパイラが関数のオーバーロードを解決するのを助ける</a></li>
<li><a href="../ja485856/index.html">ヘキサポッドをどのように印刷したか、そしてそれから何が生まれたか</a></li>
<li><a href="../ja485862/index.html">コーヒーメーカーのDDoS</a></li>
<li><a href="../ja485864/index.html">人事で分析を使い始めたとき、従業員について何を学びましたか</a></li>
<li><a href="../ja485866/index.html">Zimbra Open-Source Editionとエンタープライズポータルの統合</a></li>
<li><a href="../ja485868/index.html">教室や教室の照明</a></li>
<li><a href="../ja485870/index.html">サハリンにGameDevはありますか？2.V</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
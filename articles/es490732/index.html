<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî° üõ¥ üë©üèº Reconocimiento de voz: un curso introductorio muy corto üéÅ ‚ôíÔ∏è üë©üèø‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es casi imposible decirle al lego lo m√°s simple posible sobre el trabajo del reconocimiento de voz por computadora y convertirlo en texto. Ni una sola...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Reconocimiento de voz: un curso introductorio muy corto</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/toshibarus/blog/490732/"><img src="https://habrastorage.org/webt/tz/sh/ll/tzshllxzf2iddwai7sredy3edie.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es casi imposible decirle al lego lo m√°s simple posible sobre el trabajo del reconocimiento de voz por computadora y convertirlo en texto. </font><font style="vertical-align: inherit;">Ni una sola historia sobre esto est√° completa sin f√≥rmulas complejas y t√©rminos matem√°ticos. </font><font style="vertical-align: inherit;">Trataremos de explicar de la manera m√°s clara y simplista posible c√≥mo su tel√©fono inteligente entiende el habla, cuando los autom√≥viles han aprendido a reconocer una voz humana y en qu√© √°reas inesperadas se utiliza esta tecnolog√≠a. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Advertencia necesaria: si usted es un desarrollador o, especialmente, un matem√°tico, es poco probable que aprenda algo nuevo de la publicaci√≥n e incluso se queje de la naturaleza cient√≠fica insuficiente del material. </font><font style="vertical-align: inherit;">Nuestro objetivo es presentar a los lectores no iniciados las tecnolog√≠as del habla de la manera m√°s simple y contar c√≥mo y por qu√© Toshiba tom√≥ la creaci√≥n de su AI de voz.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hitos importantes en la historia del reconocimiento de voz</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La historia del reconocimiento del habla humana por las m√°quinas electr√≥nicas comenz√≥ un poco antes de lo habitual: en la mayor√≠a de los casos es habitual contar desde 1952, pero de hecho, uno de los primeros dispositivos que respondi√≥ a los comandos de voz fue el robot Televox, sobre el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que ya escribimos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Creado en 1927 en los EE. UU., El robot Herbert Televox era un dispositivo simple en el que varios rel√©s reaccionaban a sonidos de diferentes frecuencias. El robot ten√≠a tres diapasones, cada uno de los cuales era responsable de su tono. Dependiendo de qu√© diapas√≥n funcion√≥, se activ√≥ uno u otro rel√©.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/90/pq/4i/90pq4ixpys3c8uevjp-ovvydfny.jpeg" alt="imagen"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De hecho, todo el "llenado" de Televox, incluido el sistema de reconocimiento de comandos, estaba ubicado en un estante en el √°rea del cuerpo del "robot". Era imposible cerrar su tapa, de lo contrario los diapasones no podr√≠an "escuchar" correctamente los sonidos. Fuente: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acme Telepictures / Wikimedia:</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
fue posible comunicarse con Televox como se√±ales separadas usando un silbato, o en breves se√±ales verbales: sus diapasones tambi√©n se presentaron en una secuencia de sonidos. El creador del robot, Roy Wensley, incluso organiz√≥ una demostraci√≥n fant√°stica para esos tiempos, diciendo el comando "S√©samo, abierto", a trav√©s del cual Televox encendi√≥ el rel√© responsable de abrir la puerta. Sin tecnolog√≠a digital, redes neuronales, inteligencia artificial y aprendizaje autom√°tico, ¬°solo tecnolog√≠a anal√≥gica!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El siguiente invento clave que allan√≥ el camino para el verdadero reconocimiento del habla humana fue la m√°quina Audrey, desarrollada en 1952 en el Bell Labs Innovation Forge. El enorme Audrey consum√≠a mucha electricidad y era del tama√±o de un buen gabinete, pero toda su funcionalidad se reduc√≠a a reconocer los n√∫meros hablados del cero al nueve. Solo diez palabras, s√≠, pero no olvidemos que Audrey era una m√°quina anal√≥gica. </font></font><br>
<img src="https://habrastorage.org/webt/vd/1q/eb/vd1qebrer6czotgwty3tdyfp15i.png" alt="imagen"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desafortunadamente, la historia no ha conservado fotograf√≠as p√∫blicas de Audrey, solo hay un concepto. Simple en papel, dif√≠cil de traducir: seg√∫n las memorias de los contempor√°neos, los componentes de Audrey ocuparon un gabinete completo. Fuente: Laboratorios Bell</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Funcion√≥ as√≠: el locutor habl√≥ n√∫meros en el micr√≥fono, haciendo intervalos de al menos 350 ms entre palabras, Audrey convirti√≥ los sonidos que escuch√≥ en se√±ales el√©ctricas y los compar√≥ con muestras grabadas en la memoria anal√≥gica. Seg√∫n los resultados de la comparaci√≥n, el autom√≥vil resalt√≥ el n√∫mero en el tablero. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fue un gran avance, pero Audrey no obtuvo ning√∫n beneficio real: la m√°quina reconoci√≥ la voz de su creador con una precisi√≥n del 97%, otros oradores especialmente capacitados recibieron una precisi√≥n del 70-80%. Los extra√±os que se contactaron por primera vez con Audrey, sin importar cu√°nto lo intentaron, vieron su n√∫mero en el marcador en solo el 50% de los casos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A pesar de los resultados revolucionarios para su √©poca, Audrey no encontr√≥, y no pudo encontrar una aplicaci√≥n pr√°ctica. </font><font style="vertical-align: inherit;">Se supon√≠a que el sistema pod√≠a adaptarse en lugar de los operadores telef√≥nicos, pero sin embargo, los servicios humanos eran m√°s convenientes, m√°s r√°pidos y mucho m√°s confiables que Audrey.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rQco1sa9AwU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Presentaci√≥n similar a Audrey, m√°quinas mucho m√°s peque√±as, IBM Shoebox. </font><font style="vertical-align: inherit;">La velocidad de la caja de zapatos es claramente visible. </font><font style="vertical-align: inherit;">La m√°quina tambi√©n podr√≠a realizar operaciones matem√°ticas simples de suma y resta.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A principios de la d√©cada de 1960, el trabajo para crear m√°quinas para el reconocimiento de voz se llev√≥ a cabo en Jap√≥n, el Reino Unido, los EE. UU. E incluso la URSS, donde inventaron un algoritmo muy importante para la transformaci√≥n din√°mica de la l√≠nea de tiempo (DTW), con la ayuda de la cual fue posible construir un sistema que sepa unas 200 palabras. Pero todos los desarrollos fueron similares entre s√≠, y el principio de reconocimiento se convirti√≥ en un inconveniente com√∫n: las palabras se percib√≠an como huellas dactilares sonoras integrales, y luego se comparaban con la base de muestras (diccionario). Cualquier cambio en la velocidad, el timbre y la claridad de la pronunciaci√≥n de las palabras afectaron significativamente la calidad del reconocimiento. Los cient√≠ficos tienen una nueva tarea: ense√±ar a la m√°quina a escuchar sonidos, fonemas o s√≠labas individuales y luego hacer palabras a partir de ellos. Tal enfoque permitir√≠a nivelar el efecto de cambiar el altavoz, cuando, dependiendo del altavoz, el nivel de reconocimiento vari√≥ bruscamente.</font></font><br>
<br>
<i> ‚Äî     ,           . ,   ¬´ ¬ª  ¬´¬ª       ¬´¬ª.   ¬´¬ª   ¬´ ¬ª  ¬´ ¬ª      ¬´¬ª,    ‚Äî  ¬´¬ª.  ,  ,   . </i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En 1971, la Agencia de Proyectos de Investigaci√≥n Avanzada del Departamento de Defensa (DARPA) lanz√≥ un programa de cinco a√±os con un presupuesto de $ 15 millones, que ten√≠a la tarea de crear un sistema de reconocimiento que supiera al menos 1000 palabras. En 1976, la Universidad Carnegie Mellon introdujo Harpy, capaz de operar un diccionario de 1011 palabras. Harpy no compar√≥ las palabras completamente escuchadas con las muestras, pero las dividi√≥ en al√≥fonos (una muestra del sonido de un fonema dependiendo de las letras que lo rodean). Este fue otro √©xito, confirmando que el futuro est√° en el reconocimiento de fonemas individuales, en lugar de palabras completas. Sin embargo, entre los inconvenientes de Harpy se encontraba un nivel extremadamente bajo de reconocimiento correcto de al√≥fonos (pronunciaciones de fonemas): alrededor del 47%. Con un error tan alto, la proporci√≥n de errores creci√≥ despu√©s del volumen del diccionario.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/32KKg3aP3Vw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descripci√≥n de c√≥mo funciona Harpy. El video del programa no sobrevivi√≥.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
La experiencia de Harpy ha demostrado que construir diccionarios de huellas dactilares de sonido hol√≠stico es in√∫til: solo aumenta el tiempo de reconocimiento y reduce dr√°sticamente la precisi√≥n, por lo que los investigadores de todo el mundo han tomado un camino diferente: reconocer los fonemas. A mediados de la d√©cada de 1980, la m√°quina IBM Tangora pod√≠a aprender a entender el habla de cualquier hablante con acento, dialecto y pronunciaci√≥n, solo requiri√≥ una capacitaci√≥n de 20 minutos, durante el cual se acumul√≥ una base de datos de fonemas y muestras de al√≥fonos. El uso del </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo oculto de Markov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tambi√©n aument√≥ el vocabulario de IBM Tangora a unas impresionantes 20,000 palabras, 20 veces m√°s que Harpy, y ya es comparable al vocabulario del adolescente.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos los sistemas de reconocimiento de voz desde la d√©cada de 1950 hasta mediados de la d√©cada de 1990 no sab√≠an c√≥mo leer el lenguaje hablado natural de una persona: ten√≠an que pronunciar las palabras por separado, haciendo una pausa entre ellas. Un evento verdaderamente revolucionario fue la introducci√≥n del modelo oculto de Markov desarrollado en la d√©cada de 1980, un modelo estad√≠stico que constru√≠a suposiciones precisas sobre elementos desconocidos basados ‚Äã‚Äãen los conocidos. En pocas palabras, con solo unos pocos fonemas reconocidos en una palabra, el modelo oculto de Markov selecciona con mucha precisi√≥n los fonemas faltantes, lo que aumenta en gran medida la precisi√≥n del reconocimiento de voz.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En 1996, apareci√≥ el primer programa comercial, capaz de distinguir no palabras individuales, sino un flujo continuo de lenguaje natural: IBM MedSpeak / Radiology. IBM era un producto especializado que se usaba en medicina para describir brevemente los resultados de una radiograf√≠a administrada por un m√©dico durante el estudio. Aqu√≠, el poder de las computadoras finalmente se volvi√≥ suficiente para reconocer palabras individuales "sobre la marcha". Adem√°s, los algoritmos se han vuelto m√°s perfectos, ha aparecido el reconocimiento correcto de micropausas entre las palabras habladas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El primer motor universal para reconocer el habla natural fue el programa Dragon NaturallySpeaking en 1997. Al trabajar con ella, el locutor (es decir, el usuario) no necesitaba someterse a capacitaci√≥n u operar con un vocabulario espec√≠fico, ya que en el caso de MedSpeak, cualquier persona, incluso un ni√±o, podr√≠a trabajar con NaturallySpeaking, el programa no estableci√≥ ninguna regla de pronunciaci√≥n. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xj/m6/w-/xjm6w-kpgryltox7wquuvpl8db4.png" alt="imagen"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A pesar de la singularidad de Dragon NaturallySpeaking, los navegadores de TI no mostraron mucho entusiasmo por reconocer el habla natural. Entre las deficiencias, se observaron errores de reconocimiento y procesamiento incorrecto de comandos dirigidos al programa en s√≠. Fuente: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">itWeek</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cabe destacar que el motor de reconocimiento estaba listo en la d√©cada de 1980, pero debido a la insuficiente potencia de la computadora, el desarrollo de Dragon Systems (ahora propiedad de Nuance Communications) no tuvo tiempo para determinar los espacios entre palabras sobre la marcha, lo cual es necesario para reconocer el habla natural. </font><font style="vertical-align: inherit;">Sin esto, las palabras "durante el tratamiento", por ejemplo, podr√≠an ser escuchadas por la computadora como "lisiadas". </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por delante estaba la creciente popularidad de los sistemas de reconocimiento de voz, las redes neuronales, la aparici√≥n de la b√∫squeda por voz de Google en dispositivos m√≥viles y, por √∫ltimo, el asistente de voz Siri, que no solo convert√≠a la voz en texto, sino que tambi√©n respond√≠a adecuadamente a las consultas construidas de forma natural.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øC√≥mo escuchar lo que se dijo y pensar en lo que era inaudible?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hoy en d√≠a, la mejor herramienta para crear un motor de reconocimiento de voz es la red neuronal recurrente (RNN), en la que se construyen todos los servicios modernos para reconocer voz, m√∫sica, im√°genes, caras, objetos y texto. RNN le permite comprender palabras con extrema precisi√≥n, as√≠ como predecir la palabra m√°s probable en el contexto del contexto si no se reconoce. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La clasificaci√≥n temporal de la red neuronal del modelo (CTC) selecciona fonemas individuales en el flujo de audio grabado (palabra, frase) y los organiza en el orden en que fueron pronunciados. Despu√©s de un an√°lisis repetido, CTC identifica muy claramente ciertos fonemas, y su grabaci√≥n de texto se compara con la base de datos de palabras en la red neuronal y luego se convierte en una palabra reconocida.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las redes neuronales se llaman as√≠ porque el principio de su trabajo es similar al trabajo del cerebro humano. El entrenamiento de la red neuronal es muy similar al entrenamiento humano. Por ejemplo, para que un ni√±o muy peque√±o aprenda a reconocer los autom√≥viles y distinguirlos de las motocicletas, necesita al menos varias veces llamar su atenci√≥n sobre varios autom√≥viles y cada vez pronunciar la palabra correspondiente: esto es grande y rojo, el autom√≥vil y este negro bajo, el autom√≥vil, pero esto Y estas son motocicletas. En alg√∫n momento, el ni√±o descubrir√° patrones y se√±ales comunes para diferentes autom√≥viles, y aprender√° a reconocer correctamente d√≥nde est√° el autom√≥vil, d√≥nde est√° el jeep, d√≥nde est√° la motocicleta y d√≥nde est√° el ATV, incluso si al pasar los ve en un cartel publicitario en la calle. De la misma manera, la red neuronal necesita ser entrenada con una base de ejemplos, forz√°ndola a "estudiar" cientos y miles de variantes de pronunciaci√≥n para cada palabra, letra, fonema.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Una red neuronal recurrente para el reconocimiento de voz es buena porque despu√©s de un largo entrenamiento en la base de varias pronunciaciones, aprender√° a distinguir los fonemas de las palabras y hacer palabras a partir de ellas, independientemente de la calidad y la naturaleza de la pronunciaci√≥n. E incluso "pensar" con alta precisi√≥n, dentro del contexto de la palabra, palabras que no pudieron reconocerse sin ambig√ºedad debido a los ruidos de fondo o la pronunciaci√≥n confusa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero hay un matiz con las predicciones RNN: una red neuronal recurrente puede "pensar" una palabra que falta solo al confiar en el contexto m√°s cercano de aproximadamente cinco palabras. Fuera de este espacio, no se realizar√°n an√°lisis. ¬°Y a veces es tan necesario! Por ejemplo, para el reconocimiento, pronunciamos la frase "Gran poeta ruso Alexander Sergeyevich </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pushkin</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">", En el que la palabra" Pushkin "(especialmente en cursiva) se dec√≠a tan inaudiblemente que la IA no pod√≠a reconocerla con precisi√≥n. Pero una red neuronal recurrente, basada en la experiencia adquirida durante el entrenamiento, puede sugerir que la palabra "Pushkin" se encuentra con mayor frecuencia junto a las palabras "ruso", "poeta", "Alexander" y "Sergeyevich". Esta es una tarea bastante simple para un RNN entrenado en textos en ruso, porque un contexto muy espec√≠fico nos permite hacer suposiciones con la mayor precisi√≥n.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬øY si el contexto es vago? Tome otro texto en el que no se puede reconocer una palabra: ‚ÄúNuestro todo, Alexander Sergeyevich Pushkin, muri√≥ tr√°gicamente en la plenitud de su vida despu√©s de un duelo con Dantes. El Festival de Teatro Pushkin lleva el nombre del poeta. Si elimina la palabra "Pushkinsky", RNN simplemente no puede adivinarla, seg√∫n el contexto de la propuesta, porque solo menciona un festival de teatro y una referencia al nombre de un poeta desconocido: ¬°hay toneladas de opciones posibles! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqu√≠ es donde entra en </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">juego la</font></a><font style="vertical-align: inherit;"> arquitectura de memoria a largo plazo (LSTM) para redes neuronales recurrentes, creada en 1997 (un </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">art√≠culo detallado sobre LSTM</font></a><font style="vertical-align: inherit;"> ) </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Fue desarrollado especialmente para agregar la capacidad de RNN de tener en cuenta el contexto remoto del evento que se est√° procesando: los resultados de resolver problemas anteriores (es decir, el reconocimiento de palabras) pasan por todo el proceso de reconocimiento, sin importar cu√°nto tiempo dura el mon√≥logo, y se tienen en cuenta en cada caso de duda. Adem√°s, la distancia de eliminaci√≥n casi no tiene efecto sobre la eficiencia de la arquitectura. Con la ayuda de LSTM, si es necesario, una red de palabras tendr√° en cuenta toda la experiencia disponible en el marco de la tarea: en nuestro ejemplo, RNN mirar√° la oraci√≥n anterior y descubrir√° que Pushkin y Dantes fueron mencionados anteriormente, por lo tanto, "Por el nombre del poeta" probablemente apunta a uno de ellos. Como no hay evidencia de la existencia del Festival de Teatro de Dantes,estamos hablando de Pushkinsky (sobre todo porque la huella sonora de una palabra no reconocida es muy similar): tal festival fue la base para entrenar la red neuronal.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/P325_hrGsDI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Confesi√≥n de un asistente de voz". </font><font style="vertical-align: inherit;">Cuando entra en juego una red neuronal bien entrenada, un asistente de voz puede determinar exactamente qu√© se debe hacer con las "zapatillas verdes"</font></font></i><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øC√≥mo el reconocimiento de voz hace del mundo un lugar mejor?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En cada caso, la aplicaci√≥n es diferente: ayuda a alguien a comunicarse con dispositivos y, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seg√∫n PricewaterhouseCooper</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , m√°s de la mitad de los usuarios de tel√©fonos inteligentes dan comandos de voz a los dispositivos, entre los adultos (de 25 a 49 a√±os), el porcentaje de quienes usan constantemente interfaces de voz, incluso mayor que entre los j√≥venes (18-25): 65% contra 59%. </font><font style="vertical-align: inherit;">Y en Rusia al menos una vez, al menos el 71% de la poblaci√≥n se comunic√≥ con Siri, Google Assitant o Alice. </font><font style="vertical-align: inherit;">45 millones de rusos se comunican constantemente con "Alisa" de Yandex, y Yandex.Maps / Yandex.Navigator representa solo el 30% de las solicitudes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El reconocimiento de voz realmente ayuda a alguien en el trabajo, por ejemplo, como dijimos anteriormente, a los m√©dicos: en medicina desde 1996 (cuando sali√≥ IBM MedSpeak), el reconocimiento se usa para grabar anamnesis y estudiar im√°genes: un m√©dico puede continuar trabajando sin distraerse con grabaciones en computadora o tarjeta de papel. Por cierto, el trabajo sobre dictado en medicina se lleva a cabo no solo en Occidente: en Rusia hay un programa Voice2Med del "Centro de Tecnolog√≠as del Habla".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hay otros ejemplos, incluido el nuestro. Organizar un negocio Toshiba implica la inclusi√≥n total, es decir, la igualdad de derechos y oportunidades para las personas con diversas afecciones de salud, incluidos los empleados con discapacidad auditiva. Tenemos un programa corporativo llamado Universal Design Advisor System, en el que las personas con diversos tipos de discapacidades participan en el desarrollo de productos Toshiba, haciendo sugerencias para mejorar su conveniencia para las personas con discapacidades, es decir, no asumimos c√≥mo podemos mejorar, sino que operamos con experiencia real. y revisiones de empleados.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hace unos a√±os, en la sede de Toshiba en Jap√≥n, nos enfrentamos a una tarea muy interesante, que requer√≠a el desarrollo de un nuevo sistema de reconocimiento de voz. Durante el funcionamiento del Sistema Universal de Asesores de Dise√±o, recibimos una informaci√≥n importante: los empleados con discapacidad auditiva desean participar en debates en reuniones y conferencias en tiempo real, y no limitarse a leer la transcripci√≥n procesada horas o d√≠as despu√©s. Iniciar el reconocimiento de voz a trav√©s de un tel√©fono inteligente en tales casos da un resultado muy d√©bil, por lo que los especialistas de Toshiba tuvieron que comenzar a desarrollar un sistema de reconocimiento especializado. Y, por supuesto, inmediatamente nos encontramos con problemas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La conversaci√≥n difiere enormemente del discurso escrito: no hablamos de la forma en que escribimos cartas, y una conversaci√≥n real traducida al texto parece muy descuidada e incluso ilegible. Es decir, incluso si convertimos conversaciones en el plan de la ma√±ana en texto con alta precisi√≥n, obtendremos un hash incoherente repleto de par√°sitos verbales, interjecciones y reflexivos "aaa", "uh" y "mmm". Para deshacerse de la transcripci√≥n de sonidos, palabras y expresiones de emociones innecesarias en el texto, decidimos desarrollar una IA capaz de reconocer con la m√°xima precisi√≥n los elementos no siempre necesarios del habla coloquial, incluida la coloraci√≥n emocional de algunas palabras (por ejemplo, "s√≠, bueno" puede sonar como escepticismo o c√≥mo sincera sorpresa, y estos son literalmente significados opuestos).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6z/vv/od/6zvvodwnihcvdqdqfv4uuprbtb4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parece una computadora port√°til con un conjunto de perif√©ricos para reconocimiento de voz con Toshiba AI (izquierda) y una aplicaci√≥n con los resultados para dispositivos finales (derecha). Fuente: Toshiba</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
LSTM fue √∫til aqu√≠, sin lo cual la precisi√≥n del reconocimiento fue insuficiente para que el texto recibido se lea y entienda sin esfuerzo. Adem√°s, LSTM fue √∫til no solo para una predicci√≥n m√°s precisa de las palabras en contexto, sino tambi√©n para el procesamiento correcto de las pausas en el medio de las oraciones y par√°sitos interjecciones: para esto ense√±amos a la red neuronal estos par√°sitos y pausas que son naturales para el habla coloquial.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬øSignifica esto que ahora la red neuronal puede eliminar las interjecciones de las transcripciones? </font><font style="vertical-align: inherit;">S√≠, puede, pero esto no es necesario. </font><font style="vertical-align: inherit;">El hecho es que (otra informaci√≥n recibida) las personas con discapacidad auditiva son guiadas, incluso por los movimientos de los labios del hablante. </font><font style="vertical-align: inherit;">Si los labios se mueven, pero el texto correspondiente a estos movimientos no aparece en la pantalla, existe la sensaci√≥n de que el sistema de reconocimiento ha perdido parte de la conversaci√≥n. </font><font style="vertical-align: inherit;">Es decir, para alguien que no puede escuchar, es importante obtener tanta informaci√≥n como sea posible sobre la conversaci√≥n, incluidas pausas y mejometias desafortunadas. </font><font style="vertical-align: inherit;">Por lo tanto, el motor Toshiba deja estos elementos en la transcripci√≥n, pero en tiempo real aten√∫a el brillo de las letras, dejando en claro que estos son detalles opcionales para comprender el texto.</font></font><br>
<br>
<div class="oembed"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.toshiba-clip.com/en/detail/7655</font></font></a></div><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As√≠ es como se ve el resultado del reconocimiento sobre la marcha en el dispositivo cliente. </font><font style="vertical-align: inherit;">Las partes del mon√≥logo que no son significativas est√°n pintadas de gris.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ahora Toshiba AI trabaja con ingl√©s, japon√©s y chino, e incluso es posible la traducci√≥n entre idiomas sobre la marcha. </font><font style="vertical-align: inherit;">No es necesario usarlo para taquigraf√≠a sobre la marcha: la IA se puede adaptar para trabajar con asistentes de voz, quienes finalmente aprenden a percibir adecuadamente las interjecciones, pausas y tartamudeos cuando una persona pronuncia un comando. </font><font style="vertical-align: inherit;">En marzo de 2019, el sistema se utiliz√≥ con √©xito para agregar subt√≠tulos a la transmisi√≥n de la Convenci√≥n Nacional IPSJ en Jap√≥n. </font><font style="vertical-align: inherit;">En un futuro cercano: la transformaci√≥n de la IA de Toshiba en un servicio p√∫blico y experiencias con la implementaci√≥n del reconocimiento de voz en la producci√≥n.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es490720/index.html">¬°Motor! o ¬øQu√© es la f√≠sica del juego?</a></li>
<li><a href="../es490722/index.html">Vacaciones de g√©nero en TI. C√≥mo anotar</a></li>
<li><a href="../es490726/index.html">Autenticaci√≥n en equipos de red a trav√©s de SSH usando claves p√∫blicas</a></li>
<li><a href="../es490728/index.html">Semana de la Seguridad 10: Conferencia RSA y Conciencia de Ciberseguridad</a></li>
<li><a href="../es490730/index.html">Intel x86 Root of Trust: p√©rdida de confianza</a></li>
<li><a href="../es490734/index.html">Huevos de Pascua en mapas topogr√°ficos de Suiza</a></li>
<li><a href="../es490736/index.html">9 herramientas claras para aprender y aprender vocabulario en ingl√©s</a></li>
<li><a href="../es490738/index.html">Principio de sustituci√≥n de Lisk</a></li>
<li><a href="../es490740/index.html">Defectuoso *** s no es solo aleatorizaci√≥n</a></li>
<li><a href="../es490742/index.html">Una nueva era en rob√≥tica ha comenzado</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
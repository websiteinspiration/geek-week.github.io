<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌏 👨🏾‍🎨 👩🏿‍🚀 Apache KafkaとSparkストリーミングによるストリーミング 👩🏼‍🚀 👩🏽‍🔬 🙏🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、ハブル！今日は、Apark Kafkaを使用してSpark Streamingでメッセージストリームを処理し、処理結果をAWS RDSクラウドデータベースに書き込むシステムを構築します。
 
 特定の信用機関が、すべての支店にわたってオンザフライで着信トランザクションを処理するタスクを設...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Apache KafkaとSparkストリーミングによるストリーミング</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451160/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは、ハブル！</font><font style="vertical-align: inherit;">今日は、Apark Kafkaを使用してSpark Streamingでメッセージストリームを処理し、処理結果をAWS RDSクラウドデータベースに書き込むシステムを構築します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
特定の信用機関が、すべての支店にわたってオンザフライで着信トランザクションを処理するタスクを設定すると想像してください。</font><font style="vertical-align: inherit;">これは、財務省のオープン通貨ポジション、取引の制限または財務結果などをすばやく計算するために実行できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
マジックとマジックスペルを使用せずにこのケースを実装する方法-カットの下で読み取ります！</font><font style="vertical-align: inherit;">行こう！</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/5w/sb/8v/5wsb8vvncrzhysct-pd6oqraqky.jpeg"></div><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（画像ソース）</font></font></a><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">前書き</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、大規模なデータ配列をリアルタイムで処理すると、最新のシステムで使用するための十分な機会が提供されます。</font><font style="vertical-align: inherit;">この最も一般的な組み合わせの1つは、Apache KafkaとSpark Streamingタンデムです。この場合、Kafkaは着信メッセージパケットのストリームを作成し、Spark Streamingは指定された時間間隔でこれらのパケットを処理します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アプリケーションのフォールトトレランスを向上させるために、チェックポイント-チェックポイントを使用します。</font><font style="vertical-align: inherit;">このメカニズムを使用すると、Spark Streamingモジュールが失われたデータを回復する必要がある場合、最後の制御点に戻り、そこから計算を再開するだけで済みます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">開発中のシステムのアーキテクチャ</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/od/ef/zc/odefzciug8ckvim4-ei6pdg49tw.png"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
使用するコンポーネント：</font></font><br>
<br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><b>Apache Kafka</b></a> —         .    ,      .      Kafka       .  Kafka     ZooKeeper;</li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><b>Apache Spark Streaming</b></a> —  Spark    .  Spark Streaming    «»  (micro-batch architecture),          . Spark Streaming           .       .        ,   ,     ,   .      .    ,     (batch interval); </li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apache Spark</font></font></b></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> SQL-リレーショナル処理とSpark関数型プログラミングを組み合わせます。</font><font style="vertical-align: inherit;">構造化データとは、スキーマを持つデータ、つまりすべてのレコードの単一のフィールドセットを指します。</font><font style="vertical-align: inherit;">Spark SQLは、さまざまな構造化データソースからの入力をサポートし、スキーマ情報を利用できるため、必要なレコードフィールドのみを効率的に取得でき、DataFrame APIも提供します。</font></font></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AWS RDS</font></font></b></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、比較的安価なクラウドベースのリレーショナルデータベースであり、構成、運用、スケーリングを簡素化するウェブサービスであり、Amazonによって直接管理されます。</font></font></li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafkaサーバーをインストールして起動する</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kafkaを直接使用する前に、Javaが利用可能であることを確認する必要があります。</font><font style="vertical-align: inherit;">JVMは作業に使用されます。</font></font><br>
<br>
<pre><code class="bash hljs">sudo apt-get update <font></font>
sudo apt-get install default-jre<font></font>
java -version<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kafkaを使用する新しいユーザーを作成します。</font></font><br>
<br>
<pre><code class="bash hljs">sudo useradd kafka -m<font></font>
sudo passwd kafka<font></font>
sudo adduser kafka sudo<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、Apache Kafkaの公式Webサイトからディストリビューションをダウンロードします。</font></font><br>
<br>
<pre><code class="bash hljs">wget -P /YOUR_PATH <span class="hljs-string">"http://apache-mirror.rbc.ru/pub/apache/kafka/2.2.0/kafka_2.12-2.2.0.tgz"</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ダウンロードしたアーカイブを解凍します。</font></font><br>
<pre><code class="bash hljs">tar -xvzf /YOUR_PATH/kafka_2.12-2.2.0.tgz<font></font>
ln -s /YOUR_PATH/kafka_2.12-2.2.0 kafka<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のステップはオプションです。</font><font style="vertical-align: inherit;">実際のところ、デフォルト設定では、Apache Kafkaのすべての機能を完全に使用することはできません。</font><font style="vertical-align: inherit;">たとえば、メッセージを発行できるトピック、カテゴリ、グループを削除します。</font><font style="vertical-align: inherit;">これを変更するには、構成ファイルを編集します。</font></font><br>
<br>
<pre><code class="bash hljs">vim ~/kafka/config/server.properties</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ファイルの最後に次を追加します。</font></font><br>
<br>
<pre><code class="bash hljs">delete.topic.enable = <span class="hljs-literal">true</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kafkaサーバーを起動する前に、ZooKeeperサーバーを起動する必要があります。Kafkaディストリビューションに付属の補助スクリプトを使用します。</font></font><br>
<br>
<pre><code class="bash hljs">Cd ~/kafka<font></font>
bin/zookeeper-server-start.sh config/zookeeper.properties<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ZooKeeperが正常に起動したら、別のターミナルでKafkaサーバーを起動します。</font></font><br>
<br>
<pre><code class="bash hljs">bin/kafka-server-start.sh config/server.properties</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Transactionという新しいトピックを作成します。</font></font><br>
<br>
<pre><code class="bash hljs">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic transaction</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
適切な数のパーティションとレプリケーションのトピックが作成されていることを確認します。</font></font><br>
<br>
<pre><code class="bash hljs">bin/kafka-topics.sh --describe --zookeeper localhost:2181</code></pre><br>
<img src="https://habrastorage.org/webt/s5/gh/bu/s5ghbuswhb0dcc0pmlvu_uloes4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
新しく作成されたトピックのプロデューサーとコンシューマーをテストする瞬間を逃します。</font><font style="vertical-align: inherit;">メッセージの送受信をテストする方法の詳細については、公式ドキュメント</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-Send some messagesを</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照して</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ください</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">それでは、KafkaProducer APIを使用してPythonでプロデューサーを作成します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">プロデューサーライティング</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
プロデューサーはランダムなデータを生成します-毎秒100メッセージ。</font><font style="vertical-align: inherit;">ランダムデータとは、次の3つのフィールドで構成される辞書を意味します。</font></font><br>
<br>
<ul>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支店</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -信用機関の販売場所の名前;</font></font></li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">通貨</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -取引通貨。</font></font></li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">金額</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -トランザクション金額。</font><font style="vertical-align: inherit;">銀行による通貨の購入の場合は正の数になり、売却の場合は負の数になります。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
プロデューサーのコードは次のとおりです。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> numpy.random <span class="hljs-keyword">import</span> choice, randint<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_random_value</span>():</span><font></font>
    new_dict = {}<font></font>
<font></font>
    branch_list = [<span class="hljs-string">'Kazan'</span>, <span class="hljs-string">'SPB'</span>, <span class="hljs-string">'Novosibirsk'</span>, <span class="hljs-string">'Surgut'</span>]<font></font>
    currency_list = [<span class="hljs-string">'RUB'</span>, <span class="hljs-string">'USD'</span>, <span class="hljs-string">'EUR'</span>, <span class="hljs-string">'GBP'</span>]<font></font>
<font></font>
    new_dict[<span class="hljs-string">'branch'</span>] = choice(branch_list)<font></font>
    new_dict[<span class="hljs-string">'currency'</span>] = choice(currency_list)<font></font>
    new_dict[<span class="hljs-string">'amount'</span>] = randint(<span class="hljs-number">-100</span>, <span class="hljs-number">100</span>)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> new_dict
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、sendメソッドを使用して、必要なトピックのメッセージをサーバーにJSON形式で送信します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> kafka <span class="hljs-keyword">import</span> KafkaProducer    <font></font>
<font></font>
producer = KafkaProducer(bootstrap_servers=[<span class="hljs-string">'localhost:9092'</span>],<font></font>
                             value_serializer=<span class="hljs-keyword">lambda</span> x:dumps(x).encode(<span class="hljs-string">'utf-8'</span>),<font></font>
                             compression_type=<span class="hljs-string">'gzip'</span>)<font></font>
my_topic = <span class="hljs-string">'transaction'</span><font></font>
data = get_random_value()<font></font>
<font></font>
<span class="hljs-keyword">try</span>:<font></font>
    future = producer.send(topic = my_topic, value = data)<font></font>
    record_metadata = future.get(timeout=<span class="hljs-number">10</span>)<font></font>
    <font></font>
    print(<span class="hljs-string">'--&gt; The message has been sent to a topic: \
            {}, partition: {}, offset: {}'</span> \<font></font>
            .format(record_metadata.topic,<font></font>
                record_metadata.partition,<font></font>
                record_metadata.offset ))   <font></font>
                             <font></font>
<span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<font></font>
    print(<span class="hljs-string">'--&gt; It seems an Error occurred: {}'</span>.format(e))<font></font>
<font></font>
<span class="hljs-keyword">finally</span>:<font></font>
    producer.flush()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクリプトを実行すると、ターミナルに次のメッセージが表示されます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/_e/3g/zj/_e3gzjrmsycjb8ntjmur6ztaspw.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは、すべてが期待どおりに機能することを意味します。プロデューサーは必要なトピックにメッセージを生成して送信します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のステップは、Sparkをインストールして、このメッセージフローを処理することです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apache Sparkをインストールする</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apache Spark</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、多目的で高性能なクラスターコンピューティングプラットフォームです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
パフォーマンスの点で、SparkはMapReduceモデルの一般的な実装を上回っており、同時にインタラクティブクエリやストリーム処理など、より幅広い種類の計算をサポートしています。</font><font style="vertical-align: inherit;">スピードは、数分または数時間待つことなくインタラクティブに作業できるスピードであるため、大量のデータを処理する上で重要な役割を果たします。</font><font style="vertical-align: inherit;">このような高速でのSparkの最大の強みの1つは、メモリ内計算を実行する能力です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このフレームワークはScalaで作成されているため、まずインストールする必要があります。</font></font><br>
<br>
<pre><code class="bash hljs">sudo apt-get install scala</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
公式WebサイトからSparkディストリビューションをダウンロードします。</font></font><br>
<br>
<pre><code class="bash hljs">wget <span class="hljs-string">"http://mirror.linux-ia64.org/apache/spark/spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz"</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アーカイブを解凍します。</font></font><br>
<br>
<pre><code class="bash hljs">sudo tar xvf spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz -C /usr/<span class="hljs-built_in">local</span>/spark</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sparkへのパスをbashファイルに追加します。</font></font><br>
<br>
<pre><code class="bash hljs">vim ~/.bashrc</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
エディターで次の行を追加します。</font></font><br>
<br>
<pre><code class="bash hljs">SPARK_HOME=/usr/<span class="hljs-built_in">local</span>/spark
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$SPARK_HOME</span>/bin:<span class="hljs-variable">$PATH</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
bashrcに変更を加えた後、次のコマンドを実行します。</font></font><br>
<br>
<pre><code class="bash hljs"><span class="hljs-built_in">source</span> ~/.bashrc</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AWS PostgreSQLのデプロイ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それはデータベースをデプロイするために残り、そこでストリームから処理された情報をアップロードします。</font><font style="vertical-align: inherit;">これを行うには、AWS RDSサービスを使用します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
コンソールAWS-&gt; AWS RDS-&gt; Databases-&gt; Create databaseに移動します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dg/os/m7/dgosm7dwnh3fr-uksjdt_xpltsk.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PostgreSQLを選択し、[次へ]ボタンをクリックします。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/3y/d_/8r/3yd_8rsz2swfgaxaafpkyizthac.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
なぜなら </font><font style="vertical-align: inherit;">この例は教育目的でのみ理解されており、「最低限」無料のサーバーを使用します（無料枠）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/fn/6p/5b/fn6p5bjyitndy_ozs2cdcw_ssi0.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、無料枠ブロックにチェックを入れます。その後、t2.microクラスのインスタンスが自動的に提供されます-弱いものの、それは無料であり、タスクに非常に適しています。</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mj/jh/wg/mjjhwg3cknoehrq8wyxk3uw5v74.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データベースインスタンスの名前、マスターユーザーの名前、およびそのパスワードが非常に重要です。</font><font style="vertical-align: inherit;">レッツ・名前のインスタンス：myHabrTest、マスタユーザ：</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">habr</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、パスワード：</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">habr12345</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">次へ]ボタンをクリックしてください：</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/lg/jt/mf/lgjtmfdfst0pvqthojb_bdpeohc.png"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のページには、外部からのデータベースサーバーの可用性（パブリックアクセシビリティ）とポートの可用性に関与するパラメーターが含まれています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/40/z9/q7/40z9q7owar5kpnimyzrdj5laqgs.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
VPCセキュリティグループの新しい構成を作成して、外部からポート5432（PostgreSQL）を介してデータベースサーバーにアクセスできるようにします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
別のブラウザーウィンドウで、VPCダッシュボードのAWSコンソールに移動します-&gt; [セキュリティグループ]-&gt; [セキュリティグループの作成]セクション：</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/fl/2i/ne/fl2inejlgnghwsh3itdrlcywdsu.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
セキュリティグループの名前を設定します-PostgreSQL（説明）。このグループを関連付けるVPCを指定し、[作成]ボタンをクリックします。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/js/8r/tv/js8rtvp8tudwjtpgso6xota5h-g.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以下の図に示すように、ポート5432の新しく作成された受信ルールグループを入力します。</font><font style="vertical-align: inherit;">手動ポートを指定する必要はありませんが、[タイプ]ドロップダウンリストから[PostgreSQL]を選択します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
厳密に言うと、値:: / 0は、世界中のサーバーからの着信トラフィックの可用性を意味します。これは、正式には正確ではありませんが、例を解析するために、このアプローチを使用してみましょう。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/8j/bn/ge8jbntssnooajc8so36h0tjo80.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ブラウザーページに戻り、[Configure advanced settings]を開いて、セクションでVPCセキュリティグループ-&gt;既存のVPCセキュリティグループを選択-&gt; PostgreSQLを選択します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/nk/ae/-s/nkae-ste1tp3wgvmyilicvwlk8e.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、セクションデータベースオプション-&gt;データベース名-&gt;名前を設定します</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-habrDB</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
デフォルトでは、バックアップ（バックアップ保持期間-0日）の無効化、監視、およびPerformance Insightsを除いて、残りのパラメーターをそのままにしておくことができます。</font><font style="vertical-align: inherit;">[ </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データベース</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の</font><b><font style="vertical-align: inherit;">作成</font></b><font style="vertical-align: inherit;"> ]ボタンをクリックします</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ex/1p/po/ex1ppogq_vdsk3nnvywm7l8vq8i.png"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ストリームハンドラー</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後のステップは、Kafkaからの新しいデータを2秒ごとに処理し、その結果をデータベースに入力するSparkジョブの開発です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上記のように、チェックポイントは、耐障害性を提供​​するように構成する必要があるSparkStreamingの主要なメカニズムです。コントロールポイントを使用します。プロシージャがドロップした場合、Spark Streamingモジュールは最後のコントロールポイントに戻って計算を再開するだけで、失われたデータを復元できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ブレークポイント情報を保存するフォールトトレラントで信頼性の高いファイルシステム（HDFS、S3など）にディレクトリを設定することにより、ブレークポイントを有効にできます。これは、たとえば以下を使用して行われます。</font></font><br>
<br>
<pre><code class="python hljs">streamingContext.checkpoint(checkpointDirectory)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この例では、次のアプローチを使用します。つまり、checkpointDirectoryが存在する場合、コントロールポイントデータからコンテキストが再作成されます。</font><font style="vertical-align: inherit;">ディレクトリが存在しない（つまり、初めて実行される）場合、functionToCreateContext関数が呼び出され、新しいコンテキストを作成してDStreamsを構成します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> pyspark.streaming <span class="hljs-keyword">import</span> StreamingContext<font></font>
<font></font>
context = StreamingContext.getOrCreate(checkpointDirectory, functionToCreateContext)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
KafkaUtilsライブラリのcreateDirectStreamメソッドを使用して、「トランザクション」トピックに接続するDirectStreamオブジェクトを作成します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> pyspark.streaming.kafka <span class="hljs-keyword">import</span> KafkaUtils<font></font>
    <font></font>
sc = SparkContext(conf=conf)<font></font>
ssc = StreamingContext(sc, <span class="hljs-number">2</span>)<font></font>
<font></font>
broker_list = <span class="hljs-string">'localhost:9092'</span>
topic = <span class="hljs-string">'transaction'</span><font></font>
<font></font>
directKafkaStream = KafkaUtils.createDirectStream(ssc,<font></font>
                                [topic],<font></font>
                                {<span class="hljs-string">"metadata.broker.list"</span>: broker_list})
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
着信データをJSON形式で解析する：</font></font><br>
<br>
<pre><code class="python hljs">rowRdd = rdd.map(<span class="hljs-keyword">lambda</span> w: Row(branch=w[<span class="hljs-string">'branch'</span>],<font></font>
                                       currency=w[<span class="hljs-string">'currency'</span>],<font></font>
                                       amount=w[<span class="hljs-string">'amount'</span>]))<font></font>
                                       <font></font>
testDataFrame = spark.createDataFrame(rowRdd)<font></font>
testDataFrame.createOrReplaceTempView(<span class="hljs-string">"treasury_stream"</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Spark SQLを使用して、単純なグループ化を行い、結果をコンソールに出力します。</font></font><br>
<br>
<pre><code class="sql hljs"><span class="hljs-keyword">select</span> 
    from_unixtime(<span class="hljs-keyword">unix_timestamp</span>()) <span class="hljs-keyword">as</span> curr_time,<font></font>
    t.branch                        <span class="hljs-keyword">as</span> branch_name,<font></font>
    t.currency                      <span class="hljs-keyword">as</span> currency_code,
    <span class="hljs-keyword">sum</span>(amount)                     <span class="hljs-keyword">as</span> batch_value
<span class="hljs-keyword">from</span> treasury_stream t
<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span><font></font>
    t.branch,<font></font>
    t.currency<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
クエリテキストを取得してSpark SQLで実行する：</font></font><br>
<br>
<pre><code class="python hljs">sql_query = get_sql_query()<font></font>
testResultDataFrame = spark.sql(sql_query)<font></font>
testResultDataFrame.show(n=<span class="hljs-number">5</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、結果の集約データをAWS RDSのテーブルに保存します。</font><font style="vertical-align: inherit;">集計結果をデータベーステーブルに保存するには、DataFrameオブジェクトのwriteメソッドを使用します。</font></font><br>
<br>
<pre><code class="python hljs">testResultDataFrame.write \<font></font>
    .format(<span class="hljs-string">"jdbc"</span>) \<font></font>
    .mode(<span class="hljs-string">"append"</span>) \<font></font>
    .option(<span class="hljs-string">"driver"</span>, <span class="hljs-string">'org.postgresql.Driver'</span>) \<font></font>
    .option(<span class="hljs-string">"url"</span>,<span class="hljs-string">"jdbc:postgresql://myhabrtest.ciny8bykwxeg.us-east-1.rds.amazonaws.com:5432/habrDB"</span>) \<font></font>
    .option(<span class="hljs-string">"dbtable"</span>, <span class="hljs-string">"transaction_flow"</span>) \<font></font>
    .option(<span class="hljs-string">"user"</span>, <span class="hljs-string">"habr"</span>) \<font></font>
    .option(<span class="hljs-string">"password"</span>, <span class="hljs-string">"habr12345"</span>) \<font></font>
    .save()<font></font>
</code></pre><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AWS RDSへの接続のセットアップについて一言。</font><font style="vertical-align: inherit;">「AWS PostgreSQLのデプロイ」ステップで、ユーザーとパスワードを作成しました。</font><font style="vertical-align: inherit;">データベースサーバーのURLには、[接続性とセキュリティ]セクションに表示されるエンドポイントを使用します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/9n/sj/jd/9nsjjdun0hdy5qtwqub0xhvzunk.png"></div></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SparkとKafkaを正しく接続するには、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spark-streaming-kafka-0-8_2.11アーティファクト</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を使用して</font><b><font style="vertical-align: inherit;">smark</font></b><font style="vertical-align: inherit;"> -submitからジョブを実行する必要があり</font><b><font style="vertical-align: inherit;">ます</font></b><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">さらに、PostgreSQLデータベースと対話するためにアーティファクトも適用します。それらを--packagesを介して転送します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクリプトを柔軟にするために、メッセージサーバーの名前と、データを入力パラメーターとして受け取りたいトピックも取り出します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それでは、システムを起動してテストします。</font></font><br>
<br>
<pre><code class="bash hljs">spark-submit \<font></font>
--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2,\<font></font>
org.postgresql:postgresql:9.4.1207 \<font></font>
spark_job.py localhost:9092 transaction<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すべてがうまくいきました！</font><font style="vertical-align: inherit;">次の図に示すように、StreamingContextオブジェクトを作成したときにバッチ間隔を2秒に設定しているため、アプリケーションの操作中、新しい集計結果は2秒ごとに表示されます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/cf/q1/25/cfq125zpzkyldktsuvdo175fazy.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">transaction_flow</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テーブルのエントリを確認する簡単なデータベースクエリを作成します</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/7j/j9/qm/7jj9qmf4zpter3jkbblrmiqni2s.png"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、Apache KafkaおよびPostgreSQLと組み合わせてSpark Streamingを使用したスト​​リーミング情報処理の例を検討しました。さまざまなソースからのデータの増加に伴い、ストリーミングアプリケーションおよびリアルタイムで動作するアプリケーションを作成するためのSpark Streamingの実際的な価値を過大評価することは困難です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
完全なソースコードは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHubの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私のリポジトリにあり</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私はこの記事を喜んで議論する準備ができています。あなたのコメントを楽しみにしています。また、関係するすべての読者の建設的な批評を期待しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
あなたの成功を祈って！</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">もともとはローカルのPostgreSQLデータベースを使用するように計画されていましたが、AWSが大好きだったので、データベースをクラウドに移動することにしました。</font><font style="vertical-align: inherit;">このトピックの次の記事では、AWS KinesisとAWS EMRを使用して、上記のシステム全体をAWSに実装する方法を示します。</font><font style="vertical-align: inherit;">ニュースに従ってください！</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja451148/index.html">グラフィック言語でのオブジェクト指向プログラミング</a></li>
<li><a href="../ja451150/index.html">できればキャッチ・ミー。マネージャーのバージョン</a></li>
<li><a href="../ja451152/index.html">ゲート回路の抵抗器またはそれを正しく行う方法</a></li>
<li><a href="../ja451154/index.html">ローカル自律データ収集システム（続き）</a></li>
<li><a href="../ja451158/index.html">電気回路。回路タイプ</a></li>
<li><a href="../ja451162/index.html">エラー修正-現在のバージョンと新しいバージョンの国際単位系（SI）の物理定数</a></li>
<li><a href="../ja451164/index.html">Pythonで無料の駐車スペースを探す</a></li>
<li><a href="../ja451166/index.html">AIおよびMOシステム用の新しいストレージは何を提供しますか？</a></li>
<li><a href="../ja451170/index.html">ジェフ・ベゾスは月を征服する計画を発表しました</a></li>
<li><a href="../ja451172/index.html">ジュリア：関数と関数としての構造</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
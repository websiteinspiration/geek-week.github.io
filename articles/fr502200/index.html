<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéÜ üë¥ üåø Entropie: comment les arbres de d√©cision prennent des d√©cisions üë©‚Äçüë¶ ü§Ω üôÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Une traduction de l'article a √©t√© pr√©par√©e avant le d√©but du cours d' apprentissage automatique .
 
 
 
 Vous √™tes un sp√©cialiste de la science des do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Entropie: comment les arbres de d√©cision prennent des d√©cisions</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/502200/"><i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une traduction de l'article a √©t√© pr√©par√©e avant le d√©but du cours d' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">apprentissage automatique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></b></i><br>
<br>
<img src="https://habrastorage.org/webt/az/2h/3e/az2h3eq1jejcxtd0g4wi4gmamki.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous √™tes un sp√©cialiste de la science des donn√©es qui suit actuellement un parcours d'apprentissage. Et vous avez parcouru un long chemin depuis que vous avez √©crit votre premi√®re ligne de code en Python ou R. Vous connaissez Scikit-Learn comme le dos de votre main. Maintenant, vous √™tes plus assis sur Kaggle que sur Facebook. Vous n'√™tes pas nouveau dans la cr√©ation de superbes for√™ts al√©atoires et d'autres mod√®les d'ensemble d'arbres de d√©cision qui font un excellent travail. N√©anmoins, vous savez que vous n'obtiendrez rien si vous ne vous d√©veloppez pas compl√®tement. Vous voulez approfondir et comprendre les subtilit√©s et les concepts qui sous-tendent les mod√®les populaires d'apprentissage automatique. Et bien moi aussi.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aujourd'hui, je parlerai du concept d'entropie - l'un des sujets les plus importants en statistique, et plus tard nous parlerons du concept de gain d'information (gain d'information) et d√©couvrirai pourquoi ces concepts fondamentaux forment la base de la fa√ßon dont les arbres de d√©cision sont construits √† partir des donn√©es obtenues.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien. Maintenant, transgressons. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qu'est-ce que l'entropie? En termes simples, l'entropie n'est rien d'autre qu'une mesure du d√©sordre. (Cela peut aussi √™tre consid√©r√© comme une mesure de puret√©, et bient√¥t vous comprendrez pourquoi. Mais j'aime plus le g√¢chis parce qu'il semble plus frais.) La </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
formule math√©matique de l'entropie est la suivante: l' </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ey/wa/u-/eywau-ntm5stedcuyrelbhhoipu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entropie. Elle est parfois √©crite comme H.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ici p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est la probabilit√© de fr√©quence d'un √©l√©ment / classe i de nos donn√©es. Pour simplifier, supposons que nous ayons seulement deux classes: positive et n√©gative. Ensuite, je prendrai la valeur "+" ou "-". Si nous avions un total de 100 points dans notre ensemble de donn√©es, dont 30 appartenaient √† la classe positive et 70 appartenaient au n√©gatif, alors p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> serait 3/10, et p</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sera 7/10. Ici, tout est simple. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si je calcule l'entropie des classes √† partir de cet exemple, voici ce que j'obtiens en utilisant la formule ci-dessus: l' </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5_/hh/20/5_hh20bihmp119n_5vzmlq_vuyw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
entropie est d'environ 0,88. Cette valeur est consid√©r√©e comme assez √©lev√©e, c'est-√†-dire que nous avons un niveau √©lev√© d'entropie ou de trouble (c'est-√†-dire une faible valeur de puret√©). L'entropie est mesur√©e dans la plage de 0 √† 1. En fonction du nombre de classes dans votre ensemble de donn√©es, la valeur de l'entropie peut s'av√©rer sup√©rieure √† 1, mais cela signifie la m√™me chose car le niveau de trouble est extr√™mement √©lev√©. Pour simplifier l'explication, dans l'article d'aujourd'hui, nous aurons une entropie allant de 0 √† 1. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetez un ≈ìil au tableau ci-dessous.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jt/sx/zs/jtsxzsfwwbstp10fqo-rd0ndddw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur l'axe X, le nombre de points de la classe positive dans chaque cercle est refl√©t√©, et sur l'axe Y, les entropies correspondantes. Vous pouvez imm√©diatement remarquer la forme en U invers√©e du graphique. L'entropie sera la plus petite aux extr√©mit√©s si en principe il n'y a pas d'√©l√©ments positifs dans le cercle ou quand il n'y a que des √©l√©ments positifs. Autrement dit, lorsque les √©l√©ments sont identiques dans un cercle, le d√©sordre sera 0. L'entropie sera la plus √©lev√©e au milieu du graphique, o√π les √©l√©ments positifs et n√©gatifs seront uniform√©ment r√©partis √† l'int√©rieur du cercle. Ici, la plus grande entropie ou d√©sordre sera atteint, car il n'y aura pas d'√©l√©ments pr√©dominants.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y a-t-il une raison pour laquelle l'entropie est mesur√©e en utilisant le logarithme en base 2, ou pourquoi l'entropie est-elle mesur√©e entre 0 et 1, et non dans une plage diff√©rente? Non, il n'y a aucune raison. Ceci est juste une m√©trique. Ce n'est pas si important de comprendre pourquoi cela se produit. Il est important de savoir comment ce que nous avons obtenu ci-dessus est calcul√© et comment cela fonctionne. L'entropie est une mesure de la confusion ou de l'incertitude, et l'objectif des mod√®les d'apprentissage automatique et des sp√©cialistes de la science des donn√©es en g√©n√©ral est de r√©duire cette incertitude. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, nous savons comment le d√©sordre est mesur√©. Ensuite, nous avons besoin d'une valeur pour mesurer la r√©duction de ce trouble dans les informations suppl√©mentaires (attributs / variables ind√©pendantes) de la variable / classe cible. C'est l√† que le gain d'information ou le gain d'information entre en jeu. Du point de vue des math√©matiques, cela peut s'√©crire comme suit:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bn/el/t4/bnelt40yxay8hkbanig088mpk6a.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Nous soustrayons simplement l'entropie Y de X, de l'entropie Y, afin de calculer la diminution de l'incertitude sur Y, √† condition qu'il y ait des informations sur X sur Y. Plus l'incertitude diminue, plus il est possible d'obtenir des informations de Y sur X. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Regardons un exemple simple du tableau de contingence afin que se rapprocher de la question de savoir comment les arbres de d√©cision utilisent l'entropie et le gain d'informations pour d√©cider sur quelle base casser les n≈ìuds dans le processus d'apprentissage sur les donn√©es. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemple: Tableau de conjugaison</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/s4/ea/e5/s4eae57mpuehp3mk_mjpmikuan0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Ici, notre variable cible sera </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Responsabilit√©</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui ne peut prendre que deux valeurs: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Normal¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´√âlev√©¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Nous avons √©galement un seul signe, qui s'appelle Credit Rating, il r√©partit les valeurs en trois cat√©gories: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Excellent¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Good¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Poor¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Au total, 14 observations ont √©t√© faites. 7 d'entre eux appartiennent √† la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Responsabilit√© Normale</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et 7 autres √† la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haute Responsabilit√©</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Il s'agit d'une division en soi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si nous regardons la somme totale des valeurs dans la premi√®re ligne, nous verrons que nous avons 4 observations avec une </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">excellente</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> valeur </font><font style="vertical-align: inherit;">bas√©e sur la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cote de cr√©dit</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . De plus, je peux m√™me dire que ma variable cible est bris√©e par une </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notation de cr√©dit ¬´excellente¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Parmi les observations avec la valeur </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Excellent¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> par attribut</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Notation de cr√©dit</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , il y en a 3 qui appartiennent √† la classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilit√© normale</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et 1 qui appartient √† la </font><font style="vertical-align: inherit;">classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilit√© √©lev√©e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . De m√™me, je peux calculer des r√©sultats similaires pour d'autres valeurs </font><font style="vertical-align: inherit;">de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notation de cr√©dit √†</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> partir du tableau de contingence. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par exemple, j'utilise le tableau de contingence ci-dessus pour calculer ind√©pendamment l'entropie de notre variable cible, puis calculer son entropie, en tenant compte des informations suppl√©mentaires de l'attribut de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notation de cr√©dit</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Je peux donc calculer la quantit√© d'informations suppl√©mentaires que la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cote de cr√©dit</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> me donnera </font><font style="vertical-align: inherit;">pour la variable cible de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilit√©</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Alors, commen√ßons.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2v/2y/lg/2v2ylghvtk-f-e0eom6aeocsb1q.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 L'entropie de notre variable cible est 1, ce qui signifie un encombrement maximal en raison de la distribution uniforme des √©l√©ments entre </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Normal¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Haut¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . L'√©tape suivante consiste √† calculer l'entropie de la variable cible du </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passif</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , en tenant compte des informations suppl√©mentaires de la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notation</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de </font><i><font style="vertical-align: inherit;">cr√©dit</font></i><font style="vertical-align: inherit;"> . Pour ce faire, nous calculons l'entropie du </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passif</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour chaque valeur de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notation de cr√©dit</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et les ajoutons en utilisant le rapport d'observation pond√©r√© moyen pour chaque valeur. La raison pour laquelle nous utilisons la moyenne pond√©r√©e deviendra plus claire lorsque nous parlerons d'arbres de d√©cision. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rt/_5/fh/rt_5fhldx4dfjcioh7d_uiori6e.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Nous avons obtenu l'entropie de notre variable cible avec l'attribut </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Credit Rating</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Nous pouvons maintenant calculer le gain </font><font style="vertical-align: inherit;">de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilit√©</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> informationnel </font><font style="vertical-align: inherit;">de la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notation</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de </font><i><font style="vertical-align: inherit;">cr√©dit</font></i><font style="vertical-align: inherit;"> pour comprendre √† quel point cette fonctionnalit√© est informative. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 La connaissance </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de la cote de cr√©dit</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nous </font><i><font style="vertical-align: inherit;">a</font></i><font style="vertical-align: inherit;"> aid√©s √† r√©duire l'incertitude de notre variable cible de </font><i><font style="vertical-align: inherit;">passif</font></i><font style="vertical-align: inherit;"> .</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. N'est-ce pas un bon signe qui devrait fonctionner? Donnez-nous des informations sur la variable cible? Eh bien, pour cette raison m√™me, les arbres de d√©cision utilisent l'entropie et le gain informationnel. Ils d√©terminent selon quel crit√®re pour briser les n≈ìuds en branches, afin d'approcher la variable cible avec chaque partition suivante, et aussi de comprendre quand la construction de l'arbre doit √™tre termin√©e! (en plus des hyperparam√®tres tels que la profondeur maximale, bien s√ªr). Voyons comment tout cela fonctionne dans l'exemple suivant en utilisant des arbres de d√©cision. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemple: arbre de d√©cision</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Examinons un exemple de construction d‚Äôun arbre de d√©cision, dans le but de pr√©dire si le cr√©dit d‚Äôune personne sera radi√© ou non. La population sera de 30 exemplaires. 16 appartiendront √† la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et les 14 autres</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Non amorti¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Nous aurons deux signes, √† savoir </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Balance"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui peut prendre deux valeurs: "&lt;50K" ou "&gt; 50K", et </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"R√©sidence"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui prend trois valeurs: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OWN"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"RENT"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OTHER"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Je vais montrer comment l'algorithme d'arbre de d√©cision d√©cidera quel attribut casser en premier et quel attribut sera plus informatif, c'est-√†-dire qu'il √©limine le mieux l'incertitude de la variable cible en utilisant le concept d'entropie et de gain d'information. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sympt√¥me 1: √©quilibre</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Ici, les cercles appartiennent √† la </font><font style="vertical-align: inherit;">classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´radiation¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et les √©toiles correspondent √† la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´non radiation¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Partitionnement d'une racine parent par attribut</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'√©quilibre</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nous donnera 2 n≈ìuds h√©ritiers. Dans le n≈ìud de gauche, il y aura 13 observations, o√π 12/13 (probabilit√© 0,92) d'observations de la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´radiation¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et seulement 1/13 (probabilit√© 0,08) d'observations de la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´non radiation¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dans le n≈ìud de droite, il y aura 17 observations sur 30, dont 13/17 (probabilit√© 0,76) d'observations de la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´radiations¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et 4/17 (probabilit√© 0,24) d'observations de la classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´non radiations¬ª</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Calculons l'entropie de la racine et voyons dans quelle mesure l'arbre peut r√©duire l'incertitude en utilisant une partition bas√©e sur </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yq/ke/do/yqkedojc2s80__h-vqqcptzewai.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Une r√©partition bas√©e sur l' </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√©quilibre</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> donnera un gain d'information de 0,37. Comptons la m√™me chose pour le signe de la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©sidence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et comparer les r√©sultats. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sympt√¥me 2: R√©sidence Le</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/mx/tm/sd/mxtmsdt2hm0mamxkdxzqnb9v7mg.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 fractionnement d'un arbre bas√© sur </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©sidence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vous donnera 3 n≈ìuds h√©ritiers. Le n≈ìud successeur gauche recevra 8 observations, o√π 7/8 (probabilit√© 0,88) d'observations de la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et seulement 1/8 (probabilit√© 0,12) des observations de la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">non radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Le n≈ìud successeur moyen recevra 10 observations, dont 4/10 (probabilit√© 0,4) d'observations de la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et 6/10 (probabilit√© 0,6) des observations de la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">non radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . L'h√©ritier droit recevra 12 observations, dont 5/12 (probabilit√© 0,42) d'observations de la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et 7/12 (probabilit√© 0,58) des observations de la classe des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">non radiations</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Nous connaissons d√©j√† l'entropie du n≈ìud parent, nous calculons donc simplement l'entropie apr√®s la partition pour comprendre le gain informationnel de l'attribut </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/cb/zt/zf/cbztzffw12-wkj6cjfayt_jzlcq.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Le gain informationnel de l'attribut </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est </font><font style="vertical-align: inherit;">presque 3 fois sup√©rieur √† celui de la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©sidence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! Si vous regardez √† nouveau les graphiques, vous verrez que le partitionnement selon </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> donnera des n≈ìuds descendants plus propres que selon </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Cependant, le n≈ìud le plus √† gauche de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence est</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √©galement assez propre, mais c'est ici que la moyenne pond√©r√©e entre en jeu. Malgr√© le fait que le n≈ìud soit propre, il a le moins d'observations et son r√©sultat est perdu dans le recalcul g√©n√©ral et le calcul de l'entropie totale selon </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ceci est important car nous recherchons le contenu informatif g√©n√©ral de l'attribut et ne voulons pas que le r√©sultat final soit d√©form√© par la valeur rare de l'attribut. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'attribut </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> lui-m√™me </font><font style="vertical-align: inherit;">fournit plus d'informations sur la variable cible que </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©sidence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ainsi, l'entropie de notre variable cible est r√©duite. L'algorithme d'arbre de d√©cision utilise ce r√©sultat pour effectuer la premi√®re division selon </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour d√©cider plus tard sur quelle base casser les n≈ìuds suivants. Dans le monde r√©el, lorsqu'il y a plus de deux fonctionnalit√©s, la premi√®re ventilation se produit en fonction de la fonctionnalit√© la plus informative, puis, √† chaque rupture ult√©rieure, le gain d'informations sera recompt√© pour chaque fonctionnalit√© suppl√©mentaire, car il ne sera pas le m√™me que le gain d'informations de chaque fonctionnalit√© individuellement. L'entropie et le gain informationnel doivent √™tre calcul√©s apr√®s qu'une ou plusieurs partitions se sont produites, ce qui affectera le r√©sultat final. L'arbre de d√©cision r√©p√©tera ce processus au fur et √† mesure qu'il grandit, jusqu'√† ce qu'il atteigne une certaine profondeur ou qu'une sorte de fractionnement conduise √† un gain d'informations plus √©lev√© au-del√† d'un certain seuil, qui peut √©galement √™tre sp√©cifi√© comme hyperparam√®tre!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'est tout! </font><font style="vertical-align: inherit;">Vous savez maintenant quelle entropie, quel gain d'information et comment ils sont calcul√©s. </font><font style="vertical-align: inherit;">Vous comprenez maintenant comment l'arbre de d√©cision, seul ou en tant qu'ensemble, prend des d√©cisions sur le meilleur ordre de partitionnement par attributs et d√©cide quand s'arr√™ter lors de l'apprentissage des donn√©es disponibles. </font><font style="vertical-align: inherit;">Eh bien, si vous devez expliquer √† quelqu'un comment fonctionnent les arbres de d√©cision, j'esp√®re que vous pourrez faire face √† cette t√¢che de mani√®re ad√©quate. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'esp√®re que vous avez appris quelque chose d'utile par cet article. </font><font style="vertical-align: inherit;">Si j'ai rat√© quelque chose ou que je me suis mal exprim√©, √©crivez-moi. </font><font style="vertical-align: inherit;">Je vous en serai tr√®s reconnaissant! </font><font style="vertical-align: inherit;">Remercier.</font></font><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En savoir plus sur le cours.</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr502178/index.html">oVirt en 2 heures. Partie 3. Param√®tres avanc√©s</a></li>
<li><a href="../fr502180/index.html">Le jour o√π le p√©rim√®tre a disparu. Solutions de s√©curit√© de Microsoft et partenaires</a></li>
<li><a href="../fr502182/index.html">Encore une fois √† propos de MikroTik ou du SOCKS5 tant attendu</a></li>
<li><a href="../fr502186/index.html">S√©minaire en ligne. S√©curit√© de l'information: SOC mis en quarantaine</a></li>
<li><a href="../fr502196/index.html">Dans l'approche des math√©matiques il y a un si√®cle, on trouve de nouvelles cl√©s pour d√©m√™ler la nature du temps</a></li>
<li><a href="../fr502202/index.html">Le d√©veloppement de la technologie sans pilote dans le transport ferroviaire</a></li>
<li><a href="../fr502204/index.html">√âcriture de tests @SpringBootTest lors de l'utilisation de Spring Shell dans une application</a></li>
<li><a href="../fr502206/index.html">Yandex a enregistr√© les sons des r√©tro-ordinateurs</a></li>
<li><a href="../fr502208/index.html">Extension Chrome pour masquer les recommandations distrayantes sur YouTube</a></li>
<li><a href="../fr502234/index.html">–ò–Ω—Å–∞–π–¥—ã –æ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ Facebook: –∫–∞–∫ –ø–æ–ø–∞—Å—Ç—å –Ω–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É, –ø–æ–ª—É—á–∏—Ç—å –æ—Ñ—Ñ–µ—Ä –∏ –≤—Å–µ –æ —Ä–∞–±–æ—Ç–µ –≤ –∫–æ–º–ø–∞–Ω–∏–∏</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
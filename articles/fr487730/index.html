<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💒 👹 💅🏿 Traitement du langage naturel. Résultats 2019 et tendances 2020 🗺️ 👨🏿‍🔧 👏🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour à tous. Avec un peu de retard, j'ai décidé de publier cet article. Chaque année, j'essaie de résumer ce qui s'est passé dans le domaine du tra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Traitement du langage naturel. Résultats 2019 et tendances 2020</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/huawei/blog/487730/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonjour à tous. </font><font style="vertical-align: inherit;">Avec un peu de retard, j'ai décidé de publier cet article. </font><font style="vertical-align: inherit;">Chaque année, j'essaie de résumer ce qui s'est passé dans le domaine du traitement du langage naturel. </font><font style="vertical-align: inherit;">Cette année ne faisait pas exception.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les BERT, les BERT sont partout</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Commençons dans l'ordre. </font><font style="vertical-align: inherit;">Si vous n'êtes pas parti pour la taïga sibérienne éloignée ou des vacances à Goa depuis un an et demi, alors vous devez avoir entendu le mot BERT. </font><font style="vertical-align: inherit;">Apparu à la toute fin de 2018, au cours du temps passé, ce modèle a acquis une telle popularité que l'image sera juste:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/cu/vm/_i/cuvm_irxzrscw8rctmtyoqywxss.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les BERT ont vraiment captivé tout ce qui pouvait être rempli en PNL. </font><font style="vertical-align: inherit;">Ils ont commencé à être utilisés pour la classification, la reconnaissance des entités nommées et même pour la traduction automatique. </font><font style="vertical-align: inherit;">Autrement dit, vous ne pouvez pas les contourner et vous devez toujours dire de quoi il s'agit. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5j/mo/sq/5jmosqk9vhjts6ai88v8hcrdhci.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La photo montre une comparaison du héros de l'occasion (à gauche) avec deux modèles qui sonnaient également. </font><font style="vertical-align: inherit;">Sur la droite se trouve le prédécesseur immédiat de BERT - le modèle </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Digression lyrique.</font></font></b><div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/8a1/bb1/e07/8a1bb1e076e3b3b1b2637343e28359d4.jpg" alt="image"><br>
         « »:           ,        ,   Elmo,  Bert —   ;    ,   ,   , —    .         .  ,    ,   .<br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le modèle </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Allen AI</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ELMo </font><font style="vertical-align: inherit;">est une sorte de successeur de tout le développement de la région au cours des années précédentes - à savoir, un réseau neuronal récurrent bidirectionnel, ainsi que plusieurs nouvelles astuces pour démarrer. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> collègues d' </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">OpenAI</font></a><font style="vertical-align: inherit;"> ont </font><font style="vertical-align: inherit;">décidé de ce qui peut être mieux fait. Et pour cela, il vous suffit d'appliquer l'architecture </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformer</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> présentée l'année précédente à Google </font><font style="vertical-align: inherit;">à cette tâche. Je crois qu'au cours des 2,5 dernières années, tout le monde a déjà réussi à se familiariser avec cette architecture, donc je ne m'y attarderai pas en détail. Pour ceux qui souhaitent recevoir la communion, je me réfère à mon </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bilan de la 2017e année</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ils (employés d'OpenAI) ont appelé leur modèle </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Et puis, sur ce modèle, ils </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ont fait du très bon travail</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Mais laissons cela à leur conscience et revenons à nos moutons, c'est-à-dire les modèles. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'une des astuces ELMo les plus importantes était la pré-formation sur un grand cas non alloué. Cela s'est très bien passé et des collègues de Google ont décidé que nous pouvions faire encore mieux. En plus d'appliquer l'architecture Transformer (qui était déjà dans GPT-2), BERT, qui représente les représentations d'encodeur bidirectionnelles des transformateurs, c'est-à-dire les représentations vectorielles d'un encodeur bidirectionnel basé sur l'architecture Transformer, contenait plusieurs éléments plus importants. Plus précisément, le plus important était la façon de s'entraîner sur un gros dossier.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lb/hw/yw/lbhwywgm70j3shvnrtzrnx6clyy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'image montre une méthode pour baliser les données non allouées. Deux méthodes de mise en page sont spécifiquement présentées à la fois. Tout d'abord, une séquence de jetons (mots) est prise, par exemple, une phrase, et dans cette séquence, un jeton arbitraire ([MASQUE]) est masqué. Et le modèle dans le processus d'apprentissage devrait deviner quel type de jeton était déguisé. La deuxième façon - deux phrases sont prises séquentiellement ou à des endroits arbitraires dans le texte. Et le modèle doit deviner si ces phrases étaient séquentielles ([CLS] et [SEP]). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'idée d'une telle formation était extrêmement efficace. La réponse d'amis jurés de Facebook était le modèle </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RoBERTa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , un article sur ce modèle est intitulé «Formation BERT durablement optimisée». En outre.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je ne vais pas énumérer toutes les façons d'améliorer la formation d'un grand modèle de langage basé sur l'architecture Transfomer car il est tout simplement ennuyeux. </font><font style="vertical-align: inherit;">Je ne mentionne peut-être que le travail de mes collègues de Hong Kong - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ERNIE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Dans leur travail, les collègues enrichissent la formation en utilisant des graphiques de connaissances. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avant de poursuivre, voici quelques liens utiles: un article sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Ainsi qu'un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ensemble de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> modèles BERT et ELMo formés pour la langue russe.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Petits modèles</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais assez parlé des BERT. Il existe plusieurs tendances plus importantes. Tout d'abord, il s'agit d'une tendance à réduire la taille du modèle. Le même BERT est très exigeant en ressources, et beaucoup ont commencé à réfléchir à la façon de maintenir (ou de ne pas vraiment perdre) la qualité, de réduire les ressources nécessaires au fonctionnement des modèles. Des collègues de Google ont proposé un petit BERT, je ne plaisante pas - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ALBERT: Un petit BERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Vous pouvez voir que le petit BERT surpasse même son frère aîné dans la plupart des tâches, tout en ayant un ordre de grandeur moins de paramètres. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/y5/su/h3/y5suh3uzlmgy16l8stcoahmio4w.png"> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une autre approche du même bar a été faite à nouveau par mes collègues de Hong Kong. Ils sont venus avec un petit </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">TinyBERT</font></a><font style="vertical-align: inherit;"> . (Si à ce stade, vous pensiez que les noms ont commencé à être répétés, je suis enclin à être d'accord avec vous.)</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7_/bb/el/7_bbelco1m2dewd3gj6cjqq2upw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La différence fondamentale entre les deux modèles ci-dessus est que si ALBERT utilise des astuces pour réduire le modèle BERT d'origine, par exemple, le partage de paramètres et la réduction de la dimension des représentations vectorielles internes grâce à la décomposition matricielle, alors TinyBERT utilise une approche fondamentalement différente, à savoir la distillation des connaissances, c'est-à-dire qu'il existe un petit modèle qui apprend à répéter après sa sœur aînée dans le processus d'apprentissage.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Petits étuis</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ces dernières années (depuis environ 1990, lorsque l'Internet est apparu), il y a eu une augmentation des bâtiments disponibles. Puis sont venus les algorithmes qui sont devenus capables de traiter de si grandes enceintes (c'est ce que nous appelons la «révolution du deep learning», c'est déjà l'année depuis 2013). Et, en conséquence, il a commencé à être perçu normalement que pour obtenir une bonne qualité dans certaines tâches, d'énormes tableaux de données balisées sont nécessaires - des corps de texte dans notre cas. Par exemple, les cas typiques d'apprentissage des tâches de traduction automatique aujourd'hui sont mesurés en millions de paires de phrases. Il est depuis longtemps évident que pour de nombreuses tâches, il est impossible de rassembler de tels cas dans un délai raisonnable et pour un montant raisonnable. Pendant longtemps, on ne savait pas trop quoi faire à ce sujet. Mais l'année dernière (qui pensez-vous?) BERT est entré en scène.Ce modèle a pu se pré-former sur de grands volumes de textes non alloués, et le modèle fini était facile à adapter à la tâche avec un petit boîtier.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7_/bb/el/7_bbelco1m2dewd3gj6cjqq2upw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Toutes les tâches énumérées dans ce tableau ont un corps d'entraînement de la taille de plusieurs </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">milliers d'</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> unités. </font><font style="vertical-align: inherit;">Autrement dit, deux à trois ordres de grandeur de moins. </font><font style="vertical-align: inherit;">Et c'est une autre raison pour laquelle le BERT (et ses descendants et parents) sont devenus si populaires.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nouvelles tendances</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, au final, quelques nouvelles tendances, comme je les ai vues. Tout d'abord, il s'agit d'un changement fondamental d'attitude à l'égard du texte. Si tout le temps précédent dans la plupart des tâches, le texte n'était perçu que comme matériel d'entrée, et la sortie était quelque chose d'utile, par exemple, une étiquette de classe. La communauté a maintenant la possibilité de se rappeler que le texte est avant tout un moyen de communication, c'est-à-dire que vous pouvez «parler» au modèle - poser des questions et recevoir des réponses sous la forme d'un texte lisible par l'homme. C'est ce que dit le nouvel article de Google </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T5</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (le nom peut être traduit par «transformateur cinq fois»).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ba/vz/mj/bavzmjwryypmza-ywo18njxfbjy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une autre tendance importante est que la région réapprend à travailler avec de longs textes. Depuis les années 70, la communauté a des moyens de travailler avec des textes de longueurs arbitraires - prenez le même TF-IDF. Mais ces modèles ont leur propre limite de qualité. Mais les nouveaux modèles d'apprentissage en profondeur n'étaient pas capables de travailler avec des textes longs (le même BERT a une limite de 512 jetons de la longueur du texte d'entrée). Mais ces derniers temps, au moins deux ouvrages sont apparus qui, sous des angles différents, abordent le problème du texte long. Le premier travail du groupe de Ruslan Salakhutdinov appelé Transformer-XL. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ci/op/gj/ciopgjs1htbc2gmucz7dwkiwqtk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans ce travail, l'idée est relancée qui a rendu les réseaux récursifs si populaires - vous pouvez enregistrer l'état précédent et l'utiliser pour créer le suivant, même si vous ne faites pas reculer le dégradé dans le temps (BPTT). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deuxième</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le travail</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fonctionne avec les polynômes de Legendre et avec leur aide vous permet de traiter des séquences de dizaines de milliers de jetons avec des réseaux de neurones récurrents. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur ce point, je voudrais terminer l'examen des changements qui ont eu lieu et des tendances émergentes. </font><font style="vertical-align: inherit;">Voyons ce qui va se passer cette année, je suis sûr que beaucoup de choses intéressantes. </font><font style="vertical-align: inherit;">Vidéo de mon discours sur le même sujet dans l'arbre de données:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cdlAUcaOCDY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS Nous aurons bientôt d'autres annonces intéressantes, ne changez pas!</font></font></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr487706/index.html">Découverte de service dans les systèmes distribués à l'aide de l'exemple Consul. Alexander Sigachev</a></li>
<li><a href="../fr487716/index.html">Parfait SAST. Analyseur</a></li>
<li><a href="../fr487720/index.html">Sur le corutinisme concurrentiel (en utilisant la programmation réactive comme exemple)</a></li>
<li><a href="../fr487724/index.html">BlazingPizza: application Blazor du début à la fin. Partie 2. Ajouter un composant</a></li>
<li><a href="../fr487728/index.html">@Pythonetc compilation, janvier 2020</a></li>
<li><a href="../fr487734/index.html">Accélération du noyau Entity Framework</a></li>
<li><a href="../fr487738/index.html">Animation de schéma dans SCADA</a></li>
<li><a href="../fr487740/index.html">Assemblage d'un magnétomètre portable</a></li>
<li><a href="../fr487742/index.html">Négociation d'arbitrage (algorithme Bellman-Ford)</a></li>
<li><a href="../fr487744/index.html">FARO présente le scanner laser laser FOCUS S 70</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
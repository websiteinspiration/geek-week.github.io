<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜì üè£ üëâüèº VMware vSAN 6.7 - And the thunder struck üéΩ üî¥ üñêüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The year 2018 was ending ... 
 
 Once, on a clear December day, our Company decided to purchase a new hardware. No, of course, this did not happen ove...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>VMware vSAN 6.7 - And the thunder struck</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487592/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The year 2018 was ending ... </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Once, on a clear December day, our Company decided to purchase a new hardware. No, of course, this did not happen overnight. The decision was made earlier. Much earlier. But, as usual, not always our desires coincide with the capabilities of shareholders. And there was no money, and we held on. But finally, that joyful moment came when the acquisition was approved at all levels. Everything was fine, the white-collar workers applauded joyfully, they were tired of processing documents for 25 hours monthly on 7-year-old servers, and they very persistently asked the IT Department to come up with something to give them more time for other, equally important things .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We promised to reduce the time for processing documents by 3 times, up to 8 hours. </font><font style="vertical-align: inherit;">For this, a sparrow was fired from a cannon. </font><font style="vertical-align: inherit;">This option seemed the only one, since our team did not, and never had, a database administrator to apply all kinds of query optimization (DBA).</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The configuration of the selected equipment was, of course, sky-high. </font><font style="vertical-align: inherit;">These were three servers from the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HPE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> company </font><font style="vertical-align: inherit;">- DL560 Gen10. </font><font style="vertical-align: inherit;">Each of them boasted 4 Intel Xeon Platinum 8164 2.0Ghz processors with 26 cores, 256 DDR4 RAM, as well as 8 SSD 800Gb SAS (SSD 800Gb WD Ultrastar DC SS530 WUSTR6480ASS204) + 8 SSD 1.92Tb (Western Digital Ultrastar DC SS530 )</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
These "pieces of iron" were intended for the VMware cluster (HA + DRS + vSAN). Which has been working with us for almost 3 years on similar servers of the 7th and 8th generations, also from HPE. By the way, there were no problems until HPE refused to support them and upgrade ESXi from version 6.0, even to 6.5, without a tambourine. Well, okay, as a result, it was possible to update. By changing the installation image, removing incompatible problem modules from the installation image, etc. This also added fuel to the fire of our desire to match everything new. Of course, if it weren‚Äôt for the new vSAN ‚Äútricks‚Äù, in the coffin we saw an update of the entire system from version 6.0 to a newer one, and there would be no need to write an article, but we are not looking for easy ways ...</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, we purchased this equipment and decided to replace the long-obsolete. We applied the last </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SPP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to each new server, installed in each of them two Ethernet 10G network cards (one for user networks, and the second for SAN, 656596-B21 HP Ethernet 10Gb 2-port 530T). Yes, each new server came with an SFP + network card without modules, but our network infrastructure implied Ethernet (two stacks of DELL 4032N switches for LAN and SAN networks), and the HP distributor in Moscow did not have HPE 813874-B21 modules and we they did not wait.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When it came time to install ESXi and incorporate new nodes into a common VMware data center, a ‚Äúmiracle‚Äù happened. As it turned out, HPE ESXi Custom ISO version 6.5 and below is not designed to be installed on new Gen10 servers. Hardcore only, only 6.7. And we had to unwittingly follow the precepts of the ‚Äúvirtual company‚Äù. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A new HA + DRS cluster was created, a vSAN cluster was created, all in strict compliance with VMware HCL and </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">this document</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Everything was configured according to Feng Shui and only periodic ‚Äúalarms‚Äù were suspicious in monitoring vSAN about non-zero parameter values ‚Äã‚Äãin this section:</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/800/65a/ff5/80065aff58945762f1660b556d61216e.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We, with peace of mind, moved all virtual machines (about 50 pieces) to new servers and to a new vSAN storage built on SSD disks, we checked the performance of document processing in the new environment (by the way, it turned out to save a lot more time than we planned) . Until the heaviest base was transferred to the new cluster, the operation, which was mentioned at the beginning of the article, took about 4 hours instead of 25! This was a significant contribution to the New Year mood of all participants in the process. Some probably began to dream of a prize. Then everyone happily left for the New Year holidays.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When the weekdays of the new year 2019 began, nothing portended a catastrophe. All services, transferred to new capacities, without exaggeration, took off! Only events in the re-synchronization section of objects became much more. And after a couple of weeks trouble happened. In the early morning, almost all of the key services of the Company (1s, MSSQL, SMB, Exchange, etc.) stopped responding, or began to respond with a long delay. The entire infrastructure plunged into complete chaos, and no one knew what happened and what to do. All virtual machines in vCenter looked ‚Äúgreen‚Äù, there were no errors in their monitoring. Rebooting did not help. Moreover, after a reboot, some machines could not even boot, displaying various process errors in the console. Hell seemed to come to us and the devil was rubbing his hands in anticipation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Under the pressure of serious stress, it was possible to determine the source of the disaster. This problem turned out to be vSAN distributed storage. Uncontrolled data corruption on virtual machine disks occurred, at first glance - for no reason. At that time, the only solution that seemed rational was to contact VMware technical support with screams: SOS, save-help! </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And this decision, subsequently, saved the Company from the loss of relevant data, including employee mailboxes, databases and shared files. Together, we are talking about 30+ terabytes of information.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
He is obliged to pay tribute to the VMware support staff who did not ‚Äúplay football‚Äù with the holder of the basic technical support subscription, but included this case in the Enterpise segment, and the process spun around the clock. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What happened next:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VMware technical support posed two main questions: how to recover data and how to solve the problem of ‚Äúphantom‚Äù data corruption in virtual machine disks in the ‚ÄúvSAN‚Äù combat cluster. </font><font style="vertical-align: inherit;">By the way, the data was nowhere to recover, since the additional storage was occupied by backup copies and there was simply nowhere to deploy ‚Äúcombat‚Äù services.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">While I, jointly with VMware, tried to put together the ‚Äúdamaged‚Äù objects in the vSAN cluster, my colleagues urgently mined a new storage that could accommodate all 30+ terabytes of Company data.</font></font></li>
<li>  ,   ,     VMware      ,           ,     ¬´¬ª      - -   .         , ? </li>
<li>        .</li>
<li> ,  ¬´ ¬ª   .</li>
<li>          ,   ,   ¬´¬ª        .</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I had to temporarily (for a couple of days) sacrifice the efficiency of mail, for the sake of an additional 6 terabytes of free space in the store, to launch the key services on which the Company's income depended.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thousands of chat lines with English-speaking colleagues from VMware were saved ‚Äúfor memory‚Äù, here is a short excerpt from our conversations:</font></font></li>
</ol><br>
<pre><code class="plaintext">I understood that you are now migrating all the VMs out of vSAN datastore.<font></font>
May I know, how the migration task is going on.? How many VMs left and how much time is expected to migrate the remaining VMs. ?<font></font>
There are 6 vms still need to be migrated. 1 of them is fail so far.<font></font>
How much time is expected to complete the migration for the working VMs..?<font></font>
I think atleast 2-3 hours<font></font>
ok<font></font>
Can you please SSH to vCenter server ?<font></font>
you on it<font></font>
/localhost/Datacenter ###CLUB/computers/###Cluster&gt; vsan.check_state .<font></font>
2019-02-02 05:22:34 +0300: Step 1: Check for inaccessible vSAN objects<font></font>
Detected 3 objects to be inaccessible<font></font>
Detected 7aa2265c-6e46-2f49-df40-20677c0084e0 on esxi-dl560-gen10-2.####.lan to be inaccessible<font></font>
Detected 99c3515c-bee0-9faa-1f13-20677c038dd8 on esxi-dl560-gen10-3.####.lan to be inaccessible<font></font>
Detected f1ca455c-d47e-11f7-7e90-20677c038de0 on esxi-dl560-gen10-1.####.lan to be inaccessible<font></font>
2019-02-02 05:22:34 +0300: Step 2: Check for invalid/inaccessible VMs<font></font>
Detected VM 'i.#####.ru' as being 'inaccessible'<font></font>
2019-02-02 05:22:34 +0300: Step 3: Check for VMs for which VC/hostd/vmx are out of sync<font></font>
Did not find VMs for which VC/hostd/vmx are out of sync<font></font>
/localhost/Datacenter ###CLUB/computers/###Cluster&gt;<font></font>
Thank you<font></font>
second vm with issues: sd.####.ru</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
How this problem manifested itself (in addition to the firmly fallen organization services). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exponential growth of checksum errors (CRC) ‚Äúout of the blue‚Äù during data exchange with disks in HBA mode. </font><font style="vertical-align: inherit;">How to check this - enter the following command in the console of each ESXi node:</font></font><br>
<br>
<pre><code class="cs">while true; do clear; for disk in $(localcli vsan storage list | grep -B10 'ity Tier: tr' |grep "VSAN UUID"|awk '{print $3}'|sort -u);do echo ==DISK==$disk====;vsish -e get /vmkModules/lsom/disks/$disk/checksumErrors | grep -v ':0';done; sleep 3; done</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result of execution, you can see CRC errors for each disk in the vSAN cluster of this node (zero values ‚Äã‚Äãwill not be displayed). </font><font style="vertical-align: inherit;">If you have positive values, and moreover, they are constantly growing, then there is a reason for constantly arising tasks in the Monitor -&gt; vSAN -&gt; Resincing objects section of the cluster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
How to recover disks of virtual machines that do not clone or migrate by standard means? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Who would have thought using the powerful cat command:</font></font><br>
<br>
<pre><code class="bash">1. cd      vSAN<font></font>
[root@esxi-dl560-gen10-1:~] cd /vmfs/volumes/vsanDatastore/estaff<font></font>
<font></font>
2. grep vmdk     uuid<font></font>
<font></font>
[root@esxi-dl560-gen10-1:/vmfs/volumes/vsan:52f53dfd12dddc84-f712dbefac32cd1a/2636a75c-e8f1-d9ca-9a00-20677c0084e0] grep vsan *vmdk<font></font>
estaff.vmdk:RW 10485760 VMFS "vsan://3836a75c-d2dc-5f5d-879c-20677c0084e0"<font></font>
estaff_1.vmdk:RW 41943040 VMFS "vsan://3736a75c-e412-a6c8-6ce4-20677c0084e0"<font></font>
[root@esxi-dl560-gen10-1:/vmfs/volumes/vsan:52f53dfd12dddc84-f712dbefac32cd1a/2636a75c-e8f1-d9ca-9a00-20677c0084e0]<font></font>
<font></font>
3.    VM  ,  :<font></font>
<font></font>
mkdir /vmfs/volumes/POWERVAULT/estaff<font></font>
<font></font>
4.   vmx  <font></font>
<font></font>
cp *vmx *vmdk /vmfs/volumes/POWERVAULT/estaff<font></font>
<font></font>
5.      ,      ^_^<font></font>
<font></font>
/usr/lib/vmware/osfs/bin/objtool open -u 3836a75c-d2dc-5f5d-879c-20677c0084e0; sleep 1; cat /vmfs/devices/vsan/3836a75c-d2dc-5f5d-879c-20677c0084e0 &gt;&gt; /vmfs/volumes/POWERVAULT/estaff/estaff-flat.vmdk<font></font>
<font></font>
6. cd   :<font></font>
<font></font>
 cd /vmfs/volumes/POWERVAULT/estaff<font></font>
<font></font>
7.    - estaff.vmdk     <font></font>
<font></font>
[root@esxi-dl560-gen10-1:/tmp] cat estaff.vmdk<font></font>
# Disk DescriptorFile<font></font>
version=4<font></font>
encoding="UTF-8"<font></font>
CID=a7bb7cdc<font></font>
parentCID=ffffffff<font></font>
createType="vmfs"<font></font>
<font></font>
# Extent description<font></font>
RW 10485760 VMFS "vsan://3836a75c-d2dc-5f5d-879c-20677c0084e0"      &lt;&lt;&lt;&lt;&lt;     "estaff-flat.vmdk"<font></font>
<font></font>
# The Disk Data Base<font></font>
#DDB<font></font>
<font></font>
ddb.adapterType = "ide"<font></font>
ddb.deletable = "true"<font></font>
ddb.geometry.cylinders = "10402"<font></font>
ddb.geometry.heads = "16"<font></font>
ddb.geometry.sectors = "63"<font></font>
ddb.longContentID = "6379fa7fdf6009c344bd9a64a7bb7cdc"<font></font>
ddb.thinProvisioned = "1"<font></font>
ddb.toolsInstallType = "1"<font></font>
ddb.toolsVersion = "10252"<font></font>
ddb.uuid = "60 00 C2 92 c7 97 ca ae-8d da 1c e2 3c df cf a5"<font></font>
ddb.virtualHWVersion = "8"<font></font>
[root@esxi-dl560-gen10-1:/tmp]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
How to recognize naa.xxxx ... disks in disk groups:</font></font><br>
<br>
<pre><code class="bash">[root@esxi-dl560-gen10-1:/vmfs/volumes] vdq -Hi<font></font>
Mappings:<font></font>
   DiskMapping[0]:<font></font>
           SSD:  naa.5000c5003024eb43<font></font>
            MD:  naa.5000cca0aa0025f4<font></font>
            MD:  naa.5000cca0aa00253c<font></font>
            MD:  naa.5000cca0aa0022a8<font></font>
            MD:  naa.5000cca0aa002500<font></font>
<font></font>
   DiskMapping[2]:<font></font>
           SSD:  naa.5000c5003024eb47<font></font>
            MD:  naa.5000cca0aa002698<font></font>
            MD:  naa.5000cca0aa0029c4<font></font>
            MD:  naa.5000cca0aa002950<font></font>
            MD:  naa.5000cca0aa0028cc<font></font>
<font></font>
   DiskMapping[4]:<font></font>
           SSD:  naa.5000c5003024eb4f<font></font>
            MD:  naa.5000c50030287137<font></font>
            MD:  naa.5000c50030287093<font></font>
            MD:  naa.5000c50030287027<font></font>
            MD:  naa.5000c5003024eb5b<font></font>
            MD:  naa.5000c50030287187<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
How to find out vUAN UUIDs for each naa ....:</font></font><br>
<br>
<pre><code class="bash">[root@esxi-dl560-gen10-1:/vmfs/volumes] localcli vsan storage list | grep -B15 'ity Tier: tr' | grep -E '^naa|VSAN UUID'<font></font>
<font></font>
naa.5000cca0aa002698:<font></font>
   VSAN UUID: 52247b7d-fed5-a2f2-a2e8-5371fa7ef8ed<font></font>
naa.5000cca0aa0029c4:<font></font>
   VSAN UUID: 52309c55-3ecc-3fe8-f6ec-208701d83813<font></font>
naa.5000c50030287027:<font></font>
   VSAN UUID: 523d7ea5-a926-3acd-2d58-0c1d5889a401<font></font>
naa.5000cca0aa0022a8:<font></font>
   VSAN UUID: 524431a2-4291-cb49-7070-8fa1d5fe608d<font></font>
naa.5000c50030287187:<font></font>
   VSAN UUID: 5255739f-286c-8808-1ab9-812454968734<font></font>
naa.5000cca0aa0025f4: &lt;&lt;&lt;&lt;&lt;&lt;&lt;<font></font>
   VSAN UUID: 52b1d17e-02cc-164b-17fa-9892df0c1726<font></font>
naa.5000cca0aa00253c:<font></font>
   VSAN UUID: 52bd28f3-d84e-e1d5-b4dc-54b75456b53f<font></font>
naa.5000cca0aa002950:<font></font>
   VSAN UUID: 52d6e04f-e1af-cfb2-3230-dd941fd8a032<font></font>
naa.5000c50030287137:<font></font>
   VSAN UUID: 52df506a-36ea-f113-137d-41866c923901<font></font>
naa.5000cca0aa002500:<font></font>
   VSAN UUID: 52e2ce99-1836-c825-6600-653e8142e10f<font></font>
naa.5000cca0aa0028cc:<font></font>
   VSAN UUID: 52e89346-fd30-e96f-3bd6-8dbc9e9b4436<font></font>
naa.5000c50030287093:<font></font>
   VSAN UUID: 52ecacbe-ef3b-aa6e-eba3-6e713a0eb3b2<font></font>
naa.5000c5003024eb5b:<font></font>
   VSAN UUID: 52f1eecb-befa-12d6-8457-a031eacc1cab</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And the most important thing. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The problem turned out to be the incorrect operation of the firmware of the RAID controller and the HPE driver with vSAN. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Previously, in VMware 6.7 U1, compatible firmware for the HPE Smart Array P816i-a SR Gen10 controller in vSAN HCL was version 1.98 (which turned out to be fatal for our organization), and now </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">it says 1.65</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Moreover, version 1.99, which solved the problem at that time (January 31, 2019), was already in the HPE bins, but they did not pass it to either VMware or us, referring to the lack of certification, despite our disclaimers and all that , they say, the main thing for us is to solve the problem with the storage and that's it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, the problem was finally solved only after three months, when the firmware version 1.99 for the disk controller was released!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What conclusions have I drawn?</font></font><br>
<br>
<ol>
<li>     (   ),         .</li>
<li>     !   .</li>
<li>       ¬´¬ª ,   ¬´¬ª    ¬´¬ª   ,    30%      ¬´¬ª.</li>
<li>HPE,    ,           .</li>
<li> ,       :<br>
<br>
<ul>
<li>HPE -           .   ,     Enterprise       . ,    ,       ).</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I did not foresee a situation where additional disk space may be needed to place copies of all the Company's servers in case of emergency.</font></font></li>
</ul></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Additionally, in the light of what has happened, for VMware I will no longer buy hardware for large companies, any vendors other than DELL. </font><font style="vertical-align: inherit;">Why, because DELL, as far as I know, acquired VMware, and now the integration of hardware and software in this direction is expected to be as close as possible.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As they say, burnt in milk, blow into the water. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
That's all guys. </font><font style="vertical-align: inherit;">I wish you never to get into such terrible situations. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As I recall, I will startle already!</font></font></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en487574/index.html">Working with audio: progress and data visualization</a></li>
<li><a href="../en487578/index.html">CMake Optimization for Static Libraries</a></li>
<li><a href="../en487582/index.html">No gods burn pots</a></li>
<li><a href="../en487584/index.html">Githabification of Information Security</a></li>
<li><a href="../en487588/index.html">Quarkus: Supersonic subatomic veterinarian</a></li>
<li><a href="../en487594/index.html">Entertaining mnemonics: we collect auditory memory from visual</a></li>
<li><a href="../en487596/index.html">Eugene Varavva, a developer at Google. How to describe Google in 5 words</a></li>
<li><a href="../en487604/index.html">Embed programmer‚Äôs brief notes: section duplication in the microcontroller‚Äôs memory</a></li>
<li><a href="../en487606/index.html">Visualization of lines of tension and movements of electrostatic charges, simulation of planetary motion of the solar system</a></li>
<li><a href="../en487610/index.html">RealWorld: aiohttp, Tortoise ORM</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍🔬 😠 🙋🏼 OpenCVおよびTensorflow Squat Detector 👨🏿‍🤝‍👨🏼 🧕🏻 ▶️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="投獄の時代には体育をするのはいいことですが、すべての在宅労働者がこれに同意しているわけではないので苦労しました。しかし、自分で作業する必要があり、重力によって開始されたスポーツプロセスは、せいぜい片目で観察されただけで、景品に滑り込む傾向があったため、本当にウォーダーとして働きたくありませんでした。...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>OpenCVおよびTensorflow Squat Detector</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/501362/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">投獄の時代には体育をするのはいいことですが、すべての在宅労働者がこれに同意しているわけではないので苦労しました。</font><font style="vertical-align: inherit;">しかし、自分で作業する必要があり、重力によって開始されたスポーツプロセスは、せいぜい片目で観察されただけで、景品に滑り込む傾向があったため、本当にウォーダーとして働きたくありませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
専門的に変形した脳は、これらのプロセスを何らかの形で監視し、メトリックを収集し、そしてもちろんこれを手動で行うのではなく、それ自体ですべてを計算する必要があると心配していました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクワットから始めることにしました。</font><font style="vertical-align: inherit;">明示的な状態を伴う基本的な動き、大きな振幅、一般的には、理想的な選択です。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
技術的に言えば、私はRaspberry Piとカメラを持っています。プロトタイプとしてはこれで十分です。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データ収集</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここではすべてが簡単です。OpenCVを介してカメラの電源を入れ、シーケンスに従ってファイルに画像を書き込みます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">動き検出器</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
いくつかのオプションがありました。たとえば、セグメンテーションを使用して、画像内の人物を選択し、すでに何かをしています。</font><font style="vertical-align: inherit;">しかし、Raspberryでの妥当な時間でのセグメンテーションは非現実的な単語の組み合わせであり、これに加えて、各フレームをセグメント化する必要があり、シーケンス全体を持っているという重要な事実を見失うことになります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、私は、クリップ内の動く要素の選択に落ち着きました。</font><font style="vertical-align: inherit;">OpenCVには</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">優れた背景除去機能</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">があり、いくつかの操作を行うと、セグメント化されたオブジェクトを取得できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、背景減算器を作成します。</font></font><br>
<br>
<pre><code class="python hljs">backSub = cv.createBackgroundSubtractorMOG2()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして私たちは彼にショットを与え始めます：</font></font><br>
<br>
<pre><code class="python hljs">mask = backSub.apply(frame)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
出力は次のようになります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/or/g-/mq/org-mqpegauqqsjyquu7i9jcgtm.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、白を追加してアウトラインをより明確にします。</font></font><br>
<br>
<pre><code class="python hljs">mask = cv.dilate(mask, <span class="hljs-literal">None</span>, <span class="hljs-number">3</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 アイデアは、各フレームから同様のマスクを切り取り、スタンス、スクワット、または何にも分類しないことです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
興味深い質問は、このフレームから形状全体を切り取る方法です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、等高線を探しましょう。</font></font><br>
<br>
<pre><code class="python hljs">  cnts, _ = cv.findContours(img, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
十分な精度で最大の輪郭が図に対応すると考えています。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
悲しいかな、これは常にそうだとは限りません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それでも、解決されている問題の詳細を使用して、大きな輪郭から押し出すことができます。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクワットの特徴は、1か所で行われることです。そのため、図がフレーム間でその位置とサイズを保持しているという事実に依存できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、バウンディングrectを繰り返し作成し、メインパスがその外にある場合は増やします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
たとえば、この図では、最大の輪郭が赤、青でマークされています-この輪郭の境界の四角形、緑-すべての図形の境界の四角形。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/om/ng/gb/omnggbiqrbtqnlac437xatbuffi.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その結果、確実に動きのある長方形を得ることができる。</font><font style="vertical-align: inherit;">次に、得られたものを理解する必要があります。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ポーズの分類</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果の長方形が切り取られ、正方形に配置され、1つのサイズに縮小され、手動で分類されて、何らかのマスクが得られ</font><font style="vertical-align: inherit;">
ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクワットの場合：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kw/su/rr/kwsurrijtdee16nkjtoi0l-qlig.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ラックの場合：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ws/xu/9x/wsxu9xjobqhk1n_wswcj41tdsvy.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これはすでにニューラルネットワークにフィードできます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
分類には、白黒の画像でKeras + Tensorflowを使用します。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
写真のサイズは興味深い質問です</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。64x64と128x128の</font><font style="vertical-align: inherit;">2つのオプションで実験を行いました</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3つのクラス-スタンス、スクワット、何もありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最も単純な畳み込みネットワークを収集します。</font></font><br>
<br>
<pre><code class="python hljs"><font></font>
    model = Sequential([<font></font>
        Convolution2D(<span class="hljs-number">8</span>,(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=input_shape),<font></font>
        MaxPooling2D(),<font></font>
        Flatten(),<font></font>
        Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">'relu'</span>),<font></font>
        Dense(<span class="hljs-number">3</span>, activation=<span class="hljs-string">'softmax'</span>)<font></font>
      ])<font></font>
    model.compile(loss=<span class="hljs-string">"categorical_crossentropy"</span>, optimizer=SGD(lr=<span class="hljs-number">0.01</span>), metrics=[<span class="hljs-string">"accuracy"</span>])
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
分類の最小値は、</font><font style="vertical-align: inherit;">2つの畳み込み層を持つ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lenetのような</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルで</font><font style="vertical-align: inherit;">あるという意見があります</font><font style="vertical-align: inherit;">が、実際には、</font><font style="vertical-align: inherit;">この</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">1つの</font></a><font style="vertical-align: inherit;">畳み込みも機能します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、8つのフィルターと10の時代の128x128では、92.66％になります。</font><font style="vertical-align: inherit;">それは有望に見えます。</font><font style="vertical-align: inherit;">トレーニング時間が20時代に増えると、精度が99.34％に向上します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
10時代の64x64では、精度は86％しかありません。</font><font style="vertical-align: inherit;">20では、94に達し、30から96に達します。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、モデルは4倍小さく、4倍速く動作します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
収集したデータについては、Model-64でも同様の結果が得られたので、それで解決しました。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Raspberry Piで起動</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Opencv</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私はOpenCV-DNNモジュールの大ファンであり、ヘビー級のTensorflowに頼らずにそれを使ってモデルをスピンすることを期待しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、モデルをKerasからTFに変換してテストを実行すると、次のような悲しいメッセージが表示されました。</font></font><br>
<br>
<pre><code class="bash hljs">cv2.error: OpenCV(4.2.0) C:\projects\opencv-python\opencv\modules\dnn\src\dnn.cpp:562: error: (-2:Unspecified error) Can<span class="hljs-string">'t create layer "flatten_1/Shape" of type "Shape" in function '</span>cv::dnn::dnn4_v20191202::LayerData::getLayerInstance<span class="hljs-string">'</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
で</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スタックオーバーフロー</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">彼らは助言する場合には、6ヶ月前のトピックがあります：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最新バージョンにアップグレード</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FlattenをReshapeに置き換えることを想起させる</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
オプション</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は役に立たなかった、オプション</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2-</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">手元のタスクの代わりに私がやりたいことはまったくない。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tensorflow</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、TFを使用する以外に他に選択肢はありません。</font><font style="vertical-align: inherit;">Googleはかなり長い間Raspberryを公式にサポートしてきているので、頭痛の種は1つ減ります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
TFにはKeras用のアダプターが含まれているため、何も変換する必要はありません。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルの読み込み：</font></font><br>
<br>
<pre><code class="python hljs">    
  <span class="hljs-keyword">with</span>  open(MODEL_JSON, <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> f:<font></font>
      model_data = f.read()<font></font>
      model = tf.keras.models.model_from_json(model_data)<font></font>
      model.load_weights(MODEL_H5)<font></font>
      graph = tf.get_default_graph()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ファイルからマスクの写真をフィードします。</font></font><br>
<pre><code class="python hljs">    <font></font>
  img = cv.imread(path + f, cv.IMREAD_GRAYSCALE)<font></font>
  img = np.reshape(img,[<span class="hljs-number">1</span>,<span class="hljs-number">64</span>,<span class="hljs-number">64</span>,<span class="hljs-number">1</span>])
  <span class="hljs-keyword">with</span> graph.as_default():<font></font>
      c = model.predict_classes(img)<font></font>
      <span class="hljs-keyword">return</span> c[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> c <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
分類（ラズベリー）では、128x128の画像の場合は1/4秒、64x64の場合は60〜70ミリ秒かかります。これはほぼリアルタイムです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">プログラム</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらの作品から</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ラズベリーのプログラム</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を収集し</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
サービスは、次のインターフェイスでFlaskにあります。</font></font><br>
<br>
<ul>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GET /</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コントロールページ</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、以下について</font></font></li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GET /</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> status-現在の状態、スクワットの数、フレームを取得し</font><b><font style="vertical-align: inherit;">ます</font></b></font></li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">POST / start-</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">演習を開始します</font></font></li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">POST /停止</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -演習を終了</font></font></li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GET /ストリーム</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -カメラからのビデオストリーム</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
同じプロセスで、Tensorflowが接続されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは非常に悪い考えです。特にラズベリーでは-TFはメモリとリソースを消費し、サービスは回答によって速度が低下するだけでなく、TFがラズベリーのリソースを使い果たすと簡単に削減されます（これは間違いなく起こります）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、最初のバージョンでは、プロセス間交換を確立するのが面倒だったので、プロトタイプをそのようにしました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
エンドユーザーのために、次のことができるシンプルな</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Web</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アプリ</font><font style="vertical-align: inherit;">（同じフラスコサービスによって再度配布され</font><font style="vertical-align: inherit;">ます）を起動し</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">カメラからビデオを表示</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">運動の開始/終了</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スクワットカウンターを示しています</font></font></li>
</ul> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
練習モードでは、サービスは画像をファイルシステムに書き込みます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
良い方法では、それらを自動的に削除する必要がありますが、今のところ、ニューラルネットワークをトレーニングするためにそれらを取得できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
演習が始まるとすぐに、プログラムは動いているオブジェクトを検索して画像の処理を開始し、このオブジェクトのマスクを切り取り、このマスクを分類子に渡します。スタンス-スクワット-スタンスのシーケンスを満たすことができた場合、スクワットをカウントできます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/v1/lk/oi/v1lkoikny6xhnukk6mldz1ohqso.jpeg"><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">マークアップツール</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、python + opencv + GUIアプリケーションです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
絵、輪郭、図の枠を検索し、S（スタンド）、Q（スクワット）、N（なし）ボタンを押すことで、絵を分類することができ、そのマスクが自動的に目的のディレクトリに書き込まれます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、新しい分類済みマスクを含むカタログを</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワークの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データに転送し、</font><font style="vertical-align: inherit;">再トレーニング</font><font style="vertical-align: inherit;">する必要があります</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私はRaspberryで検出器を実行しましたが、python、opencv、およびカメラを備えたマシンでの実行を妨げるものは何もありません。raspberryを使用すると、ラップトップを持ち運ぶよりも簡単です。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">問題</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
現在の形式では、これはMVPによって認識されますが、安定したソリューションになるまで、まだ機能しています。</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">背景を削除するときの品質を向上させます。</font><font style="vertical-align: inherit;">影とまぶしさは不快なアーティファクトを残し、そこから分類器の屋根を引き裂きます</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分類器のデータをさらに収集する</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分類子を改善します。</font><font style="vertical-align: inherit;">既存のものは素早く簡単ですが、その結果の信頼性が問題です。</font><font style="vertical-align: inherit;">古代のLenet-5は非常に賢く、その背後にロジックがあるため、探索する価値があります。</font></font></li>
</ol><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参考文献</font></font></h2><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">数の分類における畳み込みネットワークに関するJan Lekunのオリジナルの記事</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ネットワークアーキテクチャの記事</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCVでの背景の削除</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Githubのレポ</font></font></a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja501352/index.html">カフカが反撃</a></li>
<li><a href="../ja501354/index.html">コードスタイルの新しい見方</a></li>
<li><a href="../ja501356/index.html">Java開発者向けのRust</a></li>
<li><a href="../ja501358/index.html">先週のフロントエンドの世界からの新鮮な食材のダイジェストNo. 414（2020年5月4日〜10日）</a></li>
<li><a href="../ja501360/index.html">テレグラム用MMORPG-最初の大きなプロジェクト-パート0</a></li>
<li><a href="../ja501366/index.html">システム設計入門（マイクロサービスを追加したパート1）</a></li>
<li><a href="../ja501368/index.html">5月11日から17日までのモスクワでのデジタルイベント</a></li>
<li><a href="../ja501370/index.html">Trello-小規模なITチームのための効果的な知識管理システム</a></li>
<li><a href="../ja501374/index.html">エミュレーションコモドール65</a></li>
<li><a href="../ja501376/index.html">アジャイルは建築の真の意味を教えてくれます</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🎓 🎣 💸 わかりました、それは私が存在することを意味します：コンピュータービジョンにおけるディープラーニングのレビュー（パート2） 🥄 🤟🏿 🍲</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="私たちは現代の魔法（コンピュータービジョン）を理解し続けています。パート2は、最初にパート1を読まなければならないという意味ではありません。パート2は、すべてが深刻になったことを意味します。ビジョンにおけるニューラルネットワークの全力を理解したいと考えています。検出、追跡、セグメンテーション、姿勢評...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>わかりました、それは私が存在することを意味します：コンピュータービジョンにおけるディープラーニングのレビュー（パート2）</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mipt/blog/458190/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私たちは現代の魔法（コンピュータービジョン）を理解し続けています。</font><font style="vertical-align: inherit;">パート2は、最初にパート1を読まなければならないという意味ではありません。パート2は、すべてが深刻になったことを意味します。ビジョンにおけるニューラルネットワークの全力を理解したいと考えています。</font><font style="vertical-align: inherit;">検出、追跡、セグメンテーション、姿勢評価、アクション認識...最もファッショナブルでクールなアーキテクチャ、何百ものレイヤー、そして何十もの素晴らしいアイデアがすでにあなたを待っています！</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yt/nk/uu/ytnkuundiudek47rjvlmlujrrm4.jpeg"><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最後のシリーズで</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私がであることを思い出してみましょう</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最初の部分</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、我々は、画像を分類し、その効果的な表現（埋め込み）を構成するタスクと同様に、畳み込みニューラルネットワークとその可視化と知り合いました。私たちは、顔認識と人々の再識別のタスクについてさえ話し合いました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
前回の記事でも、さまざまな種類のアーキテクチャ（</font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1か月に作ったの</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と同じタブレット</font><font style="vertical-align: inherit;">）について話しましたが、ここでGoogleは時間を無駄にしませんでした。さらに高速で正確な別の</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">EfficientNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アーキテクチャをリリースしました</font><font style="vertical-align: inherit;">。</font></font><abbr title="ニューラルアーキテクチャ検索"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NAS</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と特別な複合スケーリング手順</font><font style="vertical-align: inherit;">を使用して作成しました</font><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">記事を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">チェックして</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ください</font></a><font style="vertical-align: inherit;">。それだけの価値があります。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/9m/_h/5c/9m_h5cc1tsxs7bfkainm5zom-wg.jpeg" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その間、一部の研究者</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は顔</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">アニメーション化</font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">して映画</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">キス</font></a><font style="vertical-align: inherit;">を</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">探します</font></a><font style="vertical-align: inherit;">。私たちはより差し迫った問題に対処します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで人々は言う：「画像認識」。</font><font style="vertical-align: inherit;">しかし、「認識」とは何でしょうか？</font><font style="vertical-align: inherit;">「理解（シーン）」とは？</font><font style="vertical-align: inherit;">私の意見では、これらの質問に対する答えは、私たちが正確に何を「認識」したいか、そして何を正確に「理解」したいかに依存します。</font><font style="vertical-align: inherit;">人と同じくらい効率的（またはさらに優れている）ビジュアルストリームから世界に関する情報を抽出する人工知能を構築している場合、タスクから、ニーズから移動する必要があります。</font><font style="vertical-align: inherit;">歴史的に、現代の「認識」と「シーンの理解」は、いくつかの特定のタスクに分類できます：分類、検出、追跡、姿勢と顔のポイントの評価、セグメンテーション、ビデオでのアクションの認識、テキストでの画像の説明。</font><font style="vertical-align: inherit;">この記事では、リストの最初の2つのタスク（ups、3番目の部分のネタバレ）に焦点を当てるので、現在の計画は次のとおりです。</font></font><br>
<br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">可能であれば私を見つけてください：オブジェクト検出</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">顔検出：捕まらない-泥棒ではない</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">多くの文字：テキストの検出（および認識）</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ビデオと追跡：単一のストリーム</font></font></a></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ロックしましょう、スーパースター！</font></font><br>
<br>
<a name="1"></a><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">可能であれば私を見つけてください：オブジェクト検出</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/-q/9e/on/-q9eonan6thdv5jivk8kq0h7gm0.jpeg" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
だから、タスクは単純に聞こえます-写真が与えられ、その上で事前定義されたクラスのオブジェクトを見つける必要があります（人、本、リンゴ、アルテシアンノーマンバセットグリフォンなど）。</font><font style="vertical-align: inherit;">ニューラルネットワークを使用してこの問題を解決するには、テンソルと機械学習の観点から問題を提起します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
カラー画像はテンソル（H、W、3）であることを覚えています（覚えていない場合は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パート1です</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">以前は、画像全体を分類する方法しか知りませんでしたが、今の目標は、画像内の対象オブジェクト（ピクセル座標）の位置とそのクラスを予測することです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここでの重要なアイデアは、分類と回帰という2つの問題を一度に解決することです。</font><font style="vertical-align: inherit;">ニューラルネットワークを使用して座標を後退させ、内部のオブジェクトを分類します。</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分類？</font><font style="vertical-align: inherit;">回帰？</font></font></b>
                        <div class="spoiler_text">,       .   <b> </b>       <b> </b>,     .   <b></b>      <b> </b>,     (: , , ,  ,       ...).   —    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">3-  DLSchool ( )</a>.<br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、一般的に言えば、オブジェクトの座標はさまざまな方法で形式化できます。DLでは、3つの主な方法があります。</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font><font style="vertical-align: inherit;">オブジェクトの</font></font><abbr title="長方形の境界オブジェクト"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ボックス</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）、</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">姿勢の評価</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（オブジェクトのキーポイント）、</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セグメンテーション</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（オブジェクトの「マスク」）です。</font><font style="vertical-align: inherit;">ここで</font></font><abbr title="長方形の境界オブジェクト"><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、境界ボックス</font></font></b></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の正確な予測</font><font style="vertical-align: inherit;">、ポイント、セグメンテーションについてさらに説明します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ki/wt/xm/kiwtxmvvhmwsvqn3_5dovlmp8w8.jpeg" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
基本的に、検出データセットは、「各画像の各オブジェクトの左上隅と右下隅の座標」という形式のボックスでマークされます（この形式は</font></font><abbr title="「Tlbr」"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、左上、右下</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">とも呼ばれます</font><font style="vertical-align: inherit;">）。ほとんどのニューラルネットワークアプローチは、これらの座標を予測します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uo/zs/tj/uozstjspdifxpslvqyuurauxs2g.png" width="500"></div><br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出問題のデータセットとメトリックについて</font></font></b>
                        <div class="spoiler_text">     ,            .          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">13-   Deep Learning School</a> ( 2.0  ).<br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
検出用のニューラルネットワークの種類に飛び込む前に、画像内の何かを検出する問題を解決する方法を一緒に考えてみましょう。</font><font style="vertical-align: inherit;">おそらく、画像内で特定のオブジェクトを見つけたい場合は、そのオブジェクトがどのように見えるか、および画像内でどの領域を占めるべきかについておおよそわかっています（ただし、オブジェクトは変更される可能性があります）。</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ゼロからの検出の発明</font></font></b>
                        <div class="spoiler_text">        “ ”:   100100 ,     .     2020 .             ,   .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">template matching</a> (   -     ).<br>
<br>
  ,   -,    :             .   ,      — ,    .    ,     -,     (         ).<br>
<br>
     —      .         / ,      ,   10-20   1000.   Brute Force :       . ,   100200 ,     22, 23, 32, 24, 42, 33…, 34, 43… ,   ,      100*200,       ,  (100-W_window) * (200 — H_window)  ,    . ,   ,    .<br>
<br>
, ,        ,       ,    ,     —           .<br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さらに、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2019年1月から、検出領域の新しいレビューに</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">依存する場合があり</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">（写真もそこから取得されます）。検出でDLを可能な限り幅広く見たい場合は、これは必読です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
CNNを使用した検出とローカリゼーションに関する最初の記事の1つは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Overfeatでした</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。著者らは、最初にニューラルネットワークをImageNetでの検出に使用し、問題を再定式化し、損失を変更したと主張しています。ちなみに、このアプローチは実際にはエンドツーエンドでした（以下はOverfeatスキームです）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/8o/5v/tv/8o5vtvhgukkn7frba0nx8yltfis.png" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に重要なアーキテクチャは、</font><font style="vertical-align: inherit;">2014年に</font></font><abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FAIRの</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">研究者が発明した</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">地域ベースの畳み込みニューラルネットワーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RCNN</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）でした。その本質は、最初にいわゆる「関心領域」（RoI）の多くを予測し、その中にオブジェクトが存在する可能性がある（選択検索アルゴリズムを使用）、それらを分類し、CNNを使用してボックスの座標を調整することです。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/2r/2p/kp/2r2pkpcoysglv4z_v-ll_y14mqw.png" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
確かに、このようなパイプラインは、システム全体を遅くしました。なぜなら、私たちはニューラルネットワークを介してすべての領域を実行したからです（数千回のフォワードパスを実行したため）。 1年後、同じFAIR Ross GirshickがRCNNを</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fast-RCNNに</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アップグレードしました</font><font style="vertical-align: inherit;">。ここでのアイデアは、選択検索とネットワーク予測を交換することでした。まず、画像全体を事前トレーニング済みのニューラルネットワークに渡し、次に、バックボーンネットワークによって発行された機能マップ上で関心領域を予測します（たとえば、同じ選択検索を使用しますが、そこに</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">他のアルゴリズムがあります</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。それはまだかなり遅く、リアルタイムよりもはるかに低速でした（現時点では、リアルタイムは画像あたり40ミリ秒未満であると想定しています）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/uc/d-/tnucd-y6i7tr4edgjeudtrsj16u.png" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
速度はCNNではなく、ボックス生成アルゴリズム自体の影響を最も</font><font style="vertical-align: inherit;">受けたため、オブジェクトの関心領域を予測するようにトレーニングされる</font><font style="vertical-align: inherit;">、2番目のニューラルネットワークであるRegion Proposal Network（</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RPN</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">に置き換えることにしました</font><font style="vertical-align: inherit;">。これが</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster-RCNNが登場した</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">方法です</font><font style="vertical-align: inherit;">（そう、彼らは長い間名前を考えていなかったのは明らかです）。スキーム：</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/h_/ye/6vh_yee2zrsflyhh8jdvtm_bbgy.png" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R-FCNの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">形式に別の改善があり</font><font style="vertical-align: inherit;">ました。詳細については触れませんが、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mask-RCNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">について触れて</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">おき</font></a><font style="vertical-align: inherit;">ます。 Mask-RCNNはユニークなもので、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出とインスタンスセグメンテーションの問題を同時に</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">解決する最初のニューラルネットワークです</font><font style="vertical-align: inherit;">。境界ボックス内のオブジェクトの正確なマスク（シルエット）を予測します。彼女のアイデアは実際には非常に単純です。検出用とセグメンテーション用の2つのブランチがあり、両方のタスクのネットワークを一度にトレーニングする必要があります。主なことは、データにタグを付けることです。 Mask-RCNN自体はFaster-RCNNと非常によく似ています。バックボーンは同じですが</font><font style="vertical-align: inherit;">、</font><b><font style="vertical-align: inherit;">最後</font></b><font style="vertical-align: inherit;">に2つの異なるタスクのために2 </font><font style="vertical-align: inherit;">つの</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「ヘッド」があります</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font><font style="vertical-align: inherit;">ニューラルネットワークの</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最後のレイヤーは</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と呼ばれることが多い</font><font style="vertical-align: inherit;">ため）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/7w/ig/hq/7wighq6ox7tptik5f_7d7cez2hg.png" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらは、いわゆる</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2段階</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（または</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">地域ベース</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）のアプローチでした。それらと並行して、DL検出のアナログが開発されました- </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ワンステージ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アプローチ。これらには、シングルショット検出器（SSD）、You Only Look One（YOLO）、Deeply Supervised Object Detector（DSOD）、Receptive Field Block Network（RFBNet）などのニューラルネットワークが含まれます（以下のマップを参照）</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このリポジトリ</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ue/lc/-y/uelc-yeav4_avjdkycglf9uwrmm.png" width="750"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2ステージとは異なり、1ステージのアプローチは、ボックスを生成するために個別のアルゴリズムを使用せず、畳み込みニューラルネットワークによって生成された各特徴マップのいくつかのボックス座標を単に予測します。</font><font style="vertical-align: inherit;">YOLOも同様に機能し、SSDは少し異なりますが、1つの考えだけがあります。1x1のたたみ込みは、受信した特徴マップから多くの数を詳細に予測しますが、それが何を意味するかは事前に合意しています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/ml/w_/qjmlw_ympdcib6jkpfdjdvcirdy.png" width="600"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jr/i3/oy/jri3oymb48sv5vq9dwwdxbndszg.png" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
たとえば、機能マップから13x13x256のサイズは機能マップ13x13x（4 *（5 + 80））の数値であると予測します。ここでは、4つのボックスで85の数値を予測します。シーケンスの最初の4つの数値は常にボックスの座標であり、5番目-ボクシングへの信頼、および80個の数値-各クラスの確率（分類）。</font><font style="vertical-align: inherit;">これは、必要な数を必要な損失に提出し、ニューラルネットワークを適切にトレーニングするために必要です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ao/xi/o2/aoxio2rty3hgpu2f8mduomvs9nu.png" width="800"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
検出器の品質は、特徴を抽出するニューラルネットワーク（つまり、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">バックボーンニューラルネットワーク</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">の品質に直接依存するという事実に注意を向けたいと思い</font><b><font style="vertical-align: inherit;">ます</font></b><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">通常、この役割は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">前の記事で説明</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">したアーキテクチャ</font><font style="vertical-align: inherit;">（ResNet、SENetなど）の</font><font style="vertical-align: inherit;">1つが果たしますが、</font><font style="vertical-align: inherit;">作者が独自のより最適なアーキテクチャ（たとえば、YOLOv3のDarknet-53）または変更（たとえば、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">機能ピラミッドプーリング</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）を思い付く場合もあります</font><font style="vertical-align: inherit;">（FPN））。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここでも、分類と回帰の両方を同時に行うようにネットワークをトレーニングしていることに注意します。</font><font style="vertical-align: inherit;">コミュニティでは、これはマルチタスク損失と呼ばれます。いくつかのタスク（いくつかの係数を含む）の損失の合計が1つの損失に表示されます。</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">主要なマルチタスク損失を伴うニュース</font></font></b>
                        <div class="spoiler_text"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Machines Can See 2019</a>     multi-task loss  7-  <s>, </s>. ,             “”,     ,       -. :   multi-task loss, ,    multi-task’     (,           ,          ).       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  Squeeze-and-Excitation    </a>.<br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最近、2019年の記事が登場しました。著者は、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ポイントベースのボックス予測</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を使用した検出タスクで、速度/精度比がさらに優れていると宣言してい</font><b><font style="vertical-align: inherit;">ます</font></b><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「Objects as Points」</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「CornerNet-Lite」</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の記事について話している</font><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ExtremeNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">CornerNet</font></a><font style="vertical-align: inherit;">の修正版です。ニューラルネットワークを使用した検出ではSOTAと呼ばれるようになりました（ただし、これは正確ではありません）。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UPD（2020年4月25日）：</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">現時点では、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">YOLOv4</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は検出器の中で際立って</font><font style="vertical-align: inherit;">おり、著者は他のほとんどすべてのニューラルネットワーク検出器の中で最高の速度-品質比を示しています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wk/qf/mr/wkqfmrenwm3u5f6c6bzinjcffga.png" width="900"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
突然、検出器の説明がまだ混沌としていて理解できないように思えた場合は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、ビデオで</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">これについてゆっくりと説明します。</font><font style="vertical-align: inherit;">おそらく最初にそれを見る必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以下に、コードへのリンクを含む検出中のニューラルネットワークの表と、各ネットワークのチップの簡単な説明を示します。</font><font style="vertical-align: inherit;">今日のオブジェクト検出について良いアイデアを得るために、知っておくべき本当に重要なネットワーク（少なくともそれらのアイデア）だけを収集しようとしました：</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワーク検出器（2段階）</font></font></b>
                        <div class="spoiler_text"><div class="scrollable-table"><table>
<tbody><tr>
<th></th>
<th></th>
<th> </th>
<th></th>
</tr>
<tr>
<td>2013-2014</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">RCNN</a></td>
<td>        </td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Caffe</a></td>
</tr>
<tr>
<td>2015</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Fast-RCNN</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">    ,     </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Caffe</a></td>
</tr>
<tr>
<td>2016</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Faster-RCNN</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> RPN    </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2016</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">R-FCN</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">fully-convolutional     </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Caffe</a></td>
</tr>
<tr>
<td>2017</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Mask-RCNN</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> «»     , RoI-Align</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Keras, TF</a></td>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Reasoning-RCNN</a></td>
<td>  RCNN       </td>
<td>---</td>
</tr>
</tbody></table></div><br>
</div>
                    </div><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワーク検出器（1段階）</font></font></b>
                        <div class="spoiler_text"><div class="scrollable-table"><table>
<tbody><tr>
<th></th>
<th></th>
<th> </th>
<th></th>
</tr>
<tr>
<td>2013-2014</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Overfeat</a></td>
<td>    </td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">C++ (    )</a></td>
</tr>
<tr>
<td>2015</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">SSD</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  one-stage ,     </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2015</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">YOLO</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  SSD ,       (  )</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">C++</a></td>
</tr>
<tr>
<td>2016</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">YOLOv2 (aka YOLO9000)</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   YOLO</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2017</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">YOLOv3</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   YOLOv2</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2017-2018</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">DSOD</a></td>
<td> Deep Supervision    DenseNet</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Caffe</a></td>
</tr>
<tr>
<td>2017-2018</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">RFBNet</a></td>
<td>          (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">RF</a>-)</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2020</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">YOLOv4</a></td>
<td> <i></i>     YOLOv3 (. )</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">++</a></td>
</tr>
</tbody></table></div><br>
</div>
                    </div><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワーク検出器（その他）</font></font></b>
                        <div class="spoiler_text"><div class="scrollable-table"><table>
<tbody><tr>
<th></th>
<th></th>
<th> </th>
<th></th>
</tr>
<tr>
<td>2018</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">RetinaNet</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> focal loss     </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Keras</a></td>
</tr>
<tr>
<td>2014-2015</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">SPP</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">,       </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Keras</a></td>
</tr>
<tr>
<td>2016-2017</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">FPN</a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">       </a></td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">TensorFlow</a></td>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">NAS-FPN</a></td>
<td>  FPN   Neural Architecture Search</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">TensorFlow</a></td>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Daedalus</a></td>
<td>   Adversarial-</td>
<td>---</td>
</tr>
</tbody></table></div><br>
</div>
                    </div><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワーク検出器（ポイントベース）</font></font></b>
                        <div class="spoiler_text"><div class="scrollable-table"><table>
<tbody><tr>
<th></th>
<th></th>
<th> </th>
<th></th>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">CenterNet</a></td>
<td>   ,        ,   3D- </td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">CornerNet</a></td>
<td>      </td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">CornerNet-Lite</a></td>
<td> CornerNet</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
<tr>
<td>2019</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">ExtremeNet</a></td>
<td> «»   (  )</td>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">PyTorch</a></td>
</tr>
</tbody></table></div><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各アーキテクチャの速度/品質がどのように相関しているかを理解するには、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このレビュー</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">または</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">より一般的なバージョンをご覧ください</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アーキテクチャは問題ありませんが、検出は主に実用的なタスクです。</font><font style="vertical-align: inherit;">「100のネットワークはありませんが、少なくとも1つは機能しています」-これは私のメッセージです。</font><font style="vertical-align: inherit;">上記の表にはコードへのリンクがありますが、個人的には、リポジトリから直接検出器を起動することはめったにありません（少なくとも本番環境へのさらなる展開を目的としています）。</font><font style="vertical-align: inherit;">ほとんどの場合、このためにライブラリが使用されます。たとえば、TensorFlow Object Detection API（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私のレッスンの実際の部分を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照</font><font style="vertical-align: inherit;">）または</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CUHKの研究者からのライブラリ</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">私はあなたの注意を別のスーパーテーブルに持ってきます（あなたはそれらが好きですよね？）：</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出モデルを実行するためのライブラリ</font></font></b>
                        <div class="spoiler_text"><div class="scrollable-table"><table>
<tbody><tr>
<th></th>
<th></th>
<th></th>
<th> </th>
<th></th>
</tr>
<tr>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Detectron</a></td>
<td>Facebook AI Research</td>
<td>  Facebook         </td>
<td> Region-based</td>
<td>Caffe2</td>
</tr>
<tr>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">TF Object Detection API</a></td>
<td>TensorFlow team</td>
<td>  ,    ( )</td>
<td> Region-based  SSD (  backbone')</td>
<td>TensorFlow</td>
</tr>
<tr>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Darkflow</a></td>
<td>thtrieu</td>
<td> YOLO  YOLOv2,   </td>
<td>  YOLO ( ),  YOLOv3</td>
<td>TensorFlow</td>
</tr>
<tr>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">mmdetection</a></td>
<td>Open MMLab (CUHK)</td>
<td>    PyTorch, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">.  </a></td>
<td>  ,  YOLO-</td>
<td>PyTorch</td>
</tr>
<tr>
<td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Darknet (modified)</a></td>
<td>AlexAB</td>
<td>  YOLOv3    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a></td>
<td>YOLOv3</td>
<td>C++</td>
</tr>
</tbody></table></div><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多くの場合、1つのクラスのオブジェクトを検出する必要がありますが、特定の非常に可変性の高いオブジェクトです。</font><font style="vertical-align: inherit;">たとえば、写真内のすべての顔を検出する（詳細な確認/人の数を数えるため）、人全体を検出する（再識別/数を数える/追跡するため）、またはシーン上のテキストを検出する（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OCR</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> /写真の単語の翻訳の</font><font style="vertical-align: inherit;">ため</font><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">一般に、ここでの「通常の」検出のアプローチはある程度機能しますが、これらのサブタスクにはそれぞれ、品質を向上させるための独自のトリックがあります。</font></font><br>
<br>
<a name="2"></a><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">顔検出：捕まらない-泥棒ではない</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ic/ul/rp/iculrpbc7niyrdxg1yk_8r82nsw.jpeg" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
顔が画像のかなり小さな部分を占めることが多いため、ここにはある程度の特異性が現れます。さらに、人々は常にカメラを見るわけではなく、顔が横からしか見えないことがよくあります。顔認識への最初のアプローチの1つは、2001年に発明された、Haarカスケードに基づく有名なViola-Jones検出器でした。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/hc/tf/zn/hctfzn0xudbedi_aymhmlcwkamu.png" width="400"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワーク</font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">当時</font><s><font style="vertical-align: inherit;">は流行していませ</font></s><font style="vertical-align: inherit;">んでしたが、ビジョン</font><s><font style="vertical-align: inherit;">は</font></s><font style="vertical-align: inherit;">まだそれほど強力で</font><s><font style="vertical-align: inherit;">はあり</font></s><font style="vertical-align: inherit;">ませんでしたが、古き良き手作りのアプローチが機能しました。いくつかのタイプの特別なフィルターマスクが積極的に使用され、画像とその標識から顔の領域を抽出するのに役立ち、これらの標識はAdaBoost分類器に送信されました。ちなみに、この方法は本当にうまく機能しますが、今では十分に高速で、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCVを使用し</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">てすぐに開始できます</font><font style="vertical-align: inherit;">。この検出器の欠点は、カメラの正面に配置された顔しか見えないことです。少し向きを変えるだけで、検出の安定性が損なわれます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このようなより複雑なケースでは、</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">dlib</font></a><font style="vertical-align: inherit;">を使用できます</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。これはC ++-顔検出を含む多くのビジョンアルゴリズムが実装されているライブラリです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
顔検出におけるニューラルネットワークアプローチの中で、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">マルチタスクカスケードCNN（MTCNN）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MatLab</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TensorFlow</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">は特に重要</font><font style="vertical-align: inherit;">です。一般的に、（同じ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">facenetで</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">現在アクティブに使用されてい</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/80/wn/vu/80wnvuf59poodmodzswcgjlyjt4.jpeg" width="400"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MTCNNのアイデアは、3つのニューラルネットワークを順番に（したがって、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「カスケード」</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）使用</font><font style="vertical-align: inherit;">して、顔とその特異点の位置を予測すること</font><font style="vertical-align: inherit;">です。この場合、顔にはちょうど5つの特別なポイントがあります。左目、右目、唇の左端、唇の右端と鼻です。カスケードからの最初のニューラルネットワーク（</font></font><abbr title="提案ネット"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P-Net</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）は、顔の潜在的な領域を生成するために使用されます。 2番目（</font></font><abbr title="ネットをリファイン"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R-Net</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）-受信したボックスの座標を改善します。 3番目（</font></font><abbr title="フェイシャルランドマークネット"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O-Net</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）のニューラルネットワークは、ボックスの座標を再び後退させ、さらに顔の5つのキーポイントを予測します。このネットワークはマルチタスクです。ボックスポイントの回帰、各ボックスの顔/顔以外の分類、および顔ポイントの回帰の3つのタスクが解決されているためです。さらに、MTCNNはすべてをリアルタイムで実行します。つまり、画像あたりの所要時間は40ミリ秒未満です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/5e/iz/d5/5eizd5lwag9umfo1ccypep42eik.jpeg" width="800"></div><br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">どのようにして、ArXivで自分の記事をまだ読んでいないのですか？</font></font></b>
                        <div class="spoiler_text">      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   MTCNN</a>,        .     <b>5 </b>,          . ,   :)<br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
現代の最先端技術の中で、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">デュアルショット顔検出器（DSFD）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceBox</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が注目に</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">値し</font></a><font style="vertical-align: inherit;">ます</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">FaceBoxesはCPU（！）ですばやく起動することができ、DSFDは最高の品質を持っています（2019年4月にリリースされました）。</font><font style="vertical-align: inherit;">DSFDはMTCNNよりも複雑です。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">拡張された畳み込みを使用して</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">機能を改善するための特別なモジュールであるため</font><font style="vertical-align: inherit;">、処理の2つのブランチと特別なタイプの損失</font><font style="vertical-align: inherit;">がネットワーク内で使用されます</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">ちなみに、拡張されたたたみ込みでは、次のパートのセグメンテーションに関する記事で2回以上遭遇します。</font><font style="vertical-align: inherit;">以下はDSFDの例です（印象的ですね）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xv/or/it/xvoritceua0_ocjteyvm4xvisbq.jpeg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">顔</font><font style="vertical-align: inherit;">
を</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">認識する</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">方法を学ぶに</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、連載の前回の記事を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">忘れずに</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">読んでください</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br>
<a name="3"></a><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">多くの文字：テキストの検出（および認識）</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qn/v9/wo/qnv9woeqru3dioeennrkvalkjqg.png" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上の写真に注意してください。</font><font style="vertical-align: inherit;">座標軸に平行なバウンディングボックスを予測すると（以前のように）、品質が非常に悪いことがわかります。</font><font style="vertical-align: inherit;">たとえば、これらのボックスを認識ニューラルネットワークの入力に送信</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">して、画像からテキストを予測する</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">場合、これは非常に重要であることがよく</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">あります</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このような場合は、回転した境界ボックスを予測するか、テキストが湾曲している場合は長方形ではなくポリゴンにテキストを制限するのが通例です（以下の例）。</font><font style="vertical-align: inherit;">回転したボックスの予測は、たとえば</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">EAST検出器</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">によって処理され</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/j3/hd/bj/j3hdbj-xozs4voec8ekiz4k1eo0.png" width="500"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
EAST検出器の考え方は、ボックスのコーナーの座標ではなく、次の3つを予測することです。</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキストスコアマップ（各ピクセルでテキストを見つける確率）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">各ボックスの回転角度</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">各ピクセルの長方形の境界線までの距離</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、検出ではなく、セグメンテーション（テキストマスクの強調表示）のタスクに似ています。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv記事の</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">説明画像</font><font style="vertical-align: inherit;">：</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dj/vt/uu/djvtuu36dzinoratlumncsgb5t8.png" width="700"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキスト認識（そしてその検出）のタスクは非常に人気があり、したがって類似物があります：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TextBoxes ++</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caffe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SegLinks</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ですが、私の意見では、EASTが最もシンプルで手頃な価格です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキストを検出したら、すぐに別のニューラルネットワークに送り、それを</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">認識し</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">て文字列を生成します。</font><font style="vertical-align: inherit;">ここで、画像からテキストへのモダリティの興味深い変化に気づくことができます。</font><font style="vertical-align: inherit;">すべてがネットワークアーキテクチャの内容、最終層で正確に予測される内容、および使用される損失の種類にのみ依存するため、これを恐れる必要はありません。</font><font style="vertical-align: inherit;">たとえば、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MORAN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">PyTorch </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コード</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）および</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ASTER</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TensorFlowコード</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）タスクに完全に対処します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/vt/ot/nc/vtotncz1d1zhhsiytuzmarta9ta.png" width="700"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それらには超自然的なものはありませんが、2つの根本的に異なるタイプのニューラルネットワーク（CNNとRNN）がすぐに使用できます。 1つは画像から特徴を抽出するためのもので、もう1つはテキストを生成するためのものです。 MORANの例の詳細：以下は、その認識ネットワークのアーキテクチャです。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/hu/qx/_2/huqx_2jakjcggsgacvhj9a8vce4.png" width="300"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、EASTから回転されたボックスにもかかわらず、認識ネットワークは入力に長方形の画像を受け取ります。つまり、その内部のテキストがすべてのスペースから遠く離れている可能性があります。認識エンジンが画像上のテキストを直接予測しやすくするために、特定の方法で変換できます。</font><font style="vertical-align: inherit;">入力画像に</font><b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">アフィン変換</font></a></b><font style="vertical-align: inherit;">を</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
適用して</font><font style="vertical-align: inherit;">、テキストをストレッチ/回転させることができます。これは、</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">Spatial Transformet Network（STN）</font></a><font style="vertical-align: inherit;">を使用して実現できます。これは、この</font><font style="vertical-align: inherit;">ような変換を個別に学習し、他のニューラルネットワークに簡単に統合できるためです（ちなみに、この調整は、テキストだけでなく、あらゆる画像に対して行うことができます）。以下は、STNの前/後の例です。</font></font><b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a></b><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/6y/z1/p9/6yz1p942ensgepwirqrtzpcnb7q.jpeg" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここでSTNについて詳しく説明しても意味がありません</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。Habréに関する</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">素晴らしい</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">記事</font></a><font style="vertical-align: inherit;">（写真は作者のおかげでそこから撮影されたものです）と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyTorchコード</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、MORAN（テキスト認識用の同じニューラルネットワーク）はさらに賢くなります。アフィン変換のファミリーに限定されませんが、入力画像の各ピクセルの</font><font style="vertical-align: inherit;">xとyの</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">変位マップ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">予測し</font><b><font style="vertical-align: inherit;">、</font></b><font style="vertical-align: inherit;">認識のためのネットワークの学習を改善する変換を実現します。このメソッドが呼び出され</font></font><i><abbr title="訂正、訂正"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、整流</font></font></abbr></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">補助ニューラルネットワーク（使用して画像補正であり、</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">整流器</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。以下は、アフィニティ変換後と修正後の画像の比較です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/n4/az/du/n4azduih5p7wd9sx-tqhpgy-p20.png" width="300"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、「モジュール化」（検出ネットワーク-&gt;認識ネットワーク）するテキスト認識へのアプローチに加えて、エンドツーエンドのアーキテクチャがあります。入力は画像であり、出力は検出であり、テキストはその内部で認識されます。そして、これらすべてが、両方のタスクを一度に学習する単一のパイプラインです。この方向では、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">統一されたネットワーク（</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FOTS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyTorchコード</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）を使用し</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">てテキストを高速指向することでテキストを</font></a><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><b><font style="vertical-align: inherit;">見つける</font></b></a><font style="vertical-align: inherit;">という印象的な作業が</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">あり</font></a><font style="vertical-align: inherit;">、エンドツーエンドのアプローチは「検出+認識」より2倍高速であることに注意してください。以下はFOTSニューラルネットワークの図です。RoiRotateブロックが特別な役割を果たすため、ニューラルネットワークで認識のためにネットワークから「勾配をキャスト」して検出できます（これは見た目よりも複雑です）。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/a5/xh/ch/a5xhchryrwf-zpfudielmab9pqu.png" width="800"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ちなみに、毎年</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ICDAR</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">カンファレンスが</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">開催さ</font></a><font style="vertical-align: inherit;">れ、さまざまな画像のテキスト認識</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コンテスト</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">数回</font></a><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">行われ</font></a><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出における現在の問題</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私の意見では、検出の主な問題は検出器モデルの品質ではなく、データです。検出する必要のあるクラスが多い場合は特に、マークアップに時間がかかり、コストも高くなります（ただし</font><font style="vertical-align: inherit;">、500クラスの</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ソリューションの例がある</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ため）。</font><font style="vertical-align: inherit;">そのため、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">多くの作品は</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、最も総合的なデータを「総合的に」生成し、「無料」でマークアップを取得することに専念しています。</font><font style="vertical-align: inherit;">以下は、</font><font style="vertical-align: inherit;">合成データの生成を具体的に扱っている</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">、Nvidiaの記事の</font></a></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私の卒業証書の</font></font></s> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;">写真</font><font style="vertical-align: inherit;">です。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/6k/mn/wh/6kmnwhvc1pgahzwtjloa4dy9sbm.png" width="800"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、それでも今、絵のどこにあるかを確実に言うことができるのは素晴らしいことです。たとえば、フレーム上の何かの量を計算したい場合は、これを検出してボックスの数を指定するだけで十分です。人の検出では、通常のYOLOもうまく機能します。主なことは、大量のデータを送信することです。同じ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Darkflowが</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">適しており、「ヒューマン」クラスはほとんどすべての主要な検出データセットに含まれています。たとえば、カメラを使用して、たとえば1日で通り過ぎた人の数、または人が店に持っていった商品の数を数えたい場合は、数量を検出して出力します...</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/m2/ts/pl/m2tsplbgrnmoauvlghy8ivq2jdm.jpeg" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
やめる。</font><font style="vertical-align: inherit;">しかし、カメラからの各画像で人物を検出する場合は、1つのフレームと2つのフレームで人物の数を計算できます。正確には、どの人物がどこにいるかを特定できないためです。</font><font style="vertical-align: inherit;">ビデオストリーム内の正確にユニークな人々をカウントできるアルゴリズムが必要です。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">再識別</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アルゴリズムかもしれませんが、</font><font style="vertical-align: inherit;">ビデオと検出に関しては、追跡アルゴリズムを使用しないのは罪です。</font></font><br>
<br>
<a name="4"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ビデオと追跡：単一のストリーム</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここまでは、写真のタスクについてのみ説明しましたが、最も興味深いのはビデオです。</font><font style="vertical-align: inherit;">同じアクションの認識を解決するには、いわゆる</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">空間</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コンポーネントだけでなく、</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">時間</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コンポーネントも</font><font style="vertical-align: inherit;">使用する必要</font><font style="vertical-align: inherit;">があり</font><font style="vertical-align: inherit;">ます。ビデオは時間内の一連のイメージであるためです。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qm/da/pa/qmdapao0kcytnxhorj7htm6susy.jpeg" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トラッキングは画像検出のアナログですが、ビデオ用です。</font><font style="vertical-align: inherit;">つまり、画像内のボクシングではなく、時間内のトラックレット（本質的には一連のボックス）を予測するようにネットワークを教えたいと考えています。</font><font style="vertical-align: inherit;">以下は、「尾」を示す画像の例です-ビデオ内のこれらの人々の軌跡。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xz/yv/c_/xzyvc_oumhrnf_-bmf8gz5l_hli.png" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
追跡の問題を解決する方法について考えてみましょう。ビデオとそのフレーム＃1と＃2があるとします。これまでのところ、1つのオブジェクトのみを考えてみましょう。1つのボールを追跡します。フレーム＃1では、検出器を使用して検出できます。 2つ目の方法でもボールを検出できます。それが単独で存在する場合は、すべて問題ありません。前のフレームのボクシングは、フレーム2と同じボールのボクシングであると言います。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pyimagesearch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ビジョン</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">コースの</font></a><font style="vertical-align: inherit;"> gifの下にある残りのフレームに進むこともでき</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/_w/et/ak/_wetakdpybemefhert6cxslqaju.gif" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ちなみに、時間を節約するために、2番目のフレームでニューラルネットワークを開始することはできません。最初のフレームからボールのボックスを「切り取り」、2番目のフレームでまったく同じ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">相関</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">またはピクセルごと</font><font style="vertical-align: inherit;">を探します</font><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">相関トラッカー</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">はこのアプローチを利用し</font><font style="vertical-align: inherit;">ます。「空の部屋でカメラの前で1つのボールを追跡する」などの単純なケースを処理する場合、それらは単純で信頼性が高いと見なされます。このタスクは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ビジュアルオブジェクトトラッキング</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">とも呼ばれ</font><font style="vertical-align: inherit;">ます。以下は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1人の例で相関トラッカー</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">がどのように機能するか</font></a><font style="vertical-align: inherit;">の例です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/cv/fp/qd/cvfpqdd5ghelxfpucxrejxq6vpm.gif" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、複数の検出/人がいる場合は、フレーム＃1とフレーム＃2のボックスを一致させる必要があります。最初に頭に浮かぶのは、ボックスと最大の交差領域（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IoU</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）を</font><font style="vertical-align: inherit;">持つボックスを一致させる</font><font style="vertical-align: inherit;">ことです。確かに、複数の検出が重なっている場合、そのようなトラッカーは不安定になるため、さらに多くの情報を使用する必要があります。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qx/i2/t1/qxi2t1ejpnir0h52ip-23zpf4ti.png" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
IoUアプローチは</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出の</font><i><font style="vertical-align: inherit;">「幾何学的な」兆候</font></i><font style="vertical-align: inherit;">のみに依存します。つまり</font><font style="vertical-align: inherit;">、フレーム上で近接しているものと単に一致させようとします。しかし、結局のところ、私たちには自由に画像全体（この場合は2つでも）があり、これらの検出の中に</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「視覚的な」標識</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">があるという事実を利用できます</font><font style="vertical-align: inherit;">。これに加えて、私たちは各人の検出の履歴を持っています。これにより、移動の速度と方向に基づいて次の位置をより正確に予測できます。これは、条件付きで</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「物理的」標識</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と呼ばれ</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mc/ay/se/mcaysee7xq25-j6hnvjalhfy5z0.gif" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
完全な信頼性があり、困難な状況に対処できる最初のリアルタイムトラッカーの1つが2016 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Simple Online and Realtime Traker（SORT）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pythonコード</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）で</font><font style="vertical-align: inherit;">公開されました</font><font style="vertical-align: inherit;">。 SORTは視覚標識とニューラルネットワークを使用せず、各フレームの各ボックスのいくつかのパラメーター、つまり現在の速度（xとyは別々）とサイズ（高さと幅）のみを推定しました。ボックスのアスペクト比は常に、そのボックスの最初の検出から取得されます。さらに、速度は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">カルマンフィルター</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を使用して予測され</font><font style="vertical-align: inherit;">（信号処理の世界では一般的に良好で軽量です）、IoUによるボックスの交差の行列が作成され、検出は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ハンガリーアルゴリズム</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">によって割り当てられ</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
数学がもう少し多くなっているように思われる場合は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">この記事では</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">すべてがわかりやすい方法で説明さ</font><font style="vertical-align: inherit;">れ</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">てい</font></a><font style="vertical-align: inherit;">ます（これは中程度です）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すでに2017年に、SORTの変更が</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeepSORT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">TensorFlow </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コード</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">としてリリースされ</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ました</font></a><font style="vertical-align: inherit;">。 DeepSORTは、ニューラルネットワークを使用して視覚的兆候を抽出し、衝突を解決するためにそれらを使用しています。追跡の品質が向上しました-今日で最も優れたオンライントラッカーの1つと見なされているのは、当然です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/15/it/ny/15itnyht32oes3n-keaqk36jnpq.gif" width="800"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
追跡の分野は確かに活発に発展しています。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">シャムニューラルネットワーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を備えた</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トラッカーとRNNを備えたトラッカーがあり</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">いつでも、より正確で高速なアーキテクチャが登場する可能性があるため（またはすでに登場しているため）、常に最新の情報を入手する必要があります。</font><font style="vertical-align: inherit;">ちなみに、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PapersWithCode</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で</font><font style="vertical-align: inherit;">そのようなことをフォローするのは非常に便利</font><font style="vertical-align: inherit;">です。記事とそのコード（もしあれば）へのリンクが常にあります。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あとがき</font></font></h3><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jb/yh/bf/jbyhbf2ovu_ynurp_t_d9_hi4vg.jpeg" width="600"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちは本当に多くのことを経験し、多くを学びました。</font><font style="vertical-align: inherit;">しかし、コンピュータービジョンは非常に広大な領域であり、私は非常に頑固な人です。</font><font style="vertical-align: inherit;">そのため、このシリーズの3番目の記事（最後になりますか？誰が知っているのか...）でお会いします。セグメンテーション、姿勢の評価、ビデオでのアクションの認識、ニューラルネットワークを使用した画像からの説明の生成について詳しく説明します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PSこの記事と前の記事の準備で貴重なアドバイスとコメントをしてくれたVadim Gorbachevに特に感謝します。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja458180/index.html">KeaベースのフェイルオーバーDHCPサーバー</a></li>
<li><a href="../ja458182/index.html">私たちはRSSを通してVKontakteを読みます</a></li>
<li><a href="../ja458184/index.html">HaxeとPHP：静的型付け、矢印関数、メタプログラミングなど</a></li>
<li><a href="../ja458186/index.html">PostgreSQLのWAL：1.バッファキャッシュ</a></li>
<li><a href="../ja458188/index.html">2019年にソーシャルネットワークを利用した方法</a></li>
<li><a href="../ja458204/index.html">Linuxのストレージパフォーマンスを評価する方法：オープンツールを使用したベンチマーク</a></li>
<li><a href="../ja458206/index.html">サイトレイアウトの崇高なテキスト3。外観をカスタマイズしてプラグインをインストールします。初心者向けガイド</a></li>
<li><a href="../ja458208/index.html">7月1日から7月7日までのモスクワでのデジタルイベント</a></li>
<li><a href="../ja458214/index.html">Pentest-laboratory「Pentestit Test lab 12」-全文</a></li>
<li><a href="../ja458218/index.html">顎顔面外科かどうか？それが問題です</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
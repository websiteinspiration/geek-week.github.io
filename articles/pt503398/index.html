<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö≤ üêÇ üì¥ Como fazer modelagem tem√°tica de um f√≥rum rapidamente ou o que incomoda as pessoas com doen√ßa cel√≠aca üèÇüèª üì∑ üö∂üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, mostrarei e mostrarei um exemplo de como uma pessoa com experi√™ncia m√≠nima em Ci√™ncia de Dados foi capaz de coletar dados do f√≥rum e faz...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Como fazer modelagem tem√°tica de um f√≥rum rapidamente ou o que incomoda as pessoas com doen√ßa cel√≠aca</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/503398/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neste artigo, mostrarei e mostrarei um exemplo de como uma pessoa com experi√™ncia m√≠nima em Ci√™ncia de Dados foi capaz de coletar dados do f√≥rum e fazer modelagem tem√°tica de postagens usando o modelo LDA, al√©m de revelar t√≥picos dolorosos para pessoas com intoler√¢ncia cel√≠aca. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No ano passado, eu precisava melhorar urgentemente meu conhecimento no campo de aprendizado de m√°quina. Sou gerente de produto de Ci√™ncia de Dados, Machine Learning e IA, ou de outra maneira Gerente T√©cnico de Produto AI / ML. As habilidades de neg√≥cios e a capacidade de desenvolver produtos, como geralmente ocorre em projetos voltados para usu√°rios que n√£o est√£o no campo t√©cnico, n√£o s√£o suficientes. Voc√™ precisa entender os conceitos t√©cnicos b√°sicos da ind√∫stria de ML e, se necess√°rio, poder escrever um exemplo para demonstrar o produto.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
H√° cerca de 5 anos desenvolvo projetos Front-end, desenvolvendo aplicativos Web complexos em JS e React, mas nunca lidei com aprendizado de m√°quina, laptops e algoritmos. Portanto, quando vi a not√≠cia da </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otus de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que eles estavam abrindo um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">curso</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> experimental de cinco meses </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">sobre Machine Learning</font></a><font style="vertical-align: inherit;"> , sem hesita√ß√£o, decidi me submeter a testes experimentais e segui o curso.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante cinco meses, toda semana havia palestras de duas horas e trabalhos de casa para eles. L√° eu aprendi sobre os conceitos b√°sicos de ML: v√°rios algoritmos de regress√£o, classifica√ß√µes, conjuntos de modelos, aumento de gradiente e at√© tecnologias de nuvem levemente afetadas. Em princ√≠pio, se voc√™ ouvir atentamente cada palestra, existem exemplos e explica√ß√µes suficientes para a li√ß√£o de casa. Mas ainda assim, √†s vezes, como em qualquer outro projeto de codifica√ß√£o, eu precisava recorrer √† documenta√ß√£o. Dado meu emprego em per√≠odo integral, era bastante conveniente estudar, pois eu sempre podia revisar o registro de uma palestra on-line.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No final do treinamento deste curso, todos tiveram que fazer o projeto final. </font><font style="vertical-align: inherit;">A id√©ia do projeto surgiu de maneira espont√¢nea, quando comecei a treinar empreendedorismo em Stanford, onde entrei para a equipe que trabalhava no projeto para pessoas com intoler√¢ncia cel√≠aca. </font><font style="vertical-align: inherit;">Durante a pesquisa de mercado, fiquei interessado em saber o que preocupa, o que eles est√£o falando, sobre o que as pessoas com esse recurso reclamam. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√Ä medida que o estudo progredia, encontrei um f√≥rum no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">celiac.com</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">com uma enorme quantidade de material sobre a doen√ßa cel√≠aca. </font><font style="vertical-align: inherit;">Era √≥bvio que rolar manualmente e ler mais de 100 mil postagens era impratic√°vel. </font><font style="vertical-align: inherit;">Ent√£o surgiu a id√©ia de aplicar o conhecimento que recebi neste curso: coletar todas as perguntas e coment√°rios do f√≥rum de um t√≥pico espec√≠fico e fazer modelagem tem√°tica com as palavras mais comuns em cada uma delas.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Etapa 1. Coleta de Dados do F√≥rum</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O f√≥rum consiste em muitos t√≥picos de v√°rios tamanhos. </font><font style="vertical-align: inherit;">No total, este f√≥rum tem cerca de 115.000 t√≥picos e cerca de um milh√£o de posts, com coment√°rios sobre eles. </font><font style="vertical-align: inherit;">Eu estava interessado no subt√≥pico espec√≠fico </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Lidar com a doen√ßa cel√≠aca"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que literalmente significa </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">"Lidar com a doen√ßa</font></a><font style="vertical-align: inherit;"> cel√≠aca", se em russo significa mais "continuar a viver com um diagn√≥stico de doen√ßa cel√≠aca e de alguma forma lidar com as dificuldades". </font><font style="vertical-align: inherit;">Este subt√≥pico cont√©m cerca de 175.000 coment√°rios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O download dos dados ocorreu em duas etapas. </font><font style="vertical-align: inherit;">Para come√ßar, eu tive que percorrer todas as p√°ginas do t√≥pico e coletar todos os links para todas as postagens, para que, na pr√≥xima etapa, eu j√° pudesse coletar um coment√°rio.</font></font><br>
<br>
<pre><code class="python hljs">url_coping = <span class="hljs-string">'https://www.celiac.com/forums/forum/5-coping-with-celiac-disease/'</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como o f√≥rum era bastante antigo, tive muita sorte e o site n√£o teve problemas de seguran√ßa; portanto, para coletar os dados, bastava usar a combina√ß√£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Usu√°rio-Agente</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> da </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fake_useragent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">biblioteca </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beautiful Soup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">para trabalhar com a marca√ß√£o html e saber o n√∫mero de p√°ginas:</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># Get total number of pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_count</span>(<span class="hljs-params">url</span>):</span>
    response = requests.get(url, headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
    soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
    last_page_section = soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsPagination_last'</span>})
    <span class="hljs-keyword">if</span> (last_page_section):<font></font>
        count_link = last_page_section.find(<span class="hljs-string">'a'</span>)
        <span class="hljs-keyword">return</span> int(count_link[<span class="hljs-string">'data-page'</span>])
    <span class="hljs-keyword">else</span>: 
        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><font></font>
<font></font>
coping_pages_count = get_pages_count(url_coping)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, fa√ßa o download do DOM HTML de cada p√°gina para extrair dados com facilidade e facilidade usando a biblioteca </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BeautifulSoup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Python </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># collect pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">retrieve_pages</span>(<span class="hljs-params">pages_count, url</span>):</span><font></font>
    pages = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(pages_count):<font></font>
        response = requests.get(<span class="hljs-string">'{}page/{}'</span>.format(url, page), headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
        soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
        pages.append(soup)<font></font>
    <span class="hljs-keyword">return</span> pages<font></font>
<font></font>
coping_pages = retrieve_pages(coping_pages_count, url_coping)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para baixar os dados, eu precisava determinar os campos necess√°rios para an√°lise: encontre os valores desses campos no DOM e salve-os no dicion√°rio. </font><font style="vertical-align: inherit;">Eu pr√≥prio vim do fundo do Front-end, portanto, trabalhar com casa e objetos foi trivial para mim.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_post_info</span>(<span class="hljs-params">pages</span>):</span><font></font>
    posts = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> pages:<font></font>
        posts_list_soup = page.find(<span class="hljs-string">'ol'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataList'</span>}).findAll(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataItem'</span>})
        <span class="hljs-keyword">for</span> post_soup <span class="hljs-keyword">in</span> posts_list_soup:<font></font>
            post = {}<font></font>
            post[<span class="hljs-string">'id'</span>] = uuid.uuid4()
            <span class="hljs-comment"># collecting titles and urls</span>
            title_section = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_break ipsContained'</span>})
            <span class="hljs-keyword">if</span> (title_section):<font></font>
                title_section_a = title_section.find(<span class="hljs-string">'a'</span>)<font></font>
                post[<span class="hljs-string">'title'</span>] = title_section_a[<span class="hljs-string">'title'</span>]<font></font>
                post[<span class="hljs-string">'url'</span>] = title_section_a[<span class="hljs-string">'data-ipshover-target'</span>]
            <span class="hljs-comment"># collecting author &amp; last action</span>
            author_section = post_soup.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_meta'</span>})
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_a = post_soup.find(<span class="hljs-string">'a'</span>)<font></font>
                author_section_time = post_soup.find(<span class="hljs-string">'time'</span>)<font></font>
                post[<span class="hljs-string">'author'</span>] = author_section_a[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
                post[<span class="hljs-string">'last_action'</span>] = author_section_time[<span class="hljs-string">'datetime'</span>]
            <span class="hljs-comment"># collecting stats</span>
            stats_section = post_soup.find(<span class="hljs-string">'ul'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats'</span>})
            <span class="hljs-keyword">if</span> (stats_section):<font></font>
                stats_section_replies = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>})
                <span class="hljs-keyword">if</span> (stats_section_replies):<font></font>
                    post[<span class="hljs-string">'replies'</span>] = stats_section_replies.getText()<font></font>
                stats_section_views = post_soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_light'</span>})
                <span class="hljs-keyword">if</span> (stats_section_views):<font></font>
                    post[<span class="hljs-string">'views'</span>] = stats_section_views.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>}).getText()<font></font>
            posts.append(post)<font></font>
    <span class="hljs-keyword">return</span> posts
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No total, coletei cerca de 15.450 postagens neste t√≥pico.</font></font><br>
<br>
<pre><code class="python hljs">coping_posts_info = collect_post_info(coping_pages)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora eles podiam ser transferidos para o DataFrame para ficarem lindamente lidos e, ao mesmo tempo, salv√°-los em um arquivo csv para que voc√™ n√£o tivesse que esperar novamente quando os dados foram coletados no site se o notebook acidentalmente quebrar ou eu redefinir acidentalmente uma vari√°vel where. </font></font><br>
<br>
<pre><code class="python hljs">df_coping = pd.DataFrame(coping_posts_info, <font></font>
               columns =[<span class="hljs-string">'title'</span>, <span class="hljs-string">'url'</span>, <span class="hljs-string">'author'</span>, <span class="hljs-string">'last_action'</span>, <span class="hljs-string">'replies'</span>, <span class="hljs-string">'views'</span>]) <font></font>
<font></font>
<span class="hljs-comment"># format data</span>
df_coping[<span class="hljs-string">'replies'</span>] = df_coping[<span class="hljs-string">'replies'</span>].astype(int)<font></font>
df_coping[<span class="hljs-string">'views'</span>] = df_coping[<span class="hljs-string">'views'</span>].apply(<span class="hljs-keyword">lambda</span> x: int(x.replace(<span class="hljs-string">','</span>,<span class="hljs-string">''</span>)))<font></font>
df_coping.to_csv(<span class="hljs-string">'celiac_forum_coping.csv'</span>, sep=<span class="hljs-string">','</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois de coletar uma cole√ß√£o de postagens, comecei a coletar os coment√°rios.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_postpage_details</span>(<span class="hljs-params">pages, df</span>):</span><font></font>
    comments = []<font></font>
    <span class="hljs-keyword">for</span> i, page <span class="hljs-keyword">in</span> enumerate(pages):<font></font>
        articles = page.findAll(<span class="hljs-string">'article'</span>)
        <span class="hljs-keyword">for</span> k, article <span class="hljs-keyword">in</span> enumerate(articles):<font></font>
            comment = {<font></font>
                <span class="hljs-string">'url'</span>: df[<span class="hljs-string">'url'</span>][i]<font></font>
            }<font></font>
            <span class="hljs-keyword">if</span>(k == <span class="hljs-number">0</span>):<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">1</span>
            <span class="hljs-keyword">else</span>:<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">0</span>
            <span class="hljs-comment"># collecting comments</span>
            comment_section = article.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsComment_content'</span>})
            <span class="hljs-keyword">if</span> (comment_section):<font></font>
                comment_section_p = comment_section.find(<span class="hljs-string">'p'</span>)
                <span class="hljs-keyword">if</span>(comment_section_p):<font></font>
                    comment[<span class="hljs-string">'comment'</span>] = comment_section_p.getText()<font></font>
            comment[<span class="hljs-string">'date'</span>] = comment_section.find(<span class="hljs-string">'time'</span>)[<span class="hljs-string">'datetime'</span>]<font></font>
            author_section = article.find(<span class="hljs-string">'strong'</span>)
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_url = author_section.find(<span class="hljs-string">'a'</span>)
                <span class="hljs-keyword">if</span> (author_section_url):<font></font>
                    comment[<span class="hljs-string">'author'</span>] = author_section_url[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
            comments.append(comment)<font></font>
    <span class="hljs-keyword">return</span> comments<font></font>
<font></font>
coping_data = collect_postpage_details(coping_comments_pages, df_coping)<font></font>
df_coping_comments.to_csv(<span class="hljs-string">'celiac_forum_coping_comments_1.csv'</span>, sep=<span class="hljs-string">','</span>)<font></font>
<font></font>
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PASSO 2 An√°lise de Dados e Modelagem Tem√°tica</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Na etapa anterior, coletamos dados do f√≥rum e recebemos os dados finais no formato de 153777 linhas de perguntas e coment√°rios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mas apenas os dados coletados n√£o s√£o interessantes; portanto, a primeira coisa que eu queria fazer era uma an√°lise muito simples: derivava estat√≠sticas para os 30 principais t√≥picos mais vistos e os 30 mais comentados. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9o/ai/dj/9oaidjzovi7va3alxg7vdwkts84.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As postagens mais visualizadas n√£o coincidem com as mais comentadas. Os t√≠tulos das postagens comentadas, mesmo √† primeira vista, s√£o percept√≠veis. Os nomes deles s√£o mais emocionais: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Eu odeio, odeio, odeio"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou " </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Coment√°rios arrogantes"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Uau, estou com problemas"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . E os mais assistidos t√™m um formato de pergunta: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Posso comer soja?", "Por que n√£o consigo absorver √°gua adequadamente?"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de outros. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fizemos uma an√°lise de texto simples. </font><font style="vertical-align: inherit;">Para ir diretamente para uma an√°lise mais complexa, √© necess√°rio preparar os dados antes de envi√°-los √† entrada do modelo LDA para uma an√°lise por t√≥pico. </font><font style="vertical-align: inherit;">Para fazer isso, livre-se dos coment√°rios que contenham menos de 30 palavras, para filtrar spam e coment√°rios curtos sem sentido. </font><font style="vertical-align: inherit;">N√≥s os trazemos para letras min√∫sculas.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># Let's get rid of text &lt; 30 words</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_text_words</span>(<span class="hljs-params">text, min_words = <span class="hljs-number">30</span></span>):</span><font></font>
    text = str(text)<font></font>
    <span class="hljs-keyword">return</span> len(text.split()) &gt; <span class="hljs-number">30</span>
filtered_comments = filtered_comments[filtered_comments[<span class="hljs-string">'comment'</span>].apply(filter_text_words)]<font></font>
comments_only = filtered_comments[<span class="hljs-string">'comment'</span>]<font></font>
comments_only= comments_only.apply(<span class="hljs-keyword">lambda</span> x: x.lower())<font></font>
comments_only.head()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exclua palavras de parada desnecess√°rias para limpar nossa sele√ß√£o de texto</font></font><br>
<br>
<pre><code class="python hljs">stop_words = stopwords.words(<span class="hljs-string">'english'</span>)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">remove_stop_words</span>(<span class="hljs-params">tokens</span>):</span><font></font>
    new_tokens = []<font></font>
    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tokens:<font></font>
        token = []<font></font>
        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> t:
            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words:<font></font>
                token.append(word)<font></font>
        new_tokens.append(token)<font></font>
    <span class="hljs-keyword">return</span> new_tokens<font></font>
<font></font>
tokens = remove_stop_words(data_words)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tamb√©m adicionamos bigrams e formamos um conjunto de palavras para destacar frases est√°veis, por exemplo, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">como sem gl√∫ten, support_group</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e outras frases que, quando agrupadas, t√™m um certo significado.</font></font><br>
<br>
<pre><code class="python hljs">
bigram = gensim.models.Phrases(tokens, min_count=<span class="hljs-number">5</span>, threshold=<span class="hljs-number">100</span>)<font></font>
bigram_mod = gensim.models.phrases.Phraser(bigram)<font></font>
bigram_mod.save(<span class="hljs-string">'bigram_mod.pkl'</span>)<font></font>
bag_of_words = [bigram_mod[w] <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens]
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'bigrams.pkl'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:<font></font>
    pickle.dump(bag_of_words, f)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, finalmente, estamos prontos para treinar diretamente o pr√≥prio modelo de LDA.</font></font><br>
<br>
<pre><code class="python hljs"><font></font>
id2word = corpora.Dictionary(bag_of_words)<font></font>
id2word.save(<span class="hljs-string">'id2word.pkl'</span>)<font></font>
id2word.filter_extremes(no_below=<span class="hljs-number">3</span>, no_above=<span class="hljs-number">0.4</span>, keep_n=<span class="hljs-number">3</span>*<span class="hljs-number">10</span>**<span class="hljs-number">6</span>)<font></font>
corpus = [id2word.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> bag_of_words]<font></font>
<font></font>
lda_model = gensim.models.ldamodel.LdaModel(<font></font>
    corpus, <font></font>
    id2word=id2word, <font></font>
    eval_every=<span class="hljs-number">20</span>,<font></font>
    random_state=<span class="hljs-number">42</span>,<font></font>
    num_topics=<span class="hljs-number">30</span>, <font></font>
    passes=<span class="hljs-number">5</span><font></font>
    )<font></font>
lda_model.save(<span class="hljs-string">'lda_default_2.pkl'</span>)<font></font>
topics = lda_model.show_topics(num_topics=<span class="hljs-number">30</span>, num_words=<span class="hljs-number">100</span>, formatted=<span class="hljs-literal">False</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No final do treinamento, obtemos o resultado dos t√≥picos formados. Que eu anexei no final deste post.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(lda_model.num_topics):<font></font>
    plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">10</span>))<font></font>
    plt.imshow(WordCloud(background_color=<span class="hljs-string">"white"</span>, max_words=<span class="hljs-number">100</span>, width=<span class="hljs-number">900</span>, height=<span class="hljs-number">900</span>, collocations=<span class="hljs-literal">False</span>)<font></font>
               .fit_words(dict(topics[t][<span class="hljs-number">1</span>])))<font></font>
    plt.axis(<span class="hljs-string">"off"</span>)<font></font>
    plt.title(<span class="hljs-string">"Topic #"</span> + themes_headers[t])<font></font>
    plt.show()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como pode ser notado, os t√≥picos acabaram apresentando conte√∫do bastante distinto. </font><font style="vertical-align: inherit;">Segundo eles, fica claro o que as pessoas est√£o falando com intoler√¢ncia cel√≠aca. </font><font style="vertical-align: inherit;">Basicamente, sobre comida, ir a restaurantes, alimentos contaminados com gl√∫ten, dores terr√≠veis, tratamento, ir a m√©dicos, fam√≠lia, mal-entendidos e outras coisas com as quais as pessoas t√™m que lidar todos os dias em conex√£o com seu problema. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Isso √© tudo. </font><font style="vertical-align: inherit;">Obrigado a todos pela aten√ß√£o. </font><font style="vertical-align: inherit;">Espero que voc√™ ache este material interessante e √∫til. </font><font style="vertical-align: inherit;">E, no entanto, como n√£o sou desenvolvedor do DS, n√£o julgue rigorosamente. </font><font style="vertical-align: inherit;">Se h√° algo a acrescentar ou melhorar, sempre recebo cr√≠ticas construtivas, escreva. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para visualizar 30 t√≥picos</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuidado, muitas imagens</font></font></b>
                        <div class="spoiler_text"><img src="https://habrastorage.org/webt/cn/dy/tb/cndytbwrtz9ujkkh6xicy0mjyds.png"><br>
<br>
<img src="https://habrastorage.org/webt/no/n2/iq/non2iqgux8nvb5hnitr8n7yra_w.png"><br>
<br>
<img src="https://habrastorage.org/webt/dx/dh/nl/dxdhnlddgexrb_noeq8psjb7nps.png"><br>
<br>
<img src="https://habrastorage.org/webt/x1/_f/q6/x1_fq6omll0iigewzz0ba8tjvys.png"><br>
<br>
<img src="https://habrastorage.org/webt/7v/qy/fh/7vqyfh-uwk_bhypzdgisxxabzjs.png"><br>
<br>
<img src="https://habrastorage.org/webt/v7/1z/fn/v71zfn2kb0xj7rpsthrplgznzzw.png"><br>
<br>
<img src="https://habrastorage.org/webt/ab/tt/t7/abttt7c8aqydfc28gxyq9ai7a4q.png"><br>
<br>
<img src="https://habrastorage.org/webt/oz/hc/m7/ozhcm72ldjjenp5onkjydxgpvly.png"><br>
<br>
<img src="https://habrastorage.org/webt/fe/ex/lw/feexlw8tcrcwni5wmy8k8rv8k3e.png"><br>
<br>
<img src="https://habrastorage.org/webt/w0/hu/5j/w0hu5jix2zrewo2l9jnbkddd3tk.png"><br>
<br>
<img src="https://habrastorage.org/webt/zf/ye/kw/zfyekw6s6qfxuqwy-qxhv_dehrq.png"><br>
<br>
<img src="https://habrastorage.org/webt/l0/9s/vw/l09svwry19fhz1y-1-pooeo_vew.png"><br>
<br>
<img src="https://habrastorage.org/webt/pm/mt/bk/pmmtbkkybu50vhgttl-0kz4tcf4.png"><br>
<br>
<img src="https://habrastorage.org/webt/1h/hu/vr/1hhuvrmmfjxwfzh3fbhf9dbut38.png"><br>
<br>
<img src="https://habrastorage.org/webt/bw/is/ad/bwisadbn9a000lt6xp927szic2u.png"><br>
<br>
<img src="https://habrastorage.org/webt/iu/bf/4q/iubf4qt_juq9uip17rmngbr7wxe.png"><br>
<br>
<img src="https://habrastorage.org/webt/jk/of/sa/jkofsalh2hev8zx6jjlom0pnnxy.png"><br>
<br>
<img src="https://habrastorage.org/webt/js/bs/ls/jsbslsv_4ly4rwe7wir6xvcs6t4.png"><br>
<br>
<img src="https://habrastorage.org/webt/_e/ly/wr/_elywrkbtgk-4fvlnuzfr6zqq4o.png"><br>
<br>
<img src="https://habrastorage.org/webt/4j/x8/pa/4jx8paomlrca7t0syfunmtmlxk4.png"><br>
<br>
<img src="https://habrastorage.org/webt/y2/he/s1/y2hes1fvuepisygriea98m_yavw.png"><br>
<br>
<img src="https://habrastorage.org/webt/9k/xs/sr/9kxssr9rxlyeobjw12fwju0-xkq.png"><br>
<br>
<img src="https://habrastorage.org/webt/i-/sl/qd/i-slqdug6x9dkwybnfnxmdolho8.png"><br>
<br>
<img src="https://habrastorage.org/webt/nq/pk/x5/nqpkx5q6j8e_6mkpfak0ytkkvfc.png"><br>
<br>
<img src="https://habrastorage.org/webt/jv/3b/pa/jv3bpafludpki_2a-4pgajhreh0.png"><br>
<br>
<img src="https://habrastorage.org/webt/sw/-e/pn/sw-epnxhrwa4t7i6uksmggczs-8.png"><br>
<br>
<img src="https://habrastorage.org/webt/-y/qj/0t/-yqj0t-jkax-s09bivkgx8a3mqa.png"><br>
<br>
<img src="https://habrastorage.org/webt/ta/rp/4w/tarp4wr8bcui0zszwuzl7l9h8zo.png"><br>
<br>
<img src="https://habrastorage.org/webt/eo/xl/m2/eoxlm2i2z9weffxhgm-zzgszd3q.png"><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">    ¬´Machine Learning¬ª  OTUS</a>.<br>
<br>
<hr><br>
</div>
                    </div></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt503382/index.html">Fa√ßa uma caminhada em um campo limpo ou como coletar endere√ßos MAC de dispositivos Wi-Fi pr√≥ximos</a></li>
<li><a href="../pt503386/index.html">Pessoa saud√°vel de treinador √°gil</a></li>
<li><a href="../pt503388/index.html">Digitaliza√ß√£o do p√¢nico: DIT de Moscou contra moscovitas - mesa-redonda em 23 de maio</a></li>
<li><a href="../pt503390/index.html">Por que a Intel est√° apostando no desenvolvimento de chips para o g√™nio de Jim Keller?</a></li>
<li><a href="../pt503394/index.html">Experi√™ncia em Investimento em A√ß√µes</a></li>
<li><a href="../pt503402/index.html">Como lembrar de todos pessoalmente, ou uma pesquisa eficaz de rostos em um grande banco de dados</a></li>
<li><a href="../pt503404/index.html">Sistemas Digitais Sem√¢nticos</a></li>
<li><a href="../pt503406/index.html">Sem√¢ntica e atividade</a></li>
<li><a href="../pt503408/index.html">Loja Online Blazor Client Side: Parte 7 - Atualizado para a vers√£o 3.2.0 e exibi√ß√£o de imagem adicionada</a></li>
<li><a href="../pt503410/index.html">Polygons Another World: Sega Genesis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
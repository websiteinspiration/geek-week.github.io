<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ù§Ô∏è üë®üèø‚Äç‚öñÔ∏è ‚§µÔ∏è Accelerating the Qemu KVM disk subsystem on Linux üçø üë¶üèª üëÉüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sometimes I take on various tasks for setting up servers. Some time ago, the owner of a small hosting company approached me with an interesting proble...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Accelerating the Qemu KVM disk subsystem on Linux</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/493696/"><img src="https://habrastorage.org/webt/gx/ub/i1/gxubi1ucfhq7jujnimizriacaqa.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sometimes I take on various tasks for setting up servers. </font><font style="vertical-align: inherit;">Some time ago, the owner of a small hosting company approached me with an interesting problem. </font><font style="vertical-align: inherit;">He would like to run Windows virtual machines under KVM on his servers, where Ubuntu 18.04 was already installed. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, his testing showed that the KVM disk system decently lagged behind the indicators that he had under Hyper-V. </font><font style="vertical-align: inherit;">He wanted to unleash qemu on his Ubuntu servers to avoid buying expensive Windows server licenses (the free version of Microsoft Hyper-V Server did not work out because of its limitations).</font></font><br>
<a name="habracut"></a><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0. Disposition</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For testing, we used the Samsung 970 Pro 1TB SSD. </font><font style="vertical-align: inherit;">The customer checked the results of work in CrystalDiskMark, so further in the article all the graphs from it.</font></font><br>
<br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Windows 10 LTSC</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyper-V </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KVM </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2 CPU</font></font></th>
</tr>
<tr>
<td><img src="https://habrastorage.org/webt/h_/-8/n1/h_-8n1bwsgaovljitrm1wztowbi.png"></td>
<td><img src="https://habrastorage.org/webt/to/eh/ft/toehft7m0vaghk2a3vdlmkxdwq8.png"></td>
<td><img src="https://habrastorage.org/webt/-i/na/am/-inaamktv9beteru7huusvcktmo.png"></td>
</tr>
</tbody></table></div><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The first step was to improve random I / O performance. </font><font style="vertical-align: inherit;">This type of load is typical for virtual machines, especially those of them that use various databases. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ubuntu (16.04 LTS and 18.04) still uses qemu version 2.11. </font><font style="vertical-align: inherit;">Therefore, some of the latest qemu buns are not considered in this article. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We decided that we need to avoid tying iron to a virtual machine, since this complicates the portability of virtual machines, so options for throwing SSD / physical disks / partitions into virtual machines were considered undesirable.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">About the test file size for CrystalDiskMark</font></font></b><div class="spoiler_text">   ,          100  4.   ,         :   ,    .<br>
<br>
,        ,  Windows       .    100  4    ,     40  .<br>
<br>
       ,      ,         100-1.         4.<br>
</div></div><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. We use LVM volumes, not files for storing virtual machine disks.</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The logic is this. The file with the virtual disk is stored in the Linux file system, NTFS is located inside the file itself. Each file system consumes resources during disk operations. Therefore, the smaller the depth of the doll, the faster the input / output. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If we talk about qcow2 files, their name stands for ‚ÄúQemu Copy-On-Write‚Äù and, in fact, they have their own translation table inside which is responsible for which blocks are busy, which ones are not and where what is located. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The LVM layer consumes significantly less processor resources than the file system. One of the reasons for this is that the blocks in it are much larger than a typical file system block (4KB). The larger the block (extent) on the physical LVM device, the more quickly IO occurs and the less fragmentation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But even for SSD random I / O is much slower than serial. Therefore, when creating the Volume Group, we will specify a very large extent: 256MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Read ahead on a logical volume should be turned off, because it spends IO without a win, since now no one is defragmenting disks in Windows on SSDs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
LVM is quite convenient to use for hosting virtual machines. LVM volumes are easily portable between physical disks; there are snapshots and resizing online. Moreover, virt-manager (libvirt) can create logical volumes out of the box for virtual machine disks from the Volume group.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The ability to create thin volumes also looks attractive, but given that a thin volume is an additional layer of abstraction, it is obvious that it will degrade IO performance. </font><font style="vertical-align: inherit;">In addition, libvirt does not have an elegant way to automatically create disks for virtual machines in a thin pool.</font></font><br>
<br>
<pre><code class="bash hljs"><span class="hljs-comment">#    SSD    (volume group)</span><font></font>
pvcreate /dev/nvme1n1p1<font></font>
<font></font>
<span class="hljs-comment">#    win    (extent) 256.</span><font></font>
vgcreate -s 256M win_pool /dev/nvme1n1p1<font></font>
<font></font>
<span class="hljs-comment">#    vm1.    C</span><font></font>
lvcreate -n vm1 -L 100G win_pool<font></font>
<font></font>
<span class="hljs-comment">#      (read ahead)</span><font></font>
lvchange -r none /dev/win_pool/vm1<font></font>
</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.1. </font><font style="vertical-align: inherit;">Thin volume as a disk and / or logical volume settings for snapshots</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you want to use a thin pool in which you will create thin volumes, then it makes sense to set the chunk size of the pool to 4MB, which is much larger than the default size of 64KB. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Which will entail faster work of this layer of abstraction. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The snapshot mechanism in LVM works almost on the same code as thin volumes, so the settings will be the same to increase the snapshot speed.</font></font><br>
<br>
<pre><code class="bash hljs">lvcreate -c 4m -L 300G -T -Zn win_pool/thin</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The option </font></font><code>-Zn</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">disables overwriting the chunk with zeros during selection, which increases the speed of work. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Settings for lvm.conf or a similar file (e.g. lvmlocal.conf):</font></font><br>
<br>
<pre><code class="bash hljs">thin_pool_chunk_size = 4096<font></font>
thin_pool_zero = n</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can determine the optimal size of the chunk by completing the test with the following command, choosing the value </font></font><code>--blocksize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="bash hljs">fio --name=randwrite --filename=/dev/nvme0n1p9 --size=10G --ioengine=libaio --iodepth=1 --buffered=0 --direct=1 --rw=randwrite --blocksize=4m</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can view the current size of the chunk with the command:</font></font><br>
<br>
<pre><code class="bash hljs">lvs -ao name,chunksize</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2. Increasing the number of logical processors allocated to each KVM virtual machine improves disk performance</font></font></h4><br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 CPU</font></font></th>
</tr>
<tr>
<td><img src="https://habrastorage.org/webt/rk/d5/pp/rkd5pphdlwmwx0ykk_mszbtcxjc.png"></td>
<td><img src="https://habrastorage.org/webt/o6/0s/u-/o60su-evqzflfsjh4v0wl7ih8sa.png"></td>
<td><img src="https://habrastorage.org/webt/gv/0x/jf/gv0xjf7ky6xkidam9duclsztowo.png"></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is clear that hardly anyone will allocate 10 processors to the virtual machine, but it was interesting to look at the extreme case. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It already depends on the number of free processors. </font><font style="vertical-align: inherit;">In my opinion, it is inexpedient to allocate more than 4. </font><font style="vertical-align: inherit;">With the number of threads equal to 8, we got the maximum random read and write performance. </font><font style="vertical-align: inherit;">This is a specificity of CrystalDiskMark 6.0.2, in which the second test conducts 8 threads. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
From which we can conclude that it is good to have one logical processor for each task that actively uses IO.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3. We use huge pages of random access memory (hugepages) to avoid performance degradation due to fragmentation of RAM</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This package can come in handy when we need various information about hugepages during operation.</font></font><br>
<br>
<pre><code class="bash hljs">apt install hugepages</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Edit </font></font><code>/etc/default/grub</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="bash hljs">GRUB_CMDLINE_LINUX=<span class="hljs-string">"default_hugepagesz=1GB hugepagesz=1G hugepages=64"</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this case, 64GB of memory was allocated for all virtual machines as hugepages. </font><font style="vertical-align: inherit;">In your case there may be less / more. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We apply these settings to GRUB so that the next time the system boots, they become active:</font></font><br>
<br>
<pre><code class="bash hljs">grub-mkconfig -o /boot/grub/grub.cfg
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Editing the virtual machine config:</font></font><br>
<br>
<pre><code class="bash hljs">virsh edit vm_name</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Add:</font></font><br>
<br>
<pre><code class="xml hljs"><span class="hljs-tag">&lt;<span class="hljs-name">memoryBacking</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">hugepages</span>/&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">memoryBacking</span>&gt;</span></code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4. Add a dedicated stream to each virtual machine to serve IO</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You need to add what is highlighted in bold. </font><font style="vertical-align: inherit;">We use </font></font><code>virsh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, as in the previous paragraph.</font></font><br>
<br>
<blockquote><b>&lt;iothreads&gt;1&lt;/iothreads&gt;</b><br>
<br>
&lt;disk type='block' device='disk'&gt;<br>
&lt;driver name='qemu' type='raw' cache='none' io='threads' <b>iothread='1'</b>/&gt;<br>
&lt;source dev='/dev/win/terminal'/&gt;<br>
&lt;target dev='vda' bus='virtio'/&gt;<br>
&lt;boot order='2'/&gt;<br>
&lt;address type='pci' domain='0x0000' bus='0x04' slot='0x00' function='0x0'/&gt;<br>
&lt;/disk&gt;</blockquote><br>
<br>
<h4>4.1.       writeback</h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To speed up accidental writing to disk, but with an increased risk of data loss, you can use </font></font><code>cache=writeback</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the previous paragraph. </font><font style="vertical-align: inherit;">It can be used only if there is great confidence in the quality and backup of power and in the presence of backups.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5. Disk subsystem settings in Virt Manager</font></font></h4><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Disk bus: VirtIO </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Storage format: raw </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cache mode: writeback </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
IO mode: threads</font></font></blockquote><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.1. </font><font style="vertical-align: inherit;">Configuring a disk subsystem through a configuration file</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qemu 2.11 (which is currently used by Ubuntu) supports two types of disk virtual devices: virtio-blk and virtio-scsi. </font><font style="vertical-align: inherit;">When specified in Virt Manager </font></font><code>Disk bus: VirtIO</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, this means using the virtio-blk device. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In all cases, virtio-blk is better in speed, despite the fact that in the tested qemu version it still did not support TRIM, unlike virtio-scsi (it </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">already supports it</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> since version 5.x </font><font style="vertical-align: inherit;">). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In terms of disk IO speed, virtio-scsi only makes sense in exotic cases, for example, when you need to connect hundreds of disks to a virtual machine.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6. During the installation of Windows, install the VirtIO driver</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Otherwise, the disk will not be available for the OS. </font><font style="vertical-align: inherit;">To do this, use the driver image, which we pre-connect to the virtual machine.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7. Results after applying all the tweaks</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, the tweak 4.1 was not used, since I was not sure of the reliability of the power supply from the client.</font></font><br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyper-V </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KVM </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KVM </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4 CPU</font></font></th>
</tr>
<tr>
<td><img src="https://habrastorage.org/webt/to/eh/ft/toehft7m0vaghk2a3vdlmkxdwq8.png"></td>
<td><img src="https://habrastorage.org/webt/4a/la/5s/4ala5snjmars3uaepsbb63lcgqm.png"></td>
<td><img src="https://habrastorage.org/webt/fu/tt/0k/futt0kedtld37khc96igkyks1zq.png"></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You need to understand that these results have a certain convention, since each time you start CrystalDiskMark, the values ‚Äã‚Äãare slightly different.</font></font><br>
<br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KVM out of the box </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KVM after tweaks </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2 CPU</font></font></th>
</tr>
<tr>
<td><img src="https://habrastorage.org/webt/-i/na/am/-inaamktv9beteru7huusvcktmo.png"></td>
<td><img src="https://habrastorage.org/webt/4a/la/5s/4ala5snjmars3uaepsbb63lcgqm.png"></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We see that it was possible to significantly accelerate the work of the disk subsystem in qemu (kvm) with the same number of cores. </font><font style="vertical-align: inherit;">Writing was accelerated by an average of 58%, and reading by 25%. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Key success elements</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : using LVM volumes instead of qcow2 files, separate I / O, and hugepages. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Direct the noticed errors to the PM. </font><font style="vertical-align: inherit;">I increase karma for this.</font></font></i><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS vhost-user-blk and vhost-user-nvme</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
During the experiments, Qemu 2.12 and version 3 were also compiled. </font><font style="vertical-align: inherit;">The vhost-user-blk option for a disk was tested. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the end, it worked worse than virtio-blk.</font></font><br>
<br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vhost-user-blk </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4 CPU</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">virtio-blk </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4 CPU</font></font></th>
</tr>
<tr>
<td><img src="https://habrastorage.org/webt/x_/zw/04/x_zw04o-k8gq4so3yvyp66ddyga.png"></td>
<td><img src="https://habrastorage.org/webt/fu/tt/0k/futt0kedtld37khc96igkyks1zq.png"></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To use vhost-user-nvme it was necessary to patch qemu, this option complicated the automatic updating of servers in production, so it was not tested.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PPS SPDK</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Intel designed </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">this framework</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to achieve outstanding performance indicators for disk systems in virtual machines that should run on its processors. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To make spdk work well, they go to a lot of tricks - they allocate separate kernels to it, place the spdk and virtual machine kernels in one socket. Load the virtual machine into a contiguous chunk of memory. If you apply such measures to regular virtio-blk, then it will also work faster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SPDK is capable of working in 3 modes: vhost-user-scsi, vhost-user-blk and vhost-user-nvme. The second mode is only available in qemu from 2.12, which is not yet available in ubuntu. The vhost-user-nvme mode is generally mega-experimental - you need to patch qemu for it. Currently, only scsi emulation works and it is slow.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is another serious limitation for vhost-user-scsi mode - the spdk disk cannot be bootable.</font></font><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Make sure bootindex = 2 Qemu option is given to vhost-user-scsi-pci device.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Records are set when they use their driver to share SSDs on multiple devices and forward them as vhost-user-nvme. </font><font style="vertical-align: inherit;">The iron-piercing approach did not suit us. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The impression was that it was normal to use SPDK only with their implementation of logical disks (which is completely different from standard lvm). </font><font style="vertical-align: inherit;">This is such a self-made bike with its pictures and cloning. </font><font style="vertical-align: inherit;">Teams are all different from LVM. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The difficulty in configuring SPDK, support and portability of virtual machines, as well as attachment to Intel processors, turned away from its use.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acknowledgments</font></font></h4><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thanks for the image </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TripletConcept</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">It is better to watch it in full size in a separate window. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For permission to share working materials -</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">st_neon</font></font></a></i><br>
<br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can order a virtual machine with SSD from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RUVDS</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> for the coupon below. </font><b><i><font style="vertical-align: inherit;">Direct the noticed errors to the PM. </font></i></b><b><i><font style="vertical-align: inherit;">I increase karma for this.</font></i></b></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a><br>
<br>
<b><i><font style="vertical-align: inherit;"></font></i></b></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en493682/index.html">How to choose long-term investments: 6 shares from the portfolio of Warren Buffett</a></li>
<li><a href="../en493686/index.html">The mysterious origin of the board game about hacking codes Mastermind</a></li>
<li><a href="../en493688/index.html">We make Microsoft Teams free - stay in touch with colleagues at this difficult time</a></li>
<li><a href="../en493690/index.html">20 tips for pilot DJI Mavic Mini to protect your drone from crash and loss</a></li>
<li><a href="../en493692/index.html">Theoretical data structures and their application in JavaScript. P1. Couples</a></li>
<li><a href="../en493700/index.html">Using malware in Azure to gain access to Microsoft 365 tenants</a></li>
<li><a href="../en493702/index.html">Massive transition to remote work: technical problems and threats to security</a></li>
<li><a href="../en493704/index.html">Using TypeScript in JavaScript without writing TypeScript</a></li>
<li><a href="../en493706/index.html">Know your enemy: create a Node.js backdoor</a></li>
<li><a href="../en493708/index.html">Anatomy of my home Kubernetes cluster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="zh-CN">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👋🏿 ✌🏿 🏘️ 数据分类方法摘要 🚶🏻 📧 🎵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在学习数据科学时，我决定为自己编写一份数据分析中使用的基本技术的摘要。它反映了方法的名称，简要描述了本质，并提供了用于快速应用的Python代码。我当时正在为自己准备一份纲要，但我认为这可能对某人有用，例如在面试之前，比赛中或开始新项目时。专为通常熟悉所有这些方法但需要在内存中刷新它们的读者设计。下...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>数据分类方法摘要</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/491326/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在学习数据科学时，我决定为自己编写一份数据分析中使用的基本技术的摘要。</font><font style="vertical-align: inherit;">它反映了方法的名称，简要描述了本质，并提供了用于快速应用的Python代码。</font><font style="vertical-align: inherit;">我当时正在为自己准备一份纲要，但我认为这可能对某人有用，例如在面试之前，比赛中或开始新项目时。</font><font style="vertical-align: inherit;">专为通常熟悉所有这些方法但需要在内存中刷新它们的读者设计。</font><font style="vertical-align: inherit;">下条切。</font></font><br>
<a name="habracut"></a><br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">朴素贝叶斯分类器</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">用于计算将观察分类为一类或另一类的概率的公式：</font></font></p><br>
  <p><img src="https://habrastorage.org/webt/xm/ks/pe/xmkspevmmrgf6mn_os_pvslb3qc.png"></p><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 例如，您需要计算在天气晴朗的情况下进行体育比赛的概率。</font><font style="vertical-align: inherit;">下表显示了源数据和计算：</font></font><br>
<br>
 <p><img src="https://habrastorage.org/webt/yd/gc/ik/ydgcik0buynftc9j_xo0bamb3s8.png"></p><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 您可以通过公式（3/9）*（9/14）/（5/14）= 60％进行计算，或者仅根据常识3 /（2 + 3）= 60％进行计算。</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">优点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -易于解释结果，适用于大样本和多类别分类。</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">弱点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -并不总是满足特征独立的假设；特征应构成完整的事件组。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = load_iris(return_X_y=<span class="hljs-literal">True</span>)<font></font>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.5</span>, random_state=<span class="hljs-number">0</span>)<font></font>
gnb = GaussianNB()<font></font>
y_pred = gnb.fit(X_train, y_train).predict(X_test)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
print(<span class="hljs-string">"Number of mislabeled points out of a total %d points : %d"</span>
            % (X_test.shape[<span class="hljs-number">0</span>], (y_test != y_pred).sum())) 
</code></pre> <br>
 <br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最近邻居的方法</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">根据与其他观测值的相似程度对每个观测值进行分类。</font><font style="vertical-align: inherit;">该算法是非参数性的（对数据没有限制，例如，数据分布的功能），并且使用了惰性训练（未使用预训练的模型，在分类过程中使用了所有可用数据）。</font></font></p><br>
  <p><img src="https://habrastorage.org/webt/l7/vw/1n/l7vw1nxyzyori9nkeminukor90q.png"></p><br>
  <br>
 <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">优点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -易于解释结果，非常适合具有少量解释变量的任务。</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">缺点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -与其他方法相比，准确性较低。</font><font style="vertical-align: inherit;">它需要具有大量解释变量和大量样本的强大计算能力。</font></font><br>
 <br>
  <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X = [[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>], [<span class="hljs-number">3</span>]]<font></font>
y = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<font></font>
neigh = KNeighborsClassifier(n_neighbors=<span class="hljs-number">3</span>)<font></font>
neigh.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
print(neigh.predict([[<span class="hljs-number">1.1</span>]]))<font></font>
print(neigh.predict_proba([[<span class="hljs-number">0.9</span>]]))
 </code></pre> <br>
 <br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">支持向量法（SVM）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">每个数据对象都表示为p维空间中的向量（点）。</font><font style="vertical-align: inherit;">任务是用超平面分离点。</font><font style="vertical-align: inherit;">即，可以找到这样的超平面，使得从其到最近点的距离最大。</font><font style="vertical-align: inherit;">可能会有许多抢手的超平面；因此，可以认为，最大化类之间的距离有助于更可靠的分类。</font></font></p><br>
  <p><img src="https://habrastorage.org/getpro/habr/post_images/bcf/cdb/f99/bcfcdbf99544b1cd6ccb0f99ec519131.jpg"></p><br>
  <br>
 <p> <strong> </strong> —     .   ,   ,   .      . <strong> </strong> —  ,   ,   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"> </a>,    .        .<br>
 </p> <br>
  <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]<font></font>
y = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<font></font>
clf = svm.SVC()<font></font>
clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
clf.predict([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]])
 </code></pre> <br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">决策树</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">根据特定条件以树结构的形式将数据划分为子样本。</font><font style="vertical-align: inherit;">从数学上讲，将划分为几类，直到找到所有尽可能精确地确定该类的条件，即每个类中都没有其他类的代表。</font><font style="vertical-align: inherit;">实际上，使用的特征和层数量有限，并且始终有两个分支。</font></font></p><br>
  <p><img src="https://habrastorage.org/getpro/habr/post_images/b3c/162/1f1/b3c1621f19b930a48abce372977cadbb.png"></p><br>
 <br>
 <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">优势</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -可以模拟复杂的过程并轻松解释它们。</font><font style="vertical-align: inherit;">多类分类是可能的。</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">缺点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -如果制作了许多层，则很容易重新训练模型。</font><font style="vertical-align: inherit;">排放会影响精度；解决这些问题的方法是修整较低的水平。</font></font><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> tree<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = load_iris(return_X_y=<span class="hljs-literal">True</span>)<font></font>
clf = tree.DecisionTreeClassifier()<font></font>
clf = clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
tree.plot_tree(clf.fit(iris.data, iris.target)) </code></pre> <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"> / </a>.        .  —     .       (random patching)             .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">oob-</a>.</p><br>
 <p><strong> </strong>:   ,     ,  ,    ,   ,       .     ,    . <strong> </strong> —    ,      .  ,     ( 100 000),     — .</p> <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_classification<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = make_classification(n_samples=<span class="hljs-number">1000</span>, n_features=<span class="hljs-number">4</span>,<font></font>
                           n_informative=<span class="hljs-number">2</span>, n_redundant=<span class="hljs-number">0</span>,<font></font>
                           random_state=<span class="hljs-number">0</span>, shuffle=<span class="hljs-literal">False</span>)<font></font>
                           <font></font>
clf = RandomForestClassifier(max_depth=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">0</span>)<font></font>
clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span><font></font>
print(clf.feature_importances_)<font></font>
print(clf.predict([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]))</code></pre> <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">  </a>.      (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">hinge loss function</a>).      .<br>
  </p><p><img src="https://habrastorage.org/webt/d7/wk/si/d7wksizyut_vgl2idpts9-eythq.png"></p><br>
  <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 还有一个随机梯度下降的版本，用于大样本。</font><font style="vertical-align: inherit;">其本质是，它不考虑整个样本的导数，而是考虑每个观察（在线学习）（或小批量观察组）的导数并更改权重。</font><font style="vertical-align: inherit;">结果，他达到了与传统HS相同的最佳效果。</font><font style="vertical-align: inherit;">有将HS用于OLS，logit，tobit和其他方法（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">证据</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）的</font><font style="vertical-align: inherit;">方法</font><font style="vertical-align: inherit;">。</font></font><br>
 <br>
 <p><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">优点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：分类和预测的准确性高，适用于多分类。</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">弱点</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -对模型参数的敏感性。</font></font></p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X = [[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>], [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]<font></font>
y = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<font></font>
clf = SGDClassifier(loss=<span class="hljs-string">"hinge"</span>, penalty=<span class="hljs-string">"l2"</span>, max_iter=<span class="hljs-number">5</span>)<font></font>
clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
clf.predict([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]])<font></font>
clf.coef_<font></font>
clf.intercept_</code></pre> <br>
 <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"> </a>.   .         ,    . ,     ,    . </p><br>
 <br>
 <p><strong> </strong>:     ,    ,    ,    . <strong> </strong> —    .</p><br>
  <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> ensemble
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">from</span> sklearn.utils <span class="hljs-keyword">import</span> shuffle
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<font></font>
<font></font>
<span class="hljs-comment">#model fit</span><font></font>
boston = datasets.load_boston()<font></font>
X, y = shuffle(boston.data, boston.target, random_state=<span class="hljs-number">13</span>)<font></font>
X = X.astype(np.float32)<font></font>
offset = int(X.shape[<span class="hljs-number">0</span>] * <span class="hljs-number">0.9</span>)<font></font>
X_train, y_train = X[:offset], y[:offset]<font></font>
X_test, y_test = X[offset:], y[offset:]<font></font>
params = {<span class="hljs-string">'n_estimators'</span>: <span class="hljs-number">500</span>, <span class="hljs-string">'max_depth'</span>: <span class="hljs-number">4</span>, <span class="hljs-string">'min_samples_split'</span>: <span class="hljs-number">2</span>,
          <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.01</span>, <span class="hljs-string">'loss'</span>: <span class="hljs-string">'ls'</span>}<font></font>
clf = ensemble.GradientBoostingRegressor(**params)<font></font>
clf.fit(X_train, y_train)<font></font>
<font></font>
<span class="hljs-comment">#result</span><font></font>
mse = mean_squared_error(y_test, clf.predict(X_test))<font></font>
print(<span class="hljs-string">"MSE: %.4f"</span> % mse)</code></pre> <br>
 <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"> /logit</a>.     0  1,     (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">log likelihood</a>).  —    Y       w.<br>
  </p><p><img src="https://habrastorage.org/getpro/habr/post_images/859/2c1/173/8592c1173d2ff17239fca69ec8b18cac.jpg"></p><br>
  <br>
  <p><img src="https://habrastorage.org/getpro/habr/post_images/cfe/2ca/c37/cfe2cac37843ae065a3ef157a02d389c.jpg"></p><br>
  <br>
 <br>
 <p><strong> </strong>:  ,      . <strong> </strong> —    ,    .</p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = load_iris(return_X_y=<span class="hljs-literal">True</span>)<font></font>
clf = LogisticRegression(random_state=<span class="hljs-number">0</span>).fit(X, y)<font></font>
clf.predict(X[:<span class="hljs-number">2</span>, :])<font></font>
<font></font>
<span class="hljs-comment">#result</span>
clf.predict_proba(X[:<span class="hljs-number">2</span>, :])<font></font>
clf.score(X, y) </code></pre> <br>
 <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">Probit</a>.     ,     ,   ,      .</p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">import</span> statsmodels<font></font>
<font></font>
<span class="hljs-comment">#model fit</span><font></font>
result_3 = statsmodels.discrete.<font></font>
    discrete_model.Probit(labf_part, ind_var_probit )<font></font>
<font></font>
<span class="hljs-comment">#result</span>
print(result_3.summary()) </code></pre> <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">Tobit</a>. ,      .</p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_regression
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> tobit <span class="hljs-keyword">import</span> *<font></font>
<font></font>
<span class="hljs-comment">#model fit</span><font></font>
tr = TobitModel()<font></font>
<font></font>
<span class="hljs-comment">#result</span>
tr = tr.fit(x, y, cens, verbose=<span class="hljs-literal">False</span>)<font></font>
tr.coef_</code></pre> <br>
 <p>  -  , ,     .       ,  ,    ,    .   .</p><br>
 <br>
<br>
 <br></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN491302/index.html">Grandstream手机上的OVPN客户端</a></li>
<li><a href="../zh-CN491304/index.html">赫尔辛基：幸福与舒适的城市</a></li>
<li><a href="../zh-CN491308/index.html">ClickHouse-Tabix中的视觉快速直观的数据分析。伊戈尔·史翠卡（Igor Strykhar）</a></li>
<li><a href="../zh-CN491310/index.html">如何自己破解密码档案</a></li>
<li><a href="../zh-CN491312/index.html">我们如何从一个男人那里筛下来并帮助磨坊</a></li>
<li><a href="../zh-CN491332/index.html">每小时计划和其他Scrum事件优化</a></li>
<li><a href="../zh-CN491336/index.html">像游戏设计师一样玩</a></li>
<li><a href="../zh-CN491338/index.html">5G能否取代Wi-Fi-讨论意见</a></li>
<li><a href="../zh-CN491342/index.html">如何失去电报机器人的所有用户。简要说明</a></li>
<li><a href="../zh-CN491344/index.html">凭借独特技术在量子计算领域崭露头角</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
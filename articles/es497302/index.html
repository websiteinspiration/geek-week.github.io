<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¥üèø üõÄüèø üîç Navegaci√≥n aut√≥noma de un robot m√≥vil. üë®‚Äçüç≥ üõÑ ‚ùáÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hay una gran cantidad de formas en que un robot puede recibir informaci√≥n del mundo exterior para interactuar con √©l. Adem√°s, dependiendo de las tarea...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Navegaci√≥n aut√≥noma de un robot m√≥vil.</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/497302/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hay una gran cantidad de formas en que un robot puede recibir informaci√≥n del mundo exterior para interactuar con √©l. </font><font style="vertical-align: inherit;">Adem√°s, dependiendo de las tareas que se le asignen, los m√©todos de procesamiento de esta informaci√≥n difieren. </font><font style="vertical-align: inherit;">En este art√≠culo describir√© las principales etapas del trabajo realizado como parte del proyecto escolar, cuyo objetivo es sistematizar la informaci√≥n sobre varios m√©todos de navegaci√≥n aut√≥noma del robot y aplicar los conocimientos adquiridos en el proceso de creaci√≥n del robot para las competencias de la "Copa RTK".</font></font><br>
<br>
<img src="https://habrastorage.org/webt/qb/xw/dw/qbxwdwc_cwrypc3c8dthahudzmk.jpeg"><br>
<a name="habracut"></a><br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Introducci√≥n</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En las competiciones "Copa RTK" hay un bloque de tareas que deben completarse sin la intervenci√≥n del operador. </font><font style="vertical-align: inherit;">Creo que muchos participantes est√°n evitando injustamente estas tareas, porque la aparente complejidad de crear un dise√±o de robot y escribir un programa oculta tareas en gran parte simplificadas de otras disciplinas competitivas, combinadas en un campo de entrenamiento. </font><font style="vertical-align: inherit;">Por mi proyecto quiero mostrar posibles soluciones a tales problemas, considerando como ejemplo lo siguiente a lo largo de la l√≠nea. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para lograr el objetivo del proyecto, se formularon las siguientes tareas intermedias:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An√°lisis de las </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bases del</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> concurso "Copa RTK"</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An√°lisis de algoritmos existentes para la orientaci√≥n aut√≥noma de un robot m√≥vil.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creaci√≥n de software</font></font></li>
</ul><br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An√°lisis de las bases del concurso "Copa RTK"</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En las competencias de la "Copa RTK", se presenta a los participantes un campo de entrenamiento en el que se modelan secciones de diversa complejidad. </font><font style="vertical-align: inherit;">La competencia tiene como objetivo estimular la rob√≥tica joven para crear dispositivos que puedan funcionar en condiciones extremas, superar obst√°culos, bajo control humano o de forma aut√≥noma.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6a/sr/6w/6asr6wzvlhnqgkmz0b8dfyf2h9o.jpeg"><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">brevemente sobre los elementos que componen el pol√≠gono</font></font></b><div class="spoiler_text"> ¬´¬ª          ,    .    ,       ,     (), ,      (),   ..<br>
<br>
:<br>
<br>
<img src="https://habrastorage.org/webt/mk/ks/d3/mkksd313rprmlsilxcrq5xdytg4.png" width="300"><br>
<br>
:<br>
<br>
<img src="https://habrastorage.org/webt/rv/fp/cu/rvfpcu-6qtvdfrclsqjzlr2xok4.jpeg" width="300"><br>
<br>
  ‚Äì  ,     ¬´¬ª  ( )  ,        . ,         ,    ,      ,         .<br>
<br>
     .    ,       ,     ,   ,     ,    ,    .<br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las competiciones se dividen en dos nominaciones fundamentalmente diferentes entre s√≠: "Buscador" y "Extremo". Esto es para asegurar que la competencia se llevara a cabo entre participantes con una diferencia m√≠nima en edad y experiencia en el desarrollo de sistemas rob√≥ticos: Buscador para el nivel m√°s joven y Extremo para participantes a partir de 14 a√±os de edad. En la nominaci√≥n del Buscador, el operador puede moverse libremente alrededor del rango y tener contacto visual directo con la m√°quina, mientras que la nominaci√≥n Extreme asume que el robot tiene sistemas de comunicaci√≥n por video y / o visi√≥n por computadora, ya que el operador debe navegar en el laberinto, confiando solo en el laberinto La c√°mara y los sensores integrados en el robot, mientras est√° detr√°s de una pantalla especial.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para calificar en las competiciones, el robot debe pasar la tarea de control remoto del manipulador o realizar uno de los elementos de autonom√≠a. </font><font style="vertical-align: inherit;">En el marco del proyecto, la tarea se estableci√≥ para cumplir con las tareas de autonom√≠a, ya que otorgan la mayor cantidad de puntos al menor costo del operador. </font><font style="vertical-align: inherit;">Los elementos de autonom√≠a incluyen:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conducir a lo largo de una l√≠nea con un sensor de luz ambiental o un sistema de l√≠nea de visi√≥n</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Captura de baliza independiente mediante sensores de distancia o sistemas de visi√≥n</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Movimiento a lo largo de una trayectoria compleja (por ejemplo, ascenso / descenso de escaleras) a lo largo de una l√≠nea usando una br√∫jula, giroscopio, aceler√≥metro, sistema de visi√≥n o m√©todos combinados</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s, los puntos para superar obst√°culos se duplican si el robot los supera de forma aut√≥noma.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el marco de este proyecto, se considerar√° la soluci√≥n a la primera de las tareas: movimiento a lo largo de la l√≠nea. Los m√©todos m√°s comunes utilizados al moverse a lo largo de la l√≠nea son sensores de luz y una c√°mara. Las ventajas de los sensores incluyen la simplicidad de crear un programa: muchos de ellos est√°n equipados con una resistencia de sintonizaci√≥n, de modo que al configurar el sensor para la iluminaci√≥n de fondo, dar√° 0 o 1, dependiendo de si est√° en la l√≠nea o no. Por la misma raz√≥n, los sensores de luz no exigen la potencia de procesamiento del controlador utilizado. Adem√°s, debido a esto, resolver el problema con la ayuda de sensores de luz es el menos costoso: el costo del sensor m√°s simple es de 35 rublos, y para un viaje relativamente estable a lo largo de la l√≠nea, tres sensores son suficientes (uno est√° instalado en la l√≠nea y dos en los costados). Sin embargo,Una de las principales desventajas de tales sensores son las restricciones de instalaci√≥n. Idealmente, el sensor debe instalarse exactamente en el centro, a una peque√±a distancia del piso, de lo contrario dar√° valores incorrectos. Esto no es un problema en competiciones especializadas donde el robot debe conducir lo m√°s r√°pido posible a lo largo de la pista, pero, en las condiciones de la competencia "Copa RTK", todos los defectos del sensor mencionados anteriormente pueden ser cr√≠ticos: su instalaci√≥n requiere principalmente la presencia de piezas mec√°nicas adicionales en el robot que elevan y bajando los sensores, y esto requiere espacio adicional en el robot, un motor separado que mueve los sensores, y tambi√©n es un lugar de da√±o potencial y aumenta la masa del robot.de lo contrario, dar√° valores incorrectos. Esto no es un problema en competiciones especializadas donde el robot debe conducir lo m√°s r√°pido posible a lo largo de la pista, pero, en las condiciones de la competencia "Copa RTK", todos los defectos del sensor mencionados anteriormente pueden ser cr√≠ticos: su instalaci√≥n requiere principalmente la presencia de piezas mec√°nicas adicionales en el robot que elevan y bajando los sensores, y esto requiere espacio adicional en el robot, un motor separado que mueve los sensores, y tambi√©n es un lugar de da√±o potencial y aumenta la masa del robot.de lo contrario, dar√° valores incorrectos. Esto no es un problema en competiciones especializadas donde el robot debe conducir lo m√°s r√°pido posible a lo largo de la pista, pero, en las condiciones de la competencia "Copa RTK", todos los defectos del sensor mencionados anteriormente pueden ser cr√≠ticos: su instalaci√≥n requiere principalmente la presencia de piezas mec√°nicas adicionales en el robot que elevan y bajando los sensores, y esto requiere espacio adicional en el robot, un motor separado que mueve los sensores, y tambi√©n es un lugar de da√±o potencial y aumenta la masa del robot.Todos los defectos del sensor mencionados anteriormente pueden ser cr√≠ticos: su instalaci√≥n requiere principalmente la presencia de piezas mec√°nicas adicionales en el robot que elevan y bajan los sensores, y esto requiere espacio adicional en el robot, un motor separado que mueve los sensores, y tambi√©n es un lugar de da√±o potencial y aumenta la masa del robot. .Todos los defectos del sensor mencionados anteriormente pueden ser cr√≠ticos: su instalaci√≥n requiere principalmente la presencia de piezas mec√°nicas adicionales en el robot que elevan y bajan los sensores, y esto requiere espacio adicional en el robot, un motor separado que mueve los sensores, y tambi√©n es un lugar de da√±o potencial y aumenta la masa del robot. .</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><img src="https://habrastorage.org/webt/_g/pt/zz/_gptzzip0rdk6ocgg67ttumux2k.jpeg" width="300" align="right"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La c√°mara, a su vez, tiene las siguientes ventajas: tiene un radio de medici√≥n pr√°cticamente ilimitado (en comparaci√≥n con los sensores), es decir, solo un m√≥dulo de c√°mara puede ver simult√°neamente la l√≠nea, tanto directamente debajo del robot como a una distancia suficiente, lo que permite, por ejemplo, evaluar su curvatura y seleccionar una acci√≥n de control proporcional. Al mismo tiempo, el m√≥dulo de la c√°mara no interfiere con el avance del robot en otras partes del vertedero que no requieren autonom√≠a, ya que la c√°mara se fija a una distancia del piso. El principal inconveniente de la c√°mara es que el procesamiento de video requiere un potente complejo inform√°tico a bordo del robot, y el software que se est√° desarrollando necesita m√°s ajustes, porque la c√°mara recibe un orden de magnitud m√°s informaci√≥n del mundo exterior que tres sensores de luz, mientras que la c√°mara y la computadoracapaces de procesar la informaci√≥n recibida son muchas veces m√°s de tres sensores y "arduins".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para m√≠ personalmente, la respuesta es obvia para m√≠: en la nominaci√≥n "extrema", el robot debe tener una c√°mara direccional, con la cual el operador navegar√°. </font><font style="vertical-align: inherit;">Si utiliza soluciones FPV listas para usar, el costo total de los "sensores" puede ser a√∫n mayor, al tiempo que requiere la instalaci√≥n de dispositivos adicionales. </font><font style="vertical-align: inherit;">Adem√°s, un robot con raspberry pi y una c√°mara tiene un mayor potencial para el desarrollo del movimiento aut√≥nomo, ya que la c√°mara puede resolver una amplia gama de problemas y puede usarse no solo en el movimiento de l√≠nea, sin complicar mucho el dise√±o.</font></font><br>
<br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An√°lisis de algoritmos de visi√≥n por computadora existentes</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La visi√≥n por computadora es la teor√≠a de crear dispositivos que pueden recibir im√°genes de objetos del mundo real, procesar y usar los datos obtenidos para resolver varios tipos de problemas aplicados sin intervenci√≥n humana. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los sistemas de visi√≥n por computadora consisten en:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">una o mas camaras </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">complejo inform√°tico </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Software que proporciona herramientas de procesamiento de im√°genes.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Canales de comunicaci√≥n para transmitir informaci√≥n de objetivos y telemetr√≠a. </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como se escribi√≥ anteriormente, hay muchas formas de identificar objetos de inter√©s para nosotros. En el caso de conducir a lo largo de una l√≠nea, es necesario separar la l√≠nea misma del fondo de contraste (una l√≠nea negra sobre un fondo blanco o una l√≠nea blanca sobre un fondo negro para una l√≠nea inversa). Los algoritmos que utilizan un sistema de visi√≥n por computadora se pueden dividir en varios "pasos" para procesar la imagen original: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adquisici√≥n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de im√°genes: las im√°genes digitales se obtienen directamente de la c√°mara, de una transmisi√≥n de video transmitida al dispositivo o como im√°genes separadas. Los valores de p√≠xeles generalmente corresponden a la intensidad de la luz (im√°genes en color o en escala de grises), pero pueden asociarse con varias mediciones f√≠sicas, como, por ejemplo, la temperatura de una c√°mara termogr√°fica. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Procesamiento preliminar</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: Antes de que los m√©todos de visi√≥n por computadora se puedan aplicar a los datos de video, es necesario el preprocesamiento para introducir ciertas condiciones, dependiendo del m√©todo utilizado. </font><font style="vertical-align: inherit;">Ejemplos son:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eliminar el ruido o la distorsi√≥n causada por el sensor usado</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El desenfoque de la imagen se usa para eliminar peque√±os artefactos que ocurren durante el funcionamiento de la c√°mara, elementos de descompresi√≥n, ruido, etc.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mejorar el contraste para que la informaci√≥n correcta se pueda detectar con mayor probabilidad</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cambiar la exposici√≥n a sombras o reflejos de recorte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Escalado o recorte para distinguir mejor entre las estructuras de la imagen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Convertir una imagen a monocromo o cambiar su resoluci√≥n para un rendimiento m√°s r√°pido del sistema</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Detalles destacados</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : los detalles de la imagen de varios niveles de dificultad se extraen de los datos del video. </font><font style="vertical-align: inherit;">Ejemplos t√≠picos de tales detalles son l√≠neas, bordes, bordes, puntos individuales, √°reas que son caracter√≠sticas de cualquier entidad. </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Detecci√≥n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : en una determinada etapa del trabajo del programa, la informaci√≥n relevante para el programa se separa del resto de la imagen. </font><font style="vertical-align: inherit;">Ejemplos son:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La selecci√≥n de un determinado conjunto de puntos de inter√©s en color, el n√∫mero de p√≠xeles aislados que son similares de alguna manera (curvatura de la figura, color, brillo, etc.)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Segmentaci√≥n de una o m√°s secciones de imagen que contienen un objeto caracter√≠stico.</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Procesamiento de alto nivel</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : en este paso, la abundancia de informaci√≥n de la imagen se reduce a un tama√±o que puede procesarse f√°cilmente, por ejemplo, un conjunto de ciertos p√≠xeles o las coordenadas de la parte de la imagen en la que supuestamente se encuentra el objeto de inter√©s. </font><font style="vertical-align: inherit;">Ejemplos son:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Filtrar valores por cualquier criterio</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Evaluaci√≥n de par√°metros tales como las dimensiones f√≠sicas del objeto, la forma, su ubicaci√≥n en el marco o en relaci√≥n con otros objetos caracter√≠sticos.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Clasificaci√≥n</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A continuaci√≥n, fue necesario elegir la biblioteca en funci√≥n de la cual se crear√° el programa. </font><font style="vertical-align: inherit;">Los factores clave en mi elecci√≥n fueron:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El soporte de la biblioteca para la interfaz de Python debido a la relativa facilidad para que un principiante aprenda este idioma es una sintaxis simple, que tiene un efecto beneficioso sobre la legibilidad del programa.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portabilidad, es decir </font><font style="vertical-align: inherit;">la capacidad de ejecutar un programa usando esta biblioteca en raspberry pi3.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La prevalencia de la biblioteca, que garantiza una comunidad bien desarrollada de programadores que pueden haber encontrado problemas que pueden surgir durante su trabajo.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Entre las opciones que examin√©, destaqu√© la biblioteca de visi√≥n por computadora abierta OpenCV, ya que es compatible con Python, tiene una extensa documentaci√≥n en l√≠nea. </font><font style="vertical-align: inherit;">Hay muchos art√≠culos e instrucciones en Internet que describen todas las sutilezas de trabajar con esta biblioteca. </font><font style="vertical-align: inherit;">Hay un foro oficial de desarrolladores donde cualquiera puede hacer una pregunta al respecto. </font><font style="vertical-align: inherit;">Adem√°s, esta biblioteca se implementa en lenguajes C / C ++, lo que garantiza el rendimiento del sistema, y ‚Äã‚Äãsu estructura admite varios m√≥dulos que se pueden deshabilitar para aumentar el rendimiento.</font></font><br>
<br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desarrollo de software</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de instalar el sistema operativo y la configuraci√≥n inicial de Raspberry pi, pero antes de comenzar a crear el programa, debe instalar todos los paquetes necesarios para ello. </font><font style="vertical-align: inherit;">La mayor√≠a de estos paquetes, a su vez, se instalan utilizando el administrador de paquetes pip (en el caso de Python 3, pip3)</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt install python3-pip</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se instalan las siguientes bibliotecas, como:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">picamera - biblioteca para trabajar con c√°mara raspberry pi</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">numpy: una biblioteca para trabajar con matrices de datos multidimensionales, como im√°genes</font></font></li>
</ul><br>
<pre><code class="bash hljs">$ sudo pip3 install picamera<font></font>
$ sudo pip3 install numpy<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
cmake - Utilidad para construir autom√°ticamente un programa desde el c√≥digo fuente </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
cmake-curses-gui - paquete GUI (interfaz gr√°fica) para cmake</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt-get install cmake cmake-curses-gui libgtk2.0-dev<font></font>
$ sudo apt-get install cmake cmake-curses-gui libgtk2.0-dev<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
bibliotecas para trabajar con diferentes formatos de imagen y video y m√°s</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libx264-dev libxvidcore-dev<font></font>
$ sudo apt-get install libjpeg-dev libpng12-dev libtiff5-dev libjasper-dev<font></font>
$ sudo apt-get install gfortran libatlas-base-dev<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para transmitir datos de video del robot a la computadora, se utilizar√° GStreamer, un marco dise√±ado para recibir, procesar y transmitir datos multimedia:</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt install libgstreamer1.0-0 gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El siguiente paso es instalar la propia biblioteca openCV desde las fuentes, configurarla y compilarla. </font><font style="vertical-align: inherit;">Para hacer esto, se crea una carpeta de trabajo opencv.</font></font><br>
<br>
<pre><code class="bash hljs">$ mkdir opencv<font></font>
$ <span class="hljs-built_in">cd</span> opencv
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para descargar las √∫ltimas versiones de la biblioteca, se utiliza wget, un programa de consola para descargar archivos de la red. </font><font style="vertical-align: inherit;">En el momento de la creaci√≥n del programa, la √∫ltima versi√≥n estable de openCV es 4.1.0, as√≠ que descargue y desempaquete las fuentes:</font></font><br>
<br>
<pre><code class="bash hljs">$ wget https://github.com/opencv/opencv/archive/4.1.0.zip -O opencv_source.zip<font></font>
$ unzip opencv_source.zip<font></font>
$ wget https://github.com/opencv/opencv_contrib/archive/4.1.0.zip -O opencv_contrib.zip<font></font>
$ unzip opencv_contrib.zip<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Una vez que se completa el proceso de desempaquetado, se pueden eliminar los archivos fuente.</font></font><br>
<br>
<pre><code class="bash hljs">$ rm opencv_source.zip<font></font>
$ rm opencv_contrib.zip<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se crea un directorio para el ensamblaje y la configuraci√≥n.</font></font><br>
<br>
<pre><code class="bash hljs">$ <span class="hljs-built_in">cd</span> /home/pi/opencv/opencv-4.1.0<font></font>
$ mkdir build<font></font>
$ <span class="hljs-built_in">cd</span> build
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los par√°metros de compilaci√≥n se configuran utilizando la utilidad cmake. </font><font style="vertical-align: inherit;">Para hacer esto, todos los par√°metros significativos se pasan como variables de utilidad, junto con los valores asignados:</font></font><br>
<br>
<pre><code class="cmake hljs">cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D INSTALL_PYTHON_EXAMPLES=<span class="hljs-keyword">ON</span> -D INSTALL_C_EXAMPLES=<span class="hljs-keyword">OFF</span> -D BUILD_opencv_python2=<span class="hljs-keyword">OFF</span> -D WITH_GSTREAMER=<span class="hljs-keyword">ON</span> -D BUILD_EXAMPLES=<span class="hljs-keyword">ON</span> -DENABLE_VFPV3=<span class="hljs-keyword">ON</span> -DENABLE_NEON=<span class="hljs-keyword">ON</span> -DCPU_BASELINE=NEON ..
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de configurar la configuraci√≥n, la utilidad mostrar√° todos los par√°metros. A continuaci√≥n, debe compilar la biblioteca. Para hacer esto, use el comando de consola make ‚ÄìjN, donde N es el n√∫mero de n√∫cleos que estar√°n involucrados en el proceso de compilaci√≥n. Para raspberry pi 3, el n√∫mero de n√∫cleos es 4, pero definitivamente puede encontrar este n√∫mero escribiendo el comando nproc en la consola.</font></font><br>
<br>
<pre><code class="bash hljs">$ make ‚Äìj4</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debido a los recursos limitados de la frambuesa, la compilaci√≥n puede llevar bastante tiempo. </font><font style="vertical-align: inherit;">En algunos casos, las frambuesas pueden incluso congelarse, pero si luego ingresa a la carpeta de compilaci√≥n y vuelve a registrar make, el trabajo continuar√°. </font><font style="vertical-align: inherit;">Si esto sucede, vale la pena reducir la cantidad de n√∫cleos involucrados, sin embargo, mi compilaci√≥n se realiz√≥ sin problemas. </font><font style="vertical-align: inherit;">Adem√°s, en esta etapa, vale la pena pensar en el enfriamiento activo de la frambuesa, porque incluso con ella, la temperatura del procesador alcanz√≥ unos 75 grados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cuando la compilaci√≥n fue exitosa, la biblioteca necesita ser instalada. </font><font style="vertical-align: inherit;">Esto tambi√©n se hace usando la utilidad make. </font><font style="vertical-align: inherit;">Luego formaremos todas las conexiones necesarias con la utilidad ldconfig:</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo make install<font></font>
$ sudo ldconfig<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Verificamos la instalaci√≥n escribiendo los siguientes comandos en modo interactivo python:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> cv2<font></font>
print(cv2.getBuildInformation())<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La siguiente conclusi√≥n del programa ser√° evidencia de la instalaci√≥n correcta. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/np/vi/ng/npving2rmncveg11-8qxvhvco1q.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debe tenerse en cuenta que el procedimiento anterior para compilar la biblioteca se debe realizar tanto en el robot como en la PC desde la que se planea controlar el robot y en la que se recibir√° la transmisi√≥n del robot. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Crear un esquema de distribuci√≥n de video</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Antes de comenzar a escribir c√≥digo, debe desarrollar un esquema seg√∫n el cual funcionar√° el algoritmo. En el caso considerado de desarrollo de software para un robot creado para participar en las competiciones de la Copa RTK en la nominaci√≥n Extreme, el programa completo se dividir√° en dos partes: un robot y un control remoto, que ser√° jugado por una computadora con Linux instalado. Una de las tareas m√°s importantes aqu√≠ es crear un esquema aproximado de c√≥mo se transmitir√°n los datos de video entre diferentes partes del algoritmo. Wi-Fi se utilizar√° como un canal de comunicaci√≥n entre los dos dispositivos. Los paquetes de datos que proporcionan el control del robot y los datos de retroalimentaci√≥n se transmitir√°n de un dispositivo a otro utilizando el protocolo UDP implementado en la biblioteca de sockets. Datos de videodebido a limitaciones en el tama√±o del paquete UDP se transmitir√° usando GStreamer. Para la conveniencia de la depuraci√≥n, se implementar√°n dos transmisiones de video:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">transmisi√≥n de video principal: transfiere datos de video directamente desde la c√°mara del robot a una computadora para garantizar un retraso de control m√≠nimo.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">transmisi√≥n de video auxiliar: transfiere los datos de video procesados ‚Äã‚Äãpor el robot, necesarios para configurar y depurar un programa que implementa la visi√≥n por computadora.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dos transmisiones de video estar√°n activas simult√°neamente en el robot, y la computadora mostrar√° la imagen deseada dependiendo del modo de manejo habilitado. </font><font style="vertical-align: inherit;">El robot, a su vez, dependiendo de si el modo de autonom√≠a est√° activado o desactivado, utilizar√° los datos de control recibidos de una computadora o generados por un procesador de im√°genes. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/zw/0l/uw/zw0luwrmjjesbm1ygsra6gxtkm4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El control remoto del robot se realizar√° debido al trabajo de dos flujos paralelos en el robot y en la computadora:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La "consola" en un ciclo sondea todos los dispositivos de entrada disponibles y forma un paquete de datos de control que consta de los datos en s√≠ y la suma de verificaci√≥n (al momento de hacer los cambios finales al art√≠culo, me negu√© a crear sumas de verificaci√≥n para reducir el retraso, pero en la fuente, que establecido al final de este fragmento de c√≥digo) - de un cierto valor calculado a partir de un conjunto de datos mediante la operaci√≥n de alg√∫n algoritmo utilizado para determinar la integridad de los datos durante la transmisi√≥n</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robot: espera el acceso a datos desde la computadora. </font><font style="vertical-align: inherit;">Desempaqueta los datos, recalcula la suma de verificaci√≥n y la compara con la enviada y calculada en el lado de la computadora. </font><font style="vertical-align: inherit;">Si las sumas de verificaci√≥n coinciden, los datos se transfieren al programa principal.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Antes de analizar el algoritmo de detecci√≥n de l√≠nea, le sugiero que se familiarice con las caracter√≠sticas de dise√±o del robot:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sobre el robot</font></font></b><div class="spoiler_text">          .<br>
<br>
<img src="https://habrastorage.org/webt/vw/ao/ex/vwaoexwehb49titxcgdis_ryonc.jpeg" width="200" align="right"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"></a> ‚Äî       .      (3  )        .                 ,      .      6 ,        .           .      .          .     ,    -  .     ¬´¬ª   rasberry pi 3 b ‚Äî      .<br>
<br>
<img src="https://habrastorage.org/webt/ho/zw/bi/hozwbiptp_fihoiqncxq2zsbpim.png" width="200" align="left"> ,       ,   ,   ,   Solidworks    petg .    ,     raspberry        .<br>
<br>
<img src="https://habrastorage.org/webt/mh/po/bd/mhpobduedmyoxzrdbhhac2ewdpq.png" width="200" align="left">          ubiquiti bullet M5 hp.     (   )      ,          .   ,   ¬´¬ª  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"> </a> . <br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ti/h_/7l/tih_7l74vjx8leso89cwynfpb3o.jpeg" width="400"></div><br>
:     ¬´¬ª     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">  thingiverse</a>.    ,  ,   ,      ,          .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wd/df/q_/wddfq_nyi7-xcqmdiil5glkybqe.gif" width="300"></div><br>
   ,     ,   .       ,     .              ,  ,        ,     ,    .     ,       ,        ,     .<br>
<br>
<img src="https://habrastorage.org/webt/sl/ju/f9/sljuf9jwaqm2kdadelgsgubyf5o.gif" width="450"><br>
<br>
<img src="https://habrastorage.org/webt/sg/xk/_k/sgxk_kt1f0xdxkg4igwgzmbudk0.png" width="250"><br>
<br>
-     (   -  200 )    ,       ,     90       70   (     ),          ,     ¬´ ¬ª. ,            VL53L0X        ,      .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jq/wh/hc/jqwhhc7et4crpin64qkaw6txgk0.png" width="250"></div><br>
 ¬´¬ª     ,     ,    (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">rds3115</a>).    ‚Äî ,     ,  ,     ,     .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/4p/ot/ic/4poticuqt_itsiasls1of3927ma.jpeg" width="250"></div><br>
      ,      ,    ,   :<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qc/w5/ol/qcw5olk3klaxq75typuz41hdt18.png" width="250"></div><br>
- ,       ,          ,      .           . <img src="https://habrastorage.org/webt/he/4o/kp/he4okpaqyd5pof9x1cjwc1aalwi.jpeg" width="200" align="left">        raspberry,      ,     .       ,      .<br>
<br>
     ,   USB.            ,            ,     .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/wv/yr/rqwvyr8kv5dtvpgz6x7rahoyfho.gif" width="200"></div><br>
<i>        </i><br>
</div></div><br>
<h3><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creaci√≥n de un algoritmo de detecci√≥n de l√≠nea utilizando m√©todos de biblioteca OpenCV.</font></font></font></h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I. Obtenci√≥n de datos</font></font></b> <br>
<br>
<img src="https://habrastorage.org/webt/ua/q7/zo/uaq7zojtflqtezqkiq2meem5mam.png" width="300" align="right"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Debido al hecho de que el procesador de imagen no recibe datos de video directamente de la c√°mara, sino de la transmisi√≥n principal, es necesario transferirlos del formato utilizado para la traducci√≥n al formato utilizado para el procesamiento de im√°genes, es decir, una matriz numpy que consiste en valores rojos. , verde y azul para cada uno de los p√≠xeles. </font><font style="vertical-align: inherit;">Para hacer esto, necesita los datos iniciales: un marco recibido del m√≥dulo de c√°mara raspberry pi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La forma m√°s f√°cil de obtener cuadros de la c√°mara c para su posterior procesamiento es utilizar la biblioteca picamera. </font><font style="vertical-align: inherit;">Antes de comenzar, debe permitir el acceso a la c√°mara a trav√©s de raspi-config -&gt; c√°mara de opciones de interfaz -&gt; seleccione s√≠.</font></font><br>
<br>
<pre><code class="bash hljs">sudo raspi-config</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
la siguiente secci√≥n de c√≥digo est√° conectada a la c√°mara de frambuesa y en un ciclo con una frecuencia dada recibe fotogramas en forma de matriz listos para su uso por la biblioteca opencv.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> picamera.array <span class="hljs-keyword">import</span> PiRGBArray
<span class="hljs-keyword">from</span> picamera <span class="hljs-keyword">import</span> PiCamera
<span class="hljs-keyword">import</span> cv2
<span class="hljs-comment">#   </span><font></font>
camera = PiCamera()<font></font>
camera.resolution = (<span class="hljs-number">640</span>, <span class="hljs-number">480</span>) <font></font>
camera.framerate = <span class="hljs-number">30</span>
cap = PiRGBArray(camera, size=(<span class="hljs-number">640</span>, <span class="hljs-number">480</span>))<font></font>
<font></font>
<span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> camera.capture_continuous(cap , format=<span class="hljs-string">"bgr"</span>, use_video_port=<span class="hljs-literal">True</span>):<font></font>
	new_frame = frame.array<font></font>
	cap.truncate(<span class="hljs-number">0</span>)
	<span class="hljs-keyword">if</span> <span class="hljs-literal">False</span>: <span class="hljs-comment">#   -   </span>
		<span class="hljs-keyword">break</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tambi√©n vale la pena se√±alar que este m√©todo de captura de cuadros, aunque es el m√°s simple, tiene un serio inconveniente: no es muy efectivo si necesita transmitir cuadros a trav√©s de GStreamer, ya que esto requiere varias veces para volver a codificar el video, lo que reduce la velocidad del programa. </font><font style="vertical-align: inherit;">Una forma mucho m√°s r√°pida de obtener im√°genes ser√° generar cuadros del flujo de video a pedido del procesador de im√°genes, sin embargo, las etapas posteriores del procesamiento de im√°genes no depender√°n del m√©todo utilizado. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un ejemplo de una imagen de una c√°mara de rumbo de robot sin procesamiento:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/bo/yi/ez/boyiezf6vfa1nqrlcdllhwbmsgg.png" width="350"></div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">II Preprocesamiento</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Al conducir en una l√≠nea, ser√° m√°s sencillo separar el √°rea de puntos que m√°s contraste con el color de fondo. Este m√©todo es ideal para la competencia de la Copa RTK, ya que utiliza una l√≠nea negra sobre un fondo blanco (o una l√≠nea blanca sobre un fondo negro para las secciones inversas). Para reducir la cantidad de informaci√≥n que debe procesarse, puede aplicarle un algoritmo de binarizaci√≥n, es decir, convertir la imagen a un formato monocromo, donde solo hay dos tipos de p√≠xeles: oscuro y claro. Antes de esto, la imagen debe traducirse a escala de grises, y tambi√©n desenfocarla para cortar peque√±os defectos y ruidos que inevitablemente aparecen durante el funcionamiento de la c√°mara. Para desenfocar la imagen, se utiliza un filtro gaussiano.</font></font><br>
<br>
<pre><code class="python hljs">gray = cv2.cvtColor(self._frame, cv2.COLOR_RGB2GRAY)<font></font>
blur = cv2.GaussianBlur(gray, (ksize, ksize), <span class="hljs-number">0</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
donde ksize es el tama√±o del n√∫cleo gaussiano, lo que aumenta el grado de desenfoque. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imagen de ejemplo despu√©s de la traducci√≥n en escala de grises y desenfoque:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/5h/_d/ye5h_d7dqttbxo_af3hhkxnllce.png" width="350"></div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">III. </font><font style="vertical-align: inherit;">Selecci√≥n de detalles</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Despu√©s de traducir la imagen en escala de grises, es necesario binarizarla en un umbral determinado. </font><font style="vertical-align: inherit;">Esta acci√≥n le permite reducir a√∫n m√°s la cantidad de datos. Este valor umbral se ajustar√° antes de cada partida del robot en un nuevo lugar, o cuando cambien las condiciones de iluminaci√≥n. </font><font style="vertical-align: inherit;">Idealmente, la tarea de calibraci√≥n es asegurarse de que el contorno de la l√≠nea est√© definido en la imagen, pero al mismo tiempo, no debe haber otros detalles en la imagen que no sean una l√≠nea:</font></font><br>
<br>
<pre><code class="python hljs">thresh = cv2.threshold(blur, self._limit, <span class="hljs-number">255</span>, cv2.THRESH_BINARY_INV)[<span class="hljs-number">1</span>]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqu√≠, todos los p√≠xeles m√°s oscuros que el valor umbral (self._limit) se reemplazan por 0 (negro), m√°s claro - por 255 (blanco). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s del procesamiento, la imagen se ve de la siguiente manera:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ne/rq/tl/nerqtlzt7p-k0q-4quw6nhsbfau.png" width="350"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como puede ver, el programa ha identificado varias de las partes m√°s oscuras de la imagen. </font><font style="vertical-align: inherit;">Sin embargo, despu√©s de calibrar el valor umbral para "atrapar" completamente los auriculares, aparecen otros elementos blancos en la pantalla adem√°s de ellos. </font><font style="vertical-align: inherit;">Por supuesto, puede ajustar el umbral, y la c√°mara mirar√° hacia el campo de entrenamiento competitivo, sin permitir elementos innecesarios en el marco, pero considero que es necesario que separe la l√≠nea de todo lo dem√°s. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IV.Detecci√≥n</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En la imagen binarizada, apliqu√© un algoritmo de b√∫squeda de bordes. </font><font style="vertical-align: inherit;">Es necesario para determinar puntos independientes y convertirlos en una conveniente matriz de valores de coordenadas de puntos que conforman el borde. </font><font style="vertical-align: inherit;">En el caso de opencv, como est√° escrito en la documentaci√≥n, el algoritmo est√°ndar para encontrar bucles usa el algoritmo Suzuki85 (no pude encontrar referencias al algoritmo con este nombre en ninguna parte excepto la documentaci√≥n de opencv, pero supondr√© que este es el algoritmo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suzuki-Abe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<pre><code class="python hljs">contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[<span class="hljs-number">0</span>]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y aqu√≠ est√° el marco obtenido en esta etapa:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ex/3r/gx/ex3rgxc7bmefqdwhetn5wfxrtko.png" width="350"></div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">V. Procesamiento de alto nivel</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de encontrar todos los contornos en el marco, se selecciona el contorno con el √°rea m√°s grande y se toma como el contorno de la l√≠nea. Conociendo las coordenadas de todos los puntos de este contorno, se encuentra la coordenada de su centro. Para esto, se utilizan los llamados "momentos de imagen". El momento es la caracter√≠stica total del contorno, calculada sumando las coordenadas de todos los p√≠xeles del contorno. Hay varios tipos de momentos, hasta el tercer orden. Para este problema, solo se necesita el momento de orden cero (m00): el n√∫mero de todos los puntos que forman el contorno (per√≠metro del contorno), el momento de primer orden (m10), que es la suma de las coordenadas X de todos los puntos, y m01 es la suma de las coordenadas Y de todos los puntos. Al dividir la suma de las coordenadas de los puntos a lo largo de uno de los ejes por su n√∫mero, se obtiene la media aritm√©tica, la coordenada aproximada del centro del contorno. A continuaci√≥n, se calcula la desviaci√≥n del robot del curso:el curso "directamente" corresponde a la coordenada del punto central a lo largo de X cerca del ancho del marco dividido por dos. Si la coordenada del centro de la l√≠nea est√° cerca del centro del cuadro, la acci√≥n de control es m√≠nima y, en consecuencia, el robot conserva su curso actual. Si el robot se desv√≠a de uno de los lados, se introducir√° una acci√≥n de control proporcional a la desviaci√≥n hasta que regrese.</font></font><br>
<br>
<pre><code class="python hljs">mainContour = max(contours, key = cv2.contourArea)<font></font>
M = cv2.moments(mainContour)<font></font>
<span class="hljs-keyword">if</span> M[<span class="hljs-string">'m00'</span>] != <span class="hljs-number">0</span>:<span class="hljs-comment">#     (..   -  )</span>
    cx = int(M[<span class="hljs-string">'m10'</span>]/M[<span class="hljs-string">'m00'</span>])<font></font>
    cy = int(M[<span class="hljs-string">'m01'</span>]/M[<span class="hljs-string">'m00'</span>])
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A continuaci√≥n se muestra un dibujo esquem√°tico de la posici√≥n del robot con respecto a la l√≠nea y los marcos, con los resultados del programa superpuestos en ellos: el contorno "principal", las l√≠neas que pasan por el centro del contorno, as√≠ como el punto ubicado en el centro para estimar la desviaci√≥n. </font><font style="vertical-align: inherit;">Estos elementos se agregan usando el siguiente c√≥digo:</font></font><br>
<br>
<pre><code class="python hljs">cv2.line(frame, (cx, <span class="hljs-number">0</span>), (cx, self.height), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)    <span class="hljs-comment">#    </span>
cv2.line(frame, (<span class="hljs-number">0</span>, cy), (self.width, cy), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)                  <font></font>
cv2.circle(frame, (self.width//<span class="hljs-number">2</span>, self.height//<span class="hljs-number">2</span>), <span class="hljs-number">3</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">-1</span>) <span class="hljs-comment">#  </span>
cv2.drawContours(frame, mainContour, <span class="hljs-number">-1</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-number">2</span>, cv2.FILLED) <span class="hljs-comment">#   </span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para la conveniencia de la depuraci√≥n, todos los elementos descritos anteriormente se agregan al cuadro sin procesar: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/f4/fl/os/f4flos522ouvlu-vi2b9rr_17lg.png" width="350"><br>
<br>
<img src="https://habrastorage.org/webt/uc/r1/vx/ucr1vxcecjqdv5qdswcbjsltw9w.png" width="350"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo tanto, despu√©s de conducir el cuadro a trav√©s del algoritmo de procesamiento, obtuvimos las coordenadas X e Y del centro del objeto de inter√©s para nosotros, as√≠ como la imagen de depuraci√≥n. </font><font style="vertical-align: inherit;">A continuaci√≥n, se muestra esquem√°ticamente la posici√≥n del robot con respecto a la l√≠nea, as√≠ como la imagen que ha pasado el algoritmo de procesamiento.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/4r/co/fy/4rcofyknawjnesluhuvoyp9zomu.jpeg" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El siguiente paso en el programa es convertir la informaci√≥n obtenida en el paso anterior en los valores de potencia de dos motores. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/io/s3/gn/ios3gnw-mt2xsmvh_hsfrpsdkdu.jpeg" width="250" align="right"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La forma m√°s f√°cil de convertir la diferencia entre el desplazamiento del centro de la mancha de color con respecto al centro del cuadro es el regulador proporcional (tambi√©n hay un regulador de rel√©, pero, debido a las caracter√≠sticas de su funcionamiento, no es muy adecuado para conducir a lo largo de la l√≠nea). El principio de funcionamiento de dicho algoritmo es que el controlador genera una acci√≥n de control sobre el objeto en proporci√≥n a la magnitud del error. Adem√°s del controlador proporcional, tambi√©n hay uno integral, donde con el tiempo el componente integral "acumula" el error y el diferencial, cuyo principio se basa en la aplicaci√≥n de la acci√≥n reguladora solo con un cambio suficiente en la variable controlada. En la pr√°ctica, estos controladores P, I, D m√°s simples se combinan en controladores del tipo PI, PD, PID.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vale la pena mencionar que en mi robot trat√© de "iniciar" el controlador PID, pero su uso no dio ninguna ventaja seria sobre el controlador proporcional habitual. Admito que no pude ajustar correctamente el regulador, pero tambi√©n es posible que sus ventajas no sean tan claramente visibles en el caso de un robot pesado que no puede desarrollar f√≠sicamente altas velocidades. En la √∫ltima versi√≥n del programa al momento de escribir, se usa un regulador proporcional simple, pero con una peque√±a caracter√≠stica que le permite usar m√°s informaci√≥n de la c√°mara: al generar el valor de error, no solo se tuvo en cuenta la posici√≥n horizontal del centro del punto, sino tambi√©n la vertical, que permiti√≥ diferentes responder a elementos de l√≠neaubicado "en la distancia" e inmediatamente enfrente o debajo del robot (la c√°mara de rumbo del robot tiene un √°ngulo de visi√≥n enorme, por lo que al girarla solo 45 grados hacia abajo, ya puede ver una parte significativa del campo debajo del robot).</font></font><br>
<br>
<pre><code class="python hljs">error= cx / (self.width/<span class="hljs-number">2</span>) - <span class="hljs-number">1</span>  
<span class="hljs-comment">#  ( 0   )  [-1; 1]</span>
error*= cy / self.height + self.gain <span class="hljs-comment">#</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Muy a menudo, en las condiciones de la competencia "Copa RTK", los participantes usan el llamado "circuito de tanque": uno o m√°s motores controlan un lado del robot y funciona tanto con orugas como con ruedas. El uso de este esquema le permite deshacerse de elementos de transmisi√≥n complejos que aumentan la posibilidad de rotura (diferenciales o ejes card√°n), obtener el radio de giro m√°s peque√±o posible, lo que le da una ventaja en un pol√≠gono confinado. Este esquema implica el control paralelo de dos "lados" para el movimiento a lo largo de un camino complejo. Para hacer esto, el programa utiliza dos variables: la potencia del motor derecho e izquierdo. Esta potencia depende de la velocidad base (BASE_SPEED), que var√≠a en el rango de 0 a 100.Errores (error): la diferencia entre el centro del marco y la coordenada del medio de la l√≠nea y el coeficiente de efecto proporcional (self._koof), que es calibrado por el operador. Su valor absoluto afecta la rapidez con la que el robot intentar√° alinearse con la l√≠nea. Debido al hecho de que en un motor la acci√≥n de control se resta de la velocidad base, y en el otro, se agrega, se realiza un giro cuando se desv√≠a del curso. La direcci√≥n en la que se realizar√° la inversi√≥n se puede ajustar cambiando el signo de la variable self._koof. Adem√°s, puede observar que como resultado de la siguiente secci√≥n de c√≥digo, puede aparecer un valor de potencia que es m√°s de 100, pero en mi programa, estos casos se procesan adicionalmente m√°s adelante.Su valor absoluto afecta la rapidez con la que el robot intentar√° alinearse con la l√≠nea. Debido al hecho de que en un motor la acci√≥n de control se resta de la velocidad base, y en el otro, se agrega, se realiza un giro cuando se desv√≠a del curso. La direcci√≥n en la que se realizar√° la inversi√≥n se puede ajustar cambiando el signo de la variable self._koof. Adem√°s, puede observar que como resultado de la siguiente secci√≥n de c√≥digo, puede aparecer un valor de potencia que es m√°s de 100, pero en mi programa, estos casos se procesan adicionalmente m√°s adelante.Su valor absoluto afecta la rapidez con la que el robot intentar√° alinearse con la l√≠nea. Debido al hecho de que en un motor la acci√≥n de control se resta de la velocidad base, y en el otro, se agrega, se realiza un giro cuando se desv√≠a del curso. La direcci√≥n en la que se realizar√° la inversi√≥n se puede ajustar cambiando el signo de la variable self._koof. Adem√°s, puede observar que como resultado de la siguiente secci√≥n de c√≥digo, puede aparecer un valor de potencia que es m√°s de 100, pero en mi programa, estos casos se procesan adicionalmente m√°s adelante.en el que se realizar√° la inversi√≥n, puede ajustar cambiando el signo de la variable self._koof. Adem√°s, puede observar que como resultado de la siguiente secci√≥n de c√≥digo, puede aparecer un valor de potencia que es m√°s de 100, pero en mi programa, estos casos se procesan adicionalmente m√°s adelante.en el que se realizar√° la inversi√≥n, puede ajustar cambiando el signo de la variable self._koof. Adem√°s, puede observar que como resultado de la siguiente secci√≥n de c√≥digo, puede aparecer un valor de potencia que es m√°s de 100, pero en mi programa, estos casos se procesan adicionalmente m√°s adelante.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#if lineFound:</span><font></font>
leftSpeed = round(self.base_speed + error*self.koof)<font></font>
rightSpeed = round(self.base_speed - error*self.koof)<font></font>
</code></pre><br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusi√≥n</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de probar el programa resultante, puedo decir que el momento dif√≠cil principal en la configuraci√≥n del programa es la calibraci√≥n del algoritmo a las caracter√≠sticas de iluminaci√≥n. </font><font style="vertical-align: inherit;">Como la etapa de creaci√≥n del art√≠culo coincidi√≥ con el autoaislamiento declarado, tuve que crear un video con una demostraci√≥n de trabajo en una habitaci√≥n peque√±a. </font><font style="vertical-align: inherit;">Esto me puso las siguientes dificultades:</font></font><br>
<br>
<ul>
<li> -,    ,    (   ,     ),        .        ,    ,         ,      .      ,     , ,            ,              </li>
<li> -,       ‚Äî    ,   ,         </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A pesar de que ambos problemas est√°n ausentes en las condiciones de las competencias reales, tomar√© medidas para asegurar que el trabajo del programa dependa m√≠nimamente de factores externos. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s, en el futuro se planea continuar trabajando en la implementaci√≥n de algoritmos utilizando m√©todos de visi√≥n por computadora, creando software capaz de pasar por los elementos restantes de autonom√≠a descritos en la primera parte del art√≠culo (captura de balizas aut√≥nomas, movimiento a lo largo de un camino complejo). Se planea expandir la funcionalidad del robot agregando sensores adicionales: tel√©metro, giroscopio-aceler√≥metro, br√∫jula. A pesar de que la publicaci√≥n de este art√≠culo terminar√° mi trabajo en el proyecto como una asignatura obligatoria, planeo continuar describiendo aqu√≠ las etapas posteriores de desarrollo. Por lo tanto, me gustar√≠a recibir comentarios sobre este trabajo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de implementar todos los pasos destinados a resolver los problemas del proyecto, es seguro decir que el uso de algoritmos de visi√≥n por computadora, con toda su relativa complejidad en la programaci√≥n y depuraci√≥n, brinda la mayor ganancia en la etapa de las competiciones. Con las peque√±as dimensiones de la c√°mara, tiene un enorme potencial en t√©rminos de desarrollo de software, porque la c√°mara le permite reemplazar varios sensores "tradicionales" a la vez, mientras recibe incre√≠blemente m√°s informaci√≥n del mundo exterior. Fue posible alcanzar el objetivo del proyecto: crear un programa que utilice la visi√≥n por computadora para resolver el problema de la navegaci√≥n aut√≥noma del robot en las condiciones de la competencia "Copa RTK", as√≠ como describir el proceso de creaci√≥n del programa y las etapas principales en el procesamiento de im√°genes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como dije antes, sin embargo, no fue posible recrear la compleja trayectoria de la l√≠nea de la casa, y este ejemplo muestra c√≥mo el algoritmo cumple con los giros. </font><font style="vertical-align: inherit;">El grosor de la l√≠nea aqu√≠ corresponde al de acuerdo con las regulaciones, y la mayor curva de las curvas refleja aproximadamente la curvatura de rotaci√≥n en 90 grados en el pol√≠gono:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/YmHk3f-qQ5E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Puede ver el c√≥digo del programa, as√≠ como monitorear el trabajo adicional en el proyecto, en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mi github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> o aqu√≠, si contin√∫o.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es497286/index.html">Ludum Dare: lista de verificaci√≥n una semana antes del comienzo</a></li>
<li><a href="../es497288/index.html">Plaf√≥n decorativo Feron AL5000</a></li>
<li><a href="../es497290/index.html">Mejora del rendimiento con el cach√© uop en Sandy Bridge +</a></li>
<li><a href="../es497292/index.html">Technology Stack Shiro Games</a></li>
<li><a href="../es497296/index.html">Errores populares en ingl√©s entre los profesionales de TI. Parte 2: Pronunciaci√≥n</a></li>
<li><a href="../es497304/index.html">Intercepter-NG 2.5 lanzado para Android</a></li>
<li><a href="../es497306/index.html">Suplantaci√≥n de DLL (secuestro de DLL)</a></li>
<li><a href="../es497308/index.html">¬øPuede la inteligencia artificial hacer arte?</a></li>
<li><a href="../es497310/index.html">Redes morfol√≥gicas bipolares: una neurona sin multiplicaci√≥n</a></li>
<li><a href="../es497312/index.html">Pregunta acerca de CAN FD</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
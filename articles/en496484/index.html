<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóÇÔ∏è üé¥ üéÑ Selection of the importance of features for k-nearest neighbors (well, or other hyperparameters) by descent similar to gradient ‚Ü™Ô∏è ‚ô®Ô∏è üí∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Experimenting with the simplest task of machine learning, I found that it would be interesting to select 18 hyperparameters at the same time in a fair...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Selection of the importance of features for k-nearest neighbors (well, or other hyperparameters) by descent similar to gradient</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/496484/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/eg/qm/x6/egqmx63h8mgrbxfytg9nmuaby-g.gif" alt="A true nonsense can not only fulfill the impossible, but also serve as a warning example"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Experimenting with the simplest task of machine learning, I found that it would be interesting to select 18 hyperparameters at the same time in a fairly wide range. In my case, everything was so simple that the task could be taken with brute computer power. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When learning something, it can be very interesting to invent some kind of bicycle. Sometimes it turns out to really come up with something new. Sometimes it turns out that everything was invented before me. But even if I just repeat the path traveled long before me, as a reward I often get an understanding of the underlying mechanisms of the algorithms of their capabilities and internal limitations. To which I invite you.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Python and DS, to put it mildly, I am a beginner, and I do many things that can be implemented into one team according to my old programming habit, which Python punishes by slowing down, not at times, but by orders of magnitude. </font><font style="vertical-align: inherit;">Therefore, I upload all my code to the repository. </font><font style="vertical-align: inherit;">If you know how to implement it much more efficiently - do not be shy, edit there, or write in the comments. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://github.com/kraidiky/GDforHyperparameters</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Those who are already a cool datasatanist and have tried everything in this life will be interesting, I believe, a visualization of the learning process, which is applicable not only to this task.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Formulation of the problem</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is such a good DS course from ODS.ai and there is the third lecture </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification, decision trees and the method of nearest neighbors</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">There, it is shown on extremely simple and probably synthetic data how the simplest decision tree gives an accuracy of 94.5%, and the same extremely simple method of k nearest neighbors gives 89% without any preprocessing</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Import and load data</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> warnings<font></font>
warnings.filterwarnings(<span class="hljs-string">'ignore'</span>)<font></font>
<font></font>
df = pd.read_csv(<span class="hljs-string">'data/telecom_churn.csv'</span>)<font></font>
df[<span class="hljs-string">'Voice mail plan'</span>] = pd.factorize(df[<span class="hljs-string">'Voice mail plan'</span>])[<span class="hljs-number">0</span>]<font></font>
df[<span class="hljs-string">'International plan'</span>] = pd.factorize(df[<span class="hljs-string">'International plan'</span>])[<span class="hljs-number">0</span>]<font></font>
df[<span class="hljs-string">'Churn'</span>] = df[<span class="hljs-string">'Churn'</span>].astype(<span class="hljs-string">'int32'</span>)<font></font>
states = df[<span class="hljs-string">'State'</span>]<font></font>
y = df[<span class="hljs-string">'Churn'</span>]<font></font>
df.drop([<span class="hljs-string">'State'</span>,<span class="hljs-string">'Churn'</span>], axis = <span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<font></font>
df.head()<font></font>
</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Compare wood with knn</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split, StratifiedKFold
<span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV, cross_val_score
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<font></font>
<font></font>
X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=<span class="hljs-number">0.3</span>,<font></font>
random_state=<span class="hljs-number">17</span>)<font></font>
<font></font>
tree = DecisionTreeClassifier(random_state=<span class="hljs-number">17</span>, max_depth=<span class="hljs-number">5</span>)<font></font>
knn = KNeighborsClassifier(n_neighbors=<span class="hljs-number">10</span>)<font></font>
<font></font>
tree_params = {<span class="hljs-string">'max_depth'</span>: range(<span class="hljs-number">1</span>,<span class="hljs-number">11</span>), <span class="hljs-string">'max_features'</span>: range(<span class="hljs-number">4</span>,<span class="hljs-number">19</span>)}<font></font>
tree_grid = GridSearchCV(tree, tree_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
tree_grid.fit(X_train, y_train)<font></font>
tree_grid.best_params_, tree_grid.best_score_, accuracy_score(y_holdout, tree_grid.predict(X_holdout))<font></font>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'max_depth': 6, 'max_features': 16}, 0.944706386626661, 0.945)</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">same for knn</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
<font></font>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_jobs=<span class="hljs-number">-1</span>))])<font></font>
knn_params = {<span class="hljs-string">'knn__n_neighbors'</span>: range(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)}<font></font>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))<font></font>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'knn__n_neighbors': 9}, 0.8868409772824689, 0.891) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At this point, I felt sorry for knn that was obviously dishonest, because we had no work with the metric. </font><font style="vertical-align: inherit;">I did not think with my brain, I took feature_importances_ from the tree and normalized the input to it. </font><font style="vertical-align: inherit;">Thus, the more important the feature, the greater its contribution is the distance between points.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We feed the data normalized to the importance of features</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
feature_importances = pd.DataFrame({<span class="hljs-string">'features'</span>: df.columns, <span class="hljs-string">'importance'</span>:tree_grid.best_estimator_.feature_importances_})<font></font>
print(feature_importances.sort_values(by=[<span class="hljs-string">'importance'</span>], inplace=<span class="hljs-literal">False</span>, ascending=<span class="hljs-literal">False</span>))<font></font>
<font></font>
scaler = StandardScaler().fit(X_train)<font></font>
X_train_transformed = scaler.transform(X_train)<font></font>
X_train_transformed = X_train_transformed * np.array(feature_importances[<span class="hljs-string">'importance'</span>])<font></font>
<font></font>
X_holdout_transformed = scaler.transform(X_holdout)<font></font>
X_holdout_transformed = X_holdout_transformed * np.array(feature_importances[<span class="hljs-string">'importance'</span>])<font></font>
<font></font>
knn_grid = GridSearchCV(KNeighborsClassifier(n_jobs=<span class="hljs-number">-1</span>), {<span class="hljs-string">'n_neighbors'</span>: range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">2</span>)}, cv=<span class="hljs-number">5</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
knn_grid.fit(X_train_transformed, y_train)<font></font>
<span class="hljs-keyword">print</span> (knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout_transformed)))
</code></pre></div></div><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total day minutes</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.270386</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">17</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Customer service calls</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.147185</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total eve minutes</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.135475</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">International plan</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.097249</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sixteen</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total intl charge</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.091671</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fifteen</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total intl calls</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">09.090008</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Number vmail messages</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.050646</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total eve charge</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.038593</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total day charge</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.026422</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voice mail plan</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.017068</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eleven</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total night minutes</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.014185</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">thirteen</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total night charge</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.005742</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">12</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total night calls</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.005502</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total eve calls</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.003614</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total day calls</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.002246</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total intl minutes</font></font></td>
<td>0.002009</td>
</tr>
<tr>
<td>0</td>
<td>Account length</td>
<td>0.001998</td>
</tr>
<tr>
<td>1</td>
<td>Area code</td>
<td>0.000000</td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{'n_neighbors': 5} 0.909129875696528 0.913 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The tree just shared a little bit of knowledge with knn and now we see 91%. That is not so far from 94.5% of the vanilla tree. And then an idea came to me. But how, in fact, do we need to normalize the input so that knn shows the best result? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, we‚Äôll estimate in our mind how much this will now be considered ‚Äúforehead‚Äù. 18 parameters, for each we make, say, 10 possible steps of the factors in the logarithmic scale. We get 10e18 options. One option with all the possible odd number of neighbors is less than 10 and cross-validation is also 10, I think about 1.5 seconds. It turns out 42 billion years. Perhaps the idea of ‚Äã‚Äãleaving the reckoning for the night will have to be abandoned. :) And somewhere around here I thought, ‚ÄúHey! So I'll make a bike that will fly! ‚Äù</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gradient Search</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, this task most likely has only one maximum available. </font><font style="vertical-align: inherit;">Well, that is not one of course, a whole area of ‚Äã‚Äãgood results, but they are pretty much alike. </font><font style="vertical-align: inherit;">Therefore, we can just walk along the gradient and find the most suitable point. </font><font style="vertical-align: inherit;">The first thought was to generalize the genetic algorithm, but here the adaptive terrain does not seem to be very crossed, and this would be a little bit overkill.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I will try to do it manually for a start. </font><font style="vertical-align: inherit;">To push factors as hyperparameters, I need to deal with scalers. </font><font style="vertical-align: inherit;">In the previous example, as in the lesson, I used StandartScaler, which centered the training sample on average and made sigma = 1. In order to scale it nicely inside the pipeline, the hyperparameter has to be made a little trickier. </font><font style="vertical-align: inherit;">I began to look for something suitable for my case among the converters lying in sklearn.preprocessing, but I did not find anything. </font><font style="vertical-align: inherit;">Therefore, I tried to inherit from StandartScaler by hanging an additional bundle of factors on it.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Class for nominalization and then multiplication by scale slightly compatible with sklearn pipeline</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> TransformerMixin
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StandardAndPoorScaler</span>(<span class="hljs-params">StandardScaler, TransformerMixin</span>):</span>
    <span class="hljs-comment">#normalization = None</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, copy=True, with_mean=True, with_std=True, normalization = None</span>):</span>
        <span class="hljs-comment">#print("new StandardAndPoorScaler(normalization=", normalization.shape if normalization is not None else normalization, ") // ", type(self))</span><font></font>
        self.normalization = normalization<font></font>
        super().__init__(copy, with_mean, with_std)<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, X, y=None</span>):</span>
        <span class="hljs-comment">#print(type(self),".fit(",X.shape, ",", y.shape if y is not None else "&lt;null&gt;",")")</span><font></font>
        super().fit(X, y)<font></font>
        <span class="hljs-keyword">return</span> self
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">partial_fit</span>(<span class="hljs-params">self, X, y=None</span>):</span>
        <span class="hljs-comment">#print(type(self),".partial_fit(",X.shape, ",", y.shape if y is not None else "&lt;null&gt;)")</span><font></font>
        super().partial_fit(X, y)<font></font>
        <span class="hljs-keyword">if</span> self.normalization <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
            self.normalization = np.ones((X.shape[<span class="hljs-number">1</span>]))
        <span class="hljs-keyword">elif</span> type(self.normalization) != np.ndarray:<font></font>
            self.normalization = np.array(self.normalization)<font></font>
        <span class="hljs-keyword">if</span> X.shape[<span class="hljs-number">1</span>] != self.normalization.shape[<span class="hljs-number">0</span>]:
            <span class="hljs-keyword">raise</span> <span class="hljs-string">"X.shape[1]="</span>+X.shape[<span class="hljs-number">1</span>]+<span class="hljs-string">" in equal self.scale.shape[0]="</span>+self.normalization.shape[<span class="hljs-number">0</span>]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transform</span>(<span class="hljs-params">self, X, copy=None</span>):</span>
        <span class="hljs-comment">#print(type(self),".transform(",X.shape,",",copy,").self.normalization", self.normalization)</span><font></font>
        Xresult = super().transform(X, copy)<font></font>
        Xresult *= self.normalization<font></font>
        <span class="hljs-keyword">return</span> Xresult
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_reset</span>(<span class="hljs-params">self</span>):</span>
        <span class="hljs-comment">#print(type(self),"._reset()")</span><font></font>
        super()._reset()<font></font>
    <font></font>
scaler = StandardAndPoorScaler(normalization = feature_importances[<span class="hljs-string">'importance'</span>])<font></font>
scaler.fit(X = X_train, y = <span class="hljs-literal">None</span>)<font></font>
print(scaler.normalization)<font></font>
</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trying to apply this class</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_jobs=<span class="hljs-number">-1</span>))])<font></font>
<font></font>
knn_params = {<span class="hljs-string">'knn__n_neighbors'</span>: range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">4</span>), <span class="hljs-string">'scaler__normalization'</span>: [feature_importances[<span class="hljs-string">'importance'</span>]]}<font></font>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">5</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))<font></font>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'knn__n_neighbors': 5, 'scaler__normalization': Name: importance, dtype: float64}, 0.909558508358337, 0.913) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The result is slightly different from my expectations. Well, that is, in principle, everything works. Just to understand this, I had to reproduce this class with all the guts from scratch in three hours, and only then I realized that print doesn‚Äôt print not because sklearn is somehow wrongly made, but because GridSearchCV creates clones in the main stream , but configures and trains them in other threads. And everything that you print in other streams disappears into oblivion. But if you put n_jobs = 1, then all calls to overridden functions are shown as cute. Knowledge came out very expensive, now you also have it, and you paid for it by reading a tedious article.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Okay, let's move on. </font><font style="vertical-align: inherit;">Now I want to give some variance for each of their parameters, and then give it a little less around the best value, and so on until I get a result similar to reality. </font><font style="vertical-align: inherit;">This will be the first rude baseline of what should eventually get the algorithm of my dreams.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I will form several options for reweighting, differing in several parameters</font></font></b><div class="spoiler_text"><pre><code class="python hljs">feature_base = feature_importances[<span class="hljs-string">'importance'</span>]<font></font>
searchArea = np.array([feature_base - <span class="hljs-number">.05</span>, feature_base, feature_base + <span class="hljs-number">.05</span>])<font></font>
searchArea[searchArea &lt; <span class="hljs-number">0</span>] = <span class="hljs-number">0</span>
searchArea[searchArea &gt; <span class="hljs-number">1</span>] = <span class="hljs-number">1</span>
print(searchArea[<span class="hljs-number">2</span>,:] - searchArea[<span class="hljs-number">0</span>,:])<font></font>
<font></font>
<span class="hljs-keyword">import</span> itertools<font></font>
<font></font>
affected_props = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<font></font>
parametrs_ranges = np.concatenate([<font></font>
    np.linspace(searchArea[<span class="hljs-number">0</span>,affected_props], searchArea[<span class="hljs-number">1</span>,affected_props], <span class="hljs-number">2</span>, endpoint=<span class="hljs-literal">False</span>),<font></font>
    np.linspace(searchArea[<span class="hljs-number">1</span>,affected_props], searchArea[<span class="hljs-number">2</span>,affected_props], <span class="hljs-number">3</span>, endpoint=<span class="hljs-literal">True</span>)]).transpose()<font></font>
<font></font>
print(parametrs_ranges) <span class="hljs-comment">#      .  125 </span>
recombinations = itertools.product(parametrs_ranges[<span class="hljs-number">0</span>],parametrs_ranges[<span class="hljs-number">1</span>],parametrs_ranges[<span class="hljs-number">1</span>])<font></font>
<font></font>
variances = []<font></font>
<span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> recombinations: <span class="hljs-comment">#          ,       Python .</span><font></font>
    varince = feature_base.copy()<font></font>
    varince[affected_props] = item<font></font>
    variances.append(varince)<font></font>
print(variances[<span class="hljs-number">0</span>])<font></font>
print(len(variances))<font></font>
<span class="hljs-comment">#  knn   ,               .</span>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, the data set for the first experiment is ready. </font><font style="vertical-align: inherit;">Now I‚Äôll try to experiment with the data, for a start by exhaustive search of the resulting 15 options.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We make a trial selection of parameters as in the article</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-comment">#scale = np.ones([18])</span>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>))])<font></font>
<font></font>
knn_params = {<span class="hljs-string">'scaler__normalization'</span>: variances} <span class="hljs-comment"># 'knn__n_neighbors': range(3, 9, 2), </span>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, everything is bad, time was spent on a breakthrough, and the result is very unstable. </font><font style="vertical-align: inherit;">This is also seen from the X_holdout check, the result dances like in a kaleidoscope with minor changes to the input data. </font><font style="vertical-align: inherit;">I'll try a different approach. </font><font style="vertical-align: inherit;">I will change only one parameter at a time, but with a much larger discretization.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I change one 4th property</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
affected_property = <span class="hljs-number">4</span><font></font>
parametrs_range = np.concatenate([<font></font>
    np.linspace(searchArea[<span class="hljs-number">0</span>,affected_property], searchArea[<span class="hljs-number">1</span>,affected_property], <span class="hljs-number">29</span>, endpoint=<span class="hljs-literal">False</span>),<font></font>
    np.linspace(searchArea[<span class="hljs-number">1</span>,affected_property], searchArea[<span class="hljs-number">2</span>,affected_property], <span class="hljs-number">30</span>, endpoint=<span class="hljs-literal">True</span>)]).transpose()<font></font>
<font></font>
print(searchArea[<span class="hljs-number">1</span>,affected_property])<font></font>
print(parametrs_range) <span class="hljs-comment"># C   ,  .</span><font></font>
<font></font>
<font></font>
variances = []<font></font>
<span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> parametrs_range: <span class="hljs-comment">#          ,       Python .</span><font></font>
    varince = feature_base.copy()<font></font>
    varince[affected_property] = item<font></font>
    variances.append(varince)<font></font>
print(variances[<span class="hljs-number">0</span>])<font></font>
print(len(variances))<font></font>
<span class="hljs-comment">#  knn   ,               .</span><font></font>
<font></font>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>))])<font></font>
<font></font>
knn_params = {<span class="hljs-string">'scaler__normalization'</span>: variances} <span class="hljs-comment"># 'knn__n_neighbors': range(3, 9, 2), </span>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'scaler__normalization': 4 0.079957 Name: importance, dtype: float64}, 0.9099871410201458, 0.913) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, what do we have with a goose? </font><font style="vertical-align: inherit;">Shifts of one to two tenths of a percent on cross-validation, and a half-percent jump on X_holdout if you look at different affected_property. </font><font style="vertical-align: inherit;">Apparently it is essential and cheap to improve the situation if you start with the fact that the tree gives us it is impossible on such data. </font><font style="vertical-align: inherit;">But suppose that we do not have an initial, known weight distribution, and try to do the same at an arbitrary point in the cycle with tiny steps. </font><font style="vertical-align: inherit;">It‚Äôs very interesting what we‚Äôll come to.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Initial filling</font></font></b><div class="spoiler_text"><pre><code class="python hljs">searchArea = np.array([np.zeros((<span class="hljs-number">18</span>,)), np.ones((<span class="hljs-number">18</span>,)) /<span class="hljs-number">18</span>, np.ones((<span class="hljs-number">18</span>,))])<font></font>
print(searchArea[:,<span class="hljs-number">0</span>])<font></font>
<font></font>
history_parametrs = [searchArea[<span class="hljs-number">1</span>,:].copy()]<font></font>
scaler = StandardAndPoorScaler(normalization=searchArea[<span class="hljs-number">1</span>,:])<font></font>
scaler.fit(X_train)<font></font>
knn = KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>)<font></font>
knn.fit(scaler.transform(X_train), y_train)<font></font>
history_holdout_score = [accuracy_score(y_holdout, knn.predict(scaler.transform(X_holdout)))]</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Function slightly changing one parameter (with debug logs)</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">changePropertyNormalization</span>(<span class="hljs-params">affected_property, points_count = <span class="hljs-number">15</span></span>):</span><font></font>
    test_range = np.concatenate([<font></font>
        np.linspace(searchArea[<span class="hljs-number">0</span>,affected_property], searchArea[<span class="hljs-number">1</span>,affected_property], points_count//<span class="hljs-number">2</span>, endpoint=<span class="hljs-literal">False</span>),<font></font>
        np.linspace(searchArea[<span class="hljs-number">1</span>,affected_property], searchArea[<span class="hljs-number">2</span>,affected_property], points_count//<span class="hljs-number">2</span> + <span class="hljs-number">1</span>, endpoint=<span class="hljs-literal">True</span>)]).transpose()<font></font>
    variances = [searchArea[<span class="hljs-number">1</span>,:].copy() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(test_range.shape[<span class="hljs-number">0</span>])]
    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> range(len(variances)):<font></font>
        variances[row][affected_property] = test_range[row]<font></font>
    <font></font>
    knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>))])<font></font>
    knn_params = {<span class="hljs-string">'scaler__normalization'</span>: variances} <span class="hljs-comment"># 'knn__n_neighbors': range(3, 9, 2), </span>
    knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    knn_grid.fit(X_train, y_train)<font></font>
    holdout_score = accuracy_score(y_holdout, knn_grid.predict(X_holdout))<font></font>
    best_param = knn_grid.best_params_[<span class="hljs-string">'scaler__normalization'</span>][affected_property]<font></font>
    print(affected_property,<font></font>
          <span class="hljs-string">'property:'</span>, searchArea[<span class="hljs-number">1</span>, affected_property], <span class="hljs-string">"=&gt;"</span>, best_param,
          <span class="hljs-string">'holdout:'</span>, history_holdout_score[<span class="hljs-number">-1</span>], <span class="hljs-string">"=&gt;"</span>, holdout_score, <span class="hljs-string">'('</span>, knn_grid.best_score_, <span class="hljs-string">')'</span>)
    <span class="hljs-comment">#             .</span><font></font>
    before = searchArea[:, affected_property]<font></font>
    propertySearchArea = searchArea[:, affected_property].copy()<font></font>
    <span class="hljs-keyword">if</span> best_param == propertySearchArea[<span class="hljs-number">0</span>]:<font></font>
        print(<span class="hljs-string">'|&lt;&lt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = best_param/<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> best_param &gt; <span class="hljs-number">0.01</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        searchArea[<span class="hljs-number">2</span>, affected_property] = (best_param + searchArea[<span class="hljs-number">2</span>, affected_property])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param == propertySearchArea[<span class="hljs-number">2</span>]:<font></font>
        print(<span class="hljs-string">'&gt;&gt;|'</span>)<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = (best_param + <span class="hljs-number">1</span>)/<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> best_param &lt; <span class="hljs-number">0.99</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>
        searchArea[<span class="hljs-number">0</span>, affected_property] = (best_param + searchArea[<span class="hljs-number">0</span>, affected_property])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &lt; (propertySearchArea[<span class="hljs-number">0</span>] + propertySearchArea[<span class="hljs-number">1</span>])/<span class="hljs-number">2</span>:<font></font>
        print(<span class="hljs-string">'&lt;&lt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = max(propertySearchArea[<span class="hljs-number">0</span>]*<span class="hljs-number">1.1</span> - <span class="hljs-number">.1</span>*propertySearchArea[<span class="hljs-number">1</span>], <span class="hljs-number">0</span>)<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = (best_param + propertySearchArea[<span class="hljs-number">2</span>])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &gt; (propertySearchArea[<span class="hljs-number">1</span>] + propertySearchArea[<span class="hljs-number">2</span>])/<span class="hljs-number">2</span>:<font></font>
        print(<span class="hljs-string">'&gt;&gt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = (best_param + propertySearchArea[<span class="hljs-number">0</span>])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">2</span>, affected_property] = min(propertySearchArea[<span class="hljs-number">2</span>]*<span class="hljs-number">1.1</span> - <span class="hljs-number">.1</span>*propertySearchArea[<span class="hljs-number">1</span>], <span class="hljs-number">1</span>)<font></font>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &lt; propertySearchArea[<span class="hljs-number">1</span>]:<font></font>
        print(<span class="hljs-string">'&lt;'</span>)<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">2</span>, affected_property]<font></font>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &gt; propertySearchArea[<span class="hljs-number">1</span>]:<font></font>
        print(<span class="hljs-string">'&gt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">0</span>, affected_property]<font></font>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">else</span>:<font></font>
        print(<span class="hljs-string">'='</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">0</span>, affected_property]<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">2</span>, affected_property]<font></font>
    normalization = searchArea[<span class="hljs-number">1</span>,:].sum() <span class="hljs-comment">#,      .</span><font></font>
    searchArea[:,:] /= normalization<font></font>
    print(before, <span class="hljs-string">"=&gt;"</span>,searchArea[:, affected_property])<font></font>
    history_parametrs.append(searchArea[<span class="hljs-number">1</span>,:].copy())<font></font>
    history_holdout_score.append(holdout_score)<font></font>
    <font></font>
changePropertyNormalization(<span class="hljs-number">1</span>, <span class="hljs-number">9</span>)<font></font>
changePropertyNormalization(<span class="hljs-number">1</span>, <span class="hljs-number">9</span>)
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I didn‚Äôt optimize anything anywhere, and as a result, I took the next decisive step for almost half an hour:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hidden text</font></font></b><div class="spoiler_text">       40 .<pre><code class="python hljs">%%time
<span class="hljs-comment">#   </span>
searchArea = np.array([np.zeros((<span class="hljs-number">18</span>,)), np.ones((<span class="hljs-number">18</span>,)) /<span class="hljs-number">18</span>, np.ones((<span class="hljs-number">18</span>,))])<font></font>
print(searchArea[:,<span class="hljs-number">0</span>])<font></font>
<font></font>
history_parametrs = [searchArea[<span class="hljs-number">1</span>,:].copy()]<font></font>
scaler = StandardAndPoorScaler(normalization=searchArea[<span class="hljs-number">1</span>,:])<font></font>
scaler.fit(X_train)<font></font>
knn = KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>)<font></font>
knn.fit(scaler.transform(X_train), y_train)<font></font>
history_holdout_score = [accuracy_score(y_holdout, knn.predict(scaler.transform(X_holdout)))]<font></font>
<font></font>
<span class="hljs-keyword">for</span> tick <span class="hljs-keyword">in</span> range(<span class="hljs-number">40</span>):
    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> range(searchArea.shape[<span class="hljs-number">1</span>]):<font></font>
        changePropertyNormalization(p, <span class="hljs-number">7</span>)<font></font>
    <font></font>
print(searchArea[<span class="hljs-number">1</span>,:])<font></font>
print(history_holdout_score)</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The resulting accuracy from knn: 91.9% Better than when we tear the data from the tree. </font><font style="vertical-align: inherit;">And much, much better than in the original version. </font><font style="vertical-align: inherit;">Compare what we have with the importance of features according to the decision tree:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualization of the importance of features according to knn</font></font></b><div class="spoiler_text"><pre><code class="python hljs">feature_importances[<span class="hljs-string">'knn_importance'</span>] = history_parametrs[<span class="hljs-number">-1</span>]<font></font>
diagramma = feature_importances.copy()<font></font>
indexes = diagramma.index<font></font>
diagramma.index = diagramma[<span class="hljs-string">'features'</span>]<font></font>
diagramma.drop(<span class="hljs-string">'features'</span>, <span class="hljs-number">1</span>, inplace = <span class="hljs-literal">True</span>)<font></font>
diagramma.plot(kind=<span class="hljs-string">'bar'</span>);<font></font>
plt.savefig(<span class="hljs-string">"images/pic1.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()<font></font>
feature_importances</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/kk/pe/nf/kkpenftrnyfl6dpu4p1qh2dnwqq.gif"><br>
<br>
<img src="https://habrastorage.org/webt/ui/o2/rp/uio2rplq9j2p5cxppq7jb7h_mpk.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seem to be? </font><font style="vertical-align: inherit;">Yes, it seems. </font><font style="vertical-align: inherit;">But far from identical. </font><font style="vertical-align: inherit;">Interesting observation. </font><font style="vertical-align: inherit;">There are several features in the data set that completely duplicate each other, for example, 'Total night minutes' and 'Total night charge'. </font><font style="vertical-align: inherit;">So pay attention, knn itself sawed out a significant part of such repeated features.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We will save the results to a file, otherwise it‚Äôs somewhat inconvenient to return to work ....</font></font></b><div class="spoiler_text"><pre><code class="python hljs">parametrs_df = pd.DataFrame(history_parametrs)<font></font>
parametrs_df[<span class="hljs-string">'scores'</span>] = history_holdout_score<font></font>
parametrs_df.index.name = <span class="hljs-string">'index'</span>
parametrs_df.to_csv(<span class="hljs-string">'parametrs_and_scores.csv'</span>)
</code></pre></div></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">findings</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, the Result .919 per se is not bad for knn, there are 1.5 times fewer errors than in the vanilla version and 7% less than when we took the feature_importance tree to drive. </font><font style="vertical-align: inherit;">But the most interesting thing is that now we have feature_importance according to knn itself. </font><font style="vertical-align: inherit;">It is somewhat different from what the tree told us. </font><font style="vertical-align: inherit;">For example, tree and knn have different opinions about which of the signs are not important for us at all. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, in the end. </font><font style="vertical-align: inherit;">We got something relatively new and unusual, having a reserve of knowledge of three lectures mlcourse.ai </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ods and Google to answer simple questions about python. </font><font style="vertical-align: inherit;">In my opinion, not bad.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now slides</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A byproduct of the algorithm's work is the path it has traveled. True, the path is 18-dimensional, which hinders his awareness a little, well, to follow in real time what the algorithm is doing there, learning or using garbage is not so convenient. According to the error schedule, this, in fact, is not always visible. The error may not change noticeably for a long time, but the algorithm is very busy, crawling along a long narrow valley in adaptive space. Therefore, I will apply, for starters, the first simplest but quite informative approach - I randomly project an 18-dimensional space onto a two-dimensional space so that the contributions of all parameters, regardless of their significance, are single. In fact, the 18-dimensional path is very small, in our article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Peeping Over Throws of a Neural Network</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I likewise admired the space of the scales of all the synapses that the neural network had and it was nice and informative.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I read the data from the file, if I return to work, having passed the training stage itself</font></font></b><div class="spoiler_text"><pre><code class="python hljs">parametrs_df = pd.read_csv(<span class="hljs-string">'parametrs_and_scores.csv'</span>, index_col = <span class="hljs-string">'index'</span>)<font></font>
history_holdout_score = np.array(parametrs_df[<span class="hljs-string">'scores'</span>])<font></font>
parametrs_df.drop(<span class="hljs-string">'scores'</span>,axis=<span class="hljs-number">1</span>)<font></font>
history_parametrs = np.array(parametrs_df.drop(<span class="hljs-string">'scores'</span>,axis=<span class="hljs-number">1</span>))</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The error on validation ceases to change from some point. </font><font style="vertical-align: inherit;">Here it would be possible to screw in an automatic stop of learning and use the received function for the rest of my life, but I already have a little time. </font><font style="vertical-align: inherit;">:(</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We determine how much to study.</font></font></b><div class="spoiler_text"><pre><code class="python hljs">last = history_holdout_score[<span class="hljs-number">-1</span>]<font></font>
steps = np.arange(<span class="hljs-number">0</span>, history_holdout_score.shape[<span class="hljs-number">0</span>])[history_holdout_score != last].max()<font></font>
print(steps/<span class="hljs-number">18</span>)</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
35.5555555555555556 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We changed one parameter at a time, so one optimization cycle </font><font style="vertical-align: inherit;">consists of </font><font style="vertical-align: inherit;">18 steps. </font><font style="vertical-align: inherit;">It turns out that we had 36 meaningful steps, or something like that. </font><font style="vertical-align: inherit;">Now let's try to visualize the trajectory along which the method was trained.</font></font><br>
<br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hidden text</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-comment">#    :</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> math<font></font>
random.seed(<span class="hljs-number">17</span>)<font></font>
property_projection = np.array([[math.sin(a), math.cos(a)] <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> [random.uniform(-math.pi, math.pi) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(history_parametrs[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>])]]).transpose()<font></font>
history = np.array(history_parametrs[::<span class="hljs-number">18</span>]) <span class="hljs-comment">#   - 18 .</span>
<span class="hljs-comment">#           . :(</span>
points = np.array([(history[i] * property_projection).sum(axis=<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(history.shape[<span class="hljs-number">0</span>])])<font></font>
plt.plot(points[:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">0</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.savefig(<span class="hljs-string">"images/pic2.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/jt/zs/rc/jtzsrcgk60i_aeqhcvxjq9atvee.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It can be seen that a significant part of the journey was completed in the first four steps. </font><font style="vertical-align: inherit;">Let's look at the rest of the way with increasing</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Without the first 4 points</font></font></b><div class="spoiler_text"><pre><code class="python hljs">plt.plot(points[<span class="hljs-number">4</span>:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">4</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.savefig(<span class="hljs-string">"images/pic3.png"</span>, format = <span class="hljs-string">'png'</span>)</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/gq/xh/wa/gqxhwawt9nnsmypgk3tkry9vbpw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's take a closer look at the final part of the path and see what the teacher did after reaching her destination.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">getting closer</font></font></b><div class="spoiler_text"><pre><code class="python hljs">plt.plot(points[<span class="hljs-number">14</span>:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">14</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.savefig(<span class="hljs-string">"images/pic4.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()<font></font>
plt.plot(points[<span class="hljs-number">24</span>:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">24</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.plot(points[<span class="hljs-number">35</span>:,<span class="hljs-number">0</span>],points[<span class="hljs-number">35</span>:,<span class="hljs-number">1</span>], color = <span class="hljs-string">'red'</span>);<font></font>
plt.savefig(<span class="hljs-string">"images/pic5.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/a5/kq/6m/a5kq6mq5yxl3roojyjfzdw8wq8a.png"><br>
<br>
<img src="https://habrastorage.org/webt/g5/lo/gs/g5logsa_jmna5lveoc-w0679koy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It can be seen that the algorithm is being trained intently. Until he finds his destination. The specific point, of course, depends on randomization in cross-validation. But regardless of the specific point, the general picture of what is happening is understandable. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
By the way, I used to use such a schedule to demonstrate the learning process. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Not the entire trajectory is shown, but the last few steps with sliding smoothing of the scale. An example can be found in my other article, ‚ÄúWe Spy on the Throws of a Neural Network‚Äù. And yes, of course, everyone who encounters such visualization immediately asks why all the factors have the same weight, importance, then they have different. Last time in the article, I tried to re-weight the importance of synapses and it turned out less informative.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This time, armed with new knowledge, I will try using t-SNE to deploy multidimensional space into a projection in which everything can be better.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t-SNE</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">import</span> sklearn.manifold <span class="hljs-keyword">as</span> manifold<font></font>
tsne = manifold.TSNE(random_state=<span class="hljs-number">19</span>)<font></font>
tsne_representation = tsne.fit_transform(history)<font></font>
plt.plot(tsne_representation[:, <span class="hljs-number">0</span>], tsne_representation[:, <span class="hljs-number">1</span>])<font></font>
plt.savefig(<span class="hljs-string">"images/pic6.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show();</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/qe/bp/nn/qebpnnz71ywbxgqvhzj3fpv8vzc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
t-Sne seems to have unfolded the space so that it completely ate the scale of the changes for those features that quickly stopped changing, which made the picture completely uninformative. </font><font style="vertical-align: inherit;">Conclusion - do not try to slip the algorithms into places not intended for them.: \</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You can not read further</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I also tried to inject tsne inside to visualize intermediate optimization states, in the hope that beauty would turn out. but it turned out not beauty, some garbage. If interested, see how to do it. The Internet is littered examples of such injecting code but by simply copying they do not pa bot because substitute contained in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sklearn.manifold.t_sne</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> internal function </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">_gradient_descent</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and it depending on the version may be very different both in the signature and on the treatment of internal variables. So just find the sources in yourself, pick out your version of the function from there and insert just one line in it that adds intermediate dumps to your variable of your </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
own </font><font style="vertical-align: inherit;">: </font><font style="vertical-align: inherit;">positions.append (p.copy ()) # We save the current position.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And then, like, we beautifully visualize what we get as a result:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Injection code</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> linalg
<span class="hljs-comment"># This list will contain the positions of the map points at every iteration.</span><font></font>
positions = []<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_gradient_descent</span>(<span class="hljs-params">objective, p0, it, n_iter,
                      n_iter_check=<span class="hljs-number">1</span>, n_iter_without_progress=<span class="hljs-number">300</span>,
                      momentum=<span class="hljs-number">0.8</span>, learning_rate=<span class="hljs-number">200.0</span>, min_gain=<span class="hljs-number">0.01</span>,
                      min_grad_norm=<span class="hljs-number">1e-7</span>, verbose=<span class="hljs-number">0</span>, args=None, kwargs=None</span>):</span>
    <span class="hljs-comment"># The documentation of this function can be found in scikit-learn's code.</span>
    <span class="hljs-keyword">if</span> args <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
        args = []<font></font>
    <span class="hljs-keyword">if</span> kwargs <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
        kwargs = {}<font></font>
<font></font>
    p = p0.copy().ravel()<font></font>
    update = np.zeros_like(p)<font></font>
    gains = np.ones_like(p)<font></font>
    error = np.finfo(np.float).max<font></font>
    best_error = np.finfo(np.float).max<font></font>
    best_iter = i = it<font></font>
<font></font>
    tic = time()<font></font>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(it, n_iter):<font></font>
        positions.append(p.copy()) <span class="hljs-comment"># We save the current position.</span><font></font>
        <font></font>
        check_convergence = (i + <span class="hljs-number">1</span>) % n_iter_check == <span class="hljs-number">0</span>
        <span class="hljs-comment"># only compute the error when needed</span>
        kwargs[<span class="hljs-string">'compute_error'</span>] = check_convergence <span class="hljs-keyword">or</span> i == n_iter - <span class="hljs-number">1</span><font></font>
<font></font>
        error, grad = objective(p, *args, **kwargs)<font></font>
        grad_norm = linalg.norm(grad)<font></font>
<font></font>
        inc = update * grad &lt; <span class="hljs-number">0.0</span><font></font>
        dec = np.invert(inc)<font></font>
        gains[inc] += <span class="hljs-number">0.2</span>
        gains[dec] *= <span class="hljs-number">0.8</span><font></font>
        np.clip(gains, min_gain, np.inf, out=gains)<font></font>
        grad *= gains<font></font>
        update = momentum * update - learning_rate * grad<font></font>
        p += update<font></font>
<font></font>
        <span class="hljs-keyword">if</span> check_convergence:<font></font>
            toc = time()<font></font>
            duration = toc - tic<font></font>
            tic = toc<font></font>
<font></font>
            <span class="hljs-keyword">if</span> verbose &gt;= <span class="hljs-number">2</span>:<font></font>
                print(<span class="hljs-string">"[t-SNE] Iteration %d: error = %.7f,"</span>
                      <span class="hljs-string">" gradient norm = %.7f"</span>
                      <span class="hljs-string">" (%s iterations in %0.3fs)"</span>
                      % (i + <span class="hljs-number">1</span>, error, grad_norm, n_iter_check, duration))<font></font>
<font></font>
            <span class="hljs-keyword">if</span> error &lt; best_error:<font></font>
                best_error = error<font></font>
                best_iter = i<font></font>
            <span class="hljs-keyword">elif</span> i - best_iter &gt; n_iter_without_progress:
                <span class="hljs-keyword">if</span> verbose &gt;= <span class="hljs-number">2</span>:<font></font>
                    print(<span class="hljs-string">"[t-SNE] Iteration %d: did not make any progress "</span>
                          <span class="hljs-string">"during the last %d episodes. Finished."</span>
                          % (i + <span class="hljs-number">1</span>, n_iter_without_progress))
                <span class="hljs-keyword">break</span>
            <span class="hljs-keyword">if</span> grad_norm &lt;= min_grad_norm:
                <span class="hljs-keyword">if</span> verbose &gt;= <span class="hljs-number">2</span>:<font></font>
                    print(<span class="hljs-string">"[t-SNE] Iteration %d: gradient norm %f. Finished."</span>
                          % (i + <span class="hljs-number">1</span>, grad_norm))
                <span class="hljs-keyword">break</span><font></font>
<font></font>
    <span class="hljs-keyword">return</span> p, error, i<font></font>
<font></font>
manifold.t_sne._gradient_descent = _gradient_descent</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apply the `` fixed '' t-SNE</font></font></b><div class="spoiler_text"><pre><code class="python hljs">tsne_representation = manifold.TSNE(random_state=<span class="hljs-number">17</span>).fit_transform(history)<font></font>
X_iter = np.dstack(position.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> position <span class="hljs-keyword">in</span> positions)<font></font>
position_reshape = [position.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> position <span class="hljs-keyword">in</span> positions]<font></font>
print(position_reshape[<span class="hljs-number">0</span>].shape)<font></font>
print(<span class="hljs-string">'[0] min'</span>, position_reshape[<span class="hljs-number">0</span>][:,<span class="hljs-number">0</span>].min(),<span class="hljs-string">'max'</span>, position_reshape[<span class="hljs-number">0</span>][:,<span class="hljs-number">0</span>].max())<font></font>
print(<span class="hljs-string">'[1] min'</span>, position_reshape[<span class="hljs-number">1</span>][:,<span class="hljs-number">0</span>].min(),<span class="hljs-string">'max'</span>, position_reshape[<span class="hljs-number">1</span>][:,<span class="hljs-number">0</span>].max())<font></font>
print(<span class="hljs-string">'[2] min'</span>, position_reshape[<span class="hljs-number">2</span>][:,<span class="hljs-number">0</span>].min(),<span class="hljs-string">'max'</span>, position_reshape[<span class="hljs-number">2</span>][:,<span class="hljs-number">0</span>].max())
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(41, 2) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[0] min -0.00018188123 max 0.00027207955 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[1] min -0.05136269 max 0.032607622 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[2] min -4.392309 max 7.9074526 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The values ‚Äã‚Äãdance in a very wide range, so I will scale them before drawing them. </font><font style="vertical-align: inherit;">On cycles, all this is done kapets slowly. </font><font style="vertical-align: inherit;">:(</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I scale</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<font></font>
minMaxScaler = MinMaxScaler()<font></font>
minMaxScaler.fit_transform(position_reshape[<span class="hljs-number">0</span>])<font></font>
position_reshape = [minMaxScaler.fit_transform(frame) <span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> position_reshape]<font></font>
position_reshape[<span class="hljs-number">0</span>].min(), position_reshape[<span class="hljs-number">0</span>].max()</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Animate</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
<font></font>
<span class="hljs-keyword">from</span> matplotlib.animation <span class="hljs-keyword">import</span> FuncAnimation, PillowWriter
<span class="hljs-comment">#plt.style.use('seaborn-pastel')</span><font></font>
<font></font>
fig = plt.figure()<font></font>
<font></font>
ax = plt.axes(xlim=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), ylim=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<font></font>
line, = ax.plot([], [], lw=<span class="hljs-number">3</span>)<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init</span>():</span><font></font>
    line.set_data([], [])<font></font>
    <span class="hljs-keyword">return</span> line,
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">animate</span>(<span class="hljs-params">i</span>):</span>
    x = position_reshape[i][:,<span class="hljs-number">0</span>]<font></font>
    y = position_reshape[i][:,<span class="hljs-number">1</span>]<font></font>
    line.set_data(x, y)<font></font>
    <span class="hljs-keyword">return</span> line,<font></font>
<font></font>
anim = FuncAnimation(fig, animate, init_func=init, frames=<span class="hljs-number">36</span>, interval=<span class="hljs-number">20</span>, blit=<span class="hljs-literal">True</span>, repeat_delay = <span class="hljs-number">1000</span>)<font></font>
anim.save(<span class="hljs-string">'images/animate_tsne_learning.gif'</span>, writer=PillowWriter(fps=<span class="hljs-number">5</span>))
</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/lh/dq/g6/lhdqg6khzhplw6jtkei6y0s3pdu.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is instructive in terms of skills, but absolutely useless in this task and ugly. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On this I say goodbye to you. </font><font style="vertical-align: inherit;">I hope the idea that even from knn you can get something new and interesting, as well as pieces of code, will help you as well as to have fun with the data at this intellectual feast during the plague.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en496466/index.html">Any fast enough light source has a red Doppler shift</a></li>
<li><a href="../en496472/index.html">10 interesting repositories on GitHub, useful to any developer</a></li>
<li><a href="../en496476/index.html">Push Windows Server onto a low-powered VPS using Windows Server Core</a></li>
<li><a href="../en496480/index.html">The sound of future silence</a></li>
<li><a href="../en496482/index.html">The development of informed leadership for team management</a></li>
<li><a href="../en496486/index.html">Opinion: Spamhaus - online censorship or clean web fighters?</a></li>
<li><a href="../en496488/index.html">IaaS providers fight against attacks on BGP protocol</a></li>
<li><a href="../en496490/index.html">We study the Mediastreamer2 VoIP engine. Part 7</a></li>
<li><a href="../en496492/index.html">Basic LXD Features - Linux Container Systems</a></li>
<li><a href="../en496494/index.html">We play music from Mario on the system speaker</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
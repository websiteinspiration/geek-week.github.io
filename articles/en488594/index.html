<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéë üßöüèº üïµüèæ Pandas and others for thick data üë©‚Äçüë©‚Äçüëß‚Äçüëß üëãüèæ üç´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article, I will talk about a couple of simple tricks that are useful when working with data that does not fit in the local machine, but is sti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pandas and others for thick data</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488594/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this article, I will talk about a couple of simple tricks that are useful when working with data that does not fit in the local machine, but is still too small to be called Large. </font><font style="vertical-align: inherit;">Following the English-language analogy (large but not big), we will call this data thick. </font><font style="vertical-align: inherit;">We are talking about sizes of units and tens of gigabytes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[Disclaimer] If you love SQL, everything written below can cause you to have bright, most likely negative emotions, in the Netherlands there are 49262 Tesla, 427 of them are taxis, better not read further [/ Disclaimer].</font></font><br>
<br>
<img src="https://habrastorage.org/webt/-s/ac/gl/-sacgl0hwmynxnpiov5s_coofa4.png" alt="image"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The starting point was </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">an article on the hub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> with a description of an interesting dataset - a complete list of vehicles registered in the Netherlands, 14 million lines, everything from truck tractors to electric bicycles at speeds above 25 km / h. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The set is interesting, takes 7 GB, </font><font style="vertical-align: inherit;">you can </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">download</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> it on the website of the responsible organization. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The attempt to drive the data as it is in the pandas to filter and clean it ended in a fiasco (gentlemen of the SQL hussars, I warned!). Pandas fell from a lack of memory on the desktop with 8 GB. With a little bloodshed, the question can be resolved if you recall that the pandas can read csv files in pieces of moderate size. The fragment size in rows is determined by the chunksize parameter.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To illustrate the work, we will write a simple function that makes a request and determines how many Tesla cars are in total and what proportion of them work in taxis. Without tricks with fragment reading, such a request first eats up all the memory, then it suffers for a long time, and at the end the ramp falls off. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
With fragment reading, our function will look something like this:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pandas_chunky_query</span>():</span>
    print(<span class="hljs-string">'reading csv file with pandas in chunks'</span>)<font></font>
    filtered_chunk_list=[]<font></font>
    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> pd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>, chunksize=<span class="hljs-number">1E+6</span>):<font></font>
        filtered_chunk=chunk[chunk[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        filtered_chunk_list.append(filtered_chunk)<font></font>
    model_df = pd.concat(filtered_chunk_list)<font></font>
    print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 By specifying a perfectly reasonable million lines, you can execute the query in 1:46 and using 1965 M of memory at its peak. All the numbers for a dumb desktop with something ancient, eight-core about 8 GB of memory and under the seventh Windows. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7d/id/0-/7did0-qetjm9v9wrlaouudevkss.png" alt="image"><br>
<br>
<img src="https://habrastorage.org/webt/8n/ch/go/8nchgo5c-tr54min7qwpfvgwuuq.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you change chunksize, then the peak memory consumption follows it quite literally, the execution time does not change much. For 0.5 M lines, the request takes 1:44 and 1063 MB, for 2M 1:53 and 3762 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The speed is not very pleasing, even less pleasing is that reading the file in fragments forces you to write adapted for this function, working with lists of fragments that must then be collected in a data frame. Also, the csv format itself is not very happy, which takes up a lot of space and is slowly read. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since we can drive data into a ramp, a much more compact Apachev format can be used for storage</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">parquet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> where there is compression, and, thanks to the data scheme, it is much faster to read when it is read. And the ramp is quite able to work with him. Only now can not read them in fragments. What to do? </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Let's have fun, take the </font><font style="vertical-align: inherit;">Dask </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">button accordion</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and speed up! </font></font></i><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dask!</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A substitute for the ramp out of the box, able to read large files, able to work in parallel on several cores, and using lazy calculations. To my surprise about Dask on Habr√© there are only 4 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publications</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, we take the dask, we drive the original csv into it and with minimal conversion, we drive it to the floor. When reading, dask swears at the ambiguity of data types in some columns, so we set them explicitly (for the sake of clarity, the same thing was done for the ramp, the operating time is higher taking into account this factor, the dictionary with dtypes is cut out for all the queries for clarity), the rest is for himself . Further, for verification, we make small improvements in the flooring, namely, we try to reduce the data types to the most compact ones, replace a pair of columns with text yes / no with Boolean ones, and convert other data to the most economical types (for the number of engine cylinders, uint8 is definitely enough). We save the optimized flooring separately and see what we get.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first thing that pleases when working with Dask is that we do not need to write anything superfluous simply because we have thick data. If you do not pay attention to the fact that the dask is imported, and not the ramp, everything looks the same as processing a file with a hundred lines in the ramp (plus a couple of decorative whistles for profiling).</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading CSV file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>)<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts().compute())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Now compare the impact of the source file on performance when working with dasko. First we read the same csv file as when working with the ramp. The same about two minutes and two gigabytes of memory (1:38 2096 Mb). It would seem, was it worth it to kiss in the bushes? </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9a/oy/al/9aoyalzd1a62bw31uivvy699xme.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now feed the board unoptimized parquet file. The request was processed in approximately 54 seconds, consuming 1388 MB of memory, and the file itself for the request is now 10 times smaller (about 700 MB). Here the bonuses are already visible convexly. CPU utilization of hundreds of percent is parallelization across several cores.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1u/sz/_x/1usz_xafa2hng3nogb2fbp9zspm.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The previously optimized parquet with slightly altered data types in compressed form is only 1 Mb less, which means that without hints everything is compressed quite efficiently. </font><font style="vertical-align: inherit;">The increase in productivity is also not particularly significant. </font><font style="vertical-align: inherit;">The request takes the same 53 seconds and eats a little less memory - 1332 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Based on the results of our exercises, we can say the following:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If your data is ‚Äúfat‚Äù and you are used to a ramp - chunksize will help the ramp to digest this volume, the speed will be bearable. </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you want to squeeze out more speed, save space during storage and you are not holding back using just a ramp, then dusk with parquet is a good combination. </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, about lazy computing. One of the features of the dask is that it uses lazy calculations, that is, calculations are not performed immediately as they are found in the code, but when they are really needed or when you explicitly requested it using the compute method. For example, in our function, dask does not read all the data into memory when we indicate to read the file. He reads them later, and only those columns that relate to the request.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is easily seen in the following example. </font><font style="vertical-align: inherit;">We take a pre-filtered file in which we left only 12 columns from the initial 64, compressed parquet takes 203 MB. </font><font style="vertical-align: inherit;">If you run our regular request on it, then it will execute in 8.8 seconds, and the peak memory usage will be about 300 MB, which corresponds to a tenth of the compressed file if you overtake it in a simple csv. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/jg/we/bq/jgwebqzk7enoz6z6rwiearbofgs.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If we explicitly require you to read the file, and then execute the request, then the memory consumption will be almost 10 times more. </font><font style="vertical-align: inherit;">We slightly modify our function by explicitly reading the file:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading parquet file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_parquet(<span class="hljs-string">'C:\Open_data\RDW_filtered.parquet'</span> ).compute()<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]
        <span class="hljs-comment">#print(model_df.head())</span>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And here is what we get, 10.5 seconds and 3568 MB of memory (!) </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w5/5w/aj/w55wajaohsdjyevm1hxbgpvns2a.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Once again we are convinced that the dask - it is competent to cope with its tasks itself, and once again climbing into it with micro-management does not make much sense.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en488584/index.html">What you will want to know before writing an application for Apple Watch: our experience</a></li>
<li><a href="../en488586/index.html">The Ember Times - Issue 135</a></li>
<li><a href="../en488588/index.html">C ++ 20 approved! What to expect and what to prepare for developers in C ++ 23</a></li>
<li><a href="../en488590/index.html">FOSS News No. 3 - Review of free and open source news for February 10-16, 2020</a></li>
<li><a href="../en488592/index.html">An open letter from Mail.ru about the game ‚ÄúAllods II: Lord of Souls‚Äù</a></li>
<li><a href="../en488596/index.html">Google has developed an algorithm for automatically cropping video on important objects in the frame</a></li>
<li><a href="../en488598/index.html">Is the world ready for a pandemic?</a></li>
<li><a href="../en488600/index.html">How providers care about customer safety</a></li>
<li><a href="../en488602/index.html">iOS MEETUP # 2 from FUNCORP and How to keep a developer up-to-date</a></li>
<li><a href="../en488604/index.html">The digest of fresh materials from the world of the front-end for the last week No. 402 (February 10 - 16, 2020)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤲🏻 🙎🏿 👩🏻‍🚀 Pope: Ethics for AI and Unmanned Vehicles 👃🏿 ⌛️ 🛀🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The Pope fears that AI may harm people instead of becoming a tool that will complement society and improve its life. 
 
 According to the Vatican , a ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pope: Ethics for AI and Unmanned Vehicles</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itelma/blog/492918/"><img src="https://specials-images.forbesimg.com/imageserve/2da7658e8b794f2ca854b4e48f09ad08/960x0.jpg?cropX1=210&amp;cropX2=3583&amp;cropY1=0&amp;cropY2=2531" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Pope </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fears that AI may</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> harm </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">people</font></a><font style="vertical-align: inherit;"> instead of becoming a tool that will complement society and improve its life. </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">According to the Vatican</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , a recently released </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">document called the</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Rome Call For AI Ethics tells us which direction AI should take as a technology that aims to improve society, as well as preventing prospects for harm and death of society.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sometimes scientists are inclined to introduce innovations without explicitly studying the possible consequences. Thus, there are many calls for paying attention to the ethics of AI in the era of the race of development and implementation of intelligent systems (especially when it comes to systems based on machine and deep learning). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here is a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">key quote</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from a document issued by the Pope: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
“Now, more than ever, we must guarantee the prospects according to which AI will develop with emphasis not on technology, but on the benefit of humanity, the environment, our common home, and its inhabitants, which are inextricably interconnected</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Catholic Church asks everyone involved in the creation of AI to remember the potential actions of these systems. </font><font style="vertical-align: inherit;">This also includes an appeal to pay attention to both the anticipated and potentially unintended consequences. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Some AI developers turn a blind eye to the fact that the actions of their developments can cause unintended adverse effects. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Remember the following aspects of social dynamics:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Some engineers and scientists believe that as long as the AI ​​system at least does what they expected, all the other consequences are not their responsibility, and therefore they try to wash their hands from any such hardships.</font></font></li>
<li>            (  , ,  ,     ,        ).</li>
<li>          ,      ,      .      ,       ,         .</li>
<li>  ,      «»  , -          .           ,          .</li>
<li>     ,      ,       .   ,                ,         (      –    ,     –    ).</li>
</ul><br>
<h3>  –  ,      </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A document published by the Catholic Church acts as a kind of pledge, and all those involved in the creation of AI systems will be politely asked to sign this pledge. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Indeed, this document has already been signed by several players, among them IBM and Microsoft. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What is this document asking the signatories for? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I will briefly talk about some of the details. This one describes three basic principles. So, the AI ​​system should:</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"... to be inclusive for everyone and not discriminate against anyone; in the heart of this system must be the kindness of the human race as a whole and each person in particular; finally, this system must remember the complex structure of our ecosystem and be characterized by its attitude towards our common home. Intelligent system "should approach this issue from the most rational side, and its approach should include the use of AI to ensure stable food systems in the future." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So in short:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AI must not discriminate against anyone</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AI should only have good intentions</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> AI must take care of environmental sustainability</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The aspect that should be borne in mind is that AI does not determine its future itself, no matter how it seems that these systems are already autonomous and themselves create their own destiny. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All this is wrong, at least for now (it will be so in the near future). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In other words, only we humans create these systems. Therefore, only humans are responsible for what AI systems do. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I’m talking about this because this is a simple way out of the situation in which AI engineers and developers pretend that they are not to blame for the errors of their product.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You are probably familiar with the situation when you contact the motor vehicle administration to renew your driver’s license and their information system crashes. At the same time, the management agent only shrugs and complains that all this always happens with the equipment. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To be precise, it does not last forever, and not with all the technology. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If the computer system does not work, then the people who set up the computer and could not properly back up, and also did not provide the ability to gain access to the system if necessary, are to blame. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Do not fall into the logical trap, disagree with the fact that computer systems (including AI systems) have their own opinions, and if they go crazy, it’s not that this “always happens with technology”.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The truth is that the people who developed and implemented the computer system bear full responsibility, since they did not take sufficient measures and did not pay enough attention to their work. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the case of Pope Francis’s call to take part in the discussion of vital ethical principles, it might seem that all these theses are very simple and not amenable to criticism (because they are obvious as an assertion that the sky is blue), but despite this, there are parties that deny Vatican offers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
How so?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, some critics claim that there is no compulsory aspect of this pledge. If the company subscribes to it, then for non-compliance with the principles of the pledge no punishment will follow. Thus, you can subscribe without fear of responsibility. A pledge without consequences seems empty to many. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secondly, some are worried by the fact that it was the Catholic Church that made the call for AI ethics. The reason is that the presence of the church introduces religion into the subject, although some believe that it has nothing to do with the subject. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The question arises - will other religions issue similar calls? And if so, which ones will prevail? And what will we do with a fragmented and disparate set of AI ethics declarations?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thirdly, some believe that this guarantee is very soft and overly general. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Probably, the document does not contain substantive directives that could be implemented in any practical way. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Moreover, those developers who want to dodge responsibility may claim that they misunderstood the general provisions, or interpreted them differently than intended. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, given the flurry of condemnation, should we get rid of this call from the Vatican in favor of AI algoethics? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Moving away from the topic, I note that algoethics is a name that is given to issues related to algorithmic ethics. This may be a good name, but it is not very sonorous, and is unlikely to become generally accepted. Time will tell. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Returning to the topic - should we pay attention to this call for AI ethics or not?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Yes, we must. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despite the fact that this document, admittedly, does not provide for any financial sanctions for non-compliance with the principles, there is another aspect that is also important to consider. Firms that sign this call may be held accountable by the general public. If they break their promises and the church indicates it, then bad advertising can damage these companies - it will lead to the loss of business and reputation in this industry. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You could say that for violating these principles some kind of payment is implied, or suppose that it is hidden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As for the appearance of religion in a topic where, as it seems, it does not belong to it, then understand that this is a completely different issue. This issue is worth considerable discussion and debate, but also acknowledge that there are now many ethical systems and calls for AI ethics from a wide variety of sources. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In other words, this call is not the first. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you carefully study this document, you will see that there are no abstracts related to religious doctrine. This means that you could not distinguish it from any similar, performed without any religious context. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, from the point of view of the vagueness of this document - yes, you could easily drive a Mack truck through numerous loopholes, but those who want to cheat will still cheat.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I assume that further steps will be taken in the field of AI, and these steps will complement the Vatican document with specific guidance that will help fill gaps and omissions. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is also possible that anyone who tries to cheat will be condemned by the whole world, and false statements about an allegedly misunderstanding of the document will be regarded as obvious tricks that are needed only to avoid complying with reasonably formulated and quite obvious ethical standards of AI proclaimed in document. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Speaking of the belief that everyone understands the principles of AI ethics, consider the myriad use of AI. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is an interesting example in the field of applied AI related to the topic of ethics: should unmanned vehicles be developed and put on the road in accordance with the appeal of the Vatican?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
My answer is yes, definitely so. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, I urge all car and vehicle manufacturers to sign this document. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In any case, let's look at this issue and see how this appeal applies to real unmanned vehicles.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unmanned vehicle levels</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It’s important to clarify what I mean when I talk about fully unmanned vehicles with AI. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Real unmanned vehicles are vehicles in which the AI ​​manages itself without any human assistance. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Such vehicles are assigned to levels 4 and 5, while cars that require human participation for co-driving are usually assigned to levels 2 or 3. Cars in which driving with the help of a person is called semi-autonomous, and usually they contain many additional functions that are referred to as ADAS (advanced driver assistance systems). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So far, there is no fully unmanned vehicle level 5. Today, we don’t even know whether this can be achieved, and how long it will take.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Meanwhile, work is underway in level 4 area. Very narrow and selective tests are carried out on public roads, although there is debate about the admissibility of such tests (some believe that people participating in tests on roads and highways act as guinea pigs, which can survive or die in each test) . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since semi-autonomous cars require a human driver, the adoption of such cars by the masses will not be much different from driving ordinary cars, there is nothing new that could be said about them in the context of our topic (although, as you will soon see, the points that will be considered further applicable to them).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the case of semi-autonomous cars, it is important that the public is warned about the alarming aspect that has arisen recently - despite people who continue to publish videos about how they fall asleep while driving cars of 2 or 3 levels, we all need to remember that the driver cannot be distracted from driving a semi-autonomous car. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You are responsible for actions to control the vehicle level 2 or 3, regardless of the level of automation.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unmanned vehicles and AI ethics</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In vehicles of level 4 and 5, a person does not take part in the management, all people in these vehicles will be passengers, and AI will drive. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At first glance, you can assume that there is no need to consider AI ethics issues. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An unmanned vehicle is a vehicle that can transport you without the driver. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You might think that there is nothing like this, and there are no ethical considerations in how the AI ​​driver handles the control. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sorry, but those who believe that all this has nothing to do with the ethics of AI need to knock on the head or pour cold water on these people (I am against violence, this is just a metaphor). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are many considerations related to AI ethics (you can read my review on</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">this link</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , an article on the global aspects of AI ethics is located </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and an article on the potential of expert advice in this area is </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's take a brief look at each of the six basic principles outlined in the Roman Call for AI Ethics. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I will strive to keep this article concise, and therefore I will offer links to my other publications, which contain more detailed information on the following important topics:</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 1: “Transparency: AI systems must be inherently explainable”</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You get in an unmanned car, and he refuses to go where you said. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nowadays, most unmanned driving systems are developed without any explanation regarding their behavior. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The reason for the refusal may be, for example, a tornado, or a request that cannot be fulfilled (for example, there are no passable roads nearby). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, without XAI (the abbreviation for AI, which works with explanations), you will not understand what is happening (more on this here).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 2: “Inclusiveness: the needs of all people must be taken into account so that the benefits are the same for all, and the best conditions for self-expression and development should be offered to all people”</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Some are worried that unmanned vehicles will be available only to the rich, and they will not bring any benefit to the rest of the population (see Link here). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What do we get - mobility for all, or for a few?</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 3: “Responsibility: those who develop and implement AI systems must act with responsibility, and their work must be transparent”</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What will the AI ​​do in a situation where it will have to choose whether to knock a child who has run out onto the road, or crash into a tree, which will harm passengers? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This dilemma is also known as the trolley problem (see link). </font><font style="vertical-align: inherit;">Many require automakers and unmanned vehicle technology companies to be transparent about how their systems make decisions in favor of life or death.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 4: “Impartiality: Build AI Systems and Act Without Prejudice, thereby Guaranteeing Justice and Human Dignity”</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Suppose a car with automatic control responds to pedestrians depending on their race characteristics. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Or suppose that a fleet of unmanned vehicles learns to avoid driving in certain areas, which will deprive residents of free access to cars that do not need a driver. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The prejudices associated with machine learning and deep learning systems are a major concern</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 5: “Reliability: AI systems must work reliably”</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You are driving a car with automatic control, and he suddenly moves to the side of the road and stops. </font><font style="vertical-align: inherit;">Why? </font><font style="vertical-align: inherit;">You may not have a clue. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AI may have reached the limits of its scope. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Or perhaps the AI ​​system crashed, an error occurred, or something else like that.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Principle 6: “Security and Confidentiality: AI Systems Must Work Safely and Respect User Confidentiality”</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You get in an unmanned vehicle after having fun in the bars. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It turns out that this machine has cameras not only outside but also inside. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, the cameras in the cabin are needed in order to catch passengers who will draw graffiti or spoil the interior of the car. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In any case, all these cameras take you all the time while you are driving in an unmanned car, and your incoherent phrases will also get on this video, because you are in a drunken stupor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Who owns this video, and what can he do with it? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Should the owner of an unmanned car provide you with a video, and is there something that prevents him from uploading this video to the Internet? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are many privacy issues that still need to be addressed.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
From a security perspective, there are many hacking options for intelligent driving systems. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imagine an attacker who can hack an AI drone car. </font><font style="vertical-align: inherit;">He can take control, or at least order a car to take you to the place where the abductors are waiting for you. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are many creepy scenarios associated with security holes in unmanned vehicle systems or in their cloud systems. </font><font style="vertical-align: inherit;">And car manufacturers, along with technology companies, are required to use the necessary protective systems and precautions.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you compare this call to the ethics of AI with many others, you will find that they have a lot in common. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The criticism, which claims that in the end we will have an immeasurable multitude of such appeals, is somewhat true, but it can be assumed that covering absolutely all the fundamentals will also not hurt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This situation is starting to get a little confusing, and AI manufacturers will use the excuse that since there is not a single accepted standard, they will wait until such a document appears. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sounds like a reasonable excuse, but I won't buy it.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All manufacturers who say that they are going to wait until the world-wide version compiled by some big shot are approved, in fact, they are ready to postpone the adoption of any code of ethics of AI, and their expectation may be the same. like Godot’s expectation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I urge you to choose any manual on the ethics of AI, in which there is something important, and which is suggested by an authoritative source, and proceed with the implementation of this ethics. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Better sooner than later.</font></font><br>
<br>
<hr><br>
<img src="https://habrastorage.org/webt/4m/5z/_p/4m5z_pc9zhjja8pmtwxvaihckfe.png" alt="image"><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">About ITELMA</font></font></b>
                        <div class="spoiler_text">  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">automotive</a> .     2500 ,    650 . <br>
<br>
, ,          .        ( 30,     ),   -, -,  - (DSP-)  .<br>
<br>
        ,  .   ,  ,    ,       .     ,      automotive.    , , .</div>
                    </div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Read more useful articles:</font></font></b><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[Forecast] Transport of the future ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">short-term</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium-term</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">long-term</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> horizons)</font></font></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The best materials for hacking cars with DEF CON 2019-2020</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[Forecast] Motornet - a data exchange network for robotic vehicles</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">  16     ,     8 </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">  </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">   open source</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">McKinsey:       automotive</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">       </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">   </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">      …</a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en492900/index.html">Music generator Web Audio API Beginner Experience</a></li>
<li><a href="../en492906/index.html">How different MBTI types respond to stress</a></li>
<li><a href="../en492908/index.html">How to apply for a temporary transfer to remote work</a></li>
<li><a href="../en492910/index.html">Stepper motor control via Canny controller</a></li>
<li><a href="../en492914/index.html">How to protect remote employees, or Home Office Security</a></li>
<li><a href="../en492920/index.html">Quarantine in the Czech Republic: an inside look</a></li>
<li><a href="../en492924/index.html">How to visualize and animate (geophysical) models. Informativeness of visualization</a></li>
<li><a href="../en492932/index.html">13 shell-based word processing tools</a></li>
<li><a href="../en492934/index.html">Difficulties in raising a voice assistant. The look of a linguist and developer</a></li>
<li><a href="../en492938/index.html">Portal of test environments, or Save our devops</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
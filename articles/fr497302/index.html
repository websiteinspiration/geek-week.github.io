<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíö üëÜüèΩ üßôüèº Navigation autonome d'un robot mobile üë©üèø‚Äçüîß üéÖüèº üëêüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il existe un grand nombre de fa√ßons dont un robot peut recevoir des informations du monde ext√©rieur afin d'interagir avec lui. De plus, selon les t√¢ch...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Navigation autonome d'un robot mobile</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/497302/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il existe un grand nombre de fa√ßons dont un robot peut recevoir des informations du monde ext√©rieur afin d'interagir avec lui. </font><font style="vertical-align: inherit;">De plus, selon les t√¢ches qui lui sont assign√©es, les m√©thodes de traitement de ces informations diff√®rent. </font><font style="vertical-align: inherit;">Dans cet article, je d√©crirai les principales √©tapes du travail effectu√© dans le cadre du projet scolaire, dont le but est de syst√©matiser les informations sur les diff√©rentes m√©thodes de navigation autonome du robot et d'appliquer les connaissances acquises dans le processus de cr√©ation du robot pour les comp√©titions ¬´RTK Cup¬ª.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/qb/xw/dw/qbxwdwc_cwrypc3c8dthahudzmk.jpeg"><br>
<a name="habracut"></a><br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">introduction</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aux comp√©titions ¬´RTK Cup¬ª, il y a un bloc de t√¢ches qui doivent √™tre accomplies sans intervention de l'op√©rateur. </font><font style="vertical-align: inherit;">Je crois que de nombreux participants √©vitent injustement ces t√¢ches, car la complexit√© apparente de la cr√©ation d'un robot et de la r√©daction d'un programme cache des t√¢ches largement simplifi√©es d'autres disciplines comp√©titives, combin√©es dans un seul terrain d'entra√Ænement. </font><font style="vertical-align: inherit;">Par mon projet, je veux montrer des solutions possibles √† de tels probl√®mes, en prenant comme exemple ce qui suit le long de la ligne. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour atteindre l'objectif du projet, les t√¢ches interm√©diaires suivantes ont √©t√© formul√©es:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analyse du </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√®glement de la</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> comp√©tition ¬´RTK Cup¬ª</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analyse d'algorithmes existants pour l'orientation autonome d'un robot mobile</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cr√©ation de logiciels</font></font></li>
</ul><br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analyse du r√®glement de la comp√©tition ¬´RTK Cup¬ª</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors des comp√©titions ¬´RTK Cup¬ª, les participants se voient pr√©senter un terrain d'entra√Ænement sur lequel sont mod√©lis√©es des sections de complexit√© variable. </font><font style="vertical-align: inherit;">Le concours vise √† stimuler la jeune robotique √† cr√©er des appareils pouvant fonctionner dans des conditions extr√™mes, surmonter des obstacles, sous contr√¥le humain ou de mani√®re autonome.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6a/sr/6w/6asr6wzvlhnqgkmz0b8dfyf2h9o.jpeg"><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bri√®vement sur les √©l√©ments qui composent le polygone</font></font></b><div class="spoiler_text"> ¬´¬ª          ,    .    ,       ,     (), ,      (),   ..<br>
<br>
:<br>
<br>
<img src="https://habrastorage.org/webt/mk/ks/d3/mkksd313rprmlsilxcrq5xdytg4.png" width="300"><br>
<br>
:<br>
<br>
<img src="https://habrastorage.org/webt/rv/fp/cu/rvfpcu-6qtvdfrclsqjzlr2xok4.jpeg" width="300"><br>
<br>
  ‚Äì  ,     ¬´¬ª  ( )  ,        . ,         ,    ,      ,         .<br>
<br>
     .    ,       ,     ,   ,     ,    ,    .<br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les concours sont divis√©s en deux nominations fondamentalement diff√©rentes les unes des autres: ¬´Seeker¬ª et ¬´Extreme¬ª. Ceci est fait pour s'assurer que la comp√©tition a eu lieu entre les participants avec une diff√©rence d'√¢ge et d'exp√©rience minimale dans le d√©veloppement de syst√®mes robotiques: "Seeker" pour les plus jeunes, et "Extreme" - pour les participants √† partir de 14 ans et plus. Dans la nomination Seeker, l'op√©rateur peut se d√©placer librement dans la cuisini√®re et avoir un contact visuel direct avec la machine, tandis que la nomination Extreme suppose que le robot dispose de syst√®mes de communication vid√©o et / ou de vision par ordinateur, car l'op√©rateur doit naviguer dans le labyrinthe, en ne s'appuyant que sur le labyrinthe. la cam√©ra et les capteurs int√©gr√©s au robot, tout en √©tant derri√®re un √©cran sp√©cial.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour se qualifier en comp√©tition, le robot doit soit passer la t√¢che de t√©l√©commande du manipulateur, soit effectuer l'un des √©l√©ments d'autonomie. </font><font style="vertical-align: inherit;">Dans le cadre du projet, la t√¢che a √©t√© d√©finie pour accomplir des t√¢ches d'autonomie, car elles donnent le plus de points au moindre co√ªt de l'op√©rateur. </font><font style="vertical-align: inherit;">Les √©l√©ments de l'autonomie comprennent:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conduite le long d'une ligne avec un capteur de lumi√®re ambiante ou un syst√®me de visibilit√© directe</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Capture de balise autonome √† l'aide d'un capteur de distance ou de syst√®mes de vision</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mouvement le long d'une trajectoire complexe (par exemple, mont√©e / descente d'escaliers) le long d'une ligne √† l'aide d'une boussole, d'un gyroscope, d'un acc√©l√©rom√®tre, d'un syst√®me de vision ou de m√©thodes combin√©es</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, les points pour surmonter les obstacles sont doubl√©s si le robot les d√©passe de mani√®re autonome.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le cadre de ce projet, la solution √† la premi√®re des t√¢ches sera envisag√©e - le d√©placement le long de la ligne. Les m√©thodes les plus courantes utilis√©es pour se d√©placer le long de la ligne sont des capteurs de lumi√®re et une cam√©ra. Les avantages des capteurs incluent la simplicit√© de cr√©ation d'un programme - beaucoup d'entre eux sont √©quip√©s d'une r√©sistance de r√©glage, de sorte qu'en r√©glant le capteur pour l'√©clairage de fond, il donnera 0 ou 1, selon qu'il est sur la ligne ou non. Pour la m√™me raison, les capteurs de lumi√®re n'exigent pas la puissance de traitement du contr√¥leur utilis√©. De plus, pour cette raison, r√©soudre le probl√®me √† l'aide de capteurs de lumi√®re est le moins co√ªteux - le co√ªt du capteur le plus simple est de 35 roubles, et pour une conduite relativement stable le long de la ligne, trois capteurs suffisent (un est install√© sur la ligne et deux sur les c√¥t√©s). cependant,L'un des principaux inconv√©nients de ces capteurs est les restrictions d'installation. Id√©alement, le capteur doit √™tre install√© exactement au centre, √† une petite distance du sol, sinon il donnera des valeurs incorrectes. Ce n'est pas un probl√®me dans les comp√©titions sp√©cialis√©es o√π le robot doit rouler aussi vite que possible le long de la piste, mais, dans les conditions de la comp√©tition ¬´RTK Cup¬ª, tous les d√©fauts de capteur mentionn√©s ci-dessus peuvent √™tre critiques - leur installation n√©cessite principalement la pr√©sence de pi√®ces m√©caniques suppl√©mentaires sur le robot qui se soul√®vent et abaisser les capteurs, ce qui n√©cessite un espace suppl√©mentaire sur le robot, un moteur s√©par√© d√©pla√ßant les capteurs, et est √©galement un lieu de dommages potentiels et augmente la masse du robot.sinon, il donnera des valeurs incorrectes. Ce n'est pas un probl√®me dans les comp√©titions sp√©cialis√©es, o√π le robot doit rouler aussi vite que possible le long de la piste, mais, dans les conditions de la comp√©tition ¬´RTK Cup¬ª, tous les d√©fauts de capteur mentionn√©s ci-dessus peuvent √™tre critiques - leur installation n√©cessite principalement la pr√©sence de pi√®ces m√©caniques suppl√©mentaires sur le robot qui se soul√®vent et abaisser les capteurs, ce qui n√©cessite un espace suppl√©mentaire sur le robot, un moteur s√©par√© d√©pla√ßant les capteurs, et est √©galement un lieu de dommages potentiels et augmente la masse du robot.sinon, il donnera des valeurs incorrectes. Ce n'est pas un probl√®me dans les comp√©titions sp√©cialis√©es o√π le robot doit rouler aussi vite que possible le long de la piste, mais, dans les conditions de la comp√©tition ¬´RTK Cup¬ª, tous les d√©fauts de capteur mentionn√©s ci-dessus peuvent √™tre critiques - leur installation n√©cessite principalement la pr√©sence de pi√®ces m√©caniques suppl√©mentaires sur le robot qui se soul√®vent et abaisser les capteurs, ce qui n√©cessite un espace suppl√©mentaire sur le robot, un moteur s√©par√© d√©pla√ßant les capteurs, et est √©galement un lieu de dommages potentiels et augmente la masse du robot.tous les d√©fauts de capteur mentionn√©s ci-dessus peuvent √™tre critiques - leur installation n√©cessite principalement la pr√©sence de pi√®ces m√©caniques suppl√©mentaires sur le robot qui soul√®vent et abaissent les capteurs, et cela n√©cessite un espace suppl√©mentaire sur le robot, un moteur s√©par√© qui d√©place les capteurs, et est √©galement un lieu de dommages potentiels et augmente la masse du robot .tous les d√©fauts de capteur mentionn√©s ci-dessus peuvent √™tre critiques - leur installation n√©cessite principalement la pr√©sence sur le robot de pi√®ces m√©caniques suppl√©mentaires soulevant et abaissant les capteurs, et cela n√©cessite un espace suppl√©mentaire sur le robot, un moteur s√©par√© d√©pla√ßant les capteurs, et est √©galement un lieu de dommages potentiels et augmente la masse du robot .</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><img src="https://habrastorage.org/webt/_g/pt/zz/_gptzzip0rdk6ocgg67ttumux2k.jpeg" width="300" align="right"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La cam√©ra, √† son tour, pr√©sente les avantages suivants: elle a un rayon de mesure pratiquement illimit√© (par rapport aux capteurs), c'est-√†-dire un seul module de cam√©ra est capable de voir simultan√©ment la ligne, √† la fois directement sous le robot et √† une distance suffisante de celui-ci, ce qui permet par exemple d'√©valuer sa courbure et de s√©lectionner une action de commande proportionnelle. Dans le m√™me temps, le module de cam√©ra n'interf√®re pas avec l'avancement du robot dans d'autres parties de la d√©charge qui ne n√©cessitent pas d'autonomie, car la cam√©ra est fix√©e √† distance du sol. Le principal inconv√©nient de la cam√©ra est que le traitement vid√©o n√©cessite un puissant complexe informatique √† bord du robot, et le logiciel en cours de d√©veloppement a besoin de plus de r√©glages, car la cam√©ra re√ßoit un ordre de grandeur plus d'informations du monde ext√©rieur que trois capteurs de lumi√®re, tandis que la cam√©ra et l'ordinateurcapables de traiter les informations re√ßues sont plusieurs fois plus de trois capteurs et ¬´Arduins¬ª.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour moi personnellement, la r√©ponse est √©vidente pour moi - dans la nomination ¬´extr√™me¬ª, le robot doit avoir une cam√©ra directionnelle, avec laquelle l'op√©rateur naviguera. </font><font style="vertical-align: inherit;">Si vous utilisez des solutions FPV pr√™tes √† l'emploi, le co√ªt total des ¬´capteurs¬ª peut √™tre encore plus √©lev√©, tout en n√©cessitant l'installation d'appareils suppl√©mentaires. </font><font style="vertical-align: inherit;">De plus, un robot avec framboise pi et une cam√©ra a un plus grand potentiel pour le d√©veloppement d'un mouvement autonome, car la cam√©ra peut r√©soudre un large √©ventail de probl√®mes et peut √™tre utilis√©e non seulement dans le mouvement en ligne, sans compliquer consid√©rablement la conception.</font></font><br>
<br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analyse des algorithmes de vision par ordinateur existants</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La vision par ordinateur est la th√©orie de la cr√©ation d'appareils qui peuvent recevoir des images d'objets du monde r√©el, traiter et utiliser les donn√©es obtenues pour r√©soudre divers types de probl√®mes appliqu√©s sans intervention humaine. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les syst√®mes de vision par ordinateur comprennent:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">une ou plusieurs cam√©ras </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">complexe informatique </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logiciel qui fournit des outils de traitement d'image</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Canaux de communication pour la transmission d'informations sur la cible et la t√©l√©m√©trie. </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme indiqu√© pr√©c√©demment, il existe de nombreuses fa√ßons d'identifier les objets qui nous int√©ressent. Dans le cas de la conduite le long d'une ligne, il est n√©cessaire de s√©parer la ligne elle-m√™me du fond contrast√© (une ligne noire sur fond blanc ou une ligne blanche sur fond noir pour une ligne inverse). Les algorithmes utilisant un syst√®me de vision par ordinateur peuvent √™tre divis√©s en plusieurs ¬´√©tapes¬ª de traitement de l'image d'origine: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acquisition d'image</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : les images num√©riques sont obtenues directement √† partir de la cam√©ra, √† partir d'un flux vid√©o transmis √† l'appareil, ou sous forme d'images distinctes. Les valeurs des pixels correspondent g√©n√©ralement √† l'intensit√© lumineuse (images en couleur ou en niveaux de gris), mais peuvent √™tre associ√©es √† diverses mesures physiques, telles que, par exemple, la temp√©rature d'une cam√©ra thermique. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Traitement pr√©liminaire</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: Avant d'appliquer des m√©thodes de vision par ordinateur aux donn√©es vid√©o, un pr√©traitement est n√©cessaire pour introduire certaines conditions, selon la m√©thode utilis√©e. </font><font style="vertical-align: inherit;">Voici des exemples:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suppression du bruit ou de la distorsion caus√©s par le capteur utilis√©</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Flou d'image utilis√© pour se d√©barrasser des petits artefacts qui se produisent lors du fonctionnement de l'appareil photo, des √©l√©ments de d√©compression, du bruit, etc.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Am√©lioration du contraste afin que les bonnes informations puissent √™tre d√©tect√©es plus probablement</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modifier l'exposition aux zones d'ombres ou de hautes lumi√®res</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mise √† l'√©chelle ou recadrage pour mieux distinguer les structures de l'image.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conversion d'une image en monochrome ou modification de sa r√©solution pour des performances syst√®me plus rapides</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mise en √©vidence des d√©tails</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : les d√©tails de l'image de diff√©rents niveaux de difficult√© sont extraits des donn√©es vid√©o. </font><font style="vertical-align: inherit;">Des exemples typiques de tels d√©tails sont les lignes, les bordures, les ar√™tes, les points individuels, les zones caract√©ristiques de toute entit√©. </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D√©tection</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : √† un certain stade du travail du programme, les informations pertinentes au programme sont s√©par√©es du reste de l'image. </font><font style="vertical-align: inherit;">Voici des exemples:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La s√©lection d'un certain ensemble de points d'int√©r√™t en couleur, le nombre de pixels isol√©s qui se ressemblent en quelque sorte (courbure de la figure, couleur, luminosit√©, etc.)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Segmentation d'une ou plusieurs sections d'image contenant un objet caract√©ristique.</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Traitement de haut niveau</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : √† cette √©tape, l'abondance d'informations de l'image est r√©duite √† une taille qui peut √™tre facilement trait√©e, par exemple, un ensemble de certains pixels ou les coordonn√©es de la partie de l'image dans laquelle l'objet d'int√©r√™t est cens√© se trouver. </font><font style="vertical-align: inherit;">Voici des exemples:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Filtrage des valeurs par n'importe quel crit√®re</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√âvaluation de param√®tres tels que les dimensions physiques de l'objet, la forme, son emplacement dans le cadre ou par rapport √† d'autres objets caract√©ristiques</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, il a fallu choisir la biblioth√®que sur la base de laquelle le programme sera cr√©√©. </font><font style="vertical-align: inherit;">Les facteurs cl√©s de mon choix √©taient:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La prise en charge de la biblioth√®que pour l'interface Python en raison de la relative facilit√© d'apprentissage de ce langage par un d√©butant, est une syntaxe simple, qui a un effet b√©n√©fique sur la lisibilit√© du programme.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portabilit√©, c'est-√†-dire </font><font style="vertical-align: inherit;">la possibilit√© d'ex√©cuter un programme en utilisant cette biblioth√®que sur raspberry pi3.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La pr√©valence de la biblioth√®que, qui garantit une communaut√© bien d√©velopp√©e de programmeurs qui peuvent avoir d√©j√† rencontr√© des probl√®mes qui peuvent survenir au cours de votre travail.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parmi les options que j'ai examin√©es, j'ai mis en √©vidence la biblioth√®que ouverte de vision par ordinateur OpenCV, car elle prend en charge Python, poss√®de une documentation en ligne compl√®te. </font><font style="vertical-align: inherit;">Il existe de nombreux articles et instructions sur Internet qui d√©crivent toutes les subtilit√©s du travail avec cette biblioth√®que. </font><font style="vertical-align: inherit;">Il existe un forum officiel de d√©veloppeurs o√π tout le monde peut poser une question √† ce sujet. </font><font style="vertical-align: inherit;">De plus, cette biblioth√®que est impl√©ment√©e dans les langages C / C ++, ce qui garantit les performances du syst√®me, et sa structure prend en charge divers modules qui peuvent √™tre d√©sactiv√©s afin d'augmenter les performances.</font></font><br>
<br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D√©veloppement de logiciels</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir install√© le syst√®me d'exploitation et la configuration initiale de Raspberry pi, mais avant de commencer √† cr√©er le programme, vous devez installer tous les packages n√©cessaires. </font><font style="vertical-align: inherit;">La plupart de ces packages, √† leur tour, sont install√©s √† l'aide du gestionnaire de packages pip (dans le cas de Python 3, pip3)</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt install python3-pip</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les biblioth√®ques suivantes sont install√©es, telles que:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">picamera - biblioth√®que pour travailler avec la cam√©ra raspberry pi</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">numpy - une biblioth√®que pour travailler avec des tableaux de donn√©es multidimensionnelles, sous forme d'images</font></font></li>
</ul><br>
<pre><code class="bash hljs">$ sudo pip3 install picamera<font></font>
$ sudo pip3 install numpy<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
cmake - Utilitaire pour construire automatiquement un programme √† partir du code source </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
cmake-curses-gui - Package GUI (interface graphique) pour cmake</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt-get install cmake cmake-curses-gui libgtk2.0-dev<font></font>
$ sudo apt-get install cmake cmake-curses-gui libgtk2.0-dev<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
biblioth√®ques pour travailler avec diff√©rents formats d'image et vid√©o et plus</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libx264-dev libxvidcore-dev<font></font>
$ sudo apt-get install libjpeg-dev libpng12-dev libtiff5-dev libjasper-dev<font></font>
$ sudo apt-get install gfortran libatlas-base-dev<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour transmettre des donn√©es vid√©o du robot √† l'ordinateur, GStreamer sera utilis√© - un cadre con√ßu pour recevoir, traiter et transmettre des donn√©es multim√©dias:</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo apt install libgstreamer1.0-0 gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'√©tape suivante consiste √† installer la biblioth√®que openCV elle-m√™me √† partir des sources, √† la configurer et √† la cr√©er. </font><font style="vertical-align: inherit;">Pour ce faire, un dossier de travail opencv est cr√©√©.</font></font><br>
<br>
<pre><code class="bash hljs">$ mkdir opencv<font></font>
$ <span class="hljs-built_in">cd</span> opencv
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Afin de t√©l√©charger les derni√®res versions de la biblioth√®que, wget est utilis√© - un programme de console pour t√©l√©charger des fichiers depuis le r√©seau. </font><font style="vertical-align: inherit;">Au moment de la cr√©ation du programme, la derni√®re version stable d'openCV est 4.1.0, alors t√©l√©chargez et d√©compressez les sources:</font></font><br>
<br>
<pre><code class="bash hljs">$ wget https://github.com/opencv/opencv/archive/4.1.0.zip -O opencv_source.zip<font></font>
$ unzip opencv_source.zip<font></font>
$ wget https://github.com/opencv/opencv_contrib/archive/4.1.0.zip -O opencv_contrib.zip<font></font>
$ unzip opencv_contrib.zip<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une fois le processus de d√©compression termin√©, les archives source peuvent √™tre supprim√©es.</font></font><br>
<br>
<pre><code class="bash hljs">$ rm opencv_source.zip<font></font>
$ rm opencv_contrib.zip<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un r√©pertoire est cr√©√© pour l'assemblage et la configuration.</font></font><br>
<br>
<pre><code class="bash hljs">$ <span class="hljs-built_in">cd</span> /home/pi/opencv/opencv-4.1.0<font></font>
$ mkdir build<font></font>
$ <span class="hljs-built_in">cd</span> build
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les param√®tres de construction sont configur√©s √† l'aide de l'utilitaire cmake. </font><font style="vertical-align: inherit;">Pour ce faire, tous les param√®tres significatifs sont pass√©s en tant que variables d'utilit√©, avec les valeurs affect√©es:</font></font><br>
<br>
<pre><code class="cmake hljs">cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D INSTALL_PYTHON_EXAMPLES=<span class="hljs-keyword">ON</span> -D INSTALL_C_EXAMPLES=<span class="hljs-keyword">OFF</span> -D BUILD_opencv_python2=<span class="hljs-keyword">OFF</span> -D WITH_GSTREAMER=<span class="hljs-keyword">ON</span> -D BUILD_EXAMPLES=<span class="hljs-keyword">ON</span> -DENABLE_VFPV3=<span class="hljs-keyword">ON</span> -DENABLE_NEON=<span class="hljs-keyword">ON</span> -DCPU_BASELINE=NEON ..
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir configur√© la configuration, l'utilitaire affichera tous les param√®tres. Ensuite, vous devez compiler la biblioth√®que. Pour ce faire, utilisez la commande console make ‚ÄìjN, o√π N est le nombre de c≈ìurs qui seront impliqu√©s dans le processus de compilation. Pour Raspberry Pi 3, le nombre de c≈ìurs est de 4, mais vous pouvez certainement trouver ce nombre en √©crivant la commande nproc dans la console.</font></font><br>
<br>
<pre><code class="bash hljs">$ make ‚Äìj4</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En raison des ressources limit√©es de la framboise, la compilation peut prendre un certain temps. </font><font style="vertical-align: inherit;">Dans certains cas, les framboises peuvent m√™me geler, mais si vous allez plus tard dans le dossier de construction et r√©enregistrez make, le travail continuera. </font><font style="vertical-align: inherit;">Si cela se produit, cela vaut la peine de r√©duire le nombre de c≈ìurs impliqu√©s, cependant, ma compilation s'est d√©roul√©e sans probl√®me. </font><font style="vertical-align: inherit;">De plus, √† ce stade, il vaut la peine de penser au refroidissement actif de la framboise, car m√™me avec elle, la temp√©rature du processeur a atteint environ 75 degr√©s. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque la compilation a r√©ussi, la biblioth√®que doit √™tre install√©e. </font><font style="vertical-align: inherit;">Cela se fait √©galement √† l'aide de l'utilitaire make. </font><font style="vertical-align: inherit;">Ensuite, nous formerons toutes les connexions n√©cessaires avec l'utilitaire ldconfig:</font></font><br>
<br>
<pre><code class="bash hljs">$ sudo make install<font></font>
$ sudo ldconfig<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous v√©rifions l'installation en √©crivant les commandes suivantes en mode interactif python:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> cv2<font></font>
print(cv2.getBuildInformation())<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La conclusion suivante du programme sera la preuve de l'installation correcte. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/np/vi/ng/npving2rmncveg11-8qxvhvco1q.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient de noter que la proc√©dure de compilation de la biblioth√®que ci-dessus doit √™tre effectu√©e √† la fois sur le robot et sur le PC √† partir duquel il est pr√©vu de contr√¥ler le robot et sur lequel la diffusion sera re√ßue du robot. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cr√©ation d'un sch√©ma de distribution vid√©o</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avant de commencer √† √©crire du code, vous devez d√©velopper un sch√©ma selon lequel l'algorithme fonctionnera. Dans le cas consid√©r√© du d√©veloppement de logiciels pour un robot cr√©√© pour participer aux comp√©titions de la RTK Cup dans la nomination Extreme, le programme entier sera divis√© en deux parties: un robot et une t√©l√©commande, qui seront jou√©es par un ordinateur avec Linux install√©. L'une des t√¢ches les plus importantes ici consiste √† cr√©er un sch√©ma approximatif de la fa√ßon dont les donn√©es vid√©o seront transmises entre les diff√©rentes parties de l'algorithme. Le Wi-Fi sera utilis√© comme canal de communication entre les deux appareils. Les paquets de donn√©es assurant le contr√¥le du robot et les donn√©es de retour seront transmis d'un appareil √† un autre en utilisant le protocole UDP impl√©ment√© dans l'utilisation de la biblioth√®que de sockets. Donn√©es vid√©oen raison des limitations de la taille du paquet UDP sera transmis √† l'aide de GStreamer. Pour faciliter le d√©bogage, deux flux vid√©o seront mis en ≈ìuvre:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">flux vid√©o principal - transf√®re les donn√©es vid√©o directement de la cam√©ra du robot vers un ordinateur pour garantir un d√©lai de contr√¥le minimal.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">flux vid√©o auxiliaire - transf√®re les donn√©es vid√©o trait√©es par le robot, n√©cessaires √† la configuration et au d√©bogage d'un programme qui met en ≈ìuvre la vision par ordinateur.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deux flux vid√©o seront simultan√©ment actifs sur le robot et l'ordinateur affichera l'image souhait√©e en fonction du mode d'entra√Ænement activ√©. </font><font style="vertical-align: inherit;">Le robot, √† son tour, selon que le mode d'autonomie est activ√© ou d√©sactiv√©, utilisera des donn√©es de contr√¥le re√ßues d'un ordinateur ou g√©n√©r√©es par un processeur d'images. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/zw/0l/uw/zw0luwrmjjesbm1ygsra6gxtkm4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La t√©l√©commande du robot sera r√©alis√©e gr√¢ce au travail de deux flux parall√®les sur le robot et sur l'ordinateur:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La ¬´console¬ª dans un cycle interroge tous les p√©riph√©riques d'entr√©e disponibles et forme un paquet de donn√©es de contr√¥le compos√© des donn√©es elles-m√™mes et de la somme de contr√¥le (au moment d'apporter les derni√®res modifications √† l'article, j'ai refus√© de cr√©er des sommes de contr√¥le afin de r√©duire le d√©lai, mais dans la source, que j'ai dispos√© √† la fin de ce morceau de code est laiss√©) - d'une certaine valeur calcul√©e √† partir d'un ensemble de donn√©es par le fonctionnement d'un algorithme utilis√© pour d√©terminer l'int√©grit√© des donn√©es pendant la transmission</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robot - Attend l'acc√®s aux donn√©es depuis l'ordinateur. </font><font style="vertical-align: inherit;">D√©compresse les donn√©es, recalcule la somme de contr√¥le et la compare avec celle envoy√©e et calcul√©e c√¥t√© ordinateur. </font><font style="vertical-align: inherit;">Si les sommes de contr√¥le correspondent, les donn√©es sont transf√©r√©es vers le programme principal.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avant d'analyser l'algorithme de d√©tection de ligne, je vous sugg√®re de vous familiariser avec les fonctionnalit√©s de conception du robot:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√† propos du robot</font></font></b><div class="spoiler_text">          .<br>
<br>
<img src="https://habrastorage.org/webt/vw/ao/ex/vwaoexwehb49titxcgdis_ryonc.jpeg" width="200" align="right"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"></a> ‚Äî       .      (3  )        .                 ,      .      6 ,        .           .      .          .     ,    -  .     ¬´¬ª   rasberry pi 3 b ‚Äî      .<br>
<br>
<img src="https://habrastorage.org/webt/ho/zw/bi/hozwbiptp_fihoiqncxq2zsbpim.png" width="200" align="left"> ,       ,   ,   ,   Solidworks    petg .    ,     raspberry        .<br>
<br>
<img src="https://habrastorage.org/webt/mh/po/bd/mhpobduedmyoxzrdbhhac2ewdpq.png" width="200" align="left">          ubiquiti bullet M5 hp.     (   )      ,          .   ,   ¬´¬ª  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"> </a> . <br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ti/h_/7l/tih_7l74vjx8leso89cwynfpb3o.jpeg" width="400"></div><br>
:     ¬´¬ª     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">  thingiverse</a>.    ,  ,   ,      ,          .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wd/df/q_/wddfq_nyi7-xcqmdiil5glkybqe.gif" width="300"></div><br>
   ,     ,   .       ,     .              ,  ,        ,     ,    .     ,       ,        ,     .<br>
<br>
<img src="https://habrastorage.org/webt/sl/ju/f9/sljuf9jwaqm2kdadelgsgubyf5o.gif" width="450"><br>
<br>
<img src="https://habrastorage.org/webt/sg/xk/_k/sgxk_kt1f0xdxkg4igwgzmbudk0.png" width="250"><br>
<br>
-     (   -  200 )    ,       ,     90       70   (     ),          ,     ¬´ ¬ª. ,            VL53L0X        ,      .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jq/wh/hc/jqwhhc7et4crpin64qkaw6txgk0.png" width="250"></div><br>
 ¬´¬ª     ,     ,    (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">rds3115</a>).    ‚Äî ,     ,  ,     ,     .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/4p/ot/ic/4poticuqt_itsiasls1of3927ma.jpeg" width="250"></div><br>
      ,      ,    ,   :<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qc/w5/ol/qcw5olk3klaxq75typuz41hdt18.png" width="250"></div><br>
- ,       ,          ,      .           . <img src="https://habrastorage.org/webt/he/4o/kp/he4okpaqyd5pof9x1cjwc1aalwi.jpeg" width="200" align="left">        raspberry,      ,     .       ,      .<br>
<br>
     ,   USB.            ,            ,     .<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/wv/yr/rqwvyr8kv5dtvpgz6x7rahoyfho.gif" width="200"></div><br>
<i>        </i><br>
</div></div><br>
<h3><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cr√©ation d'un algorithme de d√©tection de ligne utilisant les m√©thodes de la biblioth√®que OpenCV</font></font></font></h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I. Obtention de donn√©es</font></font></b> <br>
<br>
<img src="https://habrastorage.org/webt/ua/q7/zo/uaq7zojtflqtezqkiq2meem5mam.png" width="300" align="right"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √âtant donn√© que le processeur d'image ne re√ßoit pas de donn√©es vid√©o directement de la cam√©ra, mais du flux principal, il est n√©cessaire de les transf√©rer du format utilis√© pour la traduction vers le format utilis√© pour le traitement d'image, √† savoir un tableau numpy compos√© de valeurs rouges , vert et bleu pour chacun des pixels. </font><font style="vertical-align: inherit;">Pour ce faire, vous avez besoin des donn√©es initiales - une trame re√ßue du module de cam√©ra raspberry pi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La fa√ßon la plus simple d'obtenir des images de l'appareil photo c pour un traitement ult√©rieur consiste √† utiliser la biblioth√®que picamera. </font><font style="vertical-align: inherit;">Avant de commencer, vous devez autoriser l'acc√®s √† la cam√©ra via raspi-config -&gt; options d'interface cam√©ra -&gt; s√©lectionner oui.</font></font><br>
<br>
<pre><code class="bash hljs">sudo raspi-config</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
la section suivante de code est connect√©e √† la cam√©ra framboise et dans un cycle avec une fr√©quence donn√©e re√ßoit des trames sous la forme d'un tableau pr√™t √† l'emploi par la biblioth√®que opencv.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> picamera.array <span class="hljs-keyword">import</span> PiRGBArray
<span class="hljs-keyword">from</span> picamera <span class="hljs-keyword">import</span> PiCamera
<span class="hljs-keyword">import</span> cv2
<span class="hljs-comment">#   </span><font></font>
camera = PiCamera()<font></font>
camera.resolution = (<span class="hljs-number">640</span>, <span class="hljs-number">480</span>) <font></font>
camera.framerate = <span class="hljs-number">30</span>
cap = PiRGBArray(camera, size=(<span class="hljs-number">640</span>, <span class="hljs-number">480</span>))<font></font>
<font></font>
<span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> camera.capture_continuous(cap , format=<span class="hljs-string">"bgr"</span>, use_video_port=<span class="hljs-literal">True</span>):<font></font>
	new_frame = frame.array<font></font>
	cap.truncate(<span class="hljs-number">0</span>)
	<span class="hljs-keyword">if</span> <span class="hljs-literal">False</span>: <span class="hljs-comment">#   -   </span>
		<span class="hljs-keyword">break</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient √©galement de noter que cette m√©thode de capture d'images, bien qu'elle soit la plus simple, mais pr√©sente un inconv√©nient s√©rieux: elle n'est pas tr√®s efficace si vous devez diffuser des images via GStreamer, car cela n√©cessite plusieurs fois de r√©encoder la vid√©o, ce qui r√©duit la vitesse du programme. </font><font style="vertical-align: inherit;">Un moyen beaucoup plus rapide d'obtenir des images sera de sortir des images du flux vid√©o √† la demande du processeur d'image, cependant, les √©tapes ult√©rieures du traitement d'image ne d√©pendront pas de la m√©thode utilis√©e. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un exemple d'image d'une cam√©ra de cap de robot sans traitement:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/bo/yi/ez/boyiezf6vfa1nqrlcdllhwbmsgg.png" width="350"></div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">II. Pr√©-traitement</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Lorsque vous conduisez sur une ligne, il sera plus simple de s√©parer la zone de points qui contraste le plus avec la couleur d'arri√®re-plan. Cette m√©thode est id√©ale pour la comp√©tition RTK Cup, car elle utilise une ligne noire sur fond blanc (ou une ligne blanche sur fond noir pour les sections inverses). Afin de r√©duire la quantit√© d'informations √† traiter, vous pouvez lui appliquer un algorithme de binarisation, c'est-√†-dire convertir l'image au format monochrome, o√π il n'y a que deux types de pixels - sombre et clair. Avant cela, l'image doit √™tre traduite en niveaux de gris et √©galement floue afin de supprimer les petits d√©fauts et le bruit qui appara√Æt in√©vitablement lors du fonctionnement de l'appareil photo. Pour brouiller l'image, un filtre gaussien est utilis√©.</font></font><br>
<br>
<pre><code class="python hljs">gray = cv2.cvtColor(self._frame, cv2.COLOR_RGB2GRAY)<font></font>
blur = cv2.GaussianBlur(gray, (ksize, ksize), <span class="hljs-number">0</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
o√π ksize est la taille du noyau gaussien, ce qui augmente, vous pouvez augmenter le degr√© de flou. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exemple d'image apr√®s traduction en niveaux de gris et flou:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/5h/_d/ye5h_d7dqttbxo_af3hhkxnllce.png" width="350"></div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">III. </font><font style="vertical-align: inherit;">S√©lection des d√©tails Une</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
fois l'image traduite en niveaux de gris, il est n√©cessaire de la binariser √† un seuil donn√©. </font><font style="vertical-align: inherit;">Cette action vous permet de r√©duire encore la quantit√© de donn√©es. Cette valeur seuil sera ajust√©e avant chaque d√©part du robot dans un nouvel endroit, ou lorsque les conditions d'√©clairage changent. </font><font style="vertical-align: inherit;">Id√©alement, la t√¢che de calibrage est de s'assurer que le contour de la ligne est d√©fini sur l'image, mais en m√™me temps, il ne devrait pas y avoir d'autres d√©tails sur l'image qui ne sont pas une ligne:</font></font><br>
<br>
<pre><code class="python hljs">thresh = cv2.threshold(blur, self._limit, <span class="hljs-number">255</span>, cv2.THRESH_BINARY_INV)[<span class="hljs-number">1</span>]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ici, tous les pixels plus sombres que la valeur seuil (self._limit) sont remplac√©s par 0 (noir), plus clair - par 255 (blanc). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s le traitement, l'image se pr√©sente comme suit:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ne/rq/tl/nerqtlzt7p-k0q-4quw6nhsbfau.png" width="350"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous pouvez le voir, le programme a identifi√© plusieurs des parties les plus sombres de l'image. </font><font style="vertical-align: inherit;">Cependant, apr√®s avoir calibr√© la valeur de seuil de mani√®re √† ¬´attraper¬ª compl√®tement le casque, d'autres √©l√©ments blancs apparaissent √† l'√©cran en plus d'eux. </font><font style="vertical-align: inherit;">Bien s√ªr, vous pouvez affiner le seuil, et sur le terrain d'entra√Ænement comp√©titif, la cam√©ra baissera les yeux, ne permettant pas la pr√©sence d'√©l√©ments inutiles dans le cadre, mais je consid√®re qu'il est n√©cessaire pour moi de s√©parer la ligne de tout le reste. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IV.D√©tection</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans l'image binaris√©e, j'ai appliqu√© un algorithme de recherche de bordure. </font><font style="vertical-align: inherit;">Il est n√©cessaire pour d√©terminer les points autonomes et les transformer en un tableau pratique de valeurs de coordonn√©es de points qui composent la fronti√®re. </font><font style="vertical-align: inherit;">Dans le cas d'opencv, comme √©crit dans la documentation, l'algorithme standard pour trouver des boucles utilise l'algorithme Suzuki85 (je n'ai pu trouver de r√©f√©rences √† l'algorithme avec ce nom nulle part sauf pour la documentation opencv, mais je suppose que c'est l'algorithme </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suzuki-Abe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<pre><code class="python hljs">contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[<span class="hljs-number">0</span>]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et voici le cadre obtenu √† ce stade:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ex/3r/gx/ex3rgxc7bmefqdwhetn5wfxrtko.png" width="350"></div><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">V. Traitement de haut niveau</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir trouv√© tous les contours dans le cadre, le contour avec la plus grande zone est s√©lectionn√© et pris comme contour de la ligne. Connaissant les coordonn√©es de tous les points de ce contour, la coordonn√©e de son centre est trouv√©e. Pour cela, les soi-disant "moments d'image" sont utilis√©s. Le moment est la caract√©ristique totale du contour, calcul√©e en additionnant les coordonn√©es de tous les pixels du contour. Il existe plusieurs types de moments - jusqu'au troisi√®me ordre. Pour ce probl√®me, seul le moment d'ordre z√©ro (m00) est n√©cessaire - le nombre de tous les points constituant le contour (p√©rim√®tre de contour), le moment de premier ordre (m10), qui est la somme des coordonn√©es X de tous les points, et m01 est la somme des coordonn√©es Y de tous les points. En divisant la somme des coordonn√©es des points le long d'un des axes par leur nombre, la moyenne arithm√©tique est obtenue - la coordonn√©e approximative du centre du contour. Ensuite, l'√©cart du robot par rapport au parcours est calcul√©:le parcours correspond ¬´directement¬ª √† la coordonn√©e du point central le long de X proche de la largeur du cadre divis√©e par deux. Si la coordonn√©e du centre de la ligne est proche du centre du cadre, l'action de contr√¥le est minimale et, par cons√©quent, le robot conserve sa trajectoire actuelle. Si le robot s'√©carte de l'un des c√¥t√©s, une action de contr√¥le proportionnelle √† l'√©cart sera introduite jusqu'√† son retour.</font></font><br>
<br>
<pre><code class="python hljs">mainContour = max(contours, key = cv2.contourArea)<font></font>
M = cv2.moments(mainContour)<font></font>
<span class="hljs-keyword">if</span> M[<span class="hljs-string">'m00'</span>] != <span class="hljs-number">0</span>:<span class="hljs-comment">#     (..   -  )</span>
    cx = int(M[<span class="hljs-string">'m10'</span>]/M[<span class="hljs-string">'m00'</span>])<font></font>
    cy = int(M[<span class="hljs-string">'m01'</span>]/M[<span class="hljs-string">'m00'</span>])
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ci-dessous, un sch√©ma de la position du robot par rapport √† la ligne et aux cadres, avec les r√©sultats du programme superpos√©s: le contour ¬´principal¬ª, les lignes passant par le centre du contour, ainsi que le point situ√© au centre pour estimer l'√©cart. </font><font style="vertical-align: inherit;">Ces √©l√©ments sont ajout√©s √† l'aide du code suivant:</font></font><br>
<br>
<pre><code class="python hljs">cv2.line(frame, (cx, <span class="hljs-number">0</span>), (cx, self.height), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)    <span class="hljs-comment">#    </span>
cv2.line(frame, (<span class="hljs-number">0</span>, cy), (self.width, cy), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)                  <font></font>
cv2.circle(frame, (self.width//<span class="hljs-number">2</span>, self.height//<span class="hljs-number">2</span>), <span class="hljs-number">3</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-number">-1</span>) <span class="hljs-comment">#  </span>
cv2.drawContours(frame, mainContour, <span class="hljs-number">-1</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-number">2</span>, cv2.FILLED) <span class="hljs-comment">#   </span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour faciliter le d√©bogage, tous les √©l√©ments d√©crits pr√©c√©demment sont ajout√©s au cadre brut: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/f4/fl/os/f4flos522ouvlu-vi2b9rr_17lg.png" width="350"><br>
<br>
<img src="https://habrastorage.org/webt/uc/r1/vx/ucr1vxcecjqdv5qdswcbjsltw9w.png" width="350"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainsi, apr√®s avoir conduit le cadre √† travers l'algorithme de traitement, nous avons obtenu les coordonn√©es X et Y du centre de l'objet qui nous int√©resse, ainsi que l'image de d√©bogage. </font><font style="vertical-align: inherit;">Ensuite, la position du robot par rapport √† la ligne est sch√©matis√©e, ainsi que l'image qui a r√©ussi l'algorithme de traitement.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/4r/co/fy/4rcofyknawjnesluhuvoyp9zomu.jpeg" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'√©tape suivante du programme consiste √† convertir les informations obtenues √† l'√©tape pr√©c√©dente en valeurs de puissance de deux moteurs. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/io/s3/gn/ios3gnw-mt2xsmvh_hsfrpsdkdu.jpeg" width="250" align="right"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le moyen le plus simple de convertir la diff√©rence entre le d√©calage du centre de la tache de couleur par rapport au centre du cadre est le r√©gulateur proportionnel (il existe √©galement un r√©gulateur √† relais, mais, en raison des caract√©ristiques de son fonctionnement, il n'est pas tr√®s adapt√© pour la conduite le long de la ligne). Le principe de fonctionnement d'un tel algorithme est que le contr√¥leur g√©n√®re une action de contr√¥le sur l'objet proportionnellement √† l'ampleur de l'erreur. En plus du contr√¥leur proportionnel, il y en a aussi un int√©gral, o√π au fil du temps la composante int√©grale "accumule" l'erreur et les diff√©rentielles, dont le principe est bas√© sur l'application de l'influence r√©glementaire uniquement avec un changement suffisant de la variable contr√¥l√©e. En pratique, ces contr√¥leurs P, I, D les plus simples sont combin√©s en contr√¥leurs de type PI, PD, PID.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient de mentionner que sur mon robot, j'ai essay√© de ¬´d√©marrer¬ª le contr√¥leur PID, mais son utilisation n'a pas donn√© d'avantages s√©rieux par rapport au contr√¥leur proportionnel habituel. J'avoue que je n'ai pas pu r√©gler correctement le r√©gulateur, mais il est √©galement possible que ses avantages ne soient pas aussi clairement visibles dans le cas d'un robot lourd qui est incapable de d√©velopper physiquement des vitesses √©lev√©es. Dans la derni√®re version du programme au moment de la r√©daction, un simple r√©gulateur proportionnel est utilis√©, mais avec une petite fonctionnalit√© qui vous permet d'utiliser plus d'informations de la cam√©ra: lors de la g√©n√©ration de la valeur d'erreur, non seulement la position horizontale du milieu du spot a √©t√© prise en compte, mais aussi verticalement, ce qui a permis diff√©rentes mani√®res r√©pondre aux √©l√©ments de lignesitu√© "au loin" et imm√©diatement devant ou sous le robot (la cam√©ra de direction du robot a un angle de vision √©norme, donc en le tournant √† seulement 45 degr√©s vers le bas, vous pouvez d√©j√† voir une partie importante du champ sous le robot).</font></font><br>
<br>
<pre><code class="python hljs">error= cx / (self.width/<span class="hljs-number">2</span>) - <span class="hljs-number">1</span>  
<span class="hljs-comment">#  ( 0   )  [-1; 1]</span>
error*= cy / self.height + self.gain <span class="hljs-comment">#</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le plus souvent, dans les conditions de la comp√©tition "RTK Cup", les participants utilisent ce que l'on appelle le "circuit du r√©servoir" - un ou plusieurs moteurs contr√¥lent un c√¥t√© du robot, et il fonctionne √† la fois avec des chenilles et avec des roues. L'utilisation de ce sch√©ma vous permet de vous d√©barrasser des √©l√©ments de transmission complexes qui augmentent les risques de casse (diff√©rentiels ou cardans), d'obtenir le plus petit rayon de braquage possible, ce qui donne un avantage dans un polygone confin√©. Ce sch√©ma implique le contr√¥le parall√®le de deux ¬´c√¥t√©s¬ª pour le mouvement le long d'un chemin complexe. Pour ce faire, le programme utilise deux variables - la puissance du moteur droit et gauche. Cette puissance d√©pend de la vitesse de base (BASE_SPEED), variant dans la plage de 0 √† 100.Erreurs (erreur) - la diff√©rence entre le centre du cadre et les coordonn√©es du milieu de la ligne et le coefficient d'effet proportionnel (self._koof), qui est calibr√© par l'op√©rateur. Sa valeur absolue affecte la vitesse √† laquelle le robot tentera de s'aligner sur la ligne. En raison du fait que sur un moteur, l'action de contr√¥le est soustraite de la vitesse de base, et sur l'autre - elle est ajout√©e, un virage est effectu√© en s'√©cartant du cours. La direction dans laquelle l'inversion sera effectu√©e peut √™tre ajust√©e en changeant le signe de la variable self._koof. En outre, vous pouvez remarquer qu'√† la suite de la section de code suivante, une valeur de puissance peut appara√Ætre sup√©rieure √† 100, mais dans mon programme, de tels cas sont en outre trait√©s ult√©rieurement.Sa valeur absolue affecte la vitesse √† laquelle le robot tentera de s'aligner sur la ligne. En raison du fait que sur un moteur, l'action de contr√¥le est soustraite de la vitesse de base, et sur l'autre - elle est ajout√©e, un virage est effectu√© en s'√©cartant du cours. La direction dans laquelle l'inversion sera effectu√©e peut √™tre ajust√©e en changeant le signe de la variable self._koof. En outre, vous pouvez remarquer qu'√† la suite de la section de code suivante, une valeur de puissance peut appara√Ætre sup√©rieure √† 100, mais dans mon programme, de tels cas sont en outre trait√©s ult√©rieurement.Sa valeur absolue affecte la vitesse √† laquelle le robot tentera de s'aligner sur la ligne. En raison du fait que sur un moteur, l'action de contr√¥le est soustraite de la vitesse de base, et sur l'autre - elle est ajout√©e, un virage est effectu√© en s'√©cartant du cours. La direction dans laquelle l'inversion sera effectu√©e peut √™tre ajust√©e en changeant le signe de la variable self._koof. En outre, vous pouvez remarquer qu'√† la suite de la section de code suivante, une valeur de puissance peut appara√Ætre sup√©rieure √† 100, mais dans mon programme, de tels cas sont en outre trait√©s ult√©rieurement.dans lequel l'inversion sera effectu√©e, vous pouvez ajuster en changeant le signe de la variable self._koof. En outre, vous pouvez remarquer qu'√† la suite de la section de code suivante, une valeur de puissance peut appara√Ætre sup√©rieure √† 100, mais dans mon programme, de tels cas sont en outre trait√©s ult√©rieurement.dans lequel l'inversion sera effectu√©e, vous pouvez ajuster en changeant le signe de la variable self._koof. En outre, vous pouvez remarquer qu'√† la suite de la section de code suivante, une valeur de puissance peut appara√Ætre sup√©rieure √† 100, mais dans mon programme, de tels cas sont en outre trait√©s ult√©rieurement.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#if lineFound:</span><font></font>
leftSpeed = round(self.base_speed + error*self.koof)<font></font>
rightSpeed = round(self.base_speed - error*self.koof)<font></font>
</code></pre><br>
<h2><font color="#4d7f95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir test√© le programme r√©sultant, je peux dire que le principal moment difficile dans la mise en place du programme est l'√©talonnage de l'algorithme aux caract√©ristiques d'√©clairage. </font><font style="vertical-align: inherit;">√âtant donn√© que l'√©tape de cr√©ation de l'article co√Øncidait avec l'auto-isolement d√©clar√©, j'ai d√ª cr√©er une vid√©o avec une d√©monstration du travail dans une petite pi√®ce. </font><font style="vertical-align: inherit;">Cela m'a pos√© les difficult√©s suivantes:</font></font><br>
<br>
<ul>
<li> -,    ,    (   ,     ),        .        ,    ,         ,      .      ,     , ,            ,              </li>
<li> -,       ‚Äî    ,   ,         </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Malgr√© le fait que ces deux probl√®mes soient absents dans les conditions des comp√©titions r√©elles, je prendrai des mesures pour que le travail du programme d√©pende au minimum de facteurs externes. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aussi, √† l'avenir, il est pr√©vu de poursuivre les travaux sur la mise en ≈ìuvre d'algorithmes utilisant des m√©thodes de vision par ordinateur, en cr√©ant des logiciels capables de traverser les √©l√©ments d'autonomie restants d√©crits dans la premi√®re partie de l'article (capture de balise autonome, d√©placement le long d'un chemin complexe). Il est pr√©vu d'√©tendre les fonctionnalit√©s du robot en ajoutant des capteurs suppl√©mentaires: t√©l√©m√®tre, gyroscope-acc√©l√©rom√®tre, boussole. Malgr√© le fait que la publication de cet article mettra fin √† mes travaux sur le projet en tant que mati√®re scolaire obligatoire, je compte continuer √† d√©crire ici les √©tapes ult√©rieures de d√©veloppement. Par cons√©quent, j'aimerais recevoir des commentaires sur ce travail.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir mis en ≈ìuvre toutes les √©tapes visant √† r√©soudre les probl√®mes du projet, il est s√ªr de dire que l'utilisation d'algorithmes de vision par ordinateur, avec toute sa complexit√© relative dans la programmation et le d√©bogage, donne le plus grand gain au stade des comp√©titions elles-m√™mes. Avec les petites dimensions de la cam√©ra, elle a un √©norme potentiel en termes de d√©veloppement logiciel, car la cam√©ra vous permet de remplacer plusieurs capteurs "traditionnels" √† la fois, tout en recevant incroyablement plus d'informations du monde ext√©rieur. Il a √©t√© possible de r√©aliser l'objectif du projet - cr√©er un programme qui utilise la vision par ordinateur pour r√©soudre le probl√®me de la navigation autonome du robot dans les conditions de la comp√©tition ¬´RTK Cup¬ª, ainsi que d√©crire le processus de cr√©ation du programme et les principales √©tapes du traitement d'image.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme je l'ai dit pr√©c√©demment, il n'a pas √©t√© possible de recr√©er la trajectoire complexe de la ligne de maison, et cet exemple montre comment l'algorithme remplit les virages. </font><font style="vertical-align: inherit;">L'√©paisseur de la ligne correspond ici √† celle selon la r√©glementation, et la plus grande courbe des spires refl√®te approximativement la courbure de rotation de 90 degr√©s sur le polygone:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/YmHk3f-qQ5E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez voir le code du programme, ainsi que surveiller les travaux ult√©rieurs sur le projet, sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mon github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou ici, si je continue.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr497286/index.html">Ludum Dare: check-list une semaine avant le d√©part</a></li>
<li><a href="../fr497288/index.html">Plafonnier d√©coratif Feron AL5000</a></li>
<li><a href="../fr497290/index.html">Am√©lioration des performances √† l'aide du cache uop sur Sandy Bridge +</a></li>
<li><a href="../fr497292/index.html">Jeux de technologie Shiro</a></li>
<li><a href="../fr497296/index.html">Erreurs populaires en anglais parmi les professionnels de l'informatique. Partie 2: Prononciation</a></li>
<li><a href="../fr497304/index.html">Intercepter-NG 2.5 publi√© pour Android</a></li>
<li><a href="../fr497306/index.html">Usurpation de DLL (d√©tournement de DLL)</a></li>
<li><a href="../fr497308/index.html">L'intelligence artificielle peut-elle faire de l'art?</a></li>
<li><a href="../fr497310/index.html">R√©seaux morphologiques bipolaires: un neurone sans multiplication</a></li>
<li><a href="../fr497312/index.html">Question sur CAN FD</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏼‍🤝‍👨🏾 👩🏼‍✈️ 👎🏾 Streaming column data using Apache Arrow 🤛🏻 💬 👸🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A translation of the article was prepared specifically for students of the Data Engineer course .
 
 
 
 Over the past few weeks, Nong Li and I have a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Streaming column data using Apache Arrow</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/490050/"><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A translation of the article was prepared specifically for students of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the Data Engineer</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> course </font><font style="vertical-align: inherit;">.</font></font></i></b><br>
<br>
<img src="https://habrastorage.org/webt/6b/3m/kz/6b3mkzihfzscol1hedy_gppa2f0.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Over the past few weeks, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nong Li and I</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> have added a </font><font style="vertical-align: inherit;">binary streaming format </font><font style="vertical-align: inherit;">to </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apache Arrow</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , complementing the existing random access / IPC file format. </font><font style="vertical-align: inherit;">We have implementations in Java and C ++ and Python bindings. </font><font style="vertical-align: inherit;">In this article I will tell you how the format works and show how you can achieve very high data throughput for DataFrame pandas.</font></font><a name="habracut"></a><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Column data streaming</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 A common question I get from Arrow users is the question of the high cost of moving large sets of tabular data from a row-oriented or row-oriented format to a column format. For multi-gigabyte datasets, transposing in memory or on disk can be an overwhelming task. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For streaming data, regardless of whether the source data is string or column, one option is to send small packets of strings, each of which inside contains a column layout. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Apache Arrow, a collection of in-memory column arrays representing a table chunk is called a record batch. To represent a single data structure of a logical table, several record packages can be assembled.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the existing “random access” file format, we record metadata containing the table layout and the location of the blocks at the end of the file, which allows you to extremely cheaply select any record package or any column from the data set. </font><font style="vertical-align: inherit;">In a streaming format, we send a series of messages: a scheme, and then one or more packets of records. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The different formats look something like the one shown in this figure:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/of/kd/jq/ofkdjqyesvfqkmj92jntxjuqani.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyArrow Streaming: Application</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 To show you how this works, I will create an example dataset representing a single stream chunk:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">import</span> time
<span class="hljs-attribute">import</span> numpy as np
<span class="hljs-attribute">import</span> pandas as pd
<span class="hljs-attribute">import</span> pyarrow as pa<font></font>
<font></font>
<span class="hljs-attribute">def</span> generate_data(total_size, ncols):
    <span class="hljs-attribute">nrows</span> = int(total_size / ncols / np.dtype('float<span class="hljs-number">64</span>').itemsize)
    <span class="hljs-attribute">return</span> pd.DataFrame({<font></font>
        '<span class="hljs-attribute">c</span>' + str(i): np.random.randn(nrows)
        <span class="hljs-attribute">for</span> i in range(ncols)<font></font>
    })	</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Now, suppose we want to record 1 GB of data consisting of chunks of 1 MB each, for a total of 1024 chunks. </font><font style="vertical-align: inherit;">First, let's create the first 1 MB data frame with 16 columns:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">KILOBYTE</span> = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">10</span>
<span class="hljs-attribute">MEGABYTE</span> = KILOBYTE * KILOBYTE
<span class="hljs-attribute">DATA_SIZE</span> = <span class="hljs-number">1024</span> * MEGABYTE
<span class="hljs-attribute">NCOLS</span> = <span class="hljs-number">16</span><font></font>
<font></font>
<span class="hljs-attribute">df</span> = generate_data(MEGABYTE, NCOLS)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Then I convert them to </font></font><code>pyarrow.RecordBatch</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">batch</span> = pa.RecordBatch.from_pandas(df)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Now I will create an output stream that will write to RAM and create </font></font><code>StreamWriter</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">sink</span> = pa.InMemoryOutputStream()
<span class="hljs-attribute">stream_writer</span> = pa.StreamWriter(sink, batch.schema)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Then we write 1024 chunks, which will eventually make up a 1GB data set:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">for</span> i in range(DATA_SIZE // MEGABYTE):
    <span class="hljs-attribute">stream_writer</span>.write_batch(batch)</code></pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Since we wrote in RAM, we can get the entire stream in one buffer:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">In</span><span class="hljs-meta"> [13]: source = sink.get_result()

In [14]: source
Out[14]: &lt;pyarrow.io.Buffer at 0x7f2df7118f80&gt;

In [15]: source.size
Out[15]: 1074750744</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Since this data is in memory, reading out Arrow record packets is a zero-copy operation. </font><font style="vertical-align: inherit;">I open StreamReader, read the data in </font></font><code>pyarrow.Table</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, and then convert it to </font></font><code>DataFrame pandas</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">In</span><span class="hljs-meta"> [16]: reader = pa.StreamReader(source)

In [17]: table = reader.read_all()

In [18]: table
Out[18]: &lt;pyarrow.table.Table at 0x7fae8281f6f0&gt;

In [19]: df = table.to_pandas()

In [20]: df.memory_usage().sum()
Out[20]: 1073741904</span></code></pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 All this, of course, is good, but you may have questions. </font><font style="vertical-align: inherit;">How fast is this going on? </font><font style="vertical-align: inherit;">How does chunk size affect the performance of getting DataFrame pandas?</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Streaming Performance</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 As the size of the streaming chunk decreases, the cost of reconstructing a continuous DataFrame column in pandas increases due to inefficient cache access schemes. There is also some overhead from working with C ++ data structures and arrays and their memory buffers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For 1 MB, as mentioned above, on my laptop (Quad-core Xeon E3-1505M) it turns out:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">In</span><span class="hljs-meta"> [20]: %timeit pa.StreamReader(source).read_all().to_pandas()
10 loops, best of 3: 129 ms per loop</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 It turns out that the effective bandwidth is 7.75 Gb / s for restoring a 1Gb DataFrame of 1024 chunks of 1MB each. </font><font style="vertical-align: inherit;">What happens if we use larger or smaller chunks? </font><font style="vertical-align: inherit;">Here are the results: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/_2/qz/4j/_2qz4j7k7keun29itu0bx-cnklw.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Performance drops significantly from 256K to 64K chunks. </font><font style="vertical-align: inherit;">I was surprised that 1 MB chunks processed faster than 16 MB. </font><font style="vertical-align: inherit;">It is worthwhile to conduct a more thorough study and understand whether this is a normal distribution or if something else affects it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the current implementation of the format, the data is not compressed in principle, therefore the size in the memory and in the wires is approximately the same. </font><font style="vertical-align: inherit;">In the future, compression may become an additional option.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Streaming column data can be an effective way to transfer large data sets to column analysis tools, such as pandas, using small chunks. </font><font style="vertical-align: inherit;">Data services using line-oriented storage can transfer and transpose small data chunks that are more convenient for your processor’s L2 and L3 cache. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Full code</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">import</span> time
<span class="hljs-attribute">import</span> numpy as np
<span class="hljs-attribute">import</span> pandas as pd
<span class="hljs-attribute">import</span> pyarrow as pa<font></font>
<font></font>
<span class="hljs-attribute">def</span> generate_data(total_size, ncols):
    <span class="hljs-attribute">nrows</span> = total_size / ncols / np.dtype('float<span class="hljs-number">64</span>').itemsize
    <span class="hljs-attribute">return</span> pd.DataFrame({<font></font>
        '<span class="hljs-attribute">c</span>' + str(i): np.random.randn(nrows)
        <span class="hljs-attribute">for</span> i in range(ncols)<font></font>
    })<font></font>
<font></font>
<span class="hljs-attribute">KILOBYTE</span> = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">10</span>
<span class="hljs-attribute">MEGABYTE</span> = KILOBYTE * KILOBYTE
<span class="hljs-attribute">DATA_SIZE</span> = <span class="hljs-number">1024</span> * MEGABYTE
<span class="hljs-attribute">NCOLS</span> = <span class="hljs-number">16</span><font></font>
<font></font>
<span class="hljs-attribute">def</span> get_timing(f, niter):
    <span class="hljs-attribute">start</span> = time.clock_gettime(time.CLOCK_REALTIME)
    <span class="hljs-attribute">for</span> i in range(niter):
        <span class="hljs-attribute">f</span>()
    <span class="hljs-attribute">return</span> (time.clock_gettime(time.CLOCK_REALTIME) - start) / NITER<font></font>
<font></font>
<span class="hljs-attribute">def</span> read_as_dataframe(klass, source):
    <span class="hljs-attribute">reader</span> = klass(source)
    <span class="hljs-attribute">table</span> = reader.read_all()
    <span class="hljs-attribute">return</span> table.to_pandas()
<span class="hljs-attribute">NITER</span> = <span class="hljs-number">5</span>
<span class="hljs-attribute">results</span> =<span class="hljs-meta"> []</span><font></font>
<font></font>
<span class="hljs-attribute">CHUNKSIZES</span> =<span class="hljs-meta"> [16 * KILOBYTE, 64 * KILOBYTE, 256 * KILOBYTE, MEGABYTE, 16 * MEGABYTE]</span><font></font>
<font></font>
<span class="hljs-attribute">for</span> chunksize in CHUNKSIZES:
    <span class="hljs-attribute">nchunks</span> = DATA_SIZE // chunksize
    <span class="hljs-attribute">batch</span> = pa.RecordBatch.from_pandas(generate_data(chunksize, NCOLS))<font></font>
<font></font>
    <span class="hljs-attribute">sink</span> = pa.InMemoryOutputStream()
    <span class="hljs-attribute">stream_writer</span> = pa.StreamWriter(sink, batch.schema)<font></font>
<font></font>
    <span class="hljs-attribute">for</span> i in range(nchunks):
        <span class="hljs-attribute">stream_writer</span>.write_batch(batch)<font></font>
<font></font>
    <span class="hljs-attribute">source</span> = sink.get_result()<font></font>
<font></font>
    <span class="hljs-attribute">elapsed</span> = get_timing(lambda: read_as_dataframe(pa.StreamReader, source), NITER)<font></font>
<font></font>
    <span class="hljs-attribute">result</span> = (chunksize, elapsed)
    <span class="hljs-attribute">print</span>(result)
    <span class="hljs-attribute">results</span>.append(result)</code></pre></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en490034/index.html">ML REPA Meetup at Raffeisenbank: keep broadcasting</a></li>
<li><a href="../en490040/index.html">Python-Celery in Windows with Docker managing</a></li>
<li><a href="../en490042/index.html">Positive Technologies study: 7 out of 8 financial institutions can enter the network from the Internet</a></li>
<li><a href="../en490044/index.html">CRM implementation through the eyes of the customer</a></li>
<li><a href="../en490046/index.html">NDA for development - “residual” clause and other ways to protect yourself</a></li>
<li><a href="../en490052/index.html">iOS apps can steal data from device’s clipboard + MacOS threat monitoring survey</a></li>
<li><a href="../en490054/index.html">17 surprises for my first year using the Tesla Model 3</a></li>
<li><a href="../en490056/index.html">Black Box: forget about logging</a></li>
<li><a href="../en490060/index.html">Search knowledge graph: building from multiple sources</a></li>
<li><a href="../en490066/index.html">From China to the South Pole: Joining forces to solve the neutrino mass puzzle</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
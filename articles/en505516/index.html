<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ò™Ô∏è üë´ ‚úÖ Machine learning: where to start or how to build the first model üôã üèÄ üë©üèº‚Äçüöí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As the first task for machine learning, we take something clear and simple, for example, a forecast of the cost of housing. Ready dataset can be found...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Machine learning: where to start or how to build the first model</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/505516/"><img src="https://habrastorage.org/webt/cn/mg/fr/cnmgfrvs-ej5ldlqz9cmmdjdcrk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As the first task for machine learning, we take something clear and simple, for example, a forecast of the cost of housing. Ready dataset can be found on the kaggle website. In the first steps of training, you should not take datasets with a large number of variables, for example, ‚ÄúHouse Prices: Advanced Regression Techniques‚Äù consists of 80 variables and advanced regression, we will stop at ‚ÄúHouse Sales in King County, USA‚Äù with 21 parameters. Download the data and analyze the description provided. Available date, price, number of bedrooms, bathrooms, total and living area, number of floors, view assessment, sea view, assessment of general condition, grade (assessment of construction and design), area above and below ground level, year of construction, year of last repair, area code, coordinates (longitude and latitude), data on the area of ‚Äã‚Äãhouses of 15 neighbors.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, we have chosen a task and are ready to start solving it. The solution will include two stages: data analysis and model building. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1. Work with data. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's digress and separately note the importance of data analysis. Currently, all the more or less popular algorithms are already written in the form of libraries and the direct construction of the model is reduced to several lines of code, for example, k-nearest neighbors from sklearn in python:</font></font><a name="habracut"></a><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn .neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<font></font>
clf_KNN = KNeighborsClassifier()       <span class="hljs-comment"># </span>
clf_KNN.fit(X_train, Y_train)          <span class="hljs-comment"># </span>
Y_KNN = clf_KNN.predict(X_test)        <span class="hljs-comment">#    </span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Only four lines of code to get the result. So what is the difficulty? The difficulty lies in obtaining the very X_train - the data that is fed to the input of the model. The well-known principle ‚Äúgarbage in‚Äù = ‚Äúgarbage in‚Äù (English Garbage in - garbage out (GIGO)) in modeling works for more than 100% and the quality of the obtained solution to the machine learning problem will largely depend on working with data. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And now - to the battle! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For data analysis we will use pandas, for understanding and evaluating ‚Äúby eye‚Äù we use simple graphs from seaborn. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We import the libraries, read the data, derive several records from the data array, look at the data types and omissions in them. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Code and Out</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<font></font>
df = pd.read_csv(<span class="hljs-string">'‚Ä¶/train.csv'</span>)<font></font>
df.head(<span class="hljs-number">5</span>)</code></pre><br>
<img src="https://habrastorage.org/webt/1q/cy/og/1qcyogx0fmdgtibrhx1l2b5mdty.png"><br>
<br>
<pre><code class="python hljs">df.info()</code></pre><br>
<pre><code class="plaintext hljs">RangeIndex: 21613 entries, 0 to 21612<font></font>
Data columns (total 21 columns):<font></font>
id 21613 non-null int64<font></font>
date 21613 non-null object<font></font>
price 21613 non-null float64<font></font>
bedrooms 21613 non-null int64<font></font>
bathrooms 21613 non-null float64<font></font>
sqft_living 21613 non-null int64<font></font>
sqft_lot 21613 non-null int64<font></font>
floors 21613 non-null float64<font></font>
waterfront 21613 non-null int64<font></font>
view 21613 non-null int64<font></font>
condition 21613 non-null int64<font></font>
grade 21613 non-null int64<font></font>
sqft_above 21613 non-null int64<font></font>
sqft_basement 21613 non-null int64<font></font>
yr_built 21613 non-null int64<font></font>
yr_renovated 21613 non-null int64<font></font>
zipcode 21613 non-null int64<font></font>
lat 21613 non-null float64<font></font>
long 21613 non-null float64<font></font>
sqft_living15 21613 non-null int64<font></font>
sqft_lot15 21613 non-null int64<font></font>
dtypes: float64(5), int64(15), object(1)<font></font>
memory usage: 3.5+ MB</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The data array consists of 21613 records without gaps in the data and contains only 1 text field date. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We‚Äôll work with each sign in more detail and start with the simplest one - throw away id (does not carry useful information), zipcode (the code of the area where the house is located) and coordinates (lat &amp; long), since we only get acquainted with machine learning, and the correct conversion of geographical The data is too specific for a novice specialist.</font></font><br>
<br>
<pre><code class="python hljs">df=df.drop([<span class="hljs-string">'id'</span>,<span class="hljs-string">'zipcode'</span>,<span class="hljs-string">'lat'</span>,<span class="hljs-string">'long'</span>], axis=<span class="hljs-number">1</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now let's look at the date of the announcement. The date format is set to YYYYMMDDTT000000, in general, it could also be removed from the dataset, but we have the fields the year of construction (yr_built) and the year of the last repair (yr_renovated), which are set in the format of the year (YYYY), which is not very informative. Using the date of announcement, you can convert the year into age by subtraction (year of announcement - year of construction / year of repair). We note the repair year is 0 for some houses, and assuming that this means there is no repair from the building, we replace the zeros in the repair year with the year of construction, first making sure that the data does not contain incorrect records where the repair year is less than the year of construction:</font></font><br>
<br>
<pre><code class="python hljs">df[(df[<span class="hljs-string">'yr_renovated'</span>]&lt;df[<span class="hljs-string">'yr_built'</span>])&amp;df[<span class="hljs-string">'yr_renovated'</span>]!=<span class="hljs-number">0</span>]</code></pre><br>
<img src="https://habrastorage.org/webt/l7/wo/ii/l7woii1rk3buxzexbab2i4uokmq.png"><br>
<br>
<pre><code class="python hljs">df.loc[df[<span class="hljs-string">'yr_renovated'</span>]==<span class="hljs-number">0</span>, [<span class="hljs-string">'yr_renovated'</span>]]=df[<span class="hljs-string">'yr_built'</span>]<font></font>
df[<span class="hljs-string">'yr_built'</span>]=df[<span class="hljs-string">'date'</span>].str[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>].astype(int)-df[<span class="hljs-string">'yr_built'</span>]<font></font>
df[<span class="hljs-string">'yr_renovated'</span>]=df[<span class="hljs-string">'date'</span>].str[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>].astype(int)-df[<span class="hljs-string">'yr_renovated'</span>]<font></font>
df=df.drop(<span class="hljs-string">'date'</span>, axis=<span class="hljs-number">1</span>)<font></font>
df.head(<span class="hljs-number">5</span>)</code></pre><br>
<img src="https://habrastorage.org/webt/4z/za/uw/4zzauwyidq18e0lq_8x5-up5e88.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We will analyze the price with the next parameter and use the ‚ÄúBox plot‚Äù for this. A mustache box is a simple and convenient graph showing a one-dimensional probability distribution, or, more simply, the concentration of data. Draws the median (line in the center), the upper and lower quartiles (sides of the box), the edges of the statistically significant sample ("mustache") and outliers (points behind the "mustache"). It is easy to understand from the picture on the normal distribution (right). The graph allows you to quickly assess where most of the data is located (50% are inside the box), their symmetry (the median offset to one side of the box and / or the length of the "mustache") and the degree of dispersion - variance (box size, mustache size and number of points - emissions).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bi/bh/uw/bibhuwyeeexpszcl7sahfpdo8le.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is possible to build a distribution of only this characteristic throughout the array, but it will be more informative to use 2 axes - for example, the price and the number of bedrooms, which in turn will also show the presence of a connection between the signs:</font></font><br>
<br>
<pre><code class="python hljs">sns.boxplot(y=<span class="hljs-string">'price'</span>, data=df)			<span class="hljs-comment"># price</span>
sns.boxplot(y=<span class="hljs-string">'price'</span>, x=<span class="hljs-string">'bedrooms'</span>, data=df)	<span class="hljs-comment">#price &amp; bedrooms</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Out price &amp; bedrooms: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/za/oh/ta/zaohtajsfsedoz8lagkzjto-oa0.png"><br>
<br>
<img src="https://habrastorage.org/webt/fn/em/4g/fnem4gwwbubwzkrhi25i4ly3j4k.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The graph immediately shows the presence of extreme values ‚Äã‚Äãof price and bedrooms (just imagine a house with 33 bedrooms! J). The presence of such values ‚Äã‚Äã(otherwise called as outliers) in the target attribute price often leads to retraining of the model, since they will give a big error, which the algorithms try to minimize. The graph shows that the majority (if calculated - 93.22%) lies in the range of 0-1mln, and over 2mln - only 198 values ‚Äã‚Äã(0.92%). You can get rid of 1% of the dataset almost painlessly, therefore, having called up a simple viewing of 217 records, having previously sorted them by price, we will see the desired price mark of 1 965 000 and delete everything that is higher than this price.</font></font><br>
<br>
<pre><code class="python hljs">df.sort_values (by=<span class="hljs-string">'price'</span>, ascending=<span class="hljs-literal">False</span>).head(<span class="hljs-number">217</span>) <font></font>
df=df[df[<span class="hljs-string">'price'</span>]&lt;=<span class="hljs-number">1965000</span>]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's think a little over the sign of bedrooms. </font><font style="vertical-align: inherit;">We see 13 houses with bedrooms = 0, as well as a strange record of a house with 33 bedrooms. </font><font style="vertical-align: inherit;">We will do the same as with price, removing zeros from bedroms (and bathrooms at the same time):</font></font><br>
<br>
<pre><code class="python hljs">df=df[(df[<span class="hljs-string">'bedrooms'</span>]!=<span class="hljs-number">0</span>)&amp;(df[<span class="hljs-string">'bathrooms'</span>]!=<span class="hljs-number">0</span>)]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Regarding the house with 33 bedrooms - considering the price, we can assume that this is a typo and the bedrooms are actually 3. Let us compare the living area of ‚Äã‚Äãthis house (1620) with the average living area of ‚Äã‚Äã3-bedroom houses (1798.2), which is probably our guess, therefore, just change this value to 3 and build the previous box plot again:</font></font><br>
<br>
<pre><code class="python hljs">df.loc[df[<span class="hljs-string">'bedrooms'</span>]==<span class="hljs-number">33</span>,[<span class="hljs-string">'bedrooms'</span>]]=<span class="hljs-number">3</span> 
sns.boxplot(y=<span class="hljs-string">'price'</span>, x=<span class="hljs-string">'bedrooms'</span>, data=df)</code></pre><br>
<img src="https://habrastorage.org/webt/qi/wd/fs/qiwdfscthapolbucfyjqy-uoggc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, much better. </font><font style="vertical-align: inherit;">Similarly, bedrooms look at bathrooms. </font><font style="vertical-align: inherit;">We deleted zero values, there are no other extreme values ‚Äã‚Äãin the field:</font></font><br>
<br>
<pre><code class="python hljs">sns.boxplot(y=<span class="hljs-string">'bathrooms'</span>, x=<span class="hljs-string">'bedrooms'</span>, data=df)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the fields sqft_living, floors, waterfront, view, condition, grade, sqft_living15 also all values ‚Äã‚Äãare more or less real, we will not touch them:</font></font><br>
<br>
<pre><code class="python hljs">plt.rcParams[<span class="hljs-string">'figure.figsize'</span>]=<span class="hljs-number">2</span>,<span class="hljs-number">3</span> 			<span class="hljs-comment"># </span>
sns.boxplot(y=<span class="hljs-string">'sqft_living'</span>, data=df)<font></font>
sns.boxplot(y=<span class="hljs-string">'floors'</span>,color=<span class="hljs-string">'#2ecc71'</span>, data=df)<font></font>
sns.boxplot(y=<span class="hljs-string">'sqft_living15'</span>,color=<span class="hljs-string">'#9b59b6'</span>, data=df) <font></font>
plt.rcParams[<span class="hljs-string">'figure.figsize'</span>]=<span class="hljs-number">4</span>,<span class="hljs-number">4</span>
sns.boxplot(y=<span class="hljs-string">'price'</span>, x=<span class="hljs-string">'waterfront'</span>, data=df)<font></font>
sns.boxplot(y=<span class="hljs-string">'price'</span>, x=<span class="hljs-string">'view'</span> , data=df)<font></font>
sns.boxplot(y=<span class="hljs-string">'price'</span>, x=<span class="hljs-string">'condition'</span> , data=df)<font></font>
sns.boxplot(y=<span class="hljs-string">'price'</span>, x=<span class="hljs-string">'grade'</span> , data=df)</code></pre><br>
<img src="https://habrastorage.org/webt/oq/uw/h8/oquwh8x-cln4tbaz9xrzqyk9szs.png"><br>
<br>
<img src="https://habrastorage.org/webt/yl/ns/bz/ylnsbzq_kx2dtvrvjy8iytxudve.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But with sqft_lot and sqft_lot15 you need to come up with something and because of the large values, logarithm is quite suitable:</font></font><br>
<br>
<pre><code class="python hljs">df[<span class="hljs-string">'sqft_lot'</span>]=np.log(df[<span class="hljs-string">'sqft_lot'</span>])<font></font>
df[<span class="hljs-string">'sqft_lot15'</span>]=np.log(df[<span class="hljs-string">'sqft_lot15'</span>])</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
sqft_lot before and after: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yr/up/g2/yrupg24jwmfsptci9hf8uaq6wmu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
sqft_above and sqft_basement are the components of sqft_living, so we won‚Äôt touch them either. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
With this, we will end with a preliminary analysis and look at the heat map of correlations:</font></font><br>
<br>
<pre><code class="python hljs">sns.heatmap(df.corr(),  cmap = <span class="hljs-string">'viridis'</span>,annot = <span class="hljs-literal">True</span>)</code></pre><br>
<img src="https://habrastorage.org/webt/ny/yi/uq/nyyiuqa9zbilc9l6gqzljfe35xu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Having examined the correlation map, we see that sometimes the attributes are strongly correlated with each other, so we delete some of the attributes with high correlation - sqft_lot15 (leave sqft_lot), yr_built (leave yr_renovated), sqft_above (sqft_living). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This completes the work with the data and proceed to the creation of the model. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2. Modeling </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this part, we will build 2 models: linear regression and decision tree. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All the models we need are contained in the sklearn library. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, we separate the target variable from the rest of the data for training, and also divide the samples into training (70%) and test (30%, on which we will check how the model works):</font></font><br>
<br>
<pre><code class="python hljs">Y=df[<span class="hljs-string">'price'</span>]<font></font>
X=df.drop (<span class="hljs-string">'price'</span>,axis=<span class="hljs-number">1</span>) 
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
X_train, X_test, Y_train, Y_test  = train_test_split(X, Y, test_size = <span class="hljs-number">0.3</span>, shuffle = <span class="hljs-literal">True</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Also, from sklearn, to evaluate the model, we upload 3 metrics - mean_absolute_error (mean absolute error), mean_squared_error (standard deviation), r2_score (determination coefficient):</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_absolute_error, mean_squared_error, r2_score</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's start with linear regression:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LinearRegression<font></font>
LR = LinearRegression() 				<span class="hljs-comment"># </span>
LR.fit(X_train, Y_train)				<span class="hljs-comment"># </span>
Y_LR = LR.predict(X_test)				<span class="hljs-comment">#       </span>
<span class="hljs-keyword">print</span> (<span class="hljs-string">'MAE:'</span>, round (mean_absolute_error(Y_test, Y_LR),<span class="hljs-number">3</span>))		<span class="hljs-comment">#</span>
<span class="hljs-keyword">print</span> (<span class="hljs-string">'‚àöMSE:'</span>, round (mean_squared_error(Y_test, Y_LR)**(<span class="hljs-number">1</span>/<span class="hljs-number">2</span>),<span class="hljs-number">3</span>))
<span class="hljs-keyword">print</span> (<span class="hljs-string">'R2_score:'</span>, round (r2_score(Y_test, Y_LR),<span class="hljs-number">3</span>))</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MAE: 124477.452 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚àöMSE 175205.645 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
R2_score: 0.627 Decision </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
tree:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeRegressor<font></font>
TR = DecisionTreeRegressor()				<span class="hljs-comment"># </span>
TR.fit(X_train, Y_train)				<span class="hljs-comment"># </span>
Y_TR=TR.predict(X_test)  				<span class="hljs-comment">#   </span>
<span class="hljs-keyword">print</span> (<span class="hljs-string">'MAE:'</span>, round (mean_absolute_error(Y_test, Y_TR),<span class="hljs-number">3</span>))		<span class="hljs-comment">#</span>
<span class="hljs-keyword">print</span> (<span class="hljs-string">'‚àöMSE:'</span>, round (mean_squared_error(Y_test, Y_TR)**(<span class="hljs-number">1</span>/<span class="hljs-number">2</span>),<span class="hljs-number">3</span>))
<span class="hljs-keyword">print</span> (<span class="hljs-string">'R2_score:'</span>, round (r2_score(Y_test, Y_TR),<span class="hljs-number">3</span>))</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MAE: 151734.906 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚àöMSE 220856.721 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
R2_score: 0.407 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Based on the metrics, we can conclude that Linear regression showed the best result, so it‚Äôs more logical to choose it. However, we did not ask what the model error consists of, whether the model is retrained, etc. It is quite likely that it was retraining that led to the deterioration of the DecisionTreeRegressor result, since we did not even limit the depth of the tree in the model parameters. We can easily check this by sorting through the depth of trees in a short cycle:</font></font><br>
<br>
<pre><code class="python hljs">dep,score=[],[]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>,<span class="hljs-number">16</span>):<font></font>
    TR = DecisionTreeRegressor(max_depth=i)<font></font>
    TR.fit(X_train, Y_train)<font></font>
    Y_TR=TR.predict(X_test)<font></font>
    dep.append(i)<font></font>
    score.append(mean_squared_error(Y_test, Y_TR)**(<span class="hljs-number">1</span>/<span class="hljs-number">2</span>))	<span class="hljs-comment">#  ‚àöMSE</span>
		plt.rcParams[<span class="hljs-string">'figure.figsize'</span>]=<span class="hljs-number">6</span>,<span class="hljs-number">3</span>
		plt.plot(dep, score)</code></pre><br>
<img src="https://habrastorage.org/webt/ar/fn/yt/arfnytm068lhpknk_ifnpshupgq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obviously, the best indicator is at max_depth = 7, and, looking at the metrics (MAE: 124861.441, ‚àöMSE 175322.737, R2_score: 0.626), it becomes clear that a model with such a restriction is similar to a linear regression in quality. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We can also try to evaluate what attributes were most important for the model for forecasting the cost: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/x1/qx/qw/x1qxqwlhqbfotpp45hhyr4nz0uc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Based on the graph, it is clear that grade affects the cost most - the general subjective assessment of the house by the real estate company (which, by the way, indicates the competence of the assessment :-))), in second place is the area of ‚Äã‚Äãthe house, and in third - the year of the last repair. The indicators considered the number of bedrooms, bathrooms, floors the model considered insignificant for the forecast.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To better understand the results, we calculate the average error in% - according to linear regression, the average error is 27.5%, that is, the model makes a little more error than a quarter when forecasting the cost of a house, which is quite a lot. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Can the results be improved? </font><font style="vertical-align: inherit;">Yes, of course, at the current stage we have only received a basic solution - some starting point for comparison will be better or worse models that we can create using more sophisticated methods or using more complex data processing. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We only slightly touched on the issue of retraining and did not touch at all on what the model error and many other aspects of model creation consist of. </font><font style="vertical-align: inherit;">As a rule, various methods of model validation are used to answer these questions and find the optimal solution, but we will write about this in the following articles.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en505498/index.html">How we solve the problem of uninitialized stack memory in Windows</a></li>
<li><a href="../en505502/index.html">Omnichannel in customer service: what to look for and how to do everything right?</a></li>
<li><a href="../en505506/index.html">He does not bite: how to make industrial robots safe for workers</a></li>
<li><a href="../en505508/index.html">Not only unmanned technology: the future of the automotive industry</a></li>
<li><a href="../en505510/index.html">Streamlining the Check Point API with the Python SDK</a></li>
<li><a href="../en505522/index.html">Monetization in online games: how to use someone else's experience for your own needs</a></li>
<li><a href="../en505528/index.html">The most important thing in Wi-Fi 6. No, seriously</a></li>
<li><a href="../en505530/index.html">Google makes its processor, and AMD is preparing to destroy Qualcomm</a></li>
<li><a href="../en505532/index.html">Telegram channels about game development: part 2</a></li>
<li><a href="../en505536/index.html">How to cook call tracking: Cyan experience</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
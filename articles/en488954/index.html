<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ò∏Ô∏è ü•ó üë©üèæ‚Äçüè≠ How to explain your point of view to the robot üò∏ üìá üç£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ever wonder why robots are needed today? From childhood, it seemed to me that robots are somewhere in modern factories, that it is somewhere far away ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>How to explain your point of view to the robot</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/488954/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ever wonder why robots are needed today? From childhood, it seemed to me that robots are somewhere in modern factories, that it is somewhere far away from us. Or in science fiction. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But not anymore. Today's robots are automation of any routine process. They can be put both on farms, and in auto repair shops. </font></font><br>
<img width="900" src="https://habrastorage.org/webt/pb/au/ft/pbauftdru00eqzsc9mr5xogun_a.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If before the price of such automation was huge, now it is falling. More complex technological manipulations become available. Roboruki is essentially such a universal manipulator that does not need to be designed for each task, =&gt; lowering the cost of implementation, accelerating implementation (although a roboruk can be more expensive than a piece of conveyor that performs a similar operation).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But roboruk is only half the process. </font><font style="vertical-align: inherit;">The second half is to teach Roboruk to think. </font><font style="vertical-align: inherit;">And until recently, the situation was terrible. </font><font style="vertical-align: inherit;">There are no universal approaches that any engineer can configure. </font><font style="vertical-align: inherit;">We need to hire programmers / developers / mathematicians to formulate the problem, try to make a solution. </font><font style="vertical-align: inherit;">Of course, such a situation could not exist for long. </font><font style="vertical-align: inherit;">Yes, and Computer Vision with deep training drove up. </font><font style="vertical-align: inherit;">So now, some kind of primary automation is beginning to appear, not only of strictly repeating processes. </font><font style="vertical-align: inherit;">Today we‚Äôll talk about her.</font></font><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pick-it</font></font></h2><br>
<img width="800" src="https://habrastorage.org/webt/vu/ae/i_/vuaei_vnahiepfdr7bsgelsxzlw.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The company offers a solution that allows you to capture a variety of objects using various roboruk. </font><font style="vertical-align: inherit;">As part of their solution - a 3D camera and special software for training in the capture of objects and subsequent capture. </font></font><br>
<img width="800" src="https://habrastorage.org/webt/re/dp/5e/redp5eqimuj-lblhummgiqwqsy0.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(search for cylindrical objects) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are pre-trained forms that are often found in industry: parallelepipeds, cylinders. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The usage order is approximately the following:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the client shows the 3D camera objects for capture from several sides (or uploads a CAD file of the part)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indicates directions from which to capture (not necessarily the only one)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">configures the integration of the robot with Pick-it software to perform the capture task and configures the necessary actions.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, it does not sound too complicated, but it will require some qualifications on the client side. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main minus is that as soon as the external parameters (styling / lighting / form) change, the system may stop working, and it is far from always obvious what went wrong to retrain it. </font><font style="vertical-align: inherit;">There is no stable process.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Computer Vision Technology:</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is impossible to say exactly which technology stack is used in the company. But, judging by the time the company was founded, information about technology on the Internet and other indirect signs, the ‚Äúup to deep-learning‚Äù stack of technologies for working with 3D scenes is used. For example, searching for 3D transformations for better alignment of point clouds ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ICP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> methods and </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RANSAC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> method). Sometimes special points are used, sometimes tricky ways to combine point clouds or a combination of methods with some heuristics. </font></font><br>
<img src="https://habrastorage.org/webt/mu/f-/4k/muf-4kzhoa0trouww8_wdlulwmi.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(Robust 3D point cloud registration based on bidirectional Maximum Correntropy Criterion, Xuetao Zhang, Libo Jian, Meifeng Xu)</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The key to success in this case is your own good 3D scanner, the quality of which determines the reliability of all these methods. </font><font style="vertical-align: inherit;">It is also important that the deviation of the shape of sample objects and those objects that need to be captured is not too large. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Major robot manufacturers also have similar systems: </font></font><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ABB</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> | </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kuka</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> | </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fanuc</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , as well as ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cognex</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But Pick-it covers more variability in the breadth of applications.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Standard approach now for variable objects</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thanks to the advent of deep-learning in computer vision, it has become easier for some types of objects to train a convolutional network, which, in addition to detection, also evaluates the necessary parameters. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The greatest scope for such methods is agriculture. </font><font style="vertical-align: inherit;">From plant inspection to fruit picking. </font><font style="vertical-align: inherit;">In a way, a classic example is picking cherry tomatoes. </font><font style="vertical-align: inherit;">Here are a few examples of companies that collect crops: </font></font><br>
<img width="800" src="https://habrastorage.org/webt/nu/em/bq/nuembquijd1zxu2noj8lrvso-5o.jpeg"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Collecting tomatoes. </font><font style="vertical-align: inherit;">Estimated size / distance / color</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cuD85LRWoxQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you look closely, it doesn‚Äôt collect very well. </font></font><br>
<img src="https://habrastorage.org/webt/vr/x1/hx/vrx1hxnthwlmffdowrwy_wp0gxo.jpeg"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Often, proper cultivation is already 95% of the robot.</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/EFC3OvkVKaQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
About this horror with an accuracy of 89%, even the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> on Habr√© was. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Most of these startups use a detector like SSD or YOLO with subsequent (or simultaneous) assessment of ripeness parameters. </font><font style="vertical-align: inherit;">The position of the same fruit space for capture is estimated by 3D or stereo cameras. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Accordingly, the manufacturer (and partly the solution integrator) faces the following tasks: recognition recognition quality, replenishment of the training sample in real conditions, periodic training, writing an algorithm that ties in the CV part, part with 3D evaluation and part with capture. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In our experience, solving such a problem each time takes a couple of months.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another approach</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And if you want to work with the learning system on Deep learning, but not stop at one application? And to train even without complex configuration software for each task on the client side. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It would be great to show the robot what to do, and then he would somehow somehow. But here's how to show the robot? </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Google (a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">link to one of the projects</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) and OpenAI ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">they didn‚Äôt see another project</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) are doing projects where the robot is trying to follow human hands and repeat actions. But the accuracy is far from necessary in real applications, and the mathematics of the State-of-art level are difficult to scale.</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/0iYxqo1_nJA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Is there any other way? </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At some point, when we were solving the problem of orienting controllers for VR in 3D space, another puzzle developed for us. After all, virtual reality has long been there. You can show the robot the virtual reality controller how to grab the object. But not in the simulator, like OpenAI, but in reality. Just drafting a manipulator into it, and showing the direction of capture.</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/VXzm5knCb-I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It turns out intuitively. After a couple of minutes, a person begins to understand how to grab objects or do some operations with him, controlling the robot in reality. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is always important to understand whether it is possible to do what the robot wants. And here everything is simple: if a person in VR can show the robot how to solve a problem, then he can be trained to do such things. All that can be shown is within the power of the modern level of Machine Learning, and it is guaranteed to be performed with any existing robot arm. And it eliminates the main disadvantage of modern ML - you do not need huge databases of examples for which to train. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What is the plus of this approach? Well, for example, that you do not need to prescribe low-level logic. Why detect a glass, and then talk on which side how to grab it? Set exact capture locations. You can show:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the glass is on the table normally - grab the wall</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the glass is on its side - grab it by the side</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the glass stands upside down - grab the bottom</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And voila, after an hour we get the result:</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/SjnY8P5uqck" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, or a more difficult task: we want to collect fruits, but we need to keep a branch - this is a difficult programmable logic. </font><font style="vertical-align: inherit;">But she just learns:</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tyHOH3X9VLo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Or a very simple example is to grab and cut a cucumber (of </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">course, only grab was trained</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ):</font></font><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/6Hgi_BYp0Os" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now smart robots are a bit like personal computers in the 80s. </font><font style="vertical-align: inherit;">There are various hypotheses to which everything will come. </font><font style="vertical-align: inherit;">The rental price of the robot is equal to the average salary of a worker, which means that robotization of an increasing number of areas of labor is inevitable. </font><font style="vertical-align: inherit;">Nobody knows how they will manage all this in five years, but judging by how the price of robots is falling and the number of their installations is growing, everything is only gaining ground. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Price: </font></font><br>
<img width="800" src="https://habrastorage.org/webt/np/3a/u-/np3au-vdhr4xeu_oazl7xygi9cm.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Volumes:</font></font><br>
<img src="https://habrastorage.org/webt/nm/c-/25/nmc-25eplolu2hvthovnbwnhnd8.png"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en488944/index.html">How coronavirus affects biotechnology stocks</a></li>
<li><a href="../en488946/index.html">Python console menu</a></li>
<li><a href="../en488948/index.html">UPD. Testing the REST API on Golang. 120 000 [# / sec] is not the limit?</a></li>
<li><a href="../en488950/index.html">Time in a cellular machine</a></li>
<li><a href="../en488952/index.html">Phrase sentiment analysis using neural networks</a></li>
<li><a href="../en488956/index.html">Organization of documentation and translation, for example, iondv. framework</a></li>
<li><a href="../en488958/index.html">Transcript of my interview with Ruby author</a></li>
<li><a href="../en488960/index.html">Programming, Immunity and the Army</a></li>
<li><a href="../en488962/index.html">Can I write scripts in C ++?</a></li>
<li><a href="../en488964/index.html">Urgent tasks. May the Savior come</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
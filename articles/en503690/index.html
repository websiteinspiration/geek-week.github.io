<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📜 👨🏻‍💼 👇 Kubernetes best practices. Kubernetes Zero Downtime Cluster Upgrade 🚫 👓 👩🏽‍🚒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kubernetes best practices. Creating Small Containers 
 Kubernetes Best Practices. Kubernetes Organization with the Kubernetes 
 Best Practices Namespa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Kubernetes best practices. Kubernetes Zero Downtime Cluster Upgrade</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/503690/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kubernetes best practices. Creating Small Containers </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kubernetes Best Practices. Kubernetes Organization with the Kubernetes </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Best Practices Namespace. Kubernetes Viability Test with Readiness and Liveness Tests Kubernetes </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Best Practices. Setting Queries and Resource Limits </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kubernetes Best Practices. Correct Terminate </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Disabling Kubernetes Best Practices. Mapping external services</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Everyone knows how good it is to keep your applications up to date. Kubernetes and Docker can make the upgrade process a lot easier, so you can create a new container with updated dependencies and easily deploy it. In addition to updating application dependencies, Kubernetes is constantly updating features and security policies.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thus, the base nodes and infrastructure of Kubernetes must be up to date. In this series, we will learn how the Google Kubernetes Engine can easily upgrade the Kubernetes cluster.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, when updating a cluster, you need to update the wizards and nodes, and the wizards must be updated first. Let's see how to update both elements using the Google Kubernetes Engine. This system automatically updates the wizard as it releases point releases. However, as a rule, it will not be updated to the new version, for example, 1.7-1.8, automatically. When you are ready to upgrade to the new version, you can simply click the Upgrade available link in the GKE console, after which a dialog box will appear on the screen. It contains a warning that changing the master version may take several minutes, during which you cannot edit this cluster, while during the upgrade of the wizard your deployments and services will continue to work normally. However, the entire infrastructure that needs the Kubernetes API will not work.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/o1/q5/uo/o1q5uoo8kjqvi9jrgezw2pvmrwo.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This means that QPTL and all applications that use the Kubernetes API to obtain cluster information will be disabled and you will not be able to make any changes to the cluster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's see how you can solve this problem by updating the wizard with zero downtime. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/6m/un/uc/6munuchpuwh-8_1be6o0bjvdlsm.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
While the standard GKE zone cluster supports only one wizard, you can create regional clusters that provide multi-zone high availability wizards. Therefore, when creating your cluster, be sure to choose a regional option. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Your nodes and wizards will be automatically created in three zones, and the wizards will have load-balanced IP addresses. This will keep Kubernetes API running smoothly during the upgrade.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When updating nodes, there are several different strategies that you can use. I want to focus your attention on two things - rolling rolling updates and migration using node pools. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The easiest way to update Kubernetes nodes is to use rolling update, the default update mechanism that GKE uses to update your nodes. It works as follows.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yu/hy/af/yuhyafeiliwyv-mhlkiu9mdpbti.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The nodes of the old version are decommissioned one after another so that all modules cease to work in them. Then these nodes are deleted, and instead of them, new nodes of the updated Kubernetes version appear one after another. After one node starts working, the other proceeds to the update process, and this continues until all nodes are updated. You can let GKE manage this process for you by turning on automatic updating of nodes in the node pool by selecting Enabled. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2w/jz/vy/2wjzvyfqeymrrmhtabzv4fwu85k.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you do not, the GKE dashboard will warn you when a new update is available. In this case, to perform the update, you need to click the Automatic node updates link and follow the instructions.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zi/an/_z/zian_zvgqnwnsetfizdgguuh2pw.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the same time, it is very important to make sure that your pods are controlled using the replica set, a stateful set, or something similar. Then the autonomous hearths will not be restructured. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Although rolling updates are pretty easy to do with GKE, it still has a few drawbacks. One of them is that when you upgrade, the capacity of your cluster decreases by one node. This disadvantage is easily eliminated by scaling the node pool by adding additional capacity and then reducing it after the update.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, the fully automated nature of rolling updates makes updating easier, but leaves you with less control over the process. If something goes wrong and you have to roll back to the old version, it will take time to stop rolling updates and discard any changes that have already been made. Let's see how you can use pools from multiple nodes to upgrade your cluster. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/dl/rv/wo/dlrvwo1wdrdhzsggce76vokdonu.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, instead of updating the active pool of nodes using rolling updates, you create a completely new pool of nodes, wait for all nodes to start, and then transfer workloads one node at a time. As you execute these commands yourself, you gain more control over the migration process, while GKE continues to manage your nodes.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Suppose a Kubernetes cluster consists of 3 virtual machines. You can view the nodes using the get nodes command. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xe/z2/r4/xez2r4j71qjxvmvviw0-af-7q5o.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To create a new pool of nodes named pool-two, you need to use the appropriate command, setting it up in exactly the same way as the command for the old pool. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/mw/me/kl/mwmeklsu7fc4l-zudw9f4a7is2m.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Optionally, you can also use the GUI to create a new node pool. For more information on this, use the Node pool creation link located below this video. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you check the number of nodes again, you will find three new nodes with the pool-two pool name, however, the pods will still be on the old nodes.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/v8/nb/rm/v8nbrmgfnwaddhn2fn0_wlrba9e.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's move them to a new node pool, moving one node at a time in rolling mode. To do this, use the cordon command for each old node to protect them and prevent the formation of new hearths in them. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/v0/iq/5a/v0iq5azeontfui94okav_lgacra.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As soon as all old nodes are fenced, the creation of hearths will be planned only in new nodes. This means that you can start removing pods from old nodes, and Kubernetes will automatically plan to create them in new nodes. Then you need to “drain” each node, which will lead to the removal of all hearths in the node.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/qy/y7/yb/qyy7ybf-b05k7t28ludwpluo5f0.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After you do this for one node, make sure that the new pods are ready and already working, and then move on to the next node. If you had any problems during the migration, run uncordon for the old pool, and then run cordon and drain for the new pool. In this case, the pods will be automatically transferred back to the old pool. Once all the pods have been safely transferred, you can delete the old pool. To do this, replace the default pool with the pool you want to delete.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/n_/vx/f8/n_vxf83r2fw4skngg1ijihr25ly.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Google Kubernetes Engine lets you keep your Kubernetes cluster up to date with just a few clicks. I highly recommend using GKE regional clusters for high availability wizards and automatic node updates to ensure correct and trouble-free updates. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you need additional control over the node update process, you can provide it with the help of pools, without giving up the advantages of the management platform that GKE provides.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you are not using GKE, then use the rolling update rolling method or node pool nodes to update the nodes of your cluster. </font><font style="vertical-align: inherit;">But remember that in this case you need to manually add new nodes to the cluster and perform critical updates yourself, which may not be quite simple. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The sequel will be very soon ...</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/fvpq4jqtuZ8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A bit of advertising :)</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thank you for staying with us. Do you like our articles? Want to see more interesting materials? Support us by placing an order or recommending to your friends, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cloud VPS for developers from $ 4.99</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unique analog of entry-level servers that was invented by us for you: </font></font></b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The whole truth about VPS (KVM) E5-2697 v3 (6 Cores) 10GB DDR4 480GB SSD 1Gbps from $ 19 or how to divide the server?</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (options are available with RAID1 and RAID10, up to 24 cores and up to 40GB DDR4). </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dell R730xd 2 times cheaper at the Equinix Tier IV data center in Amsterdam?</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Only we have </font></font><b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 x Intel TetraDeca-Core Xeon 2x E5-2697v3 2.6GHz 14C 64GB DDR4 4x960GB SSD 1Gbps 100 TV from $ 199</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in the Netherlands!</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dell R420 - 2x E5-2430 2.2Ghz 6C 128GB DDR3 2x960GB SSD 1Gbps 100TB - from $ 99! </font></font></b></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Read about</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> How to Build Infrastructure Bldg. </font><font style="vertical-align: inherit;">class c using Dell R730xd E5-2650 v4 servers costing 9,000 euros for a penny?</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en503676/index.html">Three geek projects for Geek Pride Day</a></li>
<li><a href="../en503678/index.html">Vuex breaks encapsulation</a></li>
<li><a href="../en503680/index.html">DBA: in pursuit of flying locks</a></li>
<li><a href="../en503682/index.html">Snom Exchange A to Z</a></li>
<li><a href="../en503688/index.html">Joel Spolsky: What Does It Mean to Be a Software Developer (Preface to Coder to Developer)</a></li>
<li><a href="../en503696/index.html">Gears of war: when mechanical analog computers ruled the sea</a></li>
<li><a href="../en503698/index.html">Remote accounting - as a business benefit</a></li>
<li><a href="../en503700/index.html">Creating React Forms in 2020</a></li>
<li><a href="../en503702/index.html">Using Raw Data in Google Analytics in practice</a></li>
<li><a href="../en503704/index.html">Instead of 100 application launches - one autotest, or how to save a QA engineer 20 years of life</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📩 ▫️ 🤝 Komputasi GPU - Mengapa, Kapan, dan Bagaimana. Ditambah beberapa tes 👨🏻‍⚕️ 📶 👩🏼‍🏫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Semua orang sudah lama tahu bahwa pada kartu video Anda tidak hanya bisa bermain mainan, tetapi juga melakukan hal-hal yang tidak terkait dengan game,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Komputasi GPU - Mengapa, Kapan, dan Bagaimana. Ditambah beberapa tes</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dbtc/blog/498374/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Semua orang sudah lama tahu bahwa pada kartu video Anda tidak hanya bisa bermain mainan, tetapi juga melakukan hal-hal yang tidak terkait dengan game, misalnya, melatih jaringan saraf, mengingat cryptocurrency atau melakukan perhitungan ilmiah. Bagaimana ini terjadi, Anda dapat membacanya di </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sini</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , tetapi saya ingin menyentuh pada topik </font></font><i><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mengapa GPU mungkin menarik bagi</font></font></strong></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> programmer rata </font><i><strong><font style="vertical-align: inherit;">-</font></strong></i><font style="vertical-align: inherit;"> rata (tidak terkait dengan GameDev) </font></font><i><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cara mendekati</font></font></strong></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pengembangan pada GPU tanpa menghabiskan banyak waktu untuk itu, </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memutuskan</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> apakah lihat ke arah ini, dan "cari </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tahu dengan jari Anda" berapa untung yang bisa Anda peroleh.</font></font></strong>&nbsp;<br>
<br>
<div style="text-align:center;"><img width="800" src="https://habrastorage.org/getpro/habr/post_images/3ee/2ac/893/3ee2ac8936a685e6993966cfa40f53fd.jpg"></div><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Artikel ini ditulis berdasarkan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">presentasi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> saya </font><font style="vertical-align: inherit;">di HighLoad ++. </font><font style="vertical-align: inherit;">Ini terutama membahas teknologi yang ditawarkan oleh NVIDIA. </font><font style="vertical-align: inherit;">Saya tidak punya tujuan untuk mengiklankan produk apa pun, saya hanya memberikan mereka sebagai contoh, dan pasti sesuatu yang serupa dapat ditemukan di produsen yang bersaing.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mengapa mengandalkan GPU?</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dua prosesor dapat dibandingkan sesuai dengan kriteria yang berbeda, mungkin yang paling populer adalah frekuensi dan jumlah core, ukuran cache, dll., Tetapi pada akhirnya, kami tertarik pada berapa banyak operasi yang dapat dilakukan prosesor per unit waktu, seperti apa operasi ini, tetapi pertanyaan terpisah Metrik umum adalah jumlah operasi titik apung per detik - jepit. Dan ketika kita ingin membandingkan hangat dengan lunak, dan dalam kasus GPU kami dengan CPU, metrik ini sangat berguna. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Grafik di bawah ini menunjukkan pertumbuhan jepit yang sama ini dari waktu ke waktu untuk prosesor dan kartu video.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5e2/048/3f5/5e20483f59e87b0a395b0fae0e6495c5.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Data dikumpulkan dari sumber terbuka, tidak ada data untuk 2019-20 tahun, karena tidak semuanya begitu indah di sana, tetapi GPU masih menang)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Yah, itu menggoda, bukan? </font><font style="vertical-align: inherit;">Kami menggeser semua perhitungan dari CPU ke GPU dan mendapatkan delapan kali kinerja terbaik! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tapi, tentu saja, tidak semuanya begitu sederhana. </font><font style="vertical-align: inherit;">Anda tidak bisa hanya mengambil dan mentransfer semuanya ke GPU, mengapa, kami akan berbicara lebih lanjut.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Arsitektur GPU dan perbandingannya dengan CPU</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saya membawa banyak gambar yang akrab dengan arsitektur CPU dan elemen dasar:</font></font><br>
<br>
<div style="text-align:center;"><img width="400" src="https://habrastorage.org/getpro/habr/post_images/df0/8c2/4c3/df08c24c3fe92cd97356670729c318cd.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CPU Core</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Apa yang istimewa? </font><font style="vertical-align: inherit;">Satu inti dan banyak blok bantu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang mari kita lihat arsitektur GPU:</font></font><br>
<br>
<div style="text-align:center;"><img width="400" src="https://habrastorage.org/getpro/habr/post_images/0fe/138/0cc/0fe1380ccbb321b289d16e39a499009a.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPU Core</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Kartu video memiliki banyak inti pemrosesan, biasanya beberapa ribu, tetapi digabungkan menjadi beberapa blok, untuk kartu video NVIDIA, biasanya 32 masing-masing, dan memiliki elemen umum, termasuk dan register. Arsitektur inti GPU dan elemen logis jauh lebih sederhana daripada pada CPU, yaitu, tidak ada prefetcher, prediktor brunch, dan banyak lagi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nah, ini adalah poin utama dari perbedaan dalam arsitektur CPU dan GPU, dan, pada kenyataannya, mereka memberlakukan batasan atau, sebaliknya, membuka kemungkinan untuk apa yang dapat kita baca secara efektif di GPU.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saya tidak menyebutkan satu poin penting lagi, biasanya, kartu video dan prosesor tidak “mencari-cari” di antara mereka sendiri dan menulis data ke kartu video dan membaca hasilnya kembali - ini adalah operasi yang terpisah dan dapat berubah menjadi “bottleneck” di sistem Anda, grafik waktu pemompaan versus ukuran data diberikan kemudian di artikel.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Batasan dan fitur GPU</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apa keterbatasan arsitektur ini pada algoritma yang dapat dieksekusi:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jika kita menghitung pada GPU, maka kita tidak dapat memilih hanya satu inti, seluruh blok inti akan dialokasikan (32 untuk NVIDIA).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Semua core menjalankan instruksi yang sama, tetapi dengan data yang berbeda (kami akan membicarakannya nanti), perhitungan seperti itu disebut Single-Instruction-Multiple-Data atau SIMD (walaupun NVIDIA memperkenalkan perbaikannya).&nbsp;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Karena serangkaian blok logika dan register umum yang relatif sederhana, GPU benar-benar tidak suka bercabang, dan memang logika yang rumit dalam algoritma.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Peluang apa yang terbuka:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sebenarnya, percepatan perhitungan SIMD yang sama. </font><font style="vertical-align: inherit;">Contoh paling sederhana adalah penambahan matriks elemen, dan mari kita menganalisisnya.</font></font></li>
</ul><br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pengurangan algoritma klasik ke representasi SIMD</font></font></h1><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformasi</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami memiliki dua larik, A dan B, dan kami ingin menambahkan elemen dari larik B ke setiap elemen larik A. Di bawah ini adalah contoh dalam C, meskipun saya harap akan jelas bagi mereka yang tidak berbicara bahasa ini:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *A, <span class="hljs-keyword">float</span> *B, size)</span>
</span>{ 
   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; size; i++) <font></font>
   { <font></font>
       A[i] += B[i]<font></font>
   } <font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Loopback klasik elemen dalam loop dan runtime linier. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang mari kita lihat bagaimana kode tersebut akan mencari GPU:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *A, <span class="hljs-keyword">float</span> *B, size)</span> 
</span>{ 
   <span class="hljs-keyword">int</span> i = threadIdx.x; 
   <span class="hljs-keyword">if</span> (i &lt; size) <font></font>
      A[i] += B[i] <font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dan di sini sudah menarik, variabel threadIdx muncul, yang sepertinya tidak kami nyatakan di mana pun. Ya, sistemnya menyediakan bagi kita. Bayangkan dalam contoh sebelumnya array terdiri dari tiga elemen, dan Anda ingin menjalankannya dalam tiga utas paralel. Untuk melakukan ini, Anda perlu menambahkan parameter lain - indeks atau nomor streaming. Inilah yang dilakukan kartu video untuk kami, meskipun ia melewati indeks sebagai variabel statis dan dapat bekerja dengan beberapa dimensi sekaligus - x, y, z. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nuansa lain, jika Anda akan memulai sejumlah besar aliran paralel sekaligus, maka aliran tersebut harus dibagi menjadi beberapa blok (fitur arsitektur kartu video). Ukuran blok maksimum tergantung pada kartu video, dan indeks elemen tempat kami melakukan perhitungan perlu diperoleh sebagai berikut:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x; <span class="hljs-comment">// blockIdx –  , blockDim –  , threadIdx –    </span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Akibatnya, apa yang kita miliki: banyak utas berjalan paralel yang mengeksekusi kode yang sama, tetapi dengan indeks yang berbeda, dan, dengan demikian, data, mis. </font><font style="vertical-align: inherit;">SIMD yang sama. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ini adalah contoh paling sederhana, tetapi jika Anda ingin bekerja dengan GPU, Anda harus membawa tugas Anda ke bentuk yang sama. </font><font style="vertical-align: inherit;">Sayangnya, ini tidak selalu memungkinkan dan dalam beberapa kasus dapat menjadi subjek disertasi doktoral, tetapi bagaimanapun, algoritma klasik masih dapat dibawa ke formulir ini.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pengumpulan</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang mari kita lihat bagaimana agregasi yang dilemparkan ke representasi SIMD akan terlihat:</font></font><br>
&nbsp;<br>
<div style="text-align:center;"><img width="400" src="https://habrastorage.org/getpro/habr/post_images/ecd/78a/bba/ecd78abbaff0c1be8799c1337f7652f8.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami memiliki array n elemen. </font><font style="vertical-align: inherit;">Pada tahap pertama, kita mulai n / 2 utas dan setiap utas menambahkan dua elemen, yaitu </font><font style="vertical-align: inherit;">dalam satu iterasi, kami menambahkan bersama setengah dari elemen dalam array. </font><font style="vertical-align: inherit;">Dan kemudian dalam loop kita mengulangi hal yang sama untuk array yang baru dibuat, sampai kita menggabungkan dua elemen terakhir. </font><font style="vertical-align: inherit;">Seperti yang Anda lihat, semakin kecil ukuran array, semakin sedikit thread paralel yang dapat kita mulai, mis. </font><font style="vertical-align: inherit;">pada GPU, masuk akal untuk menggabungkan array dengan ukuran yang cukup besar. </font><font style="vertical-align: inherit;">Algoritme seperti itu dapat digunakan untuk menghitung jumlah elemen (omong-omong, jangan lupa tentang kemungkinan melimpahnya jenis data yang Anda kerjakan), cari maksimum, minimum, atau hanya pencarian.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penyortiran</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tetapi memilah sudah terlihat jauh lebih rumit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dua algoritma pemilahan paling populer pada GPU adalah:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Semacam bitonic</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Radix-sort</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tetapi radix-sort masih lebih sering digunakan, dan implementasi siap produksi dapat ditemukan di beberapa perpustakaan. </font><font style="vertical-align: inherit;">Saya tidak akan menganalisis secara detail bagaimana algoritma ini bekerja; mereka yang tertarik dapat menemukan deskripsi radix-sort di </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.codeproject.com/Articles/543451/Parallel-Radix-Sort-on-the-GPU-using-Cplusplus- AMP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://stackoverflow.com/a/26229897</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Tapi idenya adalah bahwa bahkan algoritma non-linear seperti penyortiran dapat dikurangi menjadi tampilan SIMD. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dan sekarang, sebelum melihat bilangan real yang dapat diperoleh dari GPU, mari kita mencari tahu cara memprogram untuk keajaiban teknologi ini?</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mulai dari mana</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dua teknologi paling umum yang dapat digunakan untuk pemrograman di bawah GPU:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Opencl</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuda</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OpenCL adalah standar yang didukung oleh sebagian besar produsen kartu video, termasuk </font><font style="vertical-align: inherit;">dan pada perangkat seluler, juga kode yang ditulis dalam OpenCL dapat dijalankan pada CPU. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda dapat menggunakan OpenCL dari C / C ++, ada binder ke bahasa lain. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk OpenCL, saya paling menyukai buku </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCL in Action</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Ini juga menjelaskan berbagai algoritma pada GPU, termasuk </font><font style="vertical-align: inherit;">Semacam bitonic dan semacam Radix. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
CUDA adalah teknologi dan SDK milik NVIDIA. </font><font style="vertical-align: inherit;">Anda dapat menulis dalam C / C ++ atau menggunakan binding ke bahasa lain.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Membandingkan OpenCL dan CUDA agak tidak benar, karena </font><font style="vertical-align: inherit;">satu adalah standar, yang lainnya adalah seluruh SDK. </font><font style="vertical-align: inherit;">Namun demikian, banyak orang memilih CUDA untuk pengembangan untuk kartu video, terlepas dari kenyataan bahwa teknologinya eksklusif, meskipun gratis dan hanya berfungsi pada kartu NVIDIA. </font><font style="vertical-align: inherit;">Ada beberapa alasan untuk ini:</font></font><br>
<br>
<ul>
<li>  API</li>
<li>    </li>
<li>,   GPU,      (host) </li>
<li> ,  ..  </li>
<li>   </li>
<li>  </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kekhasan termasuk fakta bahwa CUDA datang dengan kompiler sendiri, yang juga dapat mengkompilasi kode C / C ++ standar. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Buku CUDA paling komprehensif yang saya temui adalah </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pemrograman CUDA C Profesional</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , meskipun sudah agak ketinggalan jaman, namun buku ini membahas banyak nuansa teknis pemrograman untuk kartu NVIDIA. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tetapi bagaimana jika saya tidak ingin menghabiskan beberapa bulan membaca buku-buku ini, menulis program saya sendiri untuk kartu video, menguji dan men-debug, dan kemudian mengetahui bahwa ini bukan untuk saya?&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang saya katakan, ada sejumlah besar perpustakaan yang menyembunyikan kompleksitas pengembangan di bawah GPU: XGBoost, cuBLAS, TensorFlow, PyTorch dan lainnya, kami akan mempertimbangkan perpustakaan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dorong</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, karena kurang terspesialisasi dari perpustakaan lain di atas, tetapi pada saat yang sama mengimplementasikan algoritma dasar, misalnya, pengurutan, pencarian, agregasi, dan dengan probabilitas tinggi dapat diterapkan dalam tugas Anda. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thrust adalah pustaka C ++ yang bertujuan untuk "mengganti" algoritma STL standar dengan algoritma berbasis GPU. </font><font style="vertical-align: inherit;">Misalnya, mengurutkan array angka menggunakan pustaka ini pada kartu video akan terlihat seperti ini:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function">thrust::host_vector&lt;DataType&gt; <span class="hljs-title">h_vec</span><span class="hljs-params">(size)</span></span>; <span class="hljs-comment">//    </span>
<span class="hljs-built_in">std</span>::generate(h_vec.begin(), h_vec.end(), rand); <span class="hljs-comment">//   </span>
thrust::device_vector&lt;DataType&gt; d_vec = h_vec; <span class="hljs-comment">//        &nbsp;</span>
thrust::sort(d_vec.begin(), d_vec.end()); <span class="hljs-comment">//    </span>
thrust::copy(d_vec.begin(), d_vec.end(), h_vec.begin()); <span class="hljs-comment">//   ,     </span>
</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(jangan lupa bahwa contoh harus dikompilasi oleh kompiler dari NVIDIA)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang Anda lihat, dorong :: sort sangat mirip dengan algoritma serupa dari STL. Pustaka ini menyembunyikan banyak kesulitan, khususnya pengembangan subprogram (lebih tepatnya, kernel), yang akan dieksekusi pada kartu video, tetapi pada saat yang sama menghilangkan fleksibilitas. Sebagai contoh, jika kita ingin mengurutkan beberapa gigabyte data, akan logis untuk mengirim sepotong data ke kartu untuk mulai menyortir, dan sementara penyortiran sedang berlangsung, kirim lebih banyak data ke kartu. Pendekatan ini disebut bersembunyi latensi dan memungkinkan penggunaan sumber daya peta server yang lebih efisien, tetapi, sayangnya, ketika kita menggunakan pustaka tingkat tinggi, peluang seperti itu tetap tersembunyi. Tetapi untuk membuat prototipe dan mengukur kinerja, semuanya tetap sama, terutama dengan dorongan Anda dapat mengukur overhead yang disediakan oleh transfer data. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saya menulis </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">patokan</font></a><font style="vertical-align: inherit;"> kecil</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> menggunakan pustaka ini, yang menjalankan beberapa algoritma populer dengan jumlah data yang berbeda pada GPU, mari kita lihat apa hasilnya.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasil Algoritma GPU</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk menguji GPU, saya mengambil contoh di AWS dengan kartu grafis Tesla K80, ini bukan kartu server paling kuat saat ini (Tesla v100 paling kuat), tetapi yang paling terjangkau dan ada di papan:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4992 kernel CUDA</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Memori 24 GB</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">480 Gb / s - bandwidth memori&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dan untuk pengujian pada CPU, saya mengambil contoh dengan prosesor Intel Xeon CPU E5-2686 v4 @ 2.30GHz</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformasi</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/930/6e1/687/9306e1687be5ee95c29c8aac7b2ae337.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformasi waktu eksekusi pada GPU dan CPU dalam ms.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Seperti yang Anda lihat, transformasi biasa elemen array kira-kira sama dalam waktu, baik pada GPU dan pada CPU. </font><font style="vertical-align: inherit;">Dan mengapa? </font><font style="vertical-align: inherit;">Karena overhead untuk mengirim data ke kartu dan kembali memakan seluruh peningkatan kinerja (kita akan berbicara tentang overhead secara terpisah), dan ada relatif sedikit perhitungan pada kartu. </font><font style="vertical-align: inherit;">Juga, jangan lupa bahwa prosesor juga mendukung instruksi SIMD, dan kompiler dalam kasus sederhana dapat menggunakannya secara efektif.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang mari kita lihat seberapa efisien agregasi dilakukan pada GPU.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pengumpulan</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c92/d0e/cb9/c92d0ecb96c32866000e6948f5da61f9.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Waktu eksekusi agregasi pada GPU dan CPU dalam ms.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Dalam contoh agregasi, kita sudah melihat peningkatan kinerja yang signifikan dengan peningkatan volume data. </font><font style="vertical-align: inherit;">Penting juga untuk memperhatikan fakta bahwa kami memompa sejumlah besar data ke dalam memori kartu, dan hanya satu nilai agregat yang diambil kembali, mis. </font><font style="vertical-align: inherit;">Overhead untuk mentransfer data dari kartu ke RAM minimal. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mari kita beralih ke contoh paling menarik - pengurutan.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penyortiran</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fde/504/8da/fde5048da5084d1f0902c9362b21d939.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menyortir waktu ke GPU dan CPU dalam ms.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Terlepas dari kenyataan bahwa kami mengirim seluruh array data ke kartu video dan sebaliknya, menyortir ke GPU 800 MB data kira-kira 25 kali lebih cepat daripada pada prosesor.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transfer data overhead</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti dapat dilihat dari contoh transformasi, tidak selalu jelas apakah GPU akan efektif bahkan dalam tugas-tugas yang paralel dengan baik. </font><font style="vertical-align: inherit;">Alasannya adalah overhead untuk mentransfer data dari RAM komputer ke memori kartu video (di konsol game, omong-omong, memori dibagi antara CPU dan GPU, dan tidak perlu mentransfer data). </font><font style="vertical-align: inherit;">Salah satu karakteristik kartu video adalah bandwidth memori atau bandwidth memori, yang menentukan bandwidth teoritis kartu. </font><font style="vertical-align: inherit;">Untuk Tesla k80 itu adalah 480 GB / s, untuk Tesla v100 sudah 900 GB / s. </font><font style="vertical-align: inherit;">Juga, versi PCI Express dan implementasi bagaimana Anda akan mentransfer data ke kartu akan mempengaruhi throughput, misalnya, ini dapat dilakukan dalam beberapa aliran paralel.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mari kita lihat hasil praktis yang diperoleh untuk kartu grafis Tesla K80 di cloud Amazon:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/798/fb5/613/798fb56139f6158566232bc6283b24e7.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Waktu untuk mentransfer data ke GPU, mengurutkan dan mentransfer data kembali ke RAM dalam ms </font></font></i><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HtoD - mentransfer data ke kartu video </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
GPU Eksekusi - mengurutkan pada kartu video </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
DtoH - menyalin data dari kartu video ke RAM</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Hal pertama yang perlu diperhatikan adalah membaca data dari kartu video lebih cepat daripada tuliskan di sana. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Yang kedua - ketika bekerja dengan kartu video, Anda bisa mendapatkan latensi dari 350 mikrodetik, dan ini mungkin sudah cukup untuk beberapa aplikasi latensi rendah. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bagan di bawah ini menunjukkan overhead untuk lebih banyak data:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d18/653/b96/d18653b96af325f35fade713bdaa8dae.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Saatnya mentransfer data ke GPU, mengurutkan dan mentransfer data kembali ke RAM dalam ms</font></font></i><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penggunaan server</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pertanyaan yang paling umum adalah bagaimana perbedaan kartu video game dari yang server? </font><font style="vertical-align: inherit;">Menurut karakteristik, mereka sangat mirip, tetapi harga berbeda secara signifikan.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/203/01b/741/20301b7418ee616d9611f42d2b4a8f5d.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Perbedaan utama antara server (NVIDIA) dan kartu permainan:</font></font><br>
<br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Garansi pabrik</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (kartu game tidak dirancang untuk penggunaan server)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kemungkinan masalah </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">virtualisasi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> untuk kartu grafis konsumen</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ketersediaan mekanisme koreksi kesalahan pada kartu server</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jumlah utas paralel (bukan inti CUDA) atau dukungan untuk Hyper-Q, yang memungkinkan Anda untuk bekerja dengan kartu dari beberapa utas pada CPU, misalnya, mengunggah data ke kartu dari satu utas dan memulai perhitungan dari yang lain</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inilah, mungkin, perbedaan penting utama yang saya temukan.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Multithreading</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setelah kami menemukan cara menjalankan algoritma paling sederhana pada kartu video dan hasil apa yang bisa diharapkan, pertanyaan logis berikutnya adalah bagaimana kartu video akan berperilaku ketika memproses beberapa permintaan paralel. Sebagai jawaban, saya memiliki dua grafik komputasi pada GPU dan prosesor dengan 4 dan 32 core:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a1/1f6/022/0a11f6022198a582929f384be357fe43.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Waktu yang diperlukan untuk melakukan perhitungan matematis pada GPU dan CPU dengan matriks 1000 x 60 dalam ms</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
. Grafik ini melakukan perhitungan dengan matriks 1000 x 60 elemen. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perhitungan</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dimulai </font><font style="vertical-align: inherit;">dari beberapa aliran program, aliran terpisah dibuat untuk GPU untuk setiap aliran CPU (Hyper-Q digunakan).&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang Anda lihat, prosesor mengatasi beban ini dengan sangat baik, sedangkan latensi untuk satu permintaan per GPU meningkat secara signifikan dengan jumlah permintaan paralel.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e09/22c/7fb/e0922c7fba0ef001cca97c7a99817c83.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Waktu untuk melakukan perhitungan matematis pada GPU dan CPU dengan matriks 10.000 x 60 dalam ms.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pada grafik kedua, perhitungan yang sama, tetapi dengan matriks 10 kali lebih lama, dan GPU berperilaku jauh lebih baik di bawah beban seperti itu. Grafik ini sangat indikatif, dan kita dapat menyimpulkan: perilaku di bawah beban tergantung pada sifat beban itu sendiri. Sebuah prosesor juga dapat menangani perhitungan matriks dengan cukup efisien, tetapi sampai batas tertentu. Untuk kartu video, merupakan karakteristik bahwa untuk beban komputasi yang kecil, kinerjanya turun sekitar secara linear. Dengan peningkatan beban dan jumlah utas paralel, kartu video berupaya lebih baik.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sulit untuk membuat hipotesis bagaimana GPU akan berperilaku dalam berbagai situasi, tetapi seperti yang Anda lihat, dalam kondisi tertentu, kartu server dapat memproses permintaan dari beberapa aliran paralel dengan cukup efisien. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami akan membahas beberapa pertanyaan lagi yang mungkin Anda miliki jika Anda masih memutuskan untuk menggunakan GPU dalam proyek Anda.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Batas sumber daya</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang telah kami katakan, dua sumber utama kartu video adalah komputasi core dan memori. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Misalnya, kami memiliki beberapa proses atau wadah menggunakan kartu video, dan kami ingin dapat membagikan kartu video di antara mereka. </font><font style="vertical-align: inherit;">Sayangnya, tidak ada API sederhana untuk ini. </font><font style="vertical-align: inherit;">NVIDIA menawarkan teknologi </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vGPU</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , tetapi saya tidak menemukan kartu Tesla K80 dalam daftar yang didukung, dan sejauh yang saya bisa mengerti dari deskripsi, teknologi ini lebih fokus pada tampilan virtual daripada pada perhitungan. </font><font style="vertical-align: inherit;">Mungkin AMD menawarkan sesuatu yang lebih cocok. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Oleh karena itu, jika Anda berencana untuk menggunakan GPU dalam proyek Anda, Anda harus bergantung pada kenyataan bahwa aplikasi akan menggunakan kartu video secara eksklusif, atau Anda akan secara terprogram mengontrol jumlah memori yang dialokasikan dan jumlah core yang digunakan untuk perhitungan.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wadah dan GPU</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jika Anda mengetahui batas sumber daya, maka pertanyaan logis berikut: bagaimana jika ada beberapa kartu video di server? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekali lagi, Anda dapat memutuskan pada level aplikasi GPU mana yang akan digunakan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cara lain yang lebih nyaman adalah wadah Docker. </font><font style="vertical-align: inherit;">Anda dapat menggunakan wadah reguler, tetapi NVIDIA menawarkan wadah </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NGC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -nya </font><font style="vertical-align: inherit;">, dengan versi yang dioptimalkan dari berbagai perangkat lunak, perpustakaan, dan driver. </font><font style="vertical-align: inherit;">Untuk satu kontainer, Anda dapat membatasi jumlah GPU yang digunakan dan visibilitasnya ke kontainer. </font><font style="vertical-align: inherit;">Overhead pada penggunaan kontainer adalah sekitar 3%.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bekerja dalam sebuah cluster</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pertanyaan lain, apa yang harus dilakukan jika Anda ingin melakukan satu tugas pada beberapa GPU dalam server atau cluster yang sama? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jika Anda memilih perpustakaan yang mirip dengan dorong atau solusi tingkat rendah, maka tugas harus diselesaikan secara manual. </font><font style="vertical-align: inherit;">Kerangka kerja tingkat tinggi, misalnya, untuk pembelajaran mesin atau jaringan saraf, biasanya mendukung kemampuan untuk menggunakan banyak kartu di luar kotak. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selain itu, saya ingin mencatat bahwa, misalnya, NVIDIA menawarkan antarmuka untuk pertukaran data langsung antar kartu - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVLINK</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , yang secara signifikan lebih cepat daripada PCI Express. </font><font style="vertical-align: inherit;">Dan ada teknologi untuk akses langsung ke memori kartu dari perangkat PCI Express lainnya - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPUDirect RDMA</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , termasuk. </font><font style="vertical-align: inherit;">dan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jaringan</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rekomendasi</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jika Anda mempertimbangkan untuk menggunakan GPU dalam proyek Anda, maka GPU kemungkinan besar cocok untuk Anda jika:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tugas Anda dapat dikurangi menjadi tampilan SIMD</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dimungkinkan untuk memuat sebagian besar data di peta sebelum perhitungan (cache)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tantangannya melibatkan komputasi intensif</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda juga harus mengajukan pertanyaan terlebih dahulu:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Berapa banyak permintaan paralel akan&nbsp;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apa latensi yang Anda harapkan</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apakah Anda memerlukan satu kartu untuk memuat Anda? Apakah Anda memerlukan server dengan beberapa kartu atau sekelompok server GPU&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Itu saja, saya berharap materi tersebut akan berguna bagi Anda dan membantu Anda membuat keputusan yang tepat!</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Referensi</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Benchmark dan hasil pada github - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://github.com/tishden/gpu_benchmark/tree/master/cuda</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Selain topik, rekaman laporan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Basis Data GPU - Arsitektur, Kinerja, dan Prospek untuk Penggunaan"</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
NVIDIA NGC Containers Webinar - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http : //bit.ly/2UmVIVt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> atau </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://bit.ly/2x4vJKF</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id498362/index.html">Kingston mempertahankan kepemimpinan dalam pengiriman SSD: bagaimana kita melakukannya?</a></li>
<li><a href="../id498366/index.html">Algoritma apa yang diterapkan pengembang Yandex setiap hari</a></li>
<li><a href="../id498368/index.html">Kisah satu saklar</a></li>
<li><a href="../id498370/index.html">SAP UI5 dan Confirmation Windows: Lagi Tentang Konteks</a></li>
<li><a href="../id498372/index.html">Tutorial jaringan simulator ns-3. Bab 5</a></li>
<li><a href="../id498378/index.html">Pengumuman Slurm's Evening School oleh Agile</a></li>
<li><a href="../id498380/index.html">Jendela tindakan Overton: bagaimana pandemi digunakan untuk membatasi kebebasan kita</a></li>
<li><a href="../id498390/index.html">IAR + Clion = persahabatan</a></li>
<li><a href="../id498392/index.html">18 fitur GitLab menjadi open source</a></li>
<li><a href="../id498394/index.html">7 analog gratis dari Screaming Frog dan Netpeak Spider</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏼 🕣 ⤵️ Pandas und andere für dicke Daten 🛡️ ♈️ 🙍🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In diesem Artikel werde ich auf einige einfache Tricks eingehen, die nützlich sind, wenn Sie mit Daten arbeiten, die nicht in den lokalen Computer pas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pandas und andere für dicke Daten</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488594/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In diesem Artikel werde ich auf einige einfache Tricks eingehen, die nützlich sind, wenn Sie mit Daten arbeiten, die nicht in den lokalen Computer passen, aber immer noch zu klein sind, um als groß bezeichnet zu werden. </font><font style="vertical-align: inherit;">In Anlehnung an die englischsprachige Analogie (groß, aber nicht groß) werden wir diese Daten als dick bezeichnen. </font><font style="vertical-align: inherit;">Wir sprechen von Einheitengrößen und zehn Gigabyte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[Haftungsausschluss] Wenn Sie SQL lieben, kann alles, was unten geschrieben steht, zu hellen, höchstwahrscheinlich negativen Emotionen führen. In den Niederlanden gibt es 49262 Tesla, von denen 427 Taxis sind. Lesen Sie besser nicht weiter [/ Haftungsausschluss].</font></font><br>
<br>
<img src="https://habrastorage.org/webt/-s/ac/gl/-sacgl0hwmynxnpiov5s_coofa4.png" alt="Bild"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ausgangspunkt war </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ein Artikel über die Nabe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mit einer Beschreibung eines interessanten Datensatzes - eine vollständige Liste der in den Niederlanden zugelassenen Fahrzeuge, 14 Millionen Linien, von LKW-Traktoren bis hin zu Elektrofahrrädern mit einer Geschwindigkeit von über 25 km / h. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Set ist interessant, dauert 7 GB, </font><font style="vertical-align: inherit;">Sie können es auf der Website der zuständigen Organisation </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">herunterladen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Versuch, die Daten so zu steuern, wie sie in den Pandas sind, um sie zu filtern und zu bereinigen, endete mit einem Fiasko (Herren der SQL-Husaren, warnte ich!). Pandas fielen aus einem Mangel an Speicher auf dem Desktop mit 8 GB. Mit ein wenig Blutvergießen kann die Frage gelöst werden, wenn Sie sich daran erinnern, dass die Pandas CSV-Dateien in mittelgroßen Stücken lesen können. Die Fragmentgröße in Zeilen wird durch den Parameter chunksize bestimmt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die Arbeit zu veranschaulichen, schreiben wir eine einfache Funktion, die eine Anfrage stellt und bestimmt, wie viele Tesla-Autos insgesamt sind und welcher Anteil davon in Taxis arbeitet. Ohne Tricks beim Fragmentlesen verbraucht eine solche Anfrage zuerst den gesamten Speicher, leidet dann lange und am Ende fällt die Rampe ab. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beim Lesen von Fragmenten sieht unsere Funktion ungefähr so ​​aus:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pandas_chunky_query</span>():</span>
    print(<span class="hljs-string">'reading csv file with pandas in chunks'</span>)<font></font>
    filtered_chunk_list=[]<font></font>
    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> pd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>, chunksize=<span class="hljs-number">1E+6</span>):<font></font>
        filtered_chunk=chunk[chunk[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        filtered_chunk_list.append(filtered_chunk)<font></font>
    model_df = pd.concat(filtered_chunk_list)<font></font>
    print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Indem Sie eine absolut vernünftige Million Zeilen angeben, können Sie die Abfrage in 1:46 ausführen und 1965 M Speicher in der Spitze verwenden. Alle Zahlen für einen dummen Desktop mit etwas Altem, acht Kernen, ungefähr 8 GB Speicher und unter dem siebten Windows. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7d/id/0-/7did0-qetjm9v9wrlaouudevkss.png" alt="Bild"><br>
<br>
<img src="https://habrastorage.org/webt/8n/ch/go/8nchgo5c-tr54min7qwpfvgwuuq.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie die Blockgröße ändern, folgt der maximale Speicherverbrauch buchstäblich darauf, und die Ausführungszeit ändert sich nicht wesentlich. Für 0,5 M Leitungen dauert die Anforderung 1:44 und 1063 MB, für 2M 1:53 und 3762 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Geschwindigkeit ist nicht sehr erfreulich, noch weniger erfreulich ist, dass Sie beim Lesen der Datei in Fragmenten gezwungen sind, für diese Funktion angepasstes Schreiben zu schreiben und mit Listen von Fragmenten zu arbeiten, die dann in einem Datenrahmen gesammelt werden müssen. Auch das CSV-Format selbst ist nicht sehr zufrieden, was viel Platz einnimmt und langsam gelesen wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da wir Daten in eine Rampe treiben können, kann ein viel kompakteres Apachev-Format für die Speicherung verwendet werden</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parkett</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bei Komprimierung und dank des Datenschemas ist das Lesen beim Lesen viel schneller. Und die Rampe kann durchaus mit ihm arbeiten. Nur jetzt können sie nicht in Fragmenten gelesen werden. Was ist zu tun? </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Lass uns Spaß haben, nimm das </font><font style="vertical-align: inherit;">Dask- </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Knopfakkordeon</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und beschleunige! </font></font></i><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dask!</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ein Ersatz für die sofort einsatzbereite Rampe, die große Dateien lesen, auf mehreren Kernen parallel arbeiten und verzögerte Berechnungen verwenden kann. Zu meiner Überraschung über Dask on Habré gibt es nur 4 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Veröffentlichungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Also nehmen wir den Dask, fahren den Original-CSV hinein und fahren ihn mit minimaler Konvertierung auf den Boden. Beim Lesen schwört dask auf die Mehrdeutigkeit von Datentypen in einigen Spalten, daher setzen wir sie explizit ein (aus Gründen der Klarheit wurde das Gleiche für die Rampe getan, die Betriebszeit ist unter Berücksichtigung dieses Faktors höher, das Wörterbuch mit dtypes wird aus Gründen der Klarheit aus allen Abfragen herausgeschnitten), der Rest ist für sich . Außerdem überprüfen wir zur Überprüfung den Bodenbelag geringfügig, indem wir versuchen, die Datentypen auf die kompaktesten zu reduzieren, ein Spaltenpaar durch Ja / Nein-Text durch Boolesche zu ersetzen und andere Daten in die wirtschaftlichsten Typen umzuwandeln (für die Anzahl der Motorzylinder ist uint8 definitiv ausreichend). Wir speichern den optimierten Boden separat und sehen, was wir bekommen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das erste, was bei der Arbeit mit Dask gefällt, ist, dass wir nichts Überflüssiges schreiben müssen, nur weil wir dicke Daten haben. Wenn Sie nicht darauf achten, dass das Dask importiert wird und nicht die Rampe, sieht alles so aus, als würde eine Datei mit hundert Zeilen in der Rampe verarbeitet (plus ein paar dekorative Pfeifen für die Profilerstellung).</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading CSV file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>)<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts().compute())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Vergleichen Sie nun die Auswirkungen der Quelldatei auf die Leistung bei der Arbeit mit dasko. Zuerst lesen wir die gleiche CSV-Datei wie bei der Arbeit mit der Rampe. Das gleiche ungefähr zwei Minuten und zwei Gigabyte Speicher (1:38 2096 Mb). Es schien, war es das wert, sich im Gebüsch zu küssen? </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9a/oy/al/9aoyalzd1a62bw31uivvy699xme.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Führen Sie nun die nicht optimierte Parkettdatei des Bretts ein. Die Anfrage wurde in ungefähr 54 Sekunden verarbeitet und verbrauchte 1388 MB Speicher. Die Datei selbst für die Anfrage ist jetzt zehnmal kleiner (ungefähr 700 MB). Hier sind die Boni bereits konvex sichtbar. Eine CPU-Auslastung von Hunderten von Prozent ist eine Parallelisierung über mehrere Kerne.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1u/sz/_x/1usz_xafa2hng3nogb2fbp9zspm.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das zuvor optimierte Parkett mit leicht modifizierten Datentypen in komprimierter Form ist nur 1 MB weniger, was bedeutet, dass ohne Hinweise alles recht effizient komprimiert wird. </font><font style="vertical-align: inherit;">Die Produktivitätssteigerung ist ebenfalls nicht besonders signifikant. </font><font style="vertical-align: inherit;">Die Anfrage dauert die gleichen 53 Sekunden und verbraucht etwas weniger Speicher - 1332 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Basierend auf den Ergebnissen unserer Übungen können wir Folgendes sagen:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn Ihre Daten „fett“ sind und Sie an eine Rampe gewöhnt sind - Chunksize hilft der Rampe, dieses Volumen zu verdauen, ist die Geschwindigkeit erträglich. </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn Sie mehr Geschwindigkeit herausholen möchten, während der Lagerung Platz sparen und sich nicht nur mit einer Rampe zurückhalten möchten, ist die Dämmerung mit Parkett eine gute Kombination. </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Schluss noch über Lazy Computing. Eines der Merkmale des Dasks ist, dass es verzögerte Berechnungen verwendet, dh Berechnungen werden nicht sofort ausgeführt, wie sie im Code enthalten sind, sondern wenn sie wirklich benötigt werden oder wenn Sie sie explizit mithilfe der Berechnungsmethode angefordert haben. In unserer Funktion liest dask beispielsweise nicht alle Daten in den Speicher, wenn wir angeben, die Datei zu lesen. Er liest sie später und nur die Spalten, die sich auf die Anfrage beziehen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies ist im folgenden Beispiel leicht zu erkennen. </font><font style="vertical-align: inherit;">Wir nehmen eine vorgefilterte Datei, in der wir nur 12 Spalten von den anfänglichen 64 übrig gelassen haben. Komprimiertes Parkett benötigt 203 MB. </font><font style="vertical-align: inherit;">Wenn Sie unsere reguläre Anforderung darauf ausführen, wird sie in 8,8 Sekunden ausgeführt, und die maximale Speicherauslastung beträgt ca. 300 MB, was einem Zehntel der komprimierten Datei entspricht, wenn Sie sie in einer einfachen CSV-Datei überholen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/jg/we/bq/jgwebqzk7enoz6z6rwiearbofgs.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie ausdrücklich aufgefordert werden, die Datei zu lesen und dann die Anforderung auszuführen, beträgt der Speicherverbrauch fast das Zehnfache. </font><font style="vertical-align: inherit;">Wir ändern unsere Funktion geringfügig, indem wir die Datei explizit lesen:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading parquet file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_parquet(<span class="hljs-string">'C:\Open_data\RDW_filtered.parquet'</span> ).compute()<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]
        <span class="hljs-comment">#print(model_df.head())</span>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und hier ist, was wir bekommen, 10,5 Sekunden und 3568 MB Speicher (!) </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w5/5w/aj/w55wajaohsdjyevm1hxbgpvns2a.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wieder einmal sind wir davon überzeugt, dass der Dask - er ist kompetent in seinen Aufgaben und es lohnt sich nicht, noch einmal mit Mikromanagement darauf zu klettern.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de488584/index.html">Was Sie wissen möchten, bevor Sie eine Anwendung für die Apple Watch schreiben: unsere Erfahrung</a></li>
<li><a href="../de488586/index.html">The Ember Times - Ausgabe 135</a></li>
<li><a href="../de488588/index.html">C ++ 20 genehmigt! Was Sie erwartet und was Sie für Entwickler in C ++ 23 vorbereiten müssen</a></li>
<li><a href="../de488590/index.html">FOSS News Nr. 3 - Überprüfung der kostenlosen und Open Source-Nachrichten für den 10. bis 16. Februar 2020</a></li>
<li><a href="../de488592/index.html">Ein offener Brief von Mail.ru über das Spiel "Allods II: Lord of Souls"</a></li>
<li><a href="../de488596/index.html">Google hat einen Algorithmus zum automatischen Zuschneiden von Videos auf wichtige Objekte im Frame entwickelt</a></li>
<li><a href="../de488598/index.html">Ist die Welt bereit für eine Pandemie?</a></li>
<li><a href="../de488600/index.html">Wie sich Anbieter um die Sicherheit ihrer Kunden kümmern</a></li>
<li><a href="../de488602/index.html">iOS MEETUP # 2 von FUNCORP und Wie man einen Entwickler auf dem Laufenden hält</a></li>
<li><a href="../de488604/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends für die letzte Woche Nr. 402 (10. - 16. Februar 2020)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶Ä üòß üïØÔ∏è Implementierung von WebRTC auf einem Medienserver - Praxis und Richtlinien ü§≥ üé• üí§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="1. Streaming zu Browsern in Echtzeit - keine L√∂sung. Oder ist da?
 
 Seit etwa 20 Jahren erm√∂glichen die Netzwerkbandbreite und die Rechenkapazit√§ten ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Implementierung von WebRTC auf einem Medienserver - Praxis und Richtlinien</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498418/"><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. Streaming zu Browsern in Echtzeit - keine L√∂sung. </font><font style="vertical-align: inherit;">Oder ist da?</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seit etwa 20 Jahren erm√∂glichen die Netzwerkbandbreite und die Rechenkapazit√§ten von Computern die Komprimierung und √úbertragung von Ton und Video √ºber das IP-Protokoll nahezu in Echtzeit. In dieser Zeit haben zentrale Standardisierungsorganisationen wie W3C und IETF sowie viele gro√üe und kleine Unternehmen Hunderte von Standards und Protokollen entwickelt, um Audio-Video-Inhalte auf Computern und Mobilger√§ten effizient zu komprimieren, zu verpacken, weiterzuleiten, zu synchronisieren und abzuspielen. Besonderes Augenmerk wurde auf die Erfassung, Komprimierung und √úbertragung von Videos in Echtzeit √ºber IP gelegt, da IP zum einen auf allen Ebenen am billigsten und am leichtesten zug√§nglich ist und zum anderen Videokonferenz- und Video√ºberwachungstechnologien von entscheidender Bedeutung sind und eine gro√üe Nachfrage haben.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es scheint, dass so viele Jahre vergangen sind und so viel Arbeit geleistet wurde. Welche wunderbaren Erfolge in diesem Bereich k√∂nnen wir nach 20 Jahren beobachten? Lassen Sie uns den Deckel der Box entfernen (nat√ºrlich ist dies nicht die B√ºchse von Pandora und keine ‚ÄûDose W√ºrmer‚Äú) und sehen, welche wunderbaren Technologien und M√∂glichkeiten nach langj√§hriger Arbeit von Zehntausenden talentierter Software-Ingenieure verf√ºgbar wurden. Ein Programmierer aus dem Jahr 1998, der zuerst Ton √ºber das Netzwerk gesendet hat, ein Arzt, der eine einfache, billige und zuverl√§ssige Telemedizinl√∂sung w√ºnscht, ein Lehrer, der eine Fernstunde durchf√ºhren muss - jetzt √∂ffnen sie diese Abdeckung, voller heller Hoffnungen, und was sehen sie? In einer offensiven Kochpfanne voller umwerfendem Marketing, zynischem Kapitalismus und verzweifelten Versuchen von Enthusiasten, Dinge zu verbessern, schweben alle Arten von Codecs, Protokollen, Formaten und Anwendungen.Dies bietet die IT-Suppe ‚ÄûCommunity‚Äú dem Verbraucher in Echtzeit. Fangen Sie sich, die weniger riecht, versuchen, testen, kaufen. Es gibt keine einfache und effektive L√∂sung. Im Gegensatz zu Streaming, das keine Echtzeit ben√∂tigt: Immerhin gibt es bereits etwa 5 Jahre, und es gibt einen HLS-Standard, der auf allen Browsern und Ger√§ten funktioniert, auf denen der L√∂sungsanbieter den HLS-Segmentierer einfach auf Ihrem Server installieren und ruhig schlafen kann.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hier ist RTSP - viele Konsolen und professionelle Ger√§te spielen es, aber Browser spielen nicht. Hier ist RTMP - Safari m√∂chte es nicht auf iOS spielen und nicht alle Androids spielen es. Chrome verbietet es als nicht vertrauensw√ºrdig. Hier ist MPEG2-TS - Browser spielen es auch nicht ab. HTML5 Media Source Extensions (MSE) - gut f√ºr Videosegmente mit einer L√§nge von 5 bis 10 Sekunden (d. H. F√ºr HLS / Dash), aber f√ºr kurze Segmente mit einer L√§nge von weniger als einer Sekunde - nicht immer stabil, funktioniert in verschiedenen Browsern immer wieder unterschiedlich wird unter iOS nicht unterst√ºtzt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie, fragt man sich, sendet der Kindergarten Videos von in Gruppen installierten Kameras an Eltern, die jederzeit einen Browser auf einem beliebigen Ger√§t √∂ffnen m√∂chten, ohne Plug-Ins zu installieren, um ihre Kinder in Echtzeit zu beobachten? Warum bieten nicht alle Kinderg√§rten solche Dienstleistungen an? Ja, weil die Bereitstellung eines solchen Dienstes sehr teuer ist. Wir m√ºssen Apps f√ºr mobile Ger√§te entwickeln, auf denen das Video abgespielt wird - da Browser nicht abgespielt werden. Brauche viel mehr. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Definieren wir das Konzept "nahezu in Echtzeit". Dies ist weniger als 5 Sekunden Verz√∂gerung f√ºr die Video√ºberwachung und weniger als 1 Sekunde f√ºr Videokonferenzen. Die durchschnittliche Verz√∂gerung des HLS-Protokolls betr√§gt 20-30 Sekunden. Vielleicht ist es irgendwie f√ºr Kinderg√§rten geeignet, aber f√ºr Sicherheitsvideo√ºberwachung, Videokonferenzen und Webinare wird eine andere Technologie ben√∂tigt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bis jetzt, genauer gesagt bis zum Sommer 2017, gab es keinen einzigen Standard oder Protokoll f√ºr die √úbertragung von Audio-Video an einen Browser auf einem Ger√§t in Echtzeit. Die Gr√ºnde f√ºr diese Situation werden wir sp√§ter in diesem Artikel betrachten. Sie sind aus diesen Gr√ºnden nicht technischer Natur. Lassen Sie uns in der Zwischenzeit sehen, was im Sommer 2017 passiert ist, was zumindest eine Technologie darstellt, mit der wir die oben genannten Probleme l√∂sen k√∂nnen. Bei dieser Technologie handelt es sich um WebRTC. Sowohl in dieser Ressource als auch im Netzwerk im Allgemeinen wurde viel dar√ºber geschrieben. Es kann nicht mehr als v√∂llig neu bezeichnet werden, und zum Zeitpunkt dieses Schreibens betrachtet W3C WebRTC 1.0 als abgeschlossenes Projekt. Wir werden hier nicht dar√ºber sprechen, was WebRTC ist. Wenn der Leser mit dieser Technologie nicht vertraut ist, empfehlen wir, eine Suche im Hub oder in Google durchzuf√ºhren und sich kennenzulernen.wof√ºr es verwendet wird und wie es allgemein funktioniert. Hier sagen wir nur, dass diese Technologie f√ºr die Peer-to-Peer-Kommunikation in Browsern entwickelt wurde. Mit ihr k√∂nnen Sie Video-Chat- und Sprachanwendungen ohne Server implementieren - der Browser kommuniziert direkt mit dem Browser. WebRTC wird von allen Browsern auf allen Ger√§ten unterst√ºtzt. Im Sommer 2017 kam Apple schlie√ülich zu uns und f√ºgte es seiner Safari unter iOS hinzu. Es war dieses Ereignis, das WebRTC seit dem Sonnenuntergang von RTMP, der 2015 begann, zur universellsten und allgemein akzeptierten Technologie f√ºr Echtzeit-Streaming zu Browsern machte.WebRTC wird von allen Browsern auf allen Ger√§ten unterst√ºtzt. Im Sommer 2017 kam Apple schlie√ülich zu uns und f√ºgte es seiner Safari unter iOS hinzu. Dieses Ereignis machte WebRTC zur universellsten und allgemein akzeptierten Technologie f√ºr Echtzeit-Streaming zu Browsern seit dem Sonnenuntergang von RTMP, der 2015 begann.WebRTC wird von allen Browsern auf allen Ger√§ten unterst√ºtzt. Im Sommer 2017 kam Apple schlie√ülich zu uns und f√ºgte es seiner Safari unter iOS hinzu. Dieses Ereignis machte WebRTC zur vielseitigsten und allgemein akzeptierten Technologie f√ºr Echtzeit-Streaming zu Browsern seit dem Sonnenuntergang von RTMP, der 2015 begann.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was hat das Streaming von Kameras zu Browsern damit zu tun? Tatsache ist jedoch, dass WebRTC in seiner Funktionalit√§t sehr flexibel ist und es Ihnen erm√∂glicht, Audio-Video nur an einen der beiden Teilnehmer (Peers) zu senden und nur den anderen zu akzeptieren. Daher wurde die Idee geboren, WebRTC in Medienservern anzupassen. Der Medienserver kann Videos von der Kamera empfangen, die Kommunikation mit dem Browser herstellen und zustimmen, dass nur dieser sendet und der Browser empf√§ngt. Somit kann der Medienserver gleichzeitig Videos von der Kamera an viele Browser / Betrachter senden. Umgekehrt kann ein Medienserver einen Stream von einem Browser empfangen und ihn beispielsweise an viele andere Browser weiterleiten, wobei die gew√ºnschte "Eins-zu-Viele" -Funktion implementiert wird.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Also war endlich alles geformt? Akuna Matata und der Kindergarten k√∂nnen einen solchen Medienserver irgendwo auf dem Hosting oder auf AWS installieren, von jeder Kamera einen Stream senden und von dort aus bereits mit einer Verz√∂gerung von nicht mehr als einer Sekunde an die Browser der Eltern verteilt werden. Im Allgemeinen - ja, das Leben wird besser. Aber es gibt Probleme. Und diese Probleme h√§ngen mit der Tatsache zusammen, dass WebRTC f√ºr solche Aufgaben sozusagen weit hergeholt ist, es wurde nicht f√ºr sie entwickelt und ist f√ºr sie nicht ganz geeignet. Neben der Codec-Kompatibilit√§t bestehen haupts√§chlich Probleme mit der Skalierbarkeit eines solchen Medienservers. Das hei√üt, gleichzeitig k√∂nnen 100 Eltern von einem Server-Computer aus bedient werden, und 500 sind bereits schwierig. Obwohl das Netzwerk erlaubt. Und schauen Sie sich die Prozessorlast auf dem Server mit 100 Verbindungen an - sie liegt bereits bei fast 90%. Wie das? Senden Sie doch einfach ein Soundvideo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie mit demselben Stream √ºber das RTMP-Protokoll an den Flash Player gesendet werden, k√∂nnen Sie problemlos 2000 gleichzeitige Verbindungen von einem Server aus unterst√ºtzen. Ist WebRTC nur 100? </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Warum? Es gibt zwei Gr√ºnde: Erstens ist das WebRTC-Protokoll viel rechenintensiver - dort werden beispielsweise alle Daten verschl√ºsselt und es nimmt viel Prozessorzeit in Anspruch. Der zweite Grund, auf den wir noch n√§her eingehen werden, ist die √§u√üerst ineffiziente Implementierung des Protokolls durch seinen Ersteller - Google, der den Quell-C ++ - Code f√ºr diese Implementierung zur Anpassung an Server, Gateways und andere Anwendungen bereitstellt, die WebRTC unterst√ºtzen m√∂chten: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">webrtc.org/native-code </font></font></a><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 Googles native WebRTC-API und Media Server-Kompatibilit√§t</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Denken Sie daran, dass WebRTC erstellt wurde, um Audio-Video vom Browser zum Browser zu √ºbertragen, und dass keine Aufgaben zur Unterst√ºtzung vieler gleichzeitiger Verbindungen vorhanden waren. Daher und nicht nur deshalb hat die Implementierung von WebRTC im Browser das Grundprinzip des Designs und der Architektur technischer Systeme - Eleganz (nichts weiter), Effizienz, hohe Leistung - v√∂llig au√üer Acht gelassen. Der Schwerpunkt lag auf Zuverl√§ssigkeit und Verwaltbarkeit bei Fehlern und Extremsituationen im Netzwerk - Verlust von Paketen, Verbindungen usw. Was nat√ºrlich gut ist. Bei n√§herer Betrachtung stellt sich jedoch heraus, dass dies das einzige ist, was bei der Google-Implementierung von WebRTC gut ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schauen wir uns die wichtigsten Punkte an, aufgrund derer die Verwendung der Google-Implementierung von WebRTC f√ºr Medienserver √§u√üerst problematisch ist.</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.a Der Code ist zehnmal h√∂her als er sein sollte und √§u√üerst ineffizient.</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Dies ist eine bew√§hrte Zahl. Zun√§chst laden Sie etwa 5 Gigabyte Code herunter, von denen nur 500 Megabyte f√ºr WebRTC relevant sind. Dann versuchen Sie, den unn√∂tigen Code loszuwerden. Schlie√ülich ben√∂tigen Sie f√ºr die Anforderungen eines Medienservers keine Codierung / Decodierung. Der Server sollte nur Inhalte empfangen und an alle weiterleiten. Wenn Sie alles Unn√∂tige entfernt haben, das Sie konnten (und Sie konnten viel weniger entfernen, als Sie m√∂chten), haben Sie immer noch 100 Megabyte Code. Dies ist eine monstr√∂se Figur. Sie ist zehnmal gr√∂√üer als es sein sollte.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√úbrigens werden an dieser Stelle viele sagen - wie wird das Codieren / Decodieren nicht ben√∂tigt? Was ist mit der Transcodierung von AAC zu Opus und umgekehrt? Was ist mit der Transcodierung von VP9-&gt; H264? Wenn Sie eine solche Transcodierung auf dem Server durchf√ºhren, k√∂nnen Sie auch nicht 5 gleichzeitige Verbindungen herstellen. Wenn es wirklich notwendig ist, sollte die Transcodierung nicht von einem Medienserver, sondern von einem anderen Programm durchgef√ºhrt werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber kehren wir zum Problem des aufgebl√§hten Codes zur√ºck und veranschaulichen es. Was ist Ihrer Meinung nach die Tiefe des Funktionsaufrufstapels beim Senden eines bereits komprimierten Videobilds? Ein Aufruf von Winsock (unter Windows) der Funktion send oder sendto (WSASend / WSASendTo)? Nein, nat√ºrlich muss noch etwas Arbeit geleistet werden. Im Fall von WebRTC m√ºssen Sie den Frame √ºber das RTP-Protokoll packen und verschl√ºsseln, wodurch wir insgesamt das SRTP-Protokoll erhalten. Es ist notwendig, den Frame im Falle eines Paketverlusts zu speichern, um ihn sp√§ter erneut zu senden. Wie viele C ++ - Objekte und Threads sollten daran beteiligt sein? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So macht es WebRTC 61: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ft/lo/f9/ftlof9hwbtg9so0qbsoji-z93bw.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Sie auf diesem Screenshot sehen k√∂nnen, betr√§gt die Aufrufstapeltiefe von dem Moment an, in dem wir den komprimierten Frame an WebRTC weiterleiten, bis zur Warteschlange des Paced_Sender-Objekts 8 (!) Und 7 Objekte sind beteiligt!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann zieht ein separater Thread (Thread) PacedSender unseren Frame aus der Warteschlange und sendet ihn zur Verarbeitung weiter: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/o8/m4/et/o8m4etbmhrvwhvk01zagwptrwoy.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schlie√ülich kamen wir zu Schritt 4, in dem der bereits RTP-gepackte und verschl√ºsselte Frame von der Warteschlange abh√§ngt, die an das Netzwerk gesendet werden soll, das in einem anderen Thread besch√§ftigt ist. Zu diesem Zeitpunkt betr√§gt die Tiefe des Aufrufstapels (im PacedSender-Thread) 7, und es sind 3 weitere neue Objekte beteiligt. Der Thread, der gerade mit dem Senden besch√§ftigt ist, ruft das endg√ºltige WSASend / WSASendTo auch nach 3-4 verschachtelten Funktionsaufrufen auf und umfasst 3-4 weitere neue Objekte.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben also 3 Threads gesehen, von denen jeder einen tollen Job macht. Jeder, der solche Systeme programmiert hat, hat eine Vorstellung davon, wie solche Dinge gemacht werden und was wirklich getan werden muss. Nach unseren Sch√§tzungen sind mindestens 90% der Objekte und des Codes hier √ºberfl√ºssig und versto√üen gegen die Prinzipien der objektorientierten Programmierung. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.b Pro Verbindung werden 4-5 Threads zugewiesen</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kein Zweifel, mit der Anzahl der Threads in diesem Beispiel ist alles in Ordnung. Es ist notwendig, eine asynchrone Verarbeitung bereitzustellen, um niemanden zu blockieren, und alle 3 Threads werden ben√∂tigt. Im Allgemeinen weist ein PeerConnection-WebRTC 4-5 Threads zu. Nun, es w√§re m√∂glich, innerhalb von 3 zu bleiben. Aber nicht weniger. Das Problem ist, dass dies f√ºr jede Verbindung gilt! Auf dem Server k√∂nnen Sie beispielsweise 3 Threads speichern, die jedoch alle Verbindungen zusammen bedienen und nicht jeder Verbindung 3 Threads zuweisen. Der Thread-Pool ist zweifellos eine Serverl√∂sung f√ºr solche Aufgaben. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.c Asynchrone Sockets, die Windows-Nachrichten verarbeiten</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Google WebRTC-Code unter Windows verwendet asynchrone Sockets √ºber WSAAsyncSelect. Serverprogrammierer wissen, dass die Verwendung der Auswahlfunktion auf dem Server Selbstmord und WSAAsyncSelect ist, obwohl dies die Situation verbessert, jedoch nicht um eine Gr√∂√üenordnung. Wenn Sie Hunderte und Tausende von Verbindungen unterst√ºtzen m√∂chten, gibt es unter Windows eine bessere L√∂sung als asynchrone Sockets. √úberlappende Sockets und E / A-Abschlussports m√ºssen aktiviert sein, um Benachrichtigungen an den Thread-Pool zu senden, der die Arbeit ausf√ºhrt. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.d Fazit</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Wir k√∂nnen also zu dem Schluss kommen, dass das Anwenden des WebRTC-Codes von Google ohne gr√∂√üere √Ñnderungen auf einen Medienserver m√∂glich ist, der Server jedoch nicht in der Lage ist, Hunderte von Verbindungen gleichzeitig herzustellen. Es kann zwei L√∂sungen geben:</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wesentliche √Ñnderungen am Google-Code vorzunehmen, ist ohne √úbertreibung nahezu unm√∂glich - schlie√ülich sind alle diese Objekte sehr eng miteinander verbunden, kapseln keine Funktionalit√§t, sind keine unabh√§ngigen Bl√∂cke, die bestimmte Arbeiten ausf√ºhren, wie es sein sollte. Eine unver√§nderte Einbeziehung in andere Szenarien ist nicht m√∂glich.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Verwenden Sie √ºberhaupt keinen Google-Code, sondern implementieren Sie alles selbst mithilfe offener Bibliotheken wie libsrtp und dergleichen. Vielleicht ist dies der richtige Weg, aber abgesehen von der Tatsache, dass dies auch eine gro√üe Aufgabe ist, k√∂nnen Sie auf die Tatsache sto√üen, dass Ihre Implementierung nicht vollst√§ndig mit Google kompatibel ist und dementsprechend nicht oder nicht in allen F√§llen funktioniert Zum Beispiel mit Chrom, das nicht toleriert werden kann. Sie k√∂nnen sich dann lange mit den Jungs von Google streiten und beweisen, dass Sie den Standard befolgt haben, aber sie haben es nicht, und Sie werden tausendmal Recht haben. Aber sie werden bestenfalls sagen: "Wir werden es reparieren, vielleicht irgendwie sp√§ter." Sie m√ºssen sich jetzt auf Chrom einstellen. Und der Punkt. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3. Warum ist alles so traurig?</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Situation beim Streaming zu Browsern in Echtzeit ist ein sehr charakteristisches Beispiel daf√ºr, wozu ‚Äûgesch√§ftsorientierte Technologie‚Äú manchmal f√ºhrt. Die vom Gesch√§ft motivierte Technologie entwickelt sich in die Richtung, in die sie f√ºr das Gesch√§ft notwendig ist, und sofern sie f√ºr dieses Gesch√§ft angenehm ist. Es ist dem Gesch√§ftsansatz zu verdanken, dass wir jetzt √ºber PCs und Mobiltelefone verf√ºgen - keine Regierung oder zentrale Planungsbeh√∂rde k√∂nnte jemals so interessiert sein, all diese Verbrauchertechnologien zu entwickeln und der Masse vorzustellen. Das Privatunternehmen, motiviert durch den pers√∂nlichen Gewinn seiner Eigent√ºmer, tat dies, sobald sich eine technische Gelegenheit ergab.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es ist seit langem bekannt, verstanden und akzeptiert, dass nicht wesentliche Konsumg√ºter und Dienstleistungen, ohne die Sie in Frieden leben k√∂nnen, von privaten Unternehmen besser entwickelt werden als die Dinge, die f√ºr eine Person von entscheidender Bedeutung sind - Energie, Stra√üen, Polizei und Schulbildung - zentral entwickelt werden sollten. staatlich kontrollierte Institutionen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir, die Kinder der Sowjetunion und die Mentalit√§t "machen wir technisch korrekte und starke Technologie, damit die Menschen sie nutzen k√∂nnen und alles in Ordnung ist", k√∂nnten nat√ºrlich sagen, dass in einem geplanten sowjetischen System (wenn die Regierung pl√∂tzlich entscheidet) die Streaming-Technologie Echtzeit-IP k√∂nnte in einem Jahr entwickelt und implementiert werden und w√§re um eine Gr√∂√üenordnung besser als das, was das Unternehmen in 20 Jahren gewonnen hat. Wir verstehen aber auch, dass es sich dann nicht entwickeln, veraltet werden und am Ende auf lange Sicht immer noch kommerzielle westliche Technologie verlieren w√ºrde.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da es durchaus m√∂glich ist, ohne Streaming-Shimming auszukommen, ist es daher zu Recht der Privatwirtschaft ausgeliefert. Welches entwickelt es in ihrem eigenen Interesse und nicht im Interesse des Verbrauchers. Wie ist es nicht im Interesse des Verbrauchers? Aber was ist mit Angebot und Nachfrage? Was braucht der Verbraucher, dann bietet das Unternehmen? Aber es bietet nicht. Alle Verbraucher schreien - Google unterst√ºtzt AAC-Audio in WebRTC, aber Google wird es niemals tun, obwohl es nur spuckt, um es zu tun. Apple ist das absolut egal und implementiert nichts von den dringend ben√∂tigten Streaming-Technologien in seinen Gadgets. Warum? Ja, weil das Unternehmen nicht immer das tut, was der Verbraucher braucht. Er tut dies nicht, wenn er Monopolist ist und keine Angst vor dem Verlust des Verbrauchers hat. Dann ist das Unternehmen damit besch√§ftigt, seine Position zu st√§rken. Deshalb hat Google in den letzten Jahren eine Reihe von Herstellern von Soundcodecs gekauft.Und jetzt wird Opus-Audio gepusht und die ganze Welt gezwungen, AAC-&gt; Opus entsprechend WebRTC zu transkodieren, da die gesamte Technologie seit langem auf AAC-Audio umgestellt hat. Google begr√ºndet dies angeblich damit, dass AAC eine kostenpflichtige Technologie ist und Opus kostenlos ist. Tats√§chlich geschieht dies jedoch, um seine Technologie als Standard zu etablieren. Wie Apple es einst mit seinem elenden HLS tat, das wir lieben gelernt haben, oder wie Adobe es mit seinem unverantwortlichen RTMP-Protokoll noch fr√ºher tat. Gadgets und Browser sind technisch immer noch recht schwierig zu entwickeln, von hier aus entstehen Monopolisten, von hier aus, wie sie sagen, sind Dinge da. Und das W3C und die IETF werden von denselben Monopolisten gesponsert, daher ist die Mentalit√§t ‚ÄûLasst uns technisch korrekte und starke Technologie herstellen, damit die Leute sie nutzen k√∂nnen und alles in Ordnung ist‚Äú nicht da und wird es niemals sein.Aber es h√§tte sein sollen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was ist der Ausweg aus dieser Situation? Wenn man nur auf die ‚Äûrichtige‚Äú gesch√§ftsorientierte Technologie, das Ergebnis des Wettbewerbs und allerlei andere gro√üartige Dinge wartet, wird man sich schlie√ülich etwas Demokratisches einfallen lassen, das f√ºr einen einfachen Landarzt geeignet ist, damit er mit seinem normalen Internet Telemedizin-Dienste anbieten kann. In der Tat ist es notwendig, eine √Ñnderung vorzunehmen, nicht f√ºr einen einfachen Landarzt, sondern f√ºr diejenigen, die viel Geld bezahlen k√∂nnen. Das Unternehmen bietet seit langem Echtzeit-Streaming-L√∂sungen an. Gut, zuverl√§ssig und erfordert spezielle Netzwerke und spezielle Ger√§te. In vielen F√§llen funktioniert das IP-Protokoll nicht. Was - und dies ist ein weiterer Grund f√ºr eine so traurige Situation - nicht in Echtzeit erstellt wurde und dies nicht immer garantiert. Nicht immer, aber nicht in lebenswichtigen Situationen, ist es im Moment durchaus geeignet.Versuchen wir es mit WebRTC. Bisher ist er von allen √úbeln der kleinste und demokratischste. Daf√ºr m√ºssen Sie sich schlie√ülich bei Google bedanken.</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4. Ein bisschen √ºber Medienserver, die WebRTC implementieren</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Wowza, Flashphoner, Kurento, Flussonic, Red5 Pro und Unreal Media Server - dies sind einige der Medienserver, die WebRTC unterst√ºtzen. Sie bieten die Ver√∂ffentlichung von Videos von Browsern auf dem Server und die √úbertragung von Videos √ºber WebRTC vom Server an Browser.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die in diesem Artikel beschriebenen Probleme werden in diesen Softwareprodukten auf unterschiedliche Weise und mit unterschiedlichem Erfolg gel√∂st. </font><font style="vertical-align: inherit;">Einige von ihnen, zum Beispiel Kurento und Wowza, f√ºhren Audio-Video-Transcodierungen direkt auf dem Server durch, andere, zum Beispiel Unreal Media Server, transkodieren sich nicht selbst, sondern stellen andere Programme daf√ºr bereit. </font><font style="vertical-align: inherit;">Einige Server, wie Wowza und Unreal Media Server, unterst√ºtzen das Streaming aller Verbindungen √ºber einen zentralen TCP- und UDP-Port, da WebRTC selbst f√ºr jede Verbindung einen separaten Port zuweist, sodass der Anbieter viele Ports in der Firewall √∂ffnen muss, was zu Sicherheitsproblemen f√ºhrt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In all diesen Servern sind viele Punkte und Feinheiten auf unterschiedliche Weise implementiert. </font><font style="vertical-align: inherit;">Wie sehr dies alles dem Verbraucher passt, beurteilen Sie, liebe Benutzer.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de498404/index.html">Videokonferenzen sind einfach und kostenlos</a></li>
<li><a href="../de498406/index.html">Wie die Pers√∂nlichkeit eines brillanten jungen Programmierers zerst√∂rt wurde</a></li>
<li><a href="../de498410/index.html">Vivaldi f√ºr PC und Vivaldi f√ºr Android - Teamspiel mit Punktzahl 3.0</a></li>
<li><a href="../de498412/index.html">Bewusstsein ist einfach oder was mit der Zeit nicht stimmt</a></li>
<li><a href="../de498416/index.html">Yandex verkn√ºpft die Karte automatisch mit einem anderen Konto</a></li>
<li><a href="../de498426/index.html">Wie wir die Dienstverschiebung von Yandex evakuiert haben</a></li>
<li><a href="../de498428/index.html">WAL-G: Neue Funktionen und Community-Erweiterung. Georgy Rylov</a></li>
<li><a href="../de498430/index.html">Was passiert mit dem Transport am 22. April?</a></li>
<li><a href="../de498436/index.html">GitLab CI / CD Guide f√ºr den (fast) absoluten Anf√§nger</a></li>
<li><a href="../de498438/index.html">8 einfache Fragen f√ºr Praktikums-Mentoren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
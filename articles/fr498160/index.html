<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏼‍🤝‍👨🏽 📅 👨🏼‍🤝‍👨🏻 GlusterFS comme stockage externe pour Kubernetes 🔟 🌦️ 🔌</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Trouver le stockage optimal est un processus assez compliqué, tout a ses avantages et ses inconvénients. Bien sûr, le leader dans cette catégorie est ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>GlusterFS comme stockage externe pour Kubernetes</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498160/"><img src="https://portworx.com/wp-content/uploads/2018/10/Twitter-Social-Graphic-68.png" alt="image"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trouver le stockage optimal est un processus assez compliqué, tout a ses avantages et ses inconvénients. </font><font style="vertical-align: inherit;">Bien sûr, le leader dans cette catégorie est CEPH, mais c'est un système assez complexe, mais avec des fonctionnalités très riches. </font><font style="vertical-align: inherit;">Pour nous, un tel système est redondant, étant donné que nous avions besoin d'un stockage répliqué simple en mode maître-maître pour quelques téraoctets. </font><font style="vertical-align: inherit;">Après avoir étudié beaucoup de matériel, il a été décidé de tester le produit le plus en vogue du marché pour le circuit qui nous intéresse. </font><font style="vertical-align: inherit;">Étant donné qu'aucune solution toute faite d'un tel plan n'a été trouvée, je voudrais partager mes meilleures pratiques sur ce sujet et décrire les problèmes que nous avons rencontrés dans le processus de déploiement.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Buts</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qu'attendions-nous du nouveau dépôt:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Possibilité de travailler avec un nombre pair de nœuds pour la réplication.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Installation, configuration et assistance faciles</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le système doit être adulte, éprouvé et utilisateurs</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Possibilité d'agrandir l'espace de stockage sans interruption</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le stockage doit être compatible avec Kubernetes</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Il devrait y avoir un basculement automatique lorsque l'un des nœuds plante</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'est sur le dernier point que nous avons beaucoup de questions.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Déploiement</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour le déploiement, deux machines virtuelles ont été créées sur CentOs 8. Chacune d'entre elles est connectée via un disque supplémentaire avec stockage.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Préparation préliminaire</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour GlusterFS, vous devez allouer un disque séparé avec XFS afin qu'il n'affecte en rien le système. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sélectionnez la partition:</font></font><br>
<br>
<pre><code class="bash hljs">$ fdisk /dev/sdb<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): n<font></font>
Partition <span class="hljs-built_in">type</span><font></font>
   p   primary (0 primary, 0 extended, 4 free)<font></font>
   e   extended (container <span class="hljs-keyword">for</span> logical partitions)<font></font>
Select (default p): p<font></font>
Partition number (1-4, default 1):  1<font></font>
First sector (2048-16777215, default 2048): <font></font>
Last sector, +sectors or +size{K,M,G,T,P} (2048-16777215, default 16777215): <font></font>
&nbsp;<font></font>
Created a new partition 1 of <span class="hljs-built_in">type</span> ‘Linux’ and of size 8 GiB.<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): w <font></font>
<font></font>
The partition table has been altered.<font></font>
Calling ioctl() to re-read partition table. Syncing disks.<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Format en XFS et montage:</font></font><br>
<br>
<pre><code class="bash hljs">$ mkfs.xfs /dev/sdb1<font></font>
$ mkdir /gluster<font></font>
$ mount /dev/sdb1 /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et pour couronner le tout, déposez l'entrée dans / etc / fstab pour monter automatiquement le répertoire au démarrage du système:</font></font><br>
<br>
<pre><code class="bash hljs">/dev/sdb1       /gluster        xfs     defaults        0       0</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Concernant l'installation, de nombreux articles ont été écrits, à cet égard nous n'entrerons pas en profondeur dans le processus, nous allons juste réfléchir à ce à quoi il faut prêter attention. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur les deux nœuds, installez et exécutez la dernière version de glusterfs:</font></font><br>
<br>
<pre><code class="bash hljs">$ wget -P /etc/yum.repos.d  https://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-rhel8.repo<font></font>
$ yum -y install yum-utils<font></font>
$ yum-config-manager --<span class="hljs-built_in">enable</span> PowerTools<font></font>
$ yum install -y glusterfs-server<font></font>
$ systemctl start glusterd<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, vous devez indiquer au glaster où se trouve son nœud voisin. </font><font style="vertical-align: inherit;">Cela se fait avec un seul nœud. </font><font style="vertical-align: inherit;">Un point important: si vous avez un réseau de domaine, vous devez spécifier le nom du serveur avec le domaine, sinon à l'avenir vous devrez tout refaire.</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer probe gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
S'il a réussi, nous vérifions la connexion avec la commande des deux serveurs:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer status<font></font>
Number of Peers: 1<font></font>
<font></font>
Hostname: gluster-02.example.com<font></font>
Uuid: a6de3b23-ee31-4394-8bff-0bd97bd54f46<font></font>
State: Peer <span class="hljs-keyword">in</span> Cluster (Connected)<font></font>
Other names:<font></font>
10.10.6.72<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez maintenant créer un volume dans lequel nous écrirons.</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume create main replica 2 gluster-01.example.com:/gluster/main gluster-02.example.com:/gluster/main force</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Où:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">main - nom Volume </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réplique - type Volume (plus de détails peuvent être trouvés dans la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documentation officielle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 - nombre de répliques </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exécutez Volume et vérifiez ses performances:</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume start main<font></font>
gluster volume status main</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour le volume répliqué, il est recommandé de définir les paramètres suivants:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster volume <span class="hljs-built_in">set</span> main network.ping-timeout 5<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-type fixed<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-count 1<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main performance.quick-read on</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec ces étapes simples, nous avons construit un cluster GlusterFS. </font><font style="vertical-align: inherit;">Reste à s'y connecter et à vérifier les performances. </font><font style="vertical-align: inherit;">Ubuntu est installé sur la machine client, pour le montage, vous devez installer le client:</font></font><br>
<br>
<pre><code class="bash hljs">$ add-apt-repository ppa:gluster/glusterfs-7<font></font>
$ apt install glusterfs-client<font></font>
$ mkdir /gluster<font></font>
$ mount.glusterfs gluster-01.example.com:/main /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gluster, lorsqu'il est connecté à l'un des nœuds, donne les adresses de tous les nœuds et se connecte automatiquement à tous. </font><font style="vertical-align: inherit;">Si le client est déjà connecté, la panne d'un des nœuds n'entraînera pas d'arrêt. </font><font style="vertical-align: inherit;">Mais si le premier nœud n'est pas disponible, il ne sera pas possible de se connecter en cas de rupture de session. </font><font style="vertical-align: inherit;">Pour ce faire, lors du montage, vous pouvez passer le paramètre backupvolfile indiquant le deuxième noeud.</font></font><br>
<pre><code class="bash hljs">mount.glusterfs gluster-01.example.com:/main /gluster -o backupvolfile-server=gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un point important: gluster synchronise les fichiers entre les nœuds uniquement si leur modification a été effectuée via le volume monté. </font><font style="vertical-align: inherit;">Si vous apportez des modifications directement sur les nœuds, le fichier sera désynchronisé.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Connectez-vous à Kubernetes</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À ce stade, les questions ont commencé: «Comment le connecter?». </font><font style="vertical-align: inherit;">Et il y a plusieurs options. </font><font style="vertical-align: inherit;">Considérez-les.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Heketi</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le plus populaire et recommandé est d'utiliser un service externe: heketi. </font><font style="vertical-align: inherit;">heketi est une couche entre kubernetes et gluster, qui vous permet de gérer et de travailler avec le stockage via http. </font><font style="vertical-align: inherit;">Mais heketi sera ce seul point d'échec, car </font><font style="vertical-align: inherit;">le service n'est pas en cluster. </font><font style="vertical-align: inherit;">La deuxième instance de ce service ne pourra pas fonctionner de manière indépendante, car </font><font style="vertical-align: inherit;">toutes les modifications sont stockées dans la base de données locale. </font><font style="vertical-align: inherit;">L'exécution de ce service dans kubernetes ne convient pas non plus, car </font><font style="vertical-align: inherit;">il a besoin d'un disque statique sur lequel sa base de données sera stockée. </font><font style="vertical-align: inherit;">À cet égard, cette option s'est avérée la plus inappropriée.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Endpoint chez Kubernetes</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si vous avez Kubernetes sur des systèmes avec des gestionnaires de packages, alors c'est une option très pratique. </font><font style="vertical-align: inherit;">Le fait est que pour tous les serveurs GlusteFS de Kubernetes, un point de terminaison commun est créé. </font><font style="vertical-align: inherit;">Un service est suspendu sur ce point de terminaison et nous serons déjà montés sur ce service. </font><font style="vertical-align: inherit;">Pour que cette option fonctionne, il est nécessaire d'installer glusterfs-client sur chaque nœud Kubernetes et de vous assurer qu'il peut être monté. </font><font style="vertical-align: inherit;">Dans Kubernetes, déployez la configuration suivante:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: v1<font></font>
kind: Endpoints<font></font>
metadata: <font></font>
  name: glusterfs-cluster<font></font>
subsets:<font></font>
  - addresses:<font></font>
      <span class="hljs-comment">#  ip  </span>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.71</span><font></font>
    ports:<font></font>
      <span class="hljs-comment">#    1,    </span>
      - port: <span class="hljs-number">1</span><font></font>
  - addresses:<font></font>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.72</span><font></font>
    ports:<font></font>
      - port: <span class="hljs-number">1</span><font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: Service<font></font>
metadata:<font></font>
  name: glusterfs-cluster<font></font>
spec:<font></font>
  ports:<font></font>
  - port: <span class="hljs-number">1</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous pouvons maintenant créer un déploiement de test simple et vérifier le fonctionnement du montage. </font><font style="vertical-align: inherit;">Voici un exemple de déploiement de test simple:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        glusterfs:<font></font>
          endpoints: glusterfs-cluster<font></font>
          path: main<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cette option ne nous convenait pas, car nous avons container-linux sur tous les nœuds Kubernetes. </font><font style="vertical-align: inherit;">Le gestionnaire de paquets n'est pas là, il n'a donc pas été possible d'installer gluster-client pour le montage. </font><font style="vertical-align: inherit;">À cet égard, la troisième option a été trouvée, qu'il a été décidé d'utiliser.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GlusterFS + NFS + keepalived</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jusqu'à récemment, GlusterFS offrait son propre serveur NFS, mais maintenant le service externe nfs-ganesha est utilisé pour NFS. </font><font style="vertical-align: inherit;">Beaucoup a été écrit à ce sujet, à ce sujet, nous allons voir comment le configurer. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le référentiel doit être enregistré manuellement. </font><font style="vertical-align: inherit;">Pour ce faire, dans le fichier /etc/yum.repos.d/nfs-ganesha.repo nous ajoutons:</font></font><br>
<br>
<pre><code class="bash hljs">[nfs-ganesha]<font></font>
name=nfs-ganesha<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/<span class="hljs-variable">$basearch</span>/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
[nfs-ganesha-noarch]<font></font>
name=nfs-ganesha-noarch<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/noarch/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et installez:</font></font><br>
<br>
<pre><code class="bash hljs">yum -y install nfs-ganesha-gluster --nogpgcheck
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après l'installation, nous effectuons la configuration de base dans le fichier /etc/ganesha/ganesha.conf.</font></font><br>
<br>
<pre><code class="json hljs"># create new<font></font>
NFS_CORE_PARAM {<font></font>
    # possible to mount with NFSv3 to NFSv4 Pseudo path<font></font>
    mount_path_pseudo = true;<font></font>
    # NFS protocol<font></font>
    Protocols = 3,4;<font></font>
}<font></font>
EXPORT_DEFAULTS {<font></font>
    # default access mode<font></font>
    Access_Type = RW;<font></font>
}<font></font>
EXPORT {<font></font>
    # uniq ID<font></font>
    Export_Id = 101;<font></font>
    # mount path of Gluster Volume<font></font>
    Path = <span class="hljs-attr">"/gluster/main"</span>;<font></font>
    FSAL {<font></font>
        # any name<font></font>
        name = GLUSTER;<font></font>
        # hostname or IP address of this Node<font></font>
        hostname=<span class="hljs-attr">"gluster-01.example.com"</span>;<font></font>
        # Gluster volume name<font></font>
        volume=<span class="hljs-attr">"main"</span>;<font></font>
    }<font></font>
    # config for root Squash<font></font>
    Squash=<span class="hljs-string">"No_root_squash"</span>;<font></font>
    # NFSv4 Pseudo path<font></font>
    Pseudo=<span class="hljs-string">"/main"</span>;<font></font>
    # allowed security options<font></font>
    SecType = <span class="hljs-string">"sys"</span>;<font></font>
}<font></font>
LOG {<font></font>
    # default log level<font></font>
    Default_Log_Level = WARN;<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous devons démarrer le service, activer nfs pour notre volume et vérifier qu'il est activé.</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start nfs-ganesha<font></font>
$ systemctl <span class="hljs-built_in">enable</span> nfs-ganesha<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main nfs.disable off<font></font>
$ gluster volume status main<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par conséquent, l'état doit indiquer que le serveur nfs a démarré pour notre volume. </font><font style="vertical-align: inherit;">Vous devez faire monter et vérifier.</font></font><br>
<br>
<pre><code class="bash hljs">mkdir /gluster-nfs<font></font>
mount.nfs gluster-01.example.com:/main /gluster-nfs</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais cette option n'est pas tolérante aux pannes, vous devez donc créer une adresse VIP qui se déplacera entre nos deux nœuds et aidera à commuter le trafic si l'un des nœuds tombe. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'installation de keepalived dans CentOs se fait immédiatement via le gestionnaire de paquets.</font></font><br>
<br>
<pre><code class="bash hljs">$ yum install -y keepalived</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous configurons le service dans le fichier /etc/keepalived/keepalived.conf:</font></font><br>
<br>
<pre><code class="json hljs">global_defs {<font></font>
    notification_email {<font></font>
        admin@example.com<font></font>
    }<font></font>
    notification_email_from alarm@example.com<font></font>
    smtp_server mail.example.com<font></font>
    smtp_connect_timeout <span class="hljs-number">30</span><font></font>
<font></font>
    vrrp_garp_interval <span class="hljs-number">10</span>
    vrrp_garp_master_refresh <span class="hljs-number">30</span><font></font>
}<font></font>
<font></font>
#C   ,   .    , VIP .<font></font>
vrrp_script chk_gluster {<font></font>
    script <span class="hljs-attr">"pgrep glusterd"</span><font></font>
    interval 2<font></font>
}<font></font>
<font></font>
vrrp_instance gluster {<font></font>
    interface ens192<font></font>
    state MASTER #     BACKUP<font></font>
    priority 200 #      ,  100<font></font>
    virtual_router_id 1<font></font>
    virtual_ipaddress {<font></font>
        10.10.6.70/24<font></font>
    }<font></font>
<font></font>
    unicast_peer {<font></font>
        10.10.6.72 #        <font></font>
    }<font></font>
<font></font>
    track_script {<font></font>
        chk_gluster<font></font>
    }<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous pouvons maintenant démarrer le service et vérifier que le VIP sur le nœud apparaît:</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start keepalived<font></font>
$ systemctl <span class="hljs-built_in">enable</span> keepalived<font></font>
$ ip addr<font></font>
1: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000<font></font>
    link/ether 00:50:56:97:55:eb brd ff:ff:ff:ff:ff:ff<font></font>
    inet 10.10.6.72/24 brd 10.10.6.255 scope global noprefixroute ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
    inet 10.10.6.70/24 scope global secondary ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si tout a fonctionné pour nous, il reste à ajouter PersistentVolume à Kubernetes et à créer un service de test pour vérifier le fonctionnement.</font></font><br>
<br>
<pre><code class="python hljs">---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolume<font></font>
metadata:<font></font>
  name: gluster-nfs<font></font>
spec:<font></font>
  capacity:<font></font>
    storage: <span class="hljs-number">10</span>Gi<font></font>
  accessModes:<font></font>
    - ReadWriteMany<font></font>
  persistentVolumeReclaimPolicy: Retain<font></font>
  nfs:<font></font>
    server: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.70</span><font></font>
    path: /main<font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolumeClaim<font></font>
metadata:<font></font>
 name: gluster-nfs<font></font>
spec:<font></font>
 accessModes:<font></font>
 - ReadWriteMany<font></font>
 resources:<font></font>
   requests:<font></font>
     storage: <span class="hljs-number">10</span>Gi<font></font>
 volumeName: <span class="hljs-string">"gluster-nfs"</span><font></font>
<font></font>
---<font></font>
apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
  labels:<font></font>
    app: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        persistentVolumeClaim:<font></font>
          claimName: gluster-nfs<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec cette configuration, en cas de chute du noeud principal, il restera inactif pendant environ une minute jusqu'à ce que le montage tombe en timeout et passe. </font><font style="vertical-align: inherit;">Simple pendant une minute pour ce stockage, disons que ce n'est pas une situation régulière et nous le rencontrerons rarement, mais dans ce cas, le système basculera automatiquement et continuera de fonctionner, et nous serons en mesure de résoudre le problème et d'effectuer la récupération sans se soucier du simple.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sommaire</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans cet article, nous avons examiné 3 options possibles pour connecter GlusterFS à Kubernetes, dans notre version, il est possible d'ajouter un provisionneur à Kubernetes, mais nous n'en avons pas encore besoin. </font><font style="vertical-align: inherit;">Il reste à ajouter les résultats des tests de performances entre NFS et Gluster sur les mêmes nœuds. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fichiers sur 1 Mo:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1M count=1024; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 2.63496 s, 407 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 5.4527 s, 197 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fichiers sur 1 Ko:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1K count=1048576; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 70.0508 s, 15.3 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 6.95208 s, 154 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NFS fonctionne de la même manière pour n'importe quelle taille de fichier, la différence de vitesse n'est pas particulièrement perceptible, contrairement à GlusterFS, qui est très dégradé avec de petits fichiers. </font><font style="vertical-align: inherit;">Mais en même temps, avec des fichiers de grande taille, NFS affiche des performances 2 à 3 fois inférieures à Gluster.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr498146/index.html">Six tendances de sécurité intelligentes à surveiller</a></li>
<li><a href="../fr498150/index.html">Programmeurs plombiers, ou l'histoire d'une fuite et les difficultés à y faire face</a></li>
<li><a href="../fr498154/index.html">Calendrier des événements informatiques gratuits en ligne du 20 au 26 avril</a></li>
<li><a href="../fr498156/index.html">F #, morphologie des images binaires</a></li>
<li><a href="../fr498158/index.html">Remote Marathon Week 1: Lieu de travail</a></li>
<li><a href="../fr498162/index.html">Nous vous invitons à un stage informatique chez Alfa Bank</a></li>
<li><a href="../fr498164/index.html">Stratégies de produit pour les coûts de transition</a></li>
<li><a href="../fr498168/index.html">Nouvelles architectures de réseaux de neurones</a></li>
<li><a href="../fr498172/index.html">Java Digest du 21 avril</a></li>
<li><a href="../fr498174/index.html">Comment arrêter de s'inquiéter et commencer à croire aux tests A / B</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
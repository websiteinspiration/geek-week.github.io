<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’… ğŸ’º ğŸ˜ˆ BERT, ELMO e Co. em imagens (como o treinamento de transferÃªncia chegou Ã  PNL) ğŸº ğŸ˜ ğŸ¥‘</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O ano de 2018 foi um ponto de virada para o desenvolvimento de modelos de aprendizado de mÃ¡quina destinados a resolver problemas de processamento de t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>BERT, ELMO e Co. em imagens (como o treinamento de transferÃªncia chegou Ã  PNL)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487358/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O ano de 2018 foi um ponto de virada para o desenvolvimento de modelos de aprendizado de mÃ¡quina destinados a resolver problemas de processamento de texto (ou, mais corretamente, processamento de linguagem natural (PNL)). </font><font style="vertical-align: inherit;">Um entendimento conceitual de como apresentar palavras e frases para a extraÃ§Ã£o mais precisa de seus significados semÃ¢nticos e relacionamentos entre eles estÃ¡ crescendo rapidamente. </font><font style="vertical-align: inherit;">AlÃ©m disso, a comunidade da PNL promove ferramentas incrivelmente poderosas que podem ser baixadas e usadas gratuitamente em seus modelos e pipelines. </font><font style="vertical-align: inherit;">Esse ponto de inflexÃ£o tambÃ©m Ã© chamado </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de momento ImageNet da PNL</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , referindo-se ao momento de vÃ¡rios anos atrÃ¡s, quando desenvolvimentos semelhantes aceleraram significativamente o desenvolvimento de aprendizado de mÃ¡quina no campo de problemas de visÃ£o computacional.</font></font></p><br>
<p><img src="https://habrastorage.org/webt/uh/cd/qv/uhcdqv--w2t4i8srv9rtzjgk9ac.png" alt="transformador-ber-ulmfit-elmo"></p><br>
<p><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(O ULM-FiT nÃ£o tem nada a ver com Korzhik, mas algo melhor nÃ£o ocorreu)</font></font></em></p><a name="habracut"></a><br>
<p>        â€“  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">BERT'</a>, ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"> </a>    NLP. BERT â€“  ,        NLP-.    ,  ,                BERT',        .                    ,   ,   ,        .</p><br>
<p><img src="https://habrastorage.org/webt/pz/zk/xy/pzzkxyzmqf21r5rik00228zntwm.png" alt="bert-transfer-learning"></p><br>
<p><em> BERT'.  1:   (   );  2:   .</em></p><br>
<p>BERT      ,  NLP-, ,   : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Semi-supervised Sequence learning</a> ( â€“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Andrew Dai</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Quoc Le</a>), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">ELMo</a> ( â€“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Matthew Peters</a>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">AI2</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">UW CSE</a>), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">ULMFiT</a> ( â€“  fast.ai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Jeremy Howard</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Sebastian Ruder</a>), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">OpenAI Transformer</a> ( â€“  OpenAI <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Radford</a>, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Narasimhan</a>, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Salimans</a>,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Sutskever</a>)   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Vaswani et al</a>).</p><br>
<p>  ,     ,     BERT'.   ,     ,       .</p><br>
<h1 id="primer-klassifikaciya-predlozheniy">:  </h1><br>
<p>    BERT â€“    .      :</p><br>
<p><img src="https://habrastorage.org/webt/mx/eo/u_/mxeou__qytr_9_2m6pxjo2icemc.png" alt="Bert-classificaÃ§Ã£o-spam"></p><br>
<p>   ,   ,    (classifier)       BERT'    .       (fine-tuning),      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Semi-supervised Sequence Learning</a>   ULMFiT.</p><br>
<p> ,    :   ,         .        .               (Â«Â»  Â« Â»).</p><br>
<p><img src="https://habrastorage.org/webt/hy/qr/pa/hyqrpadlqytj81eqk3xtkyr3fcu.png" alt="conjunto de dados rotulado como spam"></p><br>
<p>   BERT':</p><br>
<ul>
<li><strong>  (sentiment analysis)</strong><br>
<ul>
<li>:   /. : / </li>
<li>  : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">SST</a></li>
</ul></li>
<li><strong>  (fact-checking)</strong>:<br>
<ul>
<li>: . : Â«Â» (Claim)  Â« Â» (Not Claim)</li>
<li> / :<br>
<ul>
<li>:    (Claim sentence). : Â«Â»  Â«Â»</li>
</ul></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Full Fact</a> â€“ ,      .     ,        ,      ( , , ,    )</li>
<li>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">     </a></li>
</ul></li>
</ul><br>
<h1 id="arhitektura-modeli"> </h1><br>
<p>,         BERT', ,   .</p><br>
<p><img src="https://habrastorage.org/webt/i3/u4/fq/i3u4fq9cclcq0-zeqfk56b5y78i.png" alt="bert-base-bert-grande"></p><br>
<p>     BERT'  :</p><br>
<ul>
<li>BERT BASE () â€“       OpenAI Transformer; </li>
<li>BERT LARGE () â€“   ,     (state of the art),   .</li>
</ul><br>
<p> , BERT â€“     . . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a>,      â€“   BERTâ€™   ,      .</p><br>
<p><img src="https://habrastorage.org/webt/6k/ce/se/6kcesezyar2zqppjc31sfkcsxak.png" alt="bert-base-bert-large-encoders"></p><br>
<p>   BERT'      (    Â« Â» (Transformer Blocks)): 12     24  .          (768  1024   )   Â«Â»  (attention heads)(12  16 ),     ,     (6  , 512  , 8 Â«Â» ).</p><br>
<h3 id="vhody-modeli"> </h3><br>
<p><img src="https://habrastorage.org/webt/ed/7k/go/ed7kgoai63syz-koc-_tlqs0gwk.png" alt="bert-entrada-saÃ­da"></p><br>
<p>        [CLS]  ,     . CLS     .</p><br>
<p>  ,     , BERT     ,       .       (self-attention)       ,      .</p><br>
<p><img src="https://habrastorage.org/webt/jp/kd/qs/jpkdqszmo06ogw7xbfk1tqmz0kw.png" alt="entrada-codificadores-bert"></p><br>
<p>   ,         (   ,    ).        .</p><br>
<h3 id="vyhody-modeli"> </h3><br>
<p>        hidden_size (768    BERT').    ,    ,       (      [CLS]).</p><br>
<p><img src="https://habrastorage.org/webt/at/9b/xe/at9bxefqh-vnkxlc-xkuxlgi13s.png" alt="vetor de saÃ­da de bert"></p><br>
<p>           .      ,          .</p><br>
<p><img src="https://habrastorage.org/webt/ee/lg/99/eelg99xutp6h7oztqyyz3hv-5e4.png" alt="classificador de bert"></p><br>
<p>       (,       Â«Â», Â« Â», Â« Â», Â«Â»  .),               .</p><br>
<h1 id="paralleli-so-svertochnymi-setyami">   </h1><br>
<p> ,     ,      ,        VGGNet     .</p><br>
<p><img src="https://habrastorage.org/webt/sl/37/yf/sl37yfo6xriqw24ule31ukksi8q.png" alt="vgg-net-classifier"></p><br>
<h1 id="novaya-era-embeddingov">  </h1><br>
<p>         .   ,    NLP-     ,   :        Word2Vec  GloVe.    ,    ,     ,  .</p><br>
<h3 id="kratkiy-obzor-mehanizma-embeddingov-slov">    </h3><br>
<p>              ,        . Word2Vec ,      ( ),     ,         (..                ,  Â«Â» â€“ Â«Â»  Â«Â» â€“ Â«Â»),       (, ,    Â«Â»  Â«Â»  ,   Â«Â»  Â«Â»).</p><br>
<p>  ,     ,     ,            .        ,      Word2Vec  GloVe.      GloVe   Â«stickÂ» (   â€“ 200):</p><br>
<p><img src="https://habrastorage.org/webt/l1/u-/ad/l1u-admk5irbjkb__sq90albkx0.png" alt="incorporaÃ§Ã£o de luvas"></p><br>
<p><em>  Â«stickÂ»   GloVe â€“   200     (  2   ).</em></p><br>
<p>                .</p><br>
<p><img src="https://habrastorage.org/webt/gz/ji/ee/gzjieex8v-pmouar89ocbbzan-e.png" alt="caixas de vetor"></p><br>
<h3 id="elmo-kontekst-imeet-znachenie">ELMo:   </h3><br>
<p>    GloVe,   Â«stickÂ»        . Â« Â», â€“   NLP- (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Peters et. al., 2017</a>, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">McCann et. al., 2017</a>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Peters et. al., 2018    ELMo</a>). â€“ Â« Â«stickÂ»       ,   .         ,     â€“  ,      ,    ?Â».     (contextualized word-embeddings).</p><br>
<p><img src="https://habrastorage.org/webt/jr/rt/hb/jrrthbwj9xdzd4vgs5ckjgayv0m.png" alt="elmo-embedding-robin-williams"></p><br>
<p><em>            .</em></p><br>
<p> ,     , ELMo    ,       .        (bi-directional LSTM),       .</p><br>
<p><img src="https://habrastorage.org/webt/bf/yw/qq/bfywqqcnnk6cw6hr3l3fbl-xq-i.png" alt="elmo-word-embedding"></p><br>
<p>ELMo         NLP.  ELMo LSTM          ,        ,     .</p><br>
<p>   ELMo?</p><br>
<p>   ELMo          â€“ ,    (language modeling).  ,        ,         .</p><br>
<p><img src="https://habrastorage.org/webt/mq/j1/bo/mqj1bozk08fff_cglqbdcatcuao.png" alt="Modelagem da linguagem Bert"></p><br>
<p><em>    ELMo:     Â«Let's stick toÂ»,        â€“   .            . ,         .  ,    , , , Â«hangÂ»,       Â«outÂ» (   Â«hang outÂ»),   Â«cameraÂ».</em></p><br>
<p>  ,      LSTM  -  ELMo.       ,       .</p><br>
<p>  , ELMo        LSTM â€“ ,    Â«Â»    ,    .</p><br>
<p><img src="https://habrastorage.org/webt/0w/re/y4/0wrey4vtsshgd7wcgvi_k_cguzk.png" alt="elmo-forward-backward-language-embedding-model"></p><br>
<p><em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"> </a>  ELMo</em></p><br>
<p>ELMo        (  )   (    ).</p><br>
<p><img src="https://habrastorage.org/webt/d8/dq/ch/d8dqchc0wxmoxmg2e79fnahk3ru.png" alt="elmo-incorporaÃ§Ã£o"></p><br>
<h1 id="ulm-fit-vnedryaya-transfernoe-obuchenie-v-nlp">ULM-FiT:     NLP</h1><br>
<p>ULM-FiT      ,        â€“       . ULM-FiT              .</p><br>
<p>NLP      , ,   ,       .</p><br>
<h1 id="transformer-vyhodya-za-predely-lstm-setey">:    LSTM </h1><br>
<p>   ,    ,   ,        ,     NLP-    LSTM.          .</p><br>
<p> -       .         ?         ,        (..     ,     )?</p><br>
<h1 id="openai-transformer-predvaritelnoe-obuchenie-dekodera-transformera-dlya-yazykovogo-modelirovaniya">OpenAI Transformer:       </h1><br>
<p> ,     ,          NLP-.        .    :    ,        (  ).</p><br>
<p><img src="https://habrastorage.org/webt/3p/-d/q3/3p-dq3wsky9bqnz6mdfv6-y-r2o.png" alt="transformador openai-1"></p><br>
<p><em>OpenAI Transformer     </em></p><br>
<p>   12  .          -  ,     . ,         (   ).</p><br>
<p>                :   ,     .    7       .       , ..          ,         â€“ ,   ,        .</p><br>
<p><img src="https://habrastorage.org/webt/8d/l0/4k/8dl04ko7gbfw9kiq_jlg5ve281w.png" alt="openai-transformador-linguagem-modelagem"></p><br>
<p><em>OpenAI Transformer             7000 </em></p><br>
<h1 id="transfernoe-obuchenie-v-prikladnyh-zadachah">    </h1><br>
<p>,  OpenAI Transformer           ,         .      (    Â«Â»   Â« Â»):</p><br>
<p><img src="https://habrastorage.org/webt/-l/fo/hr/-lfohrojznururmmrni-ykoqnog.png" alt="classificaÃ§Ã£o-sentenÃ§a-transformador-openai"></p><br>
<p>  OpenAI    ,        .               :</p><br>
<p><img src="https://habrastorage.org/webt/mb/aw/na/mbawnanchccikwp7z4hhe1n0tbi.png" alt="transformaÃ§Ãµes de entrada aberta"></p><br>
<p>,   ?</p><br>
<h1 id="bert-ot-dekoderov-k-enkoderam">BERT:    </h1><br>
<p>OpenAI Transformer      ,    .  -       LSTM  .   ELMo  ,  OpenAI Transformer    .         ,      ,    ( â€“ Â«   ,    Â»)?</p><br>
<blockquote>Â«  Â», â€“      .</blockquote><br>
<h3 id="maskirovannaya-yazykovaya-model-masked-language-model">   (masked language model)</h3><br>
<blockquote>Â«    Â», â€“  .<br>
Â« !Â» â€“  . â€“ Â« ,            .Â»<br>
Â«   Â», â€“   .</blockquote><p><img src="https://habrastorage.org/webt/z7/m-/qm/z7m-qmmtz724m8viviqejgzsmjs.png" alt="BERT-language-modeling-masked-lm"></p><br>
<p><em>    BERT  Â«Â»   15%          .</em></p><br>
<p>        â€“   ,  BERT ,    Â«  Â» (masked language model)     (   Â«-Â»).</p><br>
<p>  15%  , BERT      ,      .             .</p><br>
<h3 id="zadachi-dvuh-predlozheniy">  </h3><br>
<p>     OpenAI Transformer,   ,        -      (,       ?                ,       ?).</p><br>
<p> ,  BERT         ,     :    (  );  ,      ?</p><br>
<p><img src="https://habrastorage.org/webt/rz/hr/jf/rzhrjfq5iyequzyykq9tp0urdic.png" alt="previsÃ£o da prÃ³xima sentenÃ§a de bert"></p><br>
<p><em> ,   BERT    â€“     .     , .. BERT  WordPieces,       â€“        .</em></p><br>
<h3 id="modeli-dlya-konkretnyh-zadach">   </h3><br>
<p>   BERT'        .</p><br>
<p><img src="https://habrastorage.org/webt/03/8i/a7/038ia7qjndp3qhcz8pdkcd_14nw.png" alt="tarefas-bert"></p><br>
<p><em>a)    : MNLI, QQP, QNLI, STS-B, MRPC, RTE, SWAG; b)    : SST-2, CoLA; c) - : SQuAD v1.1; d)    : CoNLL-2003 NER.</em></p><br>
<h3 id="bert-dlya-izvlecheniya-priznakov">BERT   </h3><br>
<p>   â€“     BERT.      ELMo,     BERT'    .         â€“ ,          , , ,    (named-entity recognition).</p><br>
<p><img src="https://habrastorage.org/webt/ob/pa/a6/obpaa6snqryacqb9vbyaahue7zc.png" alt="bert-contextualized-embeddings"></p><br>
<p>       ?    .    6  (    ,   96,4):</p><br>
<p><img src="https://habrastorage.org/webt/ir/vr/sv/irvrsv9mefroz7io6ilnjng3fo4.png" alt="bert-feature-extract-contextualized-embeddings"></p><br>
<h1 id="test-drayv-berta">- BERT'</h1><br>
<p>   BERT   â€“   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">BERT FineTuning with Cloud TPUs</a>,   Google Colab.       Cloud TPU,    , ..  BERT'     TPU,    CPU  GPU.</p><br>
<p>  â€“     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"> BERT'</a>:</p><br>
<ul>
<li>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">modeling.py</a> (class BertModel)      .</li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">run_classifier.py</a> â€“    .         .       , .  create_model()   .</li>
<li>     ,     BERT'     ,    ,      102 .</li>
<li>BERT     .      WordPieces. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">tokenization.py</a> â€“ ,     WordPieces,   BERT'.</li>
</ul><br>
<p>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">PyTorch- BERT'</a>.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">AllenNLP</a>      BERT'a   .</p><br>
<h1 id="avtory"></h1><br>
<ul>
<li><strong> </strong> â€” <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Jay Alammar</a></li>
<li><strong></strong> â€” <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a></li>
<li><strong>  </strong> â€” <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a></li>
</ul></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt487340/index.html">Como fizemos no prÃ³ximo designer de chat bots. Parte 1</a></li>
<li><a href="../pt487342/index.html">LiÃ§Ã£o # 2 - ReuniÃµes e Eventos</a></li>
<li><a href="../pt487346/index.html">Casos para usar ferramentas de anÃ¡lise de anomalias de rede: detecÃ§Ã£o de vazamentos</a></li>
<li><a href="../pt487348/index.html">ClassificaÃ§Ã£o de tarefas prioritÃ¡rias - aplicativo IL TEMPO</a></li>
<li><a href="../pt487356/index.html">VocÃª vai mudar? Pense de novo</a></li>
<li><a href="../pt487360/index.html">O anonimato dos dados nÃ£o garante seu anonimato completo</a></li>
<li><a href="../pt487362/index.html">O Angular 9 jÃ¡ estÃ¡ disponÃ­vel - Ivy chegou</a></li>
<li><a href="../pt487366/index.html">State Panic: um olhar nÃ£o Ã³bvio para a epidemia de coronovÃ­rus 2019-nCoV</a></li>
<li><a href="../pt487368/index.html">Equipe de vendas hÃ­brida. As pessoas + a IA trabalham na mesma equipe</a></li>
<li><a href="../pt487370/index.html">AnÃ¡lise do mercado imobiliÃ¡rio com base em dados de msgr.ru</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
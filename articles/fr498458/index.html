<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔇 🤼 🍚 Appels vidéo avec arrière-plan virtuel et outils open source ♈️ 👩🏾‍🤝‍👩🏻 🔏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Maintenant que beaucoup d'entre nous sont mis en quarantaine en raison de COVID-19 , les appels vidéo sont devenus beaucoup plus fréquents qu'auparava...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Appels vidéo avec arrière-plan virtuel et outils open source</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/498458/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant que beaucoup d'entre nous sont </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mis</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> en </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">quarantaine en</font></a><font style="vertical-align: inherit;"> raison de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">COVID-19</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , les appels vidéo sont devenus beaucoup plus fréquents qu'auparavant. En particulier, le service </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ZOOM</font></font></a> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">soudainement</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> devenu très populaire. La fonction Zoom la plus intéressante est probablement la prise en charge de l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arrière-plan virtuel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Il permet aux utilisateurs de remplacer de manière interactive l'arrière-plan derrière eux par n'importe quelle image ou vidéo.</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><div style="text-align:center;"><img src="https://habrastorage.org/webt/wf/46/1p/wf461pvjwrwmpzvkvnhyvzcf8xy.jpeg"></div></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'utilise Zoom au travail depuis longtemps, lors de réunions open source sur Kubernetes, généralement à partir d'un ordinateur portable d'entreprise. Maintenant, lorsque je travaille à domicile, je suis enclin à utiliser un ordinateur de bureau personnel plus puissant et plus pratique pour résoudre certaines de mes tâches open source. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Malheureusement, Zoom prend uniquement en charge une méthode de suppression d'arrière-plan connue sous le nom de « </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">incrustation chroma</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> » ou « </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">écran vert</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ». Pour utiliser cette méthode, il est nécessaire que l'arrière-plan soit représenté par une couleur unie, idéalement verte, et soit uniformément éclairé. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme je n'ai pas d'écran vert, j'ai décidé de simplement implémenter mon propre système de suppression d'arrière-plan. Et cela, bien sûr, est bien mieux que de mettre de l'ordre dans l'appartement ou d'utiliser constamment un ordinateur portable de travail.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il s'est avéré qu'en utilisant des composants open source prêts à l'emploi et en écrivant quelques lignes de votre propre code, vous pouvez obtenir des résultats très décents.</font></font><br>
<a name="habracut"></a><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lecture des données de la caméra</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Commençons par le début et répondons à la question suivante: "Comment obtenir la vidéo d'une webcam que nous allons traiter?" </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme j'utilise Linux sur mon ordinateur personnel (quand je ne joue pas à des jeux), j'ai décidé d'utiliser les </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">liaisons </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Open CV </font></font></a><font style="vertical-align: inherit;"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">Python</font></a><font style="vertical-align: inherit;"> , que je connais déjà. </font><font style="vertical-align: inherit;">En plus des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">liaisons V4L2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour lire les données d'une webcam, elles incluent des fonctions de traitement vidéo de base utiles. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La lecture d'un cadre depuis une webcam en python-opencv est très simple:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> cv2<font></font>
cap = cv2.VideoCapture(<span class="hljs-string">'/dev/video0'</span>)<font></font>
success, frame = cap.read()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour améliorer les résultats lorsque je travaille avec ma caméra, j'ai appliqué les paramètres suivants avant d'en capturer la vidéo:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#    720p @ 60 FPS</span>
height, width = <span class="hljs-number">720</span>, <span class="hljs-number">1280</span><font></font>
cap.set(cv2.CAP_PROP_FRAME_WIDTH ,width)<font></font>
cap.set(cv2.CAP_PROP_FRAME_HEIGHT,height)<font></font>
cap.set(cv2.CAP_PROP_FPS, <span class="hljs-number">60</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On a le sentiment que la plupart des programmes de visioconférence limitent la vidéo à 720p @ 30 FPS ou moins. </font><font style="vertical-align: inherit;">Mais nous, dans tous les cas, ne lisons pas toutes les images. </font><font style="vertical-align: inherit;">Ces paramètres définissent la limite supérieure. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mettez le mécanisme de capture d'image dans une boucle. </font><font style="vertical-align: inherit;">Maintenant, nous avons accès au flux vidéo de la caméra!</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;success, frame = cap.read()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez enregistrer le cadre à des fins de test comme suit:</font></font><br>
<br>
<pre><code class="python hljs">cv2.imwrite(<span class="hljs-string">"test.jpg"</span>, frame)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après cela, nous pouvons nous assurer que la caméra fonctionne. </font><font style="vertical-align: inherit;">Génial!</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/96c/1ea/155/96c1ea155c714c5f1c8ab70f737444f8.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'espère que tu n'es pas contre ma barbe</font></font></font></i><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Détection d'arrière-plan</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant que nous avons accès au flux vidéo, nous allons réfléchir à la façon de détecter l'arrière-plan en permettant de le remplacer en le trouvant. Mais c'est déjà une tâche assez difficile. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien qu'il y ait un sentiment que les créateurs de Zoom ne parlent jamais exactement de la façon dont le programme supprime l'arrière-plan, la façon dont le système se comporte me fait penser à ce qui aurait pu se passer des réseaux de neurones. C'est difficile à expliquer, mais les résultats ressemblent exactement à ça. En outre, j'ai trouvé un article sur la façon dont </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Microsoft Teams</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> implémente le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">flou d'arrière-plan à l'</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aide d'un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réseau neuronal convolutionnel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En principe, la création de votre propre réseau de neurones n'est pas si difficile. Il existe de nombreux articles et articles scientifiques sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la segmentation d'images.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Il existe de nombreuses bibliothèques et outils open source. Mais nous avons besoin d'un ensemble de données très spécialisé pour obtenir de bons résultats. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En particulier, nous avons besoin de beaucoup d'images ressemblant à celles obtenues à partir d'une webcam, avec une image parfaite d'une personne au premier plan. Chaque pixel d'une telle image doit être marqué comme différent de l'arrière-plan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La construction d'un tel ensemble de données en préparation de la formation d'un réseau neuronal peut ne pas nécessiter beaucoup d'efforts. Cela est dû au fait que l'équipe de chercheurs de Google a déjà fait tout son possible et a mis en open source un réseau neuronal pré-formé pour segmenter les gens. Ce réseau s'appelle </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BodyPix</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Il fonctionne très bien! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BodyPix n'est désormais disponible que sous une forme adaptée à </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TensorFlow.js</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Par conséquent, il est plus facile d'appliquer à l'aide de la bibliothèque </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">body-pix-node</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour accélérer la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sortie réseau</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (prévisions) dans le navigateur, il est préférable d'utiliser le </font><font style="vertical-align: inherit;">backend </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WebGL</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , mais dans l'environnement </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Node.js</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">vous pouvez utiliser le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">backend Tensorflow GPU</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (notez que cela nécessitera une carte vidéo de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que j'ai). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Afin de simplifier la configuration du projet, nous utiliserons un petit environnement conteneurisé qui fournit le GPU TensorFlow et Node.js. Tout utiliser avec </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nvidia-docker</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- beaucoup plus facile que de collecter vous-même les dépendances nécessaires sur votre ordinateur. </font><font style="vertical-align: inherit;">Pour ce faire, vous n'avez besoin que de Docker et des derniers pilotes graphiques sur votre ordinateur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici le contenu du fichier </font></font><code>bodypix/package.json</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="json hljs">{
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"name"</span>: <span class="hljs-string">"bodypix"</span>,
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"version"</span>: <span class="hljs-string">"0.0.1"</span>,
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"dependencies"</span>: {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"@tensorflow-models/body-pix"</span>: <span class="hljs-string">"^2.0.5"</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"@tensorflow/tfjs-node-gpu"</span>: <span class="hljs-string">"^1.7.1"</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;}<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici le dossier </font></font><code>bodypix/Dockerfile</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#  ,   TensorFlow GPU</span>
FROM nvcr.io/nvidia/cuda:<span class="hljs-number">10.0</span>-cudnn7-runtime-ubuntu18<span class="hljs-number">.04</span>
<span class="hljs-comment">#  node</span><font></font>
RUN apt update &amp;&amp; apt install -y curl make build-essential \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; curl -sL https://deb.nodesource.com/setup_12.x | bash - \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; apt-get -y install nodejs \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; mkdir /.npm \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; chmod <span class="hljs-number">777</span> /.npm
<span class="hljs-comment"># ,    &nbsp;</span>
<span class="hljs-comment">#   tfjs-node-gpu      GPU :(</span><font></font>
ENV TF_FORCE_GPU_ALLOW_GROWTH=true<font></font>
<span class="hljs-comment">#  node-</span><font></font>
WORKDIR /src<font></font>
COPY package.json /src/<font></font>
RUN npm install<font></font>
<span class="hljs-comment">#      </span><font></font>
COPY app.js /src/<font></font>
ENTRYPOINT node /src/app.js<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parlons maintenant de l'obtention de résultats. </font><font style="vertical-align: inherit;">Mais je vous préviens tout de suite: je ne suis pas un expert Node.js! </font><font style="vertical-align: inherit;">Ce n'est que le résultat de mes expériences du soir, alors soyez indulgents avec moi :-). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le script simple suivant est occupé à traiter une image de masque binaire envoyée au serveur à l'aide d'une requête HTTP POST. </font><font style="vertical-align: inherit;">Un masque est un tableau bidimensionnel de pixels. </font><font style="vertical-align: inherit;">Les pixels représentés par des zéros sont l'arrière-plan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici le code du fichier </font></font><code>app.js</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="javascript hljs"><span class="hljs-keyword">const</span> tf = <span class="hljs-built_in">require</span>(<span class="hljs-string">'@tensorflow/tfjs-node-gpu'</span>);
<span class="hljs-keyword">const</span> bodyPix = <span class="hljs-built_in">require</span>(<span class="hljs-string">'@tensorflow-models/body-pix'</span>);
<span class="hljs-keyword">const</span> http = <span class="hljs-built_in">require</span>(<span class="hljs-string">'http'</span>);
<span class="hljs-function">(<span class="hljs-params"><span class="hljs-keyword">async</span> (</span>) =&gt;</span> {
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">const</span> net = <span class="hljs-keyword">await</span> bodyPix.load({
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">architecture</span>: <span class="hljs-string">'MobileNetV1'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">outputStride</span>: <span class="hljs-number">16</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">multiplier</span>: <span class="hljs-number">0.75</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">quantBytes</span>: <span class="hljs-number">2</span>,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">const</span> server = http.createServer();<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;server.on(<span class="hljs-string">'request'</span>, <span class="hljs-keyword">async</span> (req, res) =&gt; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">var</span> chunks = [];<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;req.on(<span class="hljs-string">'data'</span>, (chunk) =&gt; {<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chunks.push(chunk);<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;req.on(<span class="hljs-string">'end'</span>, <span class="hljs-keyword">async</span> () =&gt; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">const</span> image = tf.node.decodeImage(Buffer.concat(chunks));<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;segmentation = <span class="hljs-keyword">await</span> net.segmentPerson(image, {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">flipHorizontal</span>: <span class="hljs-literal">false</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">internalResolution</span>: <span class="hljs-string">'medium'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">segmentationThreshold</span>: <span class="hljs-number">0.7</span>,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.writeHead(<span class="hljs-number">200</span>, { <span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/octet-stream'</span> });<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.write(Buffer.from(segmentation.data));<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.end();<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tf.dispose(image);<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;server.listen(<span class="hljs-number">9000</span>);<font></font>
})();<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour convertir un cadre en masque, nous pouvons, dans un script Python, utiliser le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">paquet numpy</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">request</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_mask</span>(<span class="hljs-params">frame, bodypix_url=<span class="hljs-string">'http://localhost:9000'</span></span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;_, data = cv2.imencode(<span class="hljs-string">".jpg"</span>, frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;r = requests.post(<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;url=bodypix_url,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data=data.tobytes(),<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;headers={<span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/octet-stream'</span>})
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     numpy-</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     uint8[width * height]   0  1</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = np.frombuffer(r.content, dtype=np.uint8)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = mask.reshape((frame.shape[<span class="hljs-number">0</span>], frame.shape[<span class="hljs-number">1</span>]))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le résultat est approximativement le suivant.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e51/7db/e3c/e517dbe3ce6eee99d646a8e4257a627f.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Masque</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pendant que je faisais tout cela, je suis tombé sur le</font><font style="vertical-align: inherit;">tweet</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> suivant</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5a5/c4b/4dd/5a5c4b4dda480f0fa58807ec5b89b457.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est certainement le meilleur fond pour les appels vidéo.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Maintenant que nous avons un masque pour séparer le premier plan de l'arrière-plan, remplacer l'arrière-plan par quelque chose d'autre sera très simple. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'ai pris l'image d'arrière-plan de la branche de tweet et je l'ai coupée pour obtenir une image 16x9.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/900/311/537/900311537df81d74a682ddfd447a85a5.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Image d'arrière-plan</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Après cela, j'ai fait ce qui suit:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#    (     16:9)</span>
replacement_bg_raw = cv2.imread(<span class="hljs-string">"background.jpg"</span>)<font></font>
<font></font>
<span class="hljs-comment">#    ,       (width &amp; height   )</span>
width, height = <span class="hljs-number">720</span>, <span class="hljs-number">1280</span><font></font>
replacement_bg = cv2.resize(replacement_bg_raw, (width, height))<font></font>
<font></font>
<span class="hljs-comment">#     ,   </span>
inv_mask = <span class="hljs-number">1</span>-mask
<span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> range(frame.shape[<span class="hljs-number">2</span>]):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame[:,:,c] = frame[:,:,c]*mask + replacement_bg[:,:,c]*inv_mask<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'est ce que j'ai obtenu après ça.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/500/fbf/e3b/500fbfe3ba3753878562533ced87ed69.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le résultat du remplacement de l'arrière-plan.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Un tel masque n'est évidemment pas assez précis, la raison en est les compromis de performance que nous avons faits lors de la configuration de BodyPix. </font><font style="vertical-align: inherit;">En général, alors que tout semble plus ou moins tolérant. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais, quand j'ai regardé ce contexte, une idée m'est venue.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Expériences intéressantes</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant que nous avons compris comment masquer, nous allons demander comment améliorer le résultat. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La première étape évidente consiste à adoucir les bords du masque. </font><font style="vertical-align: inherit;">Par exemple, cela peut être fait comme ceci:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post_process_mask</span>(<span class="hljs-params">mask</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.dilate(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.erode(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cela améliorera un peu la situation, mais il n'y a pas beaucoup de progrès. </font><font style="vertical-align: inherit;">Et un simple remplacement est assez ennuyeux. </font><font style="vertical-align: inherit;">Mais, puisque nous sommes arrivés à tout cela nous-mêmes, cela signifie que nous pouvons tout faire avec l'image, et pas seulement supprimer l'arrière-plan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Étant donné que nous utilisons un arrière-plan virtuel de Star Wars, j'ai décidé de créer un effet hologramme afin de rendre l'image plus intéressante. </font><font style="vertical-align: inherit;">De plus, cela vous permet de lisser le flou du masque. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tout d'abord, mettez à jour le code de post-traitement:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post_process_mask</span>(<span class="hljs-params">mask</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.dilate(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.blur(mask.astype(float), (<span class="hljs-number">30</span>,<span class="hljs-number">30</span>))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les bords sont maintenant flous. </font><font style="vertical-align: inherit;">C'est bien, mais nous devons encore créer un effet hologramme. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les hologrammes hollywoodiens ont généralement les propriétés suivantes:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une image pâle ou monochrome - comme si elle était dessinée par un laser brillant.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un effet qui rappelle les lignes de balayage ou quelque chose comme une grille - comme si l'image était affichée en plusieurs rayons.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«Effet fantôme» - comme si la projection était effectuée en couches ou comme si la distance correcte à laquelle elle devait être affichée ne serait pas maintenue lors de la création de la projection.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tous ces effets peuvent être implémentés étape par étape. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tout d'abord, pour colorer l'image dans une nuance de bleu, nous pouvons utiliser la méthode </font></font><code>applyColorMap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#     -  </span><font></font>
holo = cv2.applyColorMap(frame, cv2.COLORMAP_WINTER)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite - ajoutez une ligne de balayage avec un effet rappelant de laisser en demi-teinte:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#    bandLength    10-30%,</span>
<span class="hljs-comment">#    bandGap.</span>
bandLength, bandGap = <span class="hljs-number">2</span>, <span class="hljs-number">3</span>
<span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(holo.shape[<span class="hljs-number">0</span>]):
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> y % (bandLength+bandGap) &lt; bandLength:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;holo[y,:,:] = holo[y,:,:] * np.random.uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, nous implémentons «l'effet fantôme» en ajoutant des copies pondérées décalées de l'effet actuel à l'image:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># shift_img : https://stackoverflow.com/a/53140617</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shift_img</span>(<span class="hljs-params">img, dx, dy</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dy, axis=<span class="hljs-number">0</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dx, axis=<span class="hljs-number">1</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dy&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:dy, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dy&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[dy:, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dx&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, :dx] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dx&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, dx:] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> img<font></font>
<font></font>
<span class="hljs-comment">#    : holo * 0.2 + shifted_holo * 0.8 + 0</span>
holo2 = cv2.addWeighted(holo, <span class="hljs-number">0.2</span>, shift_img(holo1.copy(), <span class="hljs-number">5</span>, <span class="hljs-number">5</span>), <span class="hljs-number">0.8</span>, <span class="hljs-number">0</span>)<font></font>
holo2 = cv2.addWeighted(holo2, <span class="hljs-number">0.4</span>, shift_img(holo1.copy(), <span class="hljs-number">-5</span>, <span class="hljs-number">-5</span>), <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et enfin, nous voulons conserver certaines des couleurs d'origine, nous combinons donc l'effet holographique avec le cadre d'origine, en faisant quelque chose de similaire à l'ajout de «l'effet fantôme»:</font></font><br>
<br>
<pre><code class="python hljs">holo_done = cv2.addWeighted(img, <span class="hljs-number">0.5</span>, holo2, <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici à quoi ressemble un cadre avec un effet hologramme:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8ba/bda/21c/8babda21c3f11e9fa3867faf65e14c24.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un cadre avec un effet hologramme</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ce cadre lui-même semble assez bon. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essayons maintenant de le combiner avec l'arrière-plan.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/297/7b7/ce4/2977b7ce4f9efdedd6632ffb0a3ad621.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Image superposée sur le fond.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Terminé! </font><font style="vertical-align: inherit;">(Je promets - ce genre de vidéo sera plus intéressant).</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sortie vidéo</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et maintenant, je dois dire que nous avons manqué quelque chose ici. </font><font style="vertical-align: inherit;">Le fait est que nous ne pouvons toujours pas utiliser tout cela pour passer des appels vidéo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Afin de résoudre ce problème, nous utiliserons </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pyfakewebcam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v4l2loopback</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour créer une webcam factice. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, nous prévoyons de connecter cette caméra au Docker. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Créez d'abord un fichier de </font></font><code>fakecam/requirements.txt</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">description des dépendances:</font></font><br>
<br>
<pre><code class="python hljs">numpy==<span class="hljs-number">1.18</span><span class="hljs-number">.2</span>
opencv-python==<span class="hljs-number">4.2</span><span class="hljs-number">.0</span><span class="hljs-number">.32</span>
requests==<span class="hljs-number">2.23</span><span class="hljs-number">.0</span>
pyfakewebcam==<span class="hljs-number">0.1</span><span class="hljs-number">.0</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Créez maintenant un fichier </font></font><code>fakecam/Dockerfile</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour l'application qui implémente les capacités d'une caméra factice:</font></font><br>
<br>
<pre><code class="python hljs">FROM python:<span class="hljs-number">3</span>-buster
<span class="hljs-comment">#   pip</span><font></font>
RUN pip install --upgrade pip<font></font>
<span class="hljs-comment">#   opencv</span><font></font>
RUN apt-get update &amp;&amp; \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;apt-get install -y \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`<span class="hljs-comment"># opencv requirements` \</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;libsm6 libxext6 libxrender-dev \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`<span class="hljs-comment"># opencv video opening requirements` \</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;libv4l-dev<font></font>
<span class="hljs-comment">#    requirements.txt</span><font></font>
WORKDIR /src<font></font>
COPY requirements.txt /src/<font></font>
RUN pip install --no-cache-dir -r /src/requirements.txt<font></font>
<span class="hljs-comment">#   </span><font></font>
COPY background.jpg /data/<font></font>
<span class="hljs-comment">#     (     )</span><font></font>
COPY fake.py /src/<font></font>
ENTRYPOINT python -u fake.py<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, à partir de la ligne de commande, installez v4l2loopback:</font></font><br>
<br>
<pre><code class="bash hljs">sudo apt install v4l2loopback-dkms
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Configurer une caméra factice:</font></font><br>
<br>
<pre><code class="python hljs">sudo modprobe -r v4l2loopback<font></font>
sudo modprobe v4l2loopback devices=<span class="hljs-number">1</span> video_nr=<span class="hljs-number">20</span> card_label=<span class="hljs-string">"v4l2loopback"</span> exclusive_caps=<span class="hljs-number">1</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour garantir la fonctionnalité de certaines applications (Chrome, Zoom), nous avons besoin d'un paramètre </font></font><code>exclusive_caps</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">La marque </font></font><code>card_label</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est définie uniquement pour garantir la commodité du choix d'un appareil photo dans les applications. </font><font style="vertical-align: inherit;">L'indication du numéro </font></font><code>video_nr=20</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conduit à la création de l'appareil </font></font><code>/dev/video20</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">si le numéro correspondant n'est pas occupé, et il est peu probable qu'il soit occupé. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous allons maintenant modifier le script pour créer une caméra factice:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># ,  ,   ,   ,  width  height</span>
fake = pyfakewebcam.FakeWebcam(<span class="hljs-string">'/dev/video20'</span>, width, height)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient de noter que pyfakewebcam attend des images avec des canaux RVB (rouge, vert, bleu - rouge, vert, bleu), et Open CV fonctionne avec l'ordre des canaux BGR (bleu, vert, rouge). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez résoudre ce problème avant de sortir le cadre, puis envoyer le cadre comme ceci:</font></font><br>
<br>
<pre><code class="python hljs">frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<font></font>
fake.schedule_frame(frame)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici le code de script complet </font></font><code>fakecam/fake.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> pyfakewebcam<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_mask</span>(<span class="hljs-params">frame, bodypix_url=<span class="hljs-string">'http://localhost:9000'</span></span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;_, data = cv2.imencode(<span class="hljs-string">".jpg"</span>, frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;r = requests.post(<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;url=bodypix_url,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data=data.tobytes(),<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;headers={<span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/octet-stream'</span>})<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = np.frombuffer(r.content, dtype=np.uint8)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = mask.reshape((frame.shape[<span class="hljs-number">0</span>], frame.shape[<span class="hljs-number">1</span>]))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post_process_mask</span>(<span class="hljs-params">mask</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.dilate(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.blur(mask.astype(float), (<span class="hljs-number">30</span>,<span class="hljs-number">30</span>))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shift_image</span>(<span class="hljs-params">img, dx, dy</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dy, axis=<span class="hljs-number">0</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dx, axis=<span class="hljs-number">1</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dy&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:dy, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dy&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[dy:, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dx&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, :dx] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dx&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, dx:] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> img<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hologram_effect</span>(<span class="hljs-params">img</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#    </span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;holo = cv2.applyColorMap(img, cv2.COLORMAP_WINTER)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#   </span>
&nbsp;&nbsp;&nbsp;&nbsp;bandLength, bandGap = <span class="hljs-number">2</span>, <span class="hljs-number">3</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(holo.shape[<span class="hljs-number">0</span>]):
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> y % (bandLength+bandGap) &lt; bandLength:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;holo[y,:,:] = holo[y,:,:] * np.random.uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#  </span>
&nbsp;&nbsp;&nbsp;&nbsp;holo_blur = cv2.addWeighted(holo, <span class="hljs-number">0.2</span>, shift_image(holo.copy(), <span class="hljs-number">5</span>, <span class="hljs-number">5</span>), <span class="hljs-number">0.8</span>, <span class="hljs-number">0</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;holo_blur = cv2.addWeighted(holo_blur, <span class="hljs-number">0.4</span>, shift_image(holo.copy(), <span class="hljs-number">-5</span>, <span class="hljs-number">-5</span>), <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     </span>
&nbsp;&nbsp;&nbsp;&nbsp;out = cv2.addWeighted(img, <span class="hljs-number">0.5</span>, holo_blur, <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> out<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_frame</span>(<span class="hljs-params">cap, background_scaled</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;_, frame = cap.read()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#      (  ,   )</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#       </span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = <span class="hljs-literal">None</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">while</span> mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">try</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask = get_mask(frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">except</span> requests.RequestException:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<span class="hljs-string">"mask request failed, retrying"</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment"># -   </span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = post_process_mask(mask)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame = hologram_effect(frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     </span>
&nbsp;&nbsp;&nbsp;&nbsp;inv_mask = <span class="hljs-number">1</span>-mask
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> range(frame.shape[<span class="hljs-number">2</span>]):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;frame[:,:,c] = frame[:,:,c]*mask + background_scaled[:,:,c]*inv_mask<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> frame<font></font>
<font></font>
<span class="hljs-comment">#     </span>
cap = cv2.VideoCapture(<span class="hljs-string">'/dev/video0'</span>)<font></font>
height, width = <span class="hljs-number">720</span>, <span class="hljs-number">1280</span><font></font>
cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)<font></font>
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)<font></font>
cap.set(cv2.CAP_PROP_FPS, <span class="hljs-number">60</span>)<font></font>
<font></font>
<span class="hljs-comment">#   </span>
fake = pyfakewebcam.FakeWebcam(<span class="hljs-string">'/dev/video20'</span>, width, height)<font></font>
<font></font>
<span class="hljs-comment">#    </span>
background = cv2.imread(<span class="hljs-string">"/data/background.jpg"</span>)<font></font>
background_scaled = cv2.resize(background, (width, height))<font></font>
<font></font>
<span class="hljs-comment">#    </span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame = get_frame(cap, background_scaled)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#    RGB-</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;fake.schedule_frame(frame)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, rassemblez les images:</font></font><br>
<br>
<pre><code class="python hljs">docker build -t bodypix ./bodypix<font></font>
docker build -t fakecam ./fakecam<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exécutez-les:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span><font></font>
docker network create --driver bridge fakecam<font></font>
<span class="hljs-comment">#   bodypix</span><font></font>
docker run -d \<font></font>
&nbsp;&nbsp;--name=bodypix \<font></font>
&nbsp;&nbsp;--network=fakecam \<font></font>
&nbsp;&nbsp;--gpus=all --shm-size=<span class="hljs-number">1</span>g --ulimit memlock=<span class="hljs-number">-1</span> --ulimit stack=<span class="hljs-number">67108864</span> \<font></font>
&nbsp;&nbsp;bodypix<font></font>
<span class="hljs-comment">#  ,  ,      ,  ,</span>
<span class="hljs-comment">#           </span>
<span class="hljs-comment"># ,     `sudo groupadd $USER video`</span><font></font>
docker run -d \<font></font>
&nbsp;&nbsp;--name=fakecam \<font></font>
&nbsp;&nbsp;--network=fakecam \<font></font>
&nbsp;&nbsp;-p <span class="hljs-number">8080</span>:<span class="hljs-number">8080</span> \<font></font>
&nbsp;&nbsp;-u <span class="hljs-string">"$$(id -u):$$(getent group video | cut -d: -f3)"</span> \<font></font>
&nbsp;&nbsp;$$(find /dev -name <span class="hljs-string">'video*'</span> -printf <span class="hljs-string">"--device %p "</span>) \<font></font>
&nbsp;&nbsp;fakecam<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il ne reste plus qu'à considérer que cela doit être démarré avant l'ouverture de la caméra lorsque vous travaillez avec des applications. </font><font style="vertical-align: inherit;">Et dans Zoom ou ailleurs, vous devez sélectionner une caméra </font></font><code>v4l2loopback</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">/ </font></font><code>/dev/video20</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sommaire</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici un clip qui montre les résultats de mon travail.</font></font><br>
<br>
<div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Votre navigateur ne prend pas en charge la vidéo HTML5.</font></font><source src="https://elder.dev/posts/open-source-virtual-background/holo-demo.webm" type="video/webm"></video></div></div></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Résultat du changement de fond</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Voir! </font><font style="vertical-align: inherit;">J'appelle depuis le Millennium Falcon en utilisant la pile de technologies open source pour travailler avec la caméra! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ce que j'ai fait, j'ai vraiment aimé. </font><font style="vertical-align: inherit;">Et je vais certainement profiter de tout cela lors de la prochaine vidéoconférence. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chers lecteurs! </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Envisagez-vous de changer ce qui est visible pendant les appels vidéo derrière vous pour autre chose?</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/iq/fi/b4/iqfib45pgphfrxv--zfemt0qnmw.jpeg"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr498446/index.html">Questions d'emploi: stabilité imaginaire, fausse dévotion et positionnement</a></li>
<li><a href="../fr498450/index.html">Redondance MultiSim - qu'est-ce que c'est et comment ça marche</a></li>
<li><a href="../fr498452/index.html">Django: un guide rapide sur l'internationalisation</a></li>
<li><a href="../fr498454/index.html">Contes des développeurs de vos jeux préférés sur ce dont ils sont fiers</a></li>
<li><a href="../fr498456/index.html">Pratique de capture de défilement CSS</a></li>
<li><a href="../fr498462/index.html">Défilement infini avec des bannières, ou comment faire avec trois vues</a></li>
<li><a href="../fr498466/index.html">Comment les lasers et les capteurs aident à garder les juges nerveux</a></li>
<li><a href="../fr498472/index.html">Image Docker d'une seule page</a></li>
<li><a href="../fr498476/index.html">Accessibilité Comment rendre l'application accessible aux utilisateurs handicapés</a></li>
<li><a href="../fr498478/index.html">Qu'est-ce que Windows PowerShell et que mange-t-il? Partie 5: Accès aux objets externes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
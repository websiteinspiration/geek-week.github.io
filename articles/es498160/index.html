<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏜️ 👨🏼‍🤝‍👨🏻 ⚱️ GlusterFS como almacenamiento externo para Kubernetes 💪🏾 👨🏻‍⚕️ 🕴🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Encontrar el almacenamiento óptimo es un proceso bastante complicado, todo tiene sus ventajas y desventajas. Por supuesto, el líder en esta categoría ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>GlusterFS como almacenamiento externo para Kubernetes</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498160/"><img src="https://portworx.com/wp-content/uploads/2018/10/Twitter-Social-Graphic-68.png" alt="imagen"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Encontrar el almacenamiento óptimo es un proceso bastante complicado, todo tiene sus ventajas y desventajas. </font><font style="vertical-align: inherit;">Por supuesto, el líder en esta categoría es CEPH, pero es un sistema bastante complejo, aunque con una funcionalidad muy rica. </font><font style="vertical-align: inherit;">Para nosotros, dicho sistema es redundante, dado que necesitábamos un almacenamiento replicado simple en modo maestro-maestro para un par de terabytes. </font><font style="vertical-align: inherit;">Habiendo estudiado mucho material, se decidió probar el producto más moderno del mercado para el circuito que nos interesa. </font><font style="vertical-align: inherit;">Debido al hecho de que no se encontró una solución preparada de dicho plan, me gustaría compartir mis mejores prácticas sobre este tema y describir los problemas que encontramos en el proceso de implementación.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Metas</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¿Qué esperábamos del nuevo repositorio:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Capacidad para trabajar con un número par de nodos para la replicación.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fácil instalación, configuración, soporte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El sistema debe ser adulto, probado y usuarios.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Capacidad para ampliar el espacio de almacenamiento sin tiempo de inactividad</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El almacenamiento debe ser compatible con Kubernetes</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Debería haber una conmutación por error automática cuando uno de los nodos falla</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sobre el último punto tenemos muchas preguntas.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Despliegue</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para la implementación, se crearon dos máquinas virtuales en CentOs 8. Cada una de ellas está conectada a través de un disco adicional con almacenamiento.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparación preliminar</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para GlusterFS, debe asignar un disco separado con XFS para que no afecte al sistema de ninguna manera. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seleccione la partición:</font></font><br>
<br>
<pre><code class="bash hljs">$ fdisk /dev/sdb<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): n<font></font>
Partition <span class="hljs-built_in">type</span><font></font>
   p   primary (0 primary, 0 extended, 4 free)<font></font>
   e   extended (container <span class="hljs-keyword">for</span> logical partitions)<font></font>
Select (default p): p<font></font>
Partition number (1-4, default 1):  1<font></font>
First sector (2048-16777215, default 2048): <font></font>
Last sector, +sectors or +size{K,M,G,T,P} (2048-16777215, default 16777215): <font></font>
&nbsp;<font></font>
Created a new partition 1 of <span class="hljs-built_in">type</span> ‘Linux’ and of size 8 GiB.<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): w <font></font>
<font></font>
The partition table has been altered.<font></font>
Calling ioctl() to re-read partition table. Syncing disks.<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Formatear en XFS y montar:</font></font><br>
<br>
<pre><code class="bash hljs">$ mkfs.xfs /dev/sdb1<font></font>
$ mkdir /gluster<font></font>
$ mount /dev/sdb1 /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y para colmo, suelte la entrada en / etc / fstab para montar automáticamente el directorio al inicio del sistema:</font></font><br>
<br>
<pre><code class="bash hljs">/dev/sdb1       /gluster        xfs     defaults        0       0</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instalación</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Con respecto a la instalación, se han escrito muchos artículos, en este sentido no profundizaremos en el proceso, solo consideraremos a qué vale la pena prestarle atención. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En ambos nodos, instale y ejecute la última versión de glusterfs:</font></font><br>
<br>
<pre><code class="bash hljs">$ wget -P /etc/yum.repos.d  https://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-rhel8.repo<font></font>
$ yum -y install yum-utils<font></font>
$ yum-config-manager --<span class="hljs-built_in">enable</span> PowerTools<font></font>
$ yum install -y glusterfs-server<font></font>
$ systemctl start glusterd<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A continuación, debe decirle al glaster dónde está su nodo vecino. </font><font style="vertical-align: inherit;">Se realiza con un solo nodo. </font><font style="vertical-align: inherit;">Un punto importante: si tiene una red de dominio, debe especificar el nombre del servidor con el dominio, de lo contrario en el futuro tendrá que rehacer todo.</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer probe gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si fue exitoso, entonces verificamos la conexión con el comando desde ambos servidores:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer status<font></font>
Number of Peers: 1<font></font>
<font></font>
Hostname: gluster-02.example.com<font></font>
Uuid: a6de3b23-ee31-4394-8bff-0bd97bd54f46<font></font>
State: Peer <span class="hljs-keyword">in</span> Cluster (Connected)<font></font>
Other names:<font></font>
10.10.6.72<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora puede crear un Volumen en el que escribiremos.</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume create main replica 2 gluster-01.example.com:/gluster/main gluster-02.example.com:/gluster/main force</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dónde:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">main - nombre Volumen </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réplica - escriba Volumen (se pueden encontrar más detalles en la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documentación oficial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 - número de réplicas </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ejecute Volume y verifique su rendimiento:</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume start main<font></font>
gluster volume status main</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para el volumen replicado, se recomienda establecer los siguientes parámetros:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster volume <span class="hljs-built_in">set</span> main network.ping-timeout 5<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-type fixed<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-count 1<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main performance.quick-read on</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Con estos simples pasos, hemos creado un clúster GlusterFS. </font><font style="vertical-align: inherit;">Queda por conectarse y verificar el rendimiento. </font><font style="vertical-align: inherit;">Ubuntu está instalado en la máquina del cliente, para el montaje necesita instalar el cliente:</font></font><br>
<br>
<pre><code class="bash hljs">$ add-apt-repository ppa:gluster/glusterfs-7<font></font>
$ apt install glusterfs-client<font></font>
$ mkdir /gluster<font></font>
$ mount.glusterfs gluster-01.example.com:/main /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gluster, cuando está conectado a uno de los nodos, proporciona las direcciones de todos los nodos y se conecta automáticamente a todos. </font><font style="vertical-align: inherit;">Si el cliente ya se ha conectado, la falla de uno de los nodos no llevará a un alto. </font><font style="vertical-align: inherit;">Pero si el primer nodo no está disponible, no será posible conectarse en caso de interrupción de la sesión. </font><font style="vertical-align: inherit;">Para hacer esto, al montar, puede pasar el parámetro backupvolfile que indica el segundo nodo.</font></font><br>
<pre><code class="bash hljs">mount.glusterfs gluster-01.example.com:/main /gluster -o backupvolfile-server=gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un punto importante: gluster sincroniza archivos entre nodos solo si su cambio fue a través del volumen montado. </font><font style="vertical-align: inherit;">Si realiza cambios directamente en los nodos, el archivo no estará sincronizado.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conectar a Kubernetes</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En esta etapa, comenzaron las preguntas: "¿Cómo conectarlo?". </font><font style="vertical-align: inherit;">Y hay varias opciones. </font><font style="vertical-align: inherit;">Considerarlos.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Heketi</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lo más popular y recomendado es utilizar un servicio externo: heketi. </font><font style="vertical-align: inherit;">heketi es una capa entre kubernetes y gluster, que le permite administrar y trabajar con el almacenamiento a través de http. </font><font style="vertical-align: inherit;">Pero heketi será ese único punto de falla, porque </font><font style="vertical-align: inherit;">El servicio no está agrupado. </font><font style="vertical-align: inherit;">La segunda instancia de este servicio no podrá funcionar de forma independiente, porque </font><font style="vertical-align: inherit;">cualquier cambio se almacena en la base de datos local. </font><font style="vertical-align: inherit;">Ejecutar este servicio en kubernetes tampoco es adecuado, porque </font><font style="vertical-align: inherit;">necesita un disco estático en el que se almacenará su base de datos. </font><font style="vertical-align: inherit;">En este sentido, esta opción resultó ser la más inapropiada.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Punto final en Kubernetes</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si tiene Kubernetes en sistemas con gestores de paquetes, esta es una opción muy conveniente. </font><font style="vertical-align: inherit;">El punto es que para todos los servidores GlusteFS en Kubernetes, se crea un punto final común. </font><font style="vertical-align: inherit;">Se cuelga un servicio en este Endpoint y ya estaremos montados en este servicio. </font><font style="vertical-align: inherit;">Para que esta opción funcione, es necesario instalar glusterfs-client en cada nodo de Kubernetes y asegurarse de que se pueda montar. </font><font style="vertical-align: inherit;">En Kubernetes, implemente la siguiente configuración:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: v1<font></font>
kind: Endpoints<font></font>
metadata: <font></font>
  name: glusterfs-cluster<font></font>
subsets:<font></font>
  - addresses:<font></font>
      <span class="hljs-comment">#  ip  </span>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.71</span><font></font>
    ports:<font></font>
      <span class="hljs-comment">#    1,    </span>
      - port: <span class="hljs-number">1</span><font></font>
  - addresses:<font></font>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.72</span><font></font>
    ports:<font></font>
      - port: <span class="hljs-number">1</span><font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: Service<font></font>
metadata:<font></font>
  name: glusterfs-cluster<font></font>
spec:<font></font>
  ports:<font></font>
  - port: <span class="hljs-number">1</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora podemos crear una implementación de prueba simple y verificar cómo funciona el montaje. </font><font style="vertical-align: inherit;">A continuación se muestra un ejemplo de una implementación de prueba simple:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        glusterfs:<font></font>
          endpoints: glusterfs-cluster<font></font>
          path: main<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta opción no nos convenía, porque tenemos container-linux en todos los nodos de Kubernetes. </font><font style="vertical-align: inherit;">El administrador de paquetes no está allí, por lo que no fue posible instalar gluster-client para el montaje. </font><font style="vertical-align: inherit;">En este sentido, se encontró la tercera opción, que se decidió utilizar.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GlusterFS + NFS + keepalived</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hasta hace poco, GlusterFS ofrecía su propio servidor NFS, pero ahora el servicio externo nfs-ganesha se usa para NFS. </font><font style="vertical-align: inherit;">Se ha escrito bastante sobre esto, en relación con esto, descubriremos cómo configurarlo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El repositorio debe registrarse manualmente. </font><font style="vertical-align: inherit;">Para hacer esto, en el archivo /etc/yum.repos.d/nfs-ganesha.repo agregamos:</font></font><br>
<br>
<pre><code class="bash hljs">[nfs-ganesha]<font></font>
name=nfs-ganesha<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/<span class="hljs-variable">$basearch</span>/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
[nfs-ganesha-noarch]<font></font>
name=nfs-ganesha-noarch<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/noarch/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E instalar:</font></font><br>
<br>
<pre><code class="bash hljs">yum -y install nfs-ganesha-gluster --nogpgcheck
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Después de la instalación, llevamos a cabo la configuración básica en el archivo /etc/ganesha/ganesha.conf.</font></font><br>
<br>
<pre><code class="json hljs"># create new<font></font>
NFS_CORE_PARAM {<font></font>
    # possible to mount with NFSv3 to NFSv4 Pseudo path<font></font>
    mount_path_pseudo = true;<font></font>
    # NFS protocol<font></font>
    Protocols = 3,4;<font></font>
}<font></font>
EXPORT_DEFAULTS {<font></font>
    # default access mode<font></font>
    Access_Type = RW;<font></font>
}<font></font>
EXPORT {<font></font>
    # uniq ID<font></font>
    Export_Id = 101;<font></font>
    # mount path of Gluster Volume<font></font>
    Path = <span class="hljs-attr">"/gluster/main"</span>;<font></font>
    FSAL {<font></font>
        # any name<font></font>
        name = GLUSTER;<font></font>
        # hostname or IP address of this Node<font></font>
        hostname=<span class="hljs-attr">"gluster-01.example.com"</span>;<font></font>
        # Gluster volume name<font></font>
        volume=<span class="hljs-attr">"main"</span>;<font></font>
    }<font></font>
    # config for root Squash<font></font>
    Squash=<span class="hljs-string">"No_root_squash"</span>;<font></font>
    # NFSv4 Pseudo path<font></font>
    Pseudo=<span class="hljs-string">"/main"</span>;<font></font>
    # allowed security options<font></font>
    SecType = <span class="hljs-string">"sys"</span>;<font></font>
}<font></font>
LOG {<font></font>
    # default log level<font></font>
    Default_Log_Level = WARN;<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Necesitamos iniciar el servicio, habilitar nfs para nuestro volumen y verificar que esté activado.</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start nfs-ganesha<font></font>
$ systemctl <span class="hljs-built_in">enable</span> nfs-ganesha<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main nfs.disable off<font></font>
$ gluster volume status main<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, el estado debe indicar que el servidor nfs se ha iniciado para nuestro volumen. </font><font style="vertical-align: inherit;">Necesitas montar y verificar.</font></font><br>
<br>
<pre><code class="bash hljs">mkdir /gluster-nfs<font></font>
mount.nfs gluster-01.example.com:/main /gluster-nfs</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero esta opción no es tolerante a fallas, por lo que debe crear una dirección VIP que viajará entre nuestros dos nodos y ayudará a cambiar el tráfico si uno de los nodos cae. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La instalación de keepalived en CentOs se realiza inmediatamente a través del administrador de paquetes.</font></font><br>
<br>
<pre><code class="bash hljs">$ yum install -y keepalived</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Configuramos el servicio en el archivo /etc/keepalived/keepalived.conf:</font></font><br>
<br>
<pre><code class="json hljs">global_defs {<font></font>
    notification_email {<font></font>
        admin@example.com<font></font>
    }<font></font>
    notification_email_from alarm@example.com<font></font>
    smtp_server mail.example.com<font></font>
    smtp_connect_timeout <span class="hljs-number">30</span><font></font>
<font></font>
    vrrp_garp_interval <span class="hljs-number">10</span>
    vrrp_garp_master_refresh <span class="hljs-number">30</span><font></font>
}<font></font>
<font></font>
#C   ,   .    , VIP .<font></font>
vrrp_script chk_gluster {<font></font>
    script <span class="hljs-attr">"pgrep glusterd"</span><font></font>
    interval 2<font></font>
}<font></font>
<font></font>
vrrp_instance gluster {<font></font>
    interface ens192<font></font>
    state MASTER #     BACKUP<font></font>
    priority 200 #      ,  100<font></font>
    virtual_router_id 1<font></font>
    virtual_ipaddress {<font></font>
        10.10.6.70/24<font></font>
    }<font></font>
<font></font>
    unicast_peer {<font></font>
        10.10.6.72 #        <font></font>
    }<font></font>
<font></font>
    track_script {<font></font>
        chk_gluster<font></font>
    }<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora podemos iniciar el servicio y verificar que aparezca el VIP en el nodo:</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start keepalived<font></font>
$ systemctl <span class="hljs-built_in">enable</span> keepalived<font></font>
$ ip addr<font></font>
1: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000<font></font>
    link/ether 00:50:56:97:55:eb brd ff:ff:ff:ff:ff:ff<font></font>
    inet 10.10.6.72/24 brd 10.10.6.255 scope global noprefixroute ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
    inet 10.10.6.70/24 scope global secondary ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si todo funcionó para nosotros, entonces queda agregar PersistentVolume a Kubernetes y crear un servicio de prueba para verificar la operación.</font></font><br>
<br>
<pre><code class="python hljs">---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolume<font></font>
metadata:<font></font>
  name: gluster-nfs<font></font>
spec:<font></font>
  capacity:<font></font>
    storage: <span class="hljs-number">10</span>Gi<font></font>
  accessModes:<font></font>
    - ReadWriteMany<font></font>
  persistentVolumeReclaimPolicy: Retain<font></font>
  nfs:<font></font>
    server: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.70</span><font></font>
    path: /main<font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolumeClaim<font></font>
metadata:<font></font>
 name: gluster-nfs<font></font>
spec:<font></font>
 accessModes:<font></font>
 - ReadWriteMany<font></font>
 resources:<font></font>
   requests:<font></font>
     storage: <span class="hljs-number">10</span>Gi<font></font>
 volumeName: <span class="hljs-string">"gluster-nfs"</span><font></font>
<font></font>
---<font></font>
apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
  labels:<font></font>
    app: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        persistentVolumeClaim:<font></font>
          claimName: gluster-nfs<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Con esta configuración, en caso de una caída del nodo principal, estará inactivo durante aproximadamente un minuto hasta que el montaje se caiga en el tiempo de espera y cambie. </font><font style="vertical-align: inherit;">Simple por un minuto para este almacenamiento, digamos que esta no es una situación normal y rara vez nos encontraremos con ella, pero en este caso el sistema cambiará automáticamente y continuará funcionando, y podremos resolver el problema y llevar a cabo la recuperación sin preocuparnos por lo simple.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resumen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En este artículo, examinamos 3 posibles opciones para conectar GlusterFS a Kubernetes, en nuestra versión es posible agregar un aprovisionador a Kubernetes, pero aún no lo necesitamos. </font><font style="vertical-align: inherit;">Queda por agregar los resultados de las pruebas de rendimiento entre NFS y Gluster en los mismos nodos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Archivos en 1Mb:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1M count=1024; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 2.63496 s, 407 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 5.4527 s, 197 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Archivos en 1Kb:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1K count=1048576; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 70.0508 s, 15.3 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 6.95208 s, 154 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NFS funciona igual para cualquier tamaño de archivo, la diferencia de velocidad no es particularmente notable, a diferencia de GlusterFS, que está muy degradada con archivos pequeños. </font><font style="vertical-align: inherit;">Pero al mismo tiempo, con archivos de gran tamaño, NFS muestra un rendimiento 2-3 veces menor que Gluster.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es498144/index.html">Su primer BERT: una guía ilustrada</a></li>
<li><a href="../es498146/index.html">Seis tendencias de seguridad inteligente a tener en cuenta</a></li>
<li><a href="../es498150/index.html">Programadores de fontaneros, o la historia de una fuga y las dificultades de lidiar con ella</a></li>
<li><a href="../es498154/index.html">Calendario de eventos informáticos gratuitos en línea del 20 al 26 de abril</a></li>
<li><a href="../es498158/index.html">Maratón remoto Semana 1: Lugar de trabajo</a></li>
<li><a href="../es498162/index.html">Te invitamos a una pasantía de TI en Alfa Bank</a></li>
<li><a href="../es498164/index.html">Estrategias de producto para costos de transición</a></li>
<li><a href="../es498168/index.html">Nuevas arquitecturas de redes neuronales</a></li>
<li><a href="../es498172/index.html">Java Digest para el 21 de abril</a></li>
<li><a href="../es498174/index.html">Cómo dejar de preocuparte y comenzar a creer en las pruebas A / B</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
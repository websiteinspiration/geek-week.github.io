<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍮 👨🏿‍🤝‍👨🏾 👂🏿 We use DS to process customer reviews from large sites 👩🏼‍✈️ 😟 🙅🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the case, we used Python language libraries, such as: Selenium, BeautifulSoup. It turned out about 27 thousand reviews starting in 2018. On average...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>We use DS to process customer reviews from large sites</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/507238/"><img src="https://habrastorage.org/webt/ew/83/fu/ew83fubxvj8v2l04nqj8vkmicta.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the case, we used Python language libraries, such as: Selenium, BeautifulSoup. </font><font style="vertical-align: inherit;">It turned out about 27 thousand reviews starting in 2018. </font><font style="vertical-align: inherit;">On average, each review occupied 2 paragraphs of A4 sheet. </font><font style="vertical-align: inherit;">In 70% of the reviews, the rating was given by customers, in the remaining 30% - no rating was given. </font><font style="vertical-align: inherit;">We decided to use the obtained data, which were given grades, as initial data for constructing a model of teaching with a teacher. </font><font style="vertical-align: inherit;">In the future, we needed a model to determine the rating of the remaining 30% of reviews.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The ratings were from 1 to 5, but we needed to find out what the review was in terms of quality, i.e. whether it was positive or negative. </font><font style="vertical-align: inherit;">We used the logic of school grades in Russia: grades 1.2 - negative, they were converted to 0; </font><font style="vertical-align: inherit;">estimates 3,4,5 are positive, they were transformed into 1. Thus, the problem was reduced to binary classification.</font></font><br>
<a name="habracut"></a><br>
<pre><code class="python hljs">dataframe.tail(<span class="hljs-number">5</span>) </code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then they started experimenting with a binary classification model. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For the first pass, we chose the XGBoost method for teaching with a teacher. </font><font style="vertical-align: inherit;">Teachers are customer ratings. </font><font style="vertical-align: inherit;">As a text model, vector representations of Word2Vec words were taken, which are formed depending on the context. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We pre-processed the text, such as: lemmatization, removal of stop words, normalization and its tokenization.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> sent_tokenize
<span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> stopwords
<span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> word_tokenize</code></pre><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tokenize_ru</span>(<span class="hljs-params">x</span>):</span><font></font>
      tokens = x.lower()<font></font>
       tokens = re.sub(<span class="hljs-string">r'[^\w\s]+|[\d]'</span>,<span class="hljs-string">' '</span>,tokens)<font></font>
       tokens = word_tokenize(tokens)<font></font>
       tokens = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> (i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> string.punctuation)]<font></font>
       stop_words = stopwords.words(<span class="hljs-string">'russian'</span>)<font></font>
       stop_words.extend([<span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">'—'</span>, <span class="hljs-string">'–'</span>, <span class="hljs-string">''</span>, <span class="hljs-string">''</span>, <span class="hljs-string">'...'</span>])<font></font>
       tokens = [i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">if</span> (i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words)]<font></font>
       tokens = [i.replace(<span class="hljs-string">"«"</span>, <span class="hljs-string">""</span>).replace(<span class="hljs-string">"»"</span>, <span class="hljs-string">""</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tokens]
       <span class="hljs-keyword">return</span> tokens</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We sorted through the best parameters using the GridSearch method. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The optimal accuracy parameters were obtained with a tree depth of 8 (max_depth = 8) and the number of trees (n_estimators = 88). </font><font style="vertical-align: inherit;">By default, the XGBoost library is set to: n_estimators = 100, max_depth = 3.</font></font><br>
<br>
<pre><code class="python hljs">xgb_word2vec = Pipeline([<font></font>
              (<span class="hljs-string">"word2vec"</span>, MeanVect(w2v)),<font></font>
               (<span class="hljs-string">'model_fitting'</span>,  xgb)]) <font></font>
<font></font>
xgb_word2vec.fit(X_train2, y_train2)</code></pre><br>
<img src="https://habrastorage.org/webt/u2/bb/u9/u2bbu97mg296fz44uq6yf4vxn80.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
for these conditions, the Confusion matrix is ​​as follows:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">from</span> matplotlib.pylab <span class="hljs-keyword">import</span> rcParams<font></font>
rcParams[<span class="hljs-string">'figure.figsize'</span>] = <span class="hljs-number">3</span>, <span class="hljs-number">3</span>
plt.figure(figsize=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>))<font></font>
sns.set(font_scale=<span class="hljs-number">1.5</span>)<font></font>
ax = sns.heatmap((pd.crosstab(y_test2, pred2).apply(<span class="hljs-keyword">lambda</span> r: r/r.sum()*<span class="hljs-number">100</span>, axis=<span class="hljs-number">0</span>)), cbar=<span class="hljs-literal">None</span>, annot=<span class="hljs-literal">True</span>, cmap=<span class="hljs-string">"Blues"</span>)<font></font>
ax.set_ylabel(<span class="hljs-string">""</span>)<font></font>
ax.set_xlabel(<span class="hljs-string">""</span>)<font></font>
plt.yticks(rotation=<span class="hljs-number">0</span>, size = <span class="hljs-number">15</span>)<font></font>
plt.xticks(rotation=<span class="hljs-number">0</span>, size = <span class="hljs-number">15</span>)
</code></pre><br>
<img src="https://habrastorage.org/webt/zz/jb/w_/zzjbw_dele4bai2panjn7fqyzrc.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then we tried to use the SGDClassifier for the TF-IDF word vectors. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Below are the various combinations of options and their Confusion matrix: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1. SGDClassifier + Word2Vec </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rp/dn/gd/rpdngd5gbz6qny-zpggnsqvo0vs.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2. SGDClassifier + TF-IDF </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2m/37/2x/2m372xild8ugy3dc4nrze_wff94.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3. XGBoost + TF-IDF </font></font><br>
<br>
<img src="https://habrastorage.org/webt/qa/yh/mb/qayhmbyyvianjzeycktthm7xjj0.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
f-mera is calculated using the formula f-mera = 2 * Precision * Recall / (Precision + Recall), where Precision and Recall (completeness) are calculated from the Confusion matrix, this is the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">harmonic mean</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> between accuracy and completeness, for binary classification this is enough to assess the accuracy of the model. The best result was obtained with the combination of SGDClassifier + TF-IDF.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Further, in the already selected model, with better accuracy, we substituted irrelevant evaluated reviews starting from 2016 to 2018, which did not participate in the training in order to verify the correctness of the training and the model, as a result we got f-mera: 0.9326314212969897. </font><font style="vertical-align: inherit;">This model can later be used to classify reviews so as not to waste time manually searching for negative reviews.</font></font><br>
<br>
<pre><code class="python hljs">precision_recall_fscore_support(y_prov, predtest, average=<span class="hljs-string">'macro'</span>)</code></pre><br>
<img src="https://habrastorage.org/webt/1v/yd/yu/1vydyu1kkzolkbkxv2qfb58hhew.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then they used the model to evaluate the remaining unappreciated 30 percent of the reviews. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conclusion: For the natural language processing (NLP) from our experience described above, the results were better shown by a bunch of rapidly converging SGDClassifier with TF-IDF, but in turn, the key part of success lies in data preprocessing.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en507222/index.html">Why everyone should wear masks</a></li>
<li><a href="../en507224/index.html">How to eliminate blind spots with visual testing</a></li>
<li><a href="../en507226/index.html">OCR for PDF in .NET - How to extract text from inaccessible PDF documents</a></li>
<li><a href="../en507234/index.html">Snort or Suricata. Part 2: installation and initial setup of Suricata</a></li>
<li><a href="../en507236/index.html">We increase the effectiveness of interaction between designers and frontend developers</a></li>
<li><a href="../en507242/index.html">What is interesting Wi-Fi 6 in the performance of Huawei</a></li>
<li><a href="../en507250/index.html">Defining a winning poker hand using map / reduce in JavaScript</a></li>
<li><a href="../en507254/index.html">Zabbix - expanding macro borders</a></li>
<li><a href="../en507256/index.html">Peter Hinchens: Psychopath Source Code</a></li>
<li><a href="../en507258/index.html">Bonuses, benefits and bonuses in IT: the results of Habr Career research</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
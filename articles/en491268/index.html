<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüë©‚Äçüë¶‚Äçüë¶ üë† üå¥ Monte Carlo Methods for Markov Chains (MCMC). Introduction üë®üèø‚Äçüè´ üßòüèø ü§µüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, Habr! 
 
 We remind you that earlier we announced the book " Machine Learning Without Extra Words " - and now it is already on sale . Despite t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Monte Carlo Methods for Markov Chains (MCMC). Introduction</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/491268/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hello, Habr! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We remind you that earlier we announced the book " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Machine Learning Without Extra Words</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " - and now it is already </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">on sale</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Despite the fact that for beginners in MO, the book can indeed become a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">desktop</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , some topics in it still were not touched. Therefore, we are offering everyone interested a translation of an article by Simon Kerstens on the essence of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MCMC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> algorithms </font><font style="vertical-align: inherit;">with the implementation of such an algorithm in Python.</font></font><br>
<a name="habracut"></a> <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Monte Carlo methods for Markov chains</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (MCMC) are a powerful class of methods for sampling from probability distributions that are known only up to a certain (unknown) normalization constant. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, before delving into the MCMC, let's discuss why you might even need to make such a selection. The answer is: you may be interested in either the samples themselves from the sample (for example, to determine unknown parameters using the Bayesian derivation method), or to approximate the expected values ‚Äã‚Äãof the functions relative to the probability distribution (for example, to calculate thermodynamic quantities from the distribution of states in statistical physics). Sometimes we are only interested in the probability distribution mode. In this case, we obtain it by the method of numerical optimization, so it is not necessary to make a complete selection.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It turns out that sampling from any probability distributions except the most primitive ones is a difficult task. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The inverse transformation method</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is an elementary technique for sampling from probability distributions, which, however, requires the use of a cumulative distribution function, and to use it, in turn, you need to know the normalization constant, which is usually unknown. In principle, a normalization constant can be obtained by numerical integration, but this method quickly becomes impracticable with an increase in the number of dimensions. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deviation Sampling</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It does not require a normalized distribution, but in order to effectively implement it, it takes a lot to know about the distribution of interest to us. In addition, this method suffers severely from the curse of dimensions - this means that its effectiveness rapidly decreases with an increase in the number of variables. That is why you need to intelligently organize the receipt of representative samples from your distribution - not requiring to know the normalization constant. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MCMC algorithms are a class of methods designed specifically for this. They go back to the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">landmark article of Metropolis and others</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ; Metropolis developed the first MCMC algorithm named </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">after him</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and designed to calculate the equilibrium state of a two-dimensional system of hard spheres. In fact, the researchers were looking for a universal method that would allow us to calculate the expected values ‚Äã‚Äãfound in statistical physics. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This article will cover the basics of MCMC sampling. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MARKOV CHAINS</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that we understand why we need to sample, let's move on to the heart of MCMC: Markov chains. What is a Markov chain? Without going into technical details, we can say that a Markov chain is a random sequence of states in a certain state space, where the probability of choosing a certain state depends only on the current state of the chain, but not on its past history: this chain is devoid of memory. Under certain conditions, a Markov chain has a unique stationary distribution of states, to which it converges, overcoming a certain number of states. After such a number of state states in a Markov chain, an invariant distribution is obtained. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To sample from a distribution, </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the MCMC algorithm creates and simulates a Markov chain whose stationary distribution is</font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">; this means that after the initial ‚Äúseed‚Äù period, the states of such a Markov chain are distributed according to the principle </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Therefore, we will only have to save the state in order to get samples from </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For educational purposes, let us consider both a discrete state space and a discrete ‚Äútime‚Äù. The key quantity characterizing a Markov chain is a transition operator </font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indicating the probability of being in a state </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">at a time </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, provided that the chain is in a state </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">at time </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now just for fun (and as a demonstration) let's quickly weave a Markov chain with a unique stationary distribution. Let's start with some imports and settings for charts:</font></font><br>
<br>
<pre><code class="python hljs">%matplotlib notebook<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
plt.rcParams[<span class="hljs-string">'figure.figsize'</span>] = [<span class="hljs-number">10</span>, <span class="hljs-number">6</span>]<font></font>
np.random.seed(<span class="hljs-number">42</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Markov chain will go around the discrete state space formed by three weather conditions: </font></font><br>
<br>
<pre><code class="python hljs">state_space = (<span class="hljs-string">"sunny"</span>, <span class="hljs-string">"cloudy"</span>, <span class="hljs-string">"rainy"</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In a discrete state space, the transition operator is just a matrix. </font><font style="vertical-align: inherit;">In our case, the columns and rows correspond to sunny, cloudy and rainy weather. </font><font style="vertical-align: inherit;">Let us choose relatively reasonable values ‚Äã‚Äãfor the probabilities of all transitions:</font></font><br>
<br>
<pre><code class="python hljs">transition_matrix = np.array(((<span class="hljs-number">0.6</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.1</span>),<font></font>
                              (<span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.3</span>),<font></font>
                              (<span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The rows indicate the states in which the circuit may currently be located, and the columns indicate the states into which the circuit can go. </font><font style="vertical-align: inherit;">If we take the ‚Äútime‚Äù step of the Markov chain in one hour, then, provided that it is sunny now, there is a 60% chance that the sunny weather will continue for the next hour. </font><font style="vertical-align: inherit;">There is also a 30% chance that there will be cloudy weather in the next hour, and a 10% chance that it will rain immediately after sunny weather. </font><font style="vertical-align: inherit;">It also means that the values ‚Äã‚Äãin each row add up to one. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's drive our Markov chain a little:</font></font><br>
<br>
<pre><code class="python hljs">n_steps = <span class="hljs-number">20000</span>
states = [<span class="hljs-number">0</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_steps):<font></font>
    states.append(np.random.choice((<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), p=transition_matrix[states[<span class="hljs-number">-1</span>]]))<font></font>
states = np.array(states)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We can observe how the Markov chain converges to a stationary distribution, calculating the empirical probability of each of the states as a function of chain length:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">despine</span>(<span class="hljs-params">ax, spines=(<span class="hljs-params"><span class="hljs-string">'top'</span>, <span class="hljs-string">'left'</span>, <span class="hljs-string">'right'</span></span>)</span>):</span>
    <span class="hljs-keyword">for</span> spine <span class="hljs-keyword">in</span> spines:<font></font>
        ax.spines[spine].set_visible(<span class="hljs-literal">False</span>)<font></font>
<font></font>
fig, ax = plt.subplots()<font></font>
width = <span class="hljs-number">1000</span>
offsets = range(<span class="hljs-number">1</span>, n_steps, <span class="hljs-number">5</span>)
<span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> enumerate(state_space):<font></font>
    ax.plot(offsets, [np.sum(states[:offset] == i) / offset <font></font>
            <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> offsets], label=label)<font></font>
ax.set_xlabel(<span class="hljs-string">"number of steps"</span>)<font></font>
ax.set_ylabel(<span class="hljs-string">"likelihood"</span>)<font></font>
ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
despine(ax, (<span class="hljs-string">'top'</span>, <span class="hljs-string">'right'</span>))<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/vu/tg/xv/vutgxvc3lq1-sang725fmek1ibm.png"><br>
 <br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HONOR OF ALL MCMC: METROPOLIS-HASTINGS ALGORITHM</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Of course, all this is very interesting, but back to the sampling process of an arbitrary probability distribution </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. It can be either discrete, in which case we will continue to talk about the transition matrix </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, or continuous, in which case it </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">will be a transition core. Hereinafter, we will talk about continuous distributions, but all the concepts that we consider here are also applicable to discrete cases. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If we could design the transition core in such a way that the next state was already deduced from </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, then this could be limited, since our Markov chain ... would directly sample from </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Unfortunately, to achieve this, we need the ability to sample from</font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">what we cannot do - otherwise you would not read that, right? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The workaround is to break the transition core </font></font><img src="https://habrastorage.org/webt/7_/os/ja/7_osja2wwom8x6f29sp5ecxnrwc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">into two parts: the proposal step and the acceptance / rejection step. An auxiliary distribution appears at the sample step</font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from which the possible next states of the chain are selected. Not only can we make a selection from this distribution, but we can arbitrarily choose the distribution itself. However, when designing, one should strive to come to such a configuration in which samples taken from this distribution would be minimally correlated with the current state and at the same time have good chances to go through the receiving phase. The above receiving / discarding step is the second part of the transition core; at this stage, errors contained in the trial states selected from are corrected </font></font><img src="https://habrastorage.org/webt/dq/wo/ba/dqwoba_pfa-ktifmo9zviggtesm.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Here, the probability of successful reception is calculated </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and a sample is taken </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">with such probability as the next state in the chain. Getting the next state </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from</font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">then performed as follows: first, the trial state </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">is taken from </font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Then it is taken as the next state with probability </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">or discarded with probability </font></font><img src="https://habrastorage.org/webt/cr/_w/sd/cr_wsdxfgphyie2qbzl977pvfgq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, and in the latter case, the current state is copied and used as the next. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Consequently, we have </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ty/vg/w-/tyvgw-g_ij7vgrpzoxtt7t3enmw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
sufficient condition for the Markov chain had </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">as a stationary distribution is the following: The transitional core must submit </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">detailed equilibrium</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> or as write in the physical literature, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">microscopic reversibility</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hf/bg/oy/hfbgoyr944ikp5ce_menl-sg0da.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This means that the probability of being in a state </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and moving from there to</font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">must be equal to the probability of the reverse process, that is, be able to </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and go into a state </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. The transition kernels of most MCMC algorithms satisfy this condition. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order for the two-part transition core to obey detailed equilibrium, it is necessary to choose correctly </font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, that is, to ensure that it allows you to correct any asymmetries in the probability stream from / to </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">or </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Metropolis-Hastings algorithm uses admissibility criterion Metropolis: </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/mh/dm/z2/mhdmz27voos90zkz5_-zexopsdc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And here the magic begins: </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">we know only to a constant, but it does not matter, since this unknown constant nullifies the expression for</font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! It is this paccpacc property that ensures the operation of algorithms based on the Metropolis-Hastings algorithm on unnormalized distributions. Symmetric auxiliary distributions c are often used </font></font><img src="https://habrastorage.org/webt/b2/ss/pz/b2sspzujgmdn_uwizxwjjokkg5w.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, in which case the Metropolis-Hastings algorithm is reduced to the original (less general) Metropolis algorithm developed in 1953. In the original algorithm </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hd/3k/vq/hd3kvqg9l2jqltan97_gfmzutsi.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this case, the complete transitional core of the Metropolis-Hastings can be written as </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WE IMPLEMENT THE METROPOLIS-HASTINGS ALGORITHM AT PYTHON</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Great, now that we‚Äôve figured out how the Metropolis-Hastings algorithm works, let's move on to its implementation. First, we establish the logarithmic probability of the distribution from which we are going to make a selection - without normalization constants; it is assumed that we do not know them. Next, we work with the standard normal distribution:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_prob</span>(<span class="hljs-params">x</span>):</span>
     <span class="hljs-keyword">return</span> <span class="hljs-number">-0.5</span> * np.sum(x ** <span class="hljs-number">2</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, we choose a symmetric auxiliary distribution. </font><font style="vertical-align: inherit;">In general, the performance of the Metropolis-Hastings algorithm can be improved if you include information already known to you about the distribution from which you want to make a selection in the auxiliary distribution. </font><font style="vertical-align: inherit;">A simplified approach looks like this: we take the current state </font></font><code>x</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and select a sample from </font></font><img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, that is, set a certain step size </font></font><code>Œî</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and go left or right from our current state by no more than </font></font><img src="https://habrastorage.org/webt/q1/n2/d_/q1n2d_lbzpbqtvbmbgiha503cmo.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">proposal</span>(<span class="hljs-params">x, stepsize</span>):</span>
    <span class="hljs-keyword">return</span> np.random.uniform(low=x - <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             high=x + <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             size=x.shape)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, we calculate the probability that the proposal will be accepted:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">p_acc_MH</span>(<span class="hljs-params">x_new, x_old, log_prob</span>):</span>
    <span class="hljs-keyword">return</span> min(<span class="hljs-number">1</span>, np.exp(log_prob(x_new) - log_prob(x_old)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now we put all this together into a truly brief implementation of the sampling stage for the Metropolis-Hastings algorithm:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_MH</span>(<span class="hljs-params">x_old, log_prob, stepsize</span>):</span><font></font>
    x_new = proposal(x_old, stepsize)<font></font>
    <span class="hljs-comment">#   ,     :</span>
    <span class="hljs-comment">#       [0,1]  </span>
    <span class="hljs-comment">#     </span><font></font>
    accept = np.random.random() &lt; p_acc(x_new, x_old, log_prob)<font></font>
    <span class="hljs-keyword">if</span> accept:
        <span class="hljs-keyword">return</span> accept, x_new
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> accept, x_old</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition to the next state in the Markov chain, </font></font><code>x_new</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">or </font></font><code>x_old</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, we also return information about whether the MCMC step was adopted. </font><font style="vertical-align: inherit;">This will allow us to track the dynamics of sample collection. </font><font style="vertical-align: inherit;">In conclusion of this implementation, we write a function that will iteratively call </font></font><code>sample_MH</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and thus build a Markov chain:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_MH_chain</span>(<span class="hljs-params">init, stepsize, n_total, log_prob</span>):</span><font></font>
<font></font>
    n_accepted = <span class="hljs-number">0</span><font></font>
    chain = [init]<font></font>
<font></font>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(n_total):<font></font>
        accept, state = sample_MH(chain[<span class="hljs-number">-1</span>], log_prob, stepsize)<font></font>
        chain.append(state)<font></font>
        n_accepted += accept<font></font>
    <font></font>
    acceptance_rate = n_accepted / float(n_total)<font></font>
    <font></font>
    <span class="hljs-keyword">return</span> chain, acceptance_rate</code></pre><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TESTING OUR METROPOLIS-HASTINGS ALGORITHM AND RESEARCHING ITS BEHAVIOR</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Probably, now you can not wait to see all this in action. </font><font style="vertical-align: inherit;">We will do this, we will make some informed decisions about the arguments </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">chain, acceptance_rate = build_MH_chain(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">3.0</span>, <span class="hljs-number">10000</span>, log_prob)<font></font>
chain = [state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain]<font></font>
print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
last_states = <span class="hljs-string">", "</span>.join(<span class="hljs-string">"{:.5f}"</span>.format(state) 
                        <span class="hljs-keyword">for</span> state <span class="hljs-keyword">in</span> chain[<span class="hljs-number">-10</span>:])<font></font>
print(<span class="hljs-string">"Last ten states of chain: "</span> + last_states)<font></font>
Acceptance rate: <span class="hljs-number">0.722</span>
Last ten states of chain: <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.08692</span>, <span class="hljs-number">0.92728</span>, <span class="hljs-number">-0.46215</span>, <span class="hljs-number">0.08655</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span></code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Things are good. So, did it work? We succeeded in taking samples in about 71% of cases, and we have a chain of states. The first few states in which the chain has not yet converged to its stationary distribution should be discarded. Let's check if the conditions we have chosen actually have a normal distribution:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_samples</span>(<span class="hljs-params">chain, log_prob, ax, orientation=<span class="hljs-string">'vertical'</span>, normalize=True,
                 xlims=(<span class="hljs-params"><span class="hljs-number">-5</span>, <span class="hljs-number">5</span></span>), legend=True</span>):</span>
    <span class="hljs-keyword">from</span> scipy.integrate <span class="hljs-keyword">import</span> quad<font></font>
    <font></font>
    ax.hist(chain, bins=<span class="hljs-number">50</span>, density=<span class="hljs-literal">True</span>, label=<span class="hljs-string">"MCMC samples"</span>,<font></font>
           orientation=orientation)<font></font>
    <span class="hljs-comment">#     PDF</span>
    <span class="hljs-keyword">if</span> normalize:<font></font>
        Z, _ = quad(<span class="hljs-keyword">lambda</span> x: np.exp(log_prob(x)), -np.inf, np.inf)
    <span class="hljs-keyword">else</span>:<font></font>
        Z = <span class="hljs-number">1.0</span>
    xses = np.linspace(xlims[<span class="hljs-number">0</span>], xlims[<span class="hljs-number">1</span>], <span class="hljs-number">1000</span>)<font></font>
    yses = [np.exp(log_prob(x)) / Z <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xses]
    <span class="hljs-keyword">if</span> orientation == <span class="hljs-string">'horizontal'</span>:<font></font>
        (yses, xses) = (xses, yses)<font></font>
    ax.plot(xses, yses, label=<span class="hljs-string">"true distribution"</span>)
    <span class="hljs-keyword">if</span> legend:<font></font>
        ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
    <font></font>
fig, ax = plt.subplots()<font></font>
plot_samples(chain[<span class="hljs-number">500</span>:], log_prob, ax)<font></font>
despine(ax)<font></font>
ax.set_yticks(())<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/yo/rx/59/yorx59lirnkyju_dymptouaaokw.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It looks great! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What about the parameters </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">? We first discuss the step size: it determines how far the trial state can be removed from the current state of the circuit. Therefore, this is an auxiliary distribution parameter </font></font><code>q</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">that controls how large the random steps taken by the Markov chain will be. If the step size is too large, the trial states often end up in the tail of the distribution, where the probability values ‚Äã‚Äãare low. The Metropolis-Hastings sampling mechanism discards most of these steps, as a result of which reception rates are reduced and convergence slows significantly. See for yourself:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_and_display</span>(<span class="hljs-params">init_state, stepsize, n_total, n_burnin, log_prob</span>):</span><font></font>
    chain, acceptance_rate = build_MH_chain(init_state, stepsize, n_total, log_prob)<font></font>
    print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
    fig, ax = plt.subplots()<font></font>
    plot_samples([state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain[n_burnin:]], log_prob, ax)<font></font>
    despine(ax)<font></font>
    ax.set_yticks(())<font></font>
    plt.show()<font></font>
    <font></font>
sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">30</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.116</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/0g/4-/-r/0g4--rezypxzaqta-pkugq3gi3w.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Not very cool, right? Now it seems that it's best to set a tiny step size. It turns out that this is not a smart decision either, since the Markov chain will investigate the probability distribution very slowly, and therefore also will not converge as quickly as with a well-chosen step size:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.992</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/bf/qh/xi/bfqhxistqravnn7xug43ubowgmu.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Regardless of how you choose the step size parameter, the Markov chain eventually converges to a stationary distribution. But this may take a lot of time. The time during which we will simulate the Markov chain is </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">determined </font><font style="vertical-align: inherit;">by the parameter </font><font style="vertical-align: inherit;">- it simply determines how many states of the Markov chain (and, therefore, the selected samples) we will eventually have. If the chain converges slowly, then it needs to be increased </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">so that the Markov chain has time to ‚Äúforget‚Äù the initial state. Therefore, we will leave the step size tiny and increase the number of samples by increasing the parameter </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">500000</span>, <span class="hljs-number">25000</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.990</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/fs/ba/27/fsba27vppyvfqnwdnnr0ifdp3w4.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Meeeedenly we are moving towards the goal ... </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CONCLUSIONS</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Considering all the above, I hope that now you have intuitively grasped the essence of the Metropolis-Hastings algorithm, its parameters, and understand why this is an extremely useful tool for selecting from non-standard probability distributions that you may encounter in practice. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I strongly recommend that you experiment with the code given </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- so you get used to the behavior of the algorithm in various circumstances and understand it more deeply. </font><font style="vertical-align: inherit;">Try asymmetric auxiliary distribution! </font><font style="vertical-align: inherit;">What will happen if you do not configure the acceptance criterion properly? </font><font style="vertical-align: inherit;">What happens if you try to sample from a bimodal distribution? </font><font style="vertical-align: inherit;">Can you come up with a way to automatically adjust the step size? </font><font style="vertical-align: inherit;">What are the pitfalls here? </font><font style="vertical-align: inherit;">Answer these questions yourself!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en491258/index.html">IT girls, where are you from? Let's build a map</a></li>
<li><a href="../en491260/index.html">Text normalization in speech recognition tasks</a></li>
<li><a href="../en491262/index.html">An eye for an eye. Biometrics Issues</a></li>
<li><a href="../en491264/index.html">Introduction to SSD. Part 4. Physical</a></li>
<li><a href="../en491266/index.html">SurfingAttack: compromising smartphones with sound assistants [+ video]</a></li>
<li><a href="../en491272/index.html">Website development in pascal (backend)</a></li>
<li><a href="../en491276/index.html">How I circumvented the ban on Messages API through the Vkontakte documentation</a></li>
<li><a href="../en491278/index.html">CLRium # 7: Reports, Practice, Mentors</a></li>
<li><a href="../en491280/index.html">The story of how I developed a programming language</a></li>
<li><a href="../en491282/index.html">How to increase team productivity (and reduce errors) using rallies</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤳 👨‍🔧 👋🏽 マルチタグ分類 🐏 👩🏼‍🔧 👨‍👩‍👦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、habrozhiteli！私たちは、分類に特化したAndrei Burkovによる本の抜粋、「余分な単語なしの機械学習」を引用することにしました。
 
 図のイメージを説明するために、「針葉樹の森」、「山」、「道路」などの複数のラベルを同時に使用できます。ラベルに使用できる値の数は多いが...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>マルチタグ分類</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/488362/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><img src="https://habrastorage.org/webt/hm/vf/c_/hmvfc_yyxepplv1mj0crw1vu7pw.jpeg" align="left" alt="画像"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは、habrozhiteli！</font><font style="vertical-align: inherit;">私たちは</font><font style="vertical-align: inherit;">、分類に特化し</font><font style="vertical-align: inherit;">たAndrei Burkovによる本の抜粋、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「余分な単語なしの機械学習」</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を引用することにしました</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
図のイメージを説明するために、「針葉樹の森」、「山」、「道路」などの複数のラベルを同時に使用できます。ラベルに使用できる値の数は多いが、それらはすべてタグと同じ性質を持っている場合、各タグ付きサンプルは、各タグに1つずつ、複数のタグ付きデータに変換できます。このすべての新しいデータは、同じ特徴ベクトルと1つのラベルのみを持ちます。その結果、タスクはマルチクラス分類問題になります。 「すべてに対して1つ」の戦略を使用して解決できます。通常のマルチクラス分類問題との唯一の違いは、新しいハイパーパラメーターの出現であるしきい値です。ラベルの類似度スコアがしきい値を超える場合、このラベルは入力特徴ベクトルに割り当てられます。このシナリオでは、1つの特性ベクトルに複数のラベルを割り当てることができます。しきい値は、制御セットを使用して選択されます。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多くのラベルを持つ分類問題を解決するために、自然にマルチクラスに変換されるアルゴリズム（決定木、ロジスティック回帰、ニューラルネットワークなど）を同様に適用できます。それらは各クラスの推定値を返すため、しきい値を定義し、近接スコアがこのしきい値を超える1つの特徴ベクトルに複数のラベルを割り当てることができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークは、コスト関数としてバイナリクロスエントロピーを使用して、マルチラベル分類で自然にトレーニングできます。この場合のニューラルネットワークの出力層には、ラベルごとに1つのノードがあります。出力層の各ノードには、シグモイドアクティベーション関数があります。したがって、各ラベルlはバイナリです</font></font><img src="https://habrastorage.org/webt/2n/_n/mg/2n_nmgvuciuadryomnq3urrg1xw.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ここで、l = 1、...、Lおよびi = 1、...、Nです。</font></font><img src="https://habrastorage.org/webt/lb/le/cf/lblecfgyuy23k8zvlasuajncsds.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">サンプルxiがlとラベル付けされる</font><font style="vertical-align: inherit;">確率のバイナリクロスエントロピー。</font></font><img src="https://habrastorage.org/webt/qd/1e/fx/qd1efxpmi6mmuhv_fhmsqpjgpi4.jpeg" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最小化</font><font style="vertical-align: inherit;">の</font><font style="vertical-align: inherit;">基準</font><font style="vertical-align: inherit;">として定義され</font><font style="vertical-align: inherit;">ます。すべてのトレーニングサンプルのバイナリクロスエントロピーのすべてのメンバーの単純平均です。とそのすべてのタグ。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
可能なラベル値の数が少ない場合は、多くのラベルを持つ分類問題をマルチクラス分類問題に変換しようとすることができます。</font><font style="vertical-align: inherit;">次の問題を想像してみてください。</font><font style="vertical-align: inherit;">画像には2種類のラベルを割り当てる必要があります。</font><font style="vertical-align: inherit;">最初のタイプのラベルには、2つの意味があります。{ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">写真、絵画</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> }; </font><font style="vertical-align: inherit;">2番目のタイプのマークには、次の3つの意味があります。{ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ポートレート、ランドスケープ、その他</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">}。</font><font style="vertical-align: inherit;">2つのソースクラスの組み合わせごとに、新しいダミークラスを作成できます。次に例を示します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mz/px/zn/mzpxzn0rlrumwoql7gkk3no7ihk.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで同じタグ付きデータが作成されましたが、真のラベルのセットを1から6の値を持つ1つのダミーラベルに置き換えました。実際には、このアプローチは、クラスの組み合わせが多すぎない場合に良い結果をもたらします。それ以外の場合は、クラスのセットの増加を補うために、さらに多くのトレーニングデータを使用する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この後者のアプローチの主な利点は、互いに独立して各ラベルを予測する上記の方法とは異なり、ラベルが相関したままであることです。多くのタスクでは、ラベル間の相関関係が重要な要素になる場合があります。たとえば、メールを</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スパム</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font><i><font style="vertical-align: inherit;">非</font></i><i><font style="vertical-align: inherit;">スパム</font></i><font style="vertical-align: inherit;">に分類したい</font><font style="vertical-align: inherit;">とし</font><i><font style="vertical-align: inherit;">ます。</font></i></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、同時に、通常かつ重要です。</font><font style="vertical-align: inherit;">[ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spam、重要</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ] </font><font style="vertical-align: inherit;">などの予測を除外することをお勧めし</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5。</font><font style="vertical-align: inherit;">アンサンブルトレーニング</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
第3章で取り上げた基本的なアルゴリズムには制限があります。その単純さのために、彼らはあなたの仕事に十分効果的なモデルを作成できない場合があります。このような場合は、ディープニューラルネットワークを使用してみてください。ただし、実際には、ディープニューラルネットワークには大量のラベル付きデータが必要であり、これはユーザーが持っていない場合があります。単純な学習アルゴリズムの効果を高める別の方法は、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アンサンブルトレーニング</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を使用すること</font><font style="vertical-align: inherit;">です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensembleトレーニングは、1つの非常に正確なモデルだけでなく、低精度の多数のモデルのトレーニングに基づいたトレーニングパラダイムであり、これらの</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">弱い</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデル</font><font style="vertical-align: inherit;">によって提供される予測を組み合わせて</font><font style="vertical-align: inherit;">、より正確な</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">メタ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルを取得します</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
精度の低いモデルは、通常、</font><font style="vertical-align: inherit;">複雑なモデルをトレーニングできない</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">弱い学習アルゴリズム</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">によってトレーニングされる</font><font style="vertical-align: inherit;">ため、トレーニングおよび予測の段階で高速を示します。ほとんどの場合、決定木学習アルゴリズムは弱いアルゴリズムとして使用され、通常、数回の反復後にトレーニングセットの破壊を停止します。結果は小さく、非常に規則的なツリーではありませんが、アンサンブルをトレーニングするという考えが示すように、ツリーが同一でなく、各ツリーがランダムな推測よりもわずかに優れている場合は、そのようなツリーを多数組み合わせることで高い精度を得ることができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
エントリー</font><b><font style="vertical-align: inherit;">xの</font></b><font style="vertical-align: inherit;">最終予測を取得するには</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、すべての弱いモデルの予測は、加重投票のいくつかの方法を使用して結合されます。</font><font style="vertical-align: inherit;">投票の重み付けの具体的な形式はアルゴリズムに依存しますが、本質はそれに依存しません。まとめて、弱いモデルが電子メールがスパムであると予測する場合、サンプル</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">xに</font></font></b><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スパム</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ラベル</font><font style="vertical-align: inherit;">を割り当て</font><i><font style="vertical-align: inherit;">ます</font></i><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アンサンブルのトレーニングの2つの主な方法は、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ブースティング</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">バギング</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（集約）です。</font><font style="vertical-align: inherit;">ブースティングとバギングという用語の翻訳は不正確であり、慣れていません。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.1。</font><font style="vertical-align: inherit;">ブースティングとバギング</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ブースティング方法は、初期トレーニングデータを使用して、弱いアルゴリズムを使用して複数のモデルを繰り返し作成することです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
新しいモデルはそれぞれ、以前のモデルとは異なり、それを構築すると、弱いアルゴリズムが以前のモデルで発生したエラーを「修正」しようとします。</font><font style="vertical-align: inherit;">最終的なアンサンブルモデルは、これらの多くの弱く反復的に構築されたモデルの組み合わせです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
バギングの本質は、トレーニングデータの多くの「コピー」を作成し（各コピーは他とわずかに異なる）、いくつかの弱いモデルを取得するために各アルゴリズムに弱いアルゴリズムを適用し、それらを結合することです。</font><font style="vertical-align: inherit;">バギングのアイデアに基づく、広く使用されている効率的な機械学習アルゴリズムは、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ランダムフォレスト</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.2。</font><font style="vertical-align: inherit;">ランダムフォレスト</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「クラシック」バギングアルゴリズムは次のように機能します。</font><font style="vertical-align: inherit;">Bのランダムサンプルが既存のトレーニングセットから作成され</font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（各b = 1、...、Bに対して）、各サンプルに基づいて</font><font style="vertical-align: inherit;">決定木</font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルが構築さ</font><font style="vertical-align: inherit;">れます</font></font><img src="https://habrastorage.org/webt/nd/ew/4z/ndew4zvx7r0jpeilfknakojmrbs.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一部のbの</font><font style="vertical-align: inherit;">サンプルを取得するには、サンプル</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を置換して作成し</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">つまり、最初に空のサンプルが作成され、次にトレーニングセットからランダムサンプルが選択され、その正確なコピーがに配置されますが</font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、サンプル自体は元のトレーニングセットに残ります。</font><font style="vertical-align: inherit;">データの選択は、条件が満たされるまで続き</font></font><img src="https://habrastorage.org/webt/se/au/-5/seau-5gwous1c1cshmrx8rwubig.jpeg" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
、トレーニングの結果、</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B個の</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">決定木が</font><font style="vertical-align: inherit;">得られ</font><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">新しいサンプル</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の予測は、</font><font style="vertical-align: inherit;">回帰の場合、</font><b><font style="vertical-align: inherit;">B</font></b><font style="vertical-align: inherit;">の平均として決定されます。</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 予報</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/re/zp/mj/rezpmjqa9lo7w4dxvqd6njwwqcm.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
または分類の場合は多数決で。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ランダムフォレストには、従来のバギングとの違いが1つだけあります。変更されたツリー学習アルゴリズムを使用し、学習プロセスで分割するたびに、特徴のランダムなサブセットをチェックします。これは、ツリー間の相関関係を排除するために行われます。1つ以上のフィーチャに大きな予測能力がある場合、多くのツリーがデータを分割するためにそれらを選択します。これにより、多数の相関ツリーが「フォレスト」に表示されます。高い予測能力を持つ符号相関により、予測精度が向上しなくなります。モデルのアンサンブルの高い効率は、良いモデルは同じ予測に同意する可能性が最も高く、悪いモデルは一致しない可能性が高く、異なる予測を与えるという事実によって説明されます。相関関係により、貧弱なモデルが同意する可能性が高くなります。これは投票パターンを歪めるか、平均に影響を与えます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
チューニングで最も重要なハイパーパラメーターは、ツリーBの数と、各分割で考慮する必要がある機能のランダムなサブセットのサイズです。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ランダムフォレストは、最も広く使用されているアンサンブル学習アルゴリズムの1つです。その効果を決定するものは何ですか？その理由は、元のデータセットからいくつかのサンプルを使用することにより</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最終的なモデルの</font><b><font style="vertical-align: inherit;">分散</font></b><font style="vertical-align: inherit;">を減らすため</font><font style="vertical-align: inherit;">です。分散が小さいということは、</font><b><font style="vertical-align: inherit;">再トレーニング</font></b><font style="vertical-align: inherit;">する傾向が弱いことを覚えておいてください</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">データセットは、シミュレーションしようとしている現象の考えられるすべての例のほんの一部にすぎないため、モデルがデータセットの小さな変動を説明しようとすると、再学習が発生します。</font><font style="vertical-align: inherit;">トレーニングセットの形成に失敗したアプローチの場合、いくつかの望ましくない（しかし不可避の）アーティファクトがそれに入る可能性があります：ノイズ、異常、過度または不十分な代表的なデータ。</font><font style="vertical-align: inherit;">トレーニングセットを置き換えていくつかのランダムサンプルを作成することにより、これらのアーティファクトの影響を減らします。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.3。</font><font style="vertical-align: inherit;">グラデーションブースト</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ブースティングのアイデアに基づく別の効果的なアンサンブルトレーニングアルゴリズムは、勾配ブースティングです。</font><font style="vertical-align: inherit;">最初に、回帰における勾配ブースティングの使用を検討します。</font></font><img src="https://habrastorage.org/webt/7u/7x/jd/7u7xjdufljpsjwwu45j9_gkc3r0.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（ID3で行ったように）</font><font style="vertical-align: inherit;">定数モデルを使用して効果的な回帰モデルの構築を開始し</font><font style="vertical-align: inherit;">ます。</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/em/vj/bv/emvjbvtmptxl_d3bihzev4wbh7o.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、トレーニングセットのすべてのサンプルi = 1、...、Nのラベルを変更します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/va/wc/ah/vawcahk0zsdpgnumh_bfjuozw_e.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
where </font></font><img src="https://habrastorage.org/webt/rf/1x/pk/rf1xpkgfxmcivy-1tqpwv2vgroi.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">剰余</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font><font style="vertical-align: inherit;">呼ばれ、</font><font style="vertical-align: inherit;">サンプルの新しいラベルです</font></font><img src="https://habrastorage.org/webt/dk/ey/2r/dkey2rj3yf-zkei2029wfa2ujso.jpeg" alt="画像"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。ここで、元のラベルの代わりに残りを使用して変更されたトレーニングセットを使用して、決定木の新しいモデルを構築します。</font></font><img src="https://habrastorage.org/webt/mx/fw/um/mxfwumzpc5tq1wjpdate2rxra48.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ブースティングモデルは</font></font><img src="https://habrastorage.org/webt/cy/c2/vz/cyc2vz0tmrrihcm6kta_7rnwmui.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、αが学習速度（ハイパーパラメーター）</font><font style="vertical-align: inherit;">として定義されて</font><font style="vertical-align: inherit;">います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、式7.2を使用して残差を再計算し、トレーニングデータのラベルを再度置き換え、決定木の新しいモデルを教示し</font><font style="vertical-align: inherit;">、所定の最大数</font><b><font style="vertical-align: inherit;">Mの</font></b><font style="vertical-align: inherit;">ツリー</font><font style="vertical-align: inherit;">を組み合わせるまで、プロセスを繰り返すときに</font></font><img src="https://habrastorage.org/webt/p4/wk/nl/p4wknlhlvwiqtr7zz7lx_y5oq3s.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ブーストモデルを再定義し</font><font style="vertical-align: inherit;">ます。</font></font><img src="https://habrastorage.org/webt/n-/mn/ht/n-mnhtck0rar7pz4anzlbdc-bmo.jpeg" alt="画像"><font style="vertical-align: inherit;"></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで何が起こっているのかを直感的に理解しましょう。残差を計算することにより、各トレーニングサンプルの目標が現在のモデルfによってどの程度適切に（または不十分に）予測されるかを決定します。次に、別のツリーをトレーニングして現在のモデルのエラーを修正し（これが、実際のラベルの代わりに残り物を使用する理由です）、重みαを使用して既存のモデルに新しいツリーを追加します。その結果、モデルに追加された新しいツリーはそれぞれ、以前のツリーによって行われた誤りを部分的に修正します。このプロセスは、ツリーの最大数M（別のハイパーパラメーター）が結合されるまで続きます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
では、なぜこのアルゴリズムが勾配ブースティングと呼ばれるのかという質問に答えてみましょう。勾配ブースティングでは、第4章で行ったのとは異なり、線形回帰問題を解決して勾配を計算しません。勾配ブースティングと勾配降下の類似性を確認するには、線形回帰で勾配を計算した理由を思い出してください。MSEコスト関数を最小化するパラメーター値の方向を見つけるためです。勾配は方向を示していますが、この方向にどれだけ遠くに行くかは示していないため、各反復で小さなステップを実行し、再度方向を決定しました。勾配ブースティングでも同じことが起こりますが、勾配を直接計算するのではなく、その推定値を残差の形式で使用します。これらは、モデルを調整して誤差（残差）を減らす方法を示します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
勾配ブースティングでは、3つの主要なハイパーパラメーターを使用して調整できます。ツリーの数、学習の速度、およびツリーの深さです。 3つすべてがモデルの精度に影響します。木の深さは、学習と予測の速度にも影響します。深さが小さいほど速くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
残差による学習は、標準誤差標準に対してモデルf全体を最適化することを示すことができます。ここで、バギングとの違いを確認できます。ブースティングは、分散ではなくバイアス（または教育の欠如）を減らします。その結果、ブースティングは再トレーニングの対象になります。ただし、木の深さと数を調整することで、再トレーニングを大幅に回避できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
グラデーションブースティングは、グレーディングタスクでも同様ですが、手順が少し異なります。バイナリ分類の場合を考えます。 M個の回帰決定木があるとします。ロジスティック回帰と同様に、決定木の集団の予測は、シグモイド関数を使用してモデル化されます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wy/pd/gw/wypdgwjjgpzuojrelehnadtdggc.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
どこ</font></font><img src="https://habrastorage.org/webt/w6/3d/kb/w63dkbj3f9j-ik9hrhqbexyxtem.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回帰ツリーがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして再び、ロジスティック回帰のように、最大​​化するモデルfを見つけようとするとき、</font></font><img src="https://habrastorage.org/webt/c4/lv/tt/c4lvttexfzr8disbsv1ph_drzka.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最尤法の原理が適用されます。同様に、数値のオーバーフローを回避するために、尤度の積ではなく、尤度の対数の合計を最大化します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アルゴリズムは、初期定数モデルで始まる</font><font style="vertical-align: inherit;">（そのような初期化は、シグモイド関数のために最適であることを示すことができる。）次に、各反復mで、新しいツリーFMがモデルに追加されます。最良のツリー</font><font style="vertical-align: inherit;">を見つける</font><font style="vertical-align: inherit;">最良のツリー</font><font style="vertical-align: inherit;">を見つけるには、</font><font style="vertical-align: inherit;">まず</font><font style="vertical-align: inherit;">現在のモデルの</font><font style="vertical-align: inherit;">偏微分</font><font style="vertical-align: inherit;">を各i = 1、...、Nについて</font><font style="vertical-align: inherit;">計算</font><font style="vertical-align: inherit;">します。</font></font><img src="https://habrastorage.org/webt/hn/7j/ep/hn7jepdxhudnxvjjgbulvfwtpyw.jpeg" alt="画像"><font style="vertical-align: inherit;"></font><img src="https://habrastorage.org/webt/gj/6s/f6/gj6sf6i874m3gq3_fbbxbkrudae.jpeg" alt="画像"><font style="vertical-align: inherit;"></font><img src="https://habrastorage.org/webt/b0/5w/rv/b05wrvcuk5hzvnrmkpebdnk_kxu.jpeg" alt="画像"><font style="vertical-align: inherit;"></font><img src="https://habrastorage.org/webt/xm/u4/dp/xmu4dpm1hi3-podtuiayxggydti.jpeg" alt="画像"><font style="vertical-align: inherit;"></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="画像"><font style="vertical-align: inherit;"></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wg/v_/oo/wgv_oogvmupu4q5j6g3rq7dphvk.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、fは前の反復m-1で作成された集団分類器のモデルです。を計算する</font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">には</font></font><img src="https://habrastorage.org/webt/pv/pe/lb/pvpelb2jplsmq_jmkbdfyl-pzom.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、すべてのiについてfに関する</font><font style="vertical-align: inherit;">の導関数を見つける必要があります</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">そのノート</font></font><img src="https://habrastorage.org/webt/nk/zn/0l/nkzn0lh0l0brnzl_vh0xxlmttrq.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">前式の右辺のFに対して誘導体であります</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xx/en/iu/xxeniu2qr35ln17asbfk2fqb3sc.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、</font></font><img src="https://habrastorage.org/webt/a1/fv/cu/a1fvcukqqvsu5wpv3x8i1zj5smc.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">対応する偏微分の</font><font style="vertical-align: inherit;">元のラベルを置き換えることによってトレーニングセットが変換され</font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、変換されたトレーニングセットに基づいて新しいツリーが構築されます。</font></font><img src="https://habrastorage.org/webt/w1/8f/41/w18f41gto37doyvyakgs4np_fyy.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">次に、最適な更新ステップが次のように決定さ</font></font><img src="https://habrastorage.org/webt/1n/cf/sj/1ncfsjxfe-tao3ep_csuw-s-arw.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">れます。</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/co/qc/hw/coqchwpctxgy2ukbdwaybkouxx0.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
反復mの終わりに</font></font><img src="https://habrastorage.org/webt/r7/ox/vy/r7oxvyc5mesbifpwfjtkcrtdr2q.jpeg" alt="画像"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、新しいツリーを追加し</font><font style="vertical-align: inherit;">てアンサンブルモデルを更新し</font><font style="vertical-align: inherit;">ます。</font></font><img src="https://habrastorage.org/webt/s2/vp/u0/s2vpu0-7pmzuzv0n55f1z1fgktu.jpeg" alt="画像"><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/vg/ar/qn/vgarqnddik0vjhxxfsesr1t5qs8.jpeg" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
反復は、条件m = Mが満たされるまで続きます。その後、トレーニングが停止し、アンサンブルモデルfが取得されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
勾配ブースティングは、最も強力な機械学習アルゴリズムの1つです。</font><font style="vertical-align: inherit;">非常に正確なモデルを作成するだけでなく、何百万ものデータと機能を備えた巨大なデータセットを処理できるためです。</font><font style="vertical-align: inherit;">原則として、ランダムフォレストよりも精度は優れていますが、一貫性があるため、学習速度ははるかに遅くなります。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja488346/index.html">LinuxのPython 3.7仮想環境でのSCIPおよびGLPKを使用したor-toolsのインストール</a></li>
<li><a href="../ja488348/index.html">ウェビナー「10のアジャイルチャレンジと1時間でそれらを克服する方法」2月17日20:00モスクワ時間</a></li>
<li><a href="../ja488352/index.html">VDIコストの比較：オンプレミスとパブリッククラウド</a></li>
<li><a href="../ja488356/index.html">サンクトペテルブルグ国立海洋工科大学でのダッソー・システムズ製品のトレーニング</a></li>
<li><a href="../ja488360/index.html">ビッグデータの神話とデジタル文化</a></li>
<li><a href="../ja488366/index.html">また、「ロシアのタイムゾーンのタイムゾーン情報が正しくない」についても[.Netバグ、ID：693286]</a></li>
<li><a href="../ja488368/index.html">私の最初の大規模プロジェクトの作業中に学んだこと</a></li>
<li><a href="../ja488370/index.html">マイクロコントローラ用のTDD。パート2：スパイが依存症を取り除く方法</a></li>
<li><a href="../ja488374/index.html">テレグラム+ 1C + Webhook + Apache +自己署名証明書</a></li>
<li><a href="../ja488376/index.html">「すべてのもので地獄に行く、それを取り、それを行う！」という原則 機能しない：先延ばしメモ</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
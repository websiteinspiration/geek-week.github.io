<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕴🏽 🙆🏾 👨🏽‍🤝‍👨🏻 Event2Mind pour la langue russe. Comment nous avons appris au modèle à lire entre les lignes et à comprendre les intentions de l'interlocuteur ⚒️ 📈 🐗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La capacité d'un modèle à reconnaître les intentions de l'interlocuteur, c'est-à-dire à comprendre pourquoi une personne a effectué l'une ou l'autre a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Event2Mind pour la langue russe. Comment nous avons appris au modèle à lire entre les lignes et à comprendre les intentions de l'interlocuteur</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/507178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La capacité d'un modèle à reconnaître les intentions de l'interlocuteur, c'est-à-dire à comprendre pourquoi une personne a effectué l'une ou l'autre action, est applicable dans un grand nombre de tâches de PNL appliquées. Par exemple, les chatbots, assistants vocaux et autres systèmes de dialogue vous permettront de répondre émotionnellement aux déclarations de l’interlocuteur, de faire preuve de compréhension, de sympathie et d’autres émotions. En outre, l'intention de reconnaître le problème - c'est une autre étape vers la compréhension de la parole </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">humaine</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ( </font><i><font style="vertical-align: inherit;">compréhension humaine</font></i><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">
Plusieurs tentatives ont déjà été faites pour résoudre ce problème sous une forme ou une autre. Par exemple, sur </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">NLP-progress</font></a></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/uc/aq/ek/ucaqekbmpy4zkuanbo2a6qn_vei.jpeg"></a><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les dernières avancées du raisonnement sur le bon sens sont publiées. La faiblesse de la plupart des modèles existants est qu'ils sont basés sur une approche supervisée, c'est-à-dire qu'ils nécessitent de grands ensembles de données étiquetés pour la formation. Et en raison de la spécificité de la tâche, le balisage est souvent très non standard et assez complexe. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour l'anglais, il existe un certain nombre de cas et de benchmark'ov, mais pour la langue russe, la situation avec les données est beaucoup plus triste. Le manque de données étiquetées pour le russe est souvent l'un des principaux obstacles qui empêche la russification des modèles anglais qui fonctionnent. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans cet article, nous décrirons comment nous avons créé un ensemble de données pour la tâche de raisonnement Common Sense dans l'une de ses formulations possibles proposées dans l'article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">event2mind</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">avons</font></a><font style="vertical-align: inherit;"> également adapté le modèle anglais</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">event2mind</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> d' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AllenNLP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour la langue russe.</font></font><a name="habracut"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tout d'abord, parlons un peu de ce qu'est la tâche de raisonnement de bon sens. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En fait, il serait plus correct de considérer cela comme un ensemble de tâches visant à reconnaître les intentions et les émotions de l'acteur. Elle n'a pas une seule formulation, et dans cet article, nous prendrons comme base cette variante proposée par les auteurs de event2mind: dans un court texte sous forme libre contenant une action ou un événement (par exemple, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«PersonX mange le petit déjeuner le matin»</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), déterminer les intentions le sujet ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«X veut satisfaire la faim»</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), ses émotions / réactions ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«X se sent rassasié, plein»</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) et les émotions / réactions possibles des autres participants à l'événement, le cas échéant. La figure 1 illustre cela.</font></font><br>
<br>
<p><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 1. La tâche du raisonnement Commonsense est de déterminer les intentions, les émotions / réactions du sujet et les émotions / réactions des autres à partir de l'événement texte court.</font></font></i><br>
</p><div style="text-align:center;"><img src="https://habrastorage.org/webt/fj/nc/xi/fjncxilwif9qw4monmkb7po4j4q.png" width="400"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans l'article original en anglais, les auteurs ont proposé un modèle event2mind pour résoudre ce problème, ainsi qu'un grand cas balisé pour sa formation à la langue anglaise. </font><font style="vertical-align: inherit;">Notre tâche était de russifier ce modèle, en l'adaptant à la langue russe. </font><font style="vertical-align: inherit;">Nous avons ensuite voulu intégrer ce modèle dans le chatbot afin de lui apprendre à comprendre les intentions de l'utilisateur et à répondre correctement aux émotions. </font><font style="vertical-align: inherit;">Pour ce faire, nous avons collecté un ensemble de données pour la langue russe, dans un format similaire à l'anglais, et également formé et testé plusieurs modèles de l'architecture event2mind sur les données collectées.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Des données, des données et encore des données</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notre tâche était donc de rassembler un corps de textes balisés sous forme libre dans un format adapté à la formation event2mind. </font><font style="vertical-align: inherit;">Pour simplifier, nous appellerons ces textes courts simplement des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">événements</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Dans le même temps, nous avons essayé de maximiser les horizons de raisonnement de bon sens du modèle, en collectant des </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">événements</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sur une variété de sujets de la vie quotidienne.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie un. </font><font style="vertical-align: inherit;">Corpus externalisé</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors de la première étape, nous avons dû collecter un nombre suffisant d'événements "bruts" pour un marquage ultérieur. </font><font style="vertical-align: inherit;">Nous avons pris trois sources de données comme base:</font></font><br>
<br>
<ol>
<li>      .    50      ,   «», «   », «-», «», «»  .       «  »     .       ,        ,       .  ,    ,   « »  « »?             .</li>
<li>  .       1512 .</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Textes de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SynTagRus</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui fait partie du Corps national russe et contient des textes littéraires ainsi que des nouvelles.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans l'étape suivante, nous avons extrait les événements des textes collectés. </font><font style="vertical-align: inherit;">Les événements de formation event2mind peuvent être définis comme une combinaison d'un prédicat de verbe avec les arguments inclus dans le composant du verbe. </font><font style="vertical-align: inherit;">Pour rechercher de tels modèles, l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">analyseur de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> syntaxe </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">UdPipe a</font></a><font style="vertical-align: inherit;"> été utilisé </font><font style="vertical-align: inherit;">, à l'aide duquel nous avons sélectionné des modèles du </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verbe de</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> forme </font><i><font style="vertical-align: inherit;">+ des mots dépendants dans l'arbre de syntaxe</font></i><font style="vertical-align: inherit;"> , comme dans la figure 2, qui satisfaisait à l'une des règles suivantes:</font></font><br>
<br>
<i><ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nsubj + root + obj</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nsubj + root + iobj</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nsubj + advmod + root</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nsubj + root + case + obl</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">etc.</font></font></li>
</ul></i><br>
<p><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 2. Modèles syntaxiques utilisés pour extraire les événements des textes</font></font></i><br>
<br>
</p><div style="text-align:center;"><img src="https://habrastorage.org/webt/8u/72/5q/8u725q7ffw8qa2ercspo8bgi8fa.png" width="300"></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les événements sélectionnés sont dépersonnalisés. Par analogie avec l'événement original2mind, tous les acteurs et entités nommées ont été remplacés par PersonX uniforme, ainsi que PersonY et PersonZ, si la proposition mentionne plus d'un acteur. Pour la reconnaissance des entités nommées ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Named Entity Recognition</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) et le remplacement ultérieur, nous avons de nouveau utilisé UdPipe: dans les événements qui correspondent aux modèles ci-dessus, nous avons dépersonnalisé les jetons marqués avec des balises PROPN ou PRONOUN. En conclusion, nous avons exclu les événements qui ne contenaient pas de sujets animés. Par exemple, par ce critère, la phrase </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«Il pleut» a</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> été supprimée </font><font style="vertical-align: inherit;">. Par conséquent, seuls les événements avec des entités nommées animées (personnes nommées entités) sont entrés dans le corpus.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après dépersonnalisation et filtrage, nous avons utilisé l'analyse de fréquence et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la distance de Levenshtein</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour sélectionner les </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">événements</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> les plus courants </font><font style="vertical-align: inherit;">et filtrer les exemples non standard rencontrés une seule fois. Premièrement, nous avons pris plus d'une fois tous les événements qui se sont réunis dans l'échantillon initial. Pour le reste des données, nous avons calculé les distances par paires de Levenshtein</font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>L</mi><mo stretchy=&quot;false&quot;>(</mo><mi>p</mi><mi>h</mi><mi>r</mi><mi>a</mi><mi>s</mi><msub><mi>e</mi><mn>1</mn></msub><mo>,</mo><mi>p</mi><mi>h</mi><mi>r</mi><mi>a</mi><mi>s</mi><msub><mi>e</mi><mn>2</mn></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.456ex" height="2.634ex" viewBox="0 -809.3 8807.5 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-4C" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMAIN-28" x="681" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-70" x="1071" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-68" x="1574" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-72" x="2151" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-61" x="2602" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-73" x="3132" y="0"></use><g transform="translate(3601,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-65" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMAIN-31" x="659" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMAIN-2C" x="4521" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-70" x="4967" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-68" x="5470" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-72" x="6047" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-61" x="6498" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-73" x="7028" y="0"></use><g transform="translate(7497,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-65" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMAIN-32" x="659" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMAIN-29" x="8417" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>L</mi><mo stretchy="false">(</mo><mi>p</mi><mi>h</mi><mi>r</mi><mi>a</mi><mi>s</mi><msub><mi>e</mi><mn>1</mn></msub><mo>,</mo><mi>p</mi><mi>h</mi><mi>r</mi><mi>a</mi><mi>s</mi><msub><mi>e</mi><mn>2</mn></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-1">L(phrase_1,phrase_2)</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,), a sélectionné des paires pour lesquelles il ne dépassait pas 5 et a pris une phrase plus courte de chaque paire. Avec cette méthode, nous avons été guidés par la considération suivante: si pour quelques événements leur distance Levenshtein est petite (dans ce cas, seuil 5), alors ces phrases diffèrent très légèrement, par exemple, sous la forme d'un verbe ou d'un adjectif. En fait, ce sont des variations du même </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">événement</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Et nous avons choisi une phrase plus courte dans la paire car elle préfère contenir les formes initiales des mots (elles sont souvent plus courtes, mais pas toujours). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après la collecte des données, les événements devaient être balisés, mettant en évidence les intentions de PersonX, ses émotions / réactions, ainsi que les émotions / réactions de PersonY et PersonZ, le cas échéant. Pour ce faire, nous avons créé une tâche dans </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex.Tolok</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Vous pouvez en voir un exemple à la figure 3. Pour chaque événement, nous avons demandé aux marqueurs:</font></font><br>
<br>
<i><ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Contient-il un événement significatif?</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">si le texte de l'événement peut comprendre les intentions de l'acteur;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">si l'événement peut comprendre les émotions / réactions de l'acteur;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">si cet événement peut provoquer une réaction environnante.</font></font></li>
</ul></i><br>
<p><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 3. Exemple de tâche de Yandex.Tolki</font></font></i><br>
<br>
</p><div style="text-align:center;"><img src="https://habrastorage.org/webt/pd/ef/i8/pdefi8wjewqbjvqzofnavnjz9po.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour faciliter le travail des tolokers, nous leur avons préparé des conseils - réponses au modèle d'essai event2mind, formés au cas anglais traduit event2mind. </font><font style="vertical-align: inherit;">Ils ne pouvaient donc que vérifier les réponses du «projet» de modèle et, si possible, proposer les leurs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient de mentionner que puisque les données traduites se sont avérées être assez brutes, le modèle formé sur elles s'est avéré faible. </font><font style="vertical-align: inherit;">Elle n'a pas atteint un modèle à part entière, mais dans certains cas, elle a pu deviner avec précision les émotions et les intentions des sujets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En conséquence, nous avons pu collecter 6756 événements sur divers sujets quotidiens.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie 2. Corpus anglais traduit </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En plus d'utiliser l'ensemble de données russe étiqueté, nous avons partiellement traduit le corpus anglais à l'aide d'un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">traducteur Google</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , puis filtré et corrigé le résultat. Pourquoi était-ce nécessaire? Il est clair que la traduction automatique est légèrement pire que les données russes originales marquées manuellement.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le fait est que le balisage d'un tel ensemble de données est une entreprise à forte intensité de main-d'œuvre nécessitant une grande quantité de ressources, d'argent et de fonds. Nous n'avons tout simplement pas eu l'occasion de marquer le cas, de taille comparable à l'anglais, qui se compose de 46 mille exemples. Étant donné que l'ensemble de données assemblé en russe s'est avéré plus petit, nous avons décidé d'évaluer s'il y avait suffisamment de données pour la formation. Pour ce faire, nous avons formé le modèle anglais sur des parties du boîtier d'origine et mesuré comment la qualité change en fonction de la taille de l'ensemble de données de formation. Les résultats sont présentés dans le tableau. La qualité de l' </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">intention</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et des émotions / réactions ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réagir</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) a été évaluée, par analogie avec l'article d'origine, par le </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rappel</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> métrique </font><i><font style="vertical-align: inherit;">@ 10</font></i><font style="vertical-align: inherit;"> lors de la validation. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rappel @ 10</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">reflète la proportion de cas où la vraie réponse - </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'étalon-or</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - tombe dans les 10 premières prédictions du modèle. </font><font style="vertical-align: inherit;">La métrique varie de 0 à 1, plus c'est mieux.</font></font><br>
<br>
<p><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tableau 1. La dépendance de la qualité du modèle anglais sur la taille du dossier de formation</font></font></i><br>
<br>
</p><div style="text-align:center;"><img src="https://habrastorage.org/webt/cz/bj/bn/czbjbnmgz2upluaiscw_0yafz-g.png" width="400"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Immédiatement, nous pouvons dire que 5000 exemples ne sont pas suffisants pour une formation complète sur le modèle. Cependant, même avec 30 000 exemples, la perte et le rappel ne diffèrent pratiquement pas des résultats sur la totalité des données. Il s'avère que les 7000 exemples que nous avons balisés ne suffisent pas pour entraîner le modèle et il est nécessaire d'augmenter en quelque sorte la taille de l'échantillon d'apprentissage. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour ce faire, nous avons préparé un corpus supplémentaire, obtenu à partir de l'anglais à l'aide de la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">traduction</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> automatique de </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">Google par Translator</font></a><font style="vertical-align: inherit;"> . Comme indiqué ci-dessus, dans la traduction automatique de l'ensemble du corpus, certaines traductions se sont révélées incorrectes ou ont complètement perdu leur sens. Par conséquent, nous avons sélectionné la partie des données en anglais qui a été traduite le plus adéquatement. Initialement, le corps anglais était composé de plusieurs sources: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kit de formation ROC Story</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">les N-grammes </font></font></a><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GoogleSyntactic</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">le corpus Spinn3r</font></a><font style="vertical-align: inherit;"> et les idiomes. </font><font style="vertical-align: inherit;">Cependant, les offres de certaines sources étaient plus faciles à traduire que d'autres. </font><font style="vertical-align: inherit;">Par exemple, une traduction adéquate des idiomes sans modification manuelle dépassait la puissance d'un ordinateur. </font><font style="vertical-align: inherit;">Par conséquent, nous n'avons pris que des exemples de l'histoire de ROC. </font><font style="vertical-align: inherit;">Selon les résultats de l'article d'origine (voir tableau 2), cette source a un coefficient de cohérence annotateur ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">coefficient kappa de Cohen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) de 0,57. </font><font style="vertical-align: inherit;">Et cela, très probablement, indique que les événements qui en découlent sont plus faciles à comprendre et à baliser, et donc moins sujets aux erreurs de traduction.</font></font><br>
<br>
<p><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tableau 2 Données et coefficient kappa de Cohen pour différentes sources dans le cas anglais</font></font></i><br>
</p><div style="text-align:center;"><img src="https://habrastorage.org/webt/un/ix/s8/unixs8bvmj4oz5d8usft0ak5aro.png" width="350"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après cela, nous avons filtré les données sélectionnées, supprimé des exemples dans lesquels des mots anglais et des exemples qui ont été traduits incorrectement sont restés après la traduction. </font><font style="vertical-align: inherit;">Le reste a été édité par des éditeurs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient de noter que, malgré toutes les astuces, le filtrage et l'édition, le cas traduit est toujours en retard sur la «qualité» des phrases de l'ensemble de données marqué par les tolokers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En conséquence, nous avons réussi à collecter 23 409 </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">événements</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> traduits </font><font style="vertical-align: inherit;">, et le volume du corps combiné, en tenant compte de la partie russe majorée, s'élevait à 30 165. Cela, comme nous l'avons découvert au cours des expériences, aurait dû être suffisant pour former le modèle russe.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et maintenant - aux expériences! </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainsi, les données sont collectées, il est temps de passer à la formation et à l'expérimentation de modèles. Le modèle event2mind est une architecture de réseau neuronal de la forme </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">codeur-décodeur</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> avec un codeur et trois décodeurs pour chaque type de prédiction (voir figure 4): l'intention du sujet, ses émotions / réactions et les émotions / réactions des autres participants à l'événement, le cas échéant ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">intention du sujet, sujets du réactions</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font><i><font style="vertical-align: inherit;">réactions des </font></i></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">participants aux</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> autres </font><i><font style="vertical-align: inherit;">événements</font></i><font style="vertical-align: inherit;"> ). Les phrases originales sont vectorisées en utilisant l'une des méthodes de représentations vectorielles des mots (par exemple, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">word2vec</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fasttext</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) et encodées en utilisant un encodeur dans un vecteur</font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>h</mi><mi>E</mi></msup><mo>&amp;#x2208;</mo><msup><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi mathvariant=&quot;double-struck&quot;>R</mi></mrow><mi>H</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.037ex" height="2.509ex" viewBox="0 -970.7 3890.9 1080.4" role="img" focusable="false" style="vertical-align: -0.255ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-45" x="815" y="513"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMAIN-2208" x="1494" y="0"></use><g transform="translate(2440,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJAMS-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/sberbank/blog/507178/&amp;usg=ALkJrhhGKXRf3MhnnGP030qCxxmAf-93ZA#MJMATHI-48" x="1021" y="581"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>h</mi><mi>E</mi></msup><mo>∈</mo><msup><mrow class="MJX-TeXAtom-ORD"><mi mathvariant="double-struck">R</mi></mrow><mi>H</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-2">h^E\in \mathbb{R}^H</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Et puis, à l'aide de trois décodeurs RNN, des prédictions sont générées. Grâce à cela, le modèle peut générer des réponses même pour des intentions et des réactions qu'il n'avait pas vues auparavant. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 4. Architecture du modèle event2mind</font></font></i><br>
<br>
<p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/i8/ot/dg/i8otdgafbpp00ssxbvxp73kbrpy.png" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour les expériences, nous avons utilisé le corpus intégré pour la langue russe, les parties balisées et traduites. </font><font style="vertical-align: inherit;">Et pour uniformiser la distribution des exemples russes et traduits, nous avons également mélangé les données. </font><font style="vertical-align: inherit;">Notez que nous avons également essayé de former le modèle uniquement sur des données étiquetées, mais en raison du petit volume de l'ensemble de données, il a montré de très mauvais résultats. </font><font style="vertical-align: inherit;">Nous avons testé différentes couches de l'encodeur - LSTM et GRU, et également essayé diverses représentations vectorielles - </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fasttext</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">word2vec</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> avec </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RusVectores</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Les résultats sont présentés dans le tableau 3, les résultats d'intention et de réaction, tels que calculés précédemment en utilisant la mesure de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rappel @ 10</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<p><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tableau 3. Les résultats du modèle pour la langue russe, l'intention et la réaction ont été évalués par rappel @ 10</font></font></i><br>
</p><div style="text-align:center;"><img src="https://habrastorage.org/webt/dz/ar/c0/dzarc0uafcs3cokc0ya0dhcvpdu.png" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alors, quelles conclusions peut-on tirer des résultats des expériences? </font><font style="vertical-align: inherit;">Premièrement, les intégrations de word2vec se sont avérées légèrement meilleures que le texte rapide. </font><font style="vertical-align: inherit;">Dans le même temps, les intégrations de texte rapide formées à la ruscorpora se sont avérées meilleures que celles formées à l'araneum. </font><font style="vertical-align: inherit;">Deuxièmement, on peut noter que lors de l'utilisation de word2vec, GRU dans l'encodeur est meilleur que LSTM. </font><font style="vertical-align: inherit;">Et enfin, le meilleur modèle (areneum word2vec + GRU) répète pratiquement les résultats pour la langue anglaise.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et enfin - regardons de vrais exemples! </font></font></h2><br>
<p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/0t/0o/y7/0t0oy7dcsauyxp6d-xsitnkroli.png" width="600"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Très bien! </font><font style="vertical-align: inherit;">Les intentions semblent très crédibles et reflètent vraiment une sorte de concepts et de connaissances humains universels. </font><font style="vertical-align: inherit;">Mais le modèle a fait face à des émotions / réactions un peu pires, elles se sont avérées plus primitives et monotones. </font><font style="vertical-align: inherit;">Cela est peut-être dû au fait que les émotions dépendent d'un plus grand volume de texte et qu'un court texte d'événement ne suffit pas pour le déterminer correctement.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Au lieu d'une conclusion</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons donc créé un bâtiment en langue russe pour former le modèle event2mind. </font><font style="vertical-align: inherit;">De plus, nous avons mené des expériences qui ont montré que l'architecture event2mind fonctionne pour la langue russe, qui est par nature grammaticalement plus compliquée que l'anglais. </font><font style="vertical-align: inherit;">Malgré la complexité de la langue russe, il était possible d'obtenir une qualité comparable à l'anglais. </font><font style="vertical-align: inherit;">Le meilleur modèle et les meilleures données sont publiés dans le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">référentiel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<p><img src="https://habrastorage.org/webt/p3/yn/_k/p3yn_k4sbghk8xbj1nt_3rlvxrk.png" width="700"></p><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un projet d'une telle envergure n'est devenu possible que grâce aux efforts conjoints de notre équipe. </font><font style="vertical-align: inherit;">Dans l'adaptation de event2mind pour la langue russe a également participé</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">alenusch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onetwotrickster</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr507166/index.html">Expérience de l'utilisation de la technologie Rutoken pour l'enregistrement et l'autorisation des utilisateurs dans le système (partie 3)</a></li>
<li><a href="../fr507170/index.html">Est-ce que quatorze personnes consultent ce produit avec certitude?</a></li>
<li><a href="../fr507172/index.html">Ce qu'ils font à la faculté de l'énergie à basse température de l'Université ITMO</a></li>
<li><a href="../fr507174/index.html">Les Forces armées de Russie et d'autres structures du Ministère de la défense de la Fédération de Russie ont-elles besoin d'une norme pour décrire les algorithmes?</a></li>
<li><a href="../fr507176/index.html">Système MMS dans le centre de données: comment nous avons automatisé la gestion de la maintenance</a></li>
<li><a href="../fr507182/index.html">Jeu de motivations. Partie 2</a></li>
<li><a href="../fr507188/index.html">Mieux que le silicium: les scientifiques ont obtenu un matériau semi-conducteur avec des caractéristiques plus avancées</a></li>
<li><a href="../fr507190/index.html">Bot dans aucun outil de code. Détails d'implémentation</a></li>
<li><a href="../fr507194/index.html">Masques de testeur (questions pour une transition réussie vers un trouble de la personnalité du testeur)</a></li>
<li><a href="../fr507196/index.html">Quelle est la différence entre Data Analytics et Statistics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
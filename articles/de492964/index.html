<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🅾️ 🙆🏾 👩🏻‍🤝‍👨🏾 Verarbeitung von Millionen von Ereignissen pro Tag mit kaskadierenden Warteschlangen 🕵🏽 🍆 👩🏻‍🏫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hunderte, Tausende und in einigen Diensten drehen sich Millionen von Warteschlangen, durch die eine große Datenmenge geleitet wird, unter der Haube un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Verarbeitung von Millionen von Ereignissen pro Tag mit kaskadierenden Warteschlangen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/manychat/blog/492964/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hunderte, Tausende und in einigen Diensten drehen sich Millionen von Warteschlangen, durch die eine große Datenmenge geleitet wird, unter der Haube unseres Produkts. </font><font style="vertical-align: inherit;">All dies muss auf magische Weise verarbeitet und nicht erschossen werden. </font><font style="vertical-align: inherit;">In diesem Beitrag werde ich Ihnen erklären, welche architektonischen Ansätze wir zu Hause verwenden, wenn wir einen relativ bescheidenen Technologie-Stack haben und kein kleines Rechenzentrum in unserer „Speisekammer“ haben.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/iq/-o/dc/iq-odcaikfzjfsiwqgpx2phk5us.png"><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was haben wir?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einerseits haben wir also einen bekannten Technologie-Stack: Nginx, PHP, PostgreSQL, Redis. </font><font style="vertical-align: inherit;">Andererseits treten jede Minute Zehntausende von Ereignissen in unserem System auf, und in der Spitze können Hunderttausende von Ereignissen erreicht werden. </font><font style="vertical-align: inherit;">Um zu verdeutlichen, was diese Ereignisse sind und wie wir darauf reagieren sollen, werde ich einen kleinen Produkt-Exkurs durchführen. Anschließend werde ich Ihnen erläutern, wie wir das ereignisbasierte Automatisierungssystem entwickelt haben.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ManyChat ist eine Plattform für die Marketingautomatisierung. Der Eigentümer der Facebook-Seite kann sie mit unserer Plattform verbinden und die Automatisierung der Interaktion mit seinen Abonnenten konfigurieren (dh einen Chat-Bot erstellen). Die Automatisierung besteht normalerweise aus vielen Interaktionsketten, die möglicherweise nicht miteinander verbunden sind. Innerhalb dieser Automatisierungsketten können bestimmte Aktionen mit dem Teilnehmer ausgeführt werden, z. B. das Zuweisen eines bestimmten Tags im System oder das Zuweisen / Ändern des Werts eines Felds auf der Karte eines Teilnehmers. Mit diesen Daten können Sie die Zielgruppe weiter segmentieren und eine relevantere Interaktion mit den Abonnenten der Seite aufbauen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unsere Kunden wollten unbedingt eine ereignisbasierte Automatisierung - die Möglichkeit, die Ausführung einer Aktion anzupassen, wenn ein bestimmtes Ereignis innerhalb des Abonnenten ausgelöst wird (z. B. Tagging). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da ein Triggerereignis von verschiedenen Automatisierungsketten aus funktionieren kann, ist es wichtig, dass es für alle ereignisbasierten Aktionen auf der Clientseite einen einzigen Konfigurationspunkt gibt. Auf unserer Verarbeitungsseite sollte es einen einzigen Bus geben, der die Änderung im Kontext des Teilnehmers von verschiedenen Automatisierungspunkten aus verarbeitet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In unserem System gibt es einen gemeinsamen Bus, über den alle mit Teilnehmern auftretenden Ereignisse übertragen werden. Dies sind mehr als 500 Millionen Ereignisse pro Tag. Ihre Verarbeitung ist ziemlich heikel - dies ist ein Datensatz im Data Warehouse, sodass der Seiteninhaber die Möglichkeit hat, historisch alles zu sehen, was seinen Abonnenten passiert ist.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es scheint, dass wir zur Implementierung eines ereignisbasierten Systems bereits über alles verfügen und es ausreicht, unsere Geschäftslogik in die Verarbeitung eines gemeinsamen Ereignisbusses zu integrieren. </font><font style="vertical-align: inherit;">Wir haben jedoch bestimmte Anforderungen an unser neues System:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir möchten keine Leistungseinbußen bei der Verarbeitung des Hauptereignisbusses erzielen</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Für uns ist es wichtig, die Reihenfolge der Nachrichtenverarbeitung im neuen System beizubehalten, da dies möglicherweise mit der Geschäftslogik des Kunden zusammenhängt, der die Automatisierung einrichtet</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vermeiden Sie die Auswirkungen von lauten Nachbarn, wenn aktive Seiten mit einer großen Anzahl von Abonnenten die Warteschlange verstopfen und die Verarbeitung von Ereignissen "kleiner" Seiten blockieren</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir die Verarbeitung unserer Logik in die Verarbeitung eines gemeinsamen Ereignisbusses integrieren, wird die Leistung erheblich beeinträchtigt, da jedes Ereignis auf Übereinstimmung mit der konfigurierten Automatisierung überprüft werden muss. </font><font style="vertical-align: inherit;">Im Rahmen des Automatisierungs-Setups können bestimmte Filter angewendet werden (z. B. die Automatisierung starten, wenn ein Ereignis nur für weibliche Kunden ausgelöst wird, die älter als 30 Jahre sind). </font><font style="vertical-align: inherit;">Das heißt, wenn Ereignisse im Hauptbus verarbeitet werden, wird eine große Anzahl zusätzlicher Anforderungen an die Datenbank verarbeitet, und es wird auch eine ziemlich schwere Logik gestartet, die den aktuellen Teilnehmerkontext mit den Automatisierungseinstellungen vergleicht. </font><font style="vertical-align: inherit;">Diese Option passt nicht zu uns, deshalb haben wir weiter nachgedacht.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/xt/rq/in/xtrqingjirs1ne1ljopat1z-nti.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Organisation einer Kaskade von Warteschlangen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da unsere mit dem ereignisbasierten System verknüpfte Geschäftslogik sehr gut von der Logik zur Verarbeitung von Ereignissen vom Hauptbus zu trennen ist, entscheiden wir uns, die vom gemeinsam genutzten Bus benötigten Ereignistypen für die weitere Verarbeitung in einem separaten Datenstrom in eine separate Warteschlange zu stellen. Somit beseitigen wir das Problem, das mit einer Verschlechterung der Leistung bei der Verarbeitung des Hauptereignisbusses verbunden ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gleichzeitig entscheiden wir, was es cool wäre, Ereignisse in die nächste Kaskadenwarteschlange zu übertragen, um diese Ereignisse für jeden Bot in separate Warteschlangen zu stellen. So isolieren wir die Aktivität jedes Bots mit dem Rahmen seiner Runde, wodurch wir das Problem lösen können, das mit der Wirkung von lauten Nachbarn verbunden ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unser Datenflussdiagramm sieht nun folgendermaßen aus:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/he/nz/2c/henz2cmwi9i5ii7pmzew-hokd3g.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Damit dieses Schema funktioniert, müssen wir jedoch das Problem der Verarbeitung neuer Warteschlangen lösen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auf unserer Plattform befinden sich mehr als 1 Million verbundene Seiten (Bots). Dies bedeutet, dass wir möglicherweise nur auf der Ebene der ereignisbasierten Ebene ~ 1 Million Warteschlangen in unserem Schema erhalten können. </font><font style="vertical-align: inherit;">Aus technischer Sicht ist dies für uns nicht beängstigend. </font><font style="vertical-align: inherit;">Als Warteschlangenserver verwenden wir Redis mit seinen Standarddatentypen wie LIST, SORTED SET und anderen. </font><font style="vertical-align: inherit;">Dies bedeutet, wer jede Warteschlange ist die Standarddatenstruktur für Redis im RAM, die im laufenden Betrieb erstellt oder gelöscht werden kann, wodurch wir eine große Anzahl von Warteschlangen in unserem System einfach und flexibel betreiben können. </font><font style="vertical-align: inherit;">Ich werde in einem separaten Beitrag ausführlicher auf die Verwendung von Redis als Warteschlangenserver mit technischen Details eingehen, aber jetzt kehren wir zu unserer Architektur zurück.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es ist klar, dass jeder Bot eine andere Aktivität hat und dass die Wahrscheinlichkeit, 1 Million Warteschlangen im Status "Jetzt verarbeiten müssen" zu erhalten, äußerst gering ist. </font><font style="vertical-align: inherit;">Aber zu einem bestimmten Zeitpunkt ist es durchaus möglich, dass wir einige Zehntausende aktive Warteschlangen haben, die verarbeitet werden müssen. </font><font style="vertical-align: inherit;">Die Anzahl dieser Warteschlangen ändert sich ständig. </font><font style="vertical-align: inherit;">Diese Warteschlangen selbst ändern sich ebenfalls, einige werden vollständig subtrahiert und gelöscht, einige werden dynamisch erstellt und mit Ereignissen zur Verarbeitung gefüllt. </font><font style="vertical-align: inherit;">Dementsprechend müssen wir einen effektiven Weg finden, um damit umzugehen.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verarbeitung eines riesigen Pools von Warteschlangen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben also eine Reihe von Warteschlangen. Zu jedem Zeitpunkt kann es eine zufällige Menge geben. Eine wichtige Bedingung für die Verarbeitung jeder Warteschlange, die zu Beginn seines Beitrags erwähnt wurde, ist, dass Ereignisse auf jeder Seite streng nacheinander verarbeitet werden sollten. Dies bedeutet, dass zu einem bestimmten Zeitpunkt nicht jede Warteschlange von mehr als einem Mitarbeiter verarbeitet werden kann, um Wettbewerbsprobleme zu vermeiden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Verhältnis von Warteschlangen zu Handlern 1: 1 zu machen, ist jedoch eine zweifelhafte Aufgabe. Die Anzahl der Warteschlangen ändert sich ständig, sowohl nach oben als auch nach unten. Die Anzahl der ausgeführten Handler ist ebenfalls nicht unendlich, zumindest haben wir eine Einschränkung seitens des Betriebssystems und der Hardware, und wir möchten nicht, dass Mitarbeiter in leeren Warteschlangen untätig bleiben. Um das Problem der Interaktion zwischen Handlern und Warteschlangen zu lösen, haben wir ein Round-Robin-System implementiert, um unseren Warteschlangenpool zu verarbeiten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und hier kam uns die Kontrolllinie zu Hilfe.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/wg/rx/yp/wgrxypigmbunxgzyc_hkgqfodjq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn das Ereignis vom gemeinsam genutzten Bus an die ereignisbasierte Warteschlange eines bestimmten Bots weitergeleitet wird, wird auch die Kennung dieser Bot-Warteschlange in die Steuerwarteschlange gestellt. In der Steuerwarteschlange werden nur die Kennungen der Warteschlangen gespeichert, die sich im Pool befinden und verarbeitet werden müssen. In der Steuerwarteschlange werden nur eindeutige Werte gespeichert, dh dieselbe Bot-Warteschlangen-ID wird nur einmal in der Steuerwarteschlange gespeichert, unabhängig davon, wie oft sie dort geschrieben wird. Auf Redis wird dies mithilfe der Datenstruktur SORTED SET implementiert.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ferner können wir eine bestimmte Anzahl von Arbeitern unterscheiden, von denen jeder von der Kontrollwarteschlange seine Kennung der Bot-Warteschlange zur Verarbeitung erhält. Somit verarbeitet jeder Mitarbeiter den Block unabhängig von der ihm zugewiesenen Warteschlange. Nach der Verarbeitung des Blocks gibt er die Kennung der verarbeiteten Warteschlange an das Steuerelement zurück und gibt sie damit an unser Round Robin zurück. Die Hauptsache ist, nicht zu vergessen, das Ganze mit Sperren zu versehen, damit zwei Arbeiter nicht dieselbe Bot-Warteschlange parallel verarbeiten können. Diese Situation ist möglich, wenn die Bot-ID in die Steuerwarteschlange eingeht, wenn sie bereits vom Worker verarbeitet wird. Für Sperren verwenden wir auch Redis als Schlüssel: Wertspeicher mit TTL.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir eine Aufgabe mit einer Bot-Warteschlangen-ID aus der Steuerwarteschlange übernehmen, setzen wir eine TTL-Sperre für die genommene Warteschlange und beginnen mit der Verarbeitung. </font><font style="vertical-align: inherit;">Wenn der andere Verbraucher die Aufgabe mit der Warteschlange übernimmt, die bereits aus der Steuerwarteschlange verarbeitet wird, kann er nicht sperren, die Aufgabe an die Steuerwarteschlange zurückgeben und die nächste Aufgabe empfangen. </font><font style="vertical-align: inherit;">Nachdem der Verbraucher die Bot-Warteschlange verarbeitet hat, hebt er die Sperre auf und wechselt zur Steuerungswarteschlange für die nächste Aufgabe. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das endgültige Schema lautet wie folgt: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/it/jh/bl/itjhblg3hv1urwu_8gx3fhuj8wq.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis haben wir mit dem aktuellen Schema die wichtigsten identifizierten Probleme gelöst:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Leistungsabfall im Hauptereignisbus</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verstoß gegen die Ereignisbehandlung</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Wirkung von lauten Nachbarn</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie gehe ich mit dynamischer Last um?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Schema funktioniert, aber darin haben wir eine feste Anzahl von Verbrauchern für eine dynamische Anzahl von Warteschlangen. Offensichtlich werden wir bei diesem Ansatz bei der Verarbeitung von Warteschlangen jedes Mal durchhängen, wenn ihre Anzahl stark zunimmt. Es scheint schön für unsere Mitarbeiter zu sein, bei Bedarf dynamisch zu starten oder zu löschen. Es wäre auch schön, wenn dies die Einführung von neuem Code nicht wesentlich erschweren würde. In solchen Momenten juckt es die Hände sehr, Ihren Prozessmanager zu schreiben. In Zukunft haben wir genau das getan, aber diese Geschichte ist anders.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir überlegten, warum wir nicht noch einmal alle bekannten und vertrauten Werkzeuge verwenden sollten. Also haben wir unsere interne API erhalten, die an einem Standardpaket von NGINX + PHP-FPM funktioniert. Infolgedessen können wir unseren festen Pool von Mitarbeitern durch APIs ersetzen und NGINX + PHP-FPM die Mitarbeiter selbst auflösen und verwalten lassen. Es reicht aus, zwischen der Kontrollwarteschlange und unserer internen API nur einen Kontrollkonsumenten zu haben, der Warteschlangenkennungen an unsere API sendet Verarbeitung, und die Warteschlange selbst wird in dem von PHP-FPM ausgelösten Worker verarbeitet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das neue Schema war wie folgt:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/-l/a9/7p/-la97p-usddzj76y4c8grd8gbxa.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es sieht gut aus, aber unser Kontrollkonsument arbeitet in einem Thread und unsere API arbeitet synchron. </font><font style="vertical-align: inherit;">Dies bedeutet, dass der Verbraucher jedes Mal hängen bleibt, während PHP-FPM eine Warteschlange schleift. </font><font style="vertical-align: inherit;">Das passt nicht zu uns.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unsere API asynchron machen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was aber, wenn wir eine Aufgabe an unsere API senden und sie dort die Geschäftslogik dreschen lassen könnten und unser Kontrollkonsument der nächsten Aufgabe in der Kontrollwarteschlange folgt, wonach sie zurück in die API gezogen wird, und so weiter. </font><font style="vertical-align: inherit;">Gesagt, getan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Implementierung dauert einige Codezeilen, und der Proof of Concept sieht folgendermaßen aus:</font></font><br>
<br>
<pre><code class="php hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Api</span> </span>{
    	<span class="hljs-keyword">public</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">actionDoSomething</span>(<span class="hljs-params"></span>)
    	</span>{<font></font>
    		$data = $_POST;<font></font>
    		<span class="hljs-keyword">$this</span>-&gt;dropFPMSession();
    		<span class="hljs-comment">// ,        , &nbsp;   </span>
    		<span class="hljs-comment">//     </span><font></font>
    	}<font></font>
    <font></font>
    <font></font>
    	<span class="hljs-keyword">protected</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">dropFPMSession</span>(<span class="hljs-params"></span>)
    	</span>{<font></font>
    		ignore_user_abort(<span class="hljs-literal">true</span>); 
    		<span class="hljs-comment">//          </span>
    		ob_end_flush(); <span class="hljs-comment">//  </span>
    		flush(); <span class="hljs-comment">//  </span>
    		@session_write_close(); <span class="hljs-comment">// </span><font></font>
    	<font></font>
    		fastcgi_finish_request(); <font></font>
    		<span class="hljs-comment">//          </span><font></font>
    	}<font></font>
    }</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In der dropFPMSession () -Methode unterbrechen wir die Verbindung mit dem Client und geben ihm eine Antwort von 200, wonach wir jede schwere Logik in der Nachbearbeitung ausführen können. </font><font style="vertical-align: inherit;">Der Kunde ist in unserem Fall der Kontrollverbraucher. </font><font style="vertical-align: inherit;">Für ihn ist es wichtig, Aufgaben schnell aus der Steuerwarteschlange in die Verarbeitung auf der API zu verteilen und zu wissen, dass die Aufgabe die API erreicht hat. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit diesem Ansatz haben wir eine Reihe von Kopfschmerzen beseitigt, die mit der dynamischen Steuerung der Verbraucher und ihrer automatischen Skalierung verbunden sind.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Weiter skalierbar</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Infolgedessen bestand die Architektur unseres Subsystems aus drei Schichten: Datenschicht, Prozesse und interne API. Gleichzeitig durchlaufen Informationen alle Datenströme darüber, zu welchem ​​Bot das verarbeitete Ereignis / die verarbeitete Aufgabe gehört. Natürlich können wir unsere Schlüssel- / Bot-ID zum Sharding verwenden und gleichzeitig unser System horizontal skalieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir uns unsere Architektur als solide Einheit vorstellen, sieht sie folgendermaßen aus: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/bb/mw/en/bbmwendsu4hnp_xymwqnulblwvc.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir die Anzahl solcher Einheiten erhöht haben, können wir einen dünnen Balancer vor sie stellen, der unsere Ereignisse / Aufgaben abhängig vom Sharding-Schlüssel in die erforderlichen Einheiten wirft. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/wf/1g/sk/wf1gsktxy1iqdp_jhqougdnfkuw.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Somit erhalten wir einen großen Spielraum für die horizontale Skalierung unseres Systems.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei der Implementierung der Geschäftslogik sollten Sie das Thread-Sicherheitskonzept nicht vergessen, da Sie sonst unerwartete Ergebnisse erzielen können. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein solches Schema mit Kaskaden von Warteschlangen und der Entfernung schwerer Geschäftslogik in die asynchrone Verarbeitung wird seit mehr als zwei Jahren in mehreren Teilen des Systems verwendet. </font><font style="vertical-align: inherit;">Die Last während dieser Zeit für jedes der Subsysteme hat sich verzehnfacht, und die vorgeschlagene Implementierung ermöglicht es uns, einfach und schnell zu skalieren. </font><font style="vertical-align: inherit;">Gleichzeitig arbeiten wir weiter an unserem Hauptstapel, ohne ihn mit neuen Tools / Sprachen zu erweitern und ohne ihn zu erhöhen, wodurch die Einführung und Unterstützung neuer Tools überflüssig wird.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de492948/index.html">Treffen Sie aufschieben</a></li>
<li><a href="../de492952/index.html">Zurück in die Zukunft mit dem Java Developer Course</a></li>
<li><a href="../de492956/index.html">Spieler sind niemals Ex. Schöne Erinnerungen und verbotene Freuden - in einer Umfrage von DataArt</a></li>
<li><a href="../de492958/index.html">Automatisiertes rekursives Computing</a></li>
<li><a href="../de492962/index.html">Mein autonomes Quarantäne-Überlebenskit</a></li>
<li><a href="../de492966/index.html">Zum ersten Mal wurde ein Photon von einem Chip zum anderen teleportiert</a></li>
<li><a href="../de492968/index.html">In Erinnerung an Freeman Dyson wurde das Genie der Mathematik zu einem technologischen Visionär</a></li>
<li><a href="../de492970/index.html">Wie TeamViewer Passwörter speichert</a></li>
<li><a href="../de492972/index.html">Wie die Haut mit Feuchtigkeit versorgt wird und was passiert, wenn Sie Ihre Hände mit COVID-19 manuell mit Alkohol waschen</a></li>
<li><a href="../de492978/index.html">So bestellen Sie ein ausgelagertes IT-Produktvideo und erhalten das, was Sie benötigen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
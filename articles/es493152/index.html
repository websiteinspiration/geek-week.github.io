<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåÑ üõåüèº üë©üèº‚Äçü§ù‚Äçüë®üèø Redes neuronales y miner√≠a de procesos: tratando de hacer amigos ‚õπüèæ ü§òüèº üì´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Process Mining es un campo de an√°lisis de datos que le permite analizar procesos basados ‚Äã‚Äãen los registros de los sistemas de informaci√≥n. Como hay m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Redes neuronales y miner√≠a de procesos: tratando de hacer amigos</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/493152/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Process Mining es un campo de an√°lisis de datos que le permite analizar procesos basados ‚Äã‚Äãen los registros de los sistemas de informaci√≥n. Como hay muy pocas publicaciones sobre el tema del uso del aprendizaje autom√°tico en este campo en Habr√©, decidimos compartir nuestra experiencia en el desarrollo de modelos predictivos para resolver problemas orientados a procesos. Como parte del programa VTB, un junior de TI para profesionales de TI principiantes, los pasantes del equipo de miner√≠a de procesos probaron los m√©todos de aprendizaje autom√°tico en el contexto de las tareas de investigaci√≥n de procesos bancarios. Debajo del corte, hablaremos sobre cu√°ndo y c√≥mo tuvimos la idea de resolver tales problemas, qu√© hicimos y qu√© resultados obtuvimos.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6n/hi/lg/6nhilgitc0hyxrpmzuypu6w0irg.jpeg"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
IT Junior Program es un programa de pasant√≠as anual para profesionales de TI principiantes en VTB Bank, que comenz√≥ en septiembre de 2019. </font><font style="vertical-align: inherit;">La pasant√≠a dura seis meses. </font><font style="vertical-align: inherit;">Seg√∫n los resultados del programa de 2019, m√°s de la mitad de los pasantes se unieron al personal y se convirtieron en empleados de la empresa. </font><font style="vertical-align: inherit;">Puede encontrar m√°s informaci√≥n sobre el programa, el inicio de la selecci√≥n y los requisitos para los candidatos </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqu√≠</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">As√≠ es como los aprendices de este programa abordaron las tareas del banco. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el sistema de coordenadas cl√°sico, para comprender y formalizar el proceso, es necesario:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">realizar una entrevista con empleados;</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analizar los informes y la documentaci√≥n disponibles.</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el enfoque de Process Mining, se forma un modelo de proceso digital basado no solo en la opini√≥n experta de los participantes del proceso, sino tambi√©n en datos relevantes de los sistemas de informaci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, obtenemos un modelo digital objetivo del proceso, que es un reflejo del movimiento de datos reales en los sistemas de TI del proceso. El modelo resultante funciona en tiempo real y le permite mostrar el estado actual del proceso con el grado de detalle necesario. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En nuestro </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">art√≠culo</font></a><font style="vertical-align: inherit;"> anterior</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hablamos sobre nuestra plataforma de Process Mining y las tareas reales del Banco, que se resuelven con su ayuda. </font><font style="vertical-align: inherit;">La soluci√≥n implementada nos permiti√≥ reducir significativamente el tiempo requerido para preparar informes obligatorios para las agencias gubernamentales, y tambi√©n ayud√≥ a identificar y optimizar las imperfecciones del proceso, para establecer una presentaci√≥n diaria del estado actual de las compras en el trabajo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Posteriormente, nuestros clientes tuvieron la necesidad no solo de determinar cualitativamente el estado actual del proceso, sino tambi√©n de predecir sus condiciones futuras.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A continuaci√≥n, describiremos paso a paso c√≥mo resolvimos el problema de predecir la duraci√≥n del proceso de adquisici√≥n (usando el conjunto de datos BPI Challenge 2019 como ejemplo) usando un conjunto de eventos bien conocidos usando la estaci√≥n DGX de alto rendimiento, amablemente proporcionada por NVIDIA para la investigaci√≥n.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aplicaci√≥n de aprendizaje autom√°tico para miner√≠a de procesos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para resolver el problema, construimos una l√≠nea de base usando CatBoostRegressor, y luego desarrollamos una soluci√≥n con una red neuronal e incrustando variables categ√≥ricas. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debido a la presencia de caracter√≠sticas categ√≥ricas y materiales en los datos de origen, se decidi√≥ utilizar el refuerzo, que podr√≠a procesar caracter√≠sticas categ√≥ricas sin codificaci√≥n, y tambi√©n resolver el problema en una entrada discreta y material. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las redes se usaron para construir atributos completamente materiales y resolver el problema en todo el material de entrada, y luego comparar estos dos enfoques y decidir si molestarse con las redes.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descripci√≥n de datos</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se decidi√≥ utilizar datos externos que nos convengan en el √°rea de negocios y que posean un conjunto similar de caracter√≠sticas. </font><font style="vertical-align: inherit;">El conjunto de datos BPI Challenge 2019 usado incluye 250 mil casos, esto es 1.5 millones de eventos. </font><font style="vertical-align: inherit;">Los datos iniciales se describen mediante un conjunto de 21 signos: 18 categ√≥ricos (hay signos de √≠ndice), dos booleanos y uno real. </font><font style="vertical-align: inherit;">El tiempo de ejecuci√≥n del proceso de adquisici√≥n se seleccion√≥ como la variable objetivo, que correspond√≠a a las necesidades reales del negocio. </font><font style="vertical-align: inherit;">Para obtener una descripci√≥n detallada de las caracter√≠sticas, puede consultar la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">descripci√≥n del conjunto de datos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Base</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Antes del entrenamiento modelo, los datos se dividieron en muestras de entrenamiento (entrenamiento) y prueba (prueba) en la proporci√≥n de 0.8 / 0.2. Adem√°s, la divisi√≥n no se produjo seg√∫n los acontecimientos, sino seg√∫n los casos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para determinar qu√© tan apropiado es usar una soluci√≥n patentada compleja en forma de red neuronal, la l√≠nea de base se construy√≥ utilizando CatBoost, una biblioteca avanzada de aumento de gradiente en √°rboles de decisi√≥n. Para construir una l√≠nea de base, se realiz√≥ un preprocesamiento de datos m√≠nimo (codificaci√≥n de caracter√≠sticas categ√≥ricas con la frecuencia correspondiente en los datos), se desarroll√≥ una variable objetivo (duraci√≥n del caso) y una serie de nuevas caracter√≠sticas (adem√°s de las que ya est√°n en el conjunto de datos original):</font></font><br>
<br>
<ul>
<li>   .  ,        :      ,         ,     ,          ,   ,      .<br>
</li>
<li>Exponential Moving Average     . EMA     ,         .<br>
</li>
<li>     (, ,  ).<br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de entrenar al CatBoostRegressor en el conjunto de entrenamiento, obtuvimos el siguiente resultado: MAE (Error absoluto medio) = 17.5 d√≠as (es decir, el valor de la variable objetivo pronosticada es, en promedio, 17.5 d√≠as diferente del valor verdadero). Este resultado se us√≥ para probar la efectividad de una red neuronal.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uno de los detalles importantes aqu√≠ es el desarrollo de la variable objetivo para la l√≠nea de base.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tengamos un caso. Lo denotamos por c_i del conjunto C (el conjunto de todos los casos en nuestro conjunto de datos). Cada caso es una secuencia ordenada de eventos, es decir, c_i = (e_0, ‚Äã‚Äã..., e_ni), donde ni es la longitud del i-√©simo caso. Para cada evento, tenemos una marca de tiempo: la hora exacta en que comenz√≥. Con estos sellos temporales, puede calcular la duraci√≥n del caso sin el √∫ltimo evento. Sin embargo, asignar dicho objetivo a cada evento, es decir, hacer que la correspondencia ek ‚àà ‚Äã‚Äãci, ek ‚Üí ti (ti sea la duraci√≥n del i-√©simo caso), no es muy buena. En primer lugar, pueden ocurrir eventos similares (t√≠picos) en casos de diferentes duraciones. En segundo lugar, queremos predecir la duraci√≥n del caso a partir de una cierta subsecuencia (ordenada en el tiempo) de los eventos (esto est√° motivado por el hecho de que no conocemos toda la secuencia de eventos, es decir, no sabemos el caso antesc√≥mo sucedi√≥, pero queremos hacer una evaluaci√≥n de la duraci√≥n de todo el caso de acuerdo con algunos eventos conocidos (ocurridos) de este caso).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo tanto, debe dividir cada caso en subsecuencias de longitud de uno a la longitud del caso de eventos ordenados por tiempo, y asignar una variable objetivo igual a la duraci√≥n del caso del que se obtienen estas subsecuencias, es decir, las correspondencias ci ‚àà C, ci ‚Üí {sub_cj} ni (ni como antes, la longitud del i-√©simo caso), j = 1 y len (sub_cj) = j. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo tanto, dividimos cada caso en subsecuencias y asignamos la duraci√≥n de todo el caso a cada subsecuencia. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M√°s sobre subsecuencias</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Como se mencion√≥ anteriormente, dividimos el caso en subsecuencias y asignamos la duraci√≥n del caso a cada una de ellas. Vamos a utilizar el refuerzo que es exacto al tama√±o de los datos de entrada. Entonces ahora tenemos X = {{sub_c </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></sup><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> } </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ni </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k = 1</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> } </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t = 1 N</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , sub_c </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ik</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es la subsecuencia k-√©sima del caso i-√©simo, t </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es la longitud del caso i-√©simo, N es el n√∫mero de casos. Es decir, la dimensi√≥n [‚àë </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t = 1</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> n </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , sc, 17], </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sc</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es una variable igual a la longitud de la subsecuencia del caso correspondiente.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de codificar las variables categ√≥ricas por su frecuencia, tenemos variables reales y booleanas, as√≠ como variables categ√≥ricas codificadas (las variables de √≠ndice no se utilizar√°n en el proceso de aprendizaje). Tambi√©n podemos promediar valores sobre una subsecuencia, mientras que en las caracter√≠sticas categ√≥ricas obtenemos la frecuencia promedio de ocurrencia de valores categ√≥ricos, que tambi√©n puede considerarse como una caracter√≠stica que describe la agregaci√≥n de un subconjunto de eventos en un caso, es decir, como una caracter√≠stica que describe una subsecuencia. D√©jalo y mira qu√© pasa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de promediar sc sobre la dimensi√≥n, obtenemos la siguiente dimensi√≥n: [‚àë </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t = 1</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> n </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , 17]. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Construcci√≥n del modelo</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seg√∫n los casos, dividimos el tren en otro tren y muestra de validaci√≥n, tomamos un CatBoostRegressor con par√°metros predeterminados, pasamos una muestra de entrenamiento, validamos una muestra de validaci√≥n, tomamos la mejor iteraci√≥n, utilizamos MAE como m√©trica de validaci√≥n. Obtenemos lo siguiente (en la figura a continuaci√≥n) en la prueba (prepararemos la prueba por separado para la misma tuber√≠a en la que se construy√≥ el tren. Todas las se√±ales se basan en los datos que est√°n en la prueba, es decir, no tenemos se√±ales enfocadas en la variable objetivo. La √∫nica advertencia: Si las caracter√≠sticas categ√≥ricas en la prueba no cumplen con el valor que vimos en el tren, entonces consideramos la frecuencia de este valor en la prueba y actualizamos el diccionario para la codificaci√≥n). </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados de referencia</font></font></b><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/90b/f18/386/90bf183863f8ad2cdb50098c58d06a37.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
‚Ä¢ Iteraciones: 500. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚Ä¢ Tasa de aprendizaje: 0.1. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par√°metros de entrenamiento:</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚Ä¢ Tiempo de entrenamiento: menos de 2 minutos. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚Ä¢ Hierro: Tesla k80 (de colab). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Resultados: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚Ä¢ Prueba MAE: 17.5 d√≠as. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚Ä¢ La duraci√≥n promedio del caso en la prueba: 66.3 d√≠as.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Red neuronal</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparar</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para entrenar la red neuronal, se mejoraron los datos: se construyeron incrustaciones para variables categ√≥ricas y se ajust√≥ la distribuci√≥n de la variable objetivo. </font><font style="vertical-align: inherit;">Luego, la red neuronal fue entrenada en el NVIDIA Tesla K80 (Google Colab) y en la estaci√≥n NVIDIA DGX. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los siguientes resultados fueron obtenidos:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tiempo de entrenamiento en NVIDIA K80 (Google Colab): 20 minutos.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tiempo de entrenamiento en la estaci√≥n NVIDIA DGX: 8 minutos.</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El tiempo de entrenamiento de la red neuronal se debe a la diferencia en las caracter√≠sticas t√©cnicas de las GPU utilizadas:</font></font><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA Tesla K80 (Google Colab)</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA DGX Station</font></font><br>
</td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1X NVIDIA Tesla K80 12GB</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4X NVIDIA Tesla V100 32GB</font></font><br>
</td>
</tr>
</tbody></table></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preprocesamiento</font></font></h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nuevos signos</font></font></b><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">EMA sobre el valor del evento: queremos captar la tendencia en el costo de las actividades para cada caso.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tipo de falla: en la descripci√≥n del conjunto de datos puede encontrar informaci√≥n sobre cuatro tipos de algunas estad√≠sticas descriptivas de la compra (evento): estos tipos se dividen en los valores de dos variables en el conjunto de datos original. </font><font style="vertical-align: inherit;">Simplemente lo agregamos nuevamente (si observa la descripci√≥n del conjunto de datos, quedar√° claro de qu√© estamos hablando).</font></font><br>
</li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Signos categ√≥ricos</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Simplemente codificamos los valores √∫nicos de los signos categ√≥ricos con n√∫meros naturales en orden, para que luego podamos ense√±ar incrustaciones. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Incorporaciones para variables categ√≥ricas</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Determinamos la dimensi√≥n de las incorporaciones para cada variable categ√≥rica:</font></font><br>
<br>
<ul>
<li>,   ÃÜ  ÃÜ ÃÜ.    ÃÜ ,         ÃÜ  ÃÜ ,    ÃÜ,  .  : MUi&nbsp; = min(CAT_EMBEDDING_DIM; (len(uniquei) + 1) // 2), CAT_EMBEDDING_DIM ‚Äî , uniquei ‚Äî   i-  .<br>
</li>
<li> ,      3,       i-ÃÜ ÃÜ   max(3;MUi)+1,  1,        ,     train,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">unk</a>-.<br>
</li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ajustamos la distribuci√≥n del objetivo en la muestra del tren. La</font></font></b>&nbsp;<br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
distribuci√≥n inicial result√≥ ser muy desplazada hacia la izquierda debido a valores at√≠picos (casos que duraron 250 mil d√≠as) y una gran cantidad de casos cortos, por lo que contamos los percentiles 0.05 y 0.95 y dejamos los datos del tren con el objetivo entre Estos r√°pidos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de eso, todav√≠a tenemos casos que duran aproximadamente uno y aproximadamente 100 d√≠as, es decir, la variable objetivo pasa por varios √≥rdenes de magnitud. Por lo tanto, la suposici√≥n de que la varianza es constante en la distribuci√≥n de la variable objetivo alrededor del algoritmo de decisi√≥n apenas se cumple, es decir, la distribuci√≥n de la variable objetivo es cercana a la normal, pero la varianza no es constante debido al hecho de que la variable objetivo puede ser menor que 1 o mayor que 100. Por lo tanto, al menos De alguna manera nivelar este efecto, normalizamos los datos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El resultado se muestra en el siguiente gr√°fico (la l√≠nea negra es la distribuci√≥n normal).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/k4/qs/vz/k4qsvz1egedfnm9q4y6nljidoam.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Luego dividimos por caso nuestros datos en tren y validaci√≥n. </font><font style="vertical-align: inherit;">Tambi√©n hay un matiz obvio aqu√≠: normalizamos el objetivo con el promedio y la desviaci√≥n, calculados de acuerdo con todos los datos, y luego dividimos por tren y validaci√≥n, es decir, resulta como una cara en el tren, pero como resolvemos un problema auxiliar aqu√≠, esta cara no parece cr√≠tico.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se√±ales de construcci√≥n</font></font></h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Idea</font></font></b><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Solo tomamos signos categ√≥ricos de nuestro tren, codificados por n√∫meros naturales.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No tomamos subcadenas de casos, sino simplemente eventos, es decir, una l√≠nea en nuestros datos para incrustaciones es un evento caracterizado por caracter√≠sticas categ√≥ricas codificadas.</font></font><br>
</li>
<li> :     ,   ÃÜ,      ,   ,        ,            ÃÜ  ÃÜ    ÃÜ. - ,         ÃÜ,  ,  ,     ÃÜ (    ),      (     ,  - ÃÜ  ).<br>
</li>
<li>       ÃÜ        .<br>
</li>
<li>     ,     8-ÃÜÃÜ   elu   ÃÜ,   (  ,   ,     ,  L2-)     .<br>
</li>
<li>,           , ‚Äî    ,      ,    .<br>
</li>
<li>Summary:    ‚Äî ÃÜ  ÃÜ ÃÜ ÃÜ        ‚Äî  ÃÜ.<br>
</li>
</ul><br>
<h3>   </h3><br>
<ul>
<li>Batch size = 1000</li>
<li>Learning rate = 3e-04.</li>
<li>  = 15.</li>
<li>: Tesla k80 (colab) + Nvidia DGX Station .</li>
<li> (colab) ‚Äì 50 .</li>
<li> (Nvidia DGX Station) ‚Äî 18 .</li>
</ul><br>
<img src="https://habrastorage.org/webt/53/4y/gh/534yghkinehatjl8cm1xwg5j0oi.png"><br>
<br>
<h3> </h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparaci√≥n de datos</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ahora tenemos incrustaciones para variables categ√≥ricas (aqu√≠ hay un matiz: honestamente tomamos valores √∫nicos de variables categ√≥ricas en nuestro tren (no en el que asignamos para incrustaciones de entrenamiento, sino en el que asignamos al principio para entrenamiento), por lo tanto, existe la posibilidad de que en los datos de la prueba haya un valor de variables categ√≥ricas que no vimos en el tren, es decir, no tenemos una inclusi√≥n entrenada para este valor.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para tales valores, se crea una l√≠nea separada en las matrices de inclusi√≥n, pero en nuestro caso el problema es que durante el entrenamiento no est√° involucrado y, por lo tanto, no estudia. En base a esto, si cumplimos con un valor de una variable categ√≥rica que no se hab√≠a visto antes, entonces tomamos este vector, pero de hecho simplemente se toma de la distribuci√≥n de inicializaci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En c√≥mo entrenar este vector, hay una direcci√≥n para mejorar el modelo. La idea es que valores muy raros en el tren pueden codificarse con este vector, porque si vemos un nuevo valor solo en la prueba, que constituye condicionalmente el 20% de la muestra inicial completa, entonces este valor es raro y probablemente se comporta lo mismo que valores raros en el tren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En cada caso, reemplazamos las variables categ√≥ricas con la incrustaci√≥n correspondiente, nos conectamos con los atributos real y booleano, obtenemos una matriz de tama√±o [N, F], donde F es la suma de las dimensiones de las incrustaciones para las variables categ√≥ricas, el n√∫mero de atributos reales y booleanos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Realizamos una agrupaci√≥n de eventos en una subsecuencia (como se hizo anteriormente). </font><font style="vertical-align: inherit;">La variable objetivo para la subsecuencia es la duraci√≥n del caso del que se obtuvo la subsecuencia. </font><font style="vertical-align: inherit;">Agregue el n√∫mero de eventos y la suma de los costos de los eventos en esta subsecuencia al vector de la subsecuencia. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora tenemos una matriz de un tama√±o fijo: puede alimentar el modelo (antes de eso normalizamos la matriz). </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M√©todo de paralelizaci√≥n</font></font></b><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hacemos una torre para cada gpu.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En cada paso, dividimos los par√°metros entre las torres.</font></font><br>
</li>
<li>       .<br>
</li>
<li> ÃÜ   ,   .<br>
</li>
<li>       (      ,       ÃÜ ÃÜ         ).<br>
</li>
<li>        .<br>
</li>
<li>     ,   -  (   ,  word2vec-style,     ).<br>
</li>
</ul><br>
<b></b><br>
<br>
<ul>
<li>          ()   ()  ().<br>
</li>
<li>ÃÜ :   ‚Äî   ,     gpu     ,    ,   gpu     .<br>
</li>
</ul><br>
<b></b><br>
<br>
<ul>
<li>: 7-ÃÜÃÜ    elu.<br>
</li>
<li>   ÃÜ ,    .<br>
</li>
<li>Batch size = 1000.<br>
</li>
<li>Learning rate = 3e-04.<br>
</li>
<li>  = 15.<br>
</li>
<li>: Tesla k80 (colab) + Nvidia DGX Station.<br>
</li>
<li> (colab) = 20 .<br>
</li>
<li> (Nvidia DGX Station) = 8 .<br>
</li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una parte del modelo de gr√°fico. </font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/u5/4e/3e/u54e3eoth5n5kmcdryndbpqgcua.jpeg"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Consumo de recursos y paralelizaci√≥n.</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
El entrenamiento de la red neuronal en una CPU requiere aproximadamente cuatro veces m√°s tiempo que en una estaci√≥n NVIDIA DGX. En este caso, la diferencia parece insignificante: ocho minutos en la estaci√≥n NVIDIA DGX y 32 minutos en la CPU. Sin embargo, este es un modelo peque√±o con una peque√±a cantidad de datos. Al implementar proyectos reales, donde habr√° varias veces m√°s casos y eventos, la capacitaci√≥n en la CPU tomar√° al menos una semana. En este caso, el uso de la estaci√≥n NVIDIA DGX reducir√° el tiempo de capacitaci√≥n a dos d√≠as, lo que aumentar√° en gran medida la eficiencia del trabajo.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tambi√©n se revel√≥ que la velocidad del proceso de aprendizaje depende en gran medida del n√∫mero de GPU utilizadas, lo que muestra la ventaja de la estaci√≥n NVIDIA DGX.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esto se confirma mediante experimentos anteriores en la CPU y GPU NVIDIA DGX Station utilizando el conjunto de datos original sin ning√∫n procesamiento preliminar:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tiempo de aprendizaje en la CPU: 6 minutos y 18 segundos.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tiempo de entrenamiento en GPU: 34 segundos.</font></font><br>
</li>
</ul><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><b><font style="vertical-align: inherit;">Visualizaci√≥n de carga de </font></b><b><font style="vertical-align: inherit;">GPU </font></b></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/6f1/015/d82/6f1015d82101dda1e0af40e599ee96a2.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualizaci√≥n de carga de CPU</font></font></b><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/efe/3ae/f3b/efe3aef3b801dcbd14655b3851ae9ad3.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados de la red neuronal</font></font></h3><br>
<img src="https://habrastorage.org/webt/-g/2g/p1/-g2gp1o1sdktbwtspcurjfdiwqu.png"><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prueba MAE = 10 d√≠as.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La duraci√≥n promedio del caso en la prueba = 67 d√≠as.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tiempo de inferencia = 20 segundos.</font></font><br>
</li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recomendaciones</font></font></h2><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Implementamos un piloto para evaluar los m√©todos de aprendizaje autom√°tico en el contexto de las tareas de Process Mining.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Probamos y ampliamos la lista de nuestras herramientas con las que resolveremos problemas que son importantes para los negocios.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uno de los resultados interesantes fue la redacci√≥n de nuestra propia implementaci√≥n de computaci√≥n paralela en 4 tarjetas Tesla v100 con las que est√° equipada la estaci√≥n DGX: el uso de varias GPU acelera el aprendizaje casi en l√≠nea desde la cantidad de GPU (el c√≥digo est√° en paralelo).</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La transici√≥n a una entrada totalmente continua y el uso de una red neuronal permiti√≥ tomar una semana fuera de la l√≠nea de base.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El tiempo aumenta de unos pocos minutos a una hora y media (capacitaci√≥n en arquitectura final y empotramientos, pero los empotramientos se pueden usar previamente entrenados, por lo que el tiempo se reduce a 20 minutos).</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los experimentos descritos muestran que en el campo de la miner√≠a de procesos, los algoritmos de m√°quina y aprendizaje profundo pueden aplicarse con √©xito. </font><font style="vertical-align: inherit;">Adem√°s, se revel√≥ que la velocidad del proceso de aprendizaje depende en gran medida del n√∫mero de GPU utilizadas, lo que muestra la ventaja de la estaci√≥n NVIDIA DGX.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu√© y c√≥mo se puede mejorar</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Incrustaciones de Word2vec para eventos</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Cuando creamos nuestro modelo, incluidas las incrustaciones de variables categ√≥ricas, no tomamos en cuenta la secuencia de eventos entre s√≠, es decir, la sem√°ntica peculiar de eventos dentro de los casos. </font><font style="vertical-align: inherit;">Para aprender algo √∫til del orden de los eventos dentro de los casos, debe entrenar incrustaciones para estos eventos. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Idea</font></font></b><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tomamos una caracter√≠stica categ√≥rica y una real, dividimos el real en un dep√≥sito, luego cada transacci√≥n se caracterizar√° por el valor de la variable categ√≥rica y el dep√≥sito en el que cae el valor de la variable real. </font><font style="vertical-align: inherit;">Combina estos dos valores, obtenemos, por as√≠ decirlo, un an√°logo de la palabra para el evento.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Consideramos el caso como una oraci√≥n (el conjunto de palabras en la oraci√≥n corresponde al conjunto de eventos en el caso).</font></font><br>
</li>
<li> ÃÜ      ,          ÃÜ   ÃÜ,    ,             .<br>
</li>
<li>   ÃÜ,     Skipgram  CBOW   .<br>
</li>
<li>  ,      ÃÜ,            .<br>
</li>
</ul><br>
<b> </b><br>
<br>
<ul>
<li>  Skipgram.<br>
</li>
<li>  ‚Äî 5.<br>
</li>
</ul><br>
<ul>
<li>Batch size = 1000.<br>
</li>
<li>Learning rate = 3e-04.<br>
</li>
<li>  = 10.<br>
</li>
<li>: Tesla k80 (colab) + Nvidia DGX Station.<br>
</li>
<li> (colab) ‚Äî 20 .<br>
</li>
<li> (Nvidia DGX Station) ‚Äî 8 .<br>
</li>
<li>Test MAE    : 10 ÃÜ.&nbsp;<br>
</li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Contar El</font></font></b><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/438/137/cb8/438137cb87ac22637e44a01da4a56dfc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
uso de las funciones de las incrustaciones aumenta un par de d√©cimas de d√≠a. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finalmente</font></font></b><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Las incrustaciones resultaron, por supuesto, sin educaci√≥n, porque entrenaron un poco.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hay alrededor de 290 caracter√≠sticas de incrustaciones categ√≥ricas y 20 caracter√≠sticas de incrustaciones sem√°nticas (no tiene m√°s sentido hacerlo porque el tama√±o del diccionario es peque√±o), por lo que la influencia de estas caracter√≠sticas sem√°nticas puede nivelarse debido a un desequilibrio en la proporci√≥n de caracter√≠sticas.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La sem√°ntica entre eventos debe agregarse de alguna manera al conjunto de entrenamiento, porque debido al hecho de que las secuencias de eventos (casos) est√°n ordenadas, el orden es importante y se puede extraer informaci√≥n de esto.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Puede utilizar arquitecturas m√°s sofisticadas para incrustaciones.</font></font><br>
</li>
<li>      ,       ,    ‚Äî     .<br>
</li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es493138/index.html">H√°blame: qu√© pueden hacer los bots de voz hoy</a></li>
<li><a href="../es493140/index.html">Las aventuras de Cipollino: Cuarentena IT Quest de Flant</a></li>
<li><a href="../es493142/index.html">"¬°Usemos Kubernetes!" Ahora tienes 8 problemas</a></li>
<li><a href="../es493146/index.html">Proyectos secundarios emocionantes que puedes hacer hoy</a></li>
<li><a href="../es493150/index.html">"Remoto" con un enrutador Cisco</a></li>
<li><a href="../es493158/index.html">Loghouse 0.3: la tan esperada actualizaci√≥n de nuestro sistema de registro en Kubernetes</a></li>
<li><a href="../es493160/index.html">C√≥mo mejoramos Smart Search en hh.ru en 2019: infograf√≠as</a></li>
<li><a href="../es493162/index.html">Una lista abierta de reuniones y conferencias en l√≠nea.</a></li>
<li><a href="../es493164/index.html">Resulta que el negocio en l√≠nea est√° sobreviviendo en el entorno actual. ¬øPor qu√©? ADN eliminado</a></li>
<li><a href="../es493166/index.html">Ontol: una selecci√≥n de art√≠culos sobre "burnout" [100+]</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🦕 🤛🏾 🏏 Classificação com várias etiquetas 📼 👨🏾‍🏫 ❔</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Olá, habrozhiteli! Decidimos citar um trecho do livro de Andrei Burkov , Machine Learning Without Extra Words , dedicado à classificação.
 
 Para desc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Classificação com várias etiquetas</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/488362/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/hm/vf/c_/hmvfc_yyxepplv1mj0crw1vu7pw.jpeg" align="left" alt="imagem"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Olá, habrozhiteli! </font><font style="vertical-align: inherit;">Decidimos citar um trecho do livro de Andrei Burkov </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, Machine Learning Without Extra Words</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , dedicado à classificação.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para descrever a imagem na figura, vários rótulos podem ser usados ​​simultaneamente: “floresta de coníferas”, “montanhas”, “estrada”. Se o número de valores possíveis para rótulos for grande, mas todos tiverem a mesma natureza que tags, cada amostra etiquetada poderá ser convertida em vários dados marcados, um para cada tag. Todos esses novos dados terão os mesmos vetores de recursos e apenas um rótulo. Como resultado, a tarefa se torna um problema de classificação em várias classes. Pode ser resolvido usando a estratégia “um contra todos”. A única diferença do problema usual de classificação multiclasse é a aparência de um novo hiperparâmetro: o limiar. Se a pontuação de similaridade para um rótulo estiver acima de um valor limite, esse rótulo será atribuído ao vetor de recurso de entrada. Nesse cenário, vários rótulos podem ser atribuídos a um vetor de característica.O valor limite é selecionado usando o conjunto de controle.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para resolver o problema de classificação com muitos rótulos, pode-se aplicar algoritmos que são naturalmente transformados em multiclasses (árvores de decisão, regressão logística, redes neurais, etc.). Eles retornam uma estimativa para cada classe, para que possamos definir um limite e atribuir vários rótulos a um vetor de recurso para o qual a pontuação de proximidade excede esse limite. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As redes neurais podem naturalmente ser treinadas em classificações de vários rótulos usando a entropia cruzada binária como uma função de custo. A camada de saída da rede neural, neste caso, possui um nó por rótulo. Cada nó na camada de saída possui uma função de ativação sigmóide. Assim, cada rótulo l é binário</font></font><img src="https://habrastorage.org/webt/2n/_n/mg/2n_nmgvuciuadryomnq3urrg1xw.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde l = 1, ..., L e i = 1, ..., N. A entropia cruzada binária determina a probabilidade de </font></font><img src="https://habrastorage.org/webt/lb/le/cf/lblecfgyuy23k8zvlasuajncsds.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a amostra xi ter o rótulo l, é definida como o </font></font><img src="https://habrastorage.org/webt/qd/1e/fx/qd1efxpmi6mmuhv_fhmsqpjgpi4.jpeg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
critério de Minimização - uma média simples de todos os membros da entropia cruzada binária em todas as amostras de treinamento e todas as suas tags. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nos casos em que o número possível de valores de rótulo é pequeno, você pode tentar converter o problema de classificação com muitos rótulos em um problema de classificação em várias classes. </font><font style="vertical-align: inherit;">Imagine o seguinte problema. </font><font style="vertical-align: inherit;">Você precisa atribuir dois tipos de etiquetas às imagens. </font><font style="vertical-align: inherit;">Os rótulos do primeiro tipo podem ter dois significados possíveis: { </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">foto, pintura</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> }; </font><font style="vertical-align: inherit;">marcas do segundo tipo podem ter três significados possíveis: { </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">retrato, paisagem, outros</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">} </font><font style="vertical-align: inherit;">Para cada combinação de duas classes de origem, você pode criar uma nova classe fictícia, por exemplo:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mz/px/zn/mzpxzn0rlrumwoql7gkk3no7ihk.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora temos os mesmos dados marcados, mas substituímos o conjunto de rótulos verdadeiros por um rótulo simulado com valores de 1 a 6. Na prática, essa abordagem fornece bons resultados quando não há muitas combinações possíveis de classes. Caso contrário, é necessário usar muito mais dados de treinamento para compensar o aumento no conjunto de classes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A principal vantagem dessa última abordagem é que os rótulos permanecem correlacionados, diferentemente dos métodos descritos acima, que prevêem cada rótulo independentemente um do outro. Em muitas tarefas, a correlação entre rótulos pode ser um fator significativo. Por exemplo, imagine que você deseja classificar o email como </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spam</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font><i><font style="vertical-align: inherit;">não </font></i><i><font style="vertical-align: inherit;">spam</font></i></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, e ao mesmo tempo que ordinário e importante. </font><font style="vertical-align: inherit;">Você provavelmente excluiria previsões como [ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spam, importante</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ].</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5 </font><font style="vertical-align: inherit;">Treinamento do conjunto</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os algoritmos fundamentais que abordamos no capítulo 3 têm suas limitações. Devido à sua simplicidade, às vezes eles não podem criar um modelo que seja eficaz o suficiente para sua tarefa. Nesses casos, você pode tentar usar redes neurais profundas. No entanto, na prática, redes neurais profundas exigem uma quantidade significativa de dados rotulados, que você pode não ter. Outra maneira de aumentar a eficácia de algoritmos simples de aprendizado é usar o </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">treinamento em conjunto</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O treinamento em conjunto é um paradigma de treinamento que se baseia no treinamento não apenas em um modelo super-correto, mas em um grande número de modelos com baixa precisão e combinando as previsões fornecidas por esses </font><font style="vertical-align: inherit;">modelos </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fracos</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para obter um </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">metamodelo</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mais correto </font><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelos com baixa precisão geralmente são treinados por </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">algoritmos de aprendizado fracos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que não são capazes de treinar modelos complexos e, portanto, mostram alta velocidade nos estágios de treinamento e previsão. Na maioria das vezes, o algoritmo de aprendizado da árvore de decisão é usado como o algoritmo fraco, que geralmente para de interromper o conjunto de treinamento após várias iterações. O resultado são árvores pequenas e não muito regulares, mas, como diz a idéia de treinar o conjunto, se as árvores não forem idênticas e cada árvore for pelo menos um pouco melhor do que a adivinhação aleatória, podemos obter alta precisão combinando um grande número dessas árvores. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para obter a previsão final para a entrada </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, as previsões de todos os modelos fracos são combinadas usando algum método de votação ponderada. </font><font style="vertical-align: inherit;">A forma específica de ponderar os votos depende do algoritmo, mas a essência não depende dele: se, coletivamente, modelos fracos prevêem que o email é spam, atribuímos </font><font style="vertical-align: inherit;">o rótulo de </font><i><font style="vertical-align: inherit;">spam </font></i></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> à amostra </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">
Os dois principais métodos de treinamento de conjuntos são </font><b><font style="vertical-align: inherit;">reforço</font></b><font style="vertical-align: inherit;"> e </font><b><font style="vertical-align: inherit;">ensacamento</font></b><font style="vertical-align: inherit;"> (agregação). </font><font style="vertical-align: inherit;">As traduções dos termos reforço e ensacamento são imprecisas e não estão acostumadas.</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.1 </font><font style="vertical-align: inherit;">Reforço e ensacamento</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O método de reforço é usar os dados de treinamento iniciais e criar iterativamente vários modelos usando um algoritmo fraco. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada novo modelo difere dos anteriores porque, construindo-o, um algoritmo fraco tenta "consertar" os erros cometidos pelos modelos anteriores. </font><font style="vertical-align: inherit;">O modelo final do conjunto é uma combinação desses muitos modelos fracos construídos iterativamente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A essência do empacotamento é criar muitas "cópias" dos dados de treinamento (cada cópia é ligeiramente diferente das outras) e, em seguida, aplicar um algoritmo fraco a cada cópia para obter vários modelos fracos e combiná-los. </font><font style="vertical-align: inherit;">Um algoritmo de aprendizado de máquina amplamente utilizado e eficiente, baseado na idéia de ensacamento, é uma </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">floresta aleatória</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.2 </font><font style="vertical-align: inherit;">Floresta aleatória</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O algoritmo de ensacamento “clássico” funciona da seguinte maneira. </font><font style="vertical-align: inherit;">B amostras aleatórias são criadas a partir do conjunto de treinamento existente </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(para cada b = 1, ..., B) e um </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo de </font></font><img src="https://habrastorage.org/webt/nd/ew/4z/ndew4zvx7r0jpeilfknakojmrbs.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">árvore de decisão </font><font style="vertical-align: inherit;">é construído </font><font style="vertical-align: inherit;">com base em cada amostra </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Para obter uma amostra </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para alguns b, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">é feita</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> uma </font><b><font style="vertical-align: inherit;">amostra com substituição</font></b><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Ou seja, primeiro uma amostra vazia é criada e, em seguida, uma amostra aleatória é selecionada no conjunto de treinamento e sua cópia exata é colocada </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, enquanto a própria amostra permanece no conjunto de treinamento original. </font><font style="vertical-align: inherit;">A seleção dos dados continua até que a condição seja cumprida.Como </font></font><img src="https://habrastorage.org/webt/se/au/-5/seau-5gwous1c1cshmrx8rwubig.jpeg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
resultado do treinamento, </font><font style="vertical-align: inherit;">são </font><font style="vertical-align: inherit;">obtidas </font><font style="vertical-align: inherit;">árvores de decisão </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B. </font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A previsão para a nova amostra </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , no caso de regressão, é determinada como a média de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> previsões</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/re/zp/mj/rezpmjqa9lo7w4dxvqd6njwwqcm.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ou por maioria de votos em caso de classificação.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A floresta aleatória tem apenas uma diferença do ensacamento clássico. Ele usa um algoritmo de aprendizado em árvore modificado que, com cada divisão no processo de aprendizado, verifica um subconjunto aleatório de recursos. Isso é feito para eliminar a correlação entre árvores: se um ou mais recursos tiverem uma grande capacidade preditiva, muitas árvores os escolherão para dividir dados. Isso levará ao aparecimento na "floresta" de um grande número de árvores correlacionadas. A correlação de sinal com alta capacidade preditiva impede que a precisão da previsão aumente. A alta eficiência do conjunto de modelos é explicada pelo fato de que bons modelos provavelmente concordam com a mesma previsão, e modelos ruins provavelmente não concordam e fornecerão previsões diferentes. A correlação tornará os modelos ruins mais propensos a concordar,o que distorcerá o padrão de votação ou afetará a média.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os hiperparâmetros mais importantes para o ajuste são o número de árvores B e o tamanho de um subconjunto aleatório de recursos que devem ser considerados para cada divisão. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A floresta aleatória é um dos algoritmos de aprendizado de conjunto mais usados. O que determina sua eficácia? O motivo é que, usando várias amostras do conjunto de dados original, reduzimos a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">variação do</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> modelo final. Lembre-se de que baixa variação significa uma fraca predisposição para </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">treinar novamente</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">A reciclagem ocorre quando o modelo tenta explicar pequenas variações no conjunto de dados porque o conjunto de dados é apenas uma pequena amostra de todos os possíveis exemplos do fenômeno que estamos tentando simular. </font><font style="vertical-align: inherit;">No caso de uma abordagem malsucedida à formação do conjunto de treinamento, alguns artefatos indesejáveis ​​(mas inevitáveis) podem cair nele: ruído, dados anormais e dados excessivamente ou insuficientemente representativos. </font><font style="vertical-align: inherit;">Ao criar várias amostras aleatórias com a substituição do conjunto de treinamento, reduzimos a influência desses artefatos.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.3 </font><font style="vertical-align: inherit;">Aumento de gradiente</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Outro algoritmo de treinamento de conjunto eficaz baseado na idéia de aumento é o aumento de gradiente. </font><font style="vertical-align: inherit;">Primeiro, considere o uso de aumento de gradiente na regressão. </font><font style="vertical-align: inherit;">Começaremos a construir um modelo de regressão eficaz com um modelo constante </font></font><img src="https://habrastorage.org/webt/7u/7x/jd/7u7xjdufljpsjwwu45j9_gkc3r0.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(como fizemos no ID3):</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/em/vj/bv/emvjbvtmptxl_d3bihzev4wbh7o.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, altere os rótulos em todas as amostras i = 1, ..., N no conjunto de treinamento:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/va/wc/ah/vawcahk0zsdpgnumh_bfjuozw_e.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
onde </font></font><img src="https://habrastorage.org/webt/rf/1x/pk/rf1xpkgfxmcivy-1tqpwv2vgroi.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">é chamado de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">restante</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e é o novo rótulo da amostra </font></font><img src="https://habrastorage.org/webt/dk/ey/2r/dkey2rj3yf-zkei2029wfa2ujso.jpeg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, usamos o conjunto de treinamento modificado com os resíduos em vez dos rótulos originais para criar um novo modelo da árvore de </font></font><img src="https://habrastorage.org/webt/mx/fw/um/mxfwumzpc5tq1wjpdate2rxra48.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">decisão.O modelo de reforço agora é definido como </font></font><img src="https://habrastorage.org/webt/cy/c2/vz/cyc2vz0tmrrihcm6kta_7rnwmui.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde α é a velocidade de aprendizado (hiperparâmetro). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, recalculamos os resíduos usando a Equação 7.2, substituímos os rótulos nos dados de treinamento novamente, ensinamos um novo modelo da árvore de decisão, </font></font><img src="https://habrastorage.org/webt/p4/wk/nl/p4wknlhlvwiqtr7zz7lx_y5oq3s.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">redefinimos o modelo de reforço à medida </font></font><img src="https://habrastorage.org/webt/n-/mn/ht/n-mnhtck0rar7pz4anzlbdc-bmo.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que repetimos o processo, até combinarmos o número máximo predeterminado </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M de</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> árvores.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos entender intuitivamente o que está acontecendo aqui. Ao calcular os resíduos, determinamos quão bem (ou mal) o objetivo de cada amostra de treinamento é previsto pelo modelo atual f. Em seguida, treinamos outra árvore para corrigir os erros do modelo atual (é por isso que usamos sobras em vez de rótulos reais) e adicionamos uma nova árvore ao modelo existente com algum peso α. Como resultado, cada nova árvore adicionada ao modelo corrige parcialmente os erros cometidos pelas árvores anteriores. O processo continua até que o número máximo M (outro hiperparâmetro) das árvores seja combinado.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, vamos tentar responder à pergunta por que esse algoritmo é chamado de aumento de gradiente. No aumento do gradiente, não calculamos o gradiente, diferentemente do que fizemos no capítulo 4, resolvendo o problema de regressão linear. Para ver as semelhanças entre aumento de gradiente e descida de gradiente, lembre-se do motivo pelo qual calculamos o gradiente em regressão linear: para descobrir a direção dos valores dos parâmetros para minimizar a função de custo do MSE. O gradiente mostra a direção, mas não mostra até onde ir nessa direção; portanto, em cada iteração, demos um pequeno passo e depois determinamos novamente a direção. O mesmo ocorre no aumento do gradiente, mas, em vez de calcular diretamente o gradiente, usamos sua estimativa na forma de resíduos: eles mostram como o modelo deve ser ajustado para reduzir o erro (residual).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No aumento de gradiente, três hiperparâmetros principais estão disponíveis para ajuste: o número de árvores, a velocidade do aprendizado e a profundidade das árvores. Todos os três afetam a precisão do modelo. A profundidade das árvores também afeta a velocidade de aprendizado e previsão: quanto menor a profundidade, mais rápido. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pode-se mostrar que o aprendizado por resíduos otimiza o modelo geral f para o padrão de erro padrão. Aqui você pode ver a diferença do ensacamento: aumentar reduz o viés (ou falta de educação) em vez da variação. Como resultado, o aumento está sujeito a reciclagem. No entanto, ajustando a profundidade e o número de árvores, a reciclagem pode ser amplamente evitada.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O aumento de gradiente é semelhante para tarefas de classificação, mas as etapas são ligeiramente diferentes. Considere o caso da classificação binária. Suponha que haja M árvores de decisão de regressão. Por analogia com a regressão logística, a previsão do conjunto de árvores de decisão é modelada usando a função sigmóide:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wy/pd/gw/wypdgwjjgpzuojrelehnadtdggc.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Onde </font></font><img src="https://habrastorage.org/webt/w6/3d/kb/w63dkbj3f9j-ik9hrhqbexyxtem.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">está a árvore de regressão. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E, novamente, como na regressão logística, ao tentar encontrar um modelo para maximizar </font></font><img src="https://habrastorage.org/webt/c4/lv/tt/c4lvttexfzr8disbsv1ph_drzka.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, o princípio da máxima verossimilhança é aplicado. Da mesma forma, para evitar o excesso numérico, maximizamos a soma dos logaritmos de probabilidade, em vez do produto da probabilidade. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O algoritmo começa com o modelo de constante inicial em </font></font><img src="https://habrastorage.org/webt/hn/7j/ep/hn7jepdxhudnxvjjgbulvfwtpyw.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que </font></font><img src="https://habrastorage.org/webt/gj/6s/f6/gj6sf6i874m3gq3_fbbxbkrudae.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Pode ser mostrado que essa inicialização é ideal para a função sigmóide.) Em seguida, a cada iteração m, uma nova árvore fm é adicionada ao modelo. Para encontrar a melhor árvore </font></font><img src="https://habrastorage.org/webt/b0/5w/rv/b05wrvcuk5hzvnrmkpebdnk_kxu.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para encontrar a melhor árvore </font></font><img src="https://habrastorage.org/webt/xm/u4/dp/xmu4dpm1hi3-podtuiayxggydti.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, a derivada parcial do </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo atual é </font><font style="vertical-align: inherit;">primeiro calculada </font><font style="vertical-align: inherit;">para cada i = 1, ..., N:</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wg/v_/oo/wgv_oogvmupu4q5j6g3rq7dphvk.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
onde f é o modelo do classificador de conjunto construído na iteração anterior m - 1. Para calcular </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, precisamos encontrar as derivadas de em </font></font><img src="https://habrastorage.org/webt/pv/pe/lb/pvpelb2jplsmq_jmkbdfyl-pzom.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">relação a f para todo i. </font><font style="vertical-align: inherit;">Observe que a </font></font><img src="https://habrastorage.org/webt/nk/zn/0l/nkzn0lh0l0brnzl_vh0xxlmttrq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">derivada em relação a f do termo correto na equação anterior é</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xx/en/iu/xxeniu2qr35ln17asbfk2fqb3sc.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, o conjunto de treinamento é transformado substituindo o rótulo original da </font></font><img src="https://habrastorage.org/webt/a1/fv/cu/a1fvcukqqvsu5wpv3x8i1zj5smc.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">derivada parcial correspondente </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e uma nova árvore é criada com base no conjunto de treinamento convertido.A </font></font><img src="https://habrastorage.org/webt/w1/8f/41/w18f41gto37doyvyakgs4np_fyy.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seguir, a etapa ideal de atualização é determinada </font></font><img src="https://habrastorage.org/webt/1n/cf/sj/1ncfsjxfe-tao3ep_csuw-s-arw.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">como:</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/co/qc/hw/coqchwpctxgy2ukbdwaybkouxx0.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No final da iteração m, atualizamos o modelo de conjunto </font></font><img src="https://habrastorage.org/webt/r7/ox/vy/r7oxvyc5mesbifpwfjtkcrtdr2q.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">adicionando uma nova árvore</font></font><img src="https://habrastorage.org/webt/s2/vp/u0/s2vpu0-7pmzuzv0n55f1z1fgktu.jpeg" alt="imagem"><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/vg/ar/qn/vgarqnddik0vjhxxfsesr1t5qs8.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As iterações continuam até que a condição m = M seja cumprida, após o qual o treinamento para e o modelo de conjunto f é obtido. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O aumento de gradiente é um dos mais poderosos algoritmos de aprendizado de máquina. </font><font style="vertical-align: inherit;">Não apenas porque cria modelos muito precisos, mas também porque é capaz de processar enormes conjuntos de dados com milhões de dados e recursos. </font><font style="vertical-align: inherit;">Como regra, é superior em precisão a uma floresta aleatória, mas devido à natureza consistente, pode aprender muito mais lentamente.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt488346/index.html">Instalando or-tools com SCIP e GLPK em um ambiente virtual Python 3.7 no Linux</a></li>
<li><a href="../pt488348/index.html">Webinar “Os dez principais desafios ágeis e como superá-los em uma hora” 17 de fevereiro às 20:00, horário de Moscou</a></li>
<li><a href="../pt488352/index.html">Comparação de custos de VDI: nuvem local versus nuvem pública</a></li>
<li><a href="../pt488356/index.html">Treinamento na Universidade Técnica Marítima do Estado de São Petersburgo para produtos Dassault Systèmes</a></li>
<li><a href="../pt488360/index.html">Mitos sobre big data e cultura digital</a></li>
<li><a href="../pt488366/index.html">E novamente sobre "Informações incorretas de fuso horário para fusos horários russos" [.Net bug, ID: 693286]</a></li>
<li><a href="../pt488368/index.html">O que aprendi enquanto trabalhava no meu primeiro projeto em larga escala</a></li>
<li><a href="../pt488370/index.html">TDD para microcontroladores. Parte 2: Como os espiões se livram dos vícios</a></li>
<li><a href="../pt488374/index.html">Telegrama + 1C + Webhooks + Apache + Certificado autoassinado</a></li>
<li><a href="../pt488376/index.html">Quando o princípio "para o inferno com tudo, pegue e faça!" não funciona: notas de procrastinador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ï ü§õüèæ üèè Classifica√ß√£o com v√°rias etiquetas üìº üë®üèæ‚Äçüè´ ‚ùî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√°, habrozhiteli! Decidimos citar um trecho do livro de Andrei Burkov , Machine Learning Without Extra Words , dedicado √† classifica√ß√£o.
 
 Para desc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Classifica√ß√£o com v√°rias etiquetas</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/488362/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/hm/vf/c_/hmvfc_yyxepplv1mj0crw1vu7pw.jpeg" align="left" alt="imagem"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ol√°, habrozhiteli! </font><font style="vertical-align: inherit;">Decidimos citar um trecho do livro de Andrei Burkov </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, Machine Learning Without Extra Words</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , dedicado √† classifica√ß√£o.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para descrever a imagem na figura, v√°rios r√≥tulos podem ser usados ‚Äã‚Äãsimultaneamente: ‚Äúfloresta de con√≠feras‚Äù, ‚Äúmontanhas‚Äù, ‚Äúestrada‚Äù. Se o n√∫mero de valores poss√≠veis para r√≥tulos for grande, mas todos tiverem a mesma natureza que tags, cada amostra etiquetada poder√° ser convertida em v√°rios dados marcados, um para cada tag. Todos esses novos dados ter√£o os mesmos vetores de recursos e apenas um r√≥tulo. Como resultado, a tarefa se torna um problema de classifica√ß√£o em v√°rias classes. Pode ser resolvido usando a estrat√©gia ‚Äúum contra todos‚Äù. A √∫nica diferen√ßa do problema usual de classifica√ß√£o multiclasse √© a apar√™ncia de um novo hiperpar√¢metro: o limiar. Se a pontua√ß√£o de similaridade para um r√≥tulo estiver acima de um valor limite, esse r√≥tulo ser√° atribu√≠do ao vetor de recurso de entrada. Nesse cen√°rio, v√°rios r√≥tulos podem ser atribu√≠dos a um vetor de caracter√≠stica.O valor limite √© selecionado usando o conjunto de controle.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para resolver o problema de classifica√ß√£o com muitos r√≥tulos, pode-se aplicar algoritmos que s√£o naturalmente transformados em multiclasses (√°rvores de decis√£o, regress√£o log√≠stica, redes neurais, etc.). Eles retornam uma estimativa para cada classe, para que possamos definir um limite e atribuir v√°rios r√≥tulos a um vetor de recurso para o qual a pontua√ß√£o de proximidade excede esse limite. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As redes neurais podem naturalmente ser treinadas em classifica√ß√µes de v√°rios r√≥tulos usando a entropia cruzada bin√°ria como uma fun√ß√£o de custo. A camada de sa√≠da da rede neural, neste caso, possui um n√≥ por r√≥tulo. Cada n√≥ na camada de sa√≠da possui uma fun√ß√£o de ativa√ß√£o sigm√≥ide. Assim, cada r√≥tulo l √© bin√°rio</font></font><img src="https://habrastorage.org/webt/2n/_n/mg/2n_nmgvuciuadryomnq3urrg1xw.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde l = 1, ..., L e i = 1, ..., N. A entropia cruzada bin√°ria determina a probabilidade de </font></font><img src="https://habrastorage.org/webt/lb/le/cf/lblecfgyuy23k8zvlasuajncsds.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a amostra xi ter o r√≥tulo l, √© definida como o </font></font><img src="https://habrastorage.org/webt/qd/1e/fx/qd1efxpmi6mmuhv_fhmsqpjgpi4.jpeg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
crit√©rio de Minimiza√ß√£o - uma m√©dia simples de todos os membros da entropia cruzada bin√°ria em todas as amostras de treinamento e todas as suas tags. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nos casos em que o n√∫mero poss√≠vel de valores de r√≥tulo √© pequeno, voc√™ pode tentar converter o problema de classifica√ß√£o com muitos r√≥tulos em um problema de classifica√ß√£o em v√°rias classes. </font><font style="vertical-align: inherit;">Imagine o seguinte problema. </font><font style="vertical-align: inherit;">Voc√™ precisa atribuir dois tipos de etiquetas √†s imagens. </font><font style="vertical-align: inherit;">Os r√≥tulos do primeiro tipo podem ter dois significados poss√≠veis: { </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">foto, pintura</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> }; </font><font style="vertical-align: inherit;">marcas do segundo tipo podem ter tr√™s significados poss√≠veis: { </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">retrato, paisagem, outros</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">} </font><font style="vertical-align: inherit;">Para cada combina√ß√£o de duas classes de origem, voc√™ pode criar uma nova classe fict√≠cia, por exemplo:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mz/px/zn/mzpxzn0rlrumwoql7gkk3no7ihk.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora temos os mesmos dados marcados, mas substitu√≠mos o conjunto de r√≥tulos verdadeiros por um r√≥tulo simulado com valores de 1 a 6. Na pr√°tica, essa abordagem fornece bons resultados quando n√£o h√° muitas combina√ß√µes poss√≠veis de classes. Caso contr√°rio, √© necess√°rio usar muito mais dados de treinamento para compensar o aumento no conjunto de classes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A principal vantagem dessa √∫ltima abordagem √© que os r√≥tulos permanecem correlacionados, diferentemente dos m√©todos descritos acima, que prev√™em cada r√≥tulo independentemente um do outro. Em muitas tarefas, a correla√ß√£o entre r√≥tulos pode ser um fator significativo. Por exemplo, imagine que voc√™ deseja classificar o email como </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spam</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font><i><font style="vertical-align: inherit;">n√£o </font></i><i><font style="vertical-align: inherit;">spam</font></i></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, e ao mesmo tempo que ordin√°rio e importante. </font><font style="vertical-align: inherit;">Voc√™ provavelmente excluiria previs√µes como [ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">spam, importante</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ].</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5 </font><font style="vertical-align: inherit;">Treinamento do conjunto</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os algoritmos fundamentais que abordamos no cap√≠tulo 3 t√™m suas limita√ß√µes. Devido √† sua simplicidade, √†s vezes eles n√£o podem criar um modelo que seja eficaz o suficiente para sua tarefa. Nesses casos, voc√™ pode tentar usar redes neurais profundas. No entanto, na pr√°tica, redes neurais profundas exigem uma quantidade significativa de dados rotulados, que voc√™ pode n√£o ter. Outra maneira de aumentar a efic√°cia de algoritmos simples de aprendizado √© usar o </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">treinamento em conjunto</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O treinamento em conjunto √© um paradigma de treinamento que se baseia no treinamento n√£o apenas em um modelo super-correto, mas em um grande n√∫mero de modelos com baixa precis√£o e combinando as previs√µes fornecidas por esses </font><font style="vertical-align: inherit;">modelos </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fracos</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para obter um </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">metamodelo</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mais correto </font><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelos com baixa precis√£o geralmente s√£o treinados por </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">algoritmos de aprendizado fracos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que n√£o s√£o capazes de treinar modelos complexos e, portanto, mostram alta velocidade nos est√°gios de treinamento e previs√£o. Na maioria das vezes, o algoritmo de aprendizado da √°rvore de decis√£o √© usado como o algoritmo fraco, que geralmente para de interromper o conjunto de treinamento ap√≥s v√°rias itera√ß√µes. O resultado s√£o √°rvores pequenas e n√£o muito regulares, mas, como diz a id√©ia de treinar o conjunto, se as √°rvores n√£o forem id√™nticas e cada √°rvore for pelo menos um pouco melhor do que a adivinha√ß√£o aleat√≥ria, podemos obter alta precis√£o combinando um grande n√∫mero dessas √°rvores. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para obter a previs√£o final para a entrada </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, as previs√µes de todos os modelos fracos s√£o combinadas usando algum m√©todo de vota√ß√£o ponderada. </font><font style="vertical-align: inherit;">A forma espec√≠fica de ponderar os votos depende do algoritmo, mas a ess√™ncia n√£o depende dele: se, coletivamente, modelos fracos prev√™em que o email √© spam, atribu√≠mos </font><font style="vertical-align: inherit;">o r√≥tulo de </font><i><font style="vertical-align: inherit;">spam </font></i></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √† amostra </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">
Os dois principais m√©todos de treinamento de conjuntos s√£o </font><b><font style="vertical-align: inherit;">refor√ßo</font></b><font style="vertical-align: inherit;"> e </font><b><font style="vertical-align: inherit;">ensacamento</font></b><font style="vertical-align: inherit;"> (agrega√ß√£o). </font><font style="vertical-align: inherit;">As tradu√ß√µes dos termos refor√ßo e ensacamento s√£o imprecisas e n√£o est√£o acostumadas.</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.1 </font><font style="vertical-align: inherit;">Refor√ßo e ensacamento</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O m√©todo de refor√ßo √© usar os dados de treinamento iniciais e criar iterativamente v√°rios modelos usando um algoritmo fraco. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada novo modelo difere dos anteriores porque, construindo-o, um algoritmo fraco tenta "consertar" os erros cometidos pelos modelos anteriores. </font><font style="vertical-align: inherit;">O modelo final do conjunto √© uma combina√ß√£o desses muitos modelos fracos constru√≠dos iterativamente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A ess√™ncia do empacotamento √© criar muitas "c√≥pias" dos dados de treinamento (cada c√≥pia √© ligeiramente diferente das outras) e, em seguida, aplicar um algoritmo fraco a cada c√≥pia para obter v√°rios modelos fracos e combin√°-los. </font><font style="vertical-align: inherit;">Um algoritmo de aprendizado de m√°quina amplamente utilizado e eficiente, baseado na id√©ia de ensacamento, √© uma </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">floresta aleat√≥ria</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.2 </font><font style="vertical-align: inherit;">Floresta aleat√≥ria</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O algoritmo de ensacamento ‚Äúcl√°ssico‚Äù funciona da seguinte maneira. </font><font style="vertical-align: inherit;">B amostras aleat√≥rias s√£o criadas a partir do conjunto de treinamento existente </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(para cada b = 1, ..., B) e um </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo de </font></font><img src="https://habrastorage.org/webt/nd/ew/4z/ndew4zvx7r0jpeilfknakojmrbs.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√°rvore de decis√£o </font><font style="vertical-align: inherit;">√© constru√≠do </font><font style="vertical-align: inherit;">com base em cada amostra </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Para obter uma amostra </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para alguns b, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√© feita</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> uma </font><b><font style="vertical-align: inherit;">amostra com substitui√ß√£o</font></b><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Ou seja, primeiro uma amostra vazia √© criada e, em seguida, uma amostra aleat√≥ria √© selecionada no conjunto de treinamento e sua c√≥pia exata √© colocada </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, enquanto a pr√≥pria amostra permanece no conjunto de treinamento original. </font><font style="vertical-align: inherit;">A sele√ß√£o dos dados continua at√© que a condi√ß√£o seja cumprida.Como </font></font><img src="https://habrastorage.org/webt/se/au/-5/seau-5gwous1c1cshmrx8rwubig.jpeg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
resultado do treinamento, </font><font style="vertical-align: inherit;">s√£o </font><font style="vertical-align: inherit;">obtidas </font><font style="vertical-align: inherit;">√°rvores de decis√£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B. </font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A previs√£o para a nova amostra </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , no caso de regress√£o, √© determinada como a m√©dia de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> previs√µes</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/re/zp/mj/rezpmjqa9lo7w4dxvqd6njwwqcm.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ou por maioria de votos em caso de classifica√ß√£o.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A floresta aleat√≥ria tem apenas uma diferen√ßa do ensacamento cl√°ssico. Ele usa um algoritmo de aprendizado em √°rvore modificado que, com cada divis√£o no processo de aprendizado, verifica um subconjunto aleat√≥rio de recursos. Isso √© feito para eliminar a correla√ß√£o entre √°rvores: se um ou mais recursos tiverem uma grande capacidade preditiva, muitas √°rvores os escolher√£o para dividir dados. Isso levar√° ao aparecimento na "floresta" de um grande n√∫mero de √°rvores correlacionadas. A correla√ß√£o de sinal com alta capacidade preditiva impede que a precis√£o da previs√£o aumente. A alta efici√™ncia do conjunto de modelos √© explicada pelo fato de que bons modelos provavelmente concordam com a mesma previs√£o, e modelos ruins provavelmente n√£o concordam e fornecer√£o previs√µes diferentes. A correla√ß√£o tornar√° os modelos ruins mais propensos a concordar,o que distorcer√° o padr√£o de vota√ß√£o ou afetar√° a m√©dia.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os hiperpar√¢metros mais importantes para o ajuste s√£o o n√∫mero de √°rvores B e o tamanho de um subconjunto aleat√≥rio de recursos que devem ser considerados para cada divis√£o. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A floresta aleat√≥ria √© um dos algoritmos de aprendizado de conjunto mais usados. O que determina sua efic√°cia? O motivo √© que, usando v√°rias amostras do conjunto de dados original, reduzimos a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">varia√ß√£o do</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> modelo final. Lembre-se de que baixa varia√ß√£o significa uma fraca predisposi√ß√£o para </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">treinar novamente</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">A reciclagem ocorre quando o modelo tenta explicar pequenas varia√ß√µes no conjunto de dados porque o conjunto de dados √© apenas uma pequena amostra de todos os poss√≠veis exemplos do fen√¥meno que estamos tentando simular. </font><font style="vertical-align: inherit;">No caso de uma abordagem malsucedida √† forma√ß√£o do conjunto de treinamento, alguns artefatos indesej√°veis ‚Äã‚Äã(mas inevit√°veis) podem cair nele: ru√≠do, dados anormais e dados excessivamente ou insuficientemente representativos. </font><font style="vertical-align: inherit;">Ao criar v√°rias amostras aleat√≥rias com a substitui√ß√£o do conjunto de treinamento, reduzimos a influ√™ncia desses artefatos.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.3 </font><font style="vertical-align: inherit;">Aumento de gradiente</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Outro algoritmo de treinamento de conjunto eficaz baseado na id√©ia de aumento √© o aumento de gradiente. </font><font style="vertical-align: inherit;">Primeiro, considere o uso de aumento de gradiente na regress√£o. </font><font style="vertical-align: inherit;">Come√ßaremos a construir um modelo de regress√£o eficaz com um modelo constante </font></font><img src="https://habrastorage.org/webt/7u/7x/jd/7u7xjdufljpsjwwu45j9_gkc3r0.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(como fizemos no ID3):</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/em/vj/bv/emvjbvtmptxl_d3bihzev4wbh7o.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, altere os r√≥tulos em todas as amostras i = 1, ..., N no conjunto de treinamento:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/va/wc/ah/vawcahk0zsdpgnumh_bfjuozw_e.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
onde </font></font><img src="https://habrastorage.org/webt/rf/1x/pk/rf1xpkgfxmcivy-1tqpwv2vgroi.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√© chamado de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">restante</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e √© o novo r√≥tulo da amostra </font></font><img src="https://habrastorage.org/webt/dk/ey/2r/dkey2rj3yf-zkei2029wfa2ujso.jpeg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, usamos o conjunto de treinamento modificado com os res√≠duos em vez dos r√≥tulos originais para criar um novo modelo da √°rvore de </font></font><img src="https://habrastorage.org/webt/mx/fw/um/mxfwumzpc5tq1wjpdate2rxra48.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">decis√£o.O modelo de refor√ßo agora √© definido como </font></font><img src="https://habrastorage.org/webt/cy/c2/vz/cyc2vz0tmrrihcm6kta_7rnwmui.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">onde Œ± √© a velocidade de aprendizado (hiperpar√¢metro). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, recalculamos os res√≠duos usando a Equa√ß√£o 7.2, substitu√≠mos os r√≥tulos nos dados de treinamento novamente, ensinamos um novo modelo da √°rvore de decis√£o, </font></font><img src="https://habrastorage.org/webt/p4/wk/nl/p4wknlhlvwiqtr7zz7lx_y5oq3s.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">redefinimos o modelo de refor√ßo √† medida </font></font><img src="https://habrastorage.org/webt/n-/mn/ht/n-mnhtck0rar7pz4anzlbdc-bmo.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que repetimos o processo, at√© combinarmos o n√∫mero m√°ximo predeterminado </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M de</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √°rvores.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos entender intuitivamente o que est√° acontecendo aqui. Ao calcular os res√≠duos, determinamos qu√£o bem (ou mal) o objetivo de cada amostra de treinamento √© previsto pelo modelo atual f. Em seguida, treinamos outra √°rvore para corrigir os erros do modelo atual (√© por isso que usamos sobras em vez de r√≥tulos reais) e adicionamos uma nova √°rvore ao modelo existente com algum peso Œ±. Como resultado, cada nova √°rvore adicionada ao modelo corrige parcialmente os erros cometidos pelas √°rvores anteriores. O processo continua at√© que o n√∫mero m√°ximo M (outro hiperpar√¢metro) das √°rvores seja combinado.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, vamos tentar responder √† pergunta por que esse algoritmo √© chamado de aumento de gradiente. No aumento do gradiente, n√£o calculamos o gradiente, diferentemente do que fizemos no cap√≠tulo 4, resolvendo o problema de regress√£o linear. Para ver as semelhan√ßas entre aumento de gradiente e descida de gradiente, lembre-se do motivo pelo qual calculamos o gradiente em regress√£o linear: para descobrir a dire√ß√£o dos valores dos par√¢metros para minimizar a fun√ß√£o de custo do MSE. O gradiente mostra a dire√ß√£o, mas n√£o mostra at√© onde ir nessa dire√ß√£o; portanto, em cada itera√ß√£o, demos um pequeno passo e depois determinamos novamente a dire√ß√£o. O mesmo ocorre no aumento do gradiente, mas, em vez de calcular diretamente o gradiente, usamos sua estimativa na forma de res√≠duos: eles mostram como o modelo deve ser ajustado para reduzir o erro (residual).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No aumento de gradiente, tr√™s hiperpar√¢metros principais est√£o dispon√≠veis para ajuste: o n√∫mero de √°rvores, a velocidade do aprendizado e a profundidade das √°rvores. Todos os tr√™s afetam a precis√£o do modelo. A profundidade das √°rvores tamb√©m afeta a velocidade de aprendizado e previs√£o: quanto menor a profundidade, mais r√°pido. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pode-se mostrar que o aprendizado por res√≠duos otimiza o modelo geral f para o padr√£o de erro padr√£o. Aqui voc√™ pode ver a diferen√ßa do ensacamento: aumentar reduz o vi√©s (ou falta de educa√ß√£o) em vez da varia√ß√£o. Como resultado, o aumento est√° sujeito a reciclagem. No entanto, ajustando a profundidade e o n√∫mero de √°rvores, a reciclagem pode ser amplamente evitada.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O aumento de gradiente √© semelhante para tarefas de classifica√ß√£o, mas as etapas s√£o ligeiramente diferentes. Considere o caso da classifica√ß√£o bin√°ria. Suponha que haja M √°rvores de decis√£o de regress√£o. Por analogia com a regress√£o log√≠stica, a previs√£o do conjunto de √°rvores de decis√£o √© modelada usando a fun√ß√£o sigm√≥ide:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wy/pd/gw/wypdgwjjgpzuojrelehnadtdggc.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Onde </font></font><img src="https://habrastorage.org/webt/w6/3d/kb/w63dkbj3f9j-ik9hrhqbexyxtem.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est√° a √°rvore de regress√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E, novamente, como na regress√£o log√≠stica, ao tentar encontrar um modelo para maximizar </font></font><img src="https://habrastorage.org/webt/c4/lv/tt/c4lvttexfzr8disbsv1ph_drzka.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, o princ√≠pio da m√°xima verossimilhan√ßa √© aplicado. Da mesma forma, para evitar o excesso num√©rico, maximizamos a soma dos logaritmos de probabilidade, em vez do produto da probabilidade. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O algoritmo come√ßa com o modelo de constante inicial em </font></font><img src="https://habrastorage.org/webt/hn/7j/ep/hn7jepdxhudnxvjjgbulvfwtpyw.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que </font></font><img src="https://habrastorage.org/webt/gj/6s/f6/gj6sf6i874m3gq3_fbbxbkrudae.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Pode ser mostrado que essa inicializa√ß√£o √© ideal para a fun√ß√£o sigm√≥ide.) Em seguida, a cada itera√ß√£o m, uma nova √°rvore fm √© adicionada ao modelo. Para encontrar a melhor √°rvore </font></font><img src="https://habrastorage.org/webt/b0/5w/rv/b05wrvcuk5hzvnrmkpebdnk_kxu.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para encontrar a melhor √°rvore </font></font><img src="https://habrastorage.org/webt/xm/u4/dp/xmu4dpm1hi3-podtuiayxggydti.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, a derivada parcial do </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo atual √© </font><font style="vertical-align: inherit;">primeiro calculada </font><font style="vertical-align: inherit;">para cada i = 1, ..., N:</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wg/v_/oo/wgv_oogvmupu4q5j6g3rq7dphvk.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
onde f √© o modelo do classificador de conjunto constru√≠do na itera√ß√£o anterior m - 1. Para calcular </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, precisamos encontrar as derivadas de em </font></font><img src="https://habrastorage.org/webt/pv/pe/lb/pvpelb2jplsmq_jmkbdfyl-pzom.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rela√ß√£o a f para todo i. </font><font style="vertical-align: inherit;">Observe que a </font></font><img src="https://habrastorage.org/webt/nk/zn/0l/nkzn0lh0l0brnzl_vh0xxlmttrq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">derivada em rela√ß√£o a f do termo correto na equa√ß√£o anterior √©</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xx/en/iu/xxeniu2qr35ln17asbfk2fqb3sc.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, o conjunto de treinamento √© transformado substituindo o r√≥tulo original da </font></font><img src="https://habrastorage.org/webt/a1/fv/cu/a1fvcukqqvsu5wpv3x8i1zj5smc.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">derivada parcial correspondente </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e uma nova √°rvore √© criada com base no conjunto de treinamento convertido.A </font></font><img src="https://habrastorage.org/webt/w1/8f/41/w18f41gto37doyvyakgs4np_fyy.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seguir, a etapa ideal de atualiza√ß√£o √© determinada </font></font><img src="https://habrastorage.org/webt/1n/cf/sj/1ncfsjxfe-tao3ep_csuw-s-arw.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">como:</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/co/qc/hw/coqchwpctxgy2ukbdwaybkouxx0.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No final da itera√ß√£o m, atualizamos o modelo de conjunto </font></font><img src="https://habrastorage.org/webt/r7/ox/vy/r7oxvyc5mesbifpwfjtkcrtdr2q.jpeg" alt="imagem"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">adicionando uma nova √°rvore</font></font><img src="https://habrastorage.org/webt/s2/vp/u0/s2vpu0-7pmzuzv0n55f1z1fgktu.jpeg" alt="imagem"><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/vg/ar/qn/vgarqnddik0vjhxxfsesr1t5qs8.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As itera√ß√µes continuam at√© que a condi√ß√£o m = M seja cumprida, ap√≥s o qual o treinamento para e o modelo de conjunto f √© obtido. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O aumento de gradiente √© um dos mais poderosos algoritmos de aprendizado de m√°quina. </font><font style="vertical-align: inherit;">N√£o apenas porque cria modelos muito precisos, mas tamb√©m porque √© capaz de processar enormes conjuntos de dados com milh√µes de dados e recursos. </font><font style="vertical-align: inherit;">Como regra, √© superior em precis√£o a uma floresta aleat√≥ria, mas devido √† natureza consistente, pode aprender muito mais lentamente.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt488346/index.html">Instalando or-tools com SCIP e GLPK em um ambiente virtual Python 3.7 no Linux</a></li>
<li><a href="../pt488348/index.html">Webinar ‚ÄúOs dez principais desafios √°geis e como super√°-los em uma hora‚Äù 17 de fevereiro √†s 20:00, hor√°rio de Moscou</a></li>
<li><a href="../pt488352/index.html">Compara√ß√£o de custos de VDI: nuvem local versus nuvem p√∫blica</a></li>
<li><a href="../pt488356/index.html">Treinamento na Universidade T√©cnica Mar√≠tima do Estado de S√£o Petersburgo para produtos Dassault Syst√®mes</a></li>
<li><a href="../pt488360/index.html">Mitos sobre big data e cultura digital</a></li>
<li><a href="../pt488366/index.html">E novamente sobre "Informa√ß√µes incorretas de fuso hor√°rio para fusos hor√°rios russos" [.Net bug, ID: 693286]</a></li>
<li><a href="../pt488368/index.html">O que aprendi enquanto trabalhava no meu primeiro projeto em larga escala</a></li>
<li><a href="../pt488370/index.html">TDD para microcontroladores. Parte 2: Como os espi√µes se livram dos v√≠cios</a></li>
<li><a href="../pt488374/index.html">Telegrama + 1C + Webhooks + Apache + Certificado autoassinado</a></li>
<li><a href="../pt488376/index.html">Quando o princ√≠pio "para o inferno com tudo, pegue e fa√ßa!" n√£o funciona: notas de procrastinador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖖🏼 🖖 👨🏼‍🔬 CGI à la maison avec Unreal Engine et iPhone 👩‍🏭 👨‍👨‍👧‍👦 🏂🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour à tous! Je m'appelle Vasily Mazalov, je travaille comme monteur vidéo senior chez Pixonic. Notre département crée des créations vidéo pour le ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>CGI à la maison avec Unreal Engine et iPhone</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/494942/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonjour à tous! </font><font style="vertical-align: inherit;">Je m'appelle Vasily Mazalov, je travaille comme monteur vidéo senior chez Pixonic. </font><font style="vertical-align: inherit;">Notre département crée des créations vidéo pour le marketing et la communauté: vidéos pour pages en pages, revoir des vidéos d'innovations de jeux et autres contenus. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque je ne crée pas de créativité, je surveille Internet pour de nouveaux formats et façons de présenter du matériel afin de rendre notre propre contenu plus diversifié, intéressant et attrayant pour les nouveaux joueurs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a un an, je suis tombé sur la vidéo suivante:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voir la vidéo</font></font></b><div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/i51CizUXd7A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Que voyons-nous ici? </font><font style="vertical-align: inherit;">Le gars a mis un costume pour capturer le mouvement du corps (jusqu'à présent, rien d'inhabituel), a accroché un iPhone devant lui (mais c'est intéressant) et diffuse ainsi l'animation du visage et du corps du personnage directement en temps réel dans Unreal Engine, et le résultat recherche une implémentation si simple assez haute qualité. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Idée sympa, je pensais. </font><font style="vertical-align: inherit;">Puis fermé la vidéo. </font><font style="vertical-align: inherit;">Et il a continué à travailler davantage. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Six mois plus tard, le matériel de formation sur la façon de capturer des animations faciales dans Unreal Engine à l'aide d'une application sur l'iPhone s'est révélé être du domaine public. </font><font style="vertical-align: inherit;">En même temps, j'ai découvert qu'un costume pour capturer le mouvement avait été acheté dans notre département d'art. </font><font style="vertical-align: inherit;">Vu sa compatibilité avec UE: tout s'est bien passé. </font><font style="vertical-align: inherit;">Il ne restait plus qu'à trouver un iPhone pour continuer à travailler, mais de nos jours il y a encore moins de problèmes avec cela.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voir la vidéo</font></font></b><div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/AIHoDo7Y4_g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y avait beaucoup de questions. </font><font style="vertical-align: inherit;">Avant moi, il y avait un champ inculte d'animation inexplorée, l'Unreal Engine, la modélisation du visage et du corps humain, et d'autres choses complètement éloignées du montage vidéo, mais en même temps, un grand désir de réaliser ce qui était prévu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le long processus d'étude de divers documents a commencé. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lisez ce qui s'est passé et comment nous y sommes parvenus.</font></font><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Animation de visage</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour réaliser notre idée, il n'était pas rentable pour nous d'utiliser et de sculpter le personnage à partir de zéro: cela prendrait beaucoup de temps et nécessiterait des améliorations complexes et le plus souvent injustifiées. Par conséquent, nous avons décidé d'utiliser DAZ Studio: les os du visage y étaient initialement posés, vous permettant de créer rapidement les contractions et les émotions faciales nécessaires, sur lesquelles le sculpteur passerait beaucoup plus de temps. Oui, les modèles créés dans DAZ sont loin d'être une image photoréaliste, mais ils étaient parfaitement adaptés à nos objectifs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour enregistrer des animations faciales, nous n'avions besoin que d'un iPhone avec une caméra frontale TrueDepth - c'est-à-dire de l'iPhone X et supérieur. C'est cette technologie qui a lu la topologie du visage et transféré les valeurs nécessaires dans Unreal déjà à notre modèle.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/hu/yo/11/huyo11io_r0xlfw8nzzdzhawcvc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les formes de fusion sont responsables de différentes expressions faciales - des modèles 3D de la même topologie, c'est-à-dire avec le même nombre de sommets, mais de formes différentes. </font><font style="vertical-align: inherit;">Face AR utilise 51 mélanges, et grâce à la documentation détaillée d'Apple qui décrit les mélanges spécifiques utilisés dans DAZ, nous avons pu les faire assez rapidement. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'ensemble des émotions et des mélanges dans un modèle 3D ressemble à ceci: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/be/rx/ep/berxephpsuciz3wxd7vcachheo0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mélanger des formes à partir d'Internet </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/jo/9q/p2/jo9qp2iqqqyo1vyp514j-7xacpu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nos mélanges</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Donc, nous obtenons d'abord notre visage Unreal Engine pour les tests, puis construisons l'application et retournons à Unreal pour obtenir le résultat.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fh/x1/ui/fhx1uimpcjayhq0ybay3ifq8rdq.png"><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Animation corporelle</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour créer un corps, il fallait prendre en compte les spécificités du logiciel pour travailler avec une combinaison. Nous avons travaillé avec la combinaison de capture de mouvement du système de capture de mouvement Perception Neuron 2.0 de Noitom. Il en coûte environ 2500 dollars. C'est le costume le moins cher du marché et pas le meilleur représentant parmi les analogues: il est très sensible au rayonnement électromagnétique, ce qui fait bouger les coordonnées des capteurs s'il se trouve dans le rayon du rayonnement actif, et il sera encore plus difficile de nettoyer l'animation. Heureusement, nous venons de déménager à un autre étage, et dans un nouvel endroit, il était assez désert, ce qui signifie que le rayonnement électromagnétique a été réduit au minimum - c'est-à-dire qu'il était idéal pour nous.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jv/df/qt/jvdfqtdhz19xnag1w_4_lrtg1bw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pourquoi un costume? Les animations toutes faites de diverses bibliothèques ne nous convenaient pas, car notre personnage devrait avoir un caractère et un comportement uniques, et le visage et le corps devraient les refléter avec précision. Si nous faisions l'animation à partir de zéro, cela prendrait un mois, voire deux. L'utilisation d'équipement de capture de mouvement a permis de gagner du temps. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Contrairement au visage, les artistes eux-mêmes ont peint le modèle du corps à partir de zéro. Ensuite, il a fallu la faire gréer et écorcher à Maya. Après avoir assemblé le corps, nous le démarrons dans Unreal, nous collectons tout pour la mocap, enregistrons l'animation, après quoi le résultat ne reste plus qu'à pétrir.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1c/na/r0/1cnar0oe7evduomjsu9v_q-gyx0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour que l'animation soit transmise avec précision, les améliorations étaient minimes ou pour les éviter du tout, et afin de diffuser l'animation du costume directement sur l'Unreal Engine, il était nécessaire de définir correctement les os et de supprimer les valeurs inutiles de notre modèle. Noitom a un modèle 3D approximatif pour l'Unreal Engine, en utilisant lequel, comme référence, nous devions affiner notre propre modèle: le mettre dans la pose en T, placer les paumes et les doigts dans des positions de modélisation non standard et remettre toutes les valeurs à zéro. Il était très important que tous les os soient sans virages inutiles, sinon le programme les multiplierait, ce qui fausserait considérablement le mouvement.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au total, il a fallu environ deux heures pour calibrer la combinaison et enregistrer les premières vidéos. </font><font style="vertical-align: inherit;">Nous avons défini les paramètres dans l'Unreal Engine, enregistré l'animation du corps avec toutes les pauses nécessaires en fonction du script, puis enregistré l'animation du visage en fonction des mouvements du corps et du même script et obtenu le résultat, que vous verrez dans l'illustration suivante.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/E77DXw-zSu4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après l'enregistrement, l'animation devait être améliorée, nous avons donc confié à l'animateur la tâche de le nettoyer. </font><font style="vertical-align: inherit;">Il lui a fallu trois jours pour nettoyer deux minutes d'animation.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/h1KUncMcTCw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, il nous a fallu environ trois semaines pour arriver à la version finale, et si nous excluons le raffinement de certains facteurs à la fois dans le modèle du visage et dans le corps, cette période peut être réduite d'une autre semaine. </font></font><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pourquoi l'utilisons-nous?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Prenons une pause dans le processus CGI et parlons des objectifs du projet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À ce moment, quand j'ai exploré ce sujet et collecté les informations nécessaires au travail, des pilotes sont apparus dans notre jeu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Habituellement, lorsqu'un nouveau contenu sort, soit une voix hors écran en parle, soit les développeurs eux-mêmes, ou les informations arrivent simplement d'une manière ou d'une autre à travers le gameplay. Nous avons maintenant la possibilité de créer un personnage, de bien le préparer, d'assembler à partir de ressources de haute qualité les emplacements dans lesquels il sera situé et, à travers ce héros, de communiquer avec les joueurs: de l'histoire et des vidéos de révision aux émissions en direct.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour la première fois dans un jeu sur les robots, des personnages vivants sont apparus, et après eux des histoires qu'ils peuvent raconter sur eux-mêmes et sur le monde. Et je pensais que ce serait cool s'il était possible de collecter des cinématiques de gameplay avec des personnages qui plongeraient les joueurs dans le monde du jeu aussi vite que nous faisons des vidéos sur le moteur. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vu/3j/lf/vu3jlfs_gtgsym1a0slfy_otmg0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En collaboration avec le département communautaire, nous avons commencé à proposer une image du personnage, à quoi il pourrait ressembler et quelle serait son histoire. Notre gestionnaire de communauté senior a écrit le script, que nous avons ensuite développé en termes de gain de temps et de simplification de la production.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RQ6y8dRT2x8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans cette vidéo, vous voyez presque tous les tests que nous avons faits avec l'animation faciale et l'animation corporelle. </font><font style="vertical-align: inherit;">Puisqu'ils ont des spécifications différentes, ils ont dû être testés tour à tour et seulement mélangés à la fin. </font><font style="vertical-align: inherit;">Pour les tests d'animation corporelle, un modèle de costume a été tiré de la bande-annonce de CGI pour la nouvelle version:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sl-P_8CSahg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, montrons maintenant ce que nous avons obtenu:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/3WMqrO1-6ww" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec une combinaison de capture de mouvement, un iPhone, un modèle 3D et Unreal Marketplace avec une vaste sélection d'actifs gratuits de qualité, nous pouvons collecter des histoires intéressantes pour nos joueurs en seulement quelques semaines. </font><font style="vertical-align: inherit;">Nous avons également acquis une expérience et une compréhension de la façon de créer rapidement un nouveau personnage et, au stade de sa création, de prendre en compte toutes les caractéristiques de la production afin d'obtenir le meilleur résultat en peu de temps. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pourquoi n'avons-nous pas cherché à obtenir la qualité de cinématiques sympas comme Blizzard? </font><font style="vertical-align: inherit;">Pour le contenu communautaire et marketing, la qualité actuelle est suffisante pour donner à nos utilisateurs une nouvelle perspective sur le monde du jeu. </font><font style="vertical-align: inherit;">Cependant, bien qu'il ne soit toujours pas nécessaire d'améliorer la qualité des clips, nous sommes toujours à la recherche de nouvelles solutions.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr494920/index.html">Mauvais conseil au développeur: que faire pour «faire plaisir» à la direction</a></li>
<li><a href="../fr494922/index.html">Nizhny Novgorod pour un informaticien: perspectives de travail et opportunités de vie</a></li>
<li><a href="../fr494924/index.html">La mise en œuvre de l'effet aquarelle dans les jeux</a></li>
<li><a href="../fr494938/index.html">Bonne journée de sauvegarde! Ne l'oublie pas</a></li>
<li><a href="../fr494940/index.html">DevOps - qu'est-ce que c'est, pourquoi et combien est-il demandé?</a></li>
<li><a href="../fr494950/index.html">Quelques tendances de stockage à surveiller</a></li>
<li><a href="../fr494956/index.html">Durée de vie des octets de données</a></li>
<li><a href="../fr494964/index.html">Réseaux de neurones et trading. Mise en œuvre pratique</a></li>
<li><a href="../fr494966/index.html">SCRUM: un poème sur l'amour et la douleur</a></li>
<li><a href="../fr494968/index.html">Câbles Internet sous-marins: qui les achemine</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
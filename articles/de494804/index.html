<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùì üë©üèæ‚Äçüé® üêÉ "Entschuldigung, ich habe erkannt ..." oder Himbeeren und Controller mithilfe der Tensorflow-Objekterkennungs-API erkannt üë®üèΩ‚Äç‚öñÔ∏è üë©üèø‚Äçüöí ü§¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ende letzten Jahres schrieb ich einen Artikel dar√ºber, wie fasziniert mich die F√§higkeit war, Objekte in Bildern mithilfe neuronaler Netze zu erkennen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>"Entschuldigung, ich habe erkannt ..." oder Himbeeren und Controller mithilfe der Tensorflow-Objekterkennungs-API erkannt</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/494804/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ende letzten Jahres schrieb ich </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einen Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dar√ºber, wie fasziniert mich die F√§higkeit war, Objekte in Bildern mithilfe neuronaler Netze zu erkennen. In diesem Artikel haben wir mit PyTorch entweder Himbeeren oder einen Arduino-√§hnlichen Controller auf Video kategorisiert. Und trotz der Tatsache, dass ich PyTorch mochte, wandte ich mich an ihn, weil ich nicht sofort mit TensorFlow umgehen konnte. Aber ich habe versprochen, dass ich zum Thema Erkennung von Objekten im Video zur√ºckkehren werde. Es scheint an der Zeit zu sein, das Versprechen zu halten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Artikel werden wir auf unserem lokalen Computer versuchen, das fertige Modell in Tensorflow 1.13 und die Objekterkennungs-API f√ºr unsere eigenen Bilder neu zu trainieren und dann mit OpenCV Beeren und Controller im Videostream einer Webkamera zu erkennen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
M√∂chten Sie Ihre F√§higkeiten zur Beerenerkennung bis zum Sommer verbessern? </font><font style="vertical-align: inherit;">Dann sind Sie unter Katze willkommen.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fu/do/rd/fudordve5xz-8gwdnbvlnkkjusm.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inhalt: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil I: Einf√ºhrung </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil II: Trainieren des Modells in TenosrFlow </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil III: </font></font></a><font style="vertical-align: inherit;"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Anwenden </font></a><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">des Modells in OpenCV </font></a></font><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil IV: Schlussfolgerung</font></font></a><br>
<a name="I"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil I: Einf√ºhrung</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diejenigen, die den vorherigen Artikel √ºber PyTorch gelesen haben, wissen bereits, dass ich ein Amateur in Fragen neuronaler Netze bin. Nehmen Sie diesen Artikel daher nicht als die ultimative Wahrheit wahr. Trotzdem hoffe ich, dass ich jemandem helfen kann, mit den Grundlagen der Videoerkennung mithilfe der Tensorflow-Objekterkennungs-API umzugehen. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses Mal habe ich nicht versucht, ein Tutorial zu erstellen, daher ist der Artikel k√ºrzer als gew√∂hnlich.</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Zun√§chst ist das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">offizielle Tutorial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zur Verwendung der Objekterkennungs-API auf einem lokalen Computer, gelinde gesagt, kaum ersch√∂pfend. Als Neuling war ich v√∂llig unzureichend und musste mich auf Blog-Artikel konzentrieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um ehrlich zu sein, w√ºrde ich gerne TensorFlow 2.0 ausprobieren, aber in den meisten Ver√∂ffentlichungen waren Migrationsprobleme zum Zeitpunkt dieses Schreibens nicht vollst√§ndig gel√∂st. </font><font style="vertical-align: inherit;">Daher habe ich mich am Ende f√ºr TF 1.13.2 entschieden.</font></font><br>
<a name="II"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil II: Modellunterricht bei TensorFlow </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich habe Anweisungen zum Unterrichten des Modells </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aus diesem Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bzw. aus der ersten H√§lfte gezogen, bis JavaScript angewendet wurde </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Wenn Sie kein Englisch sprechen, k√∂nnen Sie einen Artikel zum gleichen Thema </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in Habr√© sehen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In meinem Fall gibt es zwar mehrere Unterschiede:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich habe Linux verwendet, weil Anaconda f√ºr Linux bereits Protobuf und Pycocoapi erstellt hat, sodass ich sie nicht selbst erstellen musste.</font></font></li>
<li>   TensorFlow 1.13.2,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Object Detection API 1.13</a> ,       TensorFlow 1.13.2.   master        TF 1.15,         1.13.</li>
<li>      numpy ‚Äî 1.17.5,  1.18    .</li>
<li>  faster_rcnn_inception_v2_coco    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">ssd_mobilenet_v2_coco</a>,    ,     .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 F√ºr alle F√§lle m√∂chte ich sagen, dass ich keinen Grafikbeschleuniger verwendet habe. Die Schulung wurde nur zu Prozessorkapazit√§ten durchgef√ºhrt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Reihe von Bildern, eine Konfigurationsdatei, ein gespeichertes Diagramm sowie ein Skript zum Erkennen von Bildern mit OpenCV k√∂nnen wie immer von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> heruntergeladen werden </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine lange 23-st√ºndige Modellschulung ist vergangen, der gesamte Tee im Haus wurde bereits getrunken: ‚ÄûWas? Wo? Wann?" inspiziert und jetzt ging meine Geduld endlich zu Ende. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir beenden das Training und speichern das Modell. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Installieren Sie OpenCV in derselben Umgebung wie "Anaconda" mit dem folgenden Befehl:</font></font><br>
<br>
<pre><code class="plaintext hljs">conda install -c conda-forge opencv</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich habe schlie√ülich Version 4.2 installiert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au√üerdem werden </font><font style="vertical-align: inherit;">wir </font><font style="vertical-align: inherit;">die Anweisungen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aus diesem Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nicht mehr ben√∂tigen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nach dem Speichern des Modells habe ich einen Fehler gemacht, der mir nicht klar war: Ich habe sofort versucht, die zuvor im Training / Ordner in der Funktion verwendete Datei graph.pbtxt zu ersetzen:</font></font><br>
<br>
<pre><code class="python hljs">cv2.dnn.readNetFromTensorflow()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Leider funktioniert dies nicht auf diese Weise und wir m√ºssen noch eine Manipulation durchf√ºhren, um graph.pbtxt f√ºr OpenCV zu erhalten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
H√∂chstwahrscheinlich ist die Tatsache, dass ich jetzt berate, kein sehr guter Weg, aber f√ºr mich funktioniert es. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Laden Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_ssd.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> herunter </font><font style="vertical-align: inherit;">und </font><font style="vertical-align: inherit;">legen Sie sie in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_common.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in dem Ordner ab, in dem sich unser gespeichertes Diagramm befindet (ich habe diesen Ordner inference_graph). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gehen Sie dann zur Konsole in diesem Ordner und f√ºhren Sie von dort aus einen Befehl mit ungef√§hr den folgenden Inhalten aus:</font></font><br>
<br>
<pre><code class="plaintext hljs">python tf_text_graph_ssd.py --input frozen_inference_graph.pb --config pipeline.config --output graph.pbtxt</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und das ist alles, was Sie brauchen, um unser Modell auf OpenCV hochzuladen.</font></font><br>
<br>
<a name="III"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teil III: Wenden Sie das Modell in OpenCV an </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie im Artikel √ºber PyTorch √ºber die Arbeit mit OpenCV habe ich den Programmcode aus </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dieser Ver√∂ffentlichung zugrunde gelegt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich habe kleine √Ñnderungen vorgenommen, um es ein wenig zu vereinfachen, aber da ich den Code nicht vollst√§ndig verstehe, werde ich ihn nicht kommentieren. </font><font style="vertical-align: inherit;">Funktioniert und sch√∂n. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist klar, dass der Code besser h√§tte sein k√∂nnen, aber ich habe noch keine Zeit, mich f√ºr OpenCV-Tutorials zu setzen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV-Code</font></font></b>
                        <div class="spoiler_text"><pre><code class="python hljs">
<span class="hljs-comment"># USAGE</span>
<span class="hljs-comment"># based on this code https://proglib.io/p/real-time-object-detection/</span>
<span class="hljs-comment"># import the necessary packages</span>
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> VideoStream
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> FPS
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> imutils
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> cv2<font></font>
<font></font>
prototxt=<span class="hljs-string">"graph.pbtxt"</span>
model=<span class="hljs-string">"frozen_inference_graph.pb"</span>
min_confidence = <span class="hljs-number">0.5</span><font></font>
<font></font>
<span class="hljs-comment"># initialize the list of class labels MobileNet SSD was trained to</span>
<span class="hljs-comment"># detect, then generate a set of bounding box colors for each class</span>
CLASSES = [<span class="hljs-string">"background"</span>, <span class="hljs-string">"duino"</span>,<span class="hljs-string">"raspb"</span>]<font></font>
COLORS = [(<span class="hljs-number">40</span>,<span class="hljs-number">50</span>,<span class="hljs-number">60</span>),((<span class="hljs-number">140</span>,<span class="hljs-number">55</span>,<span class="hljs-number">130</span>)),(<span class="hljs-number">240</span>,<span class="hljs-number">150</span>,<span class="hljs-number">25</span>)]<font></font>
<font></font>
<span class="hljs-comment"># load our serialized model from disk</span>
print(<span class="hljs-string">"[INFO] loading model..."</span>)<font></font>
<font></font>
net =cv2.dnn.readNetFromTensorflow(model,prototxt)<font></font>
<font></font>
<span class="hljs-comment"># initialize the video stream, allow the cammera sensor to warmup,</span>
<span class="hljs-comment"># and initialize the FPS counter</span>
print(<span class="hljs-string">"[INFO] starting video stream..."</span>)<font></font>
vs = VideoStream(src=<span class="hljs-number">0</span>).start()<font></font>
time.sleep(<span class="hljs-number">0.5</span>)<font></font>
fps = FPS().start()<font></font>
<font></font>
<span class="hljs-comment"># loop over the frames from the video stream</span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
	<span class="hljs-comment"># grab the frame from the threaded video stream and resize it</span>
	<span class="hljs-comment"># to have a maximum width of 400 pixels</span><font></font>
	frame = vs.read()<font></font>
	frame = imutils.resize(frame, width=<span class="hljs-number">300</span>)<font></font>
<font></font>
	<span class="hljs-comment"># grab the frame dimensions and convert it to a blob</span>
	(h, w) = frame.shape[:<span class="hljs-number">2</span>]<font></font>
	blob = cv2.dnn.blobFromImage(frame, size=(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>), swapRB=<span class="hljs-literal">True</span>)<font></font>
<font></font>
	<span class="hljs-comment"># pass the blob through the network and obtain the detections and</span>
	<span class="hljs-comment"># predictions</span><font></font>
	net.setInput(blob)<font></font>
	detections = net.forward()<font></font>
<font></font>
	<span class="hljs-comment"># loop over the detections</span>
	<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.arange(<span class="hljs-number">0</span>, detections.shape[<span class="hljs-number">2</span>]):
		<span class="hljs-comment"># extract the confidence (i.e., probability) associated with</span>
		<span class="hljs-comment"># the prediction</span>
		<span class="hljs-keyword">print</span> (detections)<font></font>
		confidence = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">2</span>]<font></font>
<font></font>
		<span class="hljs-keyword">if</span> confidence &gt; min_confidence:
			<span class="hljs-comment"># extract the index of the class label from the</span>
			<span class="hljs-comment"># `detections`, then compute the (x, y)-coordinates of</span>
			<span class="hljs-comment"># the bounding box for the object</span>
			idx = int(detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">1</span>])<font></font>
			box = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">3</span>:<span class="hljs-number">7</span>] * np.array([w, h, w, h])<font></font>
			(startX, startY, endX, endY) = box.astype(<span class="hljs-string">"int"</span>)<font></font>
<font></font>
			<span class="hljs-comment"># draw the prediction on the frame</span>
			label = <span class="hljs-string">"{}: {:.2f}%"</span>.format(CLASSES[idx],<font></font>
				confidence * <span class="hljs-number">100</span>)<font></font>
			cv2.rectangle(frame, (startX, startY), (endX, endY),<font></font>
				COLORS[idx], <span class="hljs-number">2</span>)<font></font>
			y = startY - <span class="hljs-number">15</span> <span class="hljs-keyword">if</span> startY - <span class="hljs-number">15</span> &gt; <span class="hljs-number">15</span> <span class="hljs-keyword">else</span> startY + <span class="hljs-number">15</span>
			cv2.putText(frame, label, (startX, y+<span class="hljs-number">3</span>),<font></font>
				cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, COLORS[idx], <span class="hljs-number">1</span>)<font></font>
<font></font>
	<span class="hljs-comment"># show the output frame</span>
	cv2.imshow(<span class="hljs-string">"Frame"</span>, frame)<font></font>
	key = cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span><font></font>
<font></font>
	<span class="hljs-comment"># if the `q` key was pressed, break from the loop</span>
	<span class="hljs-keyword">if</span> key == ord(<span class="hljs-string">"q"</span>):
		<span class="hljs-keyword">break</span><font></font>
<font></font>
	<span class="hljs-comment"># update the FPS counter</span><font></font>
	fps.update()<font></font>
<font></font>
<span class="hljs-comment"># stop the timer and display FPS information</span><font></font>
fps.stop()<font></font>
print(<span class="hljs-string">"[INFO] elapsed time: {:.2f}"</span>.format(fps.elapsed()))<font></font>
print(<span class="hljs-string">"[INFO] approx. FPS: {:.2f}"</span>.format(fps.fps()))<font></font>
<font></font>
<span class="hljs-comment"># do a bit of cleanup</span><font></font>
cv2.destroyAllWindows()<font></font>
vs.stop()<font></font>
</code></pre><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Also ist alles fertig. Wir starten das Modell, richten das Objektiv auf meinen alten CraftDuino und genie√üen das Ergebnis: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/bw/hj/yd/bwhjyd9pddoeop9yaz7fxbqozzo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auf den ersten Blick ist es √ºberhaupt nicht schlecht, aber nur auf den ersten Blick. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es sieht so aus, als ob das Modell in 23 Stunden umgeschult wurde, daher gibt es schwerwiegende Fehler bei der Definition von Objekten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hier ist eine visuelle Demonstration: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/1w/3y/gf/1w3ygfo-ufytpuyct1kaarpsgls.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Sie sehen k√∂nnen, definiert dieses Modell nicht nur ein Messer, sondern auch nur einen schwarzen Hintergrund als arduino√§hnlichen Controller. Vielleicht liegt das daran, dass in den Trainingsdaten dunkle Bilder mit dem Arduino und seinen Analoga waren, auf denen das Modell in 23 Stunden sto√üen konnte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Infolgedessen musste ich meinen Computer f√ºr weitere 8 Stunden laden und ein neues Modell trainieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei ihr l√§uft es viel besser. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hier ist ein Beispiel mit CraftDuino:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_c/8m/62/_c8m62y2q6as-l8sun5ah5ivppk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lebende Himbeeren sind nicht zur Hand. </font><font style="vertical-align: inherit;">Ich musste Bilder drucken. </font><font style="vertical-align: inherit;">Auf dem Bildschirm des Telefons oder Monitors k√∂nnen Sie auch erkennen, aber auf dem Papier war es bequemer. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/63/_k/ou/63_koujmchte7jor0ulqzxcvgcs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns √ºberpr√ºfen, wie das Modell den Arduino Nano erkennt, was zu gegebener Zeit</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Drzugrik</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√ºr mich habe ich mit Sensoren in mein Mega-Ger√§t eingel√∂tet: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ub/33/61/ub3361ozwkiwvl2sosx6yldvsou.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Sie sehen, erkennt es recht gut, aber bei einem sehr schlechten Winkel und bei warmem Licht kann es einige Fragmente wie Himbeeren erkennen. Tats√§chlich war es jedoch schwierig, einen fehlerhaften Rahmen in der Linse zu erfassen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns nun √ºberpr√ºfen, wie sie die Objekte klassifiziert, f√ºr die sie nicht trainiert wurde. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wieder ein Beispiel mit einem Messer und einem schwarzen Hintergrund: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/io/ja/6a/ioja6aexferclondu4228nsr06y.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diesmal funktioniert alles so, wie es sollte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir werden unser Modell anbieten, um den winzigen Canny 3-Controller zu erkennen, √ºber den ich in einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fr√ºheren Artikel geschrieben habe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xp/ay/14/xpay14o7clhp1y1twu4vyltiay4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da unser Modell nichts anderes als Himbeeren und Arduino-√§hnliche Controller kennt, k√∂nnen wir sagen, dass das Modell den Canny-Controller recht erfolgreich erkannt hat.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie beim Arduino Nano h√§ngt vieles vom Winkel und der Beleuchtung ab. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit dem warmen Licht einer Gl√ºhlampe und mit einem erfolglosen Winkel kann der Controller nicht nur nicht erkannt, sondern sogar als Himbeere definiert werden. </font><font style="vertical-align: inherit;">Zwar mussten diese Winkel wie im vergangenen Fall immer noch versuchen, sich in der Linse zu verfangen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/01/ut/h_/01uth_-raiwnzasg7ypn-aoxezs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, der letzte Fall ist eine Art Knicks f√ºr den Artikel √ºber die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Klassifizierung von Bildern in PyTorch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Wie beim letzten Mal sind der Einplatinencomputer Raspberry Pi 2 und sein Logo in einem Frame kompatibel. </font><font style="vertical-align: inherit;">Im Gegensatz zum vorherigen Artikel, in dem wir das Klassifizierungsproblem gel√∂st und ein wahrscheinlichstes Objekt f√ºr das Bild ausgew√§hlt haben, werden in diesem Fall sowohl das Logo als auch die Himbeere selbst erkannt.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vx/fv/us/vxfvusfgitn6vk1pe6o4rvoen9i.png"><br>
<br>
<a name="IV"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Teil IV: Schlussfolgerung </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Abschlie√üend m√∂chte ich sagen, dass ich trotz der Unerfahrenheit dieses kleinen Beispiels f√ºr die Arbeit mit der Tensorflow-Objekterkennungs-API sowohl freie Tage als auch einen Teil des Montags nicht bereue. Wenn zumindest ein wenig Verst√§ndnis f√ºr die Verwendung alles unglaublich neugierig wird. W√§hrend des Lernprozesses beginnen Sie, das Modell als lebendiges Modell zu betrachten und seine Erfolge und Misserfolge zu verfolgen. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Daher empfehle ich jedem, der mit diesem einen Tag nicht vertraut ist, etwas Eigenes zu erkennen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da es dabei gestiegen ist, m√ºssen Sie nicht einmal eine echte Webcam kaufen. Tatsache ist, dass ich w√§hrend der Vorbereitung des Artikels meine Webcam kaputt gemacht habe (den Fokusmechanismus gebrochen habe) und bereits gedacht habe, dass ich alles aufgeben m√ºsste. Es stellte sich jedoch heraus, dass Sie mit Hilfe von Droidcam ein Smartphone anstelle einer Webcam verwenden k√∂nnen (nicht f√ºr Werbung z√§hlen). Dar√ºber hinaus erwies sich die Aufnahmequalit√§t als viel besser als die einer kaputten Kamera, was die Qualit√§t der Erkennung von Objekten im Bild stark beeinflusste. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√úbrigens, da Anaconda einen normalen </font><b><font style="vertical-align: inherit;">Pycocotool-</font></b><font style="vertical-align: inherit;"> Aufbau hat</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich fand nur f√ºr Linux, und ich war zu faul, um zwischen Betriebssystemen zu wechseln. Ich habe diesen gesamten Artikel nur mit Open-Source-Software vorbereitet. </font><font style="vertical-align: inherit;">Es gab Analoga von Word und Photoshop und sogar einen Treiber f√ºr den Drucker. </font><font style="vertical-align: inherit;">Das erste Mal in meinem Leben geschah dies. </font><font style="vertical-align: inherit;">Es stellte sich heraus, dass moderne Versionen von Linux-Betriebssystemen und Anwendungsprogrammen sehr praktisch sein k√∂nnen, selbst f√ºr Personen, die Microsoft OS seit mehr als 25 Jahren verwenden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS Wenn jemand wei√ü, wie die Objekterkennungs-API </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
f√ºr Tensorflow Version 2 und h√∂her </font><font style="vertical-align: inherit;">ordnungsgem√§√ü ausgef√ºhrt wird, </font><font style="vertical-align: inherit;">melden Sie sich bitte in PM oder in einem Kommentar ab. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einen sch√∂nen Tag und gute Gesundheit!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de488464/index.html">Webpack 5 - Asset-Module</a></li>
<li><a href="../de488468/index.html">Einf√ºhrung in FastAPI</a></li>
<li><a href="../de488470/index.html">Kim Dotcom: Gefangen, die meistgesuchte Person online. Teil 4</a></li>
<li><a href="../de488472/index.html">Wochenendlesung: 10 Materialien zu Audioger√§ten - von sowjetischen Autoradios bis hin zu ger√§uschunterdr√ºckenden Steckern</a></li>
<li><a href="../de494800/index.html">Reverse Engineering des chinesischen USB-IR-Transceiver-Protokolls</a></li>
<li><a href="../de494806/index.html">Cyber-Ziele 2019 als Trends 2020 - Hacker haben ihren Fokus ge√§ndert</a></li>
<li><a href="../de494808/index.html">Produktanalyst: Was macht es, wie viel verdient es, welche Vorteile bringt das Unternehmen?</a></li>
<li><a href="../de494810/index.html">Einf√ºhrung in 3D: Three.js Basics</a></li>
<li><a href="../de494814/index.html">Ist Slurm n√ºtzlich?</a></li>
<li><a href="../de494818/index.html">So w√§hlen Sie ein Handelsterminal f√ºr die Arbeit an der B√∂rse aus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
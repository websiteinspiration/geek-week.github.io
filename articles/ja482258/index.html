<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕹️ 🧒🏾 🏗️ ニューラルネットワークのしくみと、大金を持ち始めた理由 🚲 👨🏻‍🚀 🤾🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ニューラルネットワークは、好奇心旺盛な状態から大規模な産業へと成長しました
 
 
 過去10年間で、コンピューターは周囲の世界を理解する能力を大幅に向上させてきました。写真機材のソフトウェアは、人の顔を自動的に認識します。スマートフォンは音声をテキストに変換します。ロボモービルは道路上の物体を認識...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ニューラルネットワークのしくみと、大金を持ち始めた理由</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482258/"><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワークは、好奇心旺盛な状態から大規模な産業へと成長しました</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/36a/21a/fd3/36a21afd35a805d95a2a67b2ec52080a.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
過去10年間で、コンピューターは周囲の世界を理解する能力を大幅に向上させてきました。写真機材のソフトウェアは、人の顔を自動的に認識します。スマートフォンは音声をテキストに変換します。ロボモービルは道路上の物体を認識し、それらとの衝突を回避します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべてのブレークスルーの中心は、ディープラーニング（GO）と呼ばれる人工知能（AI）のテクノロジーです。 GOはニューラルネットワーク（NS）に基づいており、データ構造は生物学的ニューロンで構成されるネットワークから発想を得ています。 NSはレイヤーで構成され、1つのレイヤーの入力は隣接するレイヤーの出力に接続されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
コンピュータ科学者は1950年代からNSを実験してきました。</font><font style="vertical-align: inherit;">しかし、今日の広大なGO業界の基盤は、1986年に発生した2つ目の大きな革新によって2012年に生まれました。2012年の突破-GOの革命-は、多数のレイヤーを持つNSを使用することで効率を大幅に向上できるという発見に関連しています。</font><font style="vertical-align: inherit;">この発見は、データとコンピューティング能力の両方の増大するボリュームによって促進されました。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、国会の世界を紹介します。</font><font style="vertical-align: inherit;">NAとは何か、それらがどのように機能するか、どこから来たかを説明します。</font><font style="vertical-align: inherit;">そして、何十年にもわたる以前の研究にもかかわらず、NSが2012年にのみ本当に有用なものになった理由を調査します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワークは1950年代に登場しました</font></font></h2><br>
<img src="https://habrastorage.org/getpro/habr/post_images/770/c2e/327/770c2e3276b0e875a99025f4887dda36.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">フランクローゼンブラットは彼のパーセプトロン（初期のNSモデル）に取り組んでいます。NSの</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
アイデアはかなり古く、少なくともコンピュータの標準ではそうです。 1957年に、</font><font style="vertical-align: inherit;">コーネル大学の</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">フランクローゼンブラット</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font><font style="vertical-align: inherit;">、パーセプトロンと呼ばれるNSの初期の概念を説明する</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">レポート</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">公開しました</font><font style="vertical-align: inherit;">。 1958年、アメリカ海軍の支援を得て、20x20ピクセルを分析し、単純な幾何学的形状を認識できるプリミティブシステムを作成しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ローゼンブラットの主な目標は、実用的な画像分類システムを作成することではありませんでした。彼は人間の脳がどのように機能するかを理解しようとし、そのイメージで組織されたコンピュータシステムを作成しました。しかし、このコンセプトは第三者からの過度の熱意を生み出しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「今日、米海軍は電子計算機の胚の世界を開いた。それは歩く、話す、見る、書く、遊ぶ、そして彼らの存在を実現することができると期待されている」- </font><font style="vertical-align: inherit;">ニューヨーク・タイムズに</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">書い</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">た。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際、NSの各ニューロンは、単に数学的関数です。各ニューロンは、入力データの加重和を計算します。入力の重みが大きいほど、これらの入力データがニューロンの出力に強く影響します。次に、加重和が「アクティブ化」の非線形関数に送られます。このステップで、NSは複雑な非線形現象をシミュレーションできます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ローゼンブラットが実験した初期パーセプトロンの能力、そして一般にNSは、例を用いて「学習」する能力に由来します。 NSは、ネットワークの結果に基づいてニューロンの入力の重みを調整することでトレーニングされます。たとえば、入力データが選択されています。ネットワークが画像を正しく分類すると、正解に寄与する重みは増加しますが、他の重みは減少します。ネットワークが間違っている場合、重みは反対方向に調整されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このような手順により、初期のNSは人間の神経系の行動を連想させる方法で「学習」することができました。このアプローチを取り巻く誇大宣伝は1960年代に止まりませんでした。しかし、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">影響力のある本</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1969年、コンピューターサイエンティストのMarvin MinskyとSeymour Papertの著者は、これらの初期のNAには大きな制限があることを示しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
初期のRosenblatt NSには、1つまたは2つのトレーニング済みレイヤーしかありませんでした。</font><font style="vertical-align: inherit;">MinskyとPapertは、そのようなNSは数学的に現実世界の複雑な現象をモデル化できないことを示しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
原則として、より深いNSはより有能でした。</font><font style="vertical-align: inherit;">ただし、そのようなNSは、コンピューターが当時持っていた悲惨なコンピューティングリソースに過度の負担をかけます。</font><font style="vertical-align: inherit;">最初のNSで使用された</font><font style="vertical-align: inherit;">最も単純な</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">昇順検索</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アルゴリズム</font><font style="vertical-align: inherit;">は、より深いNSに対してはスケーリングしませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その結果、国会は1970年代と1980年代初頭にすべての支持を失いました-それは「AIの冬」時代の一部でした。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">画期的なアルゴリズム</font></font></h2><br>
<img src="https://habrastorage.org/getpro/habr/post_images/970/c5b/807/970c5b8074a5b4516be251bd4b9a31b0.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私の「ソフト機器」に基づくニューラルネットワークは、この写真にホットドッグがいる確率は1であると考えています。私たちは金持ちになります！</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
運が再びNSに目を向けたのは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1986年</font><font style="vertical-align: inherit;">の有名な</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">作品の</font></a><font style="vertical-align: inherit;">おかげで、</font><font style="vertical-align: inherit;">バックプロパゲーションの概念が導入されました。これは、NSを教えるための実用的な方法です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
架空のソフトウェア会社でプログラマーとして働いていて、画像にホットドッグがあるかどうかを判別するアプリケーションを作成するように指示されたとします。画像を入力に取り込んで0から1までの値を出力するランダムに初期化されたNSで作業を開始します。1は「ホットドッグ」を意味し、0は「ホットドッグではない」ことを意味します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ネットワークをトレーニングするには、何千もの画像を収集します。各画像の下には、この画像にホットドッグがあるかどうかを示すラベルがあります。あなたは彼女に最初の画像を供給します-そしてそれにホットドッグが-ニューラルネットワークにあります。出力値は0.07で、これは「ホットドッグなし」を意味します。これは間違った答えです。ネットワークは1に近い応答を返します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
バックプロパゲーションアルゴリズムの目的は、入力ウェイトを調整して、この画像、およびできれば、ホットドッグがある他の画像が与えられた場合にネットワークがより高い値を生成するようにすることです。このため、バックプロパゲーションアルゴリズムは、出力層の入力ニューロンを調べることから始まります。各値には重み変数があります。逆伝播アルゴリズムは、NSがより高い値を与えるような方向に各重みを調整します。入力値が高いほど、重みが大きくなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここまでは、1960年代の研究者にとってなじみのあるトップへの最も単純な上昇について説明しました。逆伝播の突破口は次のステップでした。アルゴリズムは偏微分を使用して、ニューロンの入力間で誤った出力の「フォールト」を分散します。アルゴリズムは、各入力値の小さな変化がニューロンの最終出力にどのように影響するか、およびこの変化が結果を正解に近づけるか、またはその逆かを計算します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果は、前のレイヤーの各ニューロンのエラー値のセットです-実際、各ニューロンの値が大きすぎるか小さすぎるかを評価する信号です。次に、このアルゴリズムは、2番目の層（最後から）の新しいニューロンのチューニングプロセスを繰り返します。各ニューロンの入力の重みをわずかに変更して、ネットワークを正解に近づけます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、アルゴリズムは偏微分を再び使用して、前のレイヤーの各入力の値がこのレイヤーの出力エラーにどのように影響したかを計算し、これらのエラーを前のレイヤーに伝搬して、プロセスが再度繰り返されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは単純化された逆伝播モデルです。あなたは数学的な内容を詳細に説明する必要がある場合、私はこのテーマにマイケル・ニールセンの本をお勧めします[ </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私たちは彼女の翻訳を持っている</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">約/。 transl。]。私たちの目的のためには、逆分布が訓練されたNSの範囲を根本的に変えるだけで十分です。人々はもはや1つまたは2つの層を持つ単純なネットワークに制限されていませんでした。 5、10、または50層​​のネットワークを作成でき、これらのネットワークは任意に複雑な内部構造を持つことができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
バックプロパゲーションの発明は、国会の第2ブームを開始し、それは実用的な結果を生み出し始めました。 1998年、AT＆Tの研究グループが、ニューラルネットワークを使用して手書きの数字を認識する方法を示しました。これにより、チェック処理の自動化が可能になりました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「この研究の主なメッセージは、パターンを認識するための改善されたシステムを作成でき、自動学習に頼り、手動で開発されたヒューリスティックスに頼らないことです」と著者らは書いている。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、このフェーズでは、NSは機械学習研究者が自由に使用できる多くのテクノロジーの1つにすぎませんでした。 2008年に研究所のAIコースで勉強したとき、ニューラルネットワークは9つのMOアルゴリズムの1つにすぎず、そこからタスクに適したオプションを選択できました。しかし、GOはすでに、残りのテクノロジを覆い隠す準備をしていました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ビッグデータはディープラーニングの力を示してい</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/0ff/b2d/663/0ffb2d6630240722208088bd6be34644.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。ビーチのチャンス1.0。マイタイのご利用手続きを開始します。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
バックプロパゲーションはNSの計算プロセスを容易にしましたが、より深いネットワークは依然として小さなものよりも多くのコンピューティングリソースを必要としました。 1990年代と2000年代に行われた研究の結果は、NSの追加の合併症から益を得ることがますます少なくなることが可能であることをしばしば示しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、主要な研究者アレックスクリジェフスキーにちなんで名付けられた、AlexNetという名前でNSを説明した2012年の有名な作品によって、人々の考え方は変わりました。より深いネットワークと同様に、画期的な効率を提供できますが、豊富なコンピューター能力と大量のデータとの組み合わせでのみです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AlexNetは、ImageNetサイエンスコンテストに参加するために、トロント大学から3組のコンピューター科学者を育成しました。コンテストの主催者はインターネット上で100万枚の画像を収集し、それぞれにマークを付けて、「チェリー」、「コンテナ船」、「ヒョウ」などのオブジェクトの何千ものカテゴリの1つに割り当てました。 AI研究者は、これらの画像の一部でMOプログラムをトレーニングし、ソフトウェアがこれまでに遭遇したことがない他の画像の正しいラベルを書き留めるように依頼されました。ソフトウェアは各画像に対して5つの可能なラベルを選択する必要があり、それらの1つが実際のラベルと一致した場合、試行は成功したと見なされました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは困難な作業であり、2012年まで結果はあまり良くありませんでした。 2011年の受賞者のエラー率は25％でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2012年、AlexNetチームは、15％のエラーで回答することで、すべての競合他社をしのいでいます。最も近い競合他社では、この数字は26％でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トロントの研究者たちは、いくつかの技術を組み合わせて画期的な結果を達成しました。それらの1つは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">畳み込み神経症</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（SNS）の</font><font style="vertical-align: inherit;">使用でした</font><font style="vertical-align: inherit;">。実際、SNAは、小さなニューラルネットワーク（一辺が7〜11ピクセルの正方形）をトレーニングしてから、より大きな画像に「スーパーインポーズ」します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「あなたが小さなテンプレートやステンシルを取り、それを画像の各ポイントと比較しようとしたようなものです」とAI研究者のJie Tanは昨年私たちに話しました。 -あなたは犬のステンシルを持っていて、それを画像に添付して、そこに犬がいるかどうか確認しますか？そうでない場合は、ステンシルを移動します。全体像についても同様です。そして、犬が写真のどこに写っていても。ステンシルは彼女と一致します。各ネットワークサブセクションが個別の犬の分類子になることはありません。」</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AlexNetのもう1つの重要な成功要因は、グラフィックスカードを使用して学習プロセスをスピードアップしたことです。</font><font style="vertical-align: inherit;">グラフィックスカードには並列処理能力があり、ニューラルネットワークのトレーニングに必要な反復計算に適しています。</font><font style="vertical-align: inherit;">コンピューティングの負荷をGPUのペア（それぞれ3 GBのメモリを搭載したNvidia GTX 580）に転送すると、研究者は非常に大規模で複雑なネットワークを開発してトレーニングすることができました。</font><font style="vertical-align: inherit;">AlexNetには8つの学習層、65万個のニューロン、6000万個のパラメーターがありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後に、AlexNetの成功は、ImageNetの100万枚という大規模なトレーニング画像データベースによっても保証されました。</font><font style="vertical-align: inherit;">6000万のパラメーターを微調整するには、多くの画像が必要です。</font><font style="vertical-align: inherit;">決定的な勝利を収めるために、AlexNetは複雑なネットワークと大きなデータセットの組み合わせによって助けられました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
なぜそのような画期的なことが以前には起こらなかったのかと思います。</font></font><br>
<br>
<ul>
<li>  GPU  ,   AlexNet,         2012 .             .  ,               2004.</li>
<li>             2012 ,           .                      .</li>
<li>  ,   AlexNet,   .     2012      .  ,        1980-  1990-.</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、AlexNetの各成功要素は、ブレークスルーが発生するずっと前から別々に存在していました。</font><font style="vertical-align: inherit;">明らかに、それらを組み合わせるのは誰にも起こりませんでした。ほとんどの場合、この組み合わせがどれほど強力であるか誰も知らなかったためです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NSの深さを増やしても、トレーニングデータのセットが不十分である場合、実際の作業効率は向上しませんでした。</font><font style="vertical-align: inherit;">また、データセットを拡張しても、小規模ネットワークのパフォーマンスは向上しませんでした。</font><font style="vertical-align: inherit;">効率の向上を確認するには、より深いネットワークとより大きなデータセットの両方に加えて、学習プロセスを妥当な時間内に実行できるようにするための大きな計算能力が必要でした。</font><font style="vertical-align: inherit;">AlexNetチームは、3つの要素すべてを1つのプログラムにまとめた最初のチームです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ディープラーニングのブーム</font></font></h2><br>
<img src="https://habrastorage.org/getpro/habr/post_images/ef0/fb4/922/ef0fb4922c3164251c722134b84460e3.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
十分な量のトレーニングデータによって提供されるディープNSのフルパワーのデモンストレーションは、科学者、研究者、および業界の代表者の両方の間で、多くの人々によって注目されました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初に変更するのはImageNetコンテスト自体です。 2012年まで、ほとんどの競技者はディープラーニング以外のテクノロジーを使用していました。 2013年のコンテストでは、スポンサーが書いたように、参加者の「過半数」がGOを使用しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
受賞者のエラーの割合は徐々に減少しました-2012年のAlexNetでの印象的な16％から2017年の2.3％へ：</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/9ba/95e/b4b/9ba95eb4baee6580ea97ac76347a02e4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
GO革命は業界全体に急速に広まりました。 2013年、GoogleはAlexNetの作者から結成された新興企業を買収し、その技術をGoogleフォトの画像検索機能のベースとして使用しました。 2014年までに、FacebookはGOを使用して画像を認識する独自のソフトウェアを宣伝していました。 Appleは、少なくとも2016年以降、iOSの顔認識にGOを使用しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
GOはまた、音声認識技術における最近の改善の基礎にもなっています。 AppleのSiri、AmazonのAlexa、MicrosoftのCortana、GoogleのアシスタントはGOを使用して、人の言葉を理解するか、より自然な声を生成するか、またはその両方を行います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
近年、計算能力、データ容量、およびネットワークの深さの増加が相互にサポートし合う業界で、自立的な傾向が現れています。 AlexNetチームは、リーズナブルな価格で並列コンピューティングを提供したため、GPUを使用しました。しかし、ここ数年、MOの分野で使用するために特別に設計された独自のチップを開発する企業が増えています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Googleは、2016年にNS専用に設計されたTensor Processing Unitチップのリリースを発表しました。同年、Nvidiaは、NS向けに最適化されたTesla P100と呼ばれる新しいGPUのリリースを発表しました。 Intelは2017年にAIチップでこの電話に答えました。2018年に、Amazonは自社のクラウドサービスの一部として使用できる独自のAIチップのリリースを発表しました。マイクロソフトでさえ、そのAIチップに取り組んでいると言われています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スマートフォンメーカーは、サーバーにデータをアップロードしなくても、モバイルデバイスがローカルでNSを使用してより多くのコンピューティングを実行できるようにするチップにも取り組んでいます。デバイス上の同様のコンピューティングは、レイテンシを削減し、プライバシーを強化します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テスラさえ特別なチップでこのゲームに参加しました。テスラは今年、NSの計算用に最適化された新しい強力なコンピューターを展示しました。テスラはそれをフルセルフドライビングコンピューターと名付け、テスラ艦隊をロボット車両に変えるという同社の戦略の重要な瞬間として導入しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AI向けに最適化されたコンピューター容量の可用性により、ますます複雑になるNSのトレーニングに必要なデータの要求が生成されました。この動きは、企業が数百万キロの実際の道路に関するデータを収集するロボモービルセクターで最も顕著です。テスラはこのデータをユーザーの車から自動的に収集し、競合他社のウェイモとクルーズは公道で車を運転した有料ドライバーを収集しました。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/2eb/80a/3be/2eb80a3be8fd038777829faff752e8bf.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データの要求は、すでに大量のユーザーデータにアクセスしている大規模なオンライン企業に有利です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ディープラーニングは非常に柔軟性があるため、非常に多くの異なる分野を征服しています。何十年もの試行錯誤により、研究者は効率的な画像認識のための畳み込みネットワークなど、MOの分野で最も一般的なタスクの基本的なビルディングブロックを開発することができました。ただし、スキームに適した高レベルのネットワークと十分なデータがある場合、そのトレーニングのプロセスは単純になります。ディープNSは、人間の開発者からの特別なガイダンスがなくても、非常に広範囲の複雑なパターンを認識することができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん制限があります。</font><font style="vertical-align: inherit;">たとえば、GOだけでロボモービルをトレーニングするというアイデアに夢中になっている人もいます。つまり、カメラから受け取った画像、ニューラルネットワークから画像を受け取り、そこからステアリングホイールを回してペダルを押すように指示を受けます。</font><font style="vertical-align: inherit;">私はこのアプローチに懐疑的です。</font><font style="vertical-align: inherit;">国会は、道路で発生する特定の条件を理解するために必要な複雑な論理的推論を行う能力をまだ示していません。</font><font style="vertical-align: inherit;">さらに、NSは「ブラックボックス」であり、そのワークフローはほとんど見えません。</font><font style="vertical-align: inherit;">このようなシステムのセキュリティを評価および確認することは困難です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、GOは、予想外に広い範囲のアプリケーションで非常に大きな飛躍を可能にしました。</font><font style="vertical-align: inherit;">今後数年間で、この分野で次の進歩が期待できます。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja482248/index.html">SSDがRAIDの下でどのように表示されるか、どのアレイレベルがより収益性が高いかについての経験を共有します</a></li>
<li><a href="../ja482250/index.html">VueJSの単純な状態マシン</a></li>
<li><a href="../ja482252/index.html">自動猫トイレ-続き</a></li>
<li><a href="../ja482254/index.html">VonmoTradeの実験。パート3：令状。貿易情報の処理と保管</a></li>
<li><a href="../ja482256/index.html">AIと仕事の未来：近い将来の雇用の見通し</a></li>
<li><a href="../ja482260/index.html">TelegramBot。基本的な機能。ステッカーと顔文字。（パート3）</a></li>
<li><a href="../ja482262/index.html">Talend Open Studioにログインする方法</a></li>
<li><a href="../ja482264/index.html">ブラジル、ダークマジック、モータルコンバット、火星、15,000人。オンティコ年結果</a></li>
<li><a href="../ja482268/index.html">未来の巨大構造：ダイソン球、恒星エンジン、「ブラックホール爆弾」</a></li>
<li><a href="../ja482272/index.html">Prometheusのデータウェアハウスの選択：ThanosとVictoriaMetrics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
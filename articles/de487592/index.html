<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú® üëàüèª üöµüèΩ VMware vSAN 6.7 - Und der Donner schlug ein ‚úçüèº üíÉüèº üíù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Jahr 2018 ging zu Ende ... 
 
 Einmal, an einem klaren Dezembertag, entschied sich unser Unternehmen, eine neue Hardware zu kaufen. Nein, das pass...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>VMware vSAN 6.7 - Und der Donner schlug ein</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487592/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Jahr 2018 ging zu Ende ... </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einmal, an einem klaren Dezembertag, entschied sich unser Unternehmen, eine neue Hardware zu kaufen. Nein, das passierte nat√ºrlich nicht √ºber Nacht. Die Entscheidung wurde fr√ºher getroffen. Viel fr√ºher. Aber wie immer stimmen unsere W√ºnsche nicht immer mit den F√§higkeiten der Aktion√§re √ºberein. Und es gab kein Geld, und wir hielten fest. Aber schlie√ülich kam dieser freudige Moment, als die √úbernahme auf allen Ebenen genehmigt wurde. Alles war in Ordnung, die Angestellten applaudierten freudig, sie hatten es satt, 25 Stunden monatlich Dokumente auf 7 Jahre alten Servern zu verarbeiten, und sie baten die IT-Abteilung sehr beharrlich, sich etwas auszudenken, um ihnen mehr Zeit f√ºr andere, ebenso wichtige Dinge zu geben .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben versprochen, die Bearbeitungszeit f√ºr Dokumente um das Dreifache auf 8 Stunden zu verk√ºrzen. </font><font style="vertical-align: inherit;">Daf√ºr wurde ein Spatz aus einer Kanone abgefeuert. </font><font style="vertical-align: inherit;">Diese Option schien die einzige zu sein, da unser Team keinen Datenbankadministrator hatte und nie hatte, der alle Arten der Abfrageoptimierung (DBA) anwendete.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Konfiguration der ausgew√§hlten Ausr√ºstung war nat√ºrlich himmelhoch. </font><font style="vertical-align: inherit;">Dies waren drei Server der Firma </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HPE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - DL560 Gen10. </font><font style="vertical-align: inherit;">Jeder von ihnen verf√ºgte √ºber 4 Intel Xeon Platinum 8164 2,0-GHz-Prozessoren mit 26 Kernen, 256 DDR4-RAM sowie 8 SSD 800 Gb SAS (800 Gb WD Ultrastar DC SS530 WUSTR6480ASS204 SSD) + 8 1,92 TB SSD (Western Digital Ultrastar DC SS530) )</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese "Eisenst√ºcke" waren f√ºr den VMware-Cluster (HA + DRS + vSAN) bestimmt. Das arbeitet seit fast 3 Jahren mit uns auf √§hnlichen Servern der 7. und 8. Generation, ebenfalls von HPE. √úbrigens gab es keine Probleme, bis HPE sich weigerte, sie zu unterst√ºtzen und ESXi ohne Tamburin von Version 6.0 auf 6.5 zu aktualisieren. Okay, als Ergebnis war es m√∂glich zu aktualisieren. Durch √Ñndern des Installationsabbilds, Entfernen inkompatibler Problemmodule aus dem Installationsabbild usw. Dies f√ºgte auch dem Feuer unseres Wunsches hinzu, alles Neue zusammenzubringen. Wenn es nicht die neuen vSAN-Chips g√§be, h√§tten wir im Sarg ein Update des gesamten Systems von Version 6.0 auf eine neuere Version gesehen, und es w√§re nicht n√∂tig, einen Artikel zu schreiben, aber wir suchen nicht nach einfachen Wegen ...</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Also kauften wir diese Ausr√ºstung und beschlossen, die l√§ngst veraltete zu ersetzen. Wir haben den letzten </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SPP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auf jeden neuen Server </font><font style="vertical-align: inherit;">angewendet </font><font style="vertical-align: inherit;">, auf dem jeweils zwei Ethernet 10G-Netzwerkkarten installiert sind (eine f√ºr Benutzernetzwerke und die zweite f√ºr SAN, 656596-B21 HP Ethernet 10Gb 2-Port 530T). Ja, jeder neue Server wurde mit einer SFP + -Netzwerkkarte ohne Module geliefert, aber unsere Netzwerkinfrastruktur implizierte Ethernet (zwei Stapel von DELL 4032N-Switches f√ºr LAN- und SAN-Netzwerke), und der HP Distributor in Moskau verf√ºgte nicht √ºber HPE 813874-B21-Module und wir Sie haben nicht gewartet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als es an der Zeit war, ESXi zu installieren und neue Knoten in ein gemeinsames VMware-Rechenzentrum zu integrieren, geschah ein ‚ÄûWunder‚Äú. Wie sich herausstellte, ist HPE ESXi Custom ISO Version 6.5 und niedriger nicht f√ºr die Installation auf neuen Gen10-Servern ausgelegt. Nur Hardcore, nur 6.7. Und wir mussten unabsichtlich den Vorschriften des ‚Äûvirtuellen Unternehmens‚Äú folgen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es wurde ein neuer HA + DRS-Cluster erstellt, ein vSAN-Cluster wurde erstellt, und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dies</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> alles unter strikter Einhaltung von VMware HCL und </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">diesem Dokument</font></a><font style="vertical-align: inherit;"> . Alles wurde gem√§√ü Feng Shui konfiguriert und nur periodische ‚ÄûAlarme‚Äú waren bei der √úberwachung von vSAN auf Parameterwerte ungleich Null in diesem Abschnitt verd√§chtig:</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/800/65a/ff5/80065aff58945762f1660b556d61216e.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben beruhigt alle virtuellen Maschinen (ca. 50 Teile) auf neue Server verschoben und auf den neuen vSAN-Speicher, der bereits auf SSD-Festplatten aufgebaut war, die Leistung der Dokumentenverarbeitung in der neuen Umgebung √ºberpr√ºft (√ºbrigens hat sich herausgestellt, dass dies viel mehr Zeit spart als geplant). . Bis die schwerste Basis in den neuen Cluster √ºbertragen wurde, dauerte die am Anfang des Artikels erw√§hnte Operation etwa 4 statt 25 Stunden! Dies war ein wesentlicher Beitrag zur Neujahrsstimmung aller Teilnehmer des Prozesses. Einige tr√§umten wahrscheinlich von einem Preis. Dann gingen alle gl√ºcklich in die Neujahrsferien.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als die Wochentage des neuen Jahres 2019 begannen, deutete nichts auf eine Katastrophe hin. Alle Dienste, die ohne √úbertreibung auf neue Kapazit√§ten √ºbertragen wurden, starteten! Nur Ereignisse im Bereich der Neusynchronisierung von Objekten wurden viel mehr. Und nach ein paar Wochen gab es √Ñrger. Am fr√ºhen Morgen reagierten fast alle wichtigen Dienste des Unternehmens (1s, MSSQL, SMB, Exchange usw.) nicht mehr oder mit einer langen Verz√∂gerung. Die gesamte Infrastruktur st√ºrzte in v√∂lliges Chaos, und niemand wusste, was passiert war und was zu tun war. Alle virtuellen Maschinen in vCenter sahen "gr√ºn" aus, es gab keine Fehler bei ihrer √úberwachung. Ein Neustart hat nicht geholfen. Dar√ºber hinaus konnten einige Computer nach einem Neustart nicht einmal starten und zeigten verschiedene Prozessfehler in der Konsole an. Die H√∂lle schien zu uns zu kommen und der Teufel rieb sich erwartungsvoll die H√§nde.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unter dem Druck ernsthaften Stresses konnte die Ursache der Katastrophe ermittelt werden. Dieses Problem stellte sich als verteilter vSAN-Speicher heraus. Auf den ersten Blick kam es zu einer unkontrollierten Datenbesch√§digung auf Festplatten virtueller Maschinen - ohne Grund. Zu dieser Zeit schien die einzige L√∂sung, die vern√ºnftig erschien, den technischen Support von VMware mit Schreien zu kontaktieren: SOS, Save-Help! </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Entscheidung rettete das Unternehmen anschlie√üend vor dem Verlust relevanter Daten, einschlie√ülich Mitarbeiterpostf√§cher, Datenbanken und freigegebener Dateien. Zusammen sprechen wir √ºber 30 Terabyte an Informationen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Er ist verpflichtet, den Mitarbeitern des VMware-Supports Tribut zu zollen, die nicht mit dem Inhaber des Abonnements f√ºr technischen Basis-Support ‚ÄûFu√üball gespielt‚Äú haben, sondern diesen Fall in das Enterpise-Segment aufgenommen haben und den Prozess rund um die Uhr durchlaufen haben. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was danach geschah:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der technische Support von VMware stellte zwei Hauptfragen: Wie k√∂nnen Daten wiederhergestellt und das Problem der Besch√§digung von Phantomdaten auf Festplatten virtueller Maschinen im Kampfcluster "vSAN" gel√∂st werden? </font><font style="vertical-align: inherit;">√úbrigens waren die Daten nirgends wiederherzustellen, da der zus√§tzliche Speicher von Sicherungskopien belegt war und es einfach keinen Ort gab, an dem "Kampf" -Dienste bereitgestellt werden konnten.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">W√§hrend ich gemeinsam mit VMware versuchte, die ‚Äûbesch√§digten‚Äú Objekte im vSAN-Cluster zusammenzustellen, haben meine Kollegen dringend einen neuen Speicher abgebaut, der alle √ºber 30 Terabyte Unternehmensdaten aufnehmen kann.</font></font></li>
<li>  ,   ,     VMware      ,           ,     ¬´¬ª      - -   .         , ? </li>
<li>        .</li>
<li> ,  ¬´ ¬ª   .</li>
<li>          ,   ,   ¬´¬ª        .</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich musste vor√ºbergehend (f√ºr ein paar Tage) die Effizienz der Post opfern, um zus√§tzliche 6 Terabyte freien Speicherplatz im Gesch√§ft zu erhalten, um die Schl√ºsseldienste zu starten, von denen die Einnahmen des Unternehmens abhingen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tausende von Chatlines mit englischsprachigen Kollegen von VMware wurden "f√ºr den Speicher" gespeichert. Hier ein kurzer Auszug aus unseren Gespr√§chen:</font></font></li>
</ol><br>
<pre><code class="plaintext">I understood that you are now migrating all the VMs out of vSAN datastore.<font></font>
May I know, how the migration task is going on.? How many VMs left and how much time is expected to migrate the remaining VMs. ?<font></font>
There are 6 vms still need to be migrated. 1 of them is fail so far.<font></font>
How much time is expected to complete the migration for the working VMs..?<font></font>
I think atleast 2-3 hours<font></font>
ok<font></font>
Can you please SSH to vCenter server ?<font></font>
you on it<font></font>
/localhost/Datacenter ###CLUB/computers/###Cluster&gt; vsan.check_state .<font></font>
2019-02-02 05:22:34 +0300: Step 1: Check for inaccessible vSAN objects<font></font>
Detected 3 objects to be inaccessible<font></font>
Detected 7aa2265c-6e46-2f49-df40-20677c0084e0 on esxi-dl560-gen10-2.####.lan to be inaccessible<font></font>
Detected 99c3515c-bee0-9faa-1f13-20677c038dd8 on esxi-dl560-gen10-3.####.lan to be inaccessible<font></font>
Detected f1ca455c-d47e-11f7-7e90-20677c038de0 on esxi-dl560-gen10-1.####.lan to be inaccessible<font></font>
2019-02-02 05:22:34 +0300: Step 2: Check for invalid/inaccessible VMs<font></font>
Detected VM 'i.#####.ru' as being 'inaccessible'<font></font>
2019-02-02 05:22:34 +0300: Step 3: Check for VMs for which VC/hostd/vmx are out of sync<font></font>
Did not find VMs for which VC/hostd/vmx are out of sync<font></font>
/localhost/Datacenter ###CLUB/computers/###Cluster&gt;<font></font>
Thank you<font></font>
second vm with issues: sd.####.ru</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie sich dieses Problem manifestierte (zus√§tzlich zu den fest gesunkenen Organisationsdiensten). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exponentielles Wachstum von Pr√ºfsummenfehlern (CRC) aus heiterem Himmel w√§hrend des Datenaustauschs mit Festplatten im HBA-Modus. </font><font style="vertical-align: inherit;">So √ºberpr√ºfen Sie dies: Geben Sie den folgenden Befehl in die Konsole jedes ESXi-Knotens ein:</font></font><br>
<br>
<pre><code class="cs">while true; do clear; for disk in $(localcli vsan storage list | grep -B10 'ity Tier: tr' |grep "VSAN UUID"|awk '{print $3}'|sort -u);do echo ==DISK==$disk====;vsish -e get /vmkModules/lsom/disks/$disk/checksumErrors | grep -v ':0';done; sleep 3; done</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis der Ausf√ºhrung werden CRC-Fehler f√ºr jede Festplatte im vSAN-Cluster dieses Knotens angezeigt (Nullwerte werden nicht angezeigt). </font><font style="vertical-align: inherit;">Wenn Sie positive Werte haben und diese dar√ºber hinaus st√§ndig wachsen, gibt es einen Grund f√ºr st√§ndig auftretende Aufgaben im Abschnitt Monitor -&gt; vSAN -&gt; Resincing-Objekte des Clusters. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie kann ich Festplatten von virtuellen Maschinen wiederherstellen, die nicht mit Standardmitteln klonen oder migrieren? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wer h√§tte gedacht, mit dem m√§chtigen Befehl cat:</font></font><br>
<br>
<pre><code class="bash">1. cd      vSAN<font></font>
[root@esxi-dl560-gen10-1:~] cd /vmfs/volumes/vsanDatastore/estaff<font></font>
<font></font>
2. grep vmdk     uuid<font></font>
<font></font>
[root@esxi-dl560-gen10-1:/vmfs/volumes/vsan:52f53dfd12dddc84-f712dbefac32cd1a/2636a75c-e8f1-d9ca-9a00-20677c0084e0] grep vsan *vmdk<font></font>
estaff.vmdk:RW 10485760 VMFS "vsan://3836a75c-d2dc-5f5d-879c-20677c0084e0"<font></font>
estaff_1.vmdk:RW 41943040 VMFS "vsan://3736a75c-e412-a6c8-6ce4-20677c0084e0"<font></font>
[root@esxi-dl560-gen10-1:/vmfs/volumes/vsan:52f53dfd12dddc84-f712dbefac32cd1a/2636a75c-e8f1-d9ca-9a00-20677c0084e0]<font></font>
<font></font>
3.    VM  ,  :<font></font>
<font></font>
mkdir /vmfs/volumes/POWERVAULT/estaff<font></font>
<font></font>
4.   vmx  <font></font>
<font></font>
cp *vmx *vmdk /vmfs/volumes/POWERVAULT/estaff<font></font>
<font></font>
5.      ,      ^_^<font></font>
<font></font>
/usr/lib/vmware/osfs/bin/objtool open -u 3836a75c-d2dc-5f5d-879c-20677c0084e0; sleep 1; cat /vmfs/devices/vsan/3836a75c-d2dc-5f5d-879c-20677c0084e0 &gt;&gt; /vmfs/volumes/POWERVAULT/estaff/estaff-flat.vmdk<font></font>
<font></font>
6. cd   :<font></font>
<font></font>
 cd /vmfs/volumes/POWERVAULT/estaff<font></font>
<font></font>
7.    - estaff.vmdk     <font></font>
<font></font>
[root@esxi-dl560-gen10-1:/tmp] cat estaff.vmdk<font></font>
# Disk DescriptorFile<font></font>
version=4<font></font>
encoding="UTF-8"<font></font>
CID=a7bb7cdc<font></font>
parentCID=ffffffff<font></font>
createType="vmfs"<font></font>
<font></font>
# Extent description<font></font>
RW 10485760 VMFS "vsan://3836a75c-d2dc-5f5d-879c-20677c0084e0"      &lt;&lt;&lt;&lt;&lt;     "estaff-flat.vmdk"<font></font>
<font></font>
# The Disk Data Base<font></font>
#DDB<font></font>
<font></font>
ddb.adapterType = "ide"<font></font>
ddb.deletable = "true"<font></font>
ddb.geometry.cylinders = "10402"<font></font>
ddb.geometry.heads = "16"<font></font>
ddb.geometry.sectors = "63"<font></font>
ddb.longContentID = "6379fa7fdf6009c344bd9a64a7bb7cdc"<font></font>
ddb.thinProvisioned = "1"<font></font>
ddb.toolsInstallType = "1"<font></font>
ddb.toolsVersion = "10252"<font></font>
ddb.uuid = "60 00 C2 92 c7 97 ca ae-8d da 1c e2 3c df cf a5"<font></font>
ddb.virtualHWVersion = "8"<font></font>
[root@esxi-dl560-gen10-1:/tmp]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So erkennen Sie naa.xxxx ... Datentr√§ger in Datentr√§gergruppen:</font></font><br>
<br>
<pre><code class="bash">[root@esxi-dl560-gen10-1:/vmfs/volumes] vdq -Hi<font></font>
Mappings:<font></font>
   DiskMapping[0]:<font></font>
           SSD:  naa.5000c5003024eb43<font></font>
            MD:  naa.5000cca0aa0025f4<font></font>
            MD:  naa.5000cca0aa00253c<font></font>
            MD:  naa.5000cca0aa0022a8<font></font>
            MD:  naa.5000cca0aa002500<font></font>
<font></font>
   DiskMapping[2]:<font></font>
           SSD:  naa.5000c5003024eb47<font></font>
            MD:  naa.5000cca0aa002698<font></font>
            MD:  naa.5000cca0aa0029c4<font></font>
            MD:  naa.5000cca0aa002950<font></font>
            MD:  naa.5000cca0aa0028cc<font></font>
<font></font>
   DiskMapping[4]:<font></font>
           SSD:  naa.5000c5003024eb4f<font></font>
            MD:  naa.5000c50030287137<font></font>
            MD:  naa.5000c50030287093<font></font>
            MD:  naa.5000c50030287027<font></font>
            MD:  naa.5000c5003024eb5b<font></font>
            MD:  naa.5000c50030287187<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So finden Sie vUAN-UUIDs f√ºr jede Naa heraus ....:</font></font><br>
<br>
<pre><code class="bash">[root@esxi-dl560-gen10-1:/vmfs/volumes] localcli vsan storage list | grep -B15 'ity Tier: tr' | grep -E '^naa|VSAN UUID'<font></font>
<font></font>
naa.5000cca0aa002698:<font></font>
   VSAN UUID: 52247b7d-fed5-a2f2-a2e8-5371fa7ef8ed<font></font>
naa.5000cca0aa0029c4:<font></font>
   VSAN UUID: 52309c55-3ecc-3fe8-f6ec-208701d83813<font></font>
naa.5000c50030287027:<font></font>
   VSAN UUID: 523d7ea5-a926-3acd-2d58-0c1d5889a401<font></font>
naa.5000cca0aa0022a8:<font></font>
   VSAN UUID: 524431a2-4291-cb49-7070-8fa1d5fe608d<font></font>
naa.5000c50030287187:<font></font>
   VSAN UUID: 5255739f-286c-8808-1ab9-812454968734<font></font>
naa.5000cca0aa0025f4: &lt;&lt;&lt;&lt;&lt;&lt;&lt;<font></font>
   VSAN UUID: 52b1d17e-02cc-164b-17fa-9892df0c1726<font></font>
naa.5000cca0aa00253c:<font></font>
   VSAN UUID: 52bd28f3-d84e-e1d5-b4dc-54b75456b53f<font></font>
naa.5000cca0aa002950:<font></font>
   VSAN UUID: 52d6e04f-e1af-cfb2-3230-dd941fd8a032<font></font>
naa.5000c50030287137:<font></font>
   VSAN UUID: 52df506a-36ea-f113-137d-41866c923901<font></font>
naa.5000cca0aa002500:<font></font>
   VSAN UUID: 52e2ce99-1836-c825-6600-653e8142e10f<font></font>
naa.5000cca0aa0028cc:<font></font>
   VSAN UUID: 52e89346-fd30-e96f-3bd6-8dbc9e9b4436<font></font>
naa.5000c50030287093:<font></font>
   VSAN UUID: 52ecacbe-ef3b-aa6e-eba3-6e713a0eb3b2<font></font>
naa.5000c5003024eb5b:<font></font>
   VSAN UUID: 52f1eecb-befa-12d6-8457-a031eacc1cab</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und das Wichtigste. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Problem stellte sich als fehlerhafter Betrieb der Firmware des RAID-Controllers und des HPE-Treibers mit vSAN heraus. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zuvor war in VMware 6.7 U1 die kompatible Firmware f√ºr den HPE Smart Array P816i-a SR Gen10-Controller in vSAN HCL Version 1.98 (was sich f√ºr unser Unternehmen als schwerwiegend herausstellte). Jetzt </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hei√üt es 1,65</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dar√ºber hinaus befand sich die Version 1.99, mit der das Problem zu diesem Zeitpunkt (31. Januar 2019) gel√∂st wurde, bereits in den HPE-Beh√§ltern, wurde jedoch weder an VMware noch an uns weitergegeben, was auf die fehlende Zertifizierung trotz unserer Haftungsausschl√ºsse und all dessen hinweist Sie sagen, die Hauptsache f√ºr uns ist, das Problem mit dem Speicher zu l√∂sen und das war's. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Infolgedessen wurde das Problem erst nach drei Monaten behoben, als die Firmware-Version 1.99 f√ºr den Festplattencontroller ver√∂ffentlicht wurde!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Welche Schlussfolgerungen habe ich gezogen?</font></font><br>
<br>
<ol>
<li>     (   ),         .</li>
<li>     !   .</li>
<li>       ¬´¬ª ,   ¬´¬ª    ¬´¬ª   ,    30%      ¬´¬ª.</li>
<li>HPE,    ,           .</li>
<li> ,       :<br>
<br>
<ul>
<li>HPE -           .   ,     Enterprise       . ,    ,       ).</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich habe keine Situation vorausgesehen, in der zus√§tzlicher Speicherplatz erforderlich sein k√∂nnte, um im Notfall Kopien aller Server des Unternehmens zu platzieren.</font></font></li>
</ul></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Angesichts der Ereignisse werde ich f√ºr VMware keine Hardware mehr f√ºr gro√üe Unternehmen und andere Anbieter als DELL kaufen. </font><font style="vertical-align: inherit;">Warum, weil DELL, soweit ich wei√ü, VMware erworben hat und nun die Integration von Hardware und Software in diese Richtung so nah wie m√∂glich sein d√ºrfte.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie sie sagen, in Milch verbrannt, ins Wasser blasen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das sind alle Leute. </font><font style="vertical-align: inherit;">Ich w√ºnschte, Sie w√ºrden niemals in solch schreckliche Situationen geraten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Soweit ich mich erinnere, werde ich schon erschrecken!</font></font></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de487570/index.html">Redis Best Practices, Teil 2</a></li>
<li><a href="../de487578/index.html">CMake-Optimierung f√ºr statische Bibliotheken</a></li>
<li><a href="../de487582/index.html">Keine G√∂tter verbrennen T√∂pfe</a></li>
<li><a href="../de487584/index.html">Githabifizierung der Informationssicherheit</a></li>
<li><a href="../de487588/index.html">Quarkus: Subatomarer √úberschalltierarzt</a></li>
<li><a href="../de487594/index.html">Unterhaltsame Mnemonik: Wir sammeln das auditive Ged√§chtnis aus dem Visuellen</a></li>
<li><a href="../de487596/index.html">Eugene Varavva, ein Entwickler bei Google. Wie man Google in 5 Worten beschreibt</a></li>
<li><a href="../de487604/index.html">Kurznotizen des Programmierers einbetten: Abschnittsduplizierung im Speicher des Mikrocontrollers</a></li>
<li><a href="../de487606/index.html">Visualisierung von Spannungslinien und Bewegungen elektrostatischer Ladungen, Simulation der Planetenbewegung des Sonnensystems</a></li>
<li><a href="../de487610/index.html">RealWorld: aiohttp, Tortoise ORM</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
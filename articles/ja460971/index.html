<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔦 🦃 👨🏼‍🌾 NVIDIA Jetson Nano：テストと第一印象-パート2、AIテスト 🛫 🕴🏼 🤟🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、ハブル。最初の部分、NVIDIA JETSONナノが考えられていた- 、ラズベリーパイフォームファクタボードGPUを使用してコンピューティング性能に焦点を当てました。 AI指向の計算のために、設計された目的でボードをテストする時が来ました。 画像の分類や歩行者や猫の認識（それらがない場合...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>NVIDIA Jetson Nano：テストと第一印象-パート2、AIテスト</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460971/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは、ハブル。</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">最初の部分</font></a><font style="vertical-align: inherit;">、NVIDIA JETSONナノが考えられていた- 、ラズベリーパイフォームファクタボードGPUを使用してコンピューティング性能に焦点を当てました。 AI指向の計算のために、設計された目的でボードをテストする時が来ました。</font><font style="vertical-align: inherit;">
画像の分類や歩行者や猫の認識（それらがない場合）など、さまざまなタスクがボード上でどのように行われるかを検討します。すべてのテストについて、デスクトップ、Jetson Nano、またはRaspberry Piで実行できるソースコードが提供されています。興味のある方は、カットを続けてください。</font></font><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br>
<img src="https://habrastorage.org/webt/91/1a/7i/911a7i0fv9k20_edm9oftroelpq.png"><br>
<br><font style="vertical-align: inherit;"></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このボードを使用するには2つの方法があります。</font><font style="vertical-align: inherit;">1つ目は、KerasやTensorflowなどの標準フレームワークを実行することです。</font><font style="vertical-align: inherit;">原理的には機能しますが、最初の部分ですでに見たように、Jetson Nanoはもちろん、本格的なデスクトップまたはラップトップのビデオカードよりも劣っています。</font><font style="vertical-align: inherit;">ユーザーはモデルを最適化するタスクを引き受ける必要があります。</font><font style="vertical-align: inherit;">2番目の方法は、ボードに付属する既製のクラスを取ることです。</font><font style="vertical-align: inherit;">それはより単純で「そのまま」機能しますが、マイナス点はすべての実装の詳細が大幅に非表示になることです。さらに、カスタムsdkを調べて使用する必要があるため、これらのボードの他に、他の場所では役に立ちません。</font><font style="vertical-align: inherit;">ただし、両方の方法について説明します。最初の方法から始めます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">画像分類</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像認識の問題を考えてみましょう。</font><font style="vertical-align: inherit;">これを行うには、Kerasで提供されるResNet50モデルを使用します（このモデルは、2015年のImageNetチャレンジの優勝者でした）。</font><font style="vertical-align: inherit;">それを使用するには、数行のコードで十分です。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> time<font></font>
<font></font>
<font></font>
IMAGE_SIZE = <span class="hljs-number">224</span>
IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number">3</span>)<font></font>
resnet = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE)<font></font>
<font></font>
img = tf.contrib.keras.preprocessing.image.load_img(<span class="hljs-string">'cat.png'</span>, target_size=(IMAGE_SIZE, IMAGE_SIZE))<font></font>
t_start = time.time()<font></font>
img_data = tf.contrib.keras.preprocessing.image.img_to_array(img)<font></font>
x = tf.contrib.keras.applications.resnet50.preprocess_input(np.expand_dims(img_data, axis=<span class="hljs-number">0</span>))<font></font>
probabilities = resnet.predict(x)<font></font>
<font></font>
print(tf.contrib.keras.applications.resnet50.decode_predictions(probabilities, top=<span class="hljs-number">5</span>))<font></font>
print(<span class="hljs-string">"dT"</span>, time.time() - t_start)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私はネタバレの下のコードを削除し始めませんでした。</font><font style="vertical-align: inherit;">彼はとても小さいです。</font><font style="vertical-align: inherit;">ご覧のように、画像は最初に224x224（これは入力ネットワーク形式です）にサイズ変更され、最後に、予測関数がすべての作業を行います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
猫の写真を撮ってプログラムを実行します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_q/e8/ln/_qe8ln2w3hsmbw4dqcy7kdnuft0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果：</font></font><br>
<br>
<pre><code class="python hljs">[[(<span class="hljs-string">'n02123045'</span>, <span class="hljs-string">'tabby'</span>, <span class="hljs-number">0.765179</span>), (<span class="hljs-string">'n02123159'</span>, <span class="hljs-string">'tiger_cat'</span>, <span class="hljs-number">0.19059166</span>), (<span class="hljs-string">'n02124075'</span>, <span class="hljs-string">'Egyptian_cat'</span>, <span class="hljs-number">0.013605555</span>), (<span class="hljs-string">'n04493381'</span>, <span class="hljs-string">'tub'</span>, <span class="hljs-number">0.0025916891</span>), (<span class="hljs-string">'n04553703'</span>, <span class="hljs-string">'washbasin'</span>, <span class="hljs-number">0.0021566998</span>)]]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もう一度、彼の英語の知識に動揺しています（私は何人の非ネイティブの人が「タビー」が何であるか知っていますか？）、出力を辞書と比較すると、はい、すべてが機能します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PCでのコード実行時間は</font><font style="vertical-align: inherit;">、CPUでの計算で</font><font style="vertical-align: inherit;">は</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.5秒</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、GPUの計算では</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2c</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（！）でした。ログから判断すると、問題はモデル内またはTensorflow内にありますが、コードが開始すると、コードは大量のメモリを割り当てようとし、「Allocator（GPU_0_bfc）がメモリ不足になり、freed_by_count = 0で2.13GiBを割り当てようとしています。 。これは警告であり、エラーではありませんが、コードは機能しますが、本来の速度よりもはるかに遅くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetson Nanoではさらに低速です</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。CPU</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">では</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.8c</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、GPUでは</font><b><font style="vertical-align: inherit;">18.8cです</font></b><font style="vertical-align: inherit;">が、出力は次のようになります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/t6/ok/ja/t6okja2fzqx_tjvmd6evens5dn8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一般に、画像あたり3秒でさえ、これはまだリアルタイムではありません。スタックオーバーフローで推奨されているgpu_options.allow_growthオプションを設定しても効果がありません。別の方法を知っている人がいる場合は、コメントに書き込んでください。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">編集</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：コメントで提案されているように、テンソルフローの最初の開始には常に長い時間がかかり、それを使用して時間を測定することは正しくありません。実際、2番目以降のファイルを処理すると、結果ははるかに良くなります-GPUなしで0.6秒、GPUありで0.2秒。ただし、デスクトップでは、速度はそれぞれ2.0秒と0.05秒です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ResNet50の便利な機能は、最初の起動時にモデル全体をディスク（約100 MB）に送り出し、コードは登録とSMSなしで完全に自律的に機能することです。</font><font style="vertical-align: inherit;">最近のほとんどのAIサービスはサーバー上でのみ機能し、インターネットがなければデバイスは「カボチャ」に変わるので、これは特に便利です。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">猫対犬</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次の問題を考えてください。</font><font style="vertical-align: inherit;">Kerasを使用して、猫と犬を区別できるニューラルネットワークを作成します。</font><font style="vertical-align: inherit;">これは畳み込みニューラルネットワーク（CNN-畳み込みニューラルネットワーク）になります</font><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">この</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">出版物</font><font style="vertical-align: inherit;">からネットワーク設計を取り上げます</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">猫と犬の画像のトレーニングセットはtensorflow_datasetsパッケージにすでに含まれているため、自分で写真を撮る必要はありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像のセットを読み込み、トレーニング、検証、テストの3つのブロックに分割します。</font><font style="vertical-align: inherit;">各画像を「正規化」して、色を0..1の範囲にします。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers
<span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds
<span class="hljs-keyword">from</span> keras.preprocessing <span class="hljs-keyword">import</span> image
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> time<font></font>
<font></font>
<font></font>
IMAGE_SIZE = <span class="hljs-number">64</span>
IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number">3</span>)<font></font>
<font></font>
splits = tfds.Split.TRAIN.subsplit(weighted=(<span class="hljs-number">80</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>))<font></font>
(cat_train, cat_valid, cat_test), info = tfds.load(<span class="hljs-string">'cats_vs_dogs'</span>, split=list(splits), with_info=<span class="hljs-literal">True</span>, as_supervised=<span class="hljs-literal">True</span>)<font></font>
label_names = info.features[<span class="hljs-string">'label'</span>].int2str<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pre_process_image</span>(<span class="hljs-params">image, label</span>):</span><font></font>
    image = tf.cast(image, tf.float32)<font></font>
    image = image / <span class="hljs-number">255.0</span>  <span class="hljs-comment"># Normalize image: 0..255 -&gt; 0..1</span><font></font>
    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))<font></font>
    <span class="hljs-keyword">return</span> image, label<font></font>
<font></font>
BATCH_SIZE = <span class="hljs-number">32</span>
SHUFFLE_BUFFER_SIZE = <span class="hljs-number">1000</span><font></font>
train_batch = cat_train.map(pre_process_image).shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(BATCH_SIZE)<font></font>
validation_batch = cat_valid.map(pre_process_image).repeat().batch(BATCH_SIZE)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
畳み込みニューラルネットワークを生成する関数を記述します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">custom_model</span>():</span>
    <span class="hljs-comment"># Source: https://medium.com/@ferhat00/deep-learning-with-keras-classifying-cats-and-dogs-part-1-982067594856</span><font></font>
    classifier = tf.keras.Sequential()<font></font>
    <span class="hljs-comment"># Step 1 — Convolution</span>
    classifier.add(layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), input_shape=IMG_SHAPE, activation=<span class="hljs-string">'relu'</span>))
    <span class="hljs-comment"># Step 2 — Pooling</span>
    classifier.add(layers.MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))
    <span class="hljs-comment"># Adding a second convolutional layer</span>
    classifier.add(layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>))<font></font>
    classifier.add(layers.MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))
    <span class="hljs-comment"># Step 3 — Flattening</span><font></font>
    classifier.add(layers.Flatten())<font></font>
    <span class="hljs-comment"># Step 4 — Full connection</span>
    classifier.add(layers.Dense(units=<span class="hljs-number">128</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    classifier.add(layers.Dense(units=<span class="hljs-number">1</span>, activation=<span class="hljs-string">'sigmoid'</span>))
    <span class="hljs-comment"># Compiling the CNN we shall use the Adam stochastic optimisation method, binary cross entropy loss function</span>
    classifier.compile(optimizer=tf.keras.optimizers.Adam(), loss=<span class="hljs-string">'binary_crossentropy'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-keyword">return</span> classifier
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで、「cat-dog」キットでネットワークトレーニングを実行できます。</font><font style="vertical-align: inherit;">トレーニングには時間がかかるため（GPUでは20分、CPUでは1〜2時間）、終了したらモデルをファイルに保存します。</font></font><br>
<br>
<pre><code class="python hljs">tl_model = custom_model()<font></font>
<font></font>
t_start = time.time()<font></font>
tl_model.fit(train_batch, steps_per_epoch=<span class="hljs-number">8000</span>, epochs=<span class="hljs-number">2</span>, validation_data=validation_batch, validation_steps=<span class="hljs-number">10</span>, callbacks=<span class="hljs-literal">None</span>)<font></font>
print(<span class="hljs-string">"Training done, dT:"</span>, time.time() - t_start)<font></font>
print(tl_model.summary())<font></font>
<font></font>
validation_steps = <span class="hljs-number">20</span><font></font>
loss0, accuracy0 = tl_model.evaluate(validation_batch, steps=validation_steps)<font></font>
print(<span class="hljs-string">"Loss: {:.2f}"</span>.format(loss0))<font></font>
print(<span class="hljs-string">"Accuracy: {:.2f}"</span>.format(accuracy0))<font></font>
<font></font>
tl_model.save(<span class="hljs-string">"dog_cat_model.h5"</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ちなみに、Jetson Nanoで直接トレーニングを開始する試みは失敗しました-5分間でボードが過熱してハングしました。リソースを集中的に使用する計算では、ボードにクーラーが必要ですが、概して、Jetson Nanoで直接そのようなタスクを実行することは意味がありません。PCでモデルをトレーニングし、Nanoで完成した保存済みファイルを使用できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、別の落とし穴が出ました-tensowflowバージョン14ライブラリがPCにインストールされており、これまでのJetson Nanoの最新バージョンは13です。そして、14番目のバージョンで保存されたモデルが13番目に読み込まれなかったため、pipを使用して同じバージョンをインストールする必要がありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後に、ファイルからモデルをロードし、それを使用して画像を認識することができます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_model</span>(<span class="hljs-params">model, image_file</span>):</span><font></font>
    img = image.load_img(image_file, target_size=(IMAGE_SIZE, IMAGE_SIZE))<font></font>
    t_start = time.time()<font></font>
    img_arr = np.expand_dims(img, axis=<span class="hljs-number">0</span>)<font></font>
    result = model.predict_classes(img_arr)<font></font>
    print(<span class="hljs-string">"Result: {}, dT: {}"</span>.format(label_names(result[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]), time.time() - t_start))<font></font>
<font></font>
model = tf.keras.models.load_model(<span class="hljs-string">'dog_cat_model.h5'</span>)<font></font>
<font></font>
predict_model(model, <span class="hljs-string">"cat.png"</span>)<font></font>
predict_model(model, <span class="hljs-string">"dog1.png"</span>)<font></font>
predict_model(model, <span class="hljs-string">"dog2.png"</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
猫の写真も同じように使用されましたが、「犬」テストでは2つの写真が使用されました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2m/0m/6f/2m0m6fvejlzvcdfuewdq2m9b5ug.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初の</font><font style="vertical-align: inherit;">写真は</font><font style="vertical-align: inherit;">正しく推測され、2番目の写真は最初にエラーがあり、ニューラルネットワークが猫だと思ったため、トレーニングの反復回数を増やす必要がありました。</font><font style="vertical-align: inherit;">しかし、私もおそらく最初は間違っているでしょう;）</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetson Nanoでの実行時間は非常に短いことがわかりました-最初の写真は0.3秒で処理されましたが、後続のすべての写真ははるかに高速でした。データはメモリにキャッシュされているようです。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/hx/w1/vg/hxw1vgfb217p1usxaftimpmkybo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一般に、このような単純なニューラルネットワークでは、最適化を行わなくてもボードの速度は十分であり、リアルタイムのビデオでも100fpsで十分な値であると想定できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ご覧のように、KerasとTensorflowの標準モデルでさえ、Nanoで使用できます。</font><font style="vertical-align: inherit;">ただし、結果は改善される可能性があり</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">モデルの最適化とメモリサイズの削減に関する説明は、</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">こちらで参照</font></a><font style="vertical-align: inherit;">でき</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、幸いなことに、メーカーはすでにこれを行っています。</font><font style="vertical-align: inherit;">読者がまだ興味を持っている場合、最後の部分は</font><font style="vertical-align: inherit;">Jetson Nanoでの作業用に最適化された</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">既製のライブラリーに</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">専念し</font><font style="vertical-align: inherit;">ます。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja460959/index.html">マイクロソフトの新しいテクノロジーにより、実在する人物の3Dコピーで任意の言語を話すことができます</a></li>
<li><a href="../ja460961/index.html">混合Swift + Objective-Cプロジェクトでの単体テストのセットアップ</a></li>
<li><a href="../ja460965/index.html">これらのストーリーボードなしでコントローラーを分割</a></li>
<li><a href="../ja460967/index.html">トロイハント：情報技術の専門家のための10の個人的な金融レッスン</a></li>
<li><a href="../ja460969/index.html">マーガレット・ハミルトン：「彼らは男性が反逆するのではないかと心配していました。しかし、それは起こりませんでした」</a></li>
<li><a href="../ja460973/index.html">18650バッテリーの接触溶接</a></li>
<li><a href="../ja460979/index.html">若返りバイオテクノロジーは現実的で不可避です</a></li>
<li><a href="../ja460981/index.html">Catelフレームワークに基づいて構築されたWPFアプリケーション構成のMVVM実装</a></li>
<li><a href="../ja460983/index.html">私は本物ではない</a></li>
<li><a href="../ja460985/index.html">2019年の14の最高のかんばんツール</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
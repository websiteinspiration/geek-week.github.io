<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐄 🏛️ 👨‍🏭 Assurer une haute disponibilité des applications avec Kafka Streams 🥣 🧕🏼 🌰</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kafka Streams est une bibliothèque Java pour l'analyse et le traitement des données stockées dans Apache Kafka. Comme toute autre plate-forme de trait...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Assurer une haute disponibilité des applications avec Kafka Streams</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488558/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams est une bibliothèque Java pour l'analyse et le traitement des données stockées dans Apache Kafka. </font><font style="vertical-align: inherit;">Comme toute autre plate-forme de traitement en streaming, il est capable d'effectuer un traitement de données avec et / ou sans conservation d'état en temps réel. </font><font style="vertical-align: inherit;">Dans cet article, je vais essayer de décrire pourquoi la haute disponibilité (99,99%) est problématique dans Kafka Streams et ce que nous pouvons faire pour y parvenir.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'est-ce qu'on a besoin de savoir</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avant de décrire le problème et les solutions possibles, regardons les concepts de base de Kafka Streams. </font><font style="vertical-align: inherit;">Si vous avez travaillé avec les API Kafka pour les consommateurs / producteurs, la plupart de ces paradigmes vous sont familiers. </font><font style="vertical-align: inherit;">Dans les sections suivantes, je vais essayer de décrire en quelques mots le stockage des données dans les partitions, le rééquilibrage des groupes de consommateurs et comment les concepts de base des clients Kafka s'intègrent dans la bibliothèque Kafka Streams.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Partitionnement des données</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le monde de Kafka, les applications de producteurs envoient des données sous forme de paires clé-valeur à un sujet spécifique. </font><font style="vertical-align: inherit;">Le sujet lui-même est divisé en une ou plusieurs partitions dans les courtiers Kafka. </font><font style="vertical-align: inherit;">Kafka utilise une clé de message pour indiquer dans quelle partition les données doivent être écrites. </font><font style="vertical-align: inherit;">Par conséquent, les messages avec la même clé finissent toujours dans la même partition.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les applications grand public sont organisées en groupes de consommateurs, et chaque groupe peut avoir une ou plusieurs instances de consommateurs. </font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chaque instance d'un consommateur dans le groupe de consommateurs est responsable du traitement des données à partir d'un ensemble unique de partitions de la rubrique d'entrée.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les instances de consommateur sont essentiellement un moyen de développer le traitement dans votre groupe de consommateurs.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Rebalancing Consumer Group</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme nous l'avons dit précédemment, chaque instance du groupe de consommateurs reçoit un ensemble de partitions uniques à partir desquelles il consomme des données. </font><font style="vertical-align: inherit;">Chaque fois qu'un nouveau consommateur rejoint un groupe, un rééquilibrage doit avoir lieu afin qu'il obtienne une partition. </font><font style="vertical-align: inherit;">La même chose se produit lorsque le consommateur décède, le reste du consommateur doit prendre ses partitions pour s'assurer que toutes les partitions sont traitées.</font></font><br>
<cut></cut><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au début de cet article, nous avons pris connaissance du fait que la bibliothèque Kafka Streams est construite sur la base des API des producteurs et des consommateurs et le traitement des données est organisé de la même manière que la solution standard sur Kafka. Dans la configuration de Kafka Streams, le champ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est </font><font style="vertical-align: inherit;">équivalent à </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">group.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dans l'API grand public. Kafka Streams pré-crée un certain nombre de threads et chacun d'eux effectue le traitement des données à partir d'une ou plusieurs partitions de rubriques d'entrée. S'exprimant dans la terminologie de l'API Consumer, les flux coïncident essentiellement avec les instances de Consumer du même groupe. Les threads sont le principal moyen de faire évoluer le traitement des données dans Kafka Streams, cela peut être fait verticalement en augmentant le nombre de threads pour chaque application Kafka Streams sur une machine, ou horizontalement en ajoutant une machine supplémentaire avec le même application.id. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bb7/bd3/8ed/bb7bd38edd33f26a146c12a1dea385b5.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kafka.apache.org/21/documentation/streams/architecture</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a beaucoup plus d'éléments dans Kafka Streams, tels que les tâches, la topologie de traitement, le modèle de thread, etc., dont nous ne parlerons pas dans ce post. </font><font style="vertical-align: inherit;">Plus d'informations peuvent être trouvées </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ici.</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: Stockage d'état</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le traitement de flux, il existe des opérations avec et sans conservation de l'état. </font><font style="vertical-align: inherit;">L'état est ce qui permet à l'application de se souvenir des informations nécessaires qui vont au-delà de la portée de l'enregistrement en cours de traitement.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les opérations d'état, telles que le comptage, tout type d'agrégation, les jointures, etc., sont beaucoup plus compliquées. Cela est dû au fait que n'ayant qu'un seul enregistrement, vous ne pouvez pas déterminer le dernier état (par exemple, le nombre) pour une clé donnée, vous devez donc stocker l'état de votre flux dans votre application. Comme nous l'avons vu précédemment, chaque thread traite un ensemble de partitions uniques; par conséquent, un thread ne traite qu'un sous-ensemble de l'ensemble de données. Cela signifie que chaque thread d'application Kafka Streams avec le même application.id conserve son propre état isolé. Nous n'entrerons pas dans les détails sur la façon dont l'état est formé dans Kafka Streams, mais il est important de comprendre que l'état est restauré à l'aide de la rubrique du journal des modifications et est enregistré non seulement sur le disque local, mais aussi dans Kafka Broker.L'enregistrement du journal des changements d'état dans Kafka Broker en tant que rubrique distincte est effectué non seulement pour la tolérance aux pannes, mais également pour que vous puissiez facilement déployer de nouvelles instances de Kafka Streams avec le même application.id. Étant donné que l'état est stocké en tant que rubrique de journal des modifications du côté du courtier, une nouvelle instance peut charger son propre état à partir de cette rubrique.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour plus d'informations sur le stockage d'état, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cliquez ici</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pourquoi la haute disponibilité pose-t-elle problème avec les flux Kafka?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons examiné les concepts et principes de base du traitement des données avec Kafka Streams. </font><font style="vertical-align: inherit;">Essayons maintenant de combiner toutes les pièces ensemble et analysons pourquoi la haute disponibilité peut être problématique. </font><font style="vertical-align: inherit;">Dans les sections précédentes, nous devons nous rappeler:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Les données de la rubrique Kafka sont divisées en partitions, qui sont réparties entre les flux Kafka Streams.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Les applications Kafka Streams avec la même application.id sont, en fait, un groupe de consommateurs, et chacun de ses threads est une instance isolée distincte du consommateur.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pour les opérations d'état, le thread conserve son propre état, qui est «réservé» par le sujet Kafka sous la forme d'un journal des modifications.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br>
<h2>TransferWise SPaaS (Stream Processing as a Service)</h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avant de souligner l'essence de cet article, permettez-moi d'abord de vous dire ce que nous avons créé dans TransferWise et pourquoi la haute disponibilité est très importante pour nous. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans TransferWise, nous avons plusieurs nœuds pour le traitement en streaming, et chaque nœud contient plusieurs instances de Kafka Streams pour chaque équipe de produits. Les instances de Kafka Streams conçues pour une équipe de développement spécifique ont un application.id spécial et ont généralement plus de 5 threads. En général, les équipes ont généralement 10 à 20 threads (équivalent au nombre d'instances de consommateurs) dans le cluster. Les applications déployées sur les nœuds écoutent les rubriques d'entrée et effectuent plusieurs types d'opérations avec et sans état sur les données d'entrée et fournissent des mises à jour de données en temps réel pour les microservices en aval ultérieurs.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les équipes de produits doivent mettre à jour les données agrégées en temps réel. </font><font style="vertical-align: inherit;">Cela est nécessaire pour offrir à nos clients la possibilité de transférer instantanément de l'argent. </font><font style="vertical-align: inherit;">Notre SLA habituel:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chaque jour, 99,99% des données agrégées doivent être disponibles en moins de 10 secondes.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour vous donner une idée, pendant les tests de résistance, Kafka Streams a pu traiter et agréger 20 085 messages d'entrée par seconde. </font><font style="vertical-align: inherit;">Ainsi, 10 secondes de SLA sous charge normale semblaient tout à fait réalisables. </font><font style="vertical-align: inherit;">Malheureusement, notre SLA n'a pas été atteint lors de la mise à jour continue des nœuds sur lesquels les applications sont déployées, et ci-dessous, je vais expliquer pourquoi cela s'est produit.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mise à jour du nœud coulissant</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Chez TransferWise, nous croyons fermement à la livraison continue de nos logiciels et publions généralement de nouvelles versions de nos services deux fois par jour. </font><font style="vertical-align: inherit;">Examinons un exemple de mise à jour de service continue simple et voyons ce qui se passe pendant le processus de publication. </font><font style="vertical-align: inherit;">Encore une fois, nous devons nous rappeler que:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les données de la rubrique Kafka sont divisées en partitions, qui sont réparties entre les flux Kafka Streams.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les applications Kafka Streams avec la même application.id sont, en fait, un groupe de consommateurs, et chacun de ses threads est une instance isolée distincte du consommateur.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour les opérations d'état, le thread conserve son propre état, qui est «réservé» par le sujet Kafka sous la forme d'un journal des modifications.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un processus de publication sur un seul nœud prend généralement de huit à neuf secondes. </font><font style="vertical-align: inherit;">Pendant la version, les instances de Kafka Streams sur le nœud «redémarrent doucement». </font><font style="vertical-align: inherit;">Ainsi, pour un seul nœud, le temps requis pour redémarrer correctement le service est d'environ huit à neuf secondes. </font><font style="vertical-align: inherit;">De toute évidence, l'arrêt d'une instance de Kafka Streams sur un nœud entraîne un rééquilibrage du groupe de consommateurs. </font><font style="vertical-align: inherit;">Étant donné que les données sont partitionnées, toutes les partitions qui appartenaient à l'instance amorçable doivent être réparties entre les applications Kafka Streams actives avec le même application.id. </font><font style="vertical-align: inherit;">Cela s'applique également aux données agrégées qui ont été enregistrées sur le disque. </font><font style="vertical-align: inherit;">Jusqu'à la fin de ce processus, les données ne seront pas traitées.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Répliques de secours</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour réduire le temps de rééquilibrage des applications Kafka Streams, il existe un concept de réplicas de sauvegarde, qui sont définis dans la configuration comme num.standby.replicas. Les réplicas de sauvegarde sont des copies du magasin d'état local. Ce mécanisme permet de répliquer le magasin d'état d'une instance de Kafka Streams à une autre. Lorsque le thread Kafka Streams meurt pour une raison quelconque, la durée du processus de récupération d'état peut être réduite. Malheureusement, pour les raisons que j'expliquerai ci-dessous, même les réplicas de sauvegarde n'aideront pas à une mise à jour continue du service.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Supposons que nous ayons deux instances de Kafka Streams sur deux machines différentes: node-a et node-b. </font><font style="vertical-align: inherit;">Pour chacune des instances de Kafka Streams, num.standby.replicas = 1 est indiqué sur ces 2 nœuds. Avec cette configuration, chaque instance de Kafka Streams conserve sa propre copie du référentiel sur un autre nœud. </font><font style="vertical-align: inherit;">Lors d'une mise à jour continue, nous avons la situation suivante:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La nouvelle version du service a été déployée sur le nœud-a.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'instance Kafka Streams sur le nœud-a est désactivée.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le rééquilibrage a commencé.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le référentiel de node-a a déjà été répliqué sur node-b, car nous avons spécifié la configuration num.standby.replicas = 1.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">node-b a déjà un cliché instantané de node-a, donc le processus de rééquilibrage se déroule presque instantanément.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">node-a redémarre.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> node-a rejoint un groupe de consommateurs.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le courtier Kafka voit une nouvelle instance de Kafka Streams et commence le rééquilibrage.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme nous pouvons le voir, num.standby.replicas n'aide que dans les scénarios d'arrêt complet d'un nœud. </font><font style="vertical-align: inherit;">Cela signifie que si le nœud-a tombait en panne, le nœud-b pourrait continuer à fonctionner correctement presque instantanément. </font><font style="vertical-align: inherit;">Mais dans une situation de mise à jour continue, après la déconnexion, le noeud-a rejoindra le groupe, et cette dernière étape entraînera un rééquilibrage. </font><font style="vertical-align: inherit;">Lorsque le nœud-a rejoint le groupe de consommateurs après un redémarrage, il sera considéré comme une nouvelle instance du consommateur. </font><font style="vertical-align: inherit;">Encore une fois, nous devons nous rappeler que le traitement des données en temps réel s'arrête jusqu'à ce qu'une nouvelle instance restaure son état à partir de la rubrique du journal des modifications.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Veuillez noter que le rééquilibrage des partitions lorsqu'une nouvelle instance est jointe à un groupe ne s'applique pas à l'API Kafka Streams, car c'est exactement ainsi que fonctionne le protocole du groupe de consommateurs Apache Kafka.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Réalisation: haute disponibilité avec les flux Kafka</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Malgré le fait que les bibliothèques clientes Kafka ne fournissent pas de fonctionnalité intégrée pour le problème mentionné ci-dessus, il existe certaines astuces qui peuvent être utilisées pour obtenir une haute disponibilité du cluster lors d'une mise à jour continue. </font><font style="vertical-align: inherit;">L'idée derrière les réplicas de sauvegarde reste valide, et disposer de machines de sauvegarde au moment opportun est une bonne solution que nous utilisons pour garantir une haute disponibilité en cas de défaillance de l'instance.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le problème avec notre configuration initiale était que nous avions un groupe de consommateurs pour toutes les équipes sur tous les nœuds. </font><font style="vertical-align: inherit;">Maintenant, au lieu d'un groupe de consommateurs, nous en avons deux, et le second agit comme un cluster «chaud». </font><font style="vertical-align: inherit;">Dans prod, les nœuds ont une variable spéciale CLUSTER_ID, qui est ajoutée à l'application.id des instances de Kafka Streams. </font><font style="vertical-align: inherit;">Voici un exemple de configuration Spring Boot application.yml:</font></font><div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.yml</font></font></b><div class="spoiler_text"><code>spring.profiles: production<br>
streaming-pipelines:<br>
 team-a-stream-app-id: "${CLUSTER_ID}-team-a-stream-app"<br>
 team-b-stream-app-id: "${CLUSTER_ID}-team-b-stream-app"</code><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À un moment donné, un seul des clusters est en mode actif, respectivement, le cluster de sauvegarde n'envoie pas de messages en temps réel aux microservices en aval. Lors de la publication de la version, le cluster de sauvegarde devient actif, ce qui permet une mise à jour continue sur le premier cluster. Puisqu'il s'agit d'un groupe de consommateurs complètement différent, nos clients ne remarquent même aucune violation dans le traitement, et les services ultérieurs continuent de recevoir des messages du cluster récemment actif. L'un des inconvénients évidents de l'utilisation d'un groupe de sauvegarde de consommateurs est la surcharge supplémentaire et la consommation de ressources, mais, néanmoins, cette architecture offre des garanties, un contrôle et une tolérance aux pannes supplémentaires de notre système de traitement en streaming.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Outre l'ajout d'un cluster supplémentaire, il existe également des astuces qui peuvent atténuer le problème avec un rééquilibrage fréquent.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Augmentez group.initial.rebalance.delay.ms</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À partir de Kafka 0.11.0.0, la configuration group.initial.rebalance.delay.ms a été ajoutée. </font><font style="vertical-align: inherit;">Selon la documentation, ce paramètre est responsable de:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Durée en millisecondes pendant laquelle GroupCoordinator retardera le rééquilibrage initial du consommateur du groupe.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par exemple, si nous définissons 60 000 millisecondes dans ce paramètre, alors avec une mise à jour continue, nous pouvons avoir une fenêtre d'une minute pour la publication de la version. </font><font style="vertical-align: inherit;">Si l'instance de Kafka Streams redémarre avec succès dans cette fenêtre de temps, aucun rééquilibrage ne sera appelé. </font><font style="vertical-align: inherit;">Veuillez noter que les données dont l'instance Kafka Streams redémarrée était responsable resteront indisponibles jusqu'à ce que le nœud revienne en mode en ligne. </font><font style="vertical-align: inherit;">Par exemple, si le redémarrage d'une instance prend environ huit secondes, vous disposerez de huit secondes d'indisponibilité pour les données dont cette instance est responsable. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il convient de noter que le principal inconvénient de ce concept est qu'en cas de défaillance d'un nœud, vous recevrez un délai supplémentaire d'une minute pendant la restauration, en tenant compte de la configuration actuelle.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Réduction de la taille des segments dans les rubriques du journal des modifications</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le gros retard dans le rééquilibrage de Kafka Stream est dû à la restauration des magasins d'État à partir des rubriques du journal des modifications. Les rubriques du journal des modifications sont des rubriques compressées, ce qui vous permet de stocker le dernier enregistrement d'une clé particulière dans la rubrique. Je décrirai brièvement ce concept ci-dessous. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les sujets de Kafka Broker sont organisés en segments. Lorsqu'un segment atteint la taille de seuil configurée, un nouveau segment est créé et le précédent est compressé. Par défaut, ce seuil est défini sur 1 Go. Comme vous le savez probablement, la structure de données principale sous-jacente aux rubriques Kafka et à leurs partitions est la structure de journal avec une écriture en avant, c'est-à-dire que lorsque des messages sont envoyés à la rubrique, ils sont toujours ajoutés au dernier segment «actif» et la compression n'est pas passe.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par conséquent, la plupart des états de stockage stockés dans le journal des modifications se trouvent toujours dans le fichier «segment actif» et ne sont jamais compressés, ce qui entraîne des millions de messages de journal des modifications non compressés. </font><font style="vertical-align: inherit;">Pour Kafka Streams, cela signifie que lors du rééquilibrage, lorsque l'instance de Kafka Streams restaure son état à partir de la rubrique du journal des modifications, elle doit lire un grand nombre d'entrées redondantes à partir de la rubrique du journal des modifications. </font><font style="vertical-align: inherit;">Étant donné que les magasins d'État ne se soucient que du dernier état, et non de l'historique, ce temps de traitement est perdu. </font><font style="vertical-align: inherit;">La réduction de la taille du segment entraînera une compression des données plus agressive, de sorte que les nouvelles instances d'applications Kafka Streams peuvent récupérer beaucoup plus rapidement.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Même si Kafka Streams ne fournit pas de capacité intégrée pour fournir une haute disponibilité lors d'une mise à jour de service continue, cela peut toujours être fait au niveau de l'infrastructure. </font><font style="vertical-align: inherit;">Nous devons nous rappeler que Kafka Streams n'est pas un «framework de cluster» contrairement à Apache Flink ou Apache Spark. </font><font style="vertical-align: inherit;">Il s'agit d'une bibliothèque Java légère qui permet aux développeurs de créer des applications évolutives pour le streaming de données. </font><font style="vertical-align: inherit;">Malgré cela, il fournit les éléments de base nécessaires pour atteindre des objectifs de streaming aussi ambitieux que la disponibilité à «99,99%».</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr488544/index.html">Supprimer la couverture de code d'une application Node.JS déjà en cours d'exécution</a></li>
<li><a href="../fr488546/index.html">Hack The Box. Procédure pas à pas JSON. Vulnérabilité dans Json.Net et LPE via SeImpersonatePrivilege</a></li>
<li><a href="../fr488548/index.html">Expérience: comment apprendre à créer des textes populaires en anglais (et pourquoi les Habristes anglophones lisent si peu)</a></li>
<li><a href="../fr488550/index.html">Qui veut faire des coopératives des géants de l'informatique</a></li>
<li><a href="../fr488552/index.html">Développeurs Apple FAS et contrôle parental</a></li>
<li><a href="../fr488560/index.html">Hébergement gratuit de bots Telegram sur Google Cloud Platform</a></li>
<li><a href="../fr488564/index.html">Votre premier réseau neuronal sur une unité de traitement graphique (GPU). Guide du débutant</a></li>
<li><a href="../fr488566/index.html">Comment un ingénieur QA a sauvé une journée entière en liant les tests automatiques dans Visual Studio et Test IT</a></li>
<li><a href="../fr488568/index.html">Les réseaux de neurones rêvent-ils d'argent électrique?</a></li>
<li><a href="../fr488570/index.html">Comment les services secrets américains ont confondu le RPG cyberpunk avec un manuel pour les pirates</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
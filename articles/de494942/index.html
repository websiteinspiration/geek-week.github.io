<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧓🏼 🙆 🥌 CGI zu Hause mit Unreal Engine und iPhone 🤸🏼 👃🏿 ♐️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo alle zusammen! Mein Name ist Vasily Mazalov, ich arbeite als leitender Video-Editor bei Pixonic. Unsere Abteilung erstellt Videokreative für das...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>CGI zu Hause mit Unreal Engine und iPhone</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/494942/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo alle zusammen! </font><font style="vertical-align: inherit;">Mein Name ist Vasily Mazalov, ich arbeite als leitender Video-Editor bei Pixonic. </font><font style="vertical-align: inherit;">Unsere Abteilung erstellt Videokreative für das Marketing und die Community: Videos für Seiten in Seiten, Videos von Spielinnovationen und andere Inhalte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn ich keine Kreativität schaffe, überwache ich das Internet auf neue Formate und Möglichkeiten, Material zu präsentieren, um unsere eigenen Inhalte für neue Spieler vielfältiger, interessanter und attraktiver zu machen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vor einem Jahr bin ich auf folgendes Video gestoßen:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schau das Video</font></font></b><div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/i51CizUXd7A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was sehen wir hier? </font><font style="vertical-align: inherit;">Der Typ zog einen Anzug an, um die Bewegung des Körpers festzuhalten (bisher nichts Ungewöhnliches), hängte ein iPhone vor sich (aber das ist interessant) und übertrug so die Animation von Gesicht und Körper des Charakters direkt in Echtzeit in Unreal Engine, und das Ergebnis sucht nach einer so einfachen Implementierung ziemlich hohe Qualität. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Coole Idee, dachte ich. </font><font style="vertical-align: inherit;">Dann schloss das Video. </font><font style="vertical-align: inherit;">Und er arbeitete weiter. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sechs Monate später stellte sich heraus, dass Schulungsmaterial zum Erfassen von Gesichtsanimationen in Unreal Engine mithilfe einer Anwendung auf dem iPhone gemeinfrei war. </font><font style="vertical-align: inherit;">Gleichzeitig fand ich heraus, dass in unserer Kunstabteilung ein Anzug zur Bewegungserfassung gekauft wurde. </font><font style="vertical-align: inherit;">Betrachtet man die Kompatibilität mit UE: alles lief gut. </font><font style="vertical-align: inherit;">Es blieb nur ein iPhone für die weitere Arbeit zu finden, aber heutzutage gibt es noch weniger Probleme damit.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schau das Video</font></font></b><div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/AIHoDo7Y4_g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gab viele Fragen. </font><font style="vertical-align: inherit;">Vor mir befand sich ein unkultiviertes Feld unerforschter Animationen, die Unreal Engine, die Modellierung des menschlichen Gesichts und Körpers und andere Dinge, die völlig von der Videobearbeitung entfernt waren, aber gleichzeitig der große Wunsch, zu erkennen, was beabsichtigt war. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der lange Prozess des Studiums verschiedener Dokumentationen hat begonnen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was als Ergebnis passiert ist und wie wir es erreicht haben, lesen Sie weiter.</font></font><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gesichtsanimation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um unsere Idee zu verwirklichen, war es für uns nicht rentabel, den Charakter von Grund auf neu zu verwenden und zu formen: Es würde viel Zeit in Anspruch nehmen und komplexe und meist ungerechtfertigte Verbesserungen erfordern. Aus diesem Grund haben wir uns für DAZ Studio entschieden: Ursprünglich wurden dort Gesichtsknochen gelegt, damit Sie schnell die erforderlichen Gesichtskontraktionen und Emotionen erzeugen können, für die der Bildhauer viel mehr Zeit aufwenden würde. Ja, die in DAZ erstellten Modelle sind weit entfernt von einem fotorealistischen Bild, aber sie waren ideal für unsere Ziele geeignet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um Gesichtsanimationen aufzunehmen, brauchten wir nur ein iPhone mit TrueDepth-Frontkamera - also von iPhone X und höher. Es war diese Technologie, die die Gesichtstopologie las und die erforderlichen Werte in Unreal bereits auf unser Modell übertrug.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/hu/yo/11/huyo11io_r0xlfw8nzzdzhawcvc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mischformen sind für unterschiedliche Gesichtsausdrücke verantwortlich - 3D-Modelle mit derselben Topologie, dh mit derselben Anzahl von Scheitelpunkten, jedoch unterschiedlicher Form. </font><font style="vertical-align: inherit;">Face AR verwendet 51 Mischungen. Dank der detaillierten Apple-Dokumentation, in der beschrieben wird, welche spezifischen Mischungen in DAZ verwendet werden, konnten wir sie schnell genug herstellen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Menge der Emotionen und Mischungen in einem 3D-Modell sieht ungefähr so ​​aus: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/be/rx/ep/berxephpsuciz3wxd7vcachheo0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Formen aus dem Internet </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/jo/9q/p2/jo9qp2iqqqyo1vyp514j-7xacpu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mischen Unsere Mischungen</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Zuerst erhalten wir unser Unreal Engine-Gesicht für Tests, dann erstellen wir die Anwendung und kehren zu Unreal zurück, um das Ergebnis zu erhalten.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fh/x1/ui/fhx1uimpcjayhq0ybay3ifq8rdq.png"><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Körperanimation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um einen Körper zu schaffen, mussten die Besonderheiten der Software für die Arbeit mit einem Anzug berücksichtigt werden. Wir haben mit dem Motion Capture-System Perception Neuron 2.0 Motion Capture System von Noitom gearbeitet. Es kostet ungefähr 2500 Dollar. Dies ist das billigste Kostüm auf dem Markt und nicht der beste Vertreter unter den Analoga: Es ist sehr empfindlich gegenüber elektromagnetischer Strahlung, wodurch sich die Koordinaten der Sensoren bewegen, wenn es sich innerhalb des Radius der aktiven Strahlung befindet, und es wird noch schwieriger, die Animation zu reinigen. Glücklicherweise sind wir gerade in ein anderes Stockwerk gezogen und an einem neuen Ort war es ziemlich menschenleer, was bedeutet, dass die elektromagnetische Strahlung auf ein Minimum reduziert wurde - das heißt, es war ideal für uns.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jv/df/qt/jvdfqtdhz19xnag1w_4_lrtg1bw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Warum ein Anzug? Vorgefertigte Animationen aus verschiedenen Bibliotheken passten nicht zu uns, da unser Charakter einen einzigartigen Charakter und ein einzigartiges Verhalten haben sollte und Gesicht und Körper sie genau widerspiegeln sollten. Wenn wir die Animation von Grund auf neu machen würden, würde es einen oder sogar zwei Monate dauern. Die Verwendung von Bewegungserfassungsgeräten wurde diesmal gespeichert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Gegensatz zum Gesicht haben die Künstler selbst das Modell des Körpers von Grund auf neu gemalt. Dann war es notwendig, dass sie in Maya manipulierte und häutete. Nachdem wir den Körper zusammengebaut haben, starten wir ihn in Unreal, dort sammeln wir alles für die Mocap, zeichnen die Animation auf, danach bleibt das Ergebnis nur noch zu kneten.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1c/na/r0/1cnar0oe7evduomjsu9v_q-gyx0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Damit die Animation genau übertragen werden konnte, waren die Verbesserungen minimal oder um sie überhaupt zu vermeiden. Um die Animation vom Kostüm direkt an die Unreal Engine zu senden, mussten die Knochen korrekt eingestellt und unnötige Werte aus unserem Modell entfernt werden. Noitom verfügt über ein grobes 3D-Modell für die Unreal Engine, anhand dessen wir unser eigenes Modell verfeinern mussten: Legen Sie es in die T-Pose, platzieren Sie Handflächen und Finger in nicht standardmäßigen Modellierungspositionen und setzen Sie alle Werte auf Null zurück. Es war sehr wichtig, dass alle Knochen ohne unnötige Drehungen waren, da sie sonst vom Programm multipliziert werden und dadurch die Bewegung stark verzerrt wird.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Insgesamt dauerte es ungefähr zwei Stunden, um den Anzug zu kalibrieren und die ersten Videos aufzunehmen. </font><font style="vertical-align: inherit;">Wir haben die Einstellungen in der Unreal Engine festgelegt, die Animation des Körpers mit allen erforderlichen Pausen gemäß dem Skript aufgezeichnet, dann die Animation des Gesichts gemäß den Bewegungen des Körpers und demselben Skript aufgezeichnet und das Ergebnis erhalten, das Sie in der folgenden Abbildung sehen werden.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/E77DXw-zSu4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nach der Aufnahme musste die Animation verbessert werden, daher haben wir den Animator mit der Reinigung beauftragt. </font><font style="vertical-align: inherit;">Er brauchte drei Tage, um zwei Minuten Animation aufzuräumen.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/h1KUncMcTCw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann haben wir ungefähr drei Wochen bis zur endgültigen Version gebraucht, und wenn wir die Verfeinerung bestimmter Faktoren sowohl im Gesichtsmodell als auch im Körper ausschließen, kann dieser Zeitraum um eine weitere Woche verkürzt werden. </font></font><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum benutzen wir es?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Machen wir eine Pause vom CGI-Prozess und sprechen über die Ziele des Projekts. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Moment, als ich mich mit diesem Thema befasste und die für die Arbeit notwendigen Informationen sammelte, erschienen Piloten in unserem Spiel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn neue Inhalte herauskommen, spricht normalerweise entweder eine Off-Screen-Stimme darüber oder die Entwickler selbst, oder die Informationen kommen einfach irgendwie durch das Gameplay. Jetzt haben wir die Möglichkeit, einen Charakter zu erstellen, ihn richtig vorzubereiten, aus hochwertigen Assets die Orte zusammenzustellen, an denen er sich befinden wird, und über diesen Helden mit den Spielern zu kommunizieren: von Story- und Review-Videos bis hin zu Live-Übertragungen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum ersten Mal in einem Spiel über Roboter erschienen Live-Charaktere und danach Geschichten, die sie über sich und die Welt erzählen können. Und ich dachte, es wäre cool, wenn es möglich wäre, Gameplay-Kinematiken mit Charakteren zu sammeln, die die Spieler so schnell in die Spielwelt eintauchen lassen, wie wir Videos auf der Engine machen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vu/3j/lf/vu3jlfs_gtgsym1a0slfy_otmg0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zusammen mit der Community-Abteilung begannen wir, ein Bild des Charakters zu entwickeln, wie er aussehen könnte und wie seine Geschichte aussehen würde. Unser Senior Community Manager hat das Skript geschrieben, das wir später entwickelt haben, um Zeit zu sparen und die Produktion zu vereinfachen.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RQ6y8dRT2x8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Video sehen Sie fast alle Tests, die wir mit Gesichts- und Körperanimationen durchgeführt haben. </font><font style="vertical-align: inherit;">Da sie unterschiedliche Spezifikationen haben, mussten sie nacheinander getestet und erst am Ende gemischt werden. </font><font style="vertical-align: inherit;">Für Körperanimationstests wurde für die neue Version ein Kostümmodell aus dem CGI-Trailer entnommen:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sl-P_8CSahg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun wollen wir zeigen, was wir als Ergebnis haben:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/3WMqrO1-6ww" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gesamt</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit einem Motion-Capture-Anzug, einem iPhone, einem 3D-Modell und einem Unreal Marketplace mit einer riesigen Auswahl an kostenlosen Qualitätsgütern können wir in nur wenigen Wochen interessante Geschichten für unsere Spieler sammeln. </font><font style="vertical-align: inherit;">Wir haben auch Erfahrung und Verständnis dafür gesammelt, wie man schnell einen neuen Charakter erschafft und in der Phase seiner Entstehung alle Merkmale der Produktion berücksichtigt, um in kurzer Zeit das beste Ergebnis zu erzielen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Warum wollten wir nicht die Qualität cooler Kinematiken wie Blizzard erreichen? </font><font style="vertical-align: inherit;">Für Community-basierte und Marketing-Inhalte reicht die aktuelle Qualität aus, um unseren Benutzern eine neue Perspektive auf die Spielewelt zu geben. </font><font style="vertical-align: inherit;">Obwohl die Qualität der Clips noch nicht verbessert werden muss, sind wir immer auf der Suche nach neuen Lösungen.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de494920/index.html">Schlechter Rat an den Entwickler: Was tun, um das Management zufrieden zu stellen?</a></li>
<li><a href="../de494922/index.html">Nischni Nowgorod für einen IT-Spezialisten: Perspektiven für die Arbeit und Chancen für das Leben</a></li>
<li><a href="../de494924/index.html">Die Implementierung des Aquarelleffekts in Spielen</a></li>
<li><a href="../de494938/index.html">Glücklicher Backup-Tag! Vergiss ihn nicht</a></li>
<li><a href="../de494940/index.html">DevOps - was ist das, warum und wie stark ist es gefragt?</a></li>
<li><a href="../de494950/index.html">Einige Speichertrends, auf die Sie achten sollten</a></li>
<li><a href="../de494956/index.html">Datenbyte-Lebensdauer</a></li>
<li><a href="../de494964/index.html">Neuronale Netze und Handel. Praktische Anwendung</a></li>
<li><a href="../de494966/index.html">SCRUM: ein Gedicht über Liebe und Schmerz</a></li>
<li><a href="../de494968/index.html">Unterwasser-Internetkabel: Wer verlegt sie?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
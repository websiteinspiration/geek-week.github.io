<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö§ ‚õπüèæ ü•§ Monte-Carlo-Methoden f√ºr Markov-Ketten (MCMC). Einf√ºhrung üíÇ üíÉüèΩ üñ•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 
 
 Wir erinnern Sie daran, dass wir fr√ºher das Buch " Maschinelles Lernen ohne zus√§tzliche W√∂rter " angek√ºndigt haben - und jetzt ist es ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Monte-Carlo-Methoden f√ºr Markov-Ketten (MCMC). Einf√ºhrung</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/491268/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo Habr! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir erinnern Sie daran, dass wir fr√ºher das Buch " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maschinelles Lernen ohne zus√§tzliche W√∂rter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " </font><font style="vertical-align: inherit;">angek√ºndigt haben </font><font style="vertical-align: inherit;">- und jetzt ist es bereits </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">im Verkauf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Trotz der Tatsache, dass das Buch f√ºr Anf√§nger in MO tats√§chlich zu einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desktop werden kann</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , wurden einige Themen darin immer noch nicht ber√ºhrt. Daher bieten wir allen Interessierten eine √úbersetzung eines Artikels von Simon Kerstens √ºber die Essenz von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MCMC-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Algorithmen </font><font style="vertical-align: inherit;">mit der Implementierung eines solchen Algorithmus in Python an.</font></font><br>
<a name="habracut"></a> <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Monte-Carlo-Methoden f√ºr Markov-Ketten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (MCMC) sind eine leistungsstarke Klasse von Methoden zur Abtastung aus Wahrscheinlichkeitsverteilungen, die nur bis zu einer bestimmten (unbekannten) Normalisierungskonstante bekannt sind. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bevor wir uns jedoch mit dem MCMC befassen, wollen wir diskutieren, warum Sie m√∂glicherweise √ºberhaupt eine solche Auswahl treffen m√ºssen. Die Antwort lautet: M√∂glicherweise interessieren Sie sich entweder f√ºr die Stichproben selbst aus der Stichprobe (z. B. um unbekannte Parameter mithilfe der Bayes'schen Ableitungsmethode zu bestimmen) oder um die erwarteten Werte der Funktionen in Bezug auf die Wahrscheinlichkeitsverteilung zu approximieren (z. B. um thermodynamische Gr√∂√üen aus der Zustandsverteilung in der statistischen Physik zu berechnen). Manchmal interessiert uns nur der Wahrscheinlichkeitsverteilungsmodus. In diesem Fall erhalten wir es durch die Methode der numerischen Optimierung, so dass es nicht erforderlich ist, eine vollst√§ndige Auswahl zu treffen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es stellt sich heraus, dass das Abtasten aus Wahrscheinlichkeitsverteilungen mit Ausnahme der primitivsten eine schwierige Aufgabe ist. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die inverse Transformationsmethode</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ist eine elementare Technik zum Abtasten aus Wahrscheinlichkeitsverteilungen, die jedoch die Verwendung einer kumulativen Verteilungsfunktion erfordert. Um diese wiederum verwenden zu k√∂nnen, m√ºssen Sie die Normalisierungskonstante kennen, die normalerweise unbekannt ist. Im Prinzip kann eine Normalisierungskonstante durch numerische Integration erhalten werden, aber dieses Verfahren wird mit zunehmender Anzahl von Dimensionen schnell nicht praktikabel. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abweichungsabtastung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es erfordert keine normalisierte Verteilung, aber um sie effektiv umzusetzen, ist es sehr wichtig, √ºber die Verteilung des Interesses an uns Bescheid zu wissen. Dar√ºber hinaus leidet diese Methode stark unter dem Fluch der Dimensionen - dies bedeutet, dass ihre Wirksamkeit mit zunehmender Anzahl von Variablen schnell abnimmt. Aus diesem Grund m√ºssen Sie den Empfang repr√§sentativer Proben aus Ihrer Verteilung intelligent organisieren, ohne die Normalisierungskonstante kennen zu m√ºssen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MCMC-Algorithmen sind eine Klasse von Methoden, die speziell daf√ºr entwickelt wurden. Sie gehen zur√ºck auf den </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wegweisenden Artikel von Metropolis und anderen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ; Metropolis entwickelte den ersten </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">nach ihm</font></a><font style="vertical-align: inherit;"> benannten MCMC-Algorithmus</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und entworfen, um den Gleichgewichtszustand eines zweidimensionalen Systems harter Kugeln zu berechnen. Tats√§chlich suchten die Forscher nach einer universellen Methode, mit der wir die in der statistischen Physik gefundenen erwarteten Werte berechnen k√∂nnen. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dieser Artikel behandelt die Grundlagen der MCMC-Probenahme. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MARKOV-KETTEN</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir verstanden haben, warum wir Proben nehmen m√ºssen, gehen wir zum Herzen von MCMC √ºber: Markov-Ketten. Was ist eine Markov-Kette? Ohne auf technische Details einzugehen, k√∂nnen wir sagen, dass eine Markov-Kette eine zuf√§llige Folge von Zust√§nden in einem bestimmten Zustandsraum ist, wobei die Wahrscheinlichkeit, einen bestimmten Zustand zu w√§hlen, nur vom aktuellen Zustand der Kette abh√§ngt, nicht jedoch von ihrer Vergangenheit: Diese Kette ist ohne Ged√§chtnis. Unter bestimmten Bedingungen hat eine Markov-Kette eine einzigartige station√§re Verteilung von Zust√§nden, zu denen sie konvergiert und eine bestimmte Anzahl von Zust√§nden √ºberwindet. Nach einer solchen Anzahl von Zustandszust√§nden in einer Markov-Kette wird eine invariante Verteilung erhalten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um aus einer Verteilung </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">abzutasten, erstellt und simuliert der MCMC-Algorithmus eine Markov-Kette, deren station√§re Verteilung ist</font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">;; Dies bedeutet, dass nach der anf√§nglichen "Keim" -Periode die Zust√§nde einer solchen Markov-Kette nach dem Prinzip verteilt werden </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Daher m√ºssen wir nur den Status speichern, um Proben von zu erhalten </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Betrachten wir zu Bildungszwecken sowohl einen diskreten Zustandsraum als auch eine diskrete ‚ÄûZeit‚Äú. Die Schl√ºsselgr√∂√üe, die eine Markov-Kette kennzeichnet, ist ein √úbergangsoperator </font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, der die Wahrscheinlichkeit angibt, </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zu einem bestimmten Zeitpunkt in </font><font style="vertical-align: inherit;">einem Zustand </font><font style="vertical-align: inherit;">zu sein </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, vorausgesetzt, die Kette befindet sich zu einem bestimmten </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zeitpunkt </font><font style="vertical-align: inherit;">in einem Zustand </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns jetzt nur zum Spa√ü (und als Demonstration) schnell eine Markov-Kette mit einer einzigartigen station√§ren Verteilung weben. Beginnen wir mit einigen Importen und Einstellungen f√ºr Diagramme:</font></font><br>
<br>
<pre><code class="python hljs">%matplotlib notebook<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
plt.rcParams[<span class="hljs-string">'figure.figsize'</span>] = [<span class="hljs-number">10</span>, <span class="hljs-number">6</span>]<font></font>
np.random.seed(<span class="hljs-number">42</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Markov-Kette umrundet den diskreten Zustandsraum, der durch drei Wetterbedingungen gebildet wird: </font></font><br>
<br>
<pre><code class="python hljs">state_space = (<span class="hljs-string">"sunny"</span>, <span class="hljs-string">"cloudy"</span>, <span class="hljs-string">"rainy"</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einem diskreten Zustandsraum ist der √úbergangsoperator nur eine Matrix. </font><font style="vertical-align: inherit;">In unserem Fall entsprechen die Spalten und Zeilen sonnigem, bew√∂lktem und regnerischem Wetter. </font><font style="vertical-align: inherit;">W√§hlen wir relativ vern√ºnftige Werte f√ºr die Wahrscheinlichkeiten aller √úberg√§nge:</font></font><br>
<br>
<pre><code class="python hljs">transition_matrix = np.array(((<span class="hljs-number">0.6</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.1</span>),<font></font>
                              (<span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.3</span>),<font></font>
                              (<span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Zeilen geben die Zust√§nde an, in denen sich die Schaltung derzeit befinden kann, und die Spalten geben die Zust√§nde an, in die die Schaltung gehen kann. </font><font style="vertical-align: inherit;">Wenn wir den Zeitschritt der Markov-Kette in einer Stunde machen, besteht eine 60% ige Chance, dass das sonnige Wetter f√ºr die n√§chste Stunde anh√§lt, vorausgesetzt, es ist jetzt sonnig. </font><font style="vertical-align: inherit;">Es besteht auch eine Wahrscheinlichkeit von 30%, dass es in der n√§chsten Stunde bew√∂lkt wird, und eine Wahrscheinlichkeit von 10%, dass es unmittelbar nach sonnigem Wetter regnet. </font><font style="vertical-align: inherit;">Dies bedeutet auch, dass sich die Werte in jeder Zeile zu eins addieren. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns unsere Markov-Kette ein wenig fahren:</font></font><br>
<br>
<pre><code class="python hljs">n_steps = <span class="hljs-number">20000</span>
states = [<span class="hljs-number">0</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_steps):<font></font>
    states.append(np.random.choice((<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), p=transition_matrix[states[<span class="hljs-number">-1</span>]]))<font></font>
states = np.array(states)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir k√∂nnen beobachten, wie die Markov-Kette zu einer station√§ren Verteilung konvergiert, indem wir die empirische Wahrscheinlichkeit jedes Zustands als Funktion der Kettenl√§nge berechnen:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">despine</span>(<span class="hljs-params">ax, spines=(<span class="hljs-params"><span class="hljs-string">'top'</span>, <span class="hljs-string">'left'</span>, <span class="hljs-string">'right'</span></span>)</span>):</span>
    <span class="hljs-keyword">for</span> spine <span class="hljs-keyword">in</span> spines:<font></font>
        ax.spines[spine].set_visible(<span class="hljs-literal">False</span>)<font></font>
<font></font>
fig, ax = plt.subplots()<font></font>
width = <span class="hljs-number">1000</span>
offsets = range(<span class="hljs-number">1</span>, n_steps, <span class="hljs-number">5</span>)
<span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> enumerate(state_space):<font></font>
    ax.plot(offsets, [np.sum(states[:offset] == i) / offset <font></font>
            <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> offsets], label=label)<font></font>
ax.set_xlabel(<span class="hljs-string">"number of steps"</span>)<font></font>
ax.set_ylabel(<span class="hljs-string">"likelihood"</span>)<font></font>
ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
despine(ax, (<span class="hljs-string">'top'</span>, <span class="hljs-string">'right'</span>))<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/vu/tg/xv/vutgxvc3lq1-sang725fmek1ibm.png"><br>
 <br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">EHREN ALLER MCMC: METROPOLIS-HASTINGS-ALGORITHMUS</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Nat√ºrlich ist dies alles sehr interessant, aber zur√ºck zum Stichprobenprozess einer beliebigen Wahrscheinlichkeitsverteilung </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Es kann entweder diskret sein, in welchem ‚Äã‚ÄãFall wir weiter √ºber die √úbergangsmatrix sprechen </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, oder kontinuierlich, in welchem ‚Äã‚ÄãFall es </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ein √úbergangskern sein wird. Im Folgenden werden wir √ºber kontinuierliche Verteilungen sprechen, aber alle Konzepte, die wir hier betrachten, sind auch auf diskrete F√§lle anwendbar. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir den √úbergangskern so gestalten k√∂nnten, dass der n√§chste Zustand bereits abgeleitet wurde </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, dann k√∂nnte dies begrenzt sein, da unsere Markov-Kette ... direkt von abtasten w√ºrde </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Um dies zu erreichen, ben√∂tigen wir leider die M√∂glichkeit, Proben zu entnehmen</font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">was wir nicht k√∂nnen - sonst w√ºrdest du das nicht lesen, oder? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Problemumgehung besteht darin, den √úbergangskern </font></font><img src="https://habrastorage.org/webt/7_/os/ja/7_osja2wwom8x6f29sp5ecxnrwc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in zwei Teile zu unterteilen: den Vorschlagsschritt und den Akzeptanz- / Ablehnungsschritt. Eine Hilfsverteilung erscheint im Probenschritt</font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aus denen die m√∂glichen n√§chsten Zust√§nde der Kette ausgew√§hlt werden. Wir k√∂nnen nicht nur eine Auswahl aus dieser Verteilung treffen, sondern auch die Verteilung selbst willk√ºrlich ausw√§hlen. Beim Entwerfen sollte man sich jedoch bem√ºhen, zu einer Konfiguration zu gelangen, bei der aus dieser Verteilung entnommene Proben nur minimal mit dem aktuellen Zustand korrelieren und gleichzeitig gute Chancen haben, die Empfangsphase zu durchlaufen. Der obige Empfangs- / Verwerfungsschritt ist der zweite Teil des √úbergangskerns; Zu diesem Zeitpunkt werden Fehler in den ausgew√§hlten Testzust√§nden korrigiert </font></font><img src="https://habrastorage.org/webt/dq/wo/ba/dqwoba_pfa-ktifmo9zviggtesm.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Hier wird die Wahrscheinlichkeit eines erfolgreichen Empfangs berechnet </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und eine Stichprobe </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mit einer solchen Wahrscheinlichkeit wie dem n√§chsten Zustand in der Kette </font><font style="vertical-align: inherit;">entnommen </font><font style="vertical-align: inherit;">. Den n√§chsten Zustand erhalten </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von</font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dann wie folgt durchgef√ºhrt: Zuerst wird der Versuchszustand </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entnommen </font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Dann wird es als n√§chster Zustand mit Wahrscheinlichkeit genommen </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">oder </font><font style="vertical-align: inherit;">mit Wahrscheinlichkeit </font><font style="vertical-align: inherit;">verworfen </font></font><img src="https://habrastorage.org/webt/cr/_w/sd/cr_wsdxfgphyie2qbzl977pvfgq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, und im letzteren Fall wird der aktuelle Zustand kopiert und als n√§chster verwendet. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Folglich haben wir </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ty/vg/w-/tyvgw-g_ij7vgrpzoxtt7t3enmw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ausreichende Bedingungen f√ºr die Markov-Kette, </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">da eine station√§re Verteilung wie folgt ist: Der √úbergangskern muss ein </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">detailliertes Gleichgewicht aufweisen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder wie in der physikalischen Literatur geschrieben, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mikroskopische Reversibilit√§t</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hf/bg/oy/hfbgoyr944ikp5ce_menl-sg0da.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies bedeutet, dass die Wahrscheinlichkeit, in einem Zustand zu sein </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und von dort nach zu ziehen</font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">muss gleich der Wahrscheinlichkeit des umgekehrten Prozesses sein, dh in der Lage sein </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und in einen Zustand gehen </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Die √úbergangskerne der meisten MCMC-Algorithmen erf√ºllen diese Bedingung. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Damit der zweiteilige √úbergangskern dem detaillierten Gleichgewicht entspricht, muss er richtig ausw√§hlen, dh </font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sicherstellen, dass Sie Asymmetrien im Wahrscheinlichkeitsstrom von / nach </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">oder </font><font style="vertical-align: inherit;">korrigieren k√∂nnen </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Der Metropolis-Hastings-Algorithmus verwendet das Zul√§ssigkeitskriterium Metropolis : </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/mh/dm/z2/mhdmz27voos90zkz5_-zexopsdc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und hier beginnt die Magie: </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir kennen nur eine Konstante, aber es spielt keine Rolle, da diese unbekannte Konstante den Ausdruck f√ºr aufhebt</font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! Es ist diese paccpacc-Eigenschaft, die den Betrieb von Algorithmen sicherstellt, die auf dem Metropolis-Hastings-Algorithmus f√ºr nicht normalisierte Verteilungen basieren. Oft werden symmetrische Hilfsverteilungen c verwendet </font></font><img src="https://habrastorage.org/webt/b2/ss/pz/b2sspzujgmdn_uwizxwjjokkg5w.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. In diesem Fall wird der Metropolis-Hastings-Algorithmus auf den urspr√ºnglichen (weniger allgemeinen) Metropolis-Algorithmus reduziert, der 1953 entwickelt wurde. Im urspr√ºnglichen Algorithmus </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hd/3k/vq/hd3kvqg9l2jqltan97_gfmzutsi.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Fall kann der gesamte √úbergangskern der Metropolis-Hastings als geschrieben werden </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WIR UMSETZEN DEN METROPOLIS-HASTINGS-ALGORITHMUS BEI PYTHON</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, da wir herausgefunden haben, wie der Metropolis-Hastings-Algorithmus funktioniert, fahren wir mit seiner Implementierung fort. Zun√§chst legen wir die logarithmische Wahrscheinlichkeit der Verteilung fest, aus der wir eine Auswahl treffen werden - ohne Normalisierungskonstanten; es wird angenommen, dass wir sie nicht kennen. Als n√§chstes arbeiten wir mit der Standardnormalverteilung:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_prob</span>(<span class="hljs-params">x</span>):</span>
     <span class="hljs-keyword">return</span> <span class="hljs-number">-0.5</span> * np.sum(x ** <span class="hljs-number">2</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als n√§chstes w√§hlen wir eine symmetrische Hilfsverteilung. </font><font style="vertical-align: inherit;">Im Allgemeinen kann die Leistung des Metropolis-Hastings-Algorithmus verbessert werden, wenn Sie bereits bekannte Informationen √ºber die Verteilung, aus der Sie eine Auswahl treffen m√∂chten, in die Hilfsverteilung aufnehmen. </font><font style="vertical-align: inherit;">Ein vereinfachter Ansatz sieht folgenderma√üen aus: Wir nehmen den aktuellen Status </font></font><code>x</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und w√§hlen eine Stichprobe aus </font></font><img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, dh stellen eine bestimmte Schrittgr√∂√üe ein </font></font><code>Œî</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und gehen von unserem aktuellen Status um nicht mehr als </font></font><img src="https://habrastorage.org/webt/q1/n2/d_/q1n2d_lbzpbqtvbmbgiha503cmo.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">proposal</span>(<span class="hljs-params">x, stepsize</span>):</span>
    <span class="hljs-keyword">return</span> np.random.uniform(low=x - <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             high=x + <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             size=x.shape)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schlie√ülich berechnen wir die Wahrscheinlichkeit, dass der Vorschlag angenommen wird:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">p_acc_MH</span>(<span class="hljs-params">x_new, x_old, log_prob</span>):</span>
    <span class="hljs-keyword">return</span> min(<span class="hljs-number">1</span>, np.exp(log_prob(x_new) - log_prob(x_old)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt fassen wir all dies zu einer wirklich kurzen Implementierung der Abtaststufe f√ºr den Metropolis-Hastings-Algorithmus zusammen:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_MH</span>(<span class="hljs-params">x_old, log_prob, stepsize</span>):</span><font></font>
    x_new = proposal(x_old, stepsize)<font></font>
    <span class="hljs-comment">#   ,     :</span>
    <span class="hljs-comment">#       [0,1]  </span>
    <span class="hljs-comment">#     </span><font></font>
    accept = np.random.random() &lt; p_acc(x_new, x_old, log_prob)<font></font>
    <span class="hljs-keyword">if</span> accept:
        <span class="hljs-keyword">return</span> accept, x_new
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> accept, x_old</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zus√§tzlich zum n√§chsten Status in der Markov-Kette </font></font><code>x_new</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">oder geben </font></font><code>x_old</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wir auch Informationen dar√ºber zur√ºck, ob der MCMC-Schritt √ºbernommen wurde. </font><font style="vertical-align: inherit;">Auf diese Weise k√∂nnen wir die Dynamik der Probensammlung verfolgen. </font><font style="vertical-align: inherit;">Zum Abschluss dieser Implementierung schreiben wir eine Funktion, die iterativ </font></font><code>sample_MH</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eine Markov-Kette </font><font style="vertical-align: inherit;">aufruft </font><font style="vertical-align: inherit;">und somit aufbaut:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_MH_chain</span>(<span class="hljs-params">init, stepsize, n_total, log_prob</span>):</span><font></font>
<font></font>
    n_accepted = <span class="hljs-number">0</span><font></font>
    chain = [init]<font></font>
<font></font>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(n_total):<font></font>
        accept, state = sample_MH(chain[<span class="hljs-number">-1</span>], log_prob, stepsize)<font></font>
        chain.append(state)<font></font>
        n_accepted += accept<font></font>
    <font></font>
    acceptance_rate = n_accepted / float(n_total)<font></font>
    <font></font>
    <span class="hljs-keyword">return</span> chain, acceptance_rate</code></pre><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UNSEREN METROPOLIS-HASTINGS-ALGORITHMUS PR√úFEN UND SEIN VERHALTEN FORSCHEN</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Wahrscheinlich k√∂nnen Sie es jetzt nicht erwarten, all dies in Aktion zu sehen. </font><font style="vertical-align: inherit;">Wir werden dies tun, wir werden einige fundierte Entscheidungen √ºber die Argumente treffen </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">chain, acceptance_rate = build_MH_chain(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">3.0</span>, <span class="hljs-number">10000</span>, log_prob)<font></font>
chain = [state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain]<font></font>
print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
last_states = <span class="hljs-string">", "</span>.join(<span class="hljs-string">"{:.5f}"</span>.format(state) 
                        <span class="hljs-keyword">for</span> state <span class="hljs-keyword">in</span> chain[<span class="hljs-number">-10</span>:])<font></font>
print(<span class="hljs-string">"Last ten states of chain: "</span> + last_states)<font></font>
Acceptance rate: <span class="hljs-number">0.722</span>
Last ten states of chain: <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.08692</span>, <span class="hljs-number">0.92728</span>, <span class="hljs-number">-0.46215</span>, <span class="hljs-number">0.08655</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span></code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alles ist gut. Also, hat es funktioniert? In etwa 71% der F√§lle ist es uns gelungen, Proben zu entnehmen, und wir haben eine Kette von Staaten. Die ersten Zust√§nde, in denen die Kette noch nicht zu ihrer station√§ren Verteilung konvergiert hat, sollten verworfen werden. Lassen Sie uns √ºberpr√ºfen, ob die von uns gew√§hlten Bedingungen tats√§chlich eine Normalverteilung haben:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_samples</span>(<span class="hljs-params">chain, log_prob, ax, orientation=<span class="hljs-string">'vertical'</span>, normalize=True,
                 xlims=(<span class="hljs-params"><span class="hljs-number">-5</span>, <span class="hljs-number">5</span></span>), legend=True</span>):</span>
    <span class="hljs-keyword">from</span> scipy.integrate <span class="hljs-keyword">import</span> quad<font></font>
    <font></font>
    ax.hist(chain, bins=<span class="hljs-number">50</span>, density=<span class="hljs-literal">True</span>, label=<span class="hljs-string">"MCMC samples"</span>,<font></font>
           orientation=orientation)<font></font>
    <span class="hljs-comment">#     PDF</span>
    <span class="hljs-keyword">if</span> normalize:<font></font>
        Z, _ = quad(<span class="hljs-keyword">lambda</span> x: np.exp(log_prob(x)), -np.inf, np.inf)
    <span class="hljs-keyword">else</span>:<font></font>
        Z = <span class="hljs-number">1.0</span>
    xses = np.linspace(xlims[<span class="hljs-number">0</span>], xlims[<span class="hljs-number">1</span>], <span class="hljs-number">1000</span>)<font></font>
    yses = [np.exp(log_prob(x)) / Z <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xses]
    <span class="hljs-keyword">if</span> orientation == <span class="hljs-string">'horizontal'</span>:<font></font>
        (yses, xses) = (xses, yses)<font></font>
    ax.plot(xses, yses, label=<span class="hljs-string">"true distribution"</span>)
    <span class="hljs-keyword">if</span> legend:<font></font>
        ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
    <font></font>
fig, ax = plt.subplots()<font></font>
plot_samples(chain[<span class="hljs-number">500</span>:], log_prob, ax)<font></font>
despine(ax)<font></font>
ax.set_yticks(())<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/yo/rx/59/yorx59lirnkyju_dymptouaaokw.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das sieht gro√üartig aus! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was ist mit den Parametern </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">? Wir diskutieren zuerst die Schrittgr√∂√üe: Sie bestimmt, wie weit der Versuchszustand vom aktuellen Zustand der Schaltung entfernt werden kann. Daher ist dies ein Hilfsverteilungsparameter </font></font><code>q</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, der steuert, wie gro√ü die zuf√§lligen Schritte der Markov-Kette sein werden. Wenn die Schrittgr√∂√üe zu gro√ü ist, landen die Versuchszust√§nde h√§ufig am Ende der Verteilung, wo die Wahrscheinlichkeitswerte niedrig sind. Der Metropolis-Hastings-Abtastmechanismus verwirft die meisten dieser Schritte, wodurch die Empfangsraten verringert werden und die Konvergenz erheblich verlangsamt wird. √úberzeugen Sie sich selbst:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_and_display</span>(<span class="hljs-params">init_state, stepsize, n_total, n_burnin, log_prob</span>):</span><font></font>
    chain, acceptance_rate = build_MH_chain(init_state, stepsize, n_total, log_prob)<font></font>
    print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
    fig, ax = plt.subplots()<font></font>
    plot_samples([state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain[n_burnin:]], log_prob, ax)<font></font>
    despine(ax)<font></font>
    ax.set_yticks(())<font></font>
    plt.show()<font></font>
    <font></font>
sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">30</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.116</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/0g/4-/-r/0g4--rezypxzaqta-pkugq3gi3w.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nicht sehr cool, oder? Jetzt scheint es am besten zu sein, eine winzige Schrittgr√∂√üe einzustellen. Es stellt sich heraus, dass dies auch keine kluge Entscheidung ist, da die Markov-Kette die Wahrscheinlichkeitsverteilung sehr langsam untersucht und daher auch nicht so schnell konvergiert wie bei einer gut gew√§hlten Schrittgr√∂√üe:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.992</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/bf/qh/xi/bfqhxistqravnn7xug43ubowgmu.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unabh√§ngig davon, wie Sie den Schrittgr√∂√üenparameter ausw√§hlen, konvergiert die Markov-Kette schlie√ülich zu einer station√§ren Verteilung. Dies kann jedoch viel Zeit in Anspruch nehmen. Die Zeit, in der wir die Markov-Kette simulieren, wird durch den Parameter bestimmt </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- er bestimmt einfach, wie viele Zust√§nde der Markov-Kette (und daher die ausgew√§hlten Stichproben) wir letztendlich haben werden. Wenn die Kette langsam konvergiert, muss sie erh√∂ht </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">werden, damit die Markov-Kette Zeit hat, den Ausgangszustand zu ‚Äûvergessen‚Äú. Daher lassen wir die Schrittgr√∂√üe winzig und erh√∂hen die Anzahl der Proben durch Erh√∂hen des Parameters </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">500000</span>, <span class="hljs-number">25000</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.990</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/fs/ba/27/fsba27vppyvfqnwdnnr0ifdp3w4.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Meeeedenly bewegen wir uns auf das Ziel zu ... </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SCHLUSSFOLGERUNGEN In</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Anbetracht all dieser </font><font style="vertical-align: inherit;">Punkte </font><font style="vertical-align: inherit;">hoffe ich, dass Sie jetzt die Essenz des Metropolis-Hastings-Algorithmus und seine Parameter intuitiv verstanden haben und verstehen, warum dies ein √§u√üerst n√ºtzliches Werkzeug f√ºr die Auswahl von nicht standardm√§√üigen Wahrscheinlichkeitsverteilungen ist, auf die Sie in der Praxis sto√üen k√∂nnen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich empfehle dringend, dass Sie mit dem </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">hier</font></a><font style="vertical-align: inherit;"> angegebenen Code experimentieren </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Sie gew√∂hnen sich also an das Verhalten des Algorithmus unter verschiedenen Umst√§nden und verstehen es besser. </font><font style="vertical-align: inherit;">Versuchen Sie es mit einer asymmetrischen Hilfsverteilung! </font><font style="vertical-align: inherit;">Was passiert, wenn Sie das Akzeptanzkriterium nicht richtig konfigurieren? </font><font style="vertical-align: inherit;">Was passiert, wenn Sie versuchen, aus einer bimodalen Verteilung zu probieren? </font><font style="vertical-align: inherit;">K√∂nnen Sie eine M√∂glichkeit finden, die Schrittgr√∂√üe automatisch anzupassen? </font><font style="vertical-align: inherit;">Was sind die Fallstricke hier? </font><font style="vertical-align: inherit;">Beantworten Sie diese Fragen selbst!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de491258/index.html">IT-M√§dchen, woher kommst du? Lassen Sie uns eine Karte erstellen</a></li>
<li><a href="../de491260/index.html">Textnormalisierung bei Spracherkennungsaufgaben</a></li>
<li><a href="../de491262/index.html">Auge um Auge. Biometrie-Probleme</a></li>
<li><a href="../de491264/index.html">Einf√ºhrung in SSD. Teil 4. Physisch</a></li>
<li><a href="../de491266/index.html">SurfingAttack: Kompromittierung von Smartphones mit Soundassistenten [+ Video]</a></li>
<li><a href="../de491272/index.html">Website-Entwicklung in Pascal (Backend)</a></li>
<li><a href="../de491276/index.html">Wie ich das Verbot der Nachrichten-API durch die Vkontakte-Dokumentation umgangen habe</a></li>
<li><a href="../de491278/index.html">CLRium # 7: Berichte, Praxis, Mentoren</a></li>
<li><a href="../de491280/index.html">Die Geschichte, wie ich eine Programmiersprache entwickelt habe</a></li>
<li><a href="../de491282/index.html">So steigern Sie die Teamproduktivit√§t (und reduzieren Fehler) mithilfe von Rallyes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¥üèª ü§ò üîÖ Nvidia Streaming Multiprocessor History üèáüèæ üéñÔ∏è üë£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Last weekend I spent learning CUDA and SIMT programming. This fruitfully spent time ended with an almost 700-fold acceleration of my ‚Äúbusiness card ri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Nvidia Streaming Multiprocessor History</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/501108/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a29/a3e/59a/a29a3e59a2a201137c8ae9085cad5492.svg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Last weekend I spent learning CUDA and SIMT programming. </font><font style="vertical-align: inherit;">This fruitfully spent time ended with an almost 700-fold acceleration of my ‚Äúbusiness card rider racer‚Äù </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[1]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - from 101 seconds to 150 ms. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Such a pleasant experience was a good excuse for further study of the theme and evolution of Nvidia architecture. </font><font style="vertical-align: inherit;">Due to the huge amount of documentation published over the years by the ‚Äúgreen‚Äù team, I managed to go back in time and briefly walk through the amazing evolution of its streaming multiprocessors. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this article we will consider:</font></font><br>
<br>
<pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Year Generation Crystal Process Technology Series Most Powerful Card</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
=================================================== ===========================</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2006 Tesla GeForce 8 G80 90 nm 8800 GTX </font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2010 Fermi GeForce 400 GF100 40 nm GTX 480</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2012 Kepler GeForce 600 GK104 28 nm GTX 680</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2014 Maxwell GeForce 900 GM204 28 nm GTX 980 Ti</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2016 Pascal GeForce 10 GP102 16 nm GTX 1080 Ti</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2018 Turing GeForce 20 TU102 12 nm RTX 2080 Ti</font></font></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dead end</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Until 2006, NVidia's GPU architecture correlated with the logical stages of the API rendering </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[2]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The GeForce 7900 GTX, controlled by the G71 crystal, consisted of three parts involved in processing vertices (8 blocks), generating fragments (24 blocks), and combining fragments (16 blocks).</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/190/f33/4a8/190f334a8168a2f205cae8abf9538dda.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Crystal G71. </font><font style="vertical-align: inherit;">Pay attention to the Z-Cull optimization, which discards a fragment that would not pass the Z-test. </font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This correlation made the designers guess the location of the bottlenecks of the conveyor for the correct balancing of each of the layers. </font><font style="vertical-align: inherit;">With the advent of another stage in DirectX 10 - the geometric shader, Nvidia engineers faced the difficult task of balancing the crystal without knowing how actively this stage will be used. </font><font style="vertical-align: inherit;">It is time for a change.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tesla</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/349/57a/3be/34957a3be54710b4899cfb77e29e4794.svg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nvidia solved the problem of increasing complexity with the help of the ‚Äúintegrated‚Äù Tesla architecture, released in 2006. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There was no longer any difference between the layers in the G80 crystal. </font><font style="vertical-align: inherit;">Due to the ability to execute vertex, fragment, and geometric "core", the stream multiprocessor (Stream Multiprocessor, SM) has replaced all previously existing blocks. </font><font style="vertical-align: inherit;">Load balancing was performed automatically, thanks to the replacement of the ‚Äúcore‚Äù performed by each SM, depending on the requirements of the conveyor.</font></font><br>
<br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúIn fact, we threw out the entire NV30 / NV40 shader architecture and from scratch created a new one with a new common architecture for universal processors (SIMT), which also introduced new processor design methodologies.‚Äù </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
John Alben (extremetech.com interview)</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No longer able to execute SIMD instructions, ‚Äúshader blocks‚Äù turned into ‚Äúkernels‚Äù, capable of executing one integer instruction or one instruction with float32 per cycle. SM receives threads in groups of 32 threads, called warp. Ideally, all threads of the same warp execute the same instruction at the same time, only for different data (hence the name SIMT). The multi-threaded Instruction Unit (MT) is engaged in enabling / disabling threads in the warp if their instruction pointer (Instruction Pointer, IP) converges / rejects.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Two SFUs help you perform complex mathematical calculations, such as the inverse square root, sin, cos, exp, and rcp. These blocks are also capable of executing one instruction per cycle, but since there are only two of them, the speed of the warp is divided into four. There is no hardware support for float64, calculations are performed programmatically, which greatly affects the speed of execution.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SM realizes its maximum potential when it is able to hide memory latencies due to the constant presence of dispatchable warp s, but also when the flow in the warp does not deviate (control logic keeps it on the same path of executing instructions). Stream states are stored in 4 kilobyte register files (Register File, RF). Threads that take up too much space on the stack reduce the number of possible threads that can run at the same time, while reducing performance. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The flagship crystal of the Tesla generation was the 90nm G80 introduced in the GeForce 8800 GTX. Two SMs are combined in a Texture Processor Cluster (TPC) together with a Texture Unit and a Tex L1 cache. It was promised that the G80 with 8 TPC and 128 cores generates 345.6 gigaflops </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[3]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">The 8800 GTX card was extremely popular at one time, it received wonderful reviews and fell in love with those who could afford it. </font><font style="vertical-align: inherit;">It turned out to be such an excellent product that, thirteen months after its release, it remained one of the fastest GPUs on the market.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2c6/e8b/a8a/2c6e8ba8a2bf85a36daec8bdf19b1a86.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">G80 installed in 8800 GTX. </font><font style="vertical-align: inherit;">Render Output Units (ROP) do the smoothing. </font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Together with Tesla, Nvidia introduced the C programming language for Compute Unified Device Architecture (CUDA), a superset of the C99 language. </font><font style="vertical-align: inherit;">GPGPU enthusiasts, who welcomed the alternative to deceiving the GPU with GLSL textures and shaders, liked this.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Although I mainly talk about SM in this section, it was only one half of the system. </font><font style="vertical-align: inherit;">In SM, you need to transfer instructions and data stored in the memory of the GPU. </font><font style="vertical-align: inherit;">To avoid downtime, GPUs do not try to minimize memory transfers using large caches and predicting how the CPU does. </font><font style="vertical-align: inherit;">GPUs take advantage of latency, saturating the memory bus to meet the I / O needs of thousands of threads. </font><font style="vertical-align: inherit;">For this, a chip (for example, G80) realizes high memory bandwidth using six two-sided DRAM memory buses.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c48/d68/236/c48d682361196a352253fa6d9817f5a5.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPUs take advantage of memory latencies, while CPUs hide them with a huge cache and prediction logic.</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fermi</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc3/837/412/fc3837412200fc0ecbf361dc21abc7d7.svg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tesla was a risky move that proved to be very successful. </font><font style="vertical-align: inherit;">It was so successful that it became the foundation for the NVidia GPU for the next two decades.</font></font><br>
<br>
<blockquote>¬´    ,  ,     (Fermi     ,  Maxwell        ),  ,    G80,      [Pascal]¬ª.<br>
<br>
  ( extremetech.com)</blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In 2010, Nvidia released the GF100, based on the brand new Fermi architecture. The interiors of its latest chip are described in detail in the Fermi technical documentation </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[4]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The execution model is still based on warp of 32 threads dispatched to SM. NVidia managed to double / quadruple all the indicators only thanks to the 40-nanometer process technology. Thanks to two arrays of 16 CUDA cores, SM was now able to simultaneously dispatch two semi-warp (16 threads each). Despite the fact that each core executed one instruction per clock cycle, SM was essentially able to exclude one warp instruction per clock cycle (four times more than the Tesla architecture SM).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The number of SFUs has also increased, but not so much - the capacity has only doubled. It can be concluded that instructions of this type were not used very actively. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is semi-hardware support for float64, which combines operations performed by two CUDA cores. Thanks to the 32-bit ALU (in Tesla it was 24-bit), the GF100 can perform integer multiplication in one cycle, and due to the transition from IEEE 754-1985 to IEEE 754-2008 it has increased accuracy when working with the float32 pipeline using Fused Multiply -Add (FMA) (more accurate than that used in Tesla MAD). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
From a programming point of view, Fermi's integrated memory system made it possible to complement CUDA C with C ++ features such as an object, virtual methods, and exceptions.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Due to the fact that the texture blocks have now become SM, the concept of TPC has been abandoned. </font><font style="vertical-align: inherit;">It has been replaced by Graphics Processor Clusters (GPC) clusters, each with four SMs. </font><font style="vertical-align: inherit;">Last but not least, SM is now gifted with the Polymorph Engine, which deals with getting vertices, transforming the viewport and tessellation. </font><font style="vertical-align: inherit;">The flagship GeForce GTX 480 based on the GF100 was advertised as containing 512 cores and capable of providing 1,345 gigaflops </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[5]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a8f/85b/f8e/a8f85bf8ee45935200e4c7338e2d0461.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GF100 installed in the GeForce GTX 480. Note the six memory controllers that serve the GPC.</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kepler</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67f/e16/dab/67fe16dab60da7a0ba2d4f6ba1e9b25f.svg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In 2012, Nvidia released the Kepler architecture, named after an astrologer, best known for discovering the laws of planetary motion. As usual, the technical documentation GK104 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[6]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> allowed us to look inside </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At Kepler, Nvidia significantly improved the energy efficiency of the chip by lowering the clock speed and combining the core frequency with the frequency of the card (previously, their frequency was doubled). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Such changes should have led to a decrease in productivity. However, thanks to a halving process technology (28 nanometers) and replacing the hardware dispatcher with a software one, Nvidia was able to not only place more SM on the chip, but also improve their design. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next Generation Streaming Multiprocessor (SMX) is a monster, almost all of whose indicators have been doubled or tripled.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thanks to four warp dispatchers capable of processing an entire warp in one clock cycle (Fermi could only process half of the warp), SMX now contained 196 cores. Each dispatcher had dual dispatching, which allowed to execute the second instruction in warp if it was independent of the current executable instruction. Dual scheduling was not always possible because one column of 32 cores was common to two scheduling operations. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Such a scheme complicated the scheduling logic (we will return to this later), but thanks to the execution of up to six warp instructions per cycle, the SMX provided twice the performance compared to the Fermi architecture SM. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It was stated that the flagship NVIDIA GeForce GTX 680 with a GK104 chip and eight SMX has 1536 cores, reaching 3,250 gigaflops </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[7]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">The elements of the crystal became so intricate that I had to remove all the signatures from the diagram.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b32/522/626/b32522626fd6ec0182dc19d0e885e770.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GK104 installed in the GeForce GTX 680.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pay attention to the completely redesigned memory subsystems, working with a breathtaking frequency of 6 GHz. </font><font style="vertical-align: inherit;">They allowed to reduce the number of memory controllers from six to four.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maxwell</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In 2014, Nvidia released the tenth generation GPU called Maxwell. </font><font style="vertical-align: inherit;">As stated in the GM107 technical documentation </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[8]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , the motto of the first generation of architecture was ‚ÄúMaximum energy efficiency and extraordinary performance for each watt consumed.‚Äù </font><font style="vertical-align: inherit;">The cards were positioned for "power-limited environments such as laptops and small form factor (SFF) PCs." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The most important decision was to abandon the Kepler structure with the number of CUDA cores in SM, which is not a power of two: some kernels became common and returned to work in half warp mode. </font><font style="vertical-align: inherit;">For the first time in the history of architecture, SMM had fewer cores than its predecessor: ‚Äúonly‚Äù 128 cores.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Matching the number of cores and warp size improved crystal segmentation, resulting in space and energy savings.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4df/8f5/36f/4df8f536f7f16cb62139c7484dd4c16b.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One 2014 SMM had as many cores (128) as the entire GTX 8800 in 2006.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
The second generation Maxwell (described in the technical documentation GM200 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[9]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) significantly increased productivity, while maintaining the energy efficiency of the first generation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The process technology remained at 28 nanometers, so Nvidia engineers could not resort to simple miniaturization to increase productivity. However, a decrease in the number of SMM cores has reduced their size, due to which more SMMs could be placed on the chip. Compared to Kepler, the second generation of Maxwell doubled the number of SMMs, while increasing its crystal area by only 25%.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the list of enhancements, you can also find simplified dispatch logic, which allowed to reduce the number of redundant redundancy of dispatch and the delay of calculations, which ensured an increase in the optimality of the use of warp. </font><font style="vertical-align: inherit;">Also, the memory frequency was increased by 15%. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Studying the Maxwell GM200 block diagram is already starting to strain your eyes. </font><font style="vertical-align: inherit;">But we still carefully examine it. </font><font style="vertical-align: inherit;">The flagship NVIDIA GeForce GTX 980 Ti card with a GM200 crystal and 24 SMM promised 3072 cores and 6,060 gigaflops </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[10]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/067/de7/563/067de75636221eda21a2215321d403f2.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GM200 installed in the GeForce GTX 980 Ti.</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pascal</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In 2016, Nvidia introduced Pascal. </font><font style="vertical-align: inherit;">The GP104 Technical Documentation </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[11]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> leaves a d√©j√† vu sensation because the Pascal SM looks exactly like the Maxwell SMM. </font><font style="vertical-align: inherit;">The lack of SM changes did not stagnate performance, because the 16-nanometer process technology allowed us to place more SMs and double the number of gigaflops again. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Among other major improvements was a memory system based on the all-new GDDR5X. </font><font style="vertical-align: inherit;">The 256-bit memory interface, thanks to eight memory controllers, provided transfer speeds of 10 gigaflops, increasing memory bandwidth by 43% and reducing the downtime of warp s. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The flagship NVIDIA GeForce GTX 1080 Ti with a GP102 chip and 28 TSM promised 3584 cores and 11,340 gigaflops </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[12]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f6c/f31/407/f6cf314079395ffc03f426101a13486d.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GP104 installed in the GeForce GTX 1080.</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Turing</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
With the release of Turing in 2018, Nvidia made its ‚Äúlargest architectural step in ten years‚Äù </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[13]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . In Turing SM, not only specialized Tensor cores with artificial intelligence appeared, but also cores for ray tracing (rautracing, RT). Such a fragmented structure reminds me of the layered architecture that existed before Tesla, and this proves once again that history loves repetition.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c99/4f3/cc6/c994f3cc63367ead11b2e7f4ed74b2be.svg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition to the new cores, three important features have appeared in Turing. Firstly, the CUDA kernel has now become superscalar, which allows parallel execution of instructions with integers and floating-point numbers. If you find 1996, then this may remind you of Intel's ‚Äúinnovative‚Äù architecture. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secondly, the new memory subsystem on GDDR6X, supported by 16 controllers, is now able to provide 14 gigaflops. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thirdly, streams now do not have common instruction pointers (IP) in warp. Thanks to Independent Thread Scheduling in Volta, each thread has its own IP. As a result of this, SMs can more flexibly configure dispatching flows in warp without the need for convergence as quickly as possible.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The flagship NVIDIA GeForce GTX 2080 Ti with TU102 and 68 TSM crystals has 4352 and reaches 13 45 gigaflops </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[14]</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">I did not draw a block diagram because it would look like a blurred green spot.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What awaits us next</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
According to rumors, the next architecture, code-named Ampere, will be announced in 2020. </font><font style="vertical-align: inherit;">As Intel proved with the Ice Lake example that there is still the potential for miniaturization using the 7-nanometer process technology, there is almost no doubt that Nvidia uses it to further reduce SM and double its performance.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c89/467/ca7/c89467ca7286b95e2da351c43dada54f.svg"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teraflops / s for each Nvidia chip / card (data source: techpowerup.com). </font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It will be interesting to see how Nvidia continues the evolution of the idea of ‚Äã‚Äãcrystals having three types of cores that perform different tasks. </font><font style="vertical-align: inherit;">Will we see crystals, the whole state of tensor cores or RT cores? </font><font style="vertical-align: inherit;">Curious.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reference materials</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[1] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Revisiting the Business Card Raytracer</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[2] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fermi: The First Complete GPU Computing Architecture</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[3] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA GeForce 8800 GTX (techpowerup.com)</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[4] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fermi (GF100) whitepaper</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[5] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA GeForce GTX 480</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[6] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kepler (GK104) whitepaper</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[7] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA GeForce GTX 680</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[8] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maxwell Gen1 (GM107) whitepaper</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[9] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maxwell Gen2 (GM200) whitepaper</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[10] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA GeForce GTX 980 Ti</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[11] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pascal (GP102) whitepaper</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[12] Source:</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA GeForce GTX 1080 Ti</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[13] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Turing (TU102) whitepaper</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
[14] Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA GeForce GTX 2080 Ti</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en500320/index.html">Own game engines: a little research</a></li>
<li><a href="../en501090/index.html">K8S Multicluster Journey</a></li>
<li><a href="../en501092/index.html">About the search for promising June and "udalenka". Redmadrobot Technical Support Manager Experience</a></li>
<li><a href="../en501098/index.html">SmartLi Smart Battery Solutions for Modular UPS</a></li>
<li><a href="../en501106/index.html">The simplest English word simulator using Python and Balabolka</a></li>
<li><a href="../en501110/index.html">Mobius and WWDC: more fun together</a></li>
<li><a href="../en501114/index.html">Gamification of personal productivity</a></li>
<li><a href="../en501116/index.html">AdvantShop presented a study on the impact of coronavirus on the online sales market (2019-2020)</a></li>
<li><a href="../en501118/index.html">Hooray (Oh no) - udalenka</a></li>
<li><a href="../en501120/index.html">What is a Google Ads Data Hub</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¶üèø üëÜüèº üö¨ CGI at home with Unreal Engine and iPhone üí¢ üë©üèª‚Äçüåæ üéÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello everyone! My name is Vasily Mazalov, I work as a senior video editor at Pixonic. Our department is creating video creatives for marketing and th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>CGI at home with Unreal Engine and iPhone</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/494942/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hello everyone! </font><font style="vertical-align: inherit;">My name is Vasily Mazalov, I work as a senior video editor at Pixonic. </font><font style="vertical-align: inherit;">Our department is creating video creatives for marketing and the community: videos for pages in pages, review videos of game innovations and other content. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When I do not create creativity, I monitor the Internet for new formats and ways of presenting material to make our own content more diverse, interesting and attractive to new players. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A year ago, I came across the following video:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Watch the video</font></font></b><div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/i51CizUXd7A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What do we see here? </font><font style="vertical-align: inherit;">The guy put on a suit to capture the movement of the body (so far nothing unusual), hung an iPhone in front of him (but this is interesting) and thus broadcasts the animation of the character‚Äôs face and body directly in real time in Unreal Engine, and the result looks for such a simple implementation pretty high quality. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cool idea, I thought. </font><font style="vertical-align: inherit;">Then closed the video. </font><font style="vertical-align: inherit;">And he continued to work further. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Six months later, training material on how to capture facial animation in Unreal Engine using an application on the iPhone turned out to be in the public domain. </font><font style="vertical-align: inherit;">At the same time, I found out that a suit for capturing motion was purchased in our art department. </font><font style="vertical-align: inherit;">Looked at its compatibility with UE: everything went well. </font><font style="vertical-align: inherit;">It only remained to find an iPhone for further work, but nowadays there are even fewer problems with this.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Watch the video</font></font></b><div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/AIHoDo7Y4_g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There were a lot of questions. </font><font style="vertical-align: inherit;">Before me was an uncultivated field of unexplored animation, the Unreal Engine, modeling of the human face and body, and other things completely remote from video editing, but at the same time, a great desire to realize what was intended. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The long process of studying various documentation has begun. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What happened as a result and how we achieved it, read on.</font></font><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Face animation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To realize our idea, it was not profitable for us to use and sculpt the character from scratch: it would take a lot of time and would require complex and most often unjustified improvements. Therefore, we decided to use DAZ Studio: facial bones were originally laid there, allowing you to quickly create the necessary facial contractions and emotions, which the sculptor would spend much more time on. Yes, the models created in DAZ are far from a photorealistic image, but they were ideally suited for our goals. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order to record facial animations, we only needed an iPhone with TrueDepth front-facing camera - that is, from iPhone X and above. It was this technology that read the face topology and transferred the necessary values ‚Äã‚Äãin Unreal already to our model.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/hu/yo/11/huyo11io_r0xlfw8nzzdzhawcvc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Blend shapes are responsible for different facial expressions - 3D models of the same topology, that is, with the same number of vertices, but differing in shape. </font><font style="vertical-align: inherit;">Face AR uses 51 blends, and thanks to the detailed Apple documentation that describes which specific blends are used in DAZ, we were able to make them quickly enough. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The set of emotions and blends in a 3D model looks something like this: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/be/rx/ep/berxephpsuciz3wxd7vcachheo0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Blend shapes from the Internet </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/jo/9q/p2/jo9qp2iqqqyo1vyp514j-7xacpu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Our blends</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
So, first we get our Unreal Engine face for tests, then build the application and go back to Unreal to get the result.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fh/x1/ui/fhx1uimpcjayhq0ybay3ifq8rdq.png"><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Body animation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To create a body, it was necessary to take into account the specifics of software for working with a suit. We worked with Noitom's Perception Neuron 2.0 Motion Capture System motion capture suit. It costs about 2500 dollars. This is the cheapest costume on the market and not the best representative among analogues: it is very sensitive to electromagnetic radiation, which makes the coordinates of the sensors move if it is within the radius of active radiation, and it will be even more difficult to clean the animation. Fortunately, we just moved to another floor, and in a new place it was quite deserted, which means that electromagnetic radiation was reduced to a minimum - that is, it was ideal for us.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jv/df/qt/jvdfqtdhz19xnag1w_4_lrtg1bw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Why a suit? Ready-made animations from various libraries did not suit us, because our character should have a unique character and behavior, and the face and body should accurately reflect them. If we did the animation from scratch, it would take a month, or even two. Using motion capture equipment saved this time. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unlike the face, the artists themselves painted the model of the body from scratch. Then it was necessary to make her rigging and skinning in Maya. After assembling the body, we start it in Unreal, there we collect everything for the mocap, record the animation, after which the result remains only to knead.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1c/na/r0/1cnar0oe7evduomjsu9v_q-gyx0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order for the animation to be accurately transmitted, the improvements were minimal or to avoid them at all, and in order to broadcast the animation from the costume directly to the Unreal Engine, it was necessary to correctly set the bones and remove unnecessary values ‚Äã‚Äãfrom our model. Noitom has a rough 3D model for the Unreal Engine, using which, as a reference, we needed to refine our own model: put it in the T-pose, place palms and fingers in non-standard modeling positions and reset all values ‚Äã‚Äãto zero. It was very important that all the bones were without unnecessary turns, otherwise the program will multiply them, thereby greatly distorting the movement.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In total, it took about two hours to calibrate the suit and record the first videos. </font><font style="vertical-align: inherit;">We set the settings in the Unreal Engine, recorded the animation of the body with all the necessary pauses according to the script, then recorded the animation of the face according to the movements of the body and the same script and got the result, which you will see in the following illustration.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/E77DXw-zSu4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After recording, the animation needed to be improved, so we set the animator the task of cleaning it. </font><font style="vertical-align: inherit;">It took him three days to clean up two minutes of animation.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/h1KUncMcTCw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then it took us about three weeks to the final version, and if we exclude the refinement of certain factors both in the face model and in the body, this period can be reduced by another week. </font></font><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Why do we use it?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's take a break from the CGI process and talk about what the objectives of the project were. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At that moment, when I delved into this topic and collected the information necessary for work, pilots appeared in our game. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Usually, when new content comes out, either an off-screen voice speaks about it, or the developers themselves, or the information simply somehow arrives through the gameplay. Now we have the opportunity to create a character, properly prepare it, assemble from high-quality assets the locations in which it will be located, and through this hero communicate with players: from story and review videos to live broadcasts.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For the first time in a game about robots, live characters appeared, and after them stories that they can tell about themselves and the world. And I thought it would be cool if it were possible to collect gameplay cinematics with characters that would immerse players in the game world as fast as we do videos on the engine. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vu/3j/lf/vu3jlfs_gtgsym1a0slfy_otmg0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Together with the community department, we began to come up with an image of the character, how he might look and what his story would be. Our senior community manager wrote the script, which we subsequently developed in terms of saving time and simplifying production.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/RQ6y8dRT2x8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this video you see almost all the tests that we have done with facial animation and body animation. </font><font style="vertical-align: inherit;">Since they have different specifications, they had to be tested in turn and only mixed at the end. </font><font style="vertical-align: inherit;">For body animation tests, a costume model was taken from the CGI trailer for the new release:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sl-P_8CSahg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, now let's show what we got as a result:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/3WMqrO1-6ww" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Having a motion capture suit, iPhone, 3D-model and Unreal Marketplace with a huge selection of free quality assets, we can collect interesting stories for our players in just a couple of weeks. </font><font style="vertical-align: inherit;">We also gained experience and understanding of how to quickly create a new character and, at the stage of its creation, take into account all the features of production in order to achieve the best result in a short time. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Why didn‚Äôt we aim to achieve the quality of cool cinematics like Blizzard? </font><font style="vertical-align: inherit;">For community-based and marketing content, current quality is enough to give our users a new perspective on the gaming world. </font><font style="vertical-align: inherit;">However, while there is still no need to improve the quality of the clips, we are always in search of new solutions.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en494930/index.html">Unity3D: Automatic Script Manager Aggregator</a></li>
<li><a href="../en494932/index.html">Operating a Large Distributed System: What I Learned</a></li>
<li><a href="../en494934/index.html">6 mistakes in English words that are terribly enraging</a></li>
<li><a href="../en494938/index.html">Happy backup day! Don't forget about him</a></li>
<li><a href="../en494940/index.html">DevOps - what is it, why, and how much is it in demand?</a></li>
<li><a href="../en494948/index.html">Create a VIP mailbox in Zimbra Collaboration Open-Source Edition</a></li>
<li><a href="../en494950/index.html">Some storage trends to look out for</a></li>
<li><a href="../en494956/index.html">Data Byte Life</a></li>
<li><a href="../en494964/index.html">Neural networks and trading. Practical implementation</a></li>
<li><a href="../en494966/index.html">SCRUM: a poem about love and pain</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
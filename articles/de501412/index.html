<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöí ü§∏üèΩ üßîüèæ Mobiles Eye-Tracking auf PyTorch üîÑ üë®‚Äçüíº üêî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Eye-Tracking-Markt wird voraussichtlich wachsen und wachsen: von 560 Mio. USD im Jahr 2020 auf 1.786 Mrd. USD im Jahr 2025 . Was ist die Alternati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Mobiles Eye-Tracking auf PyTorch</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/501412/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Eye-Tracking-Markt wird voraussichtlich wachsen und wachsen: von 560 Mio. USD im Jahr 2020 auf 1.786 Mrd. USD im Jahr </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2025</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Was ist die Alternative zu relativ teuren Ger√§ten? </font><font style="vertical-align: inherit;">Nat√ºrlich eine einfache Webcam! </font><font style="vertical-align: inherit;">Wie andere auch st√∂√üt dieser Ansatz auf viele Schwierigkeiten, sei es: eine Vielzahl von Ger√§ten (daher ist es schwierig, Einstellungen zu w√§hlen, die f√ºr alle Kameras gleicherma√üen funktionieren), starke Variabilit√§t der Parameter (von der Beleuchtung bis zur Neigung der Kamera und ihrer Position relativ zum Gesicht), anst√§ndiges Rechnen Macht (mehrere Cuda-Kerne und Xeon - das war's) ...</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obwohl Sie eine Minute warten, ist es wirklich notwendig, Geld f√ºr Top-End-Hardware auszugeben und sogar eine Grafikkarte zu kaufen? </font><font style="vertical-align: inherit;">Vielleicht gibt es eine M√∂glichkeit, alle Berechnungen auf CPU abzustimmen und nicht gleichzeitig an Geschwindigkeit zu verlieren?</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Wenn es so etwas nicht g√§be, g√§be es keinen Artikel dar√ºber, wie man ein Neuron auf PyTorch trainiert.)</font></font></p><a name="habracut"></a><br>
<h1 id="dannye"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daten</font></font></h1><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie immer in der Datenwissenschaft die wichtigste Frage. </font><font style="vertical-align: inherit;">Nach einiger Zeit der Suche fand ich den MPIIGaze- </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datensatz</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Die Autoren des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artikels</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> schlugen viele coole M√∂glichkeiten vor, ihn zu verarbeiten (z. B. die Positionierung des Kopfes zu normalisieren), aber wir werden den einfachen Weg gehen.</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Starten Sie also </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Colab</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , laden Sie den Laptop und starten Sie:</font></font></p><br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span>
<span class="hljs-keyword">import</span> os<font></font>
<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> scipy
<span class="hljs-keyword">import</span> scipy.io<font></font>
<font></font>
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> cv2<font></font>
<font></font>
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In Colab k√∂nnen Sie Systemdienstprogramme direkt von Ihrem Laptop aus verwenden, den Datensatz s√§en, herunterladen und entpacken:</font></font></p><br>
<pre><code class="python hljs">!wget https://datasets.d2.mpi-inf.mpg.de/MPIIGaze/MPIIGaze.tar.gz<font></font>
!tar xvzf MPIIGaze.tar.gz MPIIGaze</code></pre><br>
<p>  <em>Data/Original</em>    .    15,         .  <em>Annotation Subset</em>     ,   ‚Äî        .       header',    ,      . </p><br>
<pre><code class="python hljs">database_path = <span class="hljs-string">"/content/MPIIGaze"</span><font></font>
<font></font>
<span class="hljs-comment">#      </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_image_data</span>(<span class="hljs-params">patient_name</span>):</span>
    <span class="hljs-keyword">global</span> database_path<font></font>
<font></font>
    annotation_path = os.path.join(database_path, <span class="hljs-string">"Annotation Subset"</span>, patient_name + <span class="hljs-string">".txt"</span>)<font></font>
    data_folder = os.path.join(database_path, <span class="hljs-string">"Data"</span>, <span class="hljs-string">"Original"</span>, patient_name)<font></font>
<font></font>
    annotation = pd.read_csv(annotation_path, sep=<span class="hljs-string">" "</span>, header=<span class="hljs-literal">None</span>)<font></font>
<font></font>
    points = np.array(annotation.loc[:, list(range(<span class="hljs-number">1</span>, <span class="hljs-number">17</span>))])<font></font>
<font></font>
    filenames = np.array(annotation.loc[:, [<span class="hljs-number">0</span>]]).reshape(<span class="hljs-number">-1</span>)<font></font>
    images = [np.array(Image.open(os.path.join(data_folder, filename))) <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames]<font></font>
<font></font>
    <span class="hljs-keyword">return</span> images, points</code></pre><br>
<pre><code class="python hljs">images, points = load_image_data(<span class="hljs-string">"p00"</span>)</code></pre><br>
<pre><code class="python hljs">plt.imshow(images[<span class="hljs-number">0</span>])<font></font>
colors = [<span class="hljs-string">"r"</span>, <span class="hljs-string">"g"</span>, <span class="hljs-string">"b"</span>, <span class="hljs-string">"magenta"</span>, <span class="hljs-string">"y"</span>, <span class="hljs-string">"cyan"</span>, <span class="hljs-string">"brown"</span>, <span class="hljs-string">"lightcoral"</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(points[<span class="hljs-number">0</span>]), <span class="hljs-number">2</span>):<font></font>
    x, y = points[<span class="hljs-number">0</span>, i:i+<span class="hljs-number">2</span>] <span class="hljs-comment">#     ,      2,    X, Y</span>
    plt.scatter([x], [y], c=colors[i//<span class="hljs-number">2</span>])</code></pre><br>
<p>   :</p><br>
<p><img src="https://habrastorage.org/webt/fb/6j/0a/fb6j0aj3w9sojnatl8izlymmkl0.png"></p><br>
<p>,  :     ,     ,        .</p><br>
<p>,  .         ,    :     ,    (,   , ),        ,  2:1.     2  1    ,    .</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#     </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">distance</span>(<span class="hljs-params">x1, y1, x2, y2</span>):</span>
    <span class="hljs-keyword">return</span> int(((x1 - x2) ** <span class="hljs-number">2</span> + (y1 - y2) ** <span class="hljs-number">2</span>) ** <span class="hljs-number">0.5</span>)<font></font>
<font></font>
image_shape = (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>)<font></font>
<font></font>
<span class="hljs-comment">#           </span>
<span class="hljs-comment">#   </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handle_eye</span>(<span class="hljs-params">image, p1, p2, pupil</span>):</span>
    <span class="hljs-keyword">global</span> image_shape<font></font>
<font></font>
    line_len = distance(*p1, *p2)<font></font>
    <span class="hljs-comment"># x, y -&gt; y, x</span>
    p1 = p1[::<span class="hljs-number">-1</span>]<font></font>
    p2 = p2[::<span class="hljs-number">-1</span>]<font></font>
    pupil = pupil[::<span class="hljs-number">-1</span>]<font></font>
<font></font>
    corner1 = p1 - np.array([line_len//<span class="hljs-number">4</span>, <span class="hljs-number">0</span>])<font></font>
    corner2 = p2 + np.array([line_len//<span class="hljs-number">4</span>, <span class="hljs-number">0</span>])<font></font>
<font></font>
    sub_image = image[corner1[<span class="hljs-number">0</span>]:corner2[<span class="hljs-number">0</span>]+<span class="hljs-number">1</span>, corner1[<span class="hljs-number">1</span>]:corner2[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>]<font></font>
<font></font>
    pupil_new = pupil - corner1<font></font>
    pupil_new = pupil_new / sub_image.shape[:<span class="hljs-number">2</span>]<font></font>
<font></font>
    sub_image = cv2.resize(sub_image, image_shape[::<span class="hljs-number">-1</span>], interpolation=cv2.INTER_AREA)<font></font>
    sub_image = cv2.cvtColor(sub_image, cv2.COLOR_RGB2GRAY)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> sub_image, pupil_new</code></pre><br>
<p>     2 ,    ‚Äî   :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">image_to_train_data</span>(<span class="hljs-params">image, points</span>):</span>
    eye_right_p1 = points[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]<font></font>
    eye_right_p2 = points[<span class="hljs-number">2</span>:<span class="hljs-number">4</span>]<font></font>
    eye_right_pupil = points[<span class="hljs-number">12</span>:<span class="hljs-number">14</span>]<font></font>
<font></font>
    right_image, right_pupil = handle_eye(image, eye_right_p1, eye_right_p2, eye_right_pupil)<font></font>
<font></font>
    eye_left_p1 = points[<span class="hljs-number">4</span>:<span class="hljs-number">6</span>]<font></font>
    eye_left_p2 = points[<span class="hljs-number">6</span>:<span class="hljs-number">8</span>]<font></font>
    eye_left_pupil = points[<span class="hljs-number">14</span>:<span class="hljs-number">16</span>]<font></font>
<font></font>
    left_image, left_pupil = handle_eye(image, eye_left_p1, eye_left_p2, eye_left_pupil)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> right_image, right_pupil, left_image, left_pupil</code></pre><br>
<p>  (     ):</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#   </span>
right_image, right_pupil, left_image, left_pupil = image_to_train_data(images[<span class="hljs-number">10</span>], points[<span class="hljs-number">10</span>])<font></font>
<font></font>
plt.imshow(right_image, cmap=<span class="hljs-string">"gray"</span>)<font></font>
<font></font>
r_p_x = int(right_pupil[<span class="hljs-number">1</span>] * image_shape[<span class="hljs-number">1</span>])<font></font>
r_p_y = int(right_pupil[<span class="hljs-number">0</span>] * image_shape[<span class="hljs-number">0</span>])<font></font>
plt.scatter([r_p_x], [r_p_y], c=<span class="hljs-string">"red"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/bh/yd/6x/bhyd6xkn1wzv_q4ggpqpn4bysuq.png"></p><br>
<p>, -   .    :</p><br>
<pre><code class="python hljs">images_left_conc = []<font></font>
images_right_conc = []<font></font>
pupils_left_conc = []<font></font>
pupils_right_conc = []<font></font>
<font></font>
patients_path = os.path.join(database_path, <span class="hljs-string">"Data"</span>, <span class="hljs-string">"Original"</span>)
<span class="hljs-keyword">for</span> patient <span class="hljs-keyword">in</span> os.listdir(patients_path):<font></font>
    print(patient)<font></font>
    images, points = load_image_data(patient)<font></font>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(images)):<font></font>
        signle_image_data = image_to_train_data(images[i], points[i])<font></font>
<font></font>
        <span class="hljs-keyword">if</span> any(stuff <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> stuff <span class="hljs-keyword">in</span> signle_image_data):
            <span class="hljs-keyword">continue</span><font></font>
<font></font>
        right_image, right_pupil, left_image, left_pupil = signle_image_data<font></font>
<font></font>
        <span class="hljs-keyword">if</span> any(right_pupil &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> any(left_pupil &lt; <span class="hljs-number">0</span>):
            <span class="hljs-keyword">continue</span><font></font>
<font></font>
        images_right_conc.append(right_image)<font></font>
        images_left_conc.append(left_image)<font></font>
        pupils_right_conc.append(right_pupil)<font></font>
        pupils_left_conc.append(left_pupil)<font></font>
<font></font>
images_left_conc = np.array(images_left_conc)<font></font>
images_right_conc = np.array(images_right_conc)<font></font>
pupils_left_conc = np.array(pupils_left_conc)<font></font>
pupils_right_conc = np.array(pupils_right_conc)</code></pre><br>
<p> :</p><br>
<pre><code class="python hljs">images_left_conc = images_left_conc / <span class="hljs-number">255</span>
images_right_conc = images_right_conc / <span class="hljs-number">255</span></code></pre><br>
<p>  ,       :            :</p><br>
<pre><code class="python hljs">pupils_conc = np.zeros_like(pupils_left_conc)
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>):<font></font>
    pupils_conc[:, i] = (pupils_left_conc[:, i] + pupils_right_conc[:, i]) / <span class="hljs-number">2</span></code></pre><br>
<p>   :</p><br>
<pre><code class="python hljs">viz_pupils = np.zeros(image_shape)
<span class="hljs-keyword">for</span> y, x <span class="hljs-keyword">in</span> pupils_conc:<font></font>
    y = int(y * image_shape[<span class="hljs-number">0</span>])<font></font>
    x = int(x * image_shape[<span class="hljs-number">1</span>])<font></font>
    viz_pupils[y, x] += <span class="hljs-number">1</span><font></font>
max_val = viz_pupils.max()<font></font>
viz_pupils = viz_pupils / max_val<font></font>
<font></font>
plt.imshow(viz_pupils, cmap=<span class="hljs-string">"hot"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/7p/mc/q9/7pmcq9m4ges7od0ykdy33d2tr8u.png"></p><br>
<p>,       . </p><br>
<h1 id="predobrabotka"></h1><br>
<pre><code class="python hljs"><span class="hljs-comment">#    </span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
<font></font>
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, TensorDataset</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment"># ,      --   </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_2eyes_datasets</span>(<span class="hljs-params">images_left, images_right, pupils, train_size=<span class="hljs-number">0.8</span></span>):</span><font></font>
    n, height, width = images_left.shape<font></font>
<font></font>
    images_left = images_left.reshape(n, <span class="hljs-number">1</span>, height, width)<font></font>
    images_right = images_right.reshape(n, <span class="hljs-number">1</span>, height, width)<font></font>
<font></font>
    images_left_train, images_left_val, images_right_train, images_right_val, pupils_train, pupils_val = train_test_split(<font></font>
        images_left, images_right, pupils, train_size=train_size<font></font>
    )<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_dataset</span>(<span class="hljs-params">im_left, im_right, pups</span>):</span>
        <span class="hljs-keyword">return</span> TensorDataset(<font></font>
            torch.from_numpy(im_left.astype(np.float32)), torch.from_numpy(im_right.astype(np.float32)), torch.from_numpy(pups.astype(np.float32))<font></font>
        )<font></font>
<font></font>
    train_dataset = make_dataset(images_left_train, images_right_train, pupils_train)<font></font>
    val_dataset = make_dataset(images_left_val, images_right_val, pupils_val)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> train_dataset, val_dataset<font></font>
<font></font>
<span class="hljs-comment">#    </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_dataloaders</span>(<span class="hljs-params">train_dataset, val_dataset, batch_size=<span class="hljs-number">256</span></span>):</span><font></font>
    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)<font></font>
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> train_dataloader, val_dataloader</code></pre><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">256</span><font></font>
<font></font>
eyes_datasets = make_2eyes_datasets(images_left_conc, images_right_conc, pupils_conc)<font></font>
eyes_train_loader, eyes_val_loader = make_dataloaders(*eyes_datasets, batch_size=batch_size)</code></pre><br>
<h1 id="obuchaem-modelku"> </h1><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment"># ,  `keras.layers.Reshape`</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Reshaper</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, target_shape</span>):</span><font></font>
        super(Reshaper, self).__init__()<font></font>
        self.target_shape = target_shape<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, input</span>):</span>
        <span class="hljs-keyword">return</span> torch.reshape(input, (<span class="hljs-number">-1</span>, *self.target_shape))<font></font>
<font></font>
<span class="hljs-comment">#  </span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">EyesNet</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
        super(EyesNet, self).__init__()<font></font>
<font></font>
        <span class="hljs-comment">#  feature-extractor'   </span><font></font>
        self.features_left = nn.Sequential(<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">2</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            Reshaper([<span class="hljs-number">64</span>])<font></font>
        )<font></font>
        self.features_right = nn.Sequential(<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">2</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            Reshaper([<span class="hljs-number">64</span>])<font></font>
        )<font></font>
        self.fc = nn.Sequential(<font></font>
            nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">16</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Linear(<span class="hljs-number">16</span>, <span class="hljs-number">2</span>),<font></font>
            nn.Sigmoid()<font></font>
        )<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x_left, x_right</span>):</span>
        <span class="hljs-comment">#      ,    </span><font></font>
        x_left = self.features_left(x_left)<font></font>
        x_right = self.features_right(x_right)<font></font>
        x = torch.cat((x_left, x_right), <span class="hljs-number">1</span>)<font></font>
        x = self.fc(x)<font></font>
<font></font>
        <span class="hljs-keyword">return</span> x</code></pre><br>
<p> ,     GPU (     CPU ‚âà ),      8 .</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#   </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">model, train_loader, test_loader, epochs, lr, folder=<span class="hljs-string">"gazenet"</span></span>):</span>
    os.makedirs(folder, exist_ok=<span class="hljs-literal">True</span>)<font></font>
<font></font>
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)<font></font>
    mse = nn.MSELoss()<font></font>
<font></font>
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):<font></font>
        running_loss = <span class="hljs-number">0</span><font></font>
        error_mean = []<font></font>
        error_std = []<font></font>
        <span class="hljs-keyword">for</span> i, (*xs_batch, y_batch) <span class="hljs-keyword">in</span> enumerate(train_loader):<font></font>
            xs_batch = [x_batch.cuda() <span class="hljs-keyword">for</span> x_batch <span class="hljs-keyword">in</span> xs_batch]<font></font>
            y_batch = y_batch.cuda()<font></font>
<font></font>
            optimizer.zero_grad()<font></font>
<font></font>
            y_batch_pred = model(*xs_batch)<font></font>
            loss = mse(y_batch_pred, y_batch)<font></font>
<font></font>
            loss.backward()<font></font>
            optimizer.step()<font></font>
<font></font>
            running_loss += loss.item()<font></font>
<font></font>
            difference = (y_batch - y_batch_pred).detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>)<font></font>
            error_mean.append(np.mean(difference))<font></font>
            error_std.append(np.std(difference))<font></font>
<font></font>
        error_mean = np.mean(error_mean)<font></font>
        error_std = np.mean(error_std)<font></font>
<font></font>
        print(<span class="hljs-string">f"Epoch <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{epochs}</span>, train loss: <span class="hljs-subst">{running_loss}</span>, error mean: <span class="hljs-subst">{error_mean}</span>, error std: <span class="hljs-subst">{error_std}</span>"</span>)<font></font>
<font></font>
        running_loss = <span class="hljs-number">0</span><font></font>
        error_mean = []<font></font>
        error_std = []<font></font>
        <span class="hljs-keyword">for</span> i, (*xs_batch, y_batch) <span class="hljs-keyword">in</span> enumerate(train_loader):<font></font>
            xs_batch = [x_batch.cuda() <span class="hljs-keyword">for</span> x_batch <span class="hljs-keyword">in</span> xs_batch]<font></font>
            y_batch = y_batch.cuda()<font></font>
<font></font>
            y_batch_pred = model(*xs_batch)<font></font>
            loss = mse(y_batch_pred, y_batch)<font></font>
<font></font>
            loss.backward()<font></font>
            running_loss += loss.item()<font></font>
<font></font>
            difference = (y_batch - y_batch_pred).detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>)<font></font>
            error_mean.append(np.mean(difference))<font></font>
            error_std.append(np.std(difference))<font></font>
<font></font>
        error_mean = np.mean(error_mean)<font></font>
        error_std = np.mean(error_std)<font></font>
<font></font>
        print(<span class="hljs-string">f"Epoch <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{epochs}</span>, val loss: <span class="hljs-subst">{running_loss}</span>, error mean: <span class="hljs-subst">{error_mean}</span>, error std: <span class="hljs-subst">{error_std}</span>"</span>)<font></font>
<font></font>
        epoch_path = os.path.join(folder, <span class="hljs-string">f"epoch_<span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>.pth"</span>)<font></font>
        torch.save(model.state_dict(), epoch_path)</code></pre><br>
<pre><code class="python hljs">eyesnet = EyesNet().cuda()
<span class="hljs-comment">#      *eyes_net*</span>
train(eyesnet, eyes_train_loader, eyes_val_loader, <span class="hljs-number">300</span>, <span class="hljs-number">1e-3</span>, <span class="hljs-string">"eyes_net"</span>)</code></pre><br>
<p> ,    300  (   ,      ):</p><br>
<pre><code class="plaintext hljs">Epoch 1/300, train loss: 0.3125856015831232, error mean: -0.019309822469949722, error std: 0.08668763190507889<font></font>
Epoch 1/300, val loss: 0.18365296721458435, error mean: -0.008721884340047836, error std: 0.07283741235733032<font></font>
Epoch 2/300, train loss: 0.1700970521196723, error mean: 0.0001489206333644688, error std: 0.07033108174800873<font></font>
Epoch 2/300, val loss: 0.1475073655601591, error mean: -0.001808341359719634, error std: 0.06572529673576355<font></font>
...<font></font>
Epoch 299/300, train loss: 0.003378463063199888, error mean: -8.133996743708849e-05, error std: 0.009488753043115139<font></font>
Epoch 299/300, val loss: 0.004163481352406961, error mean: -0.001996406354010105, error std: 0.010547727346420288<font></font>
Epoch 300/300, train loss: 0.003569353237253381, error mean: -9.1125002654735e-05, error std: 0.00977678969502449<font></font>
Epoch 300/300, val loss: 0.004456713928448153, error mean: 0.0008482271223329008, error std: 0.010923181660473347</code></pre><br>
<p>299     ,     .</p><br>
<h1 id="ocenka-modeli"> </h1><br>
<p>    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> random<font></font>
<font></font>
<span class="hljs-comment">#            </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_output</span>(<span class="hljs-params">model, data_loader, batch_num=<span class="hljs-number">0</span>, samples=<span class="hljs-number">5</span>, grid_shape=(<span class="hljs-params"><span class="hljs-number">5</span>, <span class="hljs-number">1</span></span>), figsize=(<span class="hljs-params"><span class="hljs-number">10</span>, <span class="hljs-number">10</span></span>)</span>):</span>
    <span class="hljs-keyword">for</span> i, (*xs, y) <span class="hljs-keyword">in</span> enumerate(data_loader):
        <span class="hljs-keyword">if</span> i == batch_num:
            <span class="hljs-keyword">break</span>
    xs = [x.cuda() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
    y_pred = model(*xs).detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>)<font></font>
<font></font>
    xs = [x.detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
    imgs_conc = np.hstack(xs)<font></font>
    y = y.cpu().numpy().reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>)<font></font>
<font></font>
    indices = random.sample(range(len(y_pred)), samples)<font></font>
    fig, axes = plt.subplots(*grid_shape, figsize=figsize)<font></font>
    <span class="hljs-keyword">for</span> i, index <span class="hljs-keyword">in</span> enumerate(indices):<font></font>
        row = i // grid_shape[<span class="hljs-number">1</span>]<font></font>
        column = i % grid_shape[<span class="hljs-number">1</span>]<font></font>
<font></font>
        axes[row, column].imshow(imgs_conc[index])<font></font>
        axes[row, column].scatter([y_pred[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>, y_pred[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>], [y_pred[index, <span class="hljs-number">0</span>]*<span class="hljs-number">16</span>, (y_pred[index, <span class="hljs-number">0</span>]+<span class="hljs-number">1</span>)*<span class="hljs-number">16</span>], c=<span class="hljs-string">"r"</span>)<font></font>
        axes[row, column].scatter([y[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>, y[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>], [y[index, <span class="hljs-number">0</span>]*<span class="hljs-number">16</span>, (y[index, <span class="hljs-number">0</span>]+<span class="hljs-number">1</span>)*<span class="hljs-number">16</span>], c=<span class="hljs-string">"g"</span>)</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment">#  299 </span>
eyesnet.load_state_dict(torch.load(<span class="hljs-string">"eyes_net/epoch_299.pth"</span>))<font></font>
<font></font>
show_output(eyesnet, eyes_val_loader, <span class="hljs-number">103</span>, <span class="hljs-number">16</span>, (<span class="hljs-number">4</span>, <span class="hljs-number">4</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/pf/4b/on/pf4bonqbbbcu9b0glanhmarvhq8.png"></p><br>
<p>,   ,  ""      ,   .   ‚Äî -, -     , -,    .   ,     .</p><br>
<p>      ( X  Y),   :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">error_distribution</span>(<span class="hljs-params">model, data_loader, image_shape=(<span class="hljs-params"><span class="hljs-number">16</span>, <span class="hljs-number">32</span></span>), bins=<span class="hljs-number">32</span>, digits=<span class="hljs-number">2</span>, figsize=(<span class="hljs-params"><span class="hljs-number">10</span>,<span class="hljs-number">10</span></span>)</span>):</span><font></font>
    ys_true = []<font></font>
    ys_pred = []<font></font>
    <span class="hljs-keyword">for</span> *xs, y <span class="hljs-keyword">in</span> data_loader:<font></font>
        xs = [x.cuda() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
        y_pred = model(*xs)<font></font>
<font></font>
        ys_true.append(y.detach().cpu().numpy())<font></font>
        ys_pred.append(y_pred.detach().cpu().numpy())<font></font>
    ys_true = np.concatenate(ys_true)<font></font>
    ys_pred = np.concatenate(ys_pred)<font></font>
    indices = np.arange(len(ys_true))<font></font>
<font></font>
    fig, axes = plt.subplots(<span class="hljs-number">2</span>, figsize=figsize)
    <span class="hljs-keyword">for</span> ax_num <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>):<font></font>
        ys_true_subset = ys_true[:, ax_num]<font></font>
        ys_pred_subset = ys_pred[:, ax_num]<font></font>
        counts, ranges = np.histogram(ys_true_subset, bins=bins)<font></font>
<font></font>
        errors = []<font></font>
        labels = []<font></font>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(counts)):<font></font>
            begin, end = ranges[i], ranges[i + <span class="hljs-number">1</span>]<font></font>
            range_indices = indices[(ys_true_subset &gt;= begin) &amp; (ys_true_subset &lt;= end)]<font></font>
<font></font>
            diffs = np.abs(ys_pred_subset[range_indices] - ys_true_subset[range_indices])<font></font>
            label = (begin + end) / <span class="hljs-number">2</span>
            <span class="hljs-keyword">if</span> image_shape:<font></font>
                diffs = diffs * image_shape[ax_num]<font></font>
                label = label * image_shape[ax_num]<font></font>
            <span class="hljs-keyword">else</span>:<font></font>
                label = round(label, digits)<font></font>
            errors.append(diffs)<font></font>
            labels.append(str(label)[:<span class="hljs-number">2</span>+digits])<font></font>
<font></font>
        axes[ax_num].boxplot(errors, labels=labels)<font></font>
<font></font>
        <span class="hljs-keyword">if</span> image_shape:<font></font>
            y_label = <span class="hljs-string">"difference, px"</span>
            x_label = <span class="hljs-string">"true position, px"</span>
        <span class="hljs-keyword">else</span>:<font></font>
            y_label = <span class="hljs-string">"difference"</span>
            x_label = <span class="hljs-string">"true position"</span><font></font>
        axes[ax_num].set_ylabel(y_label)<font></font>
        axes[ax_num].set_xlabel(x_label)<font></font>
<font></font>
        <span class="hljs-keyword">if</span> ax_num == <span class="hljs-number">0</span>:<font></font>
            title = <span class="hljs-string">"Y"</span>
        <span class="hljs-keyword">else</span>:<font></font>
            title = <span class="hljs-string">"X"</span>
        axes[ax_num].set_title(title)</code></pre><br>
<pre><code class="python hljs">error_distribution(eyesnet, eyes_val_loader, figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/le/_2/if/le_2if7ikvv3cvopxbll_pwv9ik.png"><br>
<em>    ,   </em></p><br>
<p>-,   .  ,      .    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> time<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">measure_time</span>(<span class="hljs-params">model, data_loader, n_batches=<span class="hljs-number">5</span></span>):</span><font></font>
    begin_time = time.time()<font></font>
<font></font>
    batch_num = <span class="hljs-number">0</span>
    n_samples = <span class="hljs-number">0</span><font></font>
<font></font>
    predicted = []<font></font>
    <span class="hljs-keyword">for</span> *xs, y <span class="hljs-keyword">in</span> data_loader:<font></font>
        xs = [x.cpu() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
<font></font>
        y_pred = model(*xs)<font></font>
        predicted.append(y_pred.detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>))<font></font>
<font></font>
        batch_num += <span class="hljs-number">1</span><font></font>
        n_samples += len(y)<font></font>
<font></font>
        <span class="hljs-keyword">if</span> batch_num &gt;= n_batches:
            <span class="hljs-keyword">break</span><font></font>
<font></font>
    end_time = time.time()<font></font>
<font></font>
    time_per_sample = (end_time - begin_time) / n_samples<font></font>
    <span class="hljs-keyword">return</span> time_per_sample</code></pre><br>
<pre><code class="python hljs">eyesnet_cpu = EyesNet().cpu()<font></font>
eyesnet_cpu.load_state_dict(torch.load(<span class="hljs-string">"eyes_net/epoch_299.pth"</span>, map_location=<span class="hljs-string">"cpu"</span>))<font></font>
<font></font>
<span class="hljs-comment">#  dataloader,    ,     realtime</span>
_, eyes_val_loader_single = make_dataloaders(*eyes_datasets, batch_size=<span class="hljs-number">1</span>)<font></font>
<font></font>
tps = measure_time(eyesnet_cpu, eyes_val_loader_single)<font></font>
print(<span class="hljs-string">f"<span class="hljs-subst">{tps}</span> seconds per sample"</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.003347921371459961</span> seconds per sample</code></pre><br>
<p> ,        VGG16 ( ,     ):</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VGG16Based</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
        super(VGG16Based, self).__init__()<font></font>
<font></font>
        self.vgg = models.vgg16(pretrained=<span class="hljs-literal">False</span>)<font></font>
        self.vgg.classifier = nn.Sequential(<font></font>
            nn.Linear(<span class="hljs-number">25088</span>, <span class="hljs-number">256</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">2</span>),<font></font>
            nn.Sigmoid()<font></font>
        )<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x_left, x_right</span>):</span>
        x_mid = (x_left + x_right) / <span class="hljs-number">2</span>
        x = torch.cat((x_left, x_mid, x_right), dim=<span class="hljs-number">1</span>)<font></font>
<font></font>
        <span class="hljs-comment">#  ,  VGG16   </span>
        x_pad = torch.zeros((x.shape[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<font></font>
        x_pad[:, :, :<span class="hljs-number">16</span>, :] = x<font></font>
<font></font>
        x = self.vgg(x_pad)<font></font>
<font></font>
        <span class="hljs-keyword">return</span> x<font></font>
<font></font>
vgg16 = VGG16Based()<font></font>
vgg16_tps = measure_time(vgg16, eyes_val_loader_single)<font></font>
print(<span class="hljs-string">f"<span class="hljs-subst">{vgg16_tps}</span> seconds per sample"</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.023713159561157226</span> seconds per sample</code></pre><br>
<p>  ,     (AMD A10-4600M APU, 1500 MHz):</p><br>
<pre><code class="bash hljs">python benchmark.py <font></font>
0.003980588912963867 seconds per sample, EyesNet<font></font>
0.12246298789978027 seconds per sample, VGG16-based</code></pre><br>
<h1 id="vyvody"></h1><br>
<p> ,  ,   ,    (  VGG16  80 ,   EyesNet ‚Äî 1 ;         ,     ,   ). ,  ,   .    ,     :</p><br>
<ol>
<li>       (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"></a>).</li>
<li> . ,  float8  float32 ( ,     ,      ).</li>
<li> PyTorch Mobile ‚Äî  PyTorch   .         .</li>
<li>  .   ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">GazeCapture</a>.       ,   ,  ‚Äî   : </li>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">TFLite</a> ‚Äî TensorFlow   .     !</li>
</ol><br>
<h1 id="nemnogo-o-nas">  </h1><br>
<p>  ,   .  Data science (  ‚Äî   *^*)     .       ‚Äî FARADAY Lab.  ‚Äî         ,   .</p><br>
<p> c:</p><br>
<p><img src="https://habrastorage.org/webt/ms/1u/a8/ms1ua8wsr4u5h1opv3ylaonfq2k.png"></p><br>
<h2 id="poleznye-ssylki"> :</h2><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">      </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">  MPIIGaze</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">     </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyTorch Handy</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tensorflow Lite</font></font></a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de501396/index.html">Interview mit Sergey Zhuk - Autor von B√ºchern und Screencasts auf ReactPHP</a></li>
<li><a href="../de501398/index.html">Hacking Klassiker Sonic the Hedgehog f√ºr Sega</a></li>
<li><a href="../de501404/index.html">Apple TimeCapsule / AirPort Extreme. Root-Zugriff und Flucht aus einer angeh√§ngten Region</a></li>
<li><a href="../de501406/index.html">LabVIEW NXG 5.0 - Grundlagen und Blockdiagramm</a></li>
<li><a href="../de501408/index.html">Das Entwicklungsteam schl√§gt vor, auf UTF-8 umzusteigen</a></li>
<li><a href="../de501414/index.html">Debian, Nginx und Gunicorn f√ºr ein Django-Projekt konfigurieren</a></li>
<li><a href="../de501416/index.html">Ein bisschen √ºber WebRTC: was zu verwenden ist und der Fall aus der Praxis</a></li>
<li><a href="../de501418/index.html">Woche 4 Marathon: Motivation</a></li>
<li><a href="../de501420/index.html">Online Mitapas und YouTube Shows: JUG Ru Group Stream Week</a></li>
<li><a href="../de501424/index.html">Aus dem Leben mit Kubernetes: Wie wir DBMS (und nicht nur) aus √úberpr√ºfungsumgebungen in statische Umgebungen entfernt haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
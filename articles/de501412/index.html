<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚒 🤸🏽 🧔🏾 Mobiles Eye-Tracking auf PyTorch 🔄 👨‍💼 🐔</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Eye-Tracking-Markt wird voraussichtlich wachsen und wachsen: von 560 Mio. USD im Jahr 2020 auf 1.786 Mrd. USD im Jahr 2025 . Was ist die Alternati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Mobiles Eye-Tracking auf PyTorch</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/501412/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Eye-Tracking-Markt wird voraussichtlich wachsen und wachsen: von 560 Mio. USD im Jahr 2020 auf 1.786 Mrd. USD im Jahr </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2025</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Was ist die Alternative zu relativ teuren Geräten? </font><font style="vertical-align: inherit;">Natürlich eine einfache Webcam! </font><font style="vertical-align: inherit;">Wie andere auch stößt dieser Ansatz auf viele Schwierigkeiten, sei es: eine Vielzahl von Geräten (daher ist es schwierig, Einstellungen zu wählen, die für alle Kameras gleichermaßen funktionieren), starke Variabilität der Parameter (von der Beleuchtung bis zur Neigung der Kamera und ihrer Position relativ zum Gesicht), anständiges Rechnen Macht (mehrere Cuda-Kerne und Xeon - das war's) ...</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obwohl Sie eine Minute warten, ist es wirklich notwendig, Geld für Top-End-Hardware auszugeben und sogar eine Grafikkarte zu kaufen? </font><font style="vertical-align: inherit;">Vielleicht gibt es eine Möglichkeit, alle Berechnungen auf CPU abzustimmen und nicht gleichzeitig an Geschwindigkeit zu verlieren?</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Wenn es so etwas nicht gäbe, gäbe es keinen Artikel darüber, wie man ein Neuron auf PyTorch trainiert.)</font></font></p><a name="habracut"></a><br>
<h1 id="dannye"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daten</font></font></h1><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie immer in der Datenwissenschaft die wichtigste Frage. </font><font style="vertical-align: inherit;">Nach einiger Zeit der Suche fand ich den MPIIGaze- </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datensatz</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Die Autoren des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artikels</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> schlugen viele coole Möglichkeiten vor, ihn zu verarbeiten (z. B. die Positionierung des Kopfes zu normalisieren), aber wir werden den einfachen Weg gehen.</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Starten Sie also </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Colab</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , laden Sie den Laptop und starten Sie:</font></font></p><br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span>
<span class="hljs-keyword">import</span> os<font></font>
<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> scipy
<span class="hljs-keyword">import</span> scipy.io<font></font>
<font></font>
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> cv2<font></font>
<font></font>
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In Colab können Sie Systemdienstprogramme direkt von Ihrem Laptop aus verwenden, den Datensatz säen, herunterladen und entpacken:</font></font></p><br>
<pre><code class="python hljs">!wget https://datasets.d2.mpi-inf.mpg.de/MPIIGaze/MPIIGaze.tar.gz<font></font>
!tar xvzf MPIIGaze.tar.gz MPIIGaze</code></pre><br>
<p>  <em>Data/Original</em>    .    15,         .  <em>Annotation Subset</em>     ,   —        .       header',    ,      . </p><br>
<pre><code class="python hljs">database_path = <span class="hljs-string">"/content/MPIIGaze"</span><font></font>
<font></font>
<span class="hljs-comment">#      </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_image_data</span>(<span class="hljs-params">patient_name</span>):</span>
    <span class="hljs-keyword">global</span> database_path<font></font>
<font></font>
    annotation_path = os.path.join(database_path, <span class="hljs-string">"Annotation Subset"</span>, patient_name + <span class="hljs-string">".txt"</span>)<font></font>
    data_folder = os.path.join(database_path, <span class="hljs-string">"Data"</span>, <span class="hljs-string">"Original"</span>, patient_name)<font></font>
<font></font>
    annotation = pd.read_csv(annotation_path, sep=<span class="hljs-string">" "</span>, header=<span class="hljs-literal">None</span>)<font></font>
<font></font>
    points = np.array(annotation.loc[:, list(range(<span class="hljs-number">1</span>, <span class="hljs-number">17</span>))])<font></font>
<font></font>
    filenames = np.array(annotation.loc[:, [<span class="hljs-number">0</span>]]).reshape(<span class="hljs-number">-1</span>)<font></font>
    images = [np.array(Image.open(os.path.join(data_folder, filename))) <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames]<font></font>
<font></font>
    <span class="hljs-keyword">return</span> images, points</code></pre><br>
<pre><code class="python hljs">images, points = load_image_data(<span class="hljs-string">"p00"</span>)</code></pre><br>
<pre><code class="python hljs">plt.imshow(images[<span class="hljs-number">0</span>])<font></font>
colors = [<span class="hljs-string">"r"</span>, <span class="hljs-string">"g"</span>, <span class="hljs-string">"b"</span>, <span class="hljs-string">"magenta"</span>, <span class="hljs-string">"y"</span>, <span class="hljs-string">"cyan"</span>, <span class="hljs-string">"brown"</span>, <span class="hljs-string">"lightcoral"</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(points[<span class="hljs-number">0</span>]), <span class="hljs-number">2</span>):<font></font>
    x, y = points[<span class="hljs-number">0</span>, i:i+<span class="hljs-number">2</span>] <span class="hljs-comment">#     ,      2,    X, Y</span>
    plt.scatter([x], [y], c=colors[i//<span class="hljs-number">2</span>])</code></pre><br>
<p>   :</p><br>
<p><img src="https://habrastorage.org/webt/fb/6j/0a/fb6j0aj3w9sojnatl8izlymmkl0.png"></p><br>
<p>,  :     ,     ,        .</p><br>
<p>,  .         ,    :     ,    (,   , ),        ,  2:1.     2  1    ,    .</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#     </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">distance</span>(<span class="hljs-params">x1, y1, x2, y2</span>):</span>
    <span class="hljs-keyword">return</span> int(((x1 - x2) ** <span class="hljs-number">2</span> + (y1 - y2) ** <span class="hljs-number">2</span>) ** <span class="hljs-number">0.5</span>)<font></font>
<font></font>
image_shape = (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>)<font></font>
<font></font>
<span class="hljs-comment">#           </span>
<span class="hljs-comment">#   </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">handle_eye</span>(<span class="hljs-params">image, p1, p2, pupil</span>):</span>
    <span class="hljs-keyword">global</span> image_shape<font></font>
<font></font>
    line_len = distance(*p1, *p2)<font></font>
    <span class="hljs-comment"># x, y -&gt; y, x</span>
    p1 = p1[::<span class="hljs-number">-1</span>]<font></font>
    p2 = p2[::<span class="hljs-number">-1</span>]<font></font>
    pupil = pupil[::<span class="hljs-number">-1</span>]<font></font>
<font></font>
    corner1 = p1 - np.array([line_len//<span class="hljs-number">4</span>, <span class="hljs-number">0</span>])<font></font>
    corner2 = p2 + np.array([line_len//<span class="hljs-number">4</span>, <span class="hljs-number">0</span>])<font></font>
<font></font>
    sub_image = image[corner1[<span class="hljs-number">0</span>]:corner2[<span class="hljs-number">0</span>]+<span class="hljs-number">1</span>, corner1[<span class="hljs-number">1</span>]:corner2[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>]<font></font>
<font></font>
    pupil_new = pupil - corner1<font></font>
    pupil_new = pupil_new / sub_image.shape[:<span class="hljs-number">2</span>]<font></font>
<font></font>
    sub_image = cv2.resize(sub_image, image_shape[::<span class="hljs-number">-1</span>], interpolation=cv2.INTER_AREA)<font></font>
    sub_image = cv2.cvtColor(sub_image, cv2.COLOR_RGB2GRAY)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> sub_image, pupil_new</code></pre><br>
<p>     2 ,    —   :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">image_to_train_data</span>(<span class="hljs-params">image, points</span>):</span>
    eye_right_p1 = points[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]<font></font>
    eye_right_p2 = points[<span class="hljs-number">2</span>:<span class="hljs-number">4</span>]<font></font>
    eye_right_pupil = points[<span class="hljs-number">12</span>:<span class="hljs-number">14</span>]<font></font>
<font></font>
    right_image, right_pupil = handle_eye(image, eye_right_p1, eye_right_p2, eye_right_pupil)<font></font>
<font></font>
    eye_left_p1 = points[<span class="hljs-number">4</span>:<span class="hljs-number">6</span>]<font></font>
    eye_left_p2 = points[<span class="hljs-number">6</span>:<span class="hljs-number">8</span>]<font></font>
    eye_left_pupil = points[<span class="hljs-number">14</span>:<span class="hljs-number">16</span>]<font></font>
<font></font>
    left_image, left_pupil = handle_eye(image, eye_left_p1, eye_left_p2, eye_left_pupil)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> right_image, right_pupil, left_image, left_pupil</code></pre><br>
<p>  (     ):</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#   </span>
right_image, right_pupil, left_image, left_pupil = image_to_train_data(images[<span class="hljs-number">10</span>], points[<span class="hljs-number">10</span>])<font></font>
<font></font>
plt.imshow(right_image, cmap=<span class="hljs-string">"gray"</span>)<font></font>
<font></font>
r_p_x = int(right_pupil[<span class="hljs-number">1</span>] * image_shape[<span class="hljs-number">1</span>])<font></font>
r_p_y = int(right_pupil[<span class="hljs-number">0</span>] * image_shape[<span class="hljs-number">0</span>])<font></font>
plt.scatter([r_p_x], [r_p_y], c=<span class="hljs-string">"red"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/bh/yd/6x/bhyd6xkn1wzv_q4ggpqpn4bysuq.png"></p><br>
<p>, -   .    :</p><br>
<pre><code class="python hljs">images_left_conc = []<font></font>
images_right_conc = []<font></font>
pupils_left_conc = []<font></font>
pupils_right_conc = []<font></font>
<font></font>
patients_path = os.path.join(database_path, <span class="hljs-string">"Data"</span>, <span class="hljs-string">"Original"</span>)
<span class="hljs-keyword">for</span> patient <span class="hljs-keyword">in</span> os.listdir(patients_path):<font></font>
    print(patient)<font></font>
    images, points = load_image_data(patient)<font></font>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(images)):<font></font>
        signle_image_data = image_to_train_data(images[i], points[i])<font></font>
<font></font>
        <span class="hljs-keyword">if</span> any(stuff <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> stuff <span class="hljs-keyword">in</span> signle_image_data):
            <span class="hljs-keyword">continue</span><font></font>
<font></font>
        right_image, right_pupil, left_image, left_pupil = signle_image_data<font></font>
<font></font>
        <span class="hljs-keyword">if</span> any(right_pupil &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">or</span> any(left_pupil &lt; <span class="hljs-number">0</span>):
            <span class="hljs-keyword">continue</span><font></font>
<font></font>
        images_right_conc.append(right_image)<font></font>
        images_left_conc.append(left_image)<font></font>
        pupils_right_conc.append(right_pupil)<font></font>
        pupils_left_conc.append(left_pupil)<font></font>
<font></font>
images_left_conc = np.array(images_left_conc)<font></font>
images_right_conc = np.array(images_right_conc)<font></font>
pupils_left_conc = np.array(pupils_left_conc)<font></font>
pupils_right_conc = np.array(pupils_right_conc)</code></pre><br>
<p> :</p><br>
<pre><code class="python hljs">images_left_conc = images_left_conc / <span class="hljs-number">255</span>
images_right_conc = images_right_conc / <span class="hljs-number">255</span></code></pre><br>
<p>  ,       :            :</p><br>
<pre><code class="python hljs">pupils_conc = np.zeros_like(pupils_left_conc)
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>):<font></font>
    pupils_conc[:, i] = (pupils_left_conc[:, i] + pupils_right_conc[:, i]) / <span class="hljs-number">2</span></code></pre><br>
<p>   :</p><br>
<pre><code class="python hljs">viz_pupils = np.zeros(image_shape)
<span class="hljs-keyword">for</span> y, x <span class="hljs-keyword">in</span> pupils_conc:<font></font>
    y = int(y * image_shape[<span class="hljs-number">0</span>])<font></font>
    x = int(x * image_shape[<span class="hljs-number">1</span>])<font></font>
    viz_pupils[y, x] += <span class="hljs-number">1</span><font></font>
max_val = viz_pupils.max()<font></font>
viz_pupils = viz_pupils / max_val<font></font>
<font></font>
plt.imshow(viz_pupils, cmap=<span class="hljs-string">"hot"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/7p/mc/q9/7pmcq9m4ges7od0ykdy33d2tr8u.png"></p><br>
<p>,       . </p><br>
<h1 id="predobrabotka"></h1><br>
<pre><code class="python hljs"><span class="hljs-comment">#    </span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
<font></font>
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader, TensorDataset</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment"># ,      --   </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_2eyes_datasets</span>(<span class="hljs-params">images_left, images_right, pupils, train_size=<span class="hljs-number">0.8</span></span>):</span><font></font>
    n, height, width = images_left.shape<font></font>
<font></font>
    images_left = images_left.reshape(n, <span class="hljs-number">1</span>, height, width)<font></font>
    images_right = images_right.reshape(n, <span class="hljs-number">1</span>, height, width)<font></font>
<font></font>
    images_left_train, images_left_val, images_right_train, images_right_val, pupils_train, pupils_val = train_test_split(<font></font>
        images_left, images_right, pupils, train_size=train_size<font></font>
    )<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_dataset</span>(<span class="hljs-params">im_left, im_right, pups</span>):</span>
        <span class="hljs-keyword">return</span> TensorDataset(<font></font>
            torch.from_numpy(im_left.astype(np.float32)), torch.from_numpy(im_right.astype(np.float32)), torch.from_numpy(pups.astype(np.float32))<font></font>
        )<font></font>
<font></font>
    train_dataset = make_dataset(images_left_train, images_right_train, pupils_train)<font></font>
    val_dataset = make_dataset(images_left_val, images_right_val, pupils_val)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> train_dataset, val_dataset<font></font>
<font></font>
<span class="hljs-comment">#    </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_dataloaders</span>(<span class="hljs-params">train_dataset, val_dataset, batch_size=<span class="hljs-number">256</span></span>):</span><font></font>
    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)<font></font>
    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> train_dataloader, val_dataloader</code></pre><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">256</span><font></font>
<font></font>
eyes_datasets = make_2eyes_datasets(images_left_conc, images_right_conc, pupils_conc)<font></font>
eyes_train_loader, eyes_val_loader = make_dataloaders(*eyes_datasets, batch_size=batch_size)</code></pre><br>
<h1 id="obuchaem-modelku"> </h1><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment"># ,  `keras.layers.Reshape`</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Reshaper</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, target_shape</span>):</span><font></font>
        super(Reshaper, self).__init__()<font></font>
        self.target_shape = target_shape<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, input</span>):</span>
        <span class="hljs-keyword">return</span> torch.reshape(input, (<span class="hljs-number">-1</span>, *self.target_shape))<font></font>
<font></font>
<span class="hljs-comment">#  </span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">EyesNet</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
        super(EyesNet, self).__init__()<font></font>
<font></font>
        <span class="hljs-comment">#  feature-extractor'   </span><font></font>
        self.features_left = nn.Sequential(<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">2</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            Reshaper([<span class="hljs-number">64</span>])<font></font>
        )<font></font>
        self.features_right = nn.Sequential(<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">2</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">32</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Conv2d(in_channels=<span class="hljs-number">64</span>, out_channels=<span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            Reshaper([<span class="hljs-number">64</span>])<font></font>
        )<font></font>
        self.fc = nn.Sequential(<font></font>
            nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">16</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Linear(<span class="hljs-number">16</span>, <span class="hljs-number">2</span>),<font></font>
            nn.Sigmoid()<font></font>
        )<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x_left, x_right</span>):</span>
        <span class="hljs-comment">#      ,    </span><font></font>
        x_left = self.features_left(x_left)<font></font>
        x_right = self.features_right(x_right)<font></font>
        x = torch.cat((x_left, x_right), <span class="hljs-number">1</span>)<font></font>
        x = self.fc(x)<font></font>
<font></font>
        <span class="hljs-keyword">return</span> x</code></pre><br>
<p> ,     GPU (     CPU ≈ ),      8 .</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#   </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">model, train_loader, test_loader, epochs, lr, folder=<span class="hljs-string">"gazenet"</span></span>):</span>
    os.makedirs(folder, exist_ok=<span class="hljs-literal">True</span>)<font></font>
<font></font>
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)<font></font>
    mse = nn.MSELoss()<font></font>
<font></font>
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):<font></font>
        running_loss = <span class="hljs-number">0</span><font></font>
        error_mean = []<font></font>
        error_std = []<font></font>
        <span class="hljs-keyword">for</span> i, (*xs_batch, y_batch) <span class="hljs-keyword">in</span> enumerate(train_loader):<font></font>
            xs_batch = [x_batch.cuda() <span class="hljs-keyword">for</span> x_batch <span class="hljs-keyword">in</span> xs_batch]<font></font>
            y_batch = y_batch.cuda()<font></font>
<font></font>
            optimizer.zero_grad()<font></font>
<font></font>
            y_batch_pred = model(*xs_batch)<font></font>
            loss = mse(y_batch_pred, y_batch)<font></font>
<font></font>
            loss.backward()<font></font>
            optimizer.step()<font></font>
<font></font>
            running_loss += loss.item()<font></font>
<font></font>
            difference = (y_batch - y_batch_pred).detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>)<font></font>
            error_mean.append(np.mean(difference))<font></font>
            error_std.append(np.std(difference))<font></font>
<font></font>
        error_mean = np.mean(error_mean)<font></font>
        error_std = np.mean(error_std)<font></font>
<font></font>
        print(<span class="hljs-string">f"Epoch <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{epochs}</span>, train loss: <span class="hljs-subst">{running_loss}</span>, error mean: <span class="hljs-subst">{error_mean}</span>, error std: <span class="hljs-subst">{error_std}</span>"</span>)<font></font>
<font></font>
        running_loss = <span class="hljs-number">0</span><font></font>
        error_mean = []<font></font>
        error_std = []<font></font>
        <span class="hljs-keyword">for</span> i, (*xs_batch, y_batch) <span class="hljs-keyword">in</span> enumerate(train_loader):<font></font>
            xs_batch = [x_batch.cuda() <span class="hljs-keyword">for</span> x_batch <span class="hljs-keyword">in</span> xs_batch]<font></font>
            y_batch = y_batch.cuda()<font></font>
<font></font>
            y_batch_pred = model(*xs_batch)<font></font>
            loss = mse(y_batch_pred, y_batch)<font></font>
<font></font>
            loss.backward()<font></font>
            running_loss += loss.item()<font></font>
<font></font>
            difference = (y_batch - y_batch_pred).detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>)<font></font>
            error_mean.append(np.mean(difference))<font></font>
            error_std.append(np.std(difference))<font></font>
<font></font>
        error_mean = np.mean(error_mean)<font></font>
        error_std = np.mean(error_std)<font></font>
<font></font>
        print(<span class="hljs-string">f"Epoch <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{epochs}</span>, val loss: <span class="hljs-subst">{running_loss}</span>, error mean: <span class="hljs-subst">{error_mean}</span>, error std: <span class="hljs-subst">{error_std}</span>"</span>)<font></font>
<font></font>
        epoch_path = os.path.join(folder, <span class="hljs-string">f"epoch_<span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>.pth"</span>)<font></font>
        torch.save(model.state_dict(), epoch_path)</code></pre><br>
<pre><code class="python hljs">eyesnet = EyesNet().cuda()
<span class="hljs-comment">#      *eyes_net*</span>
train(eyesnet, eyes_train_loader, eyes_val_loader, <span class="hljs-number">300</span>, <span class="hljs-number">1e-3</span>, <span class="hljs-string">"eyes_net"</span>)</code></pre><br>
<p> ,    300  (   ,      ):</p><br>
<pre><code class="plaintext hljs">Epoch 1/300, train loss: 0.3125856015831232, error mean: -0.019309822469949722, error std: 0.08668763190507889<font></font>
Epoch 1/300, val loss: 0.18365296721458435, error mean: -0.008721884340047836, error std: 0.07283741235733032<font></font>
Epoch 2/300, train loss: 0.1700970521196723, error mean: 0.0001489206333644688, error std: 0.07033108174800873<font></font>
Epoch 2/300, val loss: 0.1475073655601591, error mean: -0.001808341359719634, error std: 0.06572529673576355<font></font>
...<font></font>
Epoch 299/300, train loss: 0.003378463063199888, error mean: -8.133996743708849e-05, error std: 0.009488753043115139<font></font>
Epoch 299/300, val loss: 0.004163481352406961, error mean: -0.001996406354010105, error std: 0.010547727346420288<font></font>
Epoch 300/300, train loss: 0.003569353237253381, error mean: -9.1125002654735e-05, error std: 0.00977678969502449<font></font>
Epoch 300/300, val loss: 0.004456713928448153, error mean: 0.0008482271223329008, error std: 0.010923181660473347</code></pre><br>
<p>299     ,     .</p><br>
<h1 id="ocenka-modeli"> </h1><br>
<p>    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> random<font></font>
<font></font>
<span class="hljs-comment">#            </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_output</span>(<span class="hljs-params">model, data_loader, batch_num=<span class="hljs-number">0</span>, samples=<span class="hljs-number">5</span>, grid_shape=(<span class="hljs-params"><span class="hljs-number">5</span>, <span class="hljs-number">1</span></span>), figsize=(<span class="hljs-params"><span class="hljs-number">10</span>, <span class="hljs-number">10</span></span>)</span>):</span>
    <span class="hljs-keyword">for</span> i, (*xs, y) <span class="hljs-keyword">in</span> enumerate(data_loader):
        <span class="hljs-keyword">if</span> i == batch_num:
            <span class="hljs-keyword">break</span>
    xs = [x.cuda() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
    y_pred = model(*xs).detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>)<font></font>
<font></font>
    xs = [x.detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
    imgs_conc = np.hstack(xs)<font></font>
    y = y.cpu().numpy().reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>)<font></font>
<font></font>
    indices = random.sample(range(len(y_pred)), samples)<font></font>
    fig, axes = plt.subplots(*grid_shape, figsize=figsize)<font></font>
    <span class="hljs-keyword">for</span> i, index <span class="hljs-keyword">in</span> enumerate(indices):<font></font>
        row = i // grid_shape[<span class="hljs-number">1</span>]<font></font>
        column = i % grid_shape[<span class="hljs-number">1</span>]<font></font>
<font></font>
        axes[row, column].imshow(imgs_conc[index])<font></font>
        axes[row, column].scatter([y_pred[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>, y_pred[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>], [y_pred[index, <span class="hljs-number">0</span>]*<span class="hljs-number">16</span>, (y_pred[index, <span class="hljs-number">0</span>]+<span class="hljs-number">1</span>)*<span class="hljs-number">16</span>], c=<span class="hljs-string">"r"</span>)<font></font>
        axes[row, column].scatter([y[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>, y[index, <span class="hljs-number">1</span>]*<span class="hljs-number">32</span>], [y[index, <span class="hljs-number">0</span>]*<span class="hljs-number">16</span>, (y[index, <span class="hljs-number">0</span>]+<span class="hljs-number">1</span>)*<span class="hljs-number">16</span>], c=<span class="hljs-string">"g"</span>)</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment">#  299 </span>
eyesnet.load_state_dict(torch.load(<span class="hljs-string">"eyes_net/epoch_299.pth"</span>))<font></font>
<font></font>
show_output(eyesnet, eyes_val_loader, <span class="hljs-number">103</span>, <span class="hljs-number">16</span>, (<span class="hljs-number">4</span>, <span class="hljs-number">4</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/pf/4b/on/pf4bonqbbbcu9b0glanhmarvhq8.png"></p><br>
<p>,   ,  ""      ,   .   — -, -     , -,    .   ,     .</p><br>
<p>      ( X  Y),   :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">error_distribution</span>(<span class="hljs-params">model, data_loader, image_shape=(<span class="hljs-params"><span class="hljs-number">16</span>, <span class="hljs-number">32</span></span>), bins=<span class="hljs-number">32</span>, digits=<span class="hljs-number">2</span>, figsize=(<span class="hljs-params"><span class="hljs-number">10</span>,<span class="hljs-number">10</span></span>)</span>):</span><font></font>
    ys_true = []<font></font>
    ys_pred = []<font></font>
    <span class="hljs-keyword">for</span> *xs, y <span class="hljs-keyword">in</span> data_loader:<font></font>
        xs = [x.cuda() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
        y_pred = model(*xs)<font></font>
<font></font>
        ys_true.append(y.detach().cpu().numpy())<font></font>
        ys_pred.append(y_pred.detach().cpu().numpy())<font></font>
    ys_true = np.concatenate(ys_true)<font></font>
    ys_pred = np.concatenate(ys_pred)<font></font>
    indices = np.arange(len(ys_true))<font></font>
<font></font>
    fig, axes = plt.subplots(<span class="hljs-number">2</span>, figsize=figsize)
    <span class="hljs-keyword">for</span> ax_num <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>):<font></font>
        ys_true_subset = ys_true[:, ax_num]<font></font>
        ys_pred_subset = ys_pred[:, ax_num]<font></font>
        counts, ranges = np.histogram(ys_true_subset, bins=bins)<font></font>
<font></font>
        errors = []<font></font>
        labels = []<font></font>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(counts)):<font></font>
            begin, end = ranges[i], ranges[i + <span class="hljs-number">1</span>]<font></font>
            range_indices = indices[(ys_true_subset &gt;= begin) &amp; (ys_true_subset &lt;= end)]<font></font>
<font></font>
            diffs = np.abs(ys_pred_subset[range_indices] - ys_true_subset[range_indices])<font></font>
            label = (begin + end) / <span class="hljs-number">2</span>
            <span class="hljs-keyword">if</span> image_shape:<font></font>
                diffs = diffs * image_shape[ax_num]<font></font>
                label = label * image_shape[ax_num]<font></font>
            <span class="hljs-keyword">else</span>:<font></font>
                label = round(label, digits)<font></font>
            errors.append(diffs)<font></font>
            labels.append(str(label)[:<span class="hljs-number">2</span>+digits])<font></font>
<font></font>
        axes[ax_num].boxplot(errors, labels=labels)<font></font>
<font></font>
        <span class="hljs-keyword">if</span> image_shape:<font></font>
            y_label = <span class="hljs-string">"difference, px"</span>
            x_label = <span class="hljs-string">"true position, px"</span>
        <span class="hljs-keyword">else</span>:<font></font>
            y_label = <span class="hljs-string">"difference"</span>
            x_label = <span class="hljs-string">"true position"</span><font></font>
        axes[ax_num].set_ylabel(y_label)<font></font>
        axes[ax_num].set_xlabel(x_label)<font></font>
<font></font>
        <span class="hljs-keyword">if</span> ax_num == <span class="hljs-number">0</span>:<font></font>
            title = <span class="hljs-string">"Y"</span>
        <span class="hljs-keyword">else</span>:<font></font>
            title = <span class="hljs-string">"X"</span>
        axes[ax_num].set_title(title)</code></pre><br>
<pre><code class="python hljs">error_distribution(eyesnet, eyes_val_loader, figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/le/_2/if/le_2if7ikvv3cvopxbll_pwv9ik.png"><br>
<em>    ,   </em></p><br>
<p>-,   .  ,      .    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> time<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">measure_time</span>(<span class="hljs-params">model, data_loader, n_batches=<span class="hljs-number">5</span></span>):</span><font></font>
    begin_time = time.time()<font></font>
<font></font>
    batch_num = <span class="hljs-number">0</span>
    n_samples = <span class="hljs-number">0</span><font></font>
<font></font>
    predicted = []<font></font>
    <span class="hljs-keyword">for</span> *xs, y <span class="hljs-keyword">in</span> data_loader:<font></font>
        xs = [x.cpu() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<font></font>
<font></font>
        y_pred = model(*xs)<font></font>
        predicted.append(y_pred.detach().cpu().numpy().reshape(<span class="hljs-number">-1</span>))<font></font>
<font></font>
        batch_num += <span class="hljs-number">1</span><font></font>
        n_samples += len(y)<font></font>
<font></font>
        <span class="hljs-keyword">if</span> batch_num &gt;= n_batches:
            <span class="hljs-keyword">break</span><font></font>
<font></font>
    end_time = time.time()<font></font>
<font></font>
    time_per_sample = (end_time - begin_time) / n_samples<font></font>
    <span class="hljs-keyword">return</span> time_per_sample</code></pre><br>
<pre><code class="python hljs">eyesnet_cpu = EyesNet().cpu()<font></font>
eyesnet_cpu.load_state_dict(torch.load(<span class="hljs-string">"eyes_net/epoch_299.pth"</span>, map_location=<span class="hljs-string">"cpu"</span>))<font></font>
<font></font>
<span class="hljs-comment">#  dataloader,    ,     realtime</span>
_, eyes_val_loader_single = make_dataloaders(*eyes_datasets, batch_size=<span class="hljs-number">1</span>)<font></font>
<font></font>
tps = measure_time(eyesnet_cpu, eyes_val_loader_single)<font></font>
print(<span class="hljs-string">f"<span class="hljs-subst">{tps}</span> seconds per sample"</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.003347921371459961</span> seconds per sample</code></pre><br>
<p> ,        VGG16 ( ,     ):</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">VGG16Based</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
        super(VGG16Based, self).__init__()<font></font>
<font></font>
        self.vgg = models.vgg16(pretrained=<span class="hljs-literal">False</span>)<font></font>
        self.vgg.classifier = nn.Sequential(<font></font>
            nn.Linear(<span class="hljs-number">25088</span>, <span class="hljs-number">256</span>),<font></font>
            nn.LeakyReLU(),<font></font>
            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">2</span>),<font></font>
            nn.Sigmoid()<font></font>
        )<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x_left, x_right</span>):</span>
        x_mid = (x_left + x_right) / <span class="hljs-number">2</span>
        x = torch.cat((x_left, x_mid, x_right), dim=<span class="hljs-number">1</span>)<font></font>
<font></font>
        <span class="hljs-comment">#  ,  VGG16   </span>
        x_pad = torch.zeros((x.shape[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<font></font>
        x_pad[:, :, :<span class="hljs-number">16</span>, :] = x<font></font>
<font></font>
        x = self.vgg(x_pad)<font></font>
<font></font>
        <span class="hljs-keyword">return</span> x<font></font>
<font></font>
vgg16 = VGG16Based()<font></font>
vgg16_tps = measure_time(vgg16, eyes_val_loader_single)<font></font>
print(<span class="hljs-string">f"<span class="hljs-subst">{vgg16_tps}</span> seconds per sample"</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.023713159561157226</span> seconds per sample</code></pre><br>
<p>  ,     (AMD A10-4600M APU, 1500 MHz):</p><br>
<pre><code class="bash hljs">python benchmark.py <font></font>
0.003980588912963867 seconds per sample, EyesNet<font></font>
0.12246298789978027 seconds per sample, VGG16-based</code></pre><br>
<h1 id="vyvody"></h1><br>
<p> ,  ,   ,    (  VGG16  80 ,   EyesNet — 1 ;         ,     ,   ). ,  ,   .    ,     :</p><br>
<ol>
<li>       (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"></a>).</li>
<li> . ,  float8  float32 ( ,     ,      ).</li>
<li> PyTorch Mobile —  PyTorch   .         .</li>
<li>  .   — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">GazeCapture</a>.       ,   ,  —   : </li>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">TFLite</a> — TensorFlow   .     !</li>
</ol><br>
<h1 id="nemnogo-o-nas">  </h1><br>
<p>  ,   .  Data science (  —   *^*)     .       — FARADAY Lab.  —         ,   .</p><br>
<p> c:</p><br>
<p><img src="https://habrastorage.org/webt/ms/1u/a8/ms1ua8wsr4u5h1opv3ylaonfq2k.png"></p><br>
<h2 id="poleznye-ssylki"> :</h2><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">      </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">  MPIIGaze</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">     </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyTorch Handy</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tensorflow Lite</font></font></a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de501396/index.html">Interview mit Sergey Zhuk - Autor von Büchern und Screencasts auf ReactPHP</a></li>
<li><a href="../de501398/index.html">Hacking Klassiker Sonic the Hedgehog für Sega</a></li>
<li><a href="../de501404/index.html">Apple TimeCapsule / AirPort Extreme. Root-Zugriff und Flucht aus einer angehängten Region</a></li>
<li><a href="../de501406/index.html">LabVIEW NXG 5.0 - Grundlagen und Blockdiagramm</a></li>
<li><a href="../de501408/index.html">Das Entwicklungsteam schlägt vor, auf UTF-8 umzusteigen</a></li>
<li><a href="../de501414/index.html">Debian, Nginx und Gunicorn für ein Django-Projekt konfigurieren</a></li>
<li><a href="../de501416/index.html">Ein bisschen über WebRTC: was zu verwenden ist und der Fall aus der Praxis</a></li>
<li><a href="../de501418/index.html">Woche 4 Marathon: Motivation</a></li>
<li><a href="../de501420/index.html">Online Mitapas und YouTube Shows: JUG Ru Group Stream Week</a></li>
<li><a href="../de501424/index.html">Aus dem Leben mit Kubernetes: Wie wir DBMS (und nicht nur) aus Überprüfungsumgebungen in statische Umgebungen entfernt haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
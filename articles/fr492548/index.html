<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåô ü§ï üë¥üèΩ Apprentissage automatique Unity: apprendre aux agents MO √† sauter par-dessus les murs üôçüèæ üéØ üö∂üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a eu des perc√©es majeures dans l'apprentissage par renforcement (RL) au cours des derni√®res ann√©es: de la premi√®re utilisation r√©ussie de celui-c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Apprentissage automatique Unity: apprendre aux agents MO √† sauter par-dessus les murs</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/492548/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il y a eu des perc√©es majeures dans l'apprentissage par renforcement (RL) au cours des derni√®res ann√©es: de la premi√®re utilisation r√©ussie de celui-ci dans la formation de pixels bruts √† la formation de robots AI ouverts, et des environnements de plus en plus sophistiqu√©s sont n√©cessaires pour de nouveaux progr√®s, auxquels L'unit√© vient. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'outil Unity ML-Agents est un nouveau plugin dans le moteur de jeu Unity, vous permettant d'utiliser Unity comme constructeur d'environnement pour former des agents MO. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De jouer au football √† marcher, sauter des murs et apprendre √† ma√Ætriser l'IA avec un b√¢ton, Unity ML-Agents Toolkit fournit un large √©ventail de conditions d'entra√Ænement pour les agents. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans cet article, nous verrons comment fonctionnent les agents Unity MO, puis nous apprendrons √† l'un de ces agents √† sauter par-dessus les murs.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/9c6/5ad/bdb/9c65adbdbb38b939262c10e5ac728dde.gif" alt="image"><br>
<br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'est-ce que les agents Unity ML?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unity ML-Agents est un nouveau plugin pour le moteur de jeu Unity, qui vous permet de cr√©er ou d'utiliser des environnements pr√™ts √† l'emploi pour former nos agents. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le plugin se compose de trois composants: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/zo/mx/m_/zomxm_3g9svsej0iarjpw1vbnta.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le premier - un </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">environnement d'apprentissage</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'environnement d'apprentissage</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), contenant des sc√®nes d'Unity et des √©l√©ments environnementaux. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La seconde est l' </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">API Python</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , dans laquelle se trouvent les algorithmes RL (tels que PPO - Proximal Policy Optimization et SAC - Soft Actor-Critic). </font><font style="vertical-align: inherit;">Nous utilisons cette API pour lancer la formation, les tests, etc. Elle est connect√©e √† l'environnement d'apprentissage via le troisi√®me composant - </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un communicateur externe</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En quoi consiste l'environnement d'apprentissage</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le volet formation comprend diff√©rents √©l√©ments: </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/hy/1u/pt/hy1upt9en2esnt-amk-iipklmn4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
le premier agent est l'acteur de la sc√®ne. </font><font style="vertical-align: inherit;">C'est lui que nous formerons en optimisant un composant appel√© ¬´cerveau¬ª, dans lequel il est enregistr√© quelles actions doivent √™tre effectu√©es dans chacun des √©tats possibles. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le troisi√®me √©l√©ment, l'Acad√©mie, g√®re les agents et leurs processus d√©cisionnels et traite les demandes de l'API Python. </font><font style="vertical-align: inherit;">Pour mieux comprendre son r√¥le, rappelons le processus RL. </font><font style="vertical-align: inherit;">Il peut √™tre repr√©sent√© comme un cycle qui fonctionne comme suit: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5y/ge/ef/5ygeefzasafou6bkwggdnaq7ows.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Supposons qu'un agent ait besoin d'apprendre √† jouer √† un jeu de plateforme. </font><font style="vertical-align: inherit;">Le processus RL dans ce cas ressemblera √† ceci:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'agent re√ßoit l'√©tat </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0</font></font></sub></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de l'environnement - ce sera la premi√®re image de notre jeu.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sur la base de l'√©tat </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0, l'</font></font></sub></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> agent ex√©cute l'action </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0</font></font></sub></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et se d√©cale vers la droite.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'environnement passe dans un nouvel √©tat </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></sub></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'agent re√ßoit </font><i><sub><font style="vertical-align: inherit;">une</font></sub></i><font style="vertical-align: inherit;"> r√©compense </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></sub></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour ne pas √™tre mort ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©compense positive</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> +1).</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ce cycle RL forme une s√©quence d'√©tat, d'action et de r√©compense. </font><font style="vertical-align: inherit;">L'objectif de l'agent est de maximiser la r√©compense totale attendue. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/qm/mr/ml/qmmrmlkz7urj8cywqpsg1ejajve.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainsi, Academy envoie des instructions aux agents et assure la synchronisation de leur ex√©cution, √† savoir:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Collection d'observations;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le choix de l'action conform√©ment aux instructions fix√©es;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ex√©cution de l'action;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©initialisez si le nombre d'√©tapes a √©t√© atteint ou si l'objectif a √©t√© atteint.</font></font></li>
</ul><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous apprenons √† l'agent √† sauter √† travers les murs</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant que nous savons comment fonctionnent les agents Unity, nous allons en former un √† sauter √† travers les murs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les mod√®les d√©j√† form√©s peuvent √©galement √™tre t√©l√©charg√©s sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Environnement d'apprentissage du saut de mur</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le but de cet environnement est d'apprendre √† l'agent √† se rendre √† la tuile verte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Prenons trois cas: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1. Il n'y a pas de murs, et notre agent n'a qu'√† se rendre sur le carreau. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/17a/8fd/da8/17a8fdda8bbe767f64a34d8d05fd9be9.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2. L'agent doit apprendre √† sauter pour atteindre la tuile verte. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/d2c/149/0d0/d2c1490d0b90c4fdefb8eb4922f446b2.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3. Le cas le plus difficile: le mur est trop haut pour que l'agent puisse sauter dessus, il doit donc d'abord sauter sur le bloc blanc. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/458/175/9b6/4581759b653a175597054fcf60a0050e.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous apprendrons √† l'agent deux sc√©narios de comportement en fonction de la hauteur du mur:</font></font><br>
<br>
<ul>
<li><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmallWallJump</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans les cas sans murs ou √† faible hauteur de mur;</font></font></li>
<li><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BigWallJump</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans le cas de hauts murs.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici √† quoi ressemblera le syst√®me de r√©compense: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rt/lo/hm/rtlohmnturcucyikrnhfsadztgi.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans nos observations, nous n'utilisons pas une trame r√©guli√®re, mais 14 reykast, chacun pouvant d√©tecter 4 objets possibles. </font><font style="vertical-align: inherit;">Dans ce cas, le reykast peut √™tre per√ßu comme des faisceaux laser qui peuvent d√©terminer s'ils traversent un objet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous utiliserons √©galement la position d'agent mondial dans notre programme. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/a06/0fc/fa2/a060fcfa26e80154ef988d76dc9b8f05.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quatre options sont possibles dans notre espace: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ni/g6/zs/nig6zskfzterisy_hskg3k-rsnk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'objectif est de r√©aliser une tuile verte </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">avec une r√©compense moyenne de 0,8</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alors, commen√ßons!</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tout d'abord, ouvrez le projet </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UnitySDK</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parmi les exemples, vous devez trouver et ouvrir la sc√®ne </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WallJump</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous pouvez le voir, il y a de nombreux agents sur sc√®ne, chacun provenant du m√™me pr√©fabriqu√©, et ils ont tous le m√™me ¬´cerveau¬ª. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bad/195/820/bad195820da3e5b2c74309e9f44e9935.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme dans le cas du Deep Reinforcement Learning classique, apr√®s avoir lanc√© plusieurs instances du jeu (par exemple, 128 environnements parall√®les), il ne nous reste plus qu'√† copier et coller les agents pour avoir des √©tats plus diff√©rents. Et puisque nous voulons former notre agent √† partir de z√©ro, nous devons d'abord retirer le ¬´cerveau¬ª de l'agent. Pour ce faire, acc√©dez au dossier prefabs et ouvrez Prefab.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, dans la hi√©rarchie Prefab, vous devez s√©lectionner l'agent et acc√©der aux param√®tres. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans les param√®tres de comportement, vous devez supprimer le mod√®le. Si nous avons plusieurs GPU √† notre disposition, vous pouvez utiliser le p√©riph√©rique d'inf√©rence du CPU comme GPU. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/d0d/bdb/6ec/d0dbdb6ec05655b6fecdf675d629d126.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le composant Wall Jump Agent, vous devez supprimer les cerveaux pour un bo√Ætier sans murs, ainsi que pour les murs bas et hauts. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/618/e81/c8c/618e81c8c3c0cb15ae5fbca791c33c8c.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s cela, vous pouvez commencer √† former votre agent √† partir de z√©ro. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour notre premi√®re formation, nous modifions simplement le nombre total d'√©tapes de formation pour deux sc√©narios de comportement: SmallWallJump et BigWallJump. Ainsi, nous pouvons atteindre l'objectif en seulement 300 000 √©tapes. Pour ce faire, dans </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">config / trainer config.yaml,</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> remplacez max_steps par 3e5 pour les cas SmallWallJump et BigWallJump.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/b80/bbb/1b2/b80bbb1b21f0f9e445fa8d2583c39d52.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour former notre agent, nous utiliserons </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PPO</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Proximal Policy Optimization). L'algorithme comprend l'accumulation d'exp√©rience dans l'interaction avec l'environnement et son utilisation pour mettre √† jour les politiques d√©cisionnelles. Apr√®s sa mise √† jour, les √©v√©nements pr√©c√©dents sont supprim√©s et la collecte de donn√©es suivante est d√©j√† effectu√©e selon les termes de la politique mise √† jour. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Donc, tout d'abord, en utilisant l'API Python, nous devons appeler un communicateur externe afin qu'il ordonne √† l'Acad√©mie de lancer des agents. Pour ce faire, ouvrez le terminal o√π se trouve ml-agents-master et saisissez-le: </font></font><br>
<br>
<code>mlagents-learn config/trainer_config.yaml ‚Äî run-id=‚ÄùWallJump_FirstTrain‚Äù ‚Äî train</code><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cette commande vous demandera de d√©marrer la sc√®ne Unity. Pour ce faire, appuyez sur ‚ñ∫ en haut de l'√©diteur. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/212/874/4fb/2128744fb143fec6308d95938e0383f7.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez regarder la formation de vos agents dans Tensorboard avec la commande suivante:</font></font><br>
<br>
<code>tensorboard ‚Äî logdir=summaries</code><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une fois la formation termin√©e, vous devez d√©placer les fichiers de mod√®le enregistr√©s contenus dans </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ml-agents-master / models vers UnitySDK / Assets / ML-Agents / examples / WallJump / TFModels</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Ensuite, ouvrez √† nouveau l'√©diteur Unity et s√©lectionnez la sc√®ne </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WallJump</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , o√π nous ouvrons l'objet </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WallJumpArea</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> termin√© </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s cela, s√©lectionnez l'agent et dans ses param√®tres de comportement, faites glisser le fichier </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmallWallJump.nn</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans l' </font><i><font style="vertical-align: inherit;">espace r√©serv√©</font></i><font style="vertical-align: inherit;"> au mod√®le. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/d0d/bdb/6ec/d0dbdb6ec05655b6fecdf675d629d126.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D√©placer √©galement:</font></font><br>
<br>
<ol>
<li><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmallWallJump.nn</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √† No Wall Brain Placeholder.</font></font></li>
<li><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmallWallJump.nn</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans l' </font><i><font style="vertical-align: inherit;">espace r√©serv√©</font></i><font style="vertical-align: inherit;"> au petit mur de cerveau.</font></font></li>
<li><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BigWallJump.nn</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √† No Wall Brain Placeholder.</font></font></li>
</ol><br>
<img src="https://habrastorage.org/getpro/habr/post_images/618/e81/c8c/618e81c8c3c0cb15ae5fbca791c33c8c.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s cela, appuyez sur le bouton ‚ñ∫ en haut de l'√©diteur et vous avez termin√©! </font><font style="vertical-align: inherit;">L'algorithme de configuration de la formation des agents est maintenant termin√©.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/9c6/5ad/bdb/9c65adbdbb38b939262c10e5ac728dde.gif" alt="image"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Temps d'exp√©rimentation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La meilleure fa√ßon d'apprendre est d'essayer constamment d'apporter quelque chose de nouveau. </font><font style="vertical-align: inherit;">Maintenant que nous avons d√©j√† obtenu de bons r√©sultats, nous allons essayer de poser quelques hypoth√®ses et de les tester.</font></font><br>
<br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©duire le coefficient d'actualisation √† 0,95</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous savons donc que:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Plus le gamma est grand, plus la remise est faible. </font><font style="vertical-align: inherit;">Autrement dit, l'agent est plus pr√©occup√© par les r√©compenses √† long terme.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En revanche, plus le gamma est petit, plus la remise est importante. </font><font style="vertical-align: inherit;">Dans ce cas, la priorit√© de l'agent est la r√©mun√©ration √† court terme.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'id√©e de cette exp√©rience est que si nous augmentons la remise en diminuant la gamme de 0,99 √† 0,95, la r√©compense √† court terme sera une priorit√© pour l'agent - ce qui peut l'aider √† aborder rapidement la politique de comportement optimale. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/u_/cm/hv/u_cmhvpc0dk-npolzz49loxofiq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fait int√©ressant, dans le cas d'un saut √† travers un muret, l'agent s'efforcera d'obtenir le m√™me r√©sultat. </font><font style="vertical-align: inherit;">Cela peut s'expliquer par le fait que ce cas est assez simple: l'agent n'a qu'√† se d√©placer vers la tuile verte et, si n√©cessaire, √† sauter s'il y a un mur devant. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yc/ic/tt/ycicttb0mkwxmwn5c1ghgm2iiiu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En revanche, dans le cas de Big Wall Jump, cela fonctionne moins bien, car notre agent se soucie plus de la r√©compense √† court terme et ne comprend donc pas qu'il doit grimper sur le bloc blanc pour sauter par-dessus le mur.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Augmentation de la complexit√© du r√©seau neuronal</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Enfin, nous √©mettons l'hypoth√®se que notre agent deviendra plus intelligent si nous augmentons la complexit√© du r√©seau neuronal. </font><font style="vertical-align: inherit;">Pour ce faire, augmentez la taille du niveau cach√© de 256 √† 512. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et nous constatons que dans ce cas le nouvel agent fonctionne moins bien que notre premier agent. </font><font style="vertical-align: inherit;">Cela signifie que cela n'a aucun sens pour nous d'augmenter la complexit√© de notre r√©seau, car sinon le temps d'apprentissage augmentera √©galement. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/zo/g7/qm/zog7qm1uemu7l7taqc5uuwlqauw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons donc form√© l'agent √† sauter par-dessus les murs, et c'est tout pour aujourd'hui. </font><font style="vertical-align: inherit;">Rappelons que pour comparer les r√©sultats, des mod√®les form√©s peuvent √™tre t√©l√©charg√©s </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ici</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/af6/f00/ce3/af6f00ce3784c60469522296276d2651.gif" alt="image"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr492530/index.html">Combiner les MVVM bas√©s dans les applications UIKit et SwiftUI pour les d√©veloppeurs UIKit</a></li>
<li><a href="../fr492534/index.html">Existe-t-il ou non de vrais ouragans √† Moscou? Nous analysons le cas du 13 mars 2020 en pleine poursuite</a></li>
<li><a href="../fr492538/index.html">Wrike TechClub: Infrastructure de livraison - processus et outils (DevOps + QAA). Articles en anglais</a></li>
<li><a href="../fr492540/index.html">Le jeu "Attendez un instant!" sur arduino</a></li>
<li><a href="../fr492546/index.html">V√©rification de la vuln√©rabilit√© de tout site utilisant Nikto</a></li>
<li><a href="../fr492552/index.html">Comment vivre et travailler en quarantaine √† Barcelone</a></li>
<li><a href="../fr492558/index.html">Bonjour, c'est COVID19: le coronavirus vit-il √† la surface d'un smartphone?</a></li>
<li><a href="../fr492560/index.html">Table de hachage simple pour GPU</a></li>
<li><a href="../fr492562/index.html">Trois webinaires Apache Ignite utiles dans votre programme de quarantaine</a></li>
<li><a href="../fr492566/index.html">Analyse de la combinaison d'un algorithme de recherche de clics gourmand avec √©num√©ration partielle des sommets des graphes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
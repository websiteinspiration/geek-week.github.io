<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëß „äôÔ∏è ‚úÇÔ∏è Die Forscher entwickeln einen Ansatz zur Verringerung der Verzerrung in Computer-Vision-Datens√§tzen üòÑ üë®üèæ‚Äçü§ù‚Äçüë®üèΩ üíÖüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine √úbersetzung des Artikels wurde speziell f√ºr Studenten des Computer Vision- Kurses erstellt . 
 
 14. Februar 2020 
 Princeton University, Departm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Die Forscher entwickeln einen Ansatz zur Verringerung der Verzerrung in Computer-Vision-Datens√§tzen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/498046/"><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine √úbersetzung des Artikels wurde speziell f√ºr Studenten des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Computer Vision-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kurses erstellt </font><font style="vertical-align: inherit;">. </font></font></i></b><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14. Februar 2020 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton University, Department of Engineering.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/7l/rc/oe/7lrcoe52n2bvvynvhjwhmhhprx4.png"><br>
<hr><br>
<blockquote><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zusammenfassung:</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Um die Probleme der Verzerrung in der k√ºnstlichen Intelligenz zu l√∂sen, haben Informatiker Methoden entwickelt, um zuverl√§ssigere Datens√§tze mit Bildern von Menschen zu erhalten. Forscher bieten Verbesserungen f√ºr ImageNet an, eine Datenbank mit mehr als 14 Millionen Bildern, die in den letzten zehn Jahren eine Schl√ºsselrolle bei der Entwicklung von Computer Vision gespielt hat.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ImageNet, das Bilder von Objekten, Landschaften und insbesondere von Menschen enth√§lt, dient als Quelle f√ºr Trainingsdaten f√ºr Forscher, die Algorithmen f√ºr maschinelles Lernen erstellen, die Bilder klassifizieren oder einzelne Elemente darauf erkennen. Die beispiellose Skalierung von ImageNet erforderte eine automatisierte Bilderfassung und -anmerkung mithilfe von Crowdsourcing. W√§hrend die Kategorie der Bilder von Personen aus der Datenbank von der Forschungsgemeinschaft selten verwendet wurde, arbeitete das ImageNet-Team daran, die Verzerrung und eine Reihe anderer Probleme im Zusammenhang mit Bildern von Personen zu beseitigen, die unbeabsichtigte Folgen des ImageNet-Designs sind.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Heute funktioniert Computer Vision gut genug, um √ºberall in einer Vielzahl von Kontexten implementiert zu werden", sagte Co-Autorin Olga Russakovskaya, Associate Professor f√ºr Informatik in Princeton. "Dies bedeutet, dass es jetzt an der Zeit ist, dar√ºber zu sprechen, wie sich dies auf die Welt auswirkt, und √ºber die Fragen der Glaubw√ºrdigkeit nachzudenken."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einem neuen Artikel identifizierte das ImageNet-Team systematisch nicht-visuelle Konzepte und anst√∂√üige Kategorien wie rassistische und sexuelle Merkmale f√ºr die menschlichen Bildkategorien von ImageNet und schlug vor, sie aus der Datenbank zu entfernen. Die Forscher haben auch ein Tool entwickelt, mit dem Benutzer Bilder von Personen identifizieren und abrufen k√∂nnen, die nach Alter, Geschlecht und Hautfarbe ausgewogen sind, um geeignete Algorithmen zur zuverl√§ssigeren Klassifizierung der Gesichter von Personen und ihrer Aktionen auf Bildern zu erm√∂glichen. Die Forscher pr√§sentierten ihre Arbeit am 30. Januar auf einer Konferenz √ºber die Richtigkeit, Zuverl√§ssigkeit und Transparenz der Computing Technology Association in Barcelona, ‚Äã‚ÄãSpanien.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄûEs ist sehr wichtig, die Aufmerksamkeit von Laboratorien und Forschern mit grundlegender technischer Erfahrung auf die Diskussion zu lenken‚Äú, f√§hrt Russakovskaya fort. ‚ÄûAngesichts der Tatsache, dass wir Daten in kolossalem Ma√üstab sammeln m√ºssen und dass dies durch Crowdsourcing realisiert wird (weil es die effizienteste und bew√§hrte Pipeline ist), stellt sich die Frage, wie wir dies tun, um das Beste sicherzustellen Zuverl√§ssigkeit ohne auf einen vertrauten Rechen zu treten? Dieser Artikel konzentriert sich haupts√§chlich auf Designl√∂sungen. ‚Äú</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Gruppe von Informatikern in Princeton und Stanford startete ImageNet 2009 als Ressource f√ºr Forscher und P√§dagogen. Die Princeton-Absolventin und Lehrerin Fay-Fay Lee, heute Professorin f√ºr Informatik an der Stanford University, leitete die Initiative. Um die Forscher zu ermutigen, mithilfe von ImageNet bessere Computer-Vision-Algorithmen zu erstellen, startete das Team au√üerdem die ImageNet Large Scale Visual Recognition Challenge. Der Wettbewerb konzentrierte sich haupts√§chlich auf die Erkennung von Objekten anhand von 1000 Bildkategorien, von denen nur drei Personen zeigten.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einige der Zuverl√§ssigkeitsprobleme in ImageNet sind auf die Pipeline zur√ºckzuf√ºhren, die zum Erstellen der Datenbank verwendet wurde. Die Bildkategorien stammen aus WordNet, einer alten Datenbank englischer W√∂rter, die f√ºr die Erforschung der Verarbeitung nat√ºrlicher Sprache verwendet werden. ImageNet-Ersteller haben Substantive aus WordNet ausgeliehen - von denen einige, obwohl sie gut definierte verbale Begriffe sind, schlecht in ein visuelles W√∂rterbuch √ºbersetzt werden. Beispielsweise k√∂nnen die Begriffe, die die Religion oder die geografische Herkunft einer Person beschreiben, nur die bekanntesten Bildsuchergebnisse extrahieren, was zu Algorithmen f√ºhren kann, die Stereotypen verst√§rken.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein k√ºrzlich durchgef√ºhrtes Kunstprojekt namens ImageNet Roulette hat auf diese Probleme aufmerksam gemacht. Das Projekt, das im September 2019 im Rahmen einer Kunstausstellung f√ºr Bilderkennungssysteme ver√∂ffentlicht wurde, verwendete die Bilder von Menschen aus ImageNet, um ein Modell der k√ºnstlichen Intelligenz zu trainieren, das Menschen anhand des pr√§sentierten Bildes mit Worten kategorisierte. Benutzer k√∂nnen ihr Bild hochladen und ein Tag erhalten, das auf diesem Modell basiert. Viele der Klassifikationen waren beleidigend oder einfach unbegr√ºndet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Hauptinnovation, die es ImageNet-Erstellern erm√∂glichte, eine so gro√üe Datenbank mit getaggten Bildern zu sammeln, war die Verwendung von Crowdsourcing, insbesondere der MTurk-Plattform (Amazon Mechanical Turk), bei der Mitarbeiter f√ºr die √úberpr√ºfung von Kandidatenbildern bezahlt wurden. Obwohl dieser Ansatz revolution√§r war, war er dennoch unvollkommen, was zu einigen voreingenommenen und unangemessenen Kategorien f√ºhrte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄûWenn Sie Leute bitten, Bilder zu √ºberpr√ºfen, indem Sie aus einer Vielzahl von Kandidaten ausw√§hlen, versp√ºren die Leute den Druck, etwas auszuw√§hlen, und diese Bilder weisen tendenziell charakteristische oder stereotype Merkmale auf‚Äú, sagt der Hauptautor Kayu Young, ein Absolvent der Informatik .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Verlauf der Studie haben Jan und seine Kollegen zun√§chst potenziell missbr√§uchliche oder sensible Personengruppen aus ImageNet herausgefiltert. Sie betrachteten die Kategorien als beleidigend, die Obsz√∂nit√§ten oder rassistische oder geschlechtsspezifische Beleidigungen enthielten. Zu den sensiblen Kategorien geh√∂rte beispielsweise die Klassifizierung von Personen nach sexueller Orientierung oder Religion. Um die Kategorien zu kommentieren, rekrutierten sie 12 Doktoranden aus verschiedenen Lebensbereichen und wiesen sie an, die Kategorie als sensibel zu markieren, wenn sie sich nicht sicher sind. Sie schlossen also 1593 Kategorien aus - etwa 54% der 2932 Kategorien von Personen in ImageNet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann wandten sich die Forscher an MTurk-Mitarbeiter, um Hilfe zu erhalten, sodass sie die ‚ÄûBilder‚Äú der verbleibenden akzeptablen Kategorien auf einer Skala von 1 bis 5 bewerteten. Die Auswahl von Kategorien mit einer Bildbewertung von 4 oder h√∂her f√ºhrte dazu, dass nur 158 Kategorien als akzeptabel und ausreichend figurativ eingestuft wurden. Selbst diese sorgf√§ltig gefilterten Kategorien enthielten mehr als 133.000 Bilder - eine Vielzahl von Beispielen f√ºr das Unterrichten von Computer-Vision-Algorithmen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Innerhalb dieser 158 Kategorien untersuchten die Forscher die demografische Repr√§sentation von Personen in Bildern, um den Grad der Verzerrung in ImageNet zu bewerten und einen Ansatz zur Erstellung geeigneterer Datens√§tze zu entwickeln. ImageNet-Inhalte stammen haupts√§chlich von bildbezogenen Suchmaschinen wie Flickr. Suchmaschinen liefern im Allgemeinen Ergebnisse, die deutlich mehr M√§nner, hellh√§utige Menschen und Erwachsene zwischen 18 und 40 Jahren repr√§sentieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄûDie Leute haben festgestellt, dass die Ergebnisse der Bildsuche in Bezug auf die demografische Verteilung stark voreingenommen sind, sodass ImageNet auch eine voreingenommene Verteilung aufweist‚Äú, sagt Young. "In diesem Artikel haben wir versucht, das Ausma√ü der Verzerrung zu bewerten und eine Methode vorzuschlagen, die die Verteilung ausgleicht."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Forscher haben drei Attribute identifiziert und √ºberpr√ºft, die durch die US-Antidiskriminierungsgesetze gesch√ºtzt sind: Hautfarbe, Geschlecht und Alter. MTurk-Mitarbeiter wurden gebeten, jedes Attribut jeder Person im Bild mit Anmerkungen zu versehen. Sie klassifizierten die Hautfarbe als hell, mittel oder dunkel; und nach Alter als Kinder (unter 18), Erwachsene zwischen 18 und 40 Jahren, Erwachsene zwischen 40 und 65 Jahren oder Erwachsene √ºber 65 Jahre. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Geschlechtsklassifizierung umfasste M√§nner, Frauen und unbestimmtes Geschlecht - eine M√∂glichkeit, Menschen mit unterschiedlichen Geschlechtsausdr√ºcken einzubeziehen sowie Bilder zu kommentieren, in denen das Geschlecht nicht durch visuelle Zeichen wahrgenommen werden kann (z. B. Bilder vieler Kinder oder Taucher).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Analyse der Anmerkungen ergab, dass der ImageNet-Inhalt wie in den Suchergebnissen eine signifikante Verzerrung widerspiegelt. Als schwarz gekennzeichnete Personen, Frauen und Erwachsene √ºber 40 waren in den meisten Kategorien unterrepr√§sentiert.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obwohl der Annotationsprozess eine Qualit√§tskontrolle beinhaltete und die Annotatoren einen Konsens erzielen mussten, entschieden sich die Forscher aufgrund der Besorgnis √ºber den m√∂glichen Schaden falscher Annotationen daf√ºr, keine demografischen Annotationen f√ºr einzelne Bilder herauszugeben. Stattdessen entwickelten sie ein webbasiertes Tool, mit dem Benutzer eine Reihe von Bildern abrufen k√∂nnen, die auf die vom Benutzer angegebene Weise demografisch ausgewogen sind. Beispielsweise kann eine vollst√§ndige Sammlung von Bildern in der Programmiererkategorie etwa 90% der M√§nner und 10% der Frauen umfassen, w√§hrend in den Vereinigten Staaten etwa 20% der Programmierer Frauen sind. Der Forscher kann das neue Tool verwenden, um eine Reihe von Bildern von Programmierern zu erhalten, die 80% der M√§nner und 20% der Frauen repr√§sentieren - oder sogar einzeln, je nach den Zielen des Forschers.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Wir m√∂chten nicht dar√ºber sprechen, wie Demografie ausgeglichen werden kann, da dies kein sehr einfaches Problem ist", sagt Young. ‚ÄûDie Verteilung kann in verschiedenen Teilen der Welt unterschiedlich sein. Beispielsweise unterscheidet sich die Verteilung der Hautfarben in den USA von der Verteilung in asiatischen L√§ndern. Daher √ºberlassen wir diese Frage unserem Benutzer und stellen lediglich ein Tool zum Extrahieren einer ausgewogenen Teilmenge von Bildern bereit. " </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das ImageNet-Team arbeitet derzeit an technischen Aktualisierungen seiner Ger√§te und der Datenbank selbst sowie an der Implementierung der Gesichtsfilterung und des in dieser Studie entwickelten Tools zum Neuausgleich. ImageNet wird in K√ºrze mit diesen Updates und einer Bitte um Feedback von der Community der Computer Vision-Forscher neu aufgelegt.</font></font><br>
 <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton Ph.D. Clint Kinami und Assistenzprofessor f√ºr Informatik, Jia Dang, gemeinsam mit Young, Lee und Russakovskaya verfasst </font><font style="vertical-align: inherit;">Die Studie wurde von der National Science Foundation unterst√ºtzt. </font></font><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font></b><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Materialien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vom </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Department of Engineering der Princeton University</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Original geschrieben von Molly Charlach. </font><font style="vertical-align: inherit;">P </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hinweis: Der Inhalt kann nach Stil und L√§nge ge√§ndert werden. </font></font></i><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Link:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Kaiyu Yang, Klint Qinami, Li Fei-Fei, Jia Deng und Olga Russakovsky. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf dem Weg zu faireren Datens√§tzen: Filtern und Ausgleichen der Verteilung des Personenunterbaums in der ImageNet-Hierarchie. </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Berichte der Konferenz 2020 √ºber Fairness, Rechenschaftspflicht und Transparenz, DOI 2020: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10.1145 / 3351095.3375709</font></font></a><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erfahren Sie mehr √ºber den Kurs</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de498032/index.html">Schnelle Berechnung von Formeln aus Excel in C #</a></li>
<li><a href="../de498034/index.html">Das moderne Flugzeug ist besser als Sie denken vor biologischen Bedrohungen (COVID-19) gesch√ºtzt</a></li>
<li><a href="../de498036/index.html">Mark Andriessen: Es ist Zeit f√ºr uns selbst zu schaffen (es ist Zeit zu bauen)</a></li>
<li><a href="../de498038/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 411 (13.-19. April 2020)</a></li>
<li><a href="../de498042/index.html">Analysieren, nicht validieren</a></li>
<li><a href="../de498050/index.html">Kultur als Grundlage f√ºr die j√§hrliche Skalierung des x2-Teams. √úber Einstellungsfehler und Kultur passen</a></li>
<li><a href="../de498052/index.html">Zabbix 5.0 oder Was ist neu mit Template Server von IPMI</a></li>
<li><a href="../de498054/index.html">Besiege den Dragon News Feed: Stelle sicher, dass du ein gutes Leben lebst</a></li>
<li><a href="../de498056/index.html">Digitale Veranstaltungen in Moskau vom 20. bis 26. April</a></li>
<li><a href="../de498060/index.html">PostgreSQL Industrial Tuning-Ansatz: Datenbankexperimente. Nikolay Samokhvalov</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
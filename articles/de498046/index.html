<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👧 ㊙️ ✂️ Die Forscher entwickeln einen Ansatz zur Verringerung der Verzerrung in Computer-Vision-Datensätzen 😄 👨🏾‍🤝‍👨🏽 💅🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine Übersetzung des Artikels wurde speziell für Studenten des Computer Vision- Kurses erstellt . 
 
 14. Februar 2020 
 Princeton University, Departm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Die Forscher entwickeln einen Ansatz zur Verringerung der Verzerrung in Computer-Vision-Datensätzen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/498046/"><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine Übersetzung des Artikels wurde speziell für Studenten des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Computer Vision-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kurses erstellt </font><font style="vertical-align: inherit;">. </font></font></i></b><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14. Februar 2020 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton University, Department of Engineering.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/7l/rc/oe/7lrcoe52n2bvvynvhjwhmhhprx4.png"><br>
<hr><br>
<blockquote><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zusammenfassung:</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Um die Probleme der Verzerrung in der künstlichen Intelligenz zu lösen, haben Informatiker Methoden entwickelt, um zuverlässigere Datensätze mit Bildern von Menschen zu erhalten. Forscher bieten Verbesserungen für ImageNet an, eine Datenbank mit mehr als 14 Millionen Bildern, die in den letzten zehn Jahren eine Schlüsselrolle bei der Entwicklung von Computer Vision gespielt hat.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ImageNet, das Bilder von Objekten, Landschaften und insbesondere von Menschen enthält, dient als Quelle für Trainingsdaten für Forscher, die Algorithmen für maschinelles Lernen erstellen, die Bilder klassifizieren oder einzelne Elemente darauf erkennen. Die beispiellose Skalierung von ImageNet erforderte eine automatisierte Bilderfassung und -anmerkung mithilfe von Crowdsourcing. Während die Kategorie der Bilder von Personen aus der Datenbank von der Forschungsgemeinschaft selten verwendet wurde, arbeitete das ImageNet-Team daran, die Verzerrung und eine Reihe anderer Probleme im Zusammenhang mit Bildern von Personen zu beseitigen, die unbeabsichtigte Folgen des ImageNet-Designs sind.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Heute funktioniert Computer Vision gut genug, um überall in einer Vielzahl von Kontexten implementiert zu werden", sagte Co-Autorin Olga Russakovskaya, Associate Professor für Informatik in Princeton. "Dies bedeutet, dass es jetzt an der Zeit ist, darüber zu sprechen, wie sich dies auf die Welt auswirkt, und über die Fragen der Glaubwürdigkeit nachzudenken."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einem neuen Artikel identifizierte das ImageNet-Team systematisch nicht-visuelle Konzepte und anstößige Kategorien wie rassistische und sexuelle Merkmale für die menschlichen Bildkategorien von ImageNet und schlug vor, sie aus der Datenbank zu entfernen. Die Forscher haben auch ein Tool entwickelt, mit dem Benutzer Bilder von Personen identifizieren und abrufen können, die nach Alter, Geschlecht und Hautfarbe ausgewogen sind, um geeignete Algorithmen zur zuverlässigeren Klassifizierung der Gesichter von Personen und ihrer Aktionen auf Bildern zu ermöglichen. Die Forscher präsentierten ihre Arbeit am 30. Januar auf einer Konferenz über die Richtigkeit, Zuverlässigkeit und Transparenz der Computing Technology Association in Barcelona, ​​Spanien.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
„Es ist sehr wichtig, die Aufmerksamkeit von Laboratorien und Forschern mit grundlegender technischer Erfahrung auf die Diskussion zu lenken“, fährt Russakovskaya fort. „Angesichts der Tatsache, dass wir Daten in kolossalem Maßstab sammeln müssen und dass dies durch Crowdsourcing realisiert wird (weil es die effizienteste und bewährte Pipeline ist), stellt sich die Frage, wie wir dies tun, um das Beste sicherzustellen Zuverlässigkeit ohne auf einen vertrauten Rechen zu treten? Dieser Artikel konzentriert sich hauptsächlich auf Designlösungen. “</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Gruppe von Informatikern in Princeton und Stanford startete ImageNet 2009 als Ressource für Forscher und Pädagogen. Die Princeton-Absolventin und Lehrerin Fay-Fay Lee, heute Professorin für Informatik an der Stanford University, leitete die Initiative. Um die Forscher zu ermutigen, mithilfe von ImageNet bessere Computer-Vision-Algorithmen zu erstellen, startete das Team außerdem die ImageNet Large Scale Visual Recognition Challenge. Der Wettbewerb konzentrierte sich hauptsächlich auf die Erkennung von Objekten anhand von 1000 Bildkategorien, von denen nur drei Personen zeigten.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einige der Zuverlässigkeitsprobleme in ImageNet sind auf die Pipeline zurückzuführen, die zum Erstellen der Datenbank verwendet wurde. Die Bildkategorien stammen aus WordNet, einer alten Datenbank englischer Wörter, die für die Erforschung der Verarbeitung natürlicher Sprache verwendet werden. ImageNet-Ersteller haben Substantive aus WordNet ausgeliehen - von denen einige, obwohl sie gut definierte verbale Begriffe sind, schlecht in ein visuelles Wörterbuch übersetzt werden. Beispielsweise können die Begriffe, die die Religion oder die geografische Herkunft einer Person beschreiben, nur die bekanntesten Bildsuchergebnisse extrahieren, was zu Algorithmen führen kann, die Stereotypen verstärken.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein kürzlich durchgeführtes Kunstprojekt namens ImageNet Roulette hat auf diese Probleme aufmerksam gemacht. Das Projekt, das im September 2019 im Rahmen einer Kunstausstellung für Bilderkennungssysteme veröffentlicht wurde, verwendete die Bilder von Menschen aus ImageNet, um ein Modell der künstlichen Intelligenz zu trainieren, das Menschen anhand des präsentierten Bildes mit Worten kategorisierte. Benutzer können ihr Bild hochladen und ein Tag erhalten, das auf diesem Modell basiert. Viele der Klassifikationen waren beleidigend oder einfach unbegründet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Hauptinnovation, die es ImageNet-Erstellern ermöglichte, eine so große Datenbank mit getaggten Bildern zu sammeln, war die Verwendung von Crowdsourcing, insbesondere der MTurk-Plattform (Amazon Mechanical Turk), bei der Mitarbeiter für die Überprüfung von Kandidatenbildern bezahlt wurden. Obwohl dieser Ansatz revolutionär war, war er dennoch unvollkommen, was zu einigen voreingenommenen und unangemessenen Kategorien führte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
„Wenn Sie Leute bitten, Bilder zu überprüfen, indem Sie aus einer Vielzahl von Kandidaten auswählen, verspüren die Leute den Druck, etwas auszuwählen, und diese Bilder weisen tendenziell charakteristische oder stereotype Merkmale auf“, sagt der Hauptautor Kayu Young, ein Absolvent der Informatik .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Verlauf der Studie haben Jan und seine Kollegen zunächst potenziell missbräuchliche oder sensible Personengruppen aus ImageNet herausgefiltert. Sie betrachteten die Kategorien als beleidigend, die Obszönitäten oder rassistische oder geschlechtsspezifische Beleidigungen enthielten. Zu den sensiblen Kategorien gehörte beispielsweise die Klassifizierung von Personen nach sexueller Orientierung oder Religion. Um die Kategorien zu kommentieren, rekrutierten sie 12 Doktoranden aus verschiedenen Lebensbereichen und wiesen sie an, die Kategorie als sensibel zu markieren, wenn sie sich nicht sicher sind. Sie schlossen also 1593 Kategorien aus - etwa 54% der 2932 Kategorien von Personen in ImageNet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann wandten sich die Forscher an MTurk-Mitarbeiter, um Hilfe zu erhalten, sodass sie die „Bilder“ der verbleibenden akzeptablen Kategorien auf einer Skala von 1 bis 5 bewerteten. Die Auswahl von Kategorien mit einer Bildbewertung von 4 oder höher führte dazu, dass nur 158 Kategorien als akzeptabel und ausreichend figurativ eingestuft wurden. Selbst diese sorgfältig gefilterten Kategorien enthielten mehr als 133.000 Bilder - eine Vielzahl von Beispielen für das Unterrichten von Computer-Vision-Algorithmen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Innerhalb dieser 158 Kategorien untersuchten die Forscher die demografische Repräsentation von Personen in Bildern, um den Grad der Verzerrung in ImageNet zu bewerten und einen Ansatz zur Erstellung geeigneterer Datensätze zu entwickeln. ImageNet-Inhalte stammen hauptsächlich von bildbezogenen Suchmaschinen wie Flickr. Suchmaschinen liefern im Allgemeinen Ergebnisse, die deutlich mehr Männer, hellhäutige Menschen und Erwachsene zwischen 18 und 40 Jahren repräsentieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
„Die Leute haben festgestellt, dass die Ergebnisse der Bildsuche in Bezug auf die demografische Verteilung stark voreingenommen sind, sodass ImageNet auch eine voreingenommene Verteilung aufweist“, sagt Young. "In diesem Artikel haben wir versucht, das Ausmaß der Verzerrung zu bewerten und eine Methode vorzuschlagen, die die Verteilung ausgleicht."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Forscher haben drei Attribute identifiziert und überprüft, die durch die US-Antidiskriminierungsgesetze geschützt sind: Hautfarbe, Geschlecht und Alter. MTurk-Mitarbeiter wurden gebeten, jedes Attribut jeder Person im Bild mit Anmerkungen zu versehen. Sie klassifizierten die Hautfarbe als hell, mittel oder dunkel; und nach Alter als Kinder (unter 18), Erwachsene zwischen 18 und 40 Jahren, Erwachsene zwischen 40 und 65 Jahren oder Erwachsene über 65 Jahre. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Geschlechtsklassifizierung umfasste Männer, Frauen und unbestimmtes Geschlecht - eine Möglichkeit, Menschen mit unterschiedlichen Geschlechtsausdrücken einzubeziehen sowie Bilder zu kommentieren, in denen das Geschlecht nicht durch visuelle Zeichen wahrgenommen werden kann (z. B. Bilder vieler Kinder oder Taucher).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Analyse der Anmerkungen ergab, dass der ImageNet-Inhalt wie in den Suchergebnissen eine signifikante Verzerrung widerspiegelt. Als schwarz gekennzeichnete Personen, Frauen und Erwachsene über 40 waren in den meisten Kategorien unterrepräsentiert.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obwohl der Annotationsprozess eine Qualitätskontrolle beinhaltete und die Annotatoren einen Konsens erzielen mussten, entschieden sich die Forscher aufgrund der Besorgnis über den möglichen Schaden falscher Annotationen dafür, keine demografischen Annotationen für einzelne Bilder herauszugeben. Stattdessen entwickelten sie ein webbasiertes Tool, mit dem Benutzer eine Reihe von Bildern abrufen können, die auf die vom Benutzer angegebene Weise demografisch ausgewogen sind. Beispielsweise kann eine vollständige Sammlung von Bildern in der Programmiererkategorie etwa 90% der Männer und 10% der Frauen umfassen, während in den Vereinigten Staaten etwa 20% der Programmierer Frauen sind. Der Forscher kann das neue Tool verwenden, um eine Reihe von Bildern von Programmierern zu erhalten, die 80% der Männer und 20% der Frauen repräsentieren - oder sogar einzeln, je nach den Zielen des Forschers.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Wir möchten nicht darüber sprechen, wie Demografie ausgeglichen werden kann, da dies kein sehr einfaches Problem ist", sagt Young. „Die Verteilung kann in verschiedenen Teilen der Welt unterschiedlich sein. Beispielsweise unterscheidet sich die Verteilung der Hautfarben in den USA von der Verteilung in asiatischen Ländern. Daher überlassen wir diese Frage unserem Benutzer und stellen lediglich ein Tool zum Extrahieren einer ausgewogenen Teilmenge von Bildern bereit. " </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das ImageNet-Team arbeitet derzeit an technischen Aktualisierungen seiner Geräte und der Datenbank selbst sowie an der Implementierung der Gesichtsfilterung und des in dieser Studie entwickelten Tools zum Neuausgleich. ImageNet wird in Kürze mit diesen Updates und einer Bitte um Feedback von der Community der Computer Vision-Forscher neu aufgelegt.</font></font><br>
 <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton Ph.D. Clint Kinami und Assistenzprofessor für Informatik, Jia Dang, gemeinsam mit Young, Lee und Russakovskaya verfasst </font><font style="vertical-align: inherit;">Die Studie wurde von der National Science Foundation unterstützt. </font></font><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle: </font></font></b><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Materialien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vom </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Department of Engineering der Princeton University</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Original geschrieben von Molly Charlach. </font><font style="vertical-align: inherit;">P </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hinweis: Der Inhalt kann nach Stil und Länge geändert werden. </font></font></i><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Link:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Kaiyu Yang, Klint Qinami, Li Fei-Fei, Jia Deng und Olga Russakovsky. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf dem Weg zu faireren Datensätzen: Filtern und Ausgleichen der Verteilung des Personenunterbaums in der ImageNet-Hierarchie. </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Berichte der Konferenz 2020 über Fairness, Rechenschaftspflicht und Transparenz, DOI 2020: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10.1145 / 3351095.3375709</font></font></a><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erfahren Sie mehr über den Kurs</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de498032/index.html">Schnelle Berechnung von Formeln aus Excel in C #</a></li>
<li><a href="../de498034/index.html">Das moderne Flugzeug ist besser als Sie denken vor biologischen Bedrohungen (COVID-19) geschützt</a></li>
<li><a href="../de498036/index.html">Mark Andriessen: Es ist Zeit für uns selbst zu schaffen (es ist Zeit zu bauen)</a></li>
<li><a href="../de498038/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends für die letzte Woche Nr. 411 (13.-19. April 2020)</a></li>
<li><a href="../de498042/index.html">Analysieren, nicht validieren</a></li>
<li><a href="../de498050/index.html">Kultur als Grundlage für die jährliche Skalierung des x2-Teams. Über Einstellungsfehler und Kultur passen</a></li>
<li><a href="../de498052/index.html">Zabbix 5.0 oder Was ist neu mit Template Server von IPMI</a></li>
<li><a href="../de498054/index.html">Besiege den Dragon News Feed: Stelle sicher, dass du ein gutes Leben lebst</a></li>
<li><a href="../de498056/index.html">Digitale Veranstaltungen in Moskau vom 20. bis 26. April</a></li>
<li><a href="../de498060/index.html">PostgreSQL Industrial Tuning-Ansatz: Datenbankexperimente. Nikolay Samokhvalov</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
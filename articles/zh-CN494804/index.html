<!doctype html>
<html class="no-js" lang="zh-CN">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🍳 🙆🏾 🐫 使用Tensorflow对象检测API，“很抱歉，我识别出...”或识别树莓和控制器 🗻 🛣️ 🕝</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="去年年底，我写了一篇文章，讲述了我对使用神经网络识别图像中对象的能力所着迷。在那篇文章中，我们使用PyTorch对视频中的树莓派或类似arduino的控制器进行了分类。尽管事实上我喜欢PyTorch，但我还是向他求助，因为我无法立即处理TensorFlow。但是我保证我会回到视频中物体识别的问题。似...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>使用Tensorflow对象检测API，“很抱歉，我识别出...”或识别树莓和控制器</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/494804/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">去年年底，我写</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">了一篇文章，</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">讲述了我对使用神经网络识别图像中对象的能力所着迷。在那篇文章中，我们使用PyTorch对视频中的树莓派或类似arduino的控制器进行了分类。尽管事实上我喜欢PyTorch，但我还是向他求助，因为我无法立即处理TensorFlow。但是我保证我会回到视频中物体识别的问题。似乎是时候兑现了诺言。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在本文中，我们将尝试在本地计算机上重新训练Tensorflow 1.13中的成品模型和对象检测API（在我们自己的图像集上），然后使用它来识别使用OpenCV的网络摄像机视频流中的浆果和控制器。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
是否想在夏天之前提高您的浆果识别能力？</font><font style="vertical-align: inherit;">那么，您将受到猫的欢迎。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fu/do/rd/fudordve5xz-8gwdnbvlnkkjusm.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
内容：</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第一部分：简介</font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第二部分：在TenosrFlow中训练模型第三</font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">部分：在OpenCV中应用模型</font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第四部分：结论</font></font></a><br>
<a name="I"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第一部分：简介</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
那些已经阅读过有关PyTorch的文章的人已经知道，我是神经网络方面的业余爱好者。因此，不要将本文视为最终真理。但是无论如何，我希望我可以使用Tensorflow Object Detection API帮助某人处理视频识别的基础知识。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这次我没有尝试制作教程，因此这篇文章将比平时短。</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
首先，</font><font style="vertical-align: inherit;">温和地说，有关在本地计算机上使用对象检测API </font><font style="vertical-align: inherit;">的</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">官方教程</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">并不详尽。作为一个新手，我完全不够用，只能专注于博客文章。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
老实说，我想尝试TensorFlow 2.0，但是在大多数出版物中，在撰写本文时，迁移问题尚未完全解决。</font><font style="vertical-align: inherit;">因此，最后，我选择了TF 1.13.2。</font></font><br>
<a name="II"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第二部分：在TensorFlow上讲授模型 </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">从本文开始</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，或者从上半年开始</font><font style="vertical-align: inherit;">讲授有关模型的指导</font><font style="vertical-align: inherit;">，直到应用JavaScript为止</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（如果您不会说英语，则可以</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在Habré中</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">看到有关同一主题的文章</font><font style="vertical-align: inherit;">）</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
的确，就我而言，有几个区别：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我之所以使用Linux，是因为Linux的Anaconda已经构建了protobuf和pycocoapi，因此我不必自己构建它们。</font></font></li>
<li>   TensorFlow 1.13.2,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">Object Detection API 1.13</a> ,       TensorFlow 1.13.2.   master        TF 1.15,         1.13.</li>
<li>      numpy — 1.17.5,  1.18    .</li>
<li>  faster_rcnn_inception_v2_coco    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow">ssd_mobilenet_v2_coco</a>,    ,     .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 以防万一，我会说我没有使用图形加速器。培训仅针对处理器能力进行。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
可以像往常一样从</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">下载一组图像，一个配置文件，一个保存的图形以及使用OpenCV识别图像的脚本</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
经过长达23小时的模型培训，屋子里所有的茶都已经喝完了，“什么？哪里？什么时候？”检查，现在我的耐心终于结束了。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我们停止训练并保存模型。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
使用以下命令在与“ Anaconda”相同的环境中安装OpenCV：</font></font><br>
<br>
<pre><code class="plaintext hljs">conda install -c conda-forge opencv</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我最终安装了4.2版，</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
此外，</font><font style="vertical-align: inherit;">我们将不再需要</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">本文中</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的说明</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
保存模型后，我犯了一个对我来说并不明显的错误，即，我立即尝试替换先前在Training /文件夹中使用的graph.pbtxt文件的功能：</font></font><br>
<br>
<pre><code class="python hljs">cv2.dnn.readNetFromTensorflow()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
不幸的是，这种方式无法正常工作，我们将不得不再做一次操作来获取针对OpenCV的graph.pbtxt。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我现在建议的事实很可能不是一个很好的方法，但对我来说却有效。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
下载</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_ssd.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，还将</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_common.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">放入我们保存的图形所在的文件夹中（我有这个inference_graph文件夹）。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
然后转到该文件夹​​中的控制台，并从中执行大约以下内容的命令：</font></font><br>
<br>
<pre><code class="plaintext hljs">python tf_text_graph_ssd.py --input frozen_inference_graph.pb --config pipeline.config --output graph.pbtxt</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这就是将模型上传到OpenCV所要做的一切。</font></font><br>
<br>
<a name="III"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">第三部分：在OpenCV中应用模型 </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
就像在有关PyTorch与OpenCV的工作有关的文章中一样，我</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">以此出版物</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的程序代码为基础</font><font style="vertical-align: inherit;">。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我做了一些小的改动以简化它，但是由于我不完全理解代码，因此我不会对此发表评论。</font><font style="vertical-align: inherit;">效果很好。</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">很明显，代码可以做得更好，但是我还没有时间坐下来学习OpenCV教程</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV代码</font></font></b>
                        <div class="spoiler_text"><pre><code class="python hljs">
<span class="hljs-comment"># USAGE</span>
<span class="hljs-comment"># based on this code https://proglib.io/p/real-time-object-detection/</span>
<span class="hljs-comment"># import the necessary packages</span>
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> VideoStream
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> FPS
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> imutils
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> cv2<font></font>
<font></font>
prototxt=<span class="hljs-string">"graph.pbtxt"</span>
model=<span class="hljs-string">"frozen_inference_graph.pb"</span>
min_confidence = <span class="hljs-number">0.5</span><font></font>
<font></font>
<span class="hljs-comment"># initialize the list of class labels MobileNet SSD was trained to</span>
<span class="hljs-comment"># detect, then generate a set of bounding box colors for each class</span>
CLASSES = [<span class="hljs-string">"background"</span>, <span class="hljs-string">"duino"</span>,<span class="hljs-string">"raspb"</span>]<font></font>
COLORS = [(<span class="hljs-number">40</span>,<span class="hljs-number">50</span>,<span class="hljs-number">60</span>),((<span class="hljs-number">140</span>,<span class="hljs-number">55</span>,<span class="hljs-number">130</span>)),(<span class="hljs-number">240</span>,<span class="hljs-number">150</span>,<span class="hljs-number">25</span>)]<font></font>
<font></font>
<span class="hljs-comment"># load our serialized model from disk</span>
print(<span class="hljs-string">"[INFO] loading model..."</span>)<font></font>
<font></font>
net =cv2.dnn.readNetFromTensorflow(model,prototxt)<font></font>
<font></font>
<span class="hljs-comment"># initialize the video stream, allow the cammera sensor to warmup,</span>
<span class="hljs-comment"># and initialize the FPS counter</span>
print(<span class="hljs-string">"[INFO] starting video stream..."</span>)<font></font>
vs = VideoStream(src=<span class="hljs-number">0</span>).start()<font></font>
time.sleep(<span class="hljs-number">0.5</span>)<font></font>
fps = FPS().start()<font></font>
<font></font>
<span class="hljs-comment"># loop over the frames from the video stream</span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
	<span class="hljs-comment"># grab the frame from the threaded video stream and resize it</span>
	<span class="hljs-comment"># to have a maximum width of 400 pixels</span><font></font>
	frame = vs.read()<font></font>
	frame = imutils.resize(frame, width=<span class="hljs-number">300</span>)<font></font>
<font></font>
	<span class="hljs-comment"># grab the frame dimensions and convert it to a blob</span>
	(h, w) = frame.shape[:<span class="hljs-number">2</span>]<font></font>
	blob = cv2.dnn.blobFromImage(frame, size=(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>), swapRB=<span class="hljs-literal">True</span>)<font></font>
<font></font>
	<span class="hljs-comment"># pass the blob through the network and obtain the detections and</span>
	<span class="hljs-comment"># predictions</span><font></font>
	net.setInput(blob)<font></font>
	detections = net.forward()<font></font>
<font></font>
	<span class="hljs-comment"># loop over the detections</span>
	<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.arange(<span class="hljs-number">0</span>, detections.shape[<span class="hljs-number">2</span>]):
		<span class="hljs-comment"># extract the confidence (i.e., probability) associated with</span>
		<span class="hljs-comment"># the prediction</span>
		<span class="hljs-keyword">print</span> (detections)<font></font>
		confidence = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">2</span>]<font></font>
<font></font>
		<span class="hljs-keyword">if</span> confidence &gt; min_confidence:
			<span class="hljs-comment"># extract the index of the class label from the</span>
			<span class="hljs-comment"># `detections`, then compute the (x, y)-coordinates of</span>
			<span class="hljs-comment"># the bounding box for the object</span>
			idx = int(detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">1</span>])<font></font>
			box = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">3</span>:<span class="hljs-number">7</span>] * np.array([w, h, w, h])<font></font>
			(startX, startY, endX, endY) = box.astype(<span class="hljs-string">"int"</span>)<font></font>
<font></font>
			<span class="hljs-comment"># draw the prediction on the frame</span>
			label = <span class="hljs-string">"{}: {:.2f}%"</span>.format(CLASSES[idx],<font></font>
				confidence * <span class="hljs-number">100</span>)<font></font>
			cv2.rectangle(frame, (startX, startY), (endX, endY),<font></font>
				COLORS[idx], <span class="hljs-number">2</span>)<font></font>
			y = startY - <span class="hljs-number">15</span> <span class="hljs-keyword">if</span> startY - <span class="hljs-number">15</span> &gt; <span class="hljs-number">15</span> <span class="hljs-keyword">else</span> startY + <span class="hljs-number">15</span>
			cv2.putText(frame, label, (startX, y+<span class="hljs-number">3</span>),<font></font>
				cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, COLORS[idx], <span class="hljs-number">1</span>)<font></font>
<font></font>
	<span class="hljs-comment"># show the output frame</span>
	cv2.imshow(<span class="hljs-string">"Frame"</span>, frame)<font></font>
	key = cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span><font></font>
<font></font>
	<span class="hljs-comment"># if the `q` key was pressed, break from the loop</span>
	<span class="hljs-keyword">if</span> key == ord(<span class="hljs-string">"q"</span>):
		<span class="hljs-keyword">break</span><font></font>
<font></font>
	<span class="hljs-comment"># update the FPS counter</span><font></font>
	fps.update()<font></font>
<font></font>
<span class="hljs-comment"># stop the timer and display FPS information</span><font></font>
fps.stop()<font></font>
print(<span class="hljs-string">"[INFO] elapsed time: {:.2f}"</span>.format(fps.elapsed()))<font></font>
print(<span class="hljs-string">"[INFO] approx. FPS: {:.2f}"</span>.format(fps.fps()))<font></font>
<font></font>
<span class="hljs-comment"># do a bit of cleanup</span><font></font>
cv2.destroyAllWindows()<font></font>
vs.stop()<font></font>
</code></pre><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一切准备就绪。我们启动模型，将镜头对准我的旧CraftDuino并享受结果：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bw/hj/yd/bwhjyd9pddoeop9yaz7fxbqozzo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
乍一看，这虽然不错，但乍一看。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
看起来在23小时内，模型已经过重新训练，因此在定义对象时会出现严重错误。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这是一个视觉演示：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1w/3y/gf/1w3ygfo-ufytpuyct1kaarpsgls.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
如您所见，不仅模型是刀，甚至是黑色背景，该模型都将其定义为类似于arduino的控制器。也许这是因为在训练数据中，Arduino及其类似物上有深色图片，模型在23小时内成功达到碰撞。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
结果，我不得不将计算机再加载8个小时并训练一个新模型。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
她的情况要好得多。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这是CraftDuino的示例：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_c/8m/62/_c8m62y2q6as-l8sun5ah5ivppk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
没有活树莓。</font><font style="vertical-align: inherit;">我不得不打印图片。</font><font style="vertical-align: inherit;">在电话或显示器的屏幕上，您也可以识别，但是从纸上看，它更方便。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/63/_k/ou/63_koujmchte7jor0ulqzxcvgcs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
让我们检查一下模型如何识别Arduino nano，它会在适当的时候</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">德祖格里克</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">对我来说，我用传感器焊接到大型设备中：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ub/33/61/ub3361ozwkiwvl2sosx6yldvsou.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
如您所见，它可以很好地识别，但是角度很差，在温暖的灯光下，它可以识别一些碎片，例如覆盆子。但是实际上，有错误的镜框很难抓住镜头。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
现在，让我们检查一下她是如何对那些未经训练的对象进行分类的。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
同样，有一个带有刀和黑色背景的示例：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/io/ja/6a/ioja6aexferclondu4228nsr06y.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这次一切都按预期进行。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我们将提供模型来识别我在</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">上一篇文章中</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">写到的Canny 3微型控制器</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/xp/ay/14/xpay14o7clhp1y1twu4vyltiay4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
由于我们的模型除了覆盆子和类似arduino的控制器之外什么都不知道，因此可以说该模型非常成功地识别了Canny控制器。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
诚然，就像Arduino nano一样，很大程度上取决于角度和照明。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在白炽灯的暖光和不成功的角度下，控制器不仅可能被识别，甚至被定义为覆盆子。</font><font style="vertical-align: inherit;">诚然，像过去一样，这些角度仍然必须设法抓住镜头。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/01/ut/h_/01uth_-raiwnzasg7ypn-aoxezs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
好吧，最后一种情况是有关</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyTorch中图像分类</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的文章的一种</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">讽刺</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">与上次一样，Raspberry Pi 2单板计算机及其徽标在一帧内兼容。</font><font style="vertical-align: inherit;">与前一篇文章不同，在这篇文章中我们解决了分类问题并为图像选择了一个最可能的对象，在这种情况下，徽标和Raspberry本身都被识别。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vx/fv/us/vxfvusfgitn6vk1pe6o4rvoen9i.png"><br>
<br>
<a name="IV"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 第四部分：结论 </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
总而言之，我想说的是，尽管这个使用Tensorflow Object Detection API的小例子没有经验，但它花了几天的时间和星期一的一部分时间，我对此并不感到遗憾。当至少对如何使用它有了一点了解时，所有这些都变得非常好奇。在学习过程中，您开始将模型视为活生生的模型，跟随其成功和失败。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
因此，我建议所有不熟悉这一天的人尝试并认识自己的东西。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
而且，由于它在不断增加，您甚至不需要购买真正的网络摄像头。事实是，在撰写本文的过程中，我设法破坏了我的网络摄像头（打破了焦点机制），并且已经认为我必须放弃一切。但是事实证明，借助Droidcam，您可以使用智能手机代替网络摄像头（不计入广告费用）。而且，事实证明，其拍摄质量比损坏的相机要好得多，这极大地影响了图像中物体的识别质量。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
顺便说一下，由于Anaconda具有正常的</font><b><font style="vertical-align: inherit;">pycocotools</font></b><font style="vertical-align: inherit;">构建</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我发现它仅适用于Linux，而且我懒得在操作系统之间进行切换，因此我仅使用开放源代码软件来准备整篇文章。</font><font style="vertical-align: inherit;">有Word和Photoshop的类似物，甚至还有打印机的驱动程序。</font><font style="vertical-align: inherit;">这是我生命中的第一次。</font><font style="vertical-align: inherit;">事实证明，即使对于已经使用Microsoft操作系统超过25年的人来说，现代版本的Linux OS和应用程序也可以非常方便。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS如果有人知道如何正确运行</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tensorflow版本2及更高版本</font><font style="vertical-align: inherit;">的对象检测API </font><font style="vertical-align: inherit;">，请在PM或评论中退订。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
祝您有美好的一天，身体健康！</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN488468/index.html">引入FastAPI</a></li>
<li><a href="../zh-CN488470/index.html">Kim Dotcom：抓住了，网上最通缉的人。第4部分</a></li>
<li><a href="../zh-CN488472/index.html">周末阅读：10种有关音频工具的材料-从苏联汽车收音机到消除噪音的插头</a></li>
<li><a href="../zh-CN488474/index.html">关于色彩，声音和“人群探索”作为一种单独的美丽</a></li>
<li><a href="../zh-CN494800/index.html">中文USB IR收发器协议的逆向工程</a></li>
<li><a href="../zh-CN494806/index.html">2020年网络目标为2020年趋势-黑客改变了重点</a></li>
<li><a href="../zh-CN494808/index.html">产品分析师：它的作用是什么，它能产生多少，企业能带来什么好处</a></li>
<li><a href="../zh-CN494810/index.html">3D简介：Three.js基础</a></li>
<li><a href="../zh-CN494814/index.html">Slurm有用吗？</a></li>
<li><a href="../zh-CN494818/index.html">如何选择交易终端在交易所工作</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
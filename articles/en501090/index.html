<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐫 ❔ 👩🏽‍🤝‍👩🏻 K8S Multicluster Journey 🖖🏾 🐲 🚊</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, Habr! 
 
 We represent the Exness platform team. Earlier, our colleagues have already written an article about Production-ready images for k8s ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>K8S Multicluster Journey</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/exness/blog/501090/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hello, Habr! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We represent the Exness platform team. </font><font style="vertical-align: inherit;">Earlier, our colleagues have already written an article about </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Production-ready images for k8s</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Today we want to share the experience of service migration in Kubernetes.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_w/_v/4y/_w_v4y4cimb9xplp-da3e-cnwx4.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To begin with, we offer you some numbers for a better understanding of what will be discussed:</font></font><br>
<br>
<ul>
<li>    100+ ,    10      QA, DevOps  Scrum.   — Python, PHP, C++, Java  Golang.&nbsp;<br>
</li>
<li>    —  2000   .     Rancher v1.6      VMware.&nbsp;<br>
</li>
</ul><br>
<h4></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As they say, nothing lasts forever, and Rancher has long enough announced the termination of support for version 1.6. </font><font style="vertical-align: inherit;">Yes, for more than three years we have learned how to cook it and solve problems that arise, but more and more often we are faced with problems that will never be fixed. </font><font style="vertical-align: inherit;">Rancher 1.6 also has a ossified system for issuing rights, where you can either do almost everything or nothing. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Own virtualization, although it provided greater control over data storage and security, but imposed operational costs, which were difficult to put up with the constant growth of the company, the number of projects and requirements for them. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We wanted to follow IaC standards and, if necessary, get power quickly, in any geographical location and without vendor lock, and also be able to quickly abandon them.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">First steps</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First of all, we wanted to rely on modern technologies and solutions that would allow teams to have a faster development cycle and minimize operating costs for interaction with a platform that provides power.&nbsp; </font></font><br>
&nbsp;<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, the first thing that came to our mind was Kubernetes, but we did not get excited and did a little research on the subject of the right choice. We evaluated only opensource solutions, and Kubernetes unconditionally defeated in an unfair battle.&nbsp;&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next came the question of choosing a tool for creating clusters. We compared the most popular solutions: kops, kubespray, kubeadm. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To start, kubeadm seemed to us too complicated way, rather, a kind of inventor of the "bicycle", and kops lacked flexibility. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And the winner came out:</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/35e/1e6/e85/35e1e6e85e12e982649fd020862463cd.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We started to experiment on our own virtualization and AWS, trying to recreate an approximate likeness of our previous resource management pattern, where everyone uses the same “cluster”. </font><font style="vertical-align: inherit;">And now we have the first cluster of 10 small virtual machines, a couple of which are in AWS. </font><font style="vertical-align: inherit;">We started trying to migrate teams there, everything seemed to be “good”, and the story could be finished, but ...</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">First problems</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ansible is what kubespray is built on, it’s not the tool that allows IaC to be followed: something went wrong during the input / output of the nodes, and some intervention was required, and when using different OSs, the playbook behaved in different ways. With the growing number of commands and nodes in the cluster, we began to notice that the playbook took longer and longer, in the end, our record was 3.5 hours, and yours? :) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And it seems like kubespray is just Ansible, and everything is clear at first glance, but: </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/11e/593/7d7/11e5937d7576851ad38e8469502e6d7f.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the beginning of the journey there was a task to run capacities only in AWS and virtualization, but then, as often happens, the requirements changed.</font></font><br>
&nbsp;<br>
<img src="https://habrastorage.org/getpro/habr/post_images/e4f/b1b/f10/e4fb1bf10754dc4ea192c0a05d2e524c.png"><img src="https://habrastorage.org/getpro/habr/post_images/e1d/eeb/7d5/e1deeb7d5c4b2392962fbe5b6a528388.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In light of this, it became clear that our old pattern of combining resources into one orchestration system was not suitable - in the case when the clusters are far removed and are managed by different providers.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Further more. When all the teams work within the same cluster, various services with NodeSelector installed incorrectly could fly to the “alien” host of another team and utilize resources there, and in the case of setting taint, there were constant calls that this or that service was not working, not distributed correctly due to human factor. Another problem was the calculation of cost, especially given the problems in the distribution of services by nodes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A separate story was the issue of rights to employees: each team wanted to be “at the head” of the cluster and fully manage it, which could cause a complete collapse, since the teams are basically independent of each other.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">How to be</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Given the above and the wishes of the teams to be more independent, we made a simple conclusion: one team - one cluster.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So we got a second one: </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/5ca/125/895/5ca125895d8571f18c41034f226c65d5.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And then a third cluster:&nbsp; </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/81b/7a9/f75/81b7a9f755d7be0798ec641ef8d444ae.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then we started thinking: let's say, in a year our teams will have more than one cluster? In different geographical areas, for example, or under the control of different providers? And some of them will want to be able to quickly deploy a temporary cluster for any tests.&nbsp; </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/265/52e/0a5/26552e0a5bb71a6f82b3dd4f3226b768.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Would come full Kubernetes! This is some kind of MultiKubernetes, it turns out.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the same time, we all will need to somehow support all of these clusters, be able to easily control access to them, as well as create new ones and decommission old ones without manual intervention.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since the beginning of our journey in the world of Kubernetes, some time has passed, and we decided to re-examine the available solutions. It turned out that it already exists on the market - Rancher 2.2. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/9a2/c00/e81/9a2c00e81c4d2a0daf2b6f0a7afe8c0a.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the first stage of our research, Rancher Labs already made the first release of version 2, but although it could be raised very quickly by running the container without external dependencies with a couple of parameters or using the official HELM Chart, it seemed crude to us, and we did not know if rely on this decision, whether it will be developed or quickly abandoned. The cluster = clicks paradigm itself in the UI also did not suit us, and we did not want to get attached to RKE, since this is a fairly narrow-minded tool.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Rancher 2.2 version already had a more efficient look and, along with the previous ones, had a bunch of interesting features out of the box, such as integration with many external providers, a single point of distribution of rights and kubeconfig files, launching a kubectl image with your rights in UI, nested namespaces aka projects.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A community has already formed around Rancher 2, and the HashiCorp Terraform provider was created to manage it, which helped us put everything together.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What happened</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, we got one small cluster in which Rancher is launched, accessible to all other clusters, as well as many clusters associated with it, access to any of which can be issued as simply as adding a user to the ldap directory, regardless of where he is is located and the resources of which provider uses.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Using gitlab-ci and Terraform, a system was created that allows you to create a cluster of any configuration in cloud providers or our own infrastructure and connect them to Rancher. All this is done in IaC style, where each cluster is described by a repository, and its state is versioned. In this case, most modules are connected from external repositories so that it remains only to transfer variables or describe their custom configuration for instances, which helps to reduce the percentage of code repeatability. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/eae/814/877/eae814877be3c3a957b6f75a2c657f58.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, our journey is far from over and there are still many interesting tasks ahead, such as a single point of work with the logs and metrics of any clusters, service mesh, gitops for managing loads in a multicluster, and much more. We hope you will be interested in our experience!&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The article was written by A. Antipov, A. Ganush, Platform Engineers.&nbsp;</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en500312/index.html">Writing a JavaScript note taking application</a></li>
<li><a href="../en500314/index.html">PHP Digest No. 179 (April 21 - May 4, 2020)</a></li>
<li><a href="../en500316/index.html">New version of Apple & Google Contact Tracing Protocol</a></li>
<li><a href="../en500318/index.html">HP Elite Dragonfly - what kind of Athena laptop are you?</a></li>
<li><a href="../en500320/index.html">Own game engines: a little research</a></li>
<li><a href="../en501092/index.html">About the search for promising June and "udalenka". Redmadrobot Technical Support Manager Experience</a></li>
<li><a href="../en501098/index.html">SmartLi Smart Battery Solutions for Modular UPS</a></li>
<li><a href="../en501106/index.html">The simplest English word simulator using Python and Balabolka</a></li>
<li><a href="../en501108/index.html">Nvidia Streaming Multiprocessor History</a></li>
<li><a href="../en501110/index.html">Mobius and WWDC: more fun together</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚯 📟 👨🏿 Entendendo o modelo de aprendizado de máquina que quebra o CAPTCHA 👨🏻‍🎤 👨‍👧 😥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Olá a todos! Este mês, a OTUS está recrutando um novo grupo no curso Machine Learning . De acordo com a tradição estabelecida, na véspera do início do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Entendendo o modelo de aprendizado de máquina que quebra o CAPTCHA</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/486938/"><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Olá a todos! </font><font style="vertical-align: inherit;">Este mês, a OTUS está recrutando um novo grupo no curso </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Machine Learning</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">De acordo com a tradição estabelecida, na véspera do início do curso, estamos compartilhando com você a tradução de material interessante sobre o tema.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/cp/sm/jx/cpsmjxfi8zhhkhj2hdrbew0i66u.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A visão computacional é um dos tópicos mais relevantes e pesquisados ​​da IA ​​[1], no entanto, os métodos atuais para resolver problemas usando redes neurais convolucionais são seriamente criticados porque essas redes são fáceis de enganar. Para não ser infundado, vou falar sobre várias razões: redes desse tipo fornecem um resultado incorreto com alta confiança para imagens que ocorrem naturalmente que não contêm sinais estatísticos [2], nas quais as redes neurais convolucionais se baseiam, para imagens que foram classificadas corretamente corretamente, mas em que um pixel [3] ou imagens com objetos físicos foram adicionados à cena, mas não precisaram alterar o resultado da classificação [4] alterado. O fato é que, se queremos criar máquinas verdadeiramente inteligentes,deveria nos parecer razoável investir no estudo de novas idéias.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma dessas novas idéias é a aplicação da Vicarious da Rede Cortical Recursiva (RCN), que se inspira na neurociência. </font><font style="vertical-align: inherit;">Este modelo alegou ser extremamente eficaz em quebrar o captcha de texto, causando </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">muita conversa em</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> torno de si </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Por isso, decidi escrever vários artigos, cada um dos quais explica um certo aspecto deste modelo. </font><font style="vertical-align: inherit;">Neste artigo, falaremos sobre sua estrutura e como é gerada a geração de imagens apresentadas nos materiais do artigo principal da RCN [5].</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este artigo pressupõe que você já esteja familiarizado com redes neurais convolucionais, por isso vou fazer muitas analogias com elas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para se preparar para a conscientização da RCN, é necessário entender que as RCNs se baseiam na idéia de separar a forma (esboço do objeto) da aparência (sua textura) e que é um modelo generativo, não discriminante, para que possamos gerar imagens usando-o, como em um generativo redes adversárias. </font><font style="vertical-align: inherit;">Além disso, é usada uma estrutura hierárquica paralela, semelhante à arquitetura das redes neurais convolucionais, que começa com o estágio de determinação da forma do objeto alvo nas camadas inferiores e, em seguida, sua aparência é adicionada à camada superior. </font><font style="vertical-align: inherit;">Ao contrário das redes neurais convolucionais, o modelo que estamos considerando se baseia em uma rica base teórica de modelos gráficos, em vez de somas ponderadas e descida de gradiente. </font><font style="vertical-align: inherit;">Agora vamos nos aprofundar nos recursos da estrutura RCN.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Camadas de recursos</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O primeiro tipo de camada no RCN é chamado de camada de recurso. Vamos considerar o modelo gradualmente, então vamos supor, por enquanto, que toda a hierarquia do modelo consiste apenas em camadas desse tipo empilhadas umas sobre as outras. Passaremos de conceitos abstratos de alto nível para recursos mais específicos das camadas inferiores, como mostra a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 1</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Uma camada desse tipo consiste em vários nós localizados no espaço bidimensional, de maneira semelhante a mapas de recursos em redes neurais convolucionais. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ht/iu/jv/htiujvk93pvm2-bjqthrweo_beq.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 1</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Várias camadas de recursos localizadas uma acima da outra com nós no espaço bidimensional. A transição da quarta para a primeira camada significa a transição do geral para o particular.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada nó consiste em vários canais, cada um dos quais representa um recurso separado. Canais são variáveis ​​binárias que assumem o valor Verdadeiro ou Falso, indicando se existe um objeto correspondente a este canal na imagem final gerada na coordenada (x, y) do nó. Em qualquer nível, os nós têm o mesmo tipo de canal.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como exemplo, vamos pegar uma camada intermediária e falar sobre seus canais e as camadas acima para simplificar a explicação. A lista de canais nesta camada será uma hipérbole, um círculo e uma parábola. Em uma determinada execução ao gerar a imagem, os cálculos das camadas sobrepostas exigiram um círculo na coordenada (1,1). Assim, o nó (1, 1) terá um canal correspondente ao objeto “circle” no valor True. Isso afetará diretamente alguns nós na camada abaixo, ou seja, os recursos de nível inferior associados ao círculo na vizinhança (1,1) serão definidos como True. Esses objetos de nível inferior podem ser, por exemplo, quatro arcos com orientações diferentes. Quando os recursos da camada inferior são ativados, eles ativam os canais nas camadas mais baixas até a última camada ser atingida,geração de imagem. A visualização de ativação é mostrada em</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 2</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Você pode perguntar, como ficará claro que a representação de um círculo é de 4 arcos? E como a RCN sabe que precisa de um canal para representar o círculo? Os canais e suas ligações a outras camadas serão formados no estágio de treinamento da RCN. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ao/gr/s9/aogrs9u-zi-guzvwobln0wng8rw.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 2:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fluxo de informações nas camadas de recursos. Nós de sinais são cápsulas contendo discos representando canais. Algumas das camadas superior e inferior foram apresentadas na forma de um paralelepípedo para simplificar, no entanto, na realidade, elas também consistem em nós de características como camadas intermediárias. Observe que a camada intermediária superior consiste em 3 canais e a segunda camada consiste em 4 canais.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Você pode indicar um método muito rígido e determinístico para gerar o modelo adotado, mas para as pessoas, pequenas perturbações da curvatura do círculo ainda são consideradas um círculo, como você pode ver na </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 3</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/o1/pr/fr/o1prfrwawffkxyvl62yb1k3czag.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 3:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Muitas variações da construção de um círculo de quatro arcos curvos da Figura 2.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Seria difícil considerar cada uma dessas variações como um novo canal separado na camada. </font><font style="vertical-align: inherit;">Da mesma forma, o agrupamento de variações na mesma entidade facilitará muito a generalização em novas variações quando adaptarmos a RCN à classificação, em vez da geração, um pouco mais tarde. </font><font style="vertical-align: inherit;">Mas como mudamos a RCN para obter essa oportunidade?</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Camadas de subamostragem</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para fazer isso, você precisa de um novo tipo de camada - a camada de pool. Está localizado entre duas camadas de sinais e atua como intermediário entre elas. Também consiste em canais, porém eles têm valores inteiros, não binários.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para ilustrar como essas camadas funcionam, vamos voltar ao exemplo do círculo. Em vez de exigir 4 arcos com coordenadas fixas da camada de feição acima dela como característica de um círculo, a pesquisa será realizada na camada de subamostra. Em seguida, cada canal ativado na camada de subamostra selecionará um nó na camada subjacente nas proximidades para permitir uma leve distorção do recurso. Assim, se estabelecermos comunicação com 9 nós diretamente abaixo do nó da subamostra, o canal da subamostra, sempre que for ativado, selecionará uniformemente um desses 9 nós e o ativará, e o índice do nó selecionado será o estado do canal da subamostra - um número inteiro. Na </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">figura 4</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">você pode ver várias execuções, nas quais cada execução usa um conjunto diferente de nós de nível inferior, respectivamente, permitindo criar um círculo de várias maneiras. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ma/6t/oe/ma6toei3ncssielvv8cuff5e97i.gif"><br>
 <i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 4:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Operação das camadas de subamostragem. Cada quadro nesta imagem GIF é um lançamento separado. Nós de subamostragem são em cubos. Nesta imagem, os nós da subamostra têm 4 canais equivalentes a 4 canais da camada de feição abaixo dela. As camadas superior e inferior foram completamente removidas da imagem.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Apesar do fato de precisarmos da variabilidade do nosso modelo, seria melhor se ele permanecesse mais restrito e focado. Nas duas figuras anteriores, alguns círculos parecem estranhos demais para realmente interpretá-los como círculos devido ao fato de os arcos não estarem interconectados, como pode ser visto na </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 5</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Gostaríamos de evitar gerá-los. Assim, se pudéssemos adicionar um mecanismo para canais de subamostragem para coordenar a seleção de nós de recursos e focar em formulários contínuos, nosso modelo seria mais preciso. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ci/bc/oa/cibcoalwwxl1yawero5mnooydua.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 5:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Muitas opções para construir um círculo. Essas opções que queremos soltar estão marcadas com cruzes vermelhas.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os autores da RCN usaram a conexão lateral em camadas de subamostragem para esse fim. Essencialmente, os canais de subamostragem terão links com outros canais de subamostragem do ambiente imediato, e esses links não permitirão que alguns pares de estados coexistam em dois canais simultaneamente. De fato, a área de amostra desses dois canais será simplesmente limitada. Em várias versões do círculo, essas conexões, por exemplo, não permitem que dois arcos adjacentes se afastem um do outro. Este mecanismo é mostrado na </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 6.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Novamente, essas relações são estabelecidas na fase de treinamento. Deve-se notar que as redes neurais artificiais de baunilha modernas não têm conexões laterais em suas camadas, embora existam em redes neurais biológicas e supõe-se que elas tenham um papel na integração de contornos no córtex visual (mas, francamente, o córtex visual tem dispositivo mais complexo do que parece na declaração anterior). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fi/tw/xj/fitwxjlp-0qrkgnvt8fhwflbadm.gif"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 6:</font></font></b> GIF-   RCN   .    ,         .  ,   RCN           ,     ,    .         .</i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Até agora, falamos sobre as camadas intermediárias da RCN, temos apenas a camada superior e a camada inferior que interage com os pixels da imagem gerada. A camada superior é uma camada de recurso regular, onde os canais de cada nó são classes de nosso conjunto de dados rotulado. Ao gerar, simplesmente selecionamos o local e a classe que queremos criar, vamos para o nó com o local especificado e dizemos que ele ativa o canal da classe que selecionamos. Isso ativa alguns dos canais na camada de subamostra abaixo dele, depois a camada de recurso abaixo e assim por diante, até chegarmos à última camada de recurso. Com base no seu conhecimento de redes neurais convolucionais, você deve pensar que a camada superior terá um único nó, mas não é assim, e essa é uma das vantagens da RCN,mas uma discussão sobre este tópico está além do escopo deste artigo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A última camada de recurso será exclusiva. Lembre-se, eu falei sobre como as RCNs separam a forma da aparência? É essa camada que será responsável por obter a forma do objeto gerado. Portanto, essa camada deve funcionar com recursos de nível muito baixo, os blocos de construção mais básicos de qualquer forma, o que nos ajudará a gerar a forma desejada. Pequenas bordas rotativas em ângulos diferentes são bastante adequadas, e é exatamente elas que os autores da tecnologia usam.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os autores selecionaram os atributos do último nível para representar uma janela 3x3 que possui uma borda com um determinado ângulo de rotação, que eles chamam de descritor de patch. O número de ângulos de rotação que eles escolheram é 16. Além disso, para poder adicionar uma aparência mais tarde, você precisa de duas orientações para cada rotação, a fim de saber se o plano de fundo está na borda esquerda ou direita, se essas são bordas externas e orientação adicional no caso de limites internos (ou seja, dentro do objeto). Na </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 7</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mostra as características do último conjunto de camadas, e a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 8</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mostra como os descritores de amostras podem gerar certa forma. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/gz/2o/mp/gz2ompbptag8mfcmey7ngj7ynem.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 7:</font></font></b>    .  48   ( ) ,  16    3 .    –      45 . “IN "   ,  “OUT” — .</i><br>
<br>
<img src="https://habrastorage.org/webt/dv/wu/-e/dvwu-ea0vfc7ff9pz2zn12w-tcw.png"><br>
<i><b> 8:</b>    «i»     .</i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora que alcançamos a última camada de sinais, temos um diagrama no qual os limites do objeto são determinados e a compreensão de se a área fora da borda é interna ou externa. Resta adicionar uma aparência, designando cada área restante da imagem como IN ou OUT e pintar sobre a área. Um campo aleatório condicional pode ajudar aqui. Sem entrar em detalhes matemáticos, simplesmente atribuímos a cada pixel na imagem final uma distribuição de probabilidade por cor e estado (IN ou OUT). Esta distribuição refletirá as informações obtidas a partir da borda do mapa. Por exemplo, se houver dois pixels adjacentes, um dos quais é IN e o outro é OUT, a probabilidade de que eles tenham uma cor diferente aumenta muito. Se dois pixels adjacentes estiverem em lados opostos da borda interna, a probabilidadeque terão uma cor diferente também aumentará. Se os pixels estiverem dentro da borda e não estiverem separados por nada, a probabilidade de que eles tenham a mesma cor aumentará, mas os pixels externos podem ter um leve desvio um do outro e assim por diante. Para obter a imagem final, basta selecionar a distribuição de probabilidade conjunta que acabamos de instalar. Para tornar a imagem gerada mais interessante, podemos substituir as cores pela textura. Não discutiremos essa camada porque o RCN pode executar a classificação sem basear-se na aparência.Para obter a imagem final, basta fazer uma seleção da distribuição de probabilidade conjunta que acabamos de instalar. Para tornar a imagem gerada mais interessante, podemos substituir as cores pela textura. Não discutiremos essa camada porque o RCN pode executar a classificação sem basear-se na aparência.Para obter a imagem final, basta fazer uma seleção da distribuição de probabilidade conjunta que acabamos de instalar. Para tornar a imagem gerada mais interessante, podemos substituir as cores pela textura. Não discutiremos essa camada porque o RCN pode executar a classificação sem basear-se na aparência.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bem, vamos terminar aqui por hoje. </font><font style="vertical-align: inherit;">Se você quiser saber mais sobre a RCN, leia este artigo [5] e o apêndice com materiais adicionais ou leia meus outros artigos sobre as </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conclusões lógicas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">treinamento</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e os resultados do uso da RCN em </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vários conjuntos de dados</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fontes:</font></font></h4><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[1] R. Perrault, Y. Shoham, E. Brynjolfsson, et al., The AI ​​Index 2019 Annual Report (2019), Human-Centered AI Institute - Stanford University.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[2] D. Hendrycks, K. Zhao, S. Basart, et al., Natural Adversarial Examples (2019), arXiv: 1907.07174. </font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[3] J. Su, D. Vasconcellos Vargas e S. Kouichi, One Pixel Attack for Fooling Deep Neural Networks (2017), arXiv: 1710.08864.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[4] M. Sharif, S. Bhagavatula, L. Bauer, Uma estrutura geral para exemplos adversos com objetivos (2017), arXiv: 1801.00349.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">[5] D. George, W. Lehrach, K. Kansky, et al., A Generative Vision Model that Trains with High Data Efficiency and Break Text-based CAPTCHAs (2017), Science Mag (Vol 358 — Issue 6368).</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">[6] H. Liang, X. Gong, M. Chen, et al., Interactions Between Feedback and Lateral Connections in the Primary Visual Cortex (2017), Proceedings of the National Academy of Sciences of the United States of America.</a></li>
</ol><br>
<b>        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a>  : <i>«  :    »</i>.</b></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt486924/index.html">Encontre a bandeira e não a entregue. Como gastamos o RBKmoney CTF</a></li>
<li><a href="../pt486928/index.html">Como aumentar o servidor no RaspberryPI baseado em docker</a></li>
<li><a href="../pt486930/index.html">Uma seleção de fatos estatísticos divertidos # 4</a></li>
<li><a href="../pt486932/index.html">Cibernética na URSS: da pseudociência à panacéia</a></li>
<li><a href="../pt486934/index.html">Estamos testando uma lâmpada LED industrial barata TL-PROM-50-5K com recursos honestos</a></li>
<li><a href="../pt486942/index.html">Implementação da teoria algorítmica dos jogos em Python com Nashpy</a></li>
<li><a href="../pt486944/index.html">Seminários on-line da Hewlett Packard Enterprise | Fevereiro-abril 2020</a></li>
<li><a href="../pt486946/index.html">faça {Yoga} enquanto (dor nas costas)</a></li>
<li><a href="../pt486948/index.html">Como escolher um editor e por que escolher o NeoVim?</a></li>
<li><a href="../pt486950/index.html">Antiguidades: a atualização implacável do 386º computador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ”ƒ ğŸš£ ğŸ’´ Reconnaissance vocale: un trÃ¨s court cours d'introduction ğŸ¤¥ ğŸ™‰ ğŸšµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il est presque impossible de dire au profane le plus simplement possible le travail de reconnaissance vocale par ordinateur et de le convertir en text...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Reconnaissance vocale: un trÃ¨s court cours d'introduction</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/toshibarus/blog/490732/"><img src="https://habrastorage.org/webt/tz/sh/ll/tzshllxzf2iddwai7sredy3edie.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il est presque impossible de dire au profane le plus simplement possible le travail de reconnaissance vocale par ordinateur et de le convertir en texte. </font><font style="vertical-align: inherit;">Pas une seule histoire Ã  ce sujet n'est complÃ¨te sans formules complexes et termes mathÃ©matiques. </font><font style="vertical-align: inherit;">Nous essaierons d'expliquer aussi clairement et lÃ©gÃ¨rement simpliste que possible comment votre smartphone comprend la parole, lorsque les voitures ont appris Ã  reconnaÃ®tre une voix humaine et dans quels domaines inattendus cette technologie est utilisÃ©e. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avertissement nÃ©cessaire: si vous Ãªtes un dÃ©veloppeur ou, en particulier, un mathÃ©maticien, il est peu probable que vous appreniez quelque chose de nouveau de la poste et mÃªme vous plaignez de la nature scientifique insuffisante du matÃ©riel. </font><font style="vertical-align: inherit;">Notre objectif est d'initier les lecteurs non initiÃ©s aux technologies de la parole de la maniÃ¨re la plus simple et de dire comment et pourquoi Toshiba a commencÃ© la crÃ©ation de son IA voix.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jalons importants dans l'histoire de la reconnaissance vocale</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'histoire de la reconnaissance de la parole humaine par les machines Ã©lectroniques a commencÃ© un peu plus tÃ´t qu'il n'est coutume de penser: dans la plupart des cas, il est de coutume de compter Ã  rebours Ã  partir de 1952, mais en fait l'un des premiers appareils qui a rÃ©pondu aux commandes vocales Ã©tait le robot Televox, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dont nous avons dÃ©jÃ  parlÃ©</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . CrÃ©Ã© en 1927 aux Ã‰tats-Unis, le robot Herbert Televox Ã©tait un appareil simple dans lequel diffÃ©rents relais rÃ©agissaient Ã  des sons de frÃ©quences diffÃ©rentes. Le robot avait trois diapasons, chacun Ã©tant responsable de son ton. Selon le diapason qui fonctionnait, l'un ou l'autre relais Ã©tait activÃ©.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/90/pq/4i/90pq4ixpys3c8uevjp-ovvydfny.jpeg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En fait, tout le Â«remplissageÂ» de Televox, y compris le systÃ¨me de reconnaissance des commandes, Ã©tait situÃ© sur une crÃ©maillÃ¨re dans la zone du corps du Â«robotÂ». Il Ã©tait impossible de fermer son couvercle, sinon les diapasons ne pouvaient pas correctement Â«entendreÂ» les sons. Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acme Telepictures / Wikimedia.</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Il Ã©tait possible de communiquer avec Televox sous forme de signaux sÃ©parÃ©s avec un sifflet et de brefs signaux verbaux - leurs diapasons Ã©taient Ã©galement disposÃ©s dans une sÃ©quence de sons. Le crÃ©ateur du robot, Roy Wensley, a mÃªme organisÃ© une fantastique dÃ©monstration Ã  cette Ã©poque, en disant la commande Â«SÃ©same, ouvertÂ», par laquelle Televox a allumÃ© le relais chargÃ© d'ouvrir la porte. Pas de technologie numÃ©rique, de rÃ©seaux de neurones, d'IA et d'apprentissage automatique - juste une technologie analogique!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La prochaine invention clÃ© qui a ouvert la voie Ã  une vÃ©ritable reconnaissance de la parole humaine a Ã©tÃ© la machine Audrey, dÃ©veloppÃ©e en 1952 au Bell Labs Innovation Forge. L'Ã©norme Audrey consommait beaucoup d'Ã©lectricitÃ© et avait la taille d'une bonne armoire, mais toutes ses fonctionnalitÃ©s se rÃ©sumaient Ã  reconnaÃ®tre les nombres parlÃ©s de zÃ©ro Ã  neuf. Juste dix mots, oui, mais n'oublions pas qu'Audrey Ã©tait une machine analogique. </font></font><br>
<img src="https://habrastorage.org/webt/vd/1q/eb/vd1qebrer6czotgwty3tdyfp15i.png" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Malheureusement, l'histoire n'a pas conservÃ© les photographies publiques d'Audrey, il n'y a qu'un concept. Simple sur papier, difficile Ã  traduire - selon les mÃ©moires des contemporains, les composants Audrey occupaient un cabinet entier. Source: Bell Labs</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cela a fonctionnÃ© comme ceci: l'annonceur a parlÃ© des nombres dans le microphone, faisant des intervalles d'au moins 350 ms entre les mots, Audrey a converti les sons qu'il a entendus en signaux Ã©lectriques et les a comparÃ©s avec des Ã©chantillons enregistrÃ©s dans la mÃ©moire analogique. Selon les rÃ©sultats de la comparaison, la voiture a mis en Ã©vidence le numÃ©ro sur le tableau de bord. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'Ã©tait une percÃ©e, mais il n'y avait aucun avantage rÃ©el d'Audrey - la machine a reconnu la voix de son crÃ©ateur avec une prÃ©cision de 97%, d'autres haut-parleurs spÃ©cialement formÃ©s ont reÃ§u une prÃ©cision de 70-80%. Les Ã©trangers qui ont contactÃ© Audrey pour la premiÃ¨re fois, peu importe leurs efforts, n'ont vu leur numÃ©ro sur le tableau de bord que dans 50% des cas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MalgrÃ© les rÃ©sultats rÃ©volutionnaires pour l'Ã©poque, Audrey n'a pas trouvÃ©, et n'a pas pu trouver d'application pratique. </font><font style="vertical-align: inherit;">On a supposÃ© que le systÃ¨me pouvait Ãªtre adaptÃ© Ã  la place des opÃ©rateurs tÃ©lÃ©phoniques, mais nÃ©anmoins, les services humains Ã©taient plus pratiques, plus rapides et beaucoup plus fiables qu'Audrey.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rQco1sa9AwU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PrÃ©sentation similaire Ã  Audrey, mais beaucoup plus petites, machines - IBM Shoebox. </font><font style="vertical-align: inherit;">La vitesse de la boÃ®te Ã  chaussures est clairement visible. </font><font style="vertical-align: inherit;">La machine pourrait Ã©galement effectuer des opÃ©rations mathÃ©matiques simples d'addition et de soustraction</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au dÃ©but des annÃ©es 1960, des travaux sur la crÃ©ation de machines pour la reconnaissance vocale ont Ã©tÃ© menÃ©s au Japon, au Royaume-Uni, aux Ã‰tats-Unis et mÃªme en URSS, oÃ¹ ils ont inventÃ© un algorithme trÃ¨s important pour la transformation dynamique de la chronologie (DTW), Ã  l'aide duquel il a Ã©tÃ© possible de construire un systÃ¨me qui connaÃ®t environ 200 mots. Mais tous les dÃ©veloppements Ã©taient similaires et le principe de reconnaissance est devenu un inconvÃ©nient commun: les mots ont Ã©tÃ© perÃ§us comme des empreintes sonores intÃ©grales, puis ils ont Ã©tÃ© vÃ©rifiÃ©s par rapport Ã  la base d'Ã©chantillons (dictionnaire). Tout changement dans la vitesse, le timbre et la clartÃ© de la prononciation des mots a considÃ©rablement affectÃ© la qualitÃ© de la reconnaissance. Les scientifiques ont une nouvelle tÃ¢che: apprendre Ã  la machine Ã  entendre des sons, des phonÃ¨mes ou des syllabes individuels, puis Ã  en faire des mots. Une telle approche permettrait de niveler l'effet du changement de locuteur, lorsque, selon le locuteur, le niveau de reconnaissance variait fortement.</font></font><br>
<br>
<i> â€”     ,           . ,   Â« Â»  Â«Â»       Â«Â».   Â«Â»   Â« Â»  Â« Â»      Â«Â»,    â€”  Â«Â».  ,  ,   . </i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En 1971, l'Agence des projets de recherche avancÃ©e du ministÃ¨re de la DÃ©fense (DARPA) a lancÃ© un programme de cinq ans dotÃ© d'un budget de 15 millions de dollars, chargÃ© de crÃ©er un systÃ¨me de reconnaissance qui connaissait au moins 1 000 mots. En 1976, l'UniversitÃ© Carnegie Mellon a introduit Harpy, capable d'exploiter un dictionnaire de 1011 mots. Harpy n'a pas comparÃ© les mots complÃ¨tement entendus avec les Ã©chantillons, mais les a divisÃ©s en allophones (un Ã©chantillon du son d'un phonÃ¨me en fonction des lettres qui l'entourent). Ce fut un autre succÃ¨s, confirmant que l'avenir rÃ©side dans la reconnaissance des phonÃ¨mes individuels, plutÃ´t que des mots entiers. Cependant, parmi les inconvÃ©nients de Harpy se trouvait un niveau extrÃªmement faible de reconnaissance correcte des allophones (prononciations des phonÃ¨mes) - environ 47%. Avec une erreur aussi Ã©levÃ©e, la part des erreurs a augmentÃ© aprÃ¨s le volume du dictionnaire.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/32KKg3aP3Vw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Description du fonctionnement de Harpy. La vidÃ©o du programme n'a pas survÃ©cu.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
L'expÃ©rience de Harpie a montrÃ© que la crÃ©ation de dictionnaires d'empreintes sonores holistiques est inutile - elle augmente seulement le temps de reconnaissance et rÃ©duit considÃ©rablement la prÃ©cision, de sorte que les chercheurs du monde entier ont pris un chemin diffÃ©rent - la reconnaissance des phonÃ¨mes. Au milieu des annÃ©es 1980, la machine IBM Tangora pouvait apprendre Ã  comprendre le discours de tout locuteur avec n'importe quel accent, dialecte et prononciation, elle ne nÃ©cessitait qu'une formation de 20 minutes, au cours de laquelle une base de donnÃ©es de phonÃ¨mes et d'Ã©chantillons d'allophones Ã©tait accumulÃ©e. L'utilisation du </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modÃ¨le Markov cachÃ© a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ã©galement augmentÃ© le vocabulaire d'IBM Tangora Ã  20 000 mots, 20 fois plus que Harpy, et est dÃ©jÃ  comparable au vocabulaire de l'adolescent.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tous les systÃ¨mes de reconnaissance vocale des annÃ©es 1950 au milieu des annÃ©es 1990 ne savaient pas lire la langue parlÃ©e naturelle d'une personne - ils devaient prononcer les mots sÃ©parÃ©ment, en s'arrÃªtant entre eux. Un Ã©vÃ©nement vÃ©ritablement rÃ©volutionnaire a Ã©tÃ© l'introduction du modÃ¨le de Markov cachÃ© dÃ©veloppÃ© dans les annÃ©es 1980 - un modÃ¨le statistique qui a construit des hypothÃ¨ses prÃ©cises sur des Ã©lÃ©ments inconnus sur la base de ceux connus. En termes simples, avec seulement quelques phonÃ¨mes reconnus en un mot, le modÃ¨le de Markov cachÃ© sÃ©lectionne trÃ¨s prÃ©cisÃ©ment les phonÃ¨mes manquants, augmentant ainsi considÃ©rablement la prÃ©cision de la reconnaissance vocale.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En 1996, le premier programme commercial est apparu, capable de distinguer non pas des mots individuels, mais un flux continu de discours naturel - IBM MedSpeak / Radiology. IBM Ã©tait un produit spÃ©cialisÃ© utilisÃ© en mÃ©decine pour dÃ©crire briÃ¨vement les rÃ©sultats d'une radiographie dÃ©livrÃ©e par un mÃ©decin au cours de l'Ã©tude. Ici, la puissance des ordinateurs est finalement devenue suffisante pour reconnaÃ®tre des mots individuels "Ã  la volÃ©e". De plus, les algorithmes sont devenus plus parfaits, la reconnaissance correcte des micro-pauses entre les mots prononcÃ©s est apparue.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le premier moteur universel pour reconnaÃ®tre la parole naturelle a Ã©tÃ© le programme Dragon NaturallySpeaking en 1997. En travaillant avec elle, l'annonceur (c'est-Ã -dire l'utilisateur) n'avait pas besoin de suivre une formation ou de fonctionner avec un vocabulaire spÃ©cifique, comme dans le cas de MedSpeak, toute personne, mÃªme un enfant, pouvait travailler avec NaturallySpeaking, le programme n'a pas dÃ©fini de rÃ¨gles de prononciation. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xj/m6/w-/xjm6w-kpgryltox7wquuvpl8db4.png" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MalgrÃ© le caractÃ¨re unique de Dragon NaturallySpeaking, les navigateurs informatiques n'ont pas montrÃ© beaucoup d'enthousiasme pour reconnaÃ®tre la parole naturelle. Parmi les lacunes, des erreurs de reconnaissance et un traitement incorrect des commandes adressÃ©es au programme lui-mÃªme ont Ã©tÃ© notÃ©s. Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">itWeek</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il est Ã  noter que le moteur de reconnaissance Ã©tait prÃªt dans les annÃ©es 1980, mais en raison de la puissance informatique insuffisante, le dÃ©veloppement de Dragon Systems (maintenant dÃ©tenu par Nuance Communications) n'a pas eu le temps de dÃ©terminer les espaces entre les mots Ã  la volÃ©e, ce qui est nÃ©cessaire pour reconnaÃ®tre la parole naturelle. </font><font style="vertical-align: inherit;">Sans cela, les mots Â«tout en Ã©tant traitÃ©Â», par exemple, pourraient Ãªtre entendus par l'ordinateur comme Â«estropiÃ©sÂ». </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Devaient la popularitÃ© croissante des systÃ¨mes de reconnaissance vocale, des rÃ©seaux de neurones, l'Ã©mergence de la recherche vocale Google sur les appareils mobiles et, enfin, l'assistant vocal Siri, non seulement convertissant la parole en texte, mais rÃ©pondant Ã©galement de maniÃ¨re adÃ©quate aux requÃªtes construites de maniÃ¨re naturelle.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comment entendre ce qui a Ã©tÃ© dit et penser Ã  ce qui Ã©tait inaudible?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De nos jours, le meilleur outil pour crÃ©er un moteur de reconnaissance vocale est le rÃ©seau neuronal rÃ©current (RNN), sur lequel sont construits tous les services modernes de reconnaissance de la voix, de la musique, des images, des visages, des objets, du texte. RNN vous permet de comprendre les mots avec une extrÃªme prÃ©cision, ainsi que de prÃ©dire le mot le plus probable dans le contexte du contexte s'il n'a pas Ã©tÃ© reconnu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La classification temporelle du rÃ©seau neuronal du modÃ¨le (CTC) sÃ©lectionne les phonÃ¨mes individuels dans le flux audio enregistrÃ© (mot, phrase) et les organise dans l'ordre dans lequel ils ont Ã©tÃ© prononcÃ©s. AprÃ¨s des analyses rÃ©pÃ©tÃ©es, le CTC identifie trÃ¨s clairement certains phonÃ¨mes, et leur enregistrement de texte est comparÃ© Ã  la base de donnÃ©es de mots du rÃ©seau neuronal puis se transforme en un mot reconnu.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les rÃ©seaux de neurones sont appelÃ©s ainsi parce que le principe de leur travail est similaire Ã  celui du cerveau humain. La formation en rÃ©seau neuronal est trÃ¨s similaire Ã  la formation humaine. Par exemple, pour qu'un trÃ¨s jeune enfant apprenne Ã  reconnaÃ®tre les voitures et Ã  les distinguer des motos, vous devez au moins plusieurs fois attirer son attention sur diffÃ©rentes voitures et Ã  chaque fois prononcer le mot correspondant: c'est grand et rouge est la voiture, et ce bas noir est la voiture, mais cela et ce sont des motos. Ã€ un moment donnÃ©, l'enfant dÃ©couvrira des modÃ¨les et des signes communs pour diffÃ©rentes voitures, et apprendra Ã  reconnaÃ®tre correctement oÃ¹ se trouve la voiture, oÃ¹ la jeep, oÃ¹ la moto et oÃ¹ le VTT, mÃªme si au passage il les voit sur une affiche publicitaire dans la rue. De la mÃªme maniÃ¨re, le rÃ©seau neuronal doit Ãªtre formÃ© Ã  partir d'une base d'exemples - pour que des centaines et des milliers de variantes de prononciation de chaque mot, lettre, phonÃ¨me Â«apprennentÂ».</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un rÃ©seau de neurones rÃ©current pour la reconnaissance vocale est bon car aprÃ¨s une longue formation Ã  la base de diverses prononciations, il apprendra Ã  distinguer les phonÃ¨mes des mots et Ã  en faire des mots indÃ©pendamment de la qualitÃ© et de la nature de la prononciation. Et mÃªme Â«rÃ©flÃ©chissezÂ» avec une grande prÃ©cision, dans le contexte du mot, des mots qui ne pouvaient pas Ãªtre reconnus sans ambiguÃ¯tÃ© en raison de bruits de fond ou d'une prononciation floue. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais il y a une nuance avec les prÃ©dictions RNN - un rÃ©seau neuronal rÃ©current ne peut Â«penserÂ» un mot manquant qu'en s'appuyant sur le contexte le plus proche d'environ cinq mots. En dehors de cet espace, aucune analyse ne sera effectuÃ©e. Et parfois, il est tellement nÃ©cessaire! Par exemple, pour la reconnaissance, nous avons prononcÃ© la phrase Â«Le grand poÃ¨te russe Alexandre Sergeyevich </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pushkin</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Â», Dans lequel le motÂ« Pouchkine Â»(spÃ©cialement en italique) Ã©tait dit d'une maniÃ¨re si inaudible que l'IA ne pouvait pas le reconnaÃ®tre avec prÃ©cision. Mais un rÃ©seau de neurones rÃ©current, basÃ© sur l'expÃ©rience acquise lors de la formation, peut suggÃ©rer que le mot Â«PouchkineÂ» se trouve le plus souvent Ã  cÃ´tÃ© des mots Â«russeÂ», Â«poÃ¨teÂ», Â«AlexandreÂ» et Â«SergeyevichÂ». C'est une tÃ¢che assez simple pour un RNN formÃ© aux textes russes, car un contexte trÃ¨s spÃ©cifique nous permet de faire des hypothÃ¨ses avec la plus grande prÃ©cision.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et si le contexte est vague? Prenons un autre texte dans lequel un mot ne peut Ãªtre reconnu: Â«Notre tout, Alexandre Sergeyevich Pushkin, est dÃ©cÃ©dÃ© tragiquement dans la fleur de l'Ã¢ge aprÃ¨s un duel avec Dantes. Le festival de thÃ©Ã¢tre Pouchkine porte le nom du poÃ¨te. Â» Si vous supprimez le mot "Pushkinsky", RNN ne peut tout simplement pas le deviner, sur la base du contexte de la proposition, car il ne mentionne qu'un festival de thÃ©Ã¢tre et une rÃ©fÃ©rence au nom d'un poÃ¨te inconnu - il y a des tonnes d'options possibles! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'est lÃ  que l'architecture de la mÃ©moire Ã  long terme Ã  court terme (LSTM) pour les rÃ©seaux de neurones rÃ©currents, crÃ©Ã©e en 1997 (un </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">article dÃ©taillÃ© sur le LSTM</font></a><font style="vertical-align: inherit;"> ) entre en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jeu.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Il a Ã©tÃ© spÃ©cialement dÃ©veloppÃ© afin d'ajouter la capacitÃ© de RNN Ã  prendre en compte le contexte Ã©loignÃ© de l'Ã©vÃ©nement en cours de traitement - les rÃ©sultats de la rÃ©solution de problÃ¨mes prÃ©cÃ©dents (c'est-Ã -dire la reconnaissance de mots) passent par tout le processus de reconnaissance, quelle que soit la durÃ©e du monologue, et sont pris en compte dans chaque cas de doute. De plus, la distance de retrait n'a quasiment aucun effet sur l'efficacitÃ© de l'architecture. Avec l'aide de LSTM, si nÃ©cessaire, un rÃ©seau de mots prendra en compte toute l'expÃ©rience disponible dans le cadre de la tÃ¢che: dans notre exemple, RNN examinera la phrase prÃ©cÃ©dente, trouvera que Pouchkine et Dantes ont Ã©tÃ© mentionnÃ©s plus tÃ´t, par consÃ©quent, `` Par le nom du poÃ¨te '' pointe trÃ¨s probablement vers l'un d'entre eux. Puisqu'il n'y a aucune preuve de l'existence du Festival de ThÃ©Ã¢tre de Dantes,nous parlons de Pushkinsky (d'autant plus que l'empreinte sonore d'un mot non reconnu est trÃ¨s similaire) - un tel festival Ã©tait Ã  la base de la formation du rÃ©seau neuronal.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/P325_hrGsDI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Confession d'un assistant vocal." </font><font style="vertical-align: inherit;">Lorsqu'un rÃ©seau neuronal bien formÃ© entre en jeu, un assistant vocal peut dÃ©terminer exactement ce qui doit Ãªtre fait avec des Â«pantoufles vertesÂ»</font></font></i><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comment la reconnaissance vocale rend-elle le monde meilleur?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans chaque cas, l'application est diffÃ©rente - elle aide quelqu'un Ã  communiquer avec des gadgets et, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">selon PricewaterhouseCooper,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> plus de la moitiÃ© des utilisateurs de smartphones donnent des commandes vocales aux appareils - chez les adultes (25-49 ans), le pourcentage de ceux qui utilisent constamment des interfaces vocales, mÃªme plus Ã©levÃ© que chez les jeunes (18-25) - 65% contre 59%. </font><font style="vertical-align: inherit;">Et en Russie au moins une fois, au moins 71% de la population a communiquÃ© avec Siri, Google Assitant ou Alice. </font><font style="vertical-align: inherit;">45 millions de Russes communiquent en permanence avec Yandex d'Alice et Yandex.Maps / Yandex.Navigator ne reprÃ©sentent que 30% des demandes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La reconnaissance vocale aide vraiment quelqu'un au travail - par exemple, comme nous l'avons dit ci-dessus, pour les mÃ©decins: en mÃ©decine depuis 1996 (lorsque IBM MedSpeak est sorti), la reconnaissance est utilisÃ©e pour enregistrer l'anamnÃ¨se et Ã©tudier les images - un mÃ©decin peut continuer Ã  travailler sans Ãªtre distrait par les enregistrements dans ordinateur ou carte papier. Soit dit en passant, les travaux sur la dictÃ©e en mÃ©decine ne sont pas menÃ©s uniquement en Occident - en Russie, il existe un programme Voice2Med du Â«Center for Speech TechnologiesÂ».</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il existe d'autres exemples, dont le nÃ´tre. L'organisation d'une entreprise Toshiba implique l'inclusion complÃ¨te, c'est-Ã -dire l'Ã©galitÃ© des droits et des chances pour les personnes souffrant de divers problÃ¨mes de santÃ©, y compris pour les employÃ©s malentendants. Nous avons un programme d'entreprise appelÃ© Universal Design Advisor System, dans lequel des personnes ayant diffÃ©rents types de handicaps participent au dÃ©veloppement des produits Toshiba, faisant des suggestions pour amÃ©liorer leur commoditÃ© pour les personnes handicapÃ©es - c'est-Ã -dire que nous ne supposons pas comment nous pouvons faire mieux, mais opÃ©rons sur une expÃ©rience rÃ©elle et les Ã©valuations des employÃ©s.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a quelques annÃ©es, au siÃ¨ge de Toshiba au Japon, nous avons Ã©tÃ© confrontÃ©s Ã  une tÃ¢che trÃ¨s intÃ©ressante, nÃ©cessitant le dÃ©veloppement d'un nouveau systÃ¨me de reconnaissance vocale. Pendant le fonctionnement du systÃ¨me Universal Design Advisor, nous avons reÃ§u un aperÃ§u important: les employÃ©s malentendants veulent participer aux discussions lors des rÃ©unions et des confÃ©rences en temps rÃ©el, sans se limiter Ã  lire la transcription traitÃ©e des heures ou des jours plus tard. Le dÃ©marrage de la reconnaissance vocale via un smartphone dans de tels cas donne un rÃ©sultat trÃ¨s faible, les spÃ©cialistes Toshiba ont donc dÃ» commencer Ã  dÃ©velopper un systÃ¨me de reconnaissance spÃ©cialisÃ©. Et, bien sÃ»r, nous avons immÃ©diatement rencontrÃ© des problÃ¨mes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La conversation diffÃ¨re Ã©normÃ©ment de la parole Ã©crite - nous ne parlons pas comme nous Ã©crivons des lettres, et une vraie conversation traduite en texte semble trÃ¨s bÃ¢clÃ©e et mÃªme illisible. Autrement dit, mÃªme si nous convertissons les conversations sur le plan du matin en texte avec une grande prÃ©cision, nous obtiendrons un hachage incohÃ©rent grouillant de parasites verbaux, d'interjections et de Â«aaaÂ», Â«uhÂ» et Â«mmmÂ» rÃ©flÃ©chis. Pour se dÃ©barrasser de la transcription des sons, des mots et des expressions d'Ã©motions inutiles dans le texte, nous avons dÃ©cidÃ© de dÃ©velopper une IA capable de reconnaÃ®tre avec prÃ©cision au maximum les Ã©lÃ©ments pas nÃ©cessairement nÃ©cessaires du discours familier, y compris la coloration Ã©motionnelle de certains mots (par exemple, Â«oui, bienÂ» peut ressembler Ã  du scepticisme ou comment sincÃ¨re surprise, et ce sont des sens littÃ©ralement opposÃ©s).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6z/vv/od/6zvvodwnihcvdqdqfv4uuprbtb4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il ressemble Ã  un ordinateur portable avec un ensemble de pÃ©riphÃ©riques pour la reconnaissance vocale utilisant Toshiba AI (Ã  gauche) et une application avec les rÃ©sultats pour les appareils finaux (Ã  droite). Source: Toshiba</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
LSTM a Ã©tÃ© utile ici, sans lequel la prÃ©cision de reconnaissance Ã©tait insuffisante pour que le texte reÃ§u soit lu et compris sans effort. De plus, le LSTM Ã©tait utile non seulement pour une prÃ©diction plus prÃ©cise des mots en contexte, mais aussi pour le traitement correct des pauses au milieu des phrases et des interjections-parasites - pour cela, nous avons enseignÃ© au rÃ©seau neuronal ces parasites et pauses qui sont naturels pour la parole familiÃ¨re.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Est-ce Ã  dire que le rÃ©seau neuronal peut dÃ©sormais supprimer les interjections des transcriptions? </font><font style="vertical-align: inherit;">Oui, c'est possible, mais ce n'est pas nÃ©cessaire. </font><font style="vertical-align: inherit;">Le fait est que (une autre idÃ©e reÃ§ue) les personnes malentendantes sont guidÃ©es, y compris par les mouvements des lÃ¨vres de l'orateur. </font><font style="vertical-align: inherit;">Si les lÃ¨vres bougent, mais que le texte correspondant Ã  ces mouvements n'apparaÃ®t pas Ã  l'Ã©cran, on a l'impression que le systÃ¨me de reconnaissance a ratÃ© une partie de la conversation. </font><font style="vertical-align: inherit;">Autrement dit, pour quelqu'un qui ne peut pas entendre, il est important d'obtenir autant d'informations que possible sur la conversation, y compris les pauses malheureuses et la mÃ©jomÃ©tie. </font><font style="vertical-align: inherit;">Par consÃ©quent, le moteur Toshiba laisse ces Ã©lÃ©ments dans la transcription, mais attÃ©nue en temps rÃ©el la luminositÃ© des lettres, ce qui indique clairement qu'il s'agit de dÃ©tails facultatifs pour comprendre le texte.</font></font><br>
<br>
<div class="oembed"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.toshiba-clip.com/en/detail/7655</font></font></a></div><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici Ã  quoi ressemble le rÃ©sultat de la reconnaissance Ã  la volÃ©e sur l'appareil client. </font><font style="vertical-align: inherit;">Les parties du monologue qui ne sont pas significatives sont peintes en gris.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Maintenant, Toshiba AI fonctionne avec la parole en anglais, japonais et chinois, et mÃªme la traduction entre les langues Ã  la volÃ©e est possible. </font><font style="vertical-align: inherit;">Il n'est pas nÃ©cessaire de l'utiliser pour la stÃ©nographie Ã  la volÃ©e - l'IA peut Ãªtre adaptÃ©e pour fonctionner avec des assistants vocaux, qui apprennent enfin Ã  percevoir correctement les interjections, les pauses et les bÃ©gaiements lorsqu'une personne prononce une commande. </font><font style="vertical-align: inherit;">En mars 2019, le systÃ¨me a Ã©tÃ© utilisÃ© avec succÃ¨s pour ajouter des sous-titres Ã  la Convention nationale IPSJ diffusÃ©e au Japon. </font><font style="vertical-align: inherit;">Dans un avenir proche - la transformation de l'IA Toshiba en un service public et des expÃ©riences avec la mise en Å“uvre de la reconnaissance vocale en production.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr490720/index.html">Moteur! ou Qu'est-ce que la physique des jeux</a></li>
<li><a href="../fr490722/index.html">Vacances de genre en informatique. Comment noter</a></li>
<li><a href="../fr490726/index.html">Authentification sur l'Ã©quipement rÃ©seau via SSH Ã  l'aide de clÃ©s publiques</a></li>
<li><a href="../fr490728/index.html">Semaine de la sÃ©curitÃ© 10: ConfÃ©rence RSA et sensibilisation Ã  la cybersÃ©curitÃ©</a></li>
<li><a href="../fr490730/index.html">Intel x86 Root of Trust: perte de confiance</a></li>
<li><a href="../fr490734/index.html">Oeufs de PÃ¢ques sur les cartes topographiques de la Suisse</a></li>
<li><a href="../fr490736/index.html">9 outils clairs pour apprendre et pomper le vocabulaire anglais</a></li>
<li><a href="../fr490738/index.html">Principe de substitution de Lisk</a></li>
<li><a href="../fr490740/index.html">Les dÃ©fauts *** ne sont pas seulement de la randomisation</a></li>
<li><a href="../fr490742/index.html">Une nouvelle Ã¨re en robotique a commencÃ©</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèæ üíö üëäüèº Deepfakes und Deep Media: Ein neues Schlachtfeld f√ºr Sicherheit üë®üèø‚Äçüè´ üêÅ üö¥üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel ist Teil einer Sonderausgabe von VB. Lesen Sie hier die vollst√§ndige Serie: KI und Sicherheit .
 
 Die Anzahl der Diphakes - Medien, di...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Deepfakes und Deep Media: Ein neues Schlachtfeld f√ºr Sicherheit</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/501068/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/je/nd/hrjendr1wj5jz4hjefypyqo2gqy.jpeg"></div></a><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieser Artikel ist Teil einer Sonderausgabe von VB. Lesen Sie hier die vollst√§ndige Serie: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KI und Sicherheit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Die Anzahl der Diphakes - Medien, die ein vorhandenes Foto, Audio oder Video aufnehmen und die Pers√∂nlichkeit einer Person durch die einer anderen Person ersetzen, die KI verwendet - w√§chst rasant. Dies ist besorgniserregend, nicht nur, weil solche F√§lschungen dazu verwendet werden k√∂nnen, die Meinung der Menschen w√§hrend der Wahlen zu beeinflussen oder jemanden in Verbrechen zu verwickeln, sondern auch, weil sie bereits missbraucht wurden, um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gef√§lschte Pornos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu erstellen </font><font style="vertical-align: inherit;">und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">den Direktor eines britischen Energieunternehmens</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">t√§uschen</font></a><font style="vertical-align: inherit;"> .</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Vereinigung von akademischen Institutionen, Technologieunternehmen und gemeinn√ºtzigen Organisationen antizipiert diese Art von neuer Realit√§t und entwickelt Wege, um irref√ºhrende Medien zu identifizieren, die von KI erzeugt werden. </font><font style="vertical-align: inherit;">Ihre Arbeit zeigt, dass Erkennungswerkzeuge nur eine kurzfristig praktikable L√∂sung sind, w√§hrend das diphtheische Wettr√ºsten gerade erst beginnt.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake-Text</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fr√ºher √§hnelte die beste von AI erstellte Prosa eher Texten aus dem Spiel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mad Libs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> als dem Roman ‚ÄûBunches of Wrath‚Äú, aber moderne Sprachmodelle k√∂nnen jetzt Texte schreiben, die in ihrer Pr√§sentation und √úberzeugungskraft denen einer Person nahe kommen. </font><font style="vertical-align: inherit;">Zum Beispiel erstellt das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modell </font><font style="vertical-align: inherit;">, das von San Franciscos OpenAI-Forschungsunternehmen ver√∂ffentlicht wurde, in Sekundenschnelle Fragmente im Stil </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von Artikeln</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder Skripten </font><font style="vertical-align: inherit;">im </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">New Yorker-</font></a><font style="vertical-align: inherit;"> Stil </font><font style="vertical-align: inherit;">f√ºr Brainstorming. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Forscher</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das Zentrum f√ºr Terrorismus, Extremismus und Terrorismusbek√§mpfung des Middlebury Institute schlug vor, das GPT-2 und andere √§hnliche Modelle einzurichten, um die √úberlegenheit der wei√üen Rasse, des dschihadistischen Islamismus und anderer bedrohlicher Ideologien zu bef√ºrworten - und dies wirft noch mehr Bedenken auf.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/px/lx/fqpxlxj7iafxgiyvtrlle1pd254.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oben: Frontend GPT-2, ein geschultes Sprachmodell des Forschungsunternehmens OpenAI. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bild mit freundlicher Genehmigung von: OpenAI</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Auf der Suche nach einem System zur Erkennung synthetischer Inhalte entwickelten Forscher der Paul G. Allen School f√ºr Informatik und Ingenieurwesen an der University of Washington und des Allen Institute of Artificial Intelligence </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Grover</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einen Algorithmus, von dem sie behaupten, dass er 92% der Diphagen im Test ausw√§hlen konnte Ein Set aus offenen Daten von Common Crawl Corpus. Das Team erkl√§rt seinen Erfolg mit einem Copywriting-Ansatz, der ihnen zufolge dazu beitrug, die Merkmale der von AI erstellten Sprache zu verstehen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Team von Wissenschaftlern aus Harvard und dem MIT-IBM Watson AI Lab hat den Testraum f√ºr das </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Giant Language Model</font></a><font style="vertical-align: inherit;"> separat ver√∂ffentlicht</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, eine Webumgebung, die versucht festzustellen, ob Text mithilfe eines AI-Modells geschrieben wurde. </font><font style="vertical-align: inherit;">Angesichts des semantischen Kontexts sagt sie voraus, welche W√∂rter am wahrscheinlichsten in einem Satz vorkommen, und schreibt im Wesentlichen ihren eigenen Text. </font><font style="vertical-align: inherit;">Wenn die W√∂rter in der getesteten Probe 10, 100 oder 1000 wahrscheinlichsten W√∂rtern entsprechen, wird der Indikator gr√ºn, gelb bzw. rot. </font><font style="vertical-align: inherit;">Tats√§chlich verwendet sie ihren eigenen vorhersehbaren Text als Richtlinie zur Identifizierung k√ºnstlich erzeugter Inhalte.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake-Videos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die moderne KI, die Videos erzeugt, ist genauso gef√§hrlich und verf√ºgt √ºber dieselben, wenn nicht sogar gro√üartigen F√§higkeiten wie ihr nat√ºrliches Gegenst√ºck. In einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wissenschaftlichen Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> des in Hongkong ans√§ssigen Startups SenseTime, der Nanyang University of Technology und des Instituts f√ºr Automatisierung der Chinesischen Akademie der Wissenschaften wird das Framework beschrieben, mit dem Filmmaterial mithilfe von Audio bearbeitet wird, um realistische Videos zu synthetisieren. Forscher von Hyperconnect in Seoul haben k√ºrzlich das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MarioNETte-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tool entwickelt </font><font style="vertical-align: inherit;">, mit dem die Gesichtsz√ºge einer historischen Figur, eines Politikers oder eines CEO manipuliert werden k√∂nnen, um ein Gesicht zu synthetisieren, das durch die Bewegungen einer anderen Person animiert wird.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selbst die realistischsten Dipfakes enthalten jedoch Artefakte, die sie ausgeben. ‚ÄûMit generativen Systemen erstellte Dipfakes untersuchen eine Reihe realer Bilder in einem Video, zu denen Sie neue Bilder hinzuf√ºgen, und generieren dann ein neues Video mit neuen Bildern‚Äú, sagt Ishay Rosenberg, Leiter der Deep Training Group des Cybersicherheitsunternehmens Deep Instinct. ‚ÄûDas resultierende Video unterscheidet sich geringf√ºgig aufgrund von √Ñnderungen in der Verteilung k√ºnstlich erzeugter Daten und in der Verteilung von Daten im Originalvideo. Diese sogenannten "Einblicke in die Matrix" k√∂nnen die diphtheischen Detektoren unterscheiden.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jg/ba/nn/jgbanndfcnaymr8ggieay3n5vko.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oben: zwei gef√§lschte Videos, die mit den fortschrittlichsten Techniken erstellt wurden. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bild mit freundlicher Genehmigung von: SenseTime Im</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
vergangenen Sommer </font><font color="gray"><font style="vertical-align: inherit;">bereitete</font></font><font style="vertical-align: inherit;"> ein Team der University of California in Berkeley und der University of Southern California ein </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modell</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr die Suche nach genauen ‚ÄûEinheiten der Gesichtsaktion‚Äú vor - Daten zu Gesichtsbewegungen, Zecken und Gesichtsausdr√ºcken von Personen, einschlie√ülich beim Anheben der Oberlippe und Drehen des Kopfes bei Personen Stirnrunzeln - um gef√§lschte Videos mit einer Genauigkeit von mehr als 90% zu identifizieren. In √§hnlicher Weise testeten im August 2018 Teilnehmer des Media Forensics-Programms der US-amerikanischen Agentur f√ºr fortgeschrittene Verteidigungsforschungsprojekte (DARPA) die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Systeme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In der Lage, von KI erzeugte Videos anhand von Zeichen wie unnat√ºrlichem Blinken, seltsamen Kopfbewegungen, ungew√∂hnlicher Augenfarbe und vielem mehr zu erkennen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mehrere Startups sind derzeit dabei, √§hnliche Tools zur Erkennung gef√§lschter Videobilder zu kommerzialisieren. Das Amsterdamer Labor </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deeptrace Labs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bietet eine Reihe von √úberwachungstools zur Klassifizierung von Dipfakes, die in soziale Netzwerke, Video-Hosting-Plattformen und Desinformationsnetzwerke hochgeladen werden. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dessa hat</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Methoden zur Verbesserung von gef√§lschten Detektoren vorgeschlagen, die auf gef√§lschten Videosets trainiert wurden. Und im Juli 2018 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sammelte Truepic 8 Millionen US-Dollar.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seinen Service f√ºr die tiefe Erkennung von F√§lschungen in Videos und Fotos zu finanzieren. Im Dezember 2018 erwarb das Unternehmen das Startup Fourandsix, dessen gef√§lschter Bilddetektor eine DARPA-Lizenz erhielt.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ys/o-/y6/yso-y6hqoqnnhtvgrmvwm4pmiio.png"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oben: Dipfake-Bilder, die von AI bearbeitet wurden.</font></font><br>
</font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Neben der Entwicklung voll ausgebildeter Systeme haben eine Reihe von Unternehmen Textkorps ver√∂ffentlicht, in der Hoffnung, dass die Forschungsgemeinschaft neue Methoden zur Erkennung von F√§lschungen entwickeln wird. Um diesen Prozess zu beschleunigen, leitete Facebook zusammen mit Amazon Web Services (AWS), Partnership on AI und Wissenschaftlern mehrerer Universit√§ten die Deepfake Detection Challenge. Das Programm enth√§lt eine Reihe von Videobeispielen mit Beschriftungen, die darauf hinweisen, dass einige von ihnen von k√ºnstlicher Intelligenz betroffen waren. Im September 2019 ver√∂ffentlichte Google eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sammlung visueller F√§lschungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">im Rahmen des FaceForensics-Tests, der von der Technischen Universit√§t M√ºnchen und der Universit√§t Neapel Federico II erstellt wurde. </font><font style="vertical-align: inherit;">Und k√ºrzlich haben Forscher von SenseTime zusammen mit der Nanyang University of Technology in Singapur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeeperForensics-1.0 entwickelt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einen Datensatz zur Erkennung von F√§lschungen, von denen sie behaupten, er sei der gr√∂√üte seiner Art.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake Audio</font></font></h2><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KI und maschinelles Lernen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eignen sich nicht nur zum Synthetisieren von Video und Text, sondern k√∂nnen auch Stimmen kopieren. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unz√§hlige </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Studien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> haben gezeigt, dass nur ein kleiner Datensatz erforderlich ist, um die Sprache einer Person wiederherzustellen. Kommerzielle Systeme wie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resemble</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und Lyrebird erfordern einige Minuten Audioaufnahmen, w√§hrend anspruchsvolle Modelle wie die neueste Baidu Deep Voice-Implementierung nur Sprache aus einem 3,7-Sekunden-Sample kopieren k√∂nnen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt nicht so viele Tools zum Erkennen von Audio-Diphakes, aber es beginnen L√∂sungen zu erscheinen.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DWK_iYBl8cA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vor einigen Monaten ver√∂ffentlichte das Resemble-Team ein Open-Source-Tool namens Resemblyzer, das mithilfe von KI und maschinellem Lernen Dipfakes erkennt, indem es Sprachproben auf hoher Ebene erfasst und vorhersagt, ob sie real oder simuliert sind. Nach dem Empfang einer Audiodatei mit Sprache erstellt er eine mathematische Darstellung, in der die Eigenschaften der aufgenommenen Stimme zusammengefasst sind. Auf diese Weise k√∂nnen Entwickler die √Ñhnlichkeit der beiden Stimmen vergleichen oder herausfinden, wer gerade spricht.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Januar 2019 ver√∂ffentlichte Google im Rahmen der Google News-Initiative einen Sprachkorpus mit ‚ÄûTausenden‚Äú von Phrasen, die mithilfe von Text-to-Speech-Modellen gesprochen wurden. </font><font style="vertical-align: inherit;">Es wurden Proben aus englischen Artikeln entnommen, die von 68 verschiedenen synthetischen Stimmen in verschiedenen Dialekten gelesen wurden. </font><font style="vertical-align: inherit;">Der Fall steht allen Teilnehmern von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ASVspoof 2019 zur Verf√ºgung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einem Wettbewerb, dessen Ziel es ist, Gegenma√ünahmen gegen falsche Sprache zu f√∂rdern.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Viel zu verlieren</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keiner der Detektoren hat eine perfekte Genauigkeit erreicht, und die Forscher haben noch nicht herausgefunden, wie eine gef√§lschte Urheberschaft identifiziert werden kann. Deep Instinct Rosenberg erwartet, dass dies schlechte Schauspieler dazu inspiriert, F√§lschungen zu verbreiten. "Selbst wenn ein von einem Angreifer erzeugter Dipfake erkannt wird, besteht nur die Gefahr, dass der Dipfake aufgedeckt wird", sagte er. "F√ºr einen Schauspieler ist das Risiko, erwischt zu werden, minimal, so dass es nur wenige Einschr√§nkungen gibt, F√§lschungen zu erzeugen." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Rosenbergs Theorie wird </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">durch einen Deeptrace-Bericht gest√ºtzt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , in dem bei seiner letzten Z√§hlung im Juni und Juli 2019 </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">14.698</font></a><font style="vertical-align: inherit;"> gef√§lschte Videos online gefunden wurden. Innerhalb von sieben Monaten stieg ihre Zahl um 84%. Die √ºberwiegende Mehrheit von ihnen (96%) sind pornografische Videos mit Frauen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Angesichts dieser Zahlen argumentiert Rosenberg, dass Unternehmen, die aufgrund von Diphakes ‚Äûviel verlieren‚Äú, Deep-Detection-Technologie in ihren Produkten entwickeln und implementieren sollten, die seiner Meinung nach Antivirenprogrammen √§hnelt. Und in diesem Bereich sind Verschiebungen aufgetreten; </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facebook k√ºndigte Anfang Januar an</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , eine Kombination aus automatisierten und manuellen Systemen zu verwenden, um gef√§lschte Inhalte zu erkennen, und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Twitter schlug k√ºrzlich vor,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Diphakes zu kennzeichnen und diejenigen zu l√∂schen, die sch√§dlich sein k√∂nnten.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nat√ºrlich sind die Technologien, die der Erzeugung von Dipfakes zugrunde liegen, nur Werkzeuge und haben ein gro√ües Potenzial f√ºr gute Taten. Michael Kloser, Leiter Data &amp; Trust bei Access Partnership, einem Beratungsunternehmen, sagte, die Technologie werde bereits eingesetzt, um die medizinische Diagnose und Krebserkennung zu verbessern, L√ºcken in der Kartierung des Universums zu schlie√üen und das Training unbemannter Fahrzeuge zu verbessern. Daher warnt er vor der Verwendung allgemeiner Kampagnen, um generative KI zu blockieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄûDa die Staats- und Regierungschefs in diplomatischen Angelegenheiten damit begonnen haben, bestehende Rechtsnormen anzuwenden, ist es jetzt sehr wichtig, </font><b><font style="vertical-align: inherit;">wertvolle Technologien</font></b><font style="vertical-align: inherit;"> nicht loszuwerden</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√§lschungen loswerden ‚Äú, sagte Klozer. </font><font style="vertical-align: inherit;">"Letztendlich sind Rechtsprechung und soziale Normen in Bezug auf den Einsatz dieser neuen Technologie nicht reif genug, um leuchtend rote Linien zu erzeugen, die fairen Gebrauch und Missbrauch beschreiben."</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de501056/index.html">Warum, wann und wie Multithreading und Multiprocessing in Python verwendet werden</a></li>
<li><a href="../de501058/index.html">Teamcenter Rapid Start Solution hilft Herstellern von Industrieanlagen, die Konstruktionszeit um 25% zu verk√ºrzen</a></li>
<li><a href="../de501060/index.html">JetBrains .NET Days Online, 13.-14. Mai</a></li>
<li><a href="../de501062/index.html">Alle Berichte des kostenlosen Online-Teils von PHP Russia mit ausl√§ndischen Sprechern k√∂nnen in √úbersetzung eingesehen werden</a></li>
<li><a href="../de501064/index.html">Zum Flug des chinesischen Versuchsschiffs. Infografiken und Collagen.</a></li>
<li><a href="../de501076/index.html">Monat entfernt. Wir fassen die Life Hacks der Leiter der Arbeitsgruppen der Jet Infosystems zusammen und teilen sie</a></li>
<li><a href="../de501084/index.html">Beobachtbare Dienste in Angular</a></li>
<li><a href="../de501086/index.html">Summ3r von h4ck 2020. Sommer-Tutorial f√ºr digitale Sicherheit</a></li>
<li><a href="../de501088/index.html">Geben Sie es an. Yandex-Bericht</a></li>
<li><a href="../de501090/index.html">K8S Multicluster Reise</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
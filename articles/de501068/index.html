<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👶🏾 💚 👊🏼 Deepfakes und Deep Media: Ein neues Schlachtfeld für Sicherheit 👨🏿‍🏫 🐁 🚴🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel ist Teil einer Sonderausgabe von VB. Lesen Sie hier die vollständige Serie: KI und Sicherheit .
 
 Die Anzahl der Diphakes - Medien, di...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Deepfakes und Deep Media: Ein neues Schlachtfeld für Sicherheit</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/501068/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/je/nd/hrjendr1wj5jz4hjefypyqo2gqy.jpeg"></div></a><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieser Artikel ist Teil einer Sonderausgabe von VB. Lesen Sie hier die vollständige Serie: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KI und Sicherheit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Die Anzahl der Diphakes - Medien, die ein vorhandenes Foto, Audio oder Video aufnehmen und die Persönlichkeit einer Person durch die einer anderen Person ersetzen, die KI verwendet - wächst rasant. Dies ist besorgniserregend, nicht nur, weil solche Fälschungen dazu verwendet werden können, die Meinung der Menschen während der Wahlen zu beeinflussen oder jemanden in Verbrechen zu verwickeln, sondern auch, weil sie bereits missbraucht wurden, um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gefälschte Pornos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu erstellen </font><font style="vertical-align: inherit;">und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">den Direktor eines britischen Energieunternehmens</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">täuschen</font></a><font style="vertical-align: inherit;"> .</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Vereinigung von akademischen Institutionen, Technologieunternehmen und gemeinnützigen Organisationen antizipiert diese Art von neuer Realität und entwickelt Wege, um irreführende Medien zu identifizieren, die von KI erzeugt werden. </font><font style="vertical-align: inherit;">Ihre Arbeit zeigt, dass Erkennungswerkzeuge nur eine kurzfristig praktikable Lösung sind, während das diphtheische Wettrüsten gerade erst beginnt.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake-Text</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Früher ähnelte die beste von AI erstellte Prosa eher Texten aus dem Spiel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mad Libs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> als dem Roman „Bunches of Wrath“, aber moderne Sprachmodelle können jetzt Texte schreiben, die in ihrer Präsentation und Überzeugungskraft denen einer Person nahe kommen. </font><font style="vertical-align: inherit;">Zum Beispiel erstellt das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modell </font><font style="vertical-align: inherit;">, das von San Franciscos OpenAI-Forschungsunternehmen veröffentlicht wurde, in Sekundenschnelle Fragmente im Stil </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von Artikeln</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder Skripten </font><font style="vertical-align: inherit;">im </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">New Yorker-</font></a><font style="vertical-align: inherit;"> Stil </font><font style="vertical-align: inherit;">für Brainstorming. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Forscher</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das Zentrum für Terrorismus, Extremismus und Terrorismusbekämpfung des Middlebury Institute schlug vor, das GPT-2 und andere ähnliche Modelle einzurichten, um die Überlegenheit der weißen Rasse, des dschihadistischen Islamismus und anderer bedrohlicher Ideologien zu befürworten - und dies wirft noch mehr Bedenken auf.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/px/lx/fqpxlxj7iafxgiyvtrlle1pd254.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oben: Frontend GPT-2, ein geschultes Sprachmodell des Forschungsunternehmens OpenAI. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bild mit freundlicher Genehmigung von: OpenAI</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Auf der Suche nach einem System zur Erkennung synthetischer Inhalte entwickelten Forscher der Paul G. Allen School für Informatik und Ingenieurwesen an der University of Washington und des Allen Institute of Artificial Intelligence </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Grover</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einen Algorithmus, von dem sie behaupten, dass er 92% der Diphagen im Test auswählen konnte Ein Set aus offenen Daten von Common Crawl Corpus. Das Team erklärt seinen Erfolg mit einem Copywriting-Ansatz, der ihnen zufolge dazu beitrug, die Merkmale der von AI erstellten Sprache zu verstehen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Team von Wissenschaftlern aus Harvard und dem MIT-IBM Watson AI Lab hat den Testraum für das </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Giant Language Model</font></a><font style="vertical-align: inherit;"> separat veröffentlicht</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, eine Webumgebung, die versucht festzustellen, ob Text mithilfe eines AI-Modells geschrieben wurde. </font><font style="vertical-align: inherit;">Angesichts des semantischen Kontexts sagt sie voraus, welche Wörter am wahrscheinlichsten in einem Satz vorkommen, und schreibt im Wesentlichen ihren eigenen Text. </font><font style="vertical-align: inherit;">Wenn die Wörter in der getesteten Probe 10, 100 oder 1000 wahrscheinlichsten Wörtern entsprechen, wird der Indikator grün, gelb bzw. rot. </font><font style="vertical-align: inherit;">Tatsächlich verwendet sie ihren eigenen vorhersehbaren Text als Richtlinie zur Identifizierung künstlich erzeugter Inhalte.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake-Videos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die moderne KI, die Videos erzeugt, ist genauso gefährlich und verfügt über dieselben, wenn nicht sogar großartigen Fähigkeiten wie ihr natürliches Gegenstück. In einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wissenschaftlichen Artikel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> des in Hongkong ansässigen Startups SenseTime, der Nanyang University of Technology und des Instituts für Automatisierung der Chinesischen Akademie der Wissenschaften wird das Framework beschrieben, mit dem Filmmaterial mithilfe von Audio bearbeitet wird, um realistische Videos zu synthetisieren. Forscher von Hyperconnect in Seoul haben kürzlich das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MarioNETte-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tool entwickelt </font><font style="vertical-align: inherit;">, mit dem die Gesichtszüge einer historischen Figur, eines Politikers oder eines CEO manipuliert werden können, um ein Gesicht zu synthetisieren, das durch die Bewegungen einer anderen Person animiert wird.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selbst die realistischsten Dipfakes enthalten jedoch Artefakte, die sie ausgeben. „Mit generativen Systemen erstellte Dipfakes untersuchen eine Reihe realer Bilder in einem Video, zu denen Sie neue Bilder hinzufügen, und generieren dann ein neues Video mit neuen Bildern“, sagt Ishay Rosenberg, Leiter der Deep Training Group des Cybersicherheitsunternehmens Deep Instinct. „Das resultierende Video unterscheidet sich geringfügig aufgrund von Änderungen in der Verteilung künstlich erzeugter Daten und in der Verteilung von Daten im Originalvideo. Diese sogenannten "Einblicke in die Matrix" können die diphtheischen Detektoren unterscheiden.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jg/ba/nn/jgbanndfcnaymr8ggieay3n5vko.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oben: zwei gefälschte Videos, die mit den fortschrittlichsten Techniken erstellt wurden. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bild mit freundlicher Genehmigung von: SenseTime Im</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
vergangenen Sommer </font><font color="gray"><font style="vertical-align: inherit;">bereitete</font></font><font style="vertical-align: inherit;"> ein Team der University of California in Berkeley und der University of Southern California ein </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modell</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> für die Suche nach genauen „Einheiten der Gesichtsaktion“ vor - Daten zu Gesichtsbewegungen, Zecken und Gesichtsausdrücken von Personen, einschließlich beim Anheben der Oberlippe und Drehen des Kopfes bei Personen Stirnrunzeln - um gefälschte Videos mit einer Genauigkeit von mehr als 90% zu identifizieren. In ähnlicher Weise testeten im August 2018 Teilnehmer des Media Forensics-Programms der US-amerikanischen Agentur für fortgeschrittene Verteidigungsforschungsprojekte (DARPA) die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Systeme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In der Lage, von KI erzeugte Videos anhand von Zeichen wie unnatürlichem Blinken, seltsamen Kopfbewegungen, ungewöhnlicher Augenfarbe und vielem mehr zu erkennen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mehrere Startups sind derzeit dabei, ähnliche Tools zur Erkennung gefälschter Videobilder zu kommerzialisieren. Das Amsterdamer Labor </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deeptrace Labs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bietet eine Reihe von Überwachungstools zur Klassifizierung von Dipfakes, die in soziale Netzwerke, Video-Hosting-Plattformen und Desinformationsnetzwerke hochgeladen werden. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dessa hat</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Methoden zur Verbesserung von gefälschten Detektoren vorgeschlagen, die auf gefälschten Videosets trainiert wurden. Und im Juli 2018 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sammelte Truepic 8 Millionen US-Dollar.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seinen Service für die tiefe Erkennung von Fälschungen in Videos und Fotos zu finanzieren. Im Dezember 2018 erwarb das Unternehmen das Startup Fourandsix, dessen gefälschter Bilddetektor eine DARPA-Lizenz erhielt.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ys/o-/y6/yso-y6hqoqnnhtvgrmvwm4pmiio.png"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oben: Dipfake-Bilder, die von AI bearbeitet wurden.</font></font><br>
</font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Neben der Entwicklung voll ausgebildeter Systeme haben eine Reihe von Unternehmen Textkorps veröffentlicht, in der Hoffnung, dass die Forschungsgemeinschaft neue Methoden zur Erkennung von Fälschungen entwickeln wird. Um diesen Prozess zu beschleunigen, leitete Facebook zusammen mit Amazon Web Services (AWS), Partnership on AI und Wissenschaftlern mehrerer Universitäten die Deepfake Detection Challenge. Das Programm enthält eine Reihe von Videobeispielen mit Beschriftungen, die darauf hinweisen, dass einige von ihnen von künstlicher Intelligenz betroffen waren. Im September 2019 veröffentlichte Google eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sammlung visueller Fälschungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">im Rahmen des FaceForensics-Tests, der von der Technischen Universität München und der Universität Neapel Federico II erstellt wurde. </font><font style="vertical-align: inherit;">Und kürzlich haben Forscher von SenseTime zusammen mit der Nanyang University of Technology in Singapur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeeperForensics-1.0 entwickelt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einen Datensatz zur Erkennung von Fälschungen, von denen sie behaupten, er sei der größte seiner Art.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake Audio</font></font></h2><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KI und maschinelles Lernen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eignen sich nicht nur zum Synthetisieren von Video und Text, sondern können auch Stimmen kopieren. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unzählige </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Studien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> haben gezeigt, dass nur ein kleiner Datensatz erforderlich ist, um die Sprache einer Person wiederherzustellen. Kommerzielle Systeme wie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resemble</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und Lyrebird erfordern einige Minuten Audioaufnahmen, während anspruchsvolle Modelle wie die neueste Baidu Deep Voice-Implementierung nur Sprache aus einem 3,7-Sekunden-Sample kopieren können. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt nicht so viele Tools zum Erkennen von Audio-Diphakes, aber es beginnen Lösungen zu erscheinen.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DWK_iYBl8cA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vor einigen Monaten veröffentlichte das Resemble-Team ein Open-Source-Tool namens Resemblyzer, das mithilfe von KI und maschinellem Lernen Dipfakes erkennt, indem es Sprachproben auf hoher Ebene erfasst und vorhersagt, ob sie real oder simuliert sind. Nach dem Empfang einer Audiodatei mit Sprache erstellt er eine mathematische Darstellung, in der die Eigenschaften der aufgenommenen Stimme zusammengefasst sind. Auf diese Weise können Entwickler die Ähnlichkeit der beiden Stimmen vergleichen oder herausfinden, wer gerade spricht.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Januar 2019 veröffentlichte Google im Rahmen der Google News-Initiative einen Sprachkorpus mit „Tausenden“ von Phrasen, die mithilfe von Text-to-Speech-Modellen gesprochen wurden. </font><font style="vertical-align: inherit;">Es wurden Proben aus englischen Artikeln entnommen, die von 68 verschiedenen synthetischen Stimmen in verschiedenen Dialekten gelesen wurden. </font><font style="vertical-align: inherit;">Der Fall steht allen Teilnehmern von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ASVspoof 2019 zur Verfügung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , einem Wettbewerb, dessen Ziel es ist, Gegenmaßnahmen gegen falsche Sprache zu fördern.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Viel zu verlieren</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keiner der Detektoren hat eine perfekte Genauigkeit erreicht, und die Forscher haben noch nicht herausgefunden, wie eine gefälschte Urheberschaft identifiziert werden kann. Deep Instinct Rosenberg erwartet, dass dies schlechte Schauspieler dazu inspiriert, Fälschungen zu verbreiten. "Selbst wenn ein von einem Angreifer erzeugter Dipfake erkannt wird, besteht nur die Gefahr, dass der Dipfake aufgedeckt wird", sagte er. "Für einen Schauspieler ist das Risiko, erwischt zu werden, minimal, so dass es nur wenige Einschränkungen gibt, Fälschungen zu erzeugen." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Rosenbergs Theorie wird </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">durch einen Deeptrace-Bericht gestützt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , in dem bei seiner letzten Zählung im Juni und Juli 2019 </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">14.698</font></a><font style="vertical-align: inherit;"> gefälschte Videos online gefunden wurden. Innerhalb von sieben Monaten stieg ihre Zahl um 84%. Die überwiegende Mehrheit von ihnen (96%) sind pornografische Videos mit Frauen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Angesichts dieser Zahlen argumentiert Rosenberg, dass Unternehmen, die aufgrund von Diphakes „viel verlieren“, Deep-Detection-Technologie in ihren Produkten entwickeln und implementieren sollten, die seiner Meinung nach Antivirenprogrammen ähnelt. Und in diesem Bereich sind Verschiebungen aufgetreten; </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facebook kündigte Anfang Januar an</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , eine Kombination aus automatisierten und manuellen Systemen zu verwenden, um gefälschte Inhalte zu erkennen, und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Twitter schlug kürzlich vor,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Diphakes zu kennzeichnen und diejenigen zu löschen, die schädlich sein könnten.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Natürlich sind die Technologien, die der Erzeugung von Dipfakes zugrunde liegen, nur Werkzeuge und haben ein großes Potenzial für gute Taten. Michael Kloser, Leiter Data &amp; Trust bei Access Partnership, einem Beratungsunternehmen, sagte, die Technologie werde bereits eingesetzt, um die medizinische Diagnose und Krebserkennung zu verbessern, Lücken in der Kartierung des Universums zu schließen und das Training unbemannter Fahrzeuge zu verbessern. Daher warnt er vor der Verwendung allgemeiner Kampagnen, um generative KI zu blockieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
„Da die Staats- und Regierungschefs in diplomatischen Angelegenheiten damit begonnen haben, bestehende Rechtsnormen anzuwenden, ist es jetzt sehr wichtig, </font><b><font style="vertical-align: inherit;">wertvolle Technologien</font></b><font style="vertical-align: inherit;"> nicht loszuwerden</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fälschungen loswerden “, sagte Klozer. </font><font style="vertical-align: inherit;">"Letztendlich sind Rechtsprechung und soziale Normen in Bezug auf den Einsatz dieser neuen Technologie nicht reif genug, um leuchtend rote Linien zu erzeugen, die fairen Gebrauch und Missbrauch beschreiben."</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de501056/index.html">Warum, wann und wie Multithreading und Multiprocessing in Python verwendet werden</a></li>
<li><a href="../de501058/index.html">Teamcenter Rapid Start Solution hilft Herstellern von Industrieanlagen, die Konstruktionszeit um 25% zu verkürzen</a></li>
<li><a href="../de501060/index.html">JetBrains .NET Days Online, 13.-14. Mai</a></li>
<li><a href="../de501062/index.html">Alle Berichte des kostenlosen Online-Teils von PHP Russia mit ausländischen Sprechern können in Übersetzung eingesehen werden</a></li>
<li><a href="../de501064/index.html">Zum Flug des chinesischen Versuchsschiffs. Infografiken und Collagen.</a></li>
<li><a href="../de501076/index.html">Monat entfernt. Wir fassen die Life Hacks der Leiter der Arbeitsgruppen der Jet Infosystems zusammen und teilen sie</a></li>
<li><a href="../de501084/index.html">Beobachtbare Dienste in Angular</a></li>
<li><a href="../de501086/index.html">Summ3r von h4ck 2020. Sommer-Tutorial für digitale Sicherheit</a></li>
<li><a href="../de501088/index.html">Geben Sie es an. Yandex-Bericht</a></li>
<li><a href="../de501090/index.html">K8S Multicluster Reise</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
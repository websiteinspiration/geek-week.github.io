<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👎 🖖🏻 🏄 Sicherstellung einer hohen Verfügbarkeit von Anwendungen mit Kafka Streams 👨🏻‍🏫 🆖 👨🏾‍💻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kafka Streams ist eine Java-Bibliothek zum Analysieren und Verarbeiten von in Apache Kafka gespeicherten Daten. Wie bei jeder anderen Streaming-Verarb...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Sicherstellung einer hohen Verfügbarkeit von Anwendungen mit Kafka Streams</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488558/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams ist eine Java-Bibliothek zum Analysieren und Verarbeiten von in Apache Kafka gespeicherten Daten. </font><font style="vertical-align: inherit;">Wie bei jeder anderen Streaming-Verarbeitungsplattform kann die Datenverarbeitung mit und / oder ohne Zustandserhaltung in Echtzeit durchgeführt werden. </font><font style="vertical-align: inherit;">In diesem Beitrag werde ich versuchen zu beschreiben, warum das Erreichen einer hohen Verfügbarkeit (99,99%) in Kafka Streams problematisch ist und was wir tun können, um dies zu erreichen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was müssen wir wissen?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bevor wir das Problem und mögliche Lösungen beschreiben, schauen wir uns die Grundkonzepte von Kafka Streams an. </font><font style="vertical-align: inherit;">Wenn Sie mit Kafka-APIs für Verbraucher / Produzenten gearbeitet haben, sind Ihnen die meisten dieser Paradigmen vertraut. </font><font style="vertical-align: inherit;">In den folgenden Abschnitten werde ich versuchen, die Speicherung von Daten in Partitionen, die Neuverteilung von Verbrauchergruppen und die Anpassung der Grundkonzepte von Kafka-Clients in die Kafka Streams-Bibliothek in wenigen Worten zu beschreiben.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Partitionieren von Daten</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In der Kafka-Welt senden Produzentenanwendungen Daten als Schlüssel-Wert-Paare an ein bestimmtes Thema. </font><font style="vertical-align: inherit;">Das Thema selbst ist in Kafka-Brokern in eine oder mehrere Partitionen unterteilt. </font><font style="vertical-align: inherit;">Kafka verwendet einen Nachrichtenschlüssel, um anzugeben, in welche Partition die Daten geschrieben werden sollen. </font><font style="vertical-align: inherit;">Folglich landen Nachrichten mit demselben Schlüssel immer auf derselben Partition.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Verbraucheranwendungen sind in Verbrauchergruppen organisiert, und jede Gruppe kann eine oder mehrere Instanzen von Verbrauchern haben. </font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jede Instanz eines Verbrauchers in der Verbrauchergruppe ist für die Verarbeitung von Daten aus einem eindeutigen Satz von Partitionen des Eingabethemas verantwortlich.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Consumer-Instanzen sind im Wesentlichen ein Mittel zur Skalierung der Verarbeitung in Ihrer Consumer-Gruppe.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Verbrauchergruppe neu ausbalancieren</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie bereits erwähnt, erhält jede Instanz der Verbrauchergruppe eine Reihe eindeutiger Partitionen, von denen Daten verarbeitet werden. </font><font style="vertical-align: inherit;">Immer wenn ein neuer Verbraucher einer Gruppe beitritt, muss ein Neuausgleich stattfinden, damit er eine Partition erhält. </font><font style="vertical-align: inherit;">Dasselbe passiert, wenn der Verbraucher stirbt. Der Rest des Verbrauchers sollte seine Partitionen nehmen, um sicherzustellen, dass alle Partitionen verarbeitet werden.</font></font><br>
<cut></cut><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu Beginn dieses Beitrags haben wir festgestellt, dass die Kafka Streams-Bibliothek auf APIs von Herstellern und Verbrauchern basiert und die Datenverarbeitung genauso organisiert ist wie die Standardlösung von Kafka. In der Kafka Streams-Konfiguration entspricht das Feld </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datei group.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in der Consumer-API. Kafka Streams erstellt eine bestimmte Anzahl von Threads vorab und jeder von ihnen führt die Datenverarbeitung von einer oder mehreren Partitionen von Eingabethemen aus. In der Terminologie der Consumer-API stimmen Streams im Wesentlichen mit Instanzen von Consumer aus derselben Gruppe überein. Threads sind die Hauptmethode zum Skalieren der Datenverarbeitung in Kafka Streams. Dies kann vertikal erfolgen, indem die Anzahl der Threads für jede Kafka Streams-Anwendung auf einem Computer erhöht wird, oder horizontal, indem ein zusätzlicher Computer mit derselben application.id hinzugefügt wird. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bb7/bd3/8ed/bb7bd38edd33f26a146c12a1dea385b5.jpg" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quelle: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kafka.apache.org/21/documentation/streams/architecture</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Kafka Streams gibt es viele weitere Elemente wie Aufgaben, Verarbeitungstopologie, Threading-Modell usw., die in diesem Beitrag nicht behandelt werden. </font><font style="vertical-align: inherit;">Weitere Informationen finden Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier.</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: Staatsspeicher</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei der Stream-Verarbeitung gibt es Operationen mit und ohne Zustandserhaltung. </font><font style="vertical-align: inherit;">Der Status ermöglicht es der Anwendung, sich die erforderlichen Informationen zu merken, die über den Umfang des aktuell verarbeiteten Datensatzes hinausgehen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zustandsoperationen wie Anzahl, jede Art von Aggregation, Verknüpfungen usw. sind viel komplizierter. Dies liegt an der Tatsache, dass Sie mit nur einem Datensatz nicht den letzten Status (z. B. Anzahl) für einen bestimmten Schlüssel ermitteln können. Daher müssen Sie den Status Ihres Streams in Ihrer Anwendung speichern. Wie bereits erwähnt, verarbeitet jeder Thread eine Reihe eindeutiger Partitionen. Daher verarbeitet ein Thread nur eine Teilmenge des gesamten Datensatzes. Dies bedeutet, dass jeder Kafka Streams-Anwendungsthread mit derselben application.id seinen eigenen isolierten Status beibehält. Wir werden nicht näher darauf eingehen, wie der Status in Kafka Streams gebildet wird. Es ist jedoch wichtig zu verstehen, dass Status mithilfe des Änderungsprotokollthemas (Änderungsprotokollthema) wiederhergestellt und nicht nur auf der lokalen Festplatte, sondern auch in Kafka Broker gespeichert werden.Das Speichern des Statusänderungsprotokolls in Kafka Broker als separates Thema dient nicht nur der Fehlertoleranz, sondern auch der einfachen Bereitstellung neuer Instanzen von Kafka Streams mit derselben application.id. Da der Status auf der Brokerseite als Änderungsprotokollthema gespeichert ist, kann eine neue Instanz aus diesem Thema einen eigenen Status laden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weitere Informationen zum Zustandsspeicher finden Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum ist Hochverfügbarkeit bei Kafka Streams problematisch?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben die grundlegenden Konzepte und Prinzipien der Datenverarbeitung mit Kafka Streams überprüft. </font><font style="vertical-align: inherit;">Versuchen wir nun, alle Teile miteinander zu kombinieren und zu analysieren, warum das Erreichen einer hohen Verfügbarkeit problematisch sein kann. </font><font style="vertical-align: inherit;">Aus den vorherigen Abschnitten müssen wir uns erinnern:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Die Daten im Kafka-Thema sind in Partitionen unterteilt, die auf die Kafka-Streams verteilt sind.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kafka Streams-Anwendungen mit derselben application.id sind in der Tat eine Gruppe von Verbrauchern, und jeder seiner Threads ist eine separate isolierte Instanz des Verbrauchers.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Für Statusoperationen behält der Thread seinen eigenen Status bei, der vom Kafka-Thema in Form eines Änderungsprotokolls „reserviert“ wird.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br>
<h2>TransferWise SPaaS (Stream Processing as a Service)</h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bevor ich das Wesentliche dieses Beitrags hervorhole, möchte ich Ihnen zunächst erläutern, was wir in TransferWise erstellt haben und warum Hochverfügbarkeit für uns sehr wichtig ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In TransferWise haben wir mehrere Knoten für die Streaming-Verarbeitung, und jeder Knoten enthält mehrere Instanzen von Kafka-Streams für jedes Produktteam. Kafka Streams-Instanzen, die für ein bestimmtes Entwicklungsteam entwickelt wurden, haben eine spezielle application.id und normalerweise mehr als 5 Threads. Im Allgemeinen haben Teams im gesamten Cluster 10 bis 20 Threads (entsprechend der Anzahl der Instanzen von Verbrauchern). Anwendungen, die auf Knoten bereitgestellt werden, überwachen Eingabethemen und führen verschiedene Arten von Vorgängen mit und ohne Status für Eingabedaten aus und bieten Echtzeit-Datenaktualisierungen für nachfolgende nachgeschaltete Mikrodienste.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Produktteams müssen aggregierte Daten in Echtzeit aktualisieren. </font><font style="vertical-align: inherit;">Dies ist notwendig, um unseren Kunden die Möglichkeit zu geben, sofort Geld zu überweisen. </font><font style="vertical-align: inherit;">Unsere übliche SLA:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An einem bestimmten Tag sollten 99,99% der aggregierten Daten in weniger als 10 Sekunden verfügbar sein.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um Ihnen eine Vorstellung zu geben, konnte Kafka Streams während Stresstests 20.085 Eingabenachrichten pro Sekunde verarbeiten und aggregieren. </font><font style="vertical-align: inherit;">Somit klangen 10 Sekunden SLA unter normaler Last durchaus erreichbar. </font><font style="vertical-align: inherit;">Leider wurde unser SLA während des fortlaufenden Updates der Knoten, auf denen die Anwendungen bereitgestellt werden, nicht erreicht. Im Folgenden werde ich beschreiben, warum dies passiert ist.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sliding Node Update</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir bei TransferWise glauben fest an die kontinuierliche Bereitstellung unserer Software und veröffentlichen in der Regel mehrmals täglich neue Versionen unserer Dienste. </font><font style="vertical-align: inherit;">Schauen wir uns ein Beispiel für ein einfaches kontinuierliches Service-Update an und sehen, was während des Release-Prozesses passiert. </font><font style="vertical-align: inherit;">Auch hier müssen wir uns daran erinnern:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Daten im Kafka-Thema sind in Partitionen unterteilt, die auf die Kafka-Streams verteilt sind.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams-Anwendungen mit derselben application.id sind in der Tat eine Gruppe von Verbrauchern, und jeder seiner Threads ist eine separate isolierte Instanz des Verbrauchers.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Für Statusoperationen behält der Thread seinen eigenen Status bei, der vom Kafka-Thema in Form eines Änderungsprotokolls „reserviert“ wird.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Freigabeprozess auf einem einzelnen Knoten dauert normalerweise acht bis neun Sekunden. </font><font style="vertical-align: inherit;">Während der Veröffentlichung werden Instanzen von Kafka Streams auf dem Knoten „sanft neu gestartet“. </font><font style="vertical-align: inherit;">Für einen einzelnen Knoten beträgt die zum korrekten Neustart des Dienstes erforderliche Zeit ungefähr acht bis neun Sekunden. </font><font style="vertical-align: inherit;">Das Herunterfahren einer Kafka Streams-Instanz auf einem Knoten führt offensichtlich zu einem Neuausgleich der Verbrauchergruppe. </font><font style="vertical-align: inherit;">Da die Daten partitioniert sind, müssen alle Partitionen, die zur bootfähigen Instanz gehörten, auf aktive Kafka Streams-Anwendungen mit derselben application.id verteilt werden. </font><font style="vertical-align: inherit;">Dies gilt auch für aggregierte Daten, die auf der Festplatte gespeichert wurden. </font><font style="vertical-align: inherit;">Bis dieser Vorgang abgeschlossen ist, werden keine Daten verarbeitet.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Standby-Repliken</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die Neuausgleichszeit für Kafka Streams-Anwendungen zu verkürzen, gibt es ein Konzept für Sicherungsreplikate, die in der Konfiguration als num.standby.replicas definiert sind. Sicherungsreplikate sind Kopien des lokalen Statusspeichers. Dieser Mechanismus ermöglicht es, den Statusspeicher von einer Instanz von Kafka Streams auf eine andere zu replizieren. Wenn der Kafka Streams-Thread aus irgendeinem Grund stirbt, kann die Dauer des Statuswiederherstellungsprozesses minimiert werden. Leider helfen aus den unten erläuterten Gründen selbst Backup-Replikate bei einem fortlaufenden Service-Update nicht weiter.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Angenommen, wir haben zwei Instanzen von Kafka-Streams auf zwei verschiedenen Computern: Knoten-a und Knoten-b. </font><font style="vertical-align: inherit;">Für jede der Kafka Streams-Instanzen wird auf diesen beiden Knoten num.standby.replicas = 1 angegeben. Bei dieser Konfiguration verwaltet jede Kafka Streams-Instanz ihre eigene Kopie des Repositorys auf einem anderen Knoten. </font><font style="vertical-align: inherit;">Während eines fortlaufenden Updates haben wir die folgende Situation:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die neue Version des Dienstes wurde auf Knoten-a bereitgestellt.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Kafka Streams-Instanz auf Knoten a ist deaktiviert.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Rebalancing hat begonnen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Repository von Knoten-a wurde bereits auf Knoten-b repliziert, da wir die Konfiguration num.standby.replicas = 1 angegeben haben.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Knoten-b verfügt bereits über eine Schattenkopie von Knoten-a, sodass der Neuausgleichsprozess fast sofort erfolgt.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Knoten-a startet erneut.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> node-a tritt einer Gruppe von Verbrauchern bei.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Broker sieht eine neue Instanz von Kafka Streams und beginnt mit dem Ausgleich.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie wir sehen können, hilft num.standby.replicas nur in Szenarien eines vollständigen Herunterfahrens eines Knotens. </font><font style="vertical-align: inherit;">Dies bedeutet, dass bei einem Absturz von Knoten-a Knoten-b fast sofort ordnungsgemäß weiterarbeiten kann. </font><font style="vertical-align: inherit;">In einer fortlaufenden Aktualisierungssituation wird Node-a nach dem Trennen der Verbindung wieder der Gruppe beitreten, und dieser letzte Schritt führt zu einem Neuausgleich. </font><font style="vertical-align: inherit;">Wenn Node-a nach einem Neustart der Consumer-Gruppe beitritt, wird dies als neue Instanz des Consumer betrachtet. </font><font style="vertical-align: inherit;">Auch hier müssen wir uns daran erinnern, dass die Echtzeitdatenverarbeitung angehalten wird, bis eine neue Instanz ihren Status aus dem Änderungsprotokollthema wiederherstellt.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beachten Sie, dass das Neuausgleichen von Partitionen, wenn eine neue Instanz einer Gruppe hinzugefügt wird, nicht für die Kafka Streams-API gilt, da genau das Protokoll der Apache Kafka-Verbrauchergruppe funktioniert.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Leistung: Hochverfügbarkeit mit Kafka Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trotz der Tatsache, dass Kafka-Clientbibliotheken keine integrierte Funktionalität für das oben erwähnte Problem bieten, gibt es einige Tricks, mit denen eine hohe Clusterverfügbarkeit während eines fortlaufenden Updates erreicht werden kann. </font><font style="vertical-align: inherit;">Die Idee hinter Backup-Replikaten bleibt gültig, und Backup-Maschinen zum richtigen Zeitpunkt zu haben, ist eine gute Lösung, die wir verwenden, um im Falle eines Instanzausfalls eine hohe Verfügbarkeit sicherzustellen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Problem bei unserer Ersteinrichtung war, dass wir eine Gruppe von Verbrauchern für alle Teams auf allen Knoten hatten. </font><font style="vertical-align: inherit;">Anstelle einer Gruppe von Verbrauchern haben wir jetzt zwei, und die zweite Gruppe fungiert als „heißer“ Cluster. </font><font style="vertical-align: inherit;">In prod haben Knoten eine spezielle Variable CLUSTER_ID, die der application.id von Kafka Streams-Instanzen hinzugefügt wird. </font><font style="vertical-align: inherit;">Hier ist ein Beispiel für eine Spring Boot application.yml-Konfiguration:</font></font><div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.yml</font></font></b><div class="spoiler_text"><code>spring.profiles: production<br>
streaming-pipelines:<br>
 team-a-stream-app-id: "${CLUSTER_ID}-team-a-stream-app"<br>
 team-b-stream-app-id: "${CLUSTER_ID}-team-b-stream-app"</code><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu einem bestimmten Zeitpunkt befindet sich jeweils nur einer der Cluster im aktiven Modus. Der Sicherungscluster sendet keine Nachrichten in Echtzeit an nachgeschaltete Mikrodienste. Während der Veröffentlichung der Version wird der Sicherungscluster aktiv, wodurch ein fortlaufendes Update des ersten Clusters ermöglicht wird. Da es sich um eine völlig andere Gruppe von Verbrauchern handelt, bemerken unsere Kunden nicht einmal Verstöße bei der Verarbeitung, und nachfolgende Dienste empfangen weiterhin Nachrichten vom kürzlich aktiven Cluster. Einer der offensichtlichen Nachteile der Verwendung einer Sicherungsgruppe von Verbrauchern ist der zusätzliche Overhead und Ressourcenverbrauch. Diese Architektur bietet jedoch zusätzliche Garantien, Kontrolle und Fehlertoleranz für unser Streaming-Verarbeitungssystem.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Neben dem Hinzufügen eines zusätzlichen Clusters gibt es auch Tricks, mit denen das Problem durch häufiges Neuausgleichen behoben werden kann.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erhöhen Sie group.initial.rebalance.delay.ms</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ab Kafka 0.11.0.0 wurde die Konfigurationsgruppe.initial.rebalance.delay.ms hinzugefügt. </font><font style="vertical-align: inherit;">Laut Dokumentation ist diese Einstellung verantwortlich für:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Zeit in Millisekunden, die GroupCoordinator für die anfängliche Neuausrichtung des Verbrauchers der Gruppe verzögert.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir in dieser Einstellung beispielsweise 60.000 Millisekunden festlegen, haben wir bei einem fortlaufenden Update möglicherweise ein Minutenfenster für die Veröffentlichung der Version. </font><font style="vertical-align: inherit;">Wenn die Kafka Streams-Instanz in diesem Zeitfenster erfolgreich neu gestartet wird, wird kein Neuausgleich aufgerufen. </font><font style="vertical-align: inherit;">Beachten Sie, dass die Daten, für die die neu gestartete Kafka Streams-Instanz verantwortlich war, weiterhin nicht verfügbar sind, bis der Knoten in den Online-Modus zurückkehrt. </font><font style="vertical-align: inherit;">Wenn ein Neustart einer Instanz beispielsweise etwa acht Sekunden dauert, haben Sie acht Sekunden Ausfallzeit für die Daten, für die diese Instanz verantwortlich ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es ist zu beachten, dass der Hauptnachteil dieses Konzepts darin besteht, dass Sie im Falle eines Knotenausfalls unter Berücksichtigung der aktuellen Konfiguration eine zusätzliche Verzögerung von einer Minute während der Wiederherstellung erhalten.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verkleinern der Segmentgröße in Änderungsprotokollthemen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die große Verzögerung bei der Neuausrichtung von Kafka Stream ist auf die Wiederherstellung staatlicher Geschäfte aus Änderungsprotokollthemen zurückzuführen. Änderungsprotokollthemen sind komprimierte Themen, mit denen Sie den neuesten Datensatz für einen bestimmten Schlüssel im Thema speichern können. Ich werde dieses Konzept im Folgenden kurz beschreiben. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Themen in Kafka Broker sind in Segmente unterteilt. Wenn ein Segment die konfigurierte Schwellengröße erreicht, wird ein neues Segment erstellt und das vorherige komprimiert. Standardmäßig ist dieser Schwellenwert auf 1 GB festgelegt. Wie Sie wahrscheinlich wissen, ist die Hauptdatenstruktur, die den Kafka-Themen und ihren Partitionen zugrunde liegt, die Protokollstruktur mit einem Vorwärtsschreibvorgang. Wenn also Nachrichten an das Thema gesendet werden, werden sie immer zum letzten „aktiven“ Segment hinzugefügt, die Komprimierung jedoch nicht los.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Daher befinden sich die meisten gespeicherten Speicherzustände im Änderungsprotokoll immer in der Datei "Aktives Segment" und werden nie komprimiert, was zu Millionen unkomprimierter Änderungsprotokollnachrichten führt. </font><font style="vertical-align: inherit;">Für Kafka Streams bedeutet dies, dass die Kafka Streams-Instanz während des Neuausgleichs, wenn sie ihren Status aus dem Changelog-Thema wiederherstellt, viele redundante Einträge aus dem Changelog-Thema lesen muss. </font><font style="vertical-align: inherit;">Da sich State Stores nur um den letzten Status und nicht um den Verlauf kümmern, wird diese Verarbeitungszeit verschwendet. </font><font style="vertical-align: inherit;">Das Reduzieren der Größe des Segments führt zu einer aggressiveren Datenkomprimierung, sodass neue Instanzen von Kafka Streams-Anwendungen viel schneller wiederhergestellt werden können.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fazit</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auch wenn Kafka Streams keine integrierte Möglichkeit bietet, während eines fortlaufenden Service-Updates eine hohe Verfügbarkeit bereitzustellen, kann dies dennoch auf Infrastrukturebene erfolgen. </font><font style="vertical-align: inherit;">Wir müssen uns daran erinnern, dass Kafka Streams im Gegensatz zu Apache Flink oder Apache Spark kein „Cluster-Framework“ ist. </font><font style="vertical-align: inherit;">Es handelt sich um eine kompakte Java-Bibliothek, mit der Entwickler skalierbare Anwendungen für das Streaming von Daten erstellen können. </font><font style="vertical-align: inherit;">Trotzdem bietet es die notwendigen Bausteine, um so ehrgeizige Streaming-Ziele wie die Verfügbarkeit von „99,99%“ zu erreichen.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de488544/index.html">Entfernen Sie die Codeabdeckung aus einer bereits ausgeführten Node.JS-Anwendung</a></li>
<li><a href="../de488546/index.html">Hack The Box. JSON-exemplarische Vorgehensweise. Sicherheitsanfälligkeit in Json.Net und LPE über SeImpersonatePrivilege</a></li>
<li><a href="../de488548/index.html">Experiment: Wie man lernt, populäre Texte auf Englisch zu erstellen (und warum die englischsprachigen Habristen so wenig lesen)</a></li>
<li><a href="../de488550/index.html">Wer will aus IT-Giganten Genossenschaften machen?</a></li>
<li><a href="../de488552/index.html">Apple FAS- und Kindersicherungsentwickler</a></li>
<li><a href="../de488560/index.html">Kostenloses Telegramm-Bot-Hosting auf der Google Cloud Platform</a></li>
<li><a href="../de488564/index.html">Ihr erstes neuronales Netzwerk auf einer Grafikverarbeitungseinheit (GPU). Ratgeber für Anfänger</a></li>
<li><a href="../de488566/index.html">Wie ein QS-Techniker einen ganzen Tag gespart hat, indem er AutoTests in Visual Studio und Test IT verknüpft hat</a></li>
<li><a href="../de488568/index.html">Träumen neuronale Netze von elektrischem Geld?</a></li>
<li><a href="../de488570/index.html">Wie der US Secret Service Cyberpunk-Rollenspiel mit einem Lehrbuch für Hacker verwechselte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
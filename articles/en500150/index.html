<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë±üèø üö§ üíµ ROS and Neural Grid Beggar Robot ‚ò∏Ô∏è üçè üëÅÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Usually, two such questions arise for such crafts: ‚Äúhow?‚Äù and for what?" The publication itself is devoted to the first question, and I will answer im...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ROS and Neural Grid Beggar Robot</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/500150/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Usually, two such questions arise for such crafts: ‚Äúhow?‚Äù and for what?" The publication itself is devoted to the first question, and I will answer immediately to the second: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I started this project in order to master robotics, starting with the Raspberry Pi and the camera. As you know, one of the best ways to learn something is to come up with a technical task and try to fulfill it, while getting the necessary skills. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At that time, I still had no bright ideas in the field of robotics, so I decided to make an exclusively fun project - a beggar robot. The result is a standalone robot on the Raspberry Pi and ROS, using the Movidius Neural Cumpute Stick to detect faces. He wanders around the room, looking for people, and shakes a can in front of them. Here's what this robot looks like:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/pt/wp/nt/ptwpntdd13lkskxbxjuhoyx1oom.jpeg"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The robot randomly moves around the room, and if it notices a person, it rolls up to it and shakes a jar for small things. </font><font style="vertical-align: inherit;">For fun, I added a little facial expression to him - he knows how to move his eyebrows: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2x/lm/aw/2xlmaw5tm_hogsuqfuvqwjmeblk.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After the first attempt, the robot tries to find his face again in sight, turns to the person and shakes the bank again. </font><font style="vertical-align: inherit;">But what happens if you leave at this moment:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ko/8x/xz/ko8xxzvzo_owit62gkv8z3wn1ik.gif"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robot</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I took the idea of ‚Äã‚Äãa begging robot from the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">magazine Popular Mechanics</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The prototype authorship of Chris Eckert called Gimme looks very aesthetically pleasing.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/374/8d6/dbc/3748d6dbcb97d04751dacd866eb94e07.jpg" alt="image" width="300" height="300"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I wanted to concentrate more on functionality, so the case was assembled from improvised materials. </font><font style="vertical-align: inherit;">In particular, PVC corners proved to be the most versatile material with which you can connect almost any two parts. </font><font style="vertical-align: inherit;">It seems that at the moment the robot is five percent composed of PVC corners and M3 screws. </font><font style="vertical-align: inherit;">The case itself consists of three laminate platforms on which the head and all the electronics are mounted. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The basis of the robot is </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Raspberry Pi 2B</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and the code is written in C ++ and lies on </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vision</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To perceive reality, the robot uses the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Paspberry Pi Camera Module v2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> camera </font><font style="vertical-align: inherit;">, which can be controlled using the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RaspiCam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> library </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For face detection, I tried several different approaches. The quality of classic detectors from OpenCV did not satisfy me, so in the end I came to a rather non-standard solution. Detection of persons engaged in the neural network, running on the device </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Movidius Neural Compute Stick (NCS)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> under the control framework </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenVINO</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NCS is such a piece of hardware for the effective launch of neural networks, inside of which there are several vector processors specially tailored for this. The device is connected via USB and consumes only 1 Watt of power. Thus, the NCS acts as a co-processor for the Raspberry Pi, which does not pull the neural network. While the NCS is processing the next frame, the Paspberry processor is free for other operations. It is worth noting that for optimal operation of the device, a USB 3.0 interface is required, which is not available on older versions of Raspberry; with USB 2.0 it also works, just slower. Also, in order not to block the Raspberry USB connectors, I connect the NCS to it via a short USB cable. I wrote in detail about working with the Neural Compute Stick </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in my previous article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At first I tried to train</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">own face detector with MobileNet + SSD architecture</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> on open datasets. The detector really worked, but not very stable: with the inevitable deterioration of the shooting conditions (exposure and blurry shots), the quality of the detector sagged greatly. However, after some time, ready-made face detectors appeared in OpenVINO, and I switched to a detector with the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SqueezeNet light + SSD</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> architecture </font><font style="vertical-align: inherit;">, which not only worked better in a variety of shooting conditions, but was also faster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Before uploading the image to the NCS to obtain the predictions of the detector, the image must be preprocessed. The detector of my choice works with color images</font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>300</mn><mo>&amp;#x00D7;</mo><mn>300</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.815ex" height="2.009ex" viewBox="0 -755.5 4225.9 865.1" role="img" focusable="false" style="vertical-align: -0.255ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-33"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-D7" x="1723" y="0"></use><g transform="translate(2724,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-33"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">300</font></font></mn><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√ó</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">300</font></font></mn></math></span></span><script type="math/tex" id="MathJax-Element-1">300 \times 300</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , so the image must first be compressed. To do this, I use the lightest scaling algorithm - the nearest neighbor method (INTER_NEAREST in the OpenCV library). It works a little faster than interpolation methods, and almost does not affect the result. It is also worth paying attention to the order of the image channels: the detector expects the BGR order, so you need to set the same for the camera.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I also tried to separate the video processing into two streams, one of which received the next frame from the camera and processed it, and the other at that time uploaded the previous frame to NCS and waited for the detector results. With this scheme, technically, the processing speed increases, but the delay between receiving the frame and receiving detections for it also increases. Because of this lagging behind reality, monitoring the face becomes only more difficult, so in the end I refused this scheme. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition to actually detecting faces, they also need to be tracked to avoid detector errors. To do this, I use the lightweight tracker </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Simple Online Realtime Tracker (SORT)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . This simple tracker consists of two parts: the </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">Hungarian algorithm</font></a><font style="vertical-align: inherit;"> is used to match objects on adjacent frames</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, and to predict the trajectory of the object, if it suddenly disappears - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kalman filter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">While I was playing with face tracking, I found that the trajectories predicted by the Kalman filter can be very implausible with sudden movements, which again only complicates the process. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Therefore, I turned off the Kalman filter, leaving only the face matching algorithm and the counter of the sequential number of frames on which the face was detected - this way I get rid of the false positives of the detector. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Upper platform, from left to right: camera, servos to control the head and eyebrows, switch, power terminals, Big Red Button.</font></font></i><br>
<img src="https://habrastorage.org/webt/hb/ky/kk/hbkykkpwtkhtfl39aonaop5indg.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Traffic</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For movement, the robot has five servos: two FS5103R continuous-rotation servos spin the wheels; There are two more ordinary FS5109Ms, one of which rotates the head, and the other shakes the can; finally, the little SG90 moves its eyebrows.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To be honest, the SG90 mini-servos seemed like trash to me - one of my servos had the wrong control pulse width, and only one survived among the other four. In fairness, I accidentally took one of the servants with my elbow, but the other two simply could not bear the load (I used to use them for the head and the can). Even the last servo, which got the simplest job - moving the eyebrows, has to poke a stick from time to time so that it does not wedge. With other servos, I did not notice any problems. True, continuous rotation servos sometimes have to be calibrated so that they do not spin in the inactive state - for this there is a small regulator on them that can be turned with a clock-head screwdriver. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Managing servos with Raspberry, it turns out, is not so simple. First, they are controlled by</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pulse-width modulation (PWM / PWM)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and on Raspberry there are only two pins on which </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PWM is supported by hardware</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Secondly, of course, Raspberry will not be able to power the servos, it will not stand this. Fortunately, these problems are solved using an external PWM controller. </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adafruit PCA9685</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is a 16-channel PWM controller that can be controlled via the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I2C interface</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . It is also very convenient that it has terminals for supplying power for servos. Moreover, [theoretically] it is possible to chain up to 62 controllers, while receiving up to 992 control pins - for this you need to assign a unique address to each controller using special jumpers. So if you suddenly need an army of servos - you know what to do.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To control the PCA9685, there is a high-level </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">library</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that acts as a </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">WiringPi</font></a><font style="vertical-align: inherit;"> extension</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Working with this thing is quite convenient - during initialization, it creates 16 virtual pins into which you can write a PWM signal, but first you have to calculate the number of ticks. </font><font style="vertical-align: inherit;">To turn the servo lever to a certain angle in the range [0, 180], you must first translate this angle into the range of control pulse lengths in milliseconds [SERVO_MS_MIN, SERVO_MS_MAX]. </font><font style="vertical-align: inherit;">For all my servos, these values ‚Äã‚Äãare approximately 0.6 ms and 2.4 ms, respectively. </font><font style="vertical-align: inherit;">In general, these values ‚Äã‚Äãcan be found in the servo datasheet, but practice has shown that they can differ, so they may need to be selected. </font><font style="vertical-align: inherit;">Then divide the resulting value by 20 ms (the standard value of the length of the control cycle) and multiply by the maximum number of ticks PCA9685 (4096):</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">driveDegs</span><span class="hljs-params">(<span class="hljs-keyword">float</span> angle, <span class="hljs-keyword">int</span> pin)</span> </span>{
    <span class="hljs-keyword">int</span> ticks = (<span class="hljs-keyword">int</span>) (PCA_MAX_PWM * (angle/<span class="hljs-number">180.0f</span>*(SERVO_MS_MAX-SERVO_MS_MIN) + SERVO_MS_MIN) / <span class="hljs-number">20.0f</span>); <font></font>
    pwmWrite(pin, ticks);<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Similarly, this is done with continuous rotation servos - instead of an angle, we set the speed in the range [-1,1].</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I assembled the robot chassis, as well as the body, from improvised means: I put furniture wheels on the servo-drives of continuous rotation, and a furniture ball support acts as the third wheel. Previously, instead of it, a wheel stood on a rotating support, but with such a chassis it was difficult to make precise turns, so I had to replace it. There is also a small wheel under the can to transfer part of the weight from the servo to the housing. A simple thing that was not obvious to me initially was that servo levers must be fixed with a screw, especially for wheels, so that they do not fall off along the way. Because of such stupidity, I had to redo the chassis once. I also made the robot a wide bumper made of PVC corners so that it doesn't get stuck so often.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now about what you can do about it. Firstly, you can shake the jar and move the eyebrows - for this you just need to turn the servo lever to pre-selected angles. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secondly, you can rotate your head. I didn‚Äôt want the head to spin at the maximum speed of the servo, because it has a camera on it. Therefore, I decided to programmatically reduce the speed: I need to turn the lever a small angle, then wait a few milliseconds - and so on until the desired angle is reached. In this case, it is necessary to remember the current absolute position of the head and each time check whether it has exceeded the permissible limits (on my robot it is in the range of [10, 90] degrees).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thirdly, you can change the direction of movement by changing the speed of rotation of the wheels. </font><font style="vertical-align: inherit;">In the same way, you can rotate the platform, for example, to follow the face. </font><font style="vertical-align: inherit;">The angular speed of rotation depends both on the servos themselves and on their location on the chassis, so it is easier to measure it once and then take it into account when cornering. </font><font style="vertical-align: inherit;">To find the necessary delay between turning on the motors for rotation and turning them off, you need to divide the angle module by the angular velocity. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, you can rotate the head and chassis simultaneously and asynchronously so as not to waste time. </font><font style="vertical-align: inherit;">I do it like this:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-keyword">auto</span> waitRotation = <span class="hljs-built_in">std</span>::async(<span class="hljs-built_in">std</span>::launch::async, rotatePlatform, platformAngle);<font></font>
success = driveHead(headAngle);<font></font>
waitRotation.wait();<font></font>
</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Central platform, from left to right: PCA9685, power bus, Raspberry Pi, MCP3008 ADC</font></font></i><br>
<img src="https://habrastorage.org/webt/bq/q1/8_/bqq18_ilwmgadlcsz0ydepdk44u.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Navigation</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then I did not complicate anything, so the robot uses only two Sharp GP2Y0A02YK infrared range finders for navigation. This is also not so simple, because the sensors are analog, but Raspberry, unlike Arduino, has </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no analog inputs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. This problem is solved by the analog-to-digital converter (ADC / ADC) - I use the 10-bit, 8-channel MCP3008. It is sold as a separate microcircuit, so it had to be soldered to a printed circuit board and pins were also soldered there to make it more convenient to connect. Also, on the advice of my bati, who fumbles more in circuitry, I soldered two capacitors (ceramic and electrolytic) between the legs of the power supply and the ground to absorb the noise from the digital part of the entire circuit. The sensors output no more than three volts at the output, so 3.3v with Raspberry can be connected as a reference ADC voltage (VREF) - the same as for the MCP3008 (VDD) power supply. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The MCP3008 can be controlled via the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SPI</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> interface </font><font style="vertical-align: inherit;">, and for this it‚Äôs even easy to find </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ready-made code on GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Despite this, for convenient work with the ADC, you will need a few dances with a tambourine.</font></font></b>
                        <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> <span class="hljs-title">analogRead</span><span class="hljs-params">(mcp3008Spi &amp;adc, <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> channel)</span>
</span>{
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span> spi_data[<span class="hljs-number">3</span>];
    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> val = <span class="hljs-number">0</span>;<font></font>
<font></font>
    spi_data[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;  <span class="hljs-comment">// start bit</span>
    spi_data[<span class="hljs-number">1</span>] = <span class="hljs-number">0b10000000</span> | ( channel &lt;&lt; <span class="hljs-number">4</span>); <span class="hljs-comment">// mode and channel</span>
    spi_data[<span class="hljs-number">2</span>] = <span class="hljs-number">0</span>; <span class="hljs-comment">// anything</span>
    adc.spiWriteRead(spi_data, <span class="hljs-keyword">sizeof</span>(spi_data));<font></font>
  <font></font>
    <span class="hljs-comment">// read value, combine last two bits of second byte with whole third byte</span>
    val = (spi_data[<span class="hljs-number">1</span>]&lt;&lt; <span class="hljs-number">8</span>) &amp; <span class="hljs-number">0b1100000000</span>; <font></font>
    val |= (spi_data[<span class="hljs-number">2</span>] &amp; <span class="hljs-number">0xff</span>);
    <span class="hljs-keyword">return</span> val;<font></font>
}<font></font>
</code></pre><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Three bytes must be sent to the MCP3008, where the start bit is written in the first byte, and the mode and channel number (0-7) in the second. </font><font style="vertical-align: inherit;">We also get back three bytes, after which we need to glue the two least significant bits of the second byte with all the bits of the third. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that we can get the values ‚Äã‚Äãfrom the sensors, we need to calibrate them, because the two sensors may differ slightly from each other. </font><font style="vertical-align: inherit;">In general, the display from a distance due to the signal strength of these sensors is non-linear and not very simple ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">for more details see datasheet, pdf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Therefore, it is enough to pick up two coefficients, when multiplied by which the sensors will give a value of 1.0 at some meaningful, equal distance.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sensor readings can be quite noisy, especially on difficult obstacles, so I use an exponentially weighted moving average (EWMA) to smooth the signal from each sensor. </font><font style="vertical-align: inherit;">I selected the smoothing parameters by eye, so that the signal does not make noise and does not lag far behind reality. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Front view: bank, rangefinders and bumper.</font></font></i><br>
<img src="https://habrastorage.org/webt/kb/vw/l-/kbvwl-usmln86iqj8aq236ifhpo.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nutrition</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, let's evaluate what current the robot will consume ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">about the current consumption of Raspberry and peripherals</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Raspberry Pi 2B: not less than 350 mA, but more under load (up to 750-820 mA (?));</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Camera: about 250 mA;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neural Compute Stick: declared power consumption of 1 watt, at a voltage of 5 volts on USB it is 200 mA;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IR sensors: 33 mA each ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">datasheet, pdf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> );</font></font></li>
<li>MCP3008:  ,  0.5  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow">, pdf</a>);</li>
<li>PCA9685:  , 6  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow">, pdf</a>);</li>
<li>:  ~150-200   1500-2000     (stall current),          (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"> FS5109M, pdf</a>)</li>
<li>HDMI (   ): 50 ;</li>
<li> +  ( ): ~200 .</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In total, it can be estimated that 1.5-2.5 amperes should be enough, provided that all the servos do not move simultaneously under heavy load. At the same time, Raspberry needs a conditional 5 volts of voltage, and for servos - 4.8-6 volts. It remains to find a power source that meets these requirements. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, I decided to power the robot from 18650 format batteries. If you take two </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ROBITON 3.4 / Li18650 batteries</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (3.6 volts, 3400 mAh, maximum discharge current 4875 mA) and connect them in series, they can produce up to 4.8 amperes at a voltage of 7.2 volts. With a consumption current of 1.5-2.5 amperes, they should be enough for an hour or two. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Batteries, by the way, have a catch: in spite of the indicated form factor 18650, their sizes are far from</font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>18</mn><mo>&amp;#x00D7;</mo><mn>650</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.653ex" height="2.009ex" viewBox="0 -755.5 3725.4 865.1" role="img" focusable="false" style="vertical-align: -0.255ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-38" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-D7" x="1223" y="0"></use><g transform="translate(2223,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-36"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-35" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>18</mn><mo>√ó</mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">650</font></font></mn></math></span></span><script type="math/tex" id="MathJax-Element-2">18 \times 650</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mm - they are several millimeters longer due to the built-in charging control circuit. Because of this, I had to stab the battery compartment with a knife so that they fit there.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It remains only to lower the voltage to 5 volts. For this, I use two separate step-down DC-DC converters</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DFRobot Power Module</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. This piece of iron allows you to lower the voltage at an input voltage of 3.6-25 volts and a voltage difference of at least 0.6 volts. For convenience, it has a switch that allows you to select exactly 5 volts at the output, or you can configure an arbitrary output voltage using a special regulator. I set both converters to 5 volts; one of them feeds Raspberry through a Micro-USB connector, and the second feeds servos through PCA9685 terminals. This is necessary in order to maximize the power supply of the logical and power parts of the robot so that they do not interfere with each other.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the debugging stage, I used a Chinese 9 volt, 2 ampere power supply instead of the batteries, and it was enough for the robot to work - I connected it, like the batteries, to two DC-DC converters. Therefore, for convenience, I made terminals on the robot, to which you can connect a power supply or battery compartment to choose from. This helped a lot when I completely rewrote all the code on ROS, and I had to debug the robot for a long time, including servos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For convenience, I also had to make a "power bus" - in fact, just a piece of the board with three rows of connected pins for ground, 3.3v and 5v, respectively. The bus connects to the corresponding Raspberry pins. Only IR rangefinders are powered from the 5v bus, and MCP3008 and PCA9685 from the 3.3v bus.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And of course, according to the good old tradition, I put the Big Red Button on the robot - when it is pressed, it simply interrupts the entire power circuit. </font><font style="vertical-align: inherit;">It was not necessary to use it for an emergency stop, but turning on the robot with the help of a button is really more convenient. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lower platform, from left to right: battery compartment, NCS, DC-DC converters, servo drives with wheels, rangefinders.</font></font></i><br>
<img src="https://habrastorage.org/webt/od/tf/6b/odtf6b5gksijt0nhbflim7wrh1m.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robot control</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is no Wi-Fi on the Raspberry Pi 2B, so I have to connect via ssh via an Ethernet cable (by the way, this can be done </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">directly from the laptop, without using a router</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). It turns out this scheme: we connect via ssh via the cable, start the robot and pull off the cable. Then it can be returned to its place to access the Raspberry again. There are more elegant solutions, but I decided not to complicate. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So that the robot can be easily stopped without turning off, I added a massive Soviet switch (from a submarine?) To it, when you turn it off, the program ends and the robot stops. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The switch connects to the ground and to one of the Raspberry GPIO pins, and you can read from it using </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the WiringPi library</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<pre><code class="cpp hljs">wiringPiSetup();<font></font>
pinMode(PIN_SWITCH, INPUT);<font></font>
pullUpDnControl(PIN_SWITCH, PUD_UP);<font></font>
<span class="hljs-keyword">bool</span> value = digitalRead(BB_PIN_SWITCH);
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is worth noting that with this connection, the voltage on the pin must be pulled up to 3.3v, and at the same time it will produce a high signal in the open state, and a low signal in the closed state.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Putting it all together</font></font></h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Threads</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Now all of the above needs to be combined into one program that controls the robot. </font><font style="vertical-align: inherit;">In the first version of the robot, I did this using threads ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pthread</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">This version is in the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">master</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> branch </font><font style="vertical-align: inherit;">, but the code there is pretty scary. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The program works in four threads: one thread takes frames from the camera and starts the detector on the NCS; </font><font style="vertical-align: inherit;">the second stream reads data from rangefinders; </font><font style="vertical-align: inherit;">the third thread monitors the switch and sets the global variable </font></font><code>is_running</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to</font></font><code>false</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">if it is off; The main thread is responsible for the robot behavior and servo control. Threads have pointers in common with the main thread, by which they write the results of their work. I restricted the vectors that store information about the faces found by the detector to the mutex, and declared the other, simpler common variables as atomic. To coordinate the flow of the face detector with the main thread, there is a flag </font></font><code>face_processed</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">that is reset when a new result comes from the detector, and rises when the main thread uses this result to select a behavior - this is necessary in order not to process old data that may not be relevant after moving. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The ROS</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
version with streams worked fine, but I started all this in order to learn something, so why not at the same time master</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ros</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ? </font><font style="vertical-align: inherit;">I have been hearing this framework for a long time, and I even had to work a bit with it on a hackathon, so in the end I decided to rewrite all the code on ROS. </font><font style="vertical-align: inherit;">This version of the code lies in the default branch of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ros</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and looks much more decent. </font><font style="vertical-align: inherit;">It is clear that the implementation on ROS will almost certainly be slower than the implementation on the flows due to the overhead of sending messages and everything else - the only question is how much?</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ROS concept</font></font></b>
                        <div class="spoiler_text">ROS (Robot Operating System) ‚Äî     ,             ,   ,        .<br>
<br>
    ,  ,  ,     (node), ,    ,       .<br>
<br>
      (topic)      (message)  ,         -    . <br>
<br>
    ‚Äî   (service).         ,       ,     .      ¬´ ¬ª,    .<br>
<br>
         <code>.msg</code>  <code>.srv</code> .          .<br>
<br>
 ROS    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"> </a>.<br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For my robot, I did not use any ready-made packages with algorithms from ROS, I only designed the robot code in a separate package consisting of five nodes communicating with each other using messages and ROS services. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The simplest node </font></font><code>switch_node</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,, monitors the state of the switch. As soon as the switch turns off, the node begins to spam uninformative messages of the type </font></font><code>bool</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in the topic </font></font><code>terminator</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. This is a signal to the main node that it is time to complete the work. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The second node,, </font></font><code>sensor_node</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">periodically reads the readings of both IR rangefinders and sends them to the topic in </font></font><code>sensor_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">one message. Also, this node is responsible for signal processing: scaling by calibration factors and moving average. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Third knot</font></font><code>camera_node</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">He is responsible for everything related to faces: he takes images from the camera, processes them, receives the results of the detector, passes them through the tracker, and then finds the face closest to the center of the frame - the robot does not use the rest anyway, but you want to make smaller messages. The messages that the node sends to the topic </font></font><code>camera_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">contain the frame number, the fact of having a face (because you also need to know about the absence of a face), the relative coordinates of the upper left corner, the width and height of the face. This is how the description of the type of message in the file looks like </font></font><code>DetectionBox.msg</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="plaintext hljs">int64 count<font></font>
bool present<font></font>
float32 x<font></font>
float32 y<font></font>
float32 width<font></font>
float32 height<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The fourth node,, </font></font><code>servo_node</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">is responsible for the servos. Firstly, it supports a service </font></font><code>servo_action</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">that allows one of the actions to be performed by servos by its number: to put the entire node in its initial state (eyebrows, bank, head, stop the chassis); transfer the head to its initial state; shake the jar; depict with one eyebrow one of three expressions (good, neutral, evil). Secondly, using the service, </font></font><code>servo_speed</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">you can set new speeds for both wheels by sending them in the request. Both services do not return anything. Finally, there is a service </font></font><code>servo_head_platform</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">that allows you to rotate the head and / or chassis a certain angle relative to the current position. This service returns </font></font><code>true</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">if it was possible to turn the head at least partially, and</font></font><code>false</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">otherwise, in the case when the head is already at the border of the permissible angle, and we are trying to turn it even further. </font><font style="vertical-align: inherit;">If both angles in the request are nonzero, the service rotates asynchronously, as indicated above. </font><font style="vertical-align: inherit;">In the main loop, the servo node does nothing. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here, for example, is a description of the service </font></font><code>servo_head_platform</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="plaintext hljs">float32 head_delta<font></font>
float32 platform_delta<font></font>
---<font></font>
bool head_success<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Each of the listed nodes supports a service </font></font><code>terminate_{switch, camera, sensor, servo}</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">with an empty response request, which stops the operation of the node. </font><font style="vertical-align: inherit;">It is implemented in this way:</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Some code</font></font></b>
                        <div class="spoiler_text"><pre><code class="cpp hljs">...
<span class="hljs-built_in">std</span>::<span class="hljs-keyword">atomic_bool</span> is_running; <span class="hljs-comment">// global</span><font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">terminate_node</span><span class="hljs-params">(std_srvs::Empty::Request &amp;req, std_srvs::Empty::Response &amp;ignored)</span> </span>{<font></font>
    is_running = <span class="hljs-literal">false</span>;
    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<font></font>
}<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span> **argv)</span> </span>{<font></font>
    is_running = <span class="hljs-literal">true</span>;<font></font>
    ...<font></font>
    <span class="hljs-keyword">while</span> (is_running &amp;&amp; ros::ok()) {
        <span class="hljs-comment">// do stuff</span><font></font>
    }<font></font>
    ...<font></font>
}<font></font>
</code></pre><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The node has a global variable </font></font><code>is_running</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, the value of which determines the main cycle of the node. The service simply resets this variable, and the main loop is interrupted. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is also a main node </font></font><code>beggar_bot</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in which the basic logic of the robot is implemented. Before the start of the main loop, it subscribes to topics </font></font><code>sensor_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and </font></font><code>camera_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">saves the contents of messages in global variables in callback functions. He is also subscribed to the topic </font></font><code>terminator</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, the callback for which resets the flag </font></font><code>is_running</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, interrupting the main loop. Also, before the cycle starts, the node announces the interfaces for the services of the servo node and waits a few seconds for the other nodes to start up. After the main loop ends, this node calls the services</font></font><code>terminate_{switch, camera, sensor, servo}</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, thus turning off all other nodes, and then turning it off itself. That is, when the switch is turned off, all five nodes complete the operation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Switching to ROS forced me to change the structure of the program quite a lot. For example, earlier it was possible to change the wheel speed with a high frequency, and this worked fine, but the ROS service works an order of magnitude slower, so I had to rewrite the code so that the service was called only when the speed really changes (in "lazy mode"). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ROS also allows you to quite conveniently run all the nodes of the robot. To do this, you need to write </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a .launch launch file</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> listing all the nodes and other attributes of the robot in xml format, and then run the command:</font></font><br>
<br>
<pre><code class="plaintext hljs">roslaunch beggar_bot robot.launch</code></pre><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ROS vs. pthread</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Now, finally, you can compare the speed of the ROS version and the pthread version. </font><font style="vertical-align: inherit;">I do it this way: the thread / node responsible for working with the camera considers its FPS (as the slowest element), provided that everything else also works. </font><font style="vertical-align: inherit;">For the pthread version, I consistently got FPS 9.99 or so, for the ROS version it turned out about 8.3. </font><font style="vertical-align: inherit;">In fact, this is quite enough for such a toy, but the overhead is quite noticeable.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robot behavior</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The idea is quite simple: if the robot sees a person, he must drive up to him and shake the can. Shaking the jar is quite simple and fun, but first you need to get to the person. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is a function </font></font><code>follow_face</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">that, if there is a face in the frame, rotates the chassis and the head of the robot in its direction (only the face closest to the center is taken into account). This is necessary so that the robot always keeps its course on a person, if he is in the frame, and also looks directly in the face when he shakes a jar. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The </font></font><code>camera_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">same variable is used </font><font style="vertical-align: inherit;">to synchronize this function with the topic </font><font style="vertical-align: inherit;">.</font></font><code>face_processed</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, as in the version with streams. The idea is the same - we want to process data only once, because the robot is constantly moving. The function first waits until the callback of the topic with the detections lowers the flag that the last frame has been processed. While she waits, she constantly calls </font></font><code>ros::spinOnce()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to receive new messages (in general, this should be done wherever the program expects new data). If there is a face in the frame, the angles are calculated, which need to rotate the platform and head - this can be done by knowing the relative coordinates of the center of the face and the field of view of the camera horizontally and vertically. After that, you can call the service </font></font><code>servo_head_platform</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and move the robot.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There is one subtle point: information about the position of the face lags behind the actual movement of the face and may lag behind the movements of the robot itself. Therefore, the robot can overestimate the angle of rotation, because of which the head begins to move back and forth with increasing amplitude. To prevent this, I make delays after the move (300 ms), and also skip one frame following the move. For the same purpose, the angles of rotation of the chassis and head are multiplied by a factor of 0.8 (the P-components of the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PID controller</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> make sense </font><font style="vertical-align: inherit;">). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Function</font></font><code>follow_face</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">returns the status of a person. </font><font style="vertical-align: inherit;">A person can: be absent, be close enough to the center, be too far away from the robot; </font><font style="vertical-align: inherit;">another option - when we turned the robot and do not know what happened to the face (in the search process); </font><font style="vertical-align: inherit;">there is still a rare case when the head is on the border, which is why it is impossible to turn to the face. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A rather simple thing happens in the main loop:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Call </font></font><code>follow_face</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">until the person has a certain status (any, except for ‚Äúin the search process‚Äù). </font><font style="vertical-align: inherit;">At the end of this step, the robot will look directly at the face.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If the face is found and it is close: </font></font><br>
 <ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Shake the can;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Find the face again;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If the face is in place, make a good expression with eyebrows and shake the jar again;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If the face has disappeared, make an angry expression with eyebrows;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Turn around, go to the beginning of the cycle.</font></font></li>
</ol><br>
 </li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If there is no person (or it is far away) - navigation around the room:</font></font><br>
 <ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If there are far from obstacles on both sides, drive forward (if the face was found, but turned out to be too far, the robot will go to the person);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If obstacles are close on both sides, make a random turn in the range </font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>90</mn><mo>,</mo><mn>180</mn><mo stretchy=&quot;false&quot;>]</mo><mo>&amp;#x222A;</mo><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>180</mn><mo>,</mo><mo>&amp;#x2212;</mo><mn>90</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.479ex" height="2.634ex" viewBox="0 -809.3 9678.3 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5B" x="0" y="0"></use><g transform="translate(278,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-39"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2C" x="1279" y="0"></use><g transform="translate(1724,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-38" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5D" x="3226" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-222A" x="3726" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5B" x="4616" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2212" x="4895" y="0"></use><g transform="translate(5673,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-38" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2C" x="7175" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2212" x="7620" y="0"></use><g transform="translate(8398,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-39"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5D" x="9399" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>90</mn><mo>,</mo><mn>180</mn><mo stretchy="false">]</mo><mo>‚à™</mo><mo stretchy="false">[</mo><mo>‚àí</mo><mn>180</mn><mo>,</mo><mo>‚àí</mo><mn>90</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-3">[90, 180] \cup [-180, -90]</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If the obstacle is only on one side, turn in the opposite direction at a random angle </font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>90</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.815ex" height="2.634ex" viewBox="0 -809.3 2503.7 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2C" x="779" y="0"></use><g transform="translate(1224,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-39"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5D" x="2225" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>90</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-4">[0, 90]</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If the forward movement continues for too long (possibly stuck), pull back a little and make a random turn in the range </font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>90</mn><mo>,</mo><mn>180</mn><mo stretchy=&quot;false&quot;>]</mo><mo>&amp;#x222A;</mo><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>180</mn><mo>,</mo><mo>&amp;#x2212;</mo><mn>90</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.479ex" height="2.634ex" viewBox="0 -809.3 9678.3 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5B" x="0" y="0"></use><g transform="translate(278,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-39"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2C" x="1279" y="0"></use><g transform="translate(1724,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-38" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5D" x="3226" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-222A" x="3726" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5B" x="4616" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2212" x="4895" y="0"></use><g transform="translate(5673,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-38" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="1001" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2C" x="7175" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-2212" x="7620" y="0"></use><g transform="translate(8398,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-39"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-30" x="500" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/500150/&amp;usg=ALkJrhiFcBvf6uVSmfC_ytT9NT9TcT1SnQ#MJMAIN-5D" x="9399" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>90</mn><mo>,</mo><mn>180</mn><mo stretchy="false">]</mo><mo>‚à™</mo><mo stretchy="false">[</mo><mo>‚àí</mo><mn>180</mn><mo>,</mo><mo>‚àí</mo><mn>90</mn><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></mo></math></span></span><script type="math/tex" id="MathJax-Element-5">[90, 180] \cup [-180, -90]</script><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">; </font></font></li>
</ol><br>
 </li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This algorithm does not claim to be a strong artificial intelligence, however, randomized behavior and a wide bumper allow the robot to get out of almost any position sooner or later.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despite its apparent simplicity, this project covers many non-trivial topics: work with analog sensors, work with PWM, computer vision, coordination of asynchronous tasks. </font><font style="vertical-align: inherit;">Plus, it's just insanely fun. </font><font style="vertical-align: inherit;">Probably, further I will do something more meaningful, but more with a bias in deep learning. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As a bonus - the gallery:</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/el/cw/jd/elcwjdoa21liogjvhakstzg-yru.jpeg"><br>
<br>
<img src="https://habrastorage.org/webt/il/12/fp/il12fpucbbreblnwyb2ojwsfmwu.jpeg"><br>
<br>
<img src="https://habrastorage.org/webt/3w/kr/7m/3wkr7mfjqjo2b_f9kvekia82ztq.jpeg"><br>
<br>
<img src="https://habrastorage.org/webt/z4/3q/wr/z43qwrmlfgwndbi3dw-jnvxzqew.jpeg"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en500140/index.html">"Up to 10 thousand": more than 25 reviews of headphones</a></li>
<li><a href="../en500142/index.html">Manage rights at the facility level</a></li>
<li><a href="../en500144/index.html">David O'Brien (Xirus): Metrics! Metrics! Metrics! Part 1</a></li>
<li><a href="../en500146/index.html">Job search in Germany as a product manager and more. Part 3/5. What you need to do before you start sending out CVs</a></li>
<li><a href="../en500148/index.html">Mikrotik firewall filter: script generating the basis for a filtering policy</a></li>
<li><a href="../en500152/index.html">How I integrated POS-terminal and FR IKKM-Touch in 1C: enterprise</a></li>
<li><a href="../en500154/index.html">Confidential Machine Learning. PySyft Library</a></li>
<li><a href="../en500158/index.html">SwiftUI Interaction with Redux</a></li>
<li><a href="../en500160/index.html">Visual elements</a></li>
<li><a href="../en500162/index.html">Great python sports data processing tutorial</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗾 🤾🏼 🙅🏾 Memastikan ketersediaan tinggi aplikasi dengan Kafka Streaming 🚠 🏺 🤙🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kafka Streams adalah perpustakaan Java untuk menganalisis dan memproses data yang disimpan di Apache Kafka. Seperti halnya platform pemrosesan streami...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Memastikan ketersediaan tinggi aplikasi dengan Kafka Streaming</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488558/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams adalah perpustakaan Java untuk menganalisis dan memproses data yang disimpan di Apache Kafka. </font><font style="vertical-align: inherit;">Seperti halnya platform pemrosesan streaming lainnya, platform ini mampu melakukan pemrosesan data dengan dan / atau tanpa pelestarian status secara real time. </font><font style="vertical-align: inherit;">Dalam posting ini saya akan mencoba menjelaskan mengapa mencapai ketersediaan tinggi (99,99%) bermasalah di Aliran Kafka dan apa yang dapat kita lakukan untuk mencapainya.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apa yang perlu kita ketahui</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sebelum menjelaskan masalah dan solusi yang mungkin, mari kita lihat konsep dasar Kafka Streams. </font><font style="vertical-align: inherit;">Jika Anda telah bekerja dengan Kafka API untuk Konsumen / Produsen, maka sebagian besar paradigma ini sudah Anda kenal. </font><font style="vertical-align: inherit;">Pada bagian berikut, saya akan mencoba menjelaskan dalam beberapa kata penyimpanan data dalam partisi, penyeimbangan kembali kelompok konsumen dan bagaimana konsep dasar klien Kafka masuk ke perpustakaan Kafka Streams.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Mempartisi Data</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di dunia Kafka, aplikasi produsen mengirim data sebagai pasangan kunci-nilai ke topik tertentu. </font><font style="vertical-align: inherit;">Topiknya sendiri dibagi menjadi satu atau lebih partisi di broker Kafka. </font><font style="vertical-align: inherit;">Kafka menggunakan kunci pesan untuk menunjukkan di partisi mana data harus ditulis. </font><font style="vertical-align: inherit;">Akibatnya, pesan dengan kunci yang sama selalu berakhir di partisi yang sama.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aplikasi konsumen diatur ke dalam kelompok konsumen, dan setiap kelompok dapat memiliki satu atau lebih contoh dari konsumen. </font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setiap instance dari konsumen dalam grup konsumen bertanggung jawab untuk memproses data dari sekumpulan partisi unik dari topik input.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Instans konsumen pada dasarnya adalah cara meningkatkan pengolahan dalam kelompok konsumen Anda.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Menyeimbangkan Kelompok Konsumen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang kami katakan sebelumnya, setiap instance dari grup konsumen menerima sekumpulan partisi unik dari mana ia mengkonsumsi data. </font><font style="vertical-align: inherit;">Setiap kali konsumen baru bergabung dengan grup, penyeimbangan harus dilakukan sehingga ia mendapat partisi. </font><font style="vertical-align: inherit;">Hal yang sama terjadi ketika konsumen meninggal, seluruh konsumen harus mengambil partisi untuk memastikan bahwa semua partisi diproses.</font></font><br>
<cut></cut><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada awal posting ini kami berkenalan dengan fakta bahwa perpustakaan Kafka Streams dibangun berdasarkan API dari produsen dan konsumen dan pemrosesan data diatur dengan cara yang sama dengan solusi standar pada Kafka. Dalam konfigurasi Streaming Kafka, bidang </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> setara dengan </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">group.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">di API konsumen. Kafka Streams pra-membuat sejumlah utas dan masing-masing melakukan pemrosesan data dari satu atau lebih partisi dari topik masukan. Berbicara dalam terminologi API Konsumen, aliran dasarnya bertepatan dengan instance dari Konsumen dari grup yang sama. Thread adalah cara utama untuk menskala pemrosesan data di Kafka Streaming, ini dapat dilakukan secara vertikal dengan menambah jumlah utas untuk setiap aplikasi Streaming Kafka pada satu mesin, atau secara horizontal dengan menambahkan mesin tambahan dengan application.id yang sama. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bb7/bd3/8ed/bb7bd38edd33f26a146c12a1dea385b5.jpg" alt="gambar"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sumber: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kafka.apache.org/21/documentation/streams/architecture</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ada banyak elemen lagi di Kafka Streaming, seperti tugas, pemrosesan topologi, model threading, dll, yang tidak akan kita bahas dalam posting ini. </font><font style="vertical-align: inherit;">Informasi lebih lanjut dapat ditemukan di </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sini.</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: State Storage</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam pemrosesan aliran, ada operasi dengan dan tanpa pengawetan negara. </font><font style="vertical-align: inherit;">Keadaan inilah yang memungkinkan aplikasi untuk mengingat informasi yang diperlukan yang melampaui ruang lingkup catatan yang saat ini sedang diproses.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Operasi negara, seperti penghitungan, segala jenis agregasi, penggabungan, dll., Jauh lebih rumit. Ini disebabkan oleh fakta bahwa hanya memiliki satu catatan, Anda tidak dapat menentukan status terakhir (katakanlah, hitung) untuk kunci yang diberikan, jadi Anda perlu menyimpan status aliran Anda di aplikasi Anda. Seperti yang telah kita bahas sebelumnya, setiap utas memproses sekumpulan partisi unik, oleh karena itu, utas hanya memproses sebagian dari seluruh kumpulan data. Ini berarti bahwa setiap utas aplikasi Kafka Streaming dengan application.id yang sama mempertahankan statusnya sendiri yang terisolasi. Kami tidak akan merinci tentang bagaimana negara terbentuk di Kafka Streaming, tetapi penting untuk memahami bahwa negara dipulihkan menggunakan topik log perubahan dan disimpan tidak hanya pada disk lokal, tetapi juga di Kafka Broker.Menyimpan status perubahan log di Kafka Broker sebagai topik terpisah dibuat tidak hanya untuk toleransi kesalahan, tetapi juga agar Anda dapat dengan mudah menggunakan contoh-contoh baru Streaming Kafka dengan application.id yang sama. Karena status disimpan sebagai topik perubahan-log di sisi pialang, instance baru dapat memuat statusnya sendiri dari topik ini.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Informasi lebih lanjut tentang penyimpanan negara dapat ditemukan di </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sini</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mengapa ketersediaan tinggi bermasalah dengan Kafka Streaming?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami meninjau konsep dasar dan prinsip-prinsip pemrosesan data dengan Kafka Streaming. </font><font style="vertical-align: inherit;">Sekarang mari kita coba menggabungkan semua bagian bersama-sama dan menganalisis mengapa mencapai ketersediaan tinggi bisa bermasalah. </font><font style="vertical-align: inherit;">Dari bagian sebelumnya, kita harus ingat:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Data dalam topik Kafka dibagi menjadi beberapa partisi, yang didistribusikan antara aliran Kafka Streaming.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aplikasi Kafka Streaming dengan application.id yang sama, pada kenyataannya, satu kelompok konsumen, dan masing-masing utasnya adalah contoh terpisah dari konsumen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Untuk operasi negara, utas mempertahankan negaranya sendiri, yang "dicadangkan" oleh topik Kafka dalam bentuk log perubahan.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br>
<h2>TransferWise SPaaS (Stream Processing as a Service)</h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sebelum menyoroti esensi dari posting ini, izinkan saya terlebih dahulu memberi tahu Anda apa yang kami buat di TransferWise dan mengapa ketersediaan tinggi sangat penting bagi kami. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di TransferWise, kami memiliki beberapa node untuk pemrosesan streaming, dan setiap node berisi beberapa instance Kafka Streams untuk setiap tim produk. Contoh aliran Kafka yang dirancang untuk tim pengembangan spesifik memiliki application.id khusus dan biasanya memiliki lebih dari 5 utas. Secara umum, tim biasanya memiliki 10-20 utas (setara dengan jumlah contoh konsumen) di seluruh kluster. Aplikasi yang digunakan pada node mendengarkan pada topik input dan melakukan beberapa jenis operasi dengan dan tanpa status pada data input dan menyediakan pembaruan data real-time untuk layanan hilir berikutnya.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tim produk perlu memperbarui data yang dikumpulkan secara real time. </font><font style="vertical-align: inherit;">Ini diperlukan untuk memberi pelanggan kami kemampuan untuk mentransfer uang secara instan. </font><font style="vertical-align: inherit;">SLA biasa kami:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pada hari tertentu, 99,99% dari data agregat harus tersedia dalam waktu kurang dari 10 detik.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk memberi Anda ide, selama pengujian stres, Kafka Streaming dapat memproses dan mengagregasi 20.085 pesan input per detik. </font><font style="vertical-align: inherit;">Dengan demikian, 10 detik SLA di bawah beban normal terdengar cukup dapat dicapai. </font><font style="vertical-align: inherit;">Sayangnya, SLA kami tidak tercapai selama pembaruan bergulir dari node yang digunakan aplikasi, dan di bawah ini saya akan menjelaskan mengapa ini terjadi.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pembaruan node geser</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di TransferWise, kami sangat percaya pada pengiriman perangkat lunak kami yang berkelanjutan dan biasanya merilis versi baru layanan kami beberapa kali sehari. </font><font style="vertical-align: inherit;">Mari kita lihat contoh pembaruan layanan berkelanjutan sederhana dan lihat apa yang terjadi selama proses rilis. </font><font style="vertical-align: inherit;">Sekali lagi, kita harus ingat bahwa:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Data dalam topik Kafka dibagi menjadi beberapa partisi, yang didistribusikan antara aliran Kafka Streaming.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aplikasi Kafka Streaming dengan application.id yang sama, pada kenyataannya, satu kelompok konsumen, dan masing-masing utasnya adalah contoh terpisah dari konsumen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk operasi negara, utas mempertahankan negaranya sendiri, yang "dicadangkan" oleh topik Kafka dalam bentuk log perubahan.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Proses rilis pada satu node biasanya membutuhkan delapan hingga sembilan detik. </font><font style="vertical-align: inherit;">Selama rilis, instance Kafka Streams pada node "reboot dengan lembut". </font><font style="vertical-align: inherit;">Jadi, untuk satu simpul, waktu yang diperlukan untuk memulai kembali layanan dengan benar adalah sekitar delapan hingga sembilan detik. </font><font style="vertical-align: inherit;">Jelas, mematikan instance Kafka Streams pada node menyebabkan penyeimbangan kembali kelompok konsumen. </font><font style="vertical-align: inherit;">Karena data dipartisi, semua partisi yang termasuk dalam instance bootable harus didistribusikan antara aplikasi Kafka Streaming aktif dengan application.id yang sama. </font><font style="vertical-align: inherit;">Ini juga berlaku untuk data agregat yang telah disimpan ke disk. </font><font style="vertical-align: inherit;">Sampai proses ini selesai, data tidak akan diproses.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Replika siaga</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk mengurangi waktu penyeimbangan ulang untuk aplikasi Kafka Streams, ada konsep replika cadangan, yang didefinisikan dalam konfigurasi sebagai num.standby.replicas. Replika cadangan adalah salinan dari toko negara bagian setempat. Mekanisme ini memungkinkan untuk meniru toko negara dari satu instance Kafka Streams ke yang lain. Ketika utas Kafka Streams mati karena alasan apa pun, durasi proses pemulihan negara dapat diminimalkan. Sayangnya, untuk alasan yang akan saya jelaskan di bawah ini, bahkan replika cadangan tidak akan membantu dengan pembaruan layanan bergulir.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Misalkan kita memiliki dua contoh Kafka Streaming pada dua mesin yang berbeda: node-a dan node-b. </font><font style="vertical-align: inherit;">Untuk setiap instance Kafka Streaming, num.standby.replicas = 1 ditunjukkan pada 2 node ini. Dengan konfigurasi ini, setiap instance Kafka Streaming mempertahankan salinan repositori pada node lain. </font><font style="vertical-align: inherit;">Selama pembaruan bergulir, kami memiliki situasi berikut:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Versi layanan yang baru telah digunakan untuk node-a.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Contoh Streaming Kafka pada node-a dinonaktifkan.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penyeimbangan telah dimulai.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Repositori dari node-a telah direplikasi ke node-b, karena kami menetapkan konfigurasi num.standby.replicas = 1.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">node-b sudah memiliki salinan bayangan node-a, sehingga proses penyeimbangan terjadi hampir secara instan.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">simpul-a mulai lagi.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> simpul-a bergabung dengan sekelompok konsumen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pialang Kafka melihat contoh baru Kafka Streaming dan mulai menyeimbangkan kembali.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang bisa kita lihat, num.standby.replicas hanya membantu dalam skenario pemadaman total node. </font><font style="vertical-align: inherit;">Ini berarti bahwa jika simpul-a jatuh, maka simpul-b dapat terus bekerja dengan benar hampir secara instan. </font><font style="vertical-align: inherit;">Tetapi dalam situasi pembaruan yang bergulir, setelah terputus, node-a akan bergabung dengan grup lagi, dan langkah terakhir ini akan menyebabkan penyeimbangan kembali. </font><font style="vertical-align: inherit;">Ketika node-a bergabung dengan grup konsumen setelah reboot, itu akan dianggap sebagai instance baru dari konsumen. </font><font style="vertical-align: inherit;">Sekali lagi, kita harus ingat bahwa pemrosesan data real-time berhenti sampai sebuah instance baru mengembalikan statusnya dari topik perubahan-log.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Harap perhatikan bahwa penyeimbangan ulang partisi saat instance baru bergabung ke grup tidak berlaku untuk Kafka Streams API, karena beginilah cara protokol kelompok konsumen Apache Kafka bekerja.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prestasi: Ketersediaan Tinggi dengan Kafka Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Terlepas dari kenyataan bahwa pustaka klien Kafka tidak menyediakan fungsionalitas bawaan untuk masalah yang disebutkan di atas, ada beberapa trik yang dapat digunakan untuk mencapai ketersediaan cluster yang tinggi selama pembaruan yang bergulir. </font><font style="vertical-align: inherit;">Gagasan di balik replika cadangan tetap valid, dan memiliki mesin cadangan saat waktunya tepat adalah solusi yang baik yang kami gunakan untuk memastikan ketersediaan tinggi jika terjadi kegagalan.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Masalah dengan pengaturan awal kami adalah bahwa kami memiliki satu kelompok konsumen untuk semua tim di semua node. </font><font style="vertical-align: inherit;">Sekarang, alih-alih satu kelompok konsumen, kami memiliki dua, dan yang kedua bertindak sebagai kelompok "panas". </font><font style="vertical-align: inherit;">Dalam prod, node memiliki variabel khusus CLUSTER_ID, yang ditambahkan ke application.id dari contoh Kafka Streams. </font><font style="vertical-align: inherit;">Berikut ini contoh konfigurasi Spring Boot application.yml:</font></font><div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.yml</font></font></b><div class="spoiler_text"><code>spring.profiles: production<br>
streaming-pipelines:<br>
 team-a-stream-app-id: "${CLUSTER_ID}-team-a-stream-app"<br>
 team-b-stream-app-id: "${CLUSTER_ID}-team-b-stream-app"</code><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada satu titik waktu, hanya satu dari cluster dalam mode aktif, masing-masing, cluster cadangan tidak mengirim pesan secara real time ke layanan mikro hilir. Selama rilis rilis, cluster cadangan menjadi aktif, yang memungkinkan untuk pembaruan yang bergulir di cluster pertama. Karena ini adalah kelompok konsumen yang sangat berbeda, pelanggan kami bahkan tidak melihat adanya pelanggaran dalam pemrosesan, dan layanan selanjutnya terus menerima pesan dari gugus yang baru-baru ini aktif. Salah satu kelemahan yang jelas dari menggunakan kelompok cadangan pelanggan adalah biaya overhead tambahan dan konsumsi sumber daya, tetapi, bagaimanapun, arsitektur ini memberikan jaminan tambahan, kontrol dan toleransi kesalahan dari sistem pemrosesan aliran kami.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selain menambahkan cluster tambahan, ada juga trik yang dapat mengurangi masalah dengan penyeimbangan berulang.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tingkatkan group.initial.rebalance.delay.ms</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dimulai dengan Kafka 0.11.0.0, grup konfigurasi.initial.rebalance.delay.ms telah ditambahkan. </font><font style="vertical-align: inherit;">Menurut dokumentasi, pengaturan ini bertanggung jawab untuk:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jumlah waktu dalam milidetik yang dimiliki GroupCoordinator akan menunda penyeimbangan awal konsumen grup.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Misalnya, jika kita menetapkan 60.000 milidetik dalam pengaturan ini, maka dengan pembaruan yang bergulir, kita mungkin memiliki jendela kecil untuk rilis rilis. </font><font style="vertical-align: inherit;">Jika instance Kafka Streaming berhasil me-restart di jendela waktu ini, tidak ada penyeimbangan ulang akan dipanggil. </font><font style="vertical-align: inherit;">Harap perhatikan bahwa data yang bertanggung jawab atas kejadian aliran Kafka yang dimulai kembali akan terus tidak tersedia hingga node kembali ke mode online. </font><font style="vertical-align: inherit;">Misalnya, jika sebuah instance reboot membutuhkan waktu sekitar delapan detik, Anda akan memiliki downtime delapan detik untuk data yang menjadi tanggung jawab instance ini. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Perlu dicatat bahwa kelemahan utama dari konsep ini adalah bahwa jika terjadi kegagalan simpul, Anda akan menerima penundaan tambahan satu menit selama pemulihan, dengan mempertimbangkan konfigurasi saat ini.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mengecilkan ukuran segmen dalam topik log perubahan</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keterlambatan besar dalam menyeimbangkan aliran Kafka adalah karena pemulihan toko-toko negara dari topik perubahan-log. Topik log perubahan adalah topik terkompresi, yang memungkinkan Anda untuk menyimpan catatan terbaru untuk kunci tertentu dalam topik. Saya akan menjelaskan secara singkat konsep ini di bawah ini. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Topik dalam Kafka Broker diorganisasikan dalam segmen. Saat segmen mencapai ukuran ambang yang dikonfigurasi, segmen baru dibuat dan yang sebelumnya dikompresi. Secara default, ambang ini diatur ke 1 GB. Seperti yang Anda ketahui, struktur data utama yang mendasari topik Kafka dan partisi mereka adalah struktur log dengan penulisan maju, yaitu, ketika pesan dikirim ke topik, mereka selalu ditambahkan ke segmen "aktif" terakhir, dan kompresi tidak sedang terjadi.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Oleh karena itu, sebagian besar status penyimpanan yang disimpan dalam changelog selalu dalam file "segmen aktif" dan tidak pernah dikompres, menghasilkan jutaan pesan changelog yang tidak terkompresi. </font><font style="vertical-align: inherit;">Untuk Kafka Streaming, ini berarti bahwa selama penyeimbangan kembali, ketika instance Kafka Streaming memulihkan keadaannya dari topik changelog, ia perlu membaca banyak entri yang berlebihan dari topik changelog. </font><font style="vertical-align: inherit;">Karena toko-toko negara hanya peduli pada keadaan terakhir, dan bukan tentang sejarah, waktu pemrosesan ini terbuang sia-sia. </font><font style="vertical-align: inherit;">Mengurangi ukuran segmen akan menyebabkan kompresi data yang lebih agresif, sehingga contoh baru aplikasi Kafka Streaming dapat pulih lebih cepat.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kesimpulan</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Meskipun Kafka Streaming tidak menyediakan kemampuan bawaan untuk menyediakan ketersediaan tinggi selama pembaruan layanan bergulir, ini masih dapat dilakukan di tingkat infrastruktur. </font><font style="vertical-align: inherit;">Kita harus ingat bahwa Kafka Streams bukan "kerangka kerja klaster" tidak seperti Apache Flink atau Apache Spark. </font><font style="vertical-align: inherit;">Ini adalah perpustakaan Java ringan yang memungkinkan pengembang untuk membuat aplikasi yang dapat diskalakan untuk mengalirkan data. </font><font style="vertical-align: inherit;">Meskipun demikian, ini menyediakan blok bangunan yang diperlukan untuk mencapai tujuan streaming yang ambisius seperti ketersediaan "99,99%".</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id488544/index.html">Hapus cakupan kode dari aplikasi Node.JS yang sudah berjalan</a></li>
<li><a href="../id488546/index.html">Retas Kotak. Panduan JSON. Kerentanan dalam Json.Net dan LPE melalui SeImpersonatePrivilege</a></li>
<li><a href="../id488548/index.html">Eksperimen: cara belajar membuat teks populer dalam bahasa Inggris (dan mengapa Habrist yang berbahasa Inggris sangat sedikit membaca)</a></li>
<li><a href="../id488550/index.html">Yang ingin membuat koperasi keluar dari raksasa IT</a></li>
<li><a href="../id488552/index.html">Apple FAS dan Pengembang Kontrol Orang Tua</a></li>
<li><a href="../id488560/index.html">Hosting bot Telegram gratis di Google Cloud Platform</a></li>
<li><a href="../id488564/index.html">Jaringan saraf pertama Anda pada unit pemrosesan grafis (GPU). Panduan Pemula</a></li>
<li><a href="../id488566/index.html">Bagaimana seorang insinyur QA menyelamatkan satu hari penuh dengan menghubungkan AutoTests di Visual Studio dan Uji IT</a></li>
<li><a href="../id488568/index.html">Apakah jaringan saraf memimpikan uang listrik?</a></li>
<li><a href="../id488570/index.html">Bagaimana Dinas Rahasia AS mengacaukan RPG cyberpunk dengan buku teks untuk peretas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî¶ üíí ‚òÅÔ∏è Los investigadores est√°n desarrollando un enfoque para reducir el sesgo en los conjuntos de datos de visi√≥n por computadora üòß üòâ üë®üèª‚Äçüé®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Se prepar√≥ una traducci√≥n del art√≠culo espec√≠ficamente para estudiantes del curso de Visi√≥n por computadora . 
 
 14 de febrero de 2020 
 Universidad ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Los investigadores est√°n desarrollando un enfoque para reducir el sesgo en los conjuntos de datos de visi√≥n por computadora</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/498046/"><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se prepar√≥ una traducci√≥n del art√≠culo espec√≠ficamente para estudiantes del curso de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visi√≥n por computadora</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font></i></b><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14 de febrero de 2020 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Universidad de Princeton, Departamento de Ingenier√≠a.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/7l/rc/oe/7lrcoe52n2bvvynvhjwhmhhprx4.png"><br>
<hr><br>
<blockquote><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resumen:</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para resolver los problemas de sesgo en la inteligencia artificial, los cient√≠ficos inform√°ticos han desarrollado m√©todos para obtener conjuntos de datos m√°s confiables que contienen im√°genes de personas. Los investigadores est√°n ofreciendo mejoras a ImageNet, una base de datos de m√°s de 14 millones de im√°genes, que ha desempe√±ado un papel clave en el desarrollo de la visi√≥n por computadora durante la √∫ltima d√©cada.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ImageNet, que incluye im√°genes de objetos, paisajes y, en particular, personas, sirve como fuente de datos de capacitaci√≥n para investigadores que crean algoritmos de aprendizaje autom√°tico que clasifican im√°genes o reconocen elementos individuales en ellos. La escala sin precedentes de ImageNet requer√≠a la recopilaci√≥n y anotaci√≥n automatizadas de im√°genes mediante crowdsourcing. Si bien la comunidad de investigaci√≥n rara vez usaba la categor√≠a de im√°genes de personas de la base de datos, el equipo de ImageNet trabaj√≥ para eliminar el sesgo y una serie de otros problemas asociados con las im√°genes de personas que son consecuencias involuntarias del dise√±o de ImageNet.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Hoy en d√≠a, la visi√≥n por computadora funciona lo suficientemente bien como para implementarse en todas partes en una variedad de contextos", dijo la coautora Olga Russakovskaya, profesora asociada de ciencias de la computaci√≥n en Princeton. "Esto significa que ahora es el momento de hablar sobre c√≥mo afecta al mundo y pensar sobre los problemas de credibilidad".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En un nuevo art√≠culo, el equipo de ImageNet identific√≥ sistem√°ticamente conceptos no visuales y categor√≠as ofensivas, como las caracter√≠sticas raciales y sexuales, para las categor√≠as de im√°genes humanas de ImageNet y sugiri√≥ eliminarlas de la base de datos. Los investigadores tambi√©n han desarrollado una herramienta que permite a los usuarios identificar y obtener conjuntos de im√°genes de personas que est√°n equilibradas por edad, g√©nero y color de piel, a fin de facilitar algoritmos apropiados para clasificar de manera m√°s confiable los rostros de las personas y sus acciones en las im√°genes. Los investigadores presentaron su trabajo el 30 de enero en una conferencia sobre la veracidad, fiabilidad y transparencia de la Asociaci√≥n de Tecnolog√≠a Inform√°tica en Barcelona, ‚Äã‚ÄãEspa√±a.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Es muy importante llevar a la discusi√≥n la atenci√≥n de laboratorios e investigadores con experiencia t√©cnica fundamental", contin√∫a Russakovskaya. "Dado el hecho de que necesitamos recopilar datos a una escala colosal, y el hecho de que esto se lograr√° a trav√©s del crowdsourcing (porque es la tuber√≠a m√°s eficiente y bien probada), surge la pregunta: ¬øc√≥mo hacemos esto para garantizar la mayor fiabilidad sin pisar un rastrillo familiar? Este art√≠culo se centra principalmente en soluciones de dise√±o ".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un grupo de inform√°ticos en Princeton y Stanford lanz√≥ ImageNet en 2009 como un recurso para investigadores y educadores. El graduado y profesor de Princeton, Fay-Fay Lee, ahora profesor de inform√°tica en Stanford, dirigi√≥ la iniciativa. Para alentar a los investigadores a crear mejores algoritmos de visi√≥n por computadora usando ImageNet, el equipo tambi√©n lanz√≥ el Desaf√≠o de reconocimiento visual a gran escala ImageNet. La competencia se centr√≥ principalmente en el reconocimiento de objetos utilizando 1000 categor√≠as de im√°genes, de las cuales solo tres inclu√≠an personas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Algunos de los problemas de confiabilidad en ImageNet provienen de la tuber√≠a utilizada para crear la base de datos. Sus categor√≠as de im√°genes est√°n tomadas de WordNet, una antigua base de datos de palabras en ingl√©s utilizadas para la investigaci√≥n del procesamiento del lenguaje natural. Los creadores de ImageNet tomaron prestados sustantivos de WordNet, algunos de los cuales, aunque son t√©rminos verbales bien definidos, est√°n mal traducidos a un diccionario visual. Por ejemplo, los t√©rminos que describen la religi√≥n o el origen geogr√°fico de una persona solo pueden extraer los resultados de b√∫squeda de im√°genes m√°s destacados, lo que puede generar algoritmos que refuerzan los estereotipos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un proyecto de arte reciente llamado ImageNet Roulette ha llamado la atenci√≥n sobre estos temas. El proyecto, lanzado en septiembre de 2019 como parte de una exposici√≥n de arte dedicada a los sistemas de reconocimiento de im√°genes, utiliz√≥ las im√°genes de personas de ImageNet para entrenar un modelo de inteligencia artificial que clasificaba a las personas con palabras basadas en la imagen presentada. Los usuarios pueden subir su imagen y obtener una etiqueta basada en este modelo. Muchas de las clasificaciones eran ofensivas o simplemente infundadas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La principal innovaci√≥n que permiti√≥ a los creadores de ImageNet acumular una base de datos tan grande de im√°genes etiquetadas fue el uso de crowdsourcing, en particular la plataforma Amazon Mechanical Turk (MTurk), en la que se pagaba a los empleados para verificar las im√°genes candidatas. Este enfoque, aunque fue revolucionario, fue sin embargo imperfecto, lo que condujo a algunas categor√≠as sesgadas e inapropiadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Cuando le pides a la gente que verifique las im√°genes seleccionando entre una amplia gama de candidatos, las personas sienten la presi√≥n de elegir algo, y estas im√°genes tienden a tener caracter√≠sticas distintivas o estereotipadas", dice el autor principal Kayu Young, un graduado en inform√°tica .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el curso del estudio, Jan y sus colegas primero filtraron categor√≠as de personas potencialmente abusivas o sensibles de ImageNet. Consideraron ofensivo las categor√≠as que conten√≠an blasfemias o insultos raciales o de g√©nero; Las categor√≠as sensibles inclu√≠an, por ejemplo, la clasificaci√≥n de personas seg√∫n la orientaci√≥n sexual o la religi√≥n. Para anotar las categor√≠as, reclutaron a 12 estudiantes de posgrado de diferentes √°mbitos de la vida, orden√°ndoles que marcaran la categor√≠a como sensible si no est√°n seguros. Entonces excluyeron 1593 categor√≠as, aproximadamente el 54% de las 2932 categor√≠as de personas en ImageNet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Luego, los investigadores recurrieron a los empleados de MTurk en busca de ayuda, de modo que calificaron las "im√°genes" de las categor√≠as aceptables restantes en una escala de 1 a 5. La selecci√≥n de categor√≠as con una calificaci√≥n de im√°genes de 4 o m√°s llev√≥ al hecho de que solo 158 categor√≠as se clasificaron como aceptables y suficientemente figurativas. Incluso este conjunto de categor√≠as cuidadosamente filtrado conten√≠a m√°s de 133,000 im√°genes, una gran cantidad de ejemplos para ense√±ar algoritmos de visi√≥n por computadora.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dentro de estas 158 categor√≠as, los investigadores estudiaron la representaci√≥n demogr√°fica de las personas en im√°genes para evaluar el nivel de sesgo en ImageNet y desarrollar un enfoque para crear conjuntos de datos m√°s apropiados. El contenido de ImageNet proviene principalmente de motores de b√∫squeda orientados a im√°genes como Flickr. Los motores de b√∫squeda, en general, tienden a arrojar resultados que representan a hombres, personas de piel clara y adultos de 18 a 40 a√±os en mayor medida. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"La gente ha descubierto que los resultados de b√∫squeda de im√°genes est√°n muy sesgados en t√©rminos de distribuci√≥n demogr√°fica, por lo que ImageNet tambi√©n tiene una distribuci√≥n sesgada", dice Young. "En este art√≠culo, intentamos evaluar el nivel de sesgo y tambi√©n proponer un m√©todo que equilibrara la distribuci√≥n".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los investigadores han identificado y revisado tres atributos que est√°n protegidos por las leyes antidiscriminatorias de los Estados Unidos: color de piel, g√©nero y edad. Se pidi√≥ a los trabajadores de MTurk que anotaran cada atributo de cada persona en la imagen. Clasificaron el color de la piel como claro, medio u oscuro; y por edad como ni√±os (menores de 18 a√±os), adultos de 18 a 40 a√±os, adultos de 40 a 65 a√±os o adultos mayores de 65 a√±os. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La clasificaci√≥n de g√©nero inclu√≠a hombres, mujeres y g√©nero indefinido, una forma de incluir personas con diferentes expresiones de g√©nero, as√≠ como anotar im√°genes en las que el g√©nero no puede ser percibido por signos visuales (como im√°genes de muchos ni√±os o buzos).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un an√°lisis de las anotaciones mostr√≥ que, como en los resultados de b√∫squeda, el contenido de ImageNet refleja un sesgo significativo. Las personas marcadas como negras, las mujeres y los adultos mayores de 40 a√±os estaban subrepresentados en la mayor√≠a de las categor√≠as.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aunque el proceso de anotaci√≥n inclu√≠a control de calidad y requer√≠a que los anotadores llegaran a un consenso, debido a las preocupaciones sobre el da√±o potencial de las anotaciones incorrectas, los investigadores decidieron no emitir anotaciones demogr√°ficas para im√°genes individuales. En cambio, desarrollaron una herramienta basada en la web que permite a los usuarios recuperar un conjunto de im√°genes que est√°n equilibradas demogr√°ficamente de la manera especificada por el usuario. Por ejemplo, una colecci√≥n completa de im√°genes en la categor√≠a de programador puede incluir aproximadamente el 90% de los hombres y el 10% de las mujeres, mientras que en los Estados Unidos aproximadamente el 20% de los programadores son mujeres. El investigador puede usar la nueva herramienta para obtener un conjunto de im√°genes de programadores que representan el 80% de los hombres y el 20% de las mujeres, o incluso de forma individual, seg√∫n los objetivos del investigador.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"No queremos hablar sobre c√≥mo equilibrar la demograf√≠a, porque no es un problema muy simple", dice Young. ‚ÄúLa distribuci√≥n puede ser diferente en diferentes partes del mundo; por ejemplo, la distribuci√≥n de los colores de la piel en los EE. UU. Es diferente de la distribuci√≥n en los pa√≠ses asi√°ticos. Por lo tanto, dejamos esta pregunta a nuestro usuario y simplemente proporcionamos una herramienta para extraer un subconjunto equilibrado de im√°genes ". </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El equipo de ImageNet est√° trabajando actualmente en actualizaciones t√©cnicas de su equipo y la base de datos en s√≠, adem√°s de implementar el filtrado facial y la herramienta de reequilibrio desarrollada en este estudio. ImageNet pronto volver√° a emitirse con estas actualizaciones y una solicitud de comentarios de la comunidad de investigadores de visi√≥n artificial.</font></font><br>
 <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton Ph.D. Clint Kinami y profesor asociado de ciencias de la computaci√≥n, Jia Dang, coautor con Young, Lee y Russakovskaya. </font><font style="vertical-align: inherit;">El estudio fue apoyado por la National Science Foundation. </font></font><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fuente: </font></font></b><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Materiales</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> proporcionados por </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">el Departamento de Ingenier√≠a, Universidad de Princeton</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Original escrito por Molly Charlach. </font><font style="vertical-align: inherit;">P </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nota: El contenido puede modificarse por estilo y longitud. </font></font></i><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Enlace:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Kaiyu Yang, Klint Qinami, Li Fei-Fei, Jia Deng, Olga Russakovsky. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hacia conjuntos de datos m√°s justos: filtrado y equilibrio de la distribuci√≥n del sub√°rbol de personas en la jerarqu√≠a de ImageNet. </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Actas de la Conferencia 2020 sobre equidad, responsabilidad y transparencia, 2020 DOI: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10.1145 / 3351095.3375709</font></font></a><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aprende m√°s sobre el curso</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es498032/index.html">C√°lculo r√°pido de f√≥rmulas de Excel en C #</a></li>
<li><a href="../es498034/index.html">El avi√≥n de dise√±o moderno est√° protegido contra amenazas biol√≥gicas (COVID-19) mejor de lo que piensas</a></li>
<li><a href="../es498036/index.html">Mark Andriessen: es hora de crear para nosotros mismos (es hora de construir)</a></li>
<li><a href="../es498038/index.html">El resumen de materiales frescos del mundo del front-end para la √∫ltima semana No. 411 (13-19 de abril de 2020)</a></li>
<li><a href="../es498042/index.html">Analizar, no validar</a></li>
<li><a href="../es498050/index.html">La cultura como base para escalar el equipo x2 cada a√±o. Sobre los errores de contrataci√≥n y el ajuste cultural</a></li>
<li><a href="../es498052/index.html">Zabbix 5.0 o Novedades con Template Server de IPMI</a></li>
<li><a href="../es498054/index.html">Derrota al Drag√≥n News Feed: Aseg√∫rate de vivir una buena vida</a></li>
<li><a href="../es498056/index.html">Eventos digitales en Mosc√∫ del 20 al 26 de abril.</a></li>
<li><a href="../es498060/index.html">Enfoque de ajuste industrial de PostgreSQL: experimentos de bases de datos Nikolay Samokhvalov</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëæ üàÇÔ∏è üë®‚Äçüíº Scaling Android Testing at Odnoklassniki ü§∑ üññüèª ‚ô•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! My name is Roman Ivanitsky, I work in the Odnoklassniki testing automation team. OK is a huge service with over 70 million users. If we talk ab...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Scaling Android Testing at Odnoklassniki</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/497726/"><img src="https://habrastorage.org/webt/dp/ei/lm/dpeilmobnwcglrby0p_rtptmgv8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hello! My name is Roman Ivanitsky, I work in the Odnoklassniki testing automation team. OK is a huge service with over 70 million users. If we talk about mobile devices, the majority uses OK.RU on smartphones running Android. For this reason, we are very serious about testing our Android application. In this article I will tell the story of the development of automated testing in our company.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2012, Odnoklassniki, the company is experiencing an active increase in the number of users and an increase in the number of user features. </font><font style="vertical-align: inherit;">In order to satisfy the business objectives, it was necessary to shorten the release cycle, but this was hampered by the fact that all the functionalities were tested manually. </font><font style="vertical-align: inherit;">The solution to this problem came by itself - we need autotests. </font><font style="vertical-align: inherit;">Thus, in 2012 in Odnoklassniki a test automation team appeared, and the first step was to start writing tests.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A bit of history</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first autotests in Odnoklassniki were written in Selenium, for their launch they raised Jenkins, Selenium Grid with Selenium Hub and a set of Selenium Node. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quick solution, quick start, quick profit - perfect. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Over time, the number of tests increased, and auxiliary services appeared - for example, launch services, report service, test data service. By the end of 2014, we had a thousand tests that ran in about fifteen to twenty minutes. This did not suit us, since it was clear that the number of tests would increase, and with it the time taken to run them would increase. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At that time, the automated testing infrastructure looked like this:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2q/ou/7s/2qou7sruwzlvihxfhhq2fdcd9qm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, with an amount of Selenium Node greater than or equal to 200, the Hub could not cope with the load. </font><font style="vertical-align: inherit;">Now this problem has already been studied, and that is why tools such as Zalenium or everyone's favorite Selenoid appeared. </font><font style="vertical-align: inherit;">But in 2014 there was no standard solution, so we decided to make our own. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Defined the minimum requirements that the service must meet:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scalability. </font><font style="vertical-align: inherit;">We do not want to depend on the limitations of the Selenium Hub.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stability. </font><font style="vertical-align: inherit;">In 2014, the Selenium Hub was not famous for stable operation.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fault tolerance. </font><font style="vertical-align: inherit;">We need the ability to continue the testing process in the event of a failure of the data center or any of the servers.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thus, our solution for scaling Selenium Grid appeared, consisting of a coordinator and Node-managers, outwardly very similar to the standard Selenium Grid, but with its own features. </font><font style="vertical-align: inherit;">These features will be discussed further.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Coordinator</font></font></h3><br>
<img src="https://habrastorage.org/webt/s0/gu/ib/s0guibehaq2q0zpa5vi40jc9un4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, it is a resource broker (resources are understood as browsers). It has an external API through which tests send requests for resources. These queries are saved to the database as tasks to run. The coordinator knows everything about the configuration of our cluster - which Node managers exist, what types of resources these Node managers can provide, the total number of resources, how many resources are currently involved in tasks. At the same time, he monitors resources - activity, stability, and in which case notifies those responsible. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A feature of the coordinator is that it integrates all Node managers into so-called farms. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is what the farm looks like. More than half of the resources are used, and all nodes online:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ti/ar/ib/tiariberzr9rt2lpau2vfohpcoa.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can also display nodes offline or enter them into rotation by a certain percentage, this is required if it becomes necessary to reduce the load on a particular node. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Each farm can be combined with others in a logical unit, which we call a service. At the same time, one farm can be included in several different services. Firstly, it makes it possible to set limits and prioritize the resources used by each specific service. Secondly, it allows you to easily manage the configuration - we have the ability to add the number of Node managers in the service on the fly, or vice versa to remove them from the farm in order to be able to interact with these Node managers, for example, configure or update, etc. .</font></font><br>
<br>
<img src="https://habrastorage.org/webt/wv/rj/fc/wvrjfcs7gh4e3fsf6kjloe1uh_k.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The coordinator‚Äôs API is pretty simple: it‚Äôs possible to request the service for the current amount of resources used, get its limit and start or stop some resource.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Node Manager</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is a service that can do two things well ‚Äî receive tasks from the coordinator and launch some resources on demand. </font><font style="vertical-align: inherit;">By default, it is designed so that each launch of the resource is isolated, that is, none of the previous launches can affect the launch of subsequent tests. </font><font style="vertical-align: inherit;">As a response, the coordinator uses a bunch of host and a set of raised ports. </font><font style="vertical-align: inherit;">For example, the host on which the Selenium server was launched, and its port. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/p8/xa/43/p8xa43yokgfpxyumwpmagx4ilpa.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On the host, it looks like this: the Node manager service is running, and it manages the entire resource life cycle. </font><font style="vertical-align: inherit;">He picks up browsers, completes them, makes sure that they are not forgotten to close. </font><font style="vertical-align: inherit;">To guarantee isolation from each other, all this happens on behalf of the service user.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interaction</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The test interacts with the infrastructure described above as follows: it addresses the coordinator with a request for the necessary resources, the coordinator saves this task as requiring execution. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Node manager, in turn, turns to the task coordinator. Having received the task, he starts the resource. After that, he sends the result of the launch to the coordinator, failed starts are also reported to the coordinator. The test receives the result of the resource request and, if successful, starts working with the resource directly. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fe/np/sf/fenpsf31k75tnpnxgwtw5mjymro.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The advantages of this approach are to reduce the load on the coordinator by gaining the ability to work with the resource directly. Cons - the need to implement the logic of interaction with the coordinator within the test frameworks, but for us this is acceptable.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Today we can run more than 800 browsers in parallel in three data centers. </font><font style="vertical-align: inherit;">For the coordinator, this is not the limit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fault tolerance is ensured by the launch of several coordinator instances wound up behind the DNS firewall in different data centers. </font><font style="vertical-align: inherit;">This guarantees access to the working instance in case of a problem with the data center or server. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, we got a solution that met all the initially set requirements. </font><font style="vertical-align: inherit;">It has been operating steadily since 2015 and has proven its effectiveness.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Android</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When it comes to testing on Android, there are usually two main approaches. The first is to use WebDriver - this is how Selendroid and Appium work. The second - in working with native tools, thus implemented Robotium, UI Automator or Espresso. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The fundamental similarities between these approaches are to get the device and get the browser. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are much more differences, the main one is the need to install the tested APK, with which we will take artifacts in the form of logs, screenshots, etc. and also, the fact that testing is carried out on the device itself, and not on the CI.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In 2015, Odnoklassniki began to cover their Android application with autotests. We selected one Linux machine, connected one real device via USB and started writing tests on Robotium. This simple solution allowed you to quickly get results. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Time passed, the number of tests and the number of devices grew. To solve management tasks, Device Manager was created - a wrapper over </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">adb</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Android Debug Bridge) commands, which allows the http api interface to execute them. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is how the first API for Device Manager looked - with its help you could get a list of devices, install / uninstall APKs, run tests and get results.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ra/j5/pc/raj5pcnmij6_km7w1zla73xzix4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, we noticed that the test results degrade at startup on the ADB server to which more than one device is connected. The solution that helped us improve stability was found in isolating each ADB server using Docker. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The farm is ready - you can connect phones. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rb/lh/gr/rblhgrqkdhtp6xgue6ysjzkjcx0.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Many are familiar with this picture. I heard that if you are engaged in Android farms, you are as if in hell every day.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yb/lo/sh/ybloshbgsavgewkhufosue3gqzi.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An Android emulator came to our aid. Its use was due to two factors: firstly, at that time it had already reached the necessary level of stability, and secondly, we did not have any features that would depend specifically on iron in our tests. In addition, this emulator was well projected onto the existing infrastructure at that time. The next step was to teach the Node manager to launch new types of resources. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What is required to run the Android emulator? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, you need an Android SDK with a set of utilities. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then you need to create AVD - Android Virtual Device - this is how your Android emulator will be organized - what architecture it will have, how many cores it will use, whether Google services will be available, etc.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/gt/az/6e/gtaz6ejxanl2ppil-8niyzhkvjc.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After that, you need to select the name of the created AVD, set the parameters, for example, transfer the port on which ADB will be launched, and start. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, there is a peculiarity in such a scheme - the system allows you to run only one instance emulator on one specific AVD. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The solution to this problem was to create a basic AVD, which was stored in memory, this made it possible to copy it somewhere else. </font><font style="vertical-align: inherit;">During the launch of the Android emulator, the base AVD was copied to a temporary directory mapped into memory, after which it started. </font><font style="vertical-align: inherit;">Such a scheme worked quickly, but was cumbersome. </font><font style="vertical-align: inherit;">To date, this problem has been solved by the read only option, which allows you to run Android emulators in unlimited quantities from one AVD</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Performance</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Based on the results of working with AVD, we developed several internal recommendations:</font></font><br>
<br>
<ol>
<li>  86  ,  ARM  .     dev/kvm  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">Linux  HAXM-  Mac  Windows</a></li>
<li>GPU-  .     ,    .  ,          ,   ,    Android-  </li>
<li> .       </li>
<li>   ,         localhost,        </li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As for the Docker-images for testing on Android, I want to highlight Agoda and Selenoid, they use the capabilities of Android emulators to the maximum. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The difference between them is that in the default Selenoid have </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Appium</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Agoda and used "clean" emulator. In addition, Selenoid has more community support. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the end of 2018, CloudNode-Manager was created, it contacts the coordinator, receives tasks and is launched using commands in the cloud. Instead of iron machines, this service uses the resources of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">one-cloud</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Odnoklassniki's own private cloud.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We managed to achieve scaling by teaching DeviceManager how to work with the Coordinator. To do this, I had to change the Device manager API to add the ability to request a device type (virtual / real). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is what happens if you try to run ADB Install on 250 emulators from a single machine. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/lk/ab/td/lkabtdmlsx7-1x6ne200l5jgi10.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The attendants immediately reacted to this and started an incident - the machine loaded the gigabit network interface with outgoing traffic. This complexity was resolved by increasing the throughput on the server. I can‚Äôt say that this problem gave us a lot of trouble, but you should not forget about it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It would seem that success is the Devicemanager, coordinator, scaling. We can run tests on the whole farm. In principle, we can run them on every pull request, and the developer will quickly receive feedback.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/uk/zl/l_/ukzll_cniqi00nxoiy67osju6do.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But not everything is so rosy. You may have noticed that so far nothing has been said about the quality of the tests. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/sr/he/4k/srhe4kzvbock0mcztvh88d2s_98.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is what our launches looked like. And the most interesting thing is that between the launches completely different tests could fall. These were unstable falls. And neither I, nor the developers, nor the testers trusted these results. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
How did we deal with this problem? They just copied everything from Robotium to Espresso, and it became good ... Actually, no. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To solve this problem, we not only rewrote everything on Espresso, but also started using the API for all kinds of actions such as uploading photos, creating posts, adding to friends, etc., made a quick login, used </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">diplinks</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that allowed you to go directly to the desired screen , and, of course, we analyzed all test cases.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now the test runs look like this: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/m2/zg/lo/m2zglocfnlq8e31pgwew1czj-ic.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You may notice that the red tests remain, but it is important to remember that these are end-to-end tests that run on production. We have a limit on the number of tests that can fall in the main branch of the application. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now we have stable tests and scaling. However, the test infrastructure is still highly tied to the tests. At the same time, due to the expectation of end-to-end tests, CI is busy, and other assemblies can queue, waiting for free agents. In addition, there is no clear scheme for working with parallel starts.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The reasons mentioned above became the impetus for the development of QueueRunner - a service that allows you to run tests asynchronously without blocking the CI. </font><font style="vertical-align: inherit;">To work, he needs a test and test APK, as well as a set of tests. </font><font style="vertical-align: inherit;">Having received the necessary data, he will be able to organize runs of runs in the queue, allocating and freeing the required resources. </font><font style="vertical-align: inherit;">QueueRunner downloads the results of the run to Jira and Stash, and also sends it by mail and in the messenger. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
QueueRunner has a test flow - it monitors the life cycle of the test. </font><font style="vertical-align: inherit;">The default flow that we use now consists of five steps:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Receiving device. </font><font style="vertical-align: inherit;">At this point, the Devicemanager requests through the coordinator a real or virtual device.</font></font></li>
<li> .        APK  ,    ‚Äì  ,           .</li>
<li>,      </li>
<li> </li>
<li>    </li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, five simple steps are the entire test life cycle in our service. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ke/pd/yg/kepdyglhyclwq8ogfg4thqparxy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What benefits did QueueRunner give us? Firstly, it uses all possible resources to the maximum - it can be scaled to the entire farm and quickly get results. Secondly, with the bonus, we got the opportunity to control the sequence of tests. For example, we can run the longest or most problematic tests at the beginning and thus reduce the time it takes to wait for them to run. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
QueueRunner also allows you to make smart retrays. We store all the data in the database, so at any time we can see the history of the test. For example, it is possible to look at the ratio of successful and unsuccessful passes of the test and decide whether, in principle, it is worth restarting the test.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
QueueRunner and Devicemanager have given us the ability to adapt to the amount of resources. Now we can scale to the whole farm, thanks to the use of emulators, that is, an almost unlimited number of virtual devices gave us the opportunity to run much more tests, but if for some reason the resources are unavailable, the service will wait for them to return and there will be no loss of launches. We use only the resources available to us, accordingly, after some time the results will still be obtained and at the same time the CI will not be blocked. And most importantly, the test infrastructure and tests are now separate. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now, in order to run tests on Android, you just need to give us a test APK and a list of tests.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We have come a long way from the Selenium farm on virtual machines to the launch of Android tests in the cloud. </font><font style="vertical-align: inherit;">However, this path has not yet been completed.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Development process</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's see how the test infrastructure is related to the development process and how testers and developers see it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Our Android team uses the standard GitFlow: </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/rf/p9/ot/rfp9ot5imowggxpkdgyekbym2ao.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Each feature has its own branch. The main development takes place in the develop branch. A developer who decides to create a new super feature begins its development in its own branch, while other developers can work in other branches in parallel. When a developer considers that the ideally beautiful, best code in the world is ready and needs to be rolled out to users as quickly as possible, he makes a pull request in develop, the unit is automatically assembled, unit tests and component tests are run. Simultaneously, the APKs are assembled, sent to QueueRunner, and end-to-end tests are run. After that, the results of running the tests come to the developer.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, there is a high probability that after the creation of the feature branch in develop, there were many commits. </font><font style="vertical-align: inherit;">This means that develop may not be what it used to be. </font><font style="vertical-align: inherit;">Therefore, pre-merge happens first - we merge develop into the current feature-branch, and it is on this premature state that we build, unit-tests, component tests, end-to-end, and based on these results we make a report. </font><font style="vertical-align: inherit;">Thus, we understand how functional the feature is in the current version of develop and, if everything is OK, then it is sent to users.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/og/qs/2m/ogqs2mqcef0dwn-lyaxugjzhrca.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reporting</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is how Stash reporting looks like: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/61/7b/qi/617bqiddnqointrhxigp3g2o904.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Our bot first writes that the tests have started, and when they pass, it updates the message and adds how many have passed, how many have fallen, how many known errors, and how many Flaky-tests. He writes the same thing in Jira, and adds a link to a comparison of launches. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is how the comparison of the two launches looks: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/li/kf/62/likf62ljuom4erhqvkxvoq4o-li.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here the current run in the feature branch is compared with the last run in the development. It contains information about the number of tests being run, matching problems, dropped tests, and unstable Flaky tests that were in one state and switched to another. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If at least one unit test or more than some threshold of end-to-end tests falls, then merge will be blocked.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order to understand whether the tests fall stably, we compare the hashes of the trace traces of the falls, before that they are preliminarily cleared of the digits, only the line numbers remain. </font><font style="vertical-align: inherit;">If the hashes match, then this is the same fall, if they are different, then most likely the falls will be different.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Summary</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, we implemented a stable, fault-tolerant solution that scales well to our infrastructure. </font><font style="vertical-align: inherit;">Then the resulting infrastructure was adapted for Android testing. </font><font style="vertical-align: inherit;">We were helped in this by the Device manager, which helps us to work both with real devices and virtual ones, as well as QueueRunner, which helped us to separate the infrastructure and tests, and not to block CI during the tests. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It looked like the test run time for one week in 2016 - from fifty minutes or longer. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/j9/0-/bk/j90-bkvotdp0g3zmlpphaskbmnu.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
That's how it looks now: </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/gi/0h/zy/gi0hzyeoygzkwphzp74vpph21q8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This chart shows the runs that took place over 2 hours of an average business day. </font><font style="vertical-align: inherit;">The running time was reduced to a maximum of 15 minutes, the number of runs increased markedly.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en497700/index.html">Weekly online mitaps on backing and DevOps, security and robots from April 17</a></li>
<li><a href="../en497702/index.html">Five trends in data storage that you should pay attention to in 2020</a></li>
<li><a href="../en497708/index.html">We invite you to a series of Fujitsu webinars in April and May</a></li>
<li><a href="../en497714/index.html">How to protect processes and kernel extensions on macOS</a></li>
<li><a href="../en497724/index.html">Preparing a server for publishing a web-app in Python</a></li>
<li><a href="../en497728/index.html">The dangers of ‚Äúburning‚Äù chips</a></li>
<li><a href="../en497730/index.html">Convenient BDD: SpecFlow + TFS</a></li>
<li><a href="../en497736/index.html">Review of 10 new internal combustion engines</a></li>
<li><a href="../en497738/index.html">Test yourself in Swift: a puzzle for puzzle lovers</a></li>
<li><a href="../en497740/index.html">Automakers admit that it‚Äôs a very long time before fully unmanned vehicles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
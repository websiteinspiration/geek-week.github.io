<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✳️ ⚡️ 👸🏿 「あなたのための記事を読む」という見出し。2019年10月〜12月 💄 〽️ 🍬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、ハブル！オープンデータサイエンスコミュニティのメンバーによる科学記事のレビューは、チャンネル#article_essenseから引き続き公開しています。誰よりも先に受け取りたい場合は、コミュニティに参加してください！
 

今日の記事：
 

1. Poly-encoders: Tran...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>「あなたのための記事を読む」という見出し。2019年10月〜12月</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/485122/"><img src="https://habrastorage.org/webt/gx/-y/xl/gx-yxlo7xiz-5y8krpyoj3rgswq.png"><br>
<p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
こんにちは、ハブル！</font><font style="vertical-align: inherit;">オープンデータサイエンスコミュニティのメンバーによる科学記事のレビューは、チャンネル#article_essenseから引き続き公開しています。</font><font style="vertical-align: inherit;">誰よりも先に受け取りたい場合は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コミュニティに</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参加して</font><font style="vertical-align: inherit;">ください！</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">今日の記事：</font></font></p><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring (Facebook, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Implicit Discriminator in Variational Autoencoder (Indian Institute of Technology Ropar, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Self-training with Noisy Student improves ImageNet classification (Google Research, Carnegie Mellon University, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Momentum Contrast for Unsupervised Visual Representation Learning (Facebook, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Benchmarking Neural Network Robustness to Common Corruptions and Perturbations (University of California, Oregon State University, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter (Hugging Face, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Plug and Play Language Models: A Simple Approach To Controlled Text Generation (Uber AI, Caltech, HKUST, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Deep Salience Representation for F0 Estimation in Polyphonic Music ( New York University, USA, 2017)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Analyzing and Improving the Image Quality of StyleGAN (NVIDIA, 2019)</a></li>
</ol><a name="habracut"></a><br>
<div class="spoiler"><b class="spoiler_title">    :</b><div class="spoiler_text"><ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2019年7月〜9月</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2019年1月〜6月</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2018年2月〜3月</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2017年12月〜2018年1月</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2017年10月〜11月</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2017年9月</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2017年8月</font></font></a></li>
</ul></div></div><br>
<h3 id="1-poly-encoders-transformer-architectures-and-pre-training-strategies-for-fast-and-accurate-multi-sentence-scoring">1. Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring</h3><br>
<p> : Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston (Facebook, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :  (  zhirzemli)</p><br>
<p><strong>TLDR</strong></p><br>
<p>         ().          ,      next sentense prediction.   Poly-Encoder   Bi-Encoder  Cross-Encoder .      Bi-Encoder (   )  Cross-Encoder (   context  answer )</p><br>
<img src="https://habrastorage.org/webt/ax/qd/nl/axqdnlibzffxcyjtbfzeguhsdja.png" width="500" height="250"><br>
<p><br>
</p><br>
<p><strong>Multi-sentence Scoring</strong></p><br>
<p>(   Bi  Cross Encoder .  ,  ,  )</p><br>
<p>    (   )           information-retrieval .      (dot product)      ,               .</p><br>
<p>   Bi-Encoder        offline-    .   ,         ,  dot product      .  ,      negative sampling   .  ,         ,          .  ,  forward pass     .  Bi-Encoder    ,        .  ,    - information flow      —      dot product’.   -     .</p><br>
<p>  — Cross-Encoder.            .         .     -,      (, )   .  ,          ,         .  ,        , ,     ( -&gt; )   logits-   ,         .      offline-  :       ,      . ,               .       .</p><br>
<p><strong></strong><br>
  ,        Bi  Cross Encoder .  ,     ,             ,    ,            .        :   ( dot product  )    .        .     ,         ,          .</p><br>
<p><strong></strong><br>
     :         Bi-Encoder:        ([CLS]-)   transformer-based  (BERT).       .</p><br>
<p> ,   ,        .      ,  .</p><br>
<p> ,      ( )   ( )   .       ,    — .  dot product   — softmax   .       .  ,        .  ,     Bi-Encoder  dot product   .</p><br>
<p>,           .        ,     m    .</p><br>
<p><strong></strong><br>
  ,  Cross-Encoder -   .  Poly-Encoder         ,          .</p><br>
<h3 id="2-implicit-discriminator-in-variational-autoencoder">2. Implicit Discriminator in Variational Autoencoder</h3><br>
<p> : Prateek Munjal, Akanksha Paul, Narayanan C. Krishnan (Indian Institute of Technology Ropar, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  shiron8bit)</p><br>
<p>    ,       VAE  GAN-   ,      :    , mode collapse/ mode missing   adversarial-.              /, , -,    ,  -,          ,  /      .</p><br>
<p><strong> </strong><br>
          Q     P,     -.        ,   . ,         ,     Div_KL(P||Q)  Div_KL (Q||P).       (  ),   Div_KL (P||Q) (  forward-KL,   zero avoiding)       ,   Div_KL(Q||P) (  backward-KL,   zero forcing)         . ,     VAE  GAN: reconstruction (L2) loss   forward-KL  (      ,    ),       backward-KL  (   ,     )</p><br>
<img src="https://habrastorage.org/webt/y9/7k/cd/y97kcdipocff08h4dsoaqly3udq.png" width="500" height="250"><br>
<p><br>
</p><br>
<p><strong>,   </strong><br>
    ,               (  ),          (   fully connected ,  ‘’    mu,sigma   VAE),      .    .    :    L_enc  L2-    -  N(0,1) (L_prior),  — adversarial  (     ,      /),   2  :</p><br>
<ul>
<li><p> ,   adversarial-,    2    :   /   /    N(0,1)</p><br>
</li>
<li><p>   L_dec  ,        ( ,        )      .</p><br>
</li>
</ul><br>
<img src="https://habrastorage.org/webt/-d/n5/jh/-dn5jh_obvrbb4am3ujm37hd9qs.png" width="500" height="250"><br>
<p><strong></strong><br>
    VAE    ,      VAE  GAN’ (VAE-GAN, alpha-GAN  AGE      )   celeba  cifar10 (,   mnist),            Frechet Inception Distance (         ).   ,    FID     ,        ‘’ ( ).</p><br>
<h3 id="3-self-training-with-noisy-student-improves-imagenet-classification">3. Self-training with Noisy Student improves ImageNet classification</h3><br>
<p> : Qizhe Xie, Eduard Hovy, Minh-Thang Luong, Quoc V. Le (Google Research, Carnegie Mellon University, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  belskikh)</p><br>
<p>    87.4% 1  98.2% 5   .       .   Noisy Student.</p><br>
<img src="https://habrastorage.org/webt/es/s8/tm/ess8tmsezy4cjwydsqqfhjxclcu.png"><br>
<p><br>
</p><br>
<p><strong></strong>  :</p><br>
<ol>
<li> teacher model,    .</li>
<li> soft psudo labels    JFT .</li>
<li> student model   ,     :  ,   stochastic depth</li>
<li> student model,    teacher  .2   .     .    EfficientNet-B0,   ,     JFT .    ,      0.3.     130  (    0.3     — ,   —      ).  130 ,  ,  81</li>
</ol><br>
<p><strong>:</strong><br>
EfficeintNet,  student     teacher .     EfficientNet   EfficientNet-L0/L1/L2,    L2   480  ( 50 26 ,  )</p><br>
<p><strong> :</strong><br>
 2048. Sota  L2  350 .    L2     3.5   Cloud TPU v3 Pod  2048 .</p><br>
<p><strong>  :</strong><br>
  B7   ,   . ,  B7  ,    L0  . ,     ,    L2 ,           L2 .: :sota:   2          (FixRes ResNeXt-101 WSL 829M )</p><br>
<p>    <strong></strong>  ImageNet-A/C/P</p><br>
<img src="https://habrastorage.org/webt/ht/me/ce/htmeceti9jluqoyj84uqcy2fibo.png"><br>
<p><br>
</p><br>
<h3 id="4-momentum-contrast-for-unsupervised-visual-representation-learning">4. Momentum Contrast for Unsupervised Visual Representation Learning</h3><br>
<p> : Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick (Facebook, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  arsenyinfo)</p><br>
<p>SotA  unsupervised    computer vision  (   dense pose estimation),     (imagenet, instagram)    (imagenet, COCO, cityscapes, LVIS etc.).</p><br>
<img src="https://habrastorage.org/webt/li/5p/bn/li5pbnzez-zowzce2movvxthfea.png"><br>
<p><br>
</p><br>
<p>  unsupervised pretrain?  - ,     ,  ,  ,     ,    (  ,      ).        — instance discrimination,   contrastive , ..  ,            (,    ),    — .</p><br>
<p>     end-to-end,      :        .  ,        .    -   :   ,       .</p><br>
<p> -   memory bank:             , ..  .   ,   :          .</p><br>
<p>,  :</p><br>
<ol>
<li>   memory bank  ,      ;</li>
<li>    :       ,   —  ,      ,    ;</li>
<li>    ,      .</li>
</ol><br>
<p>       end-to-end , ,   ,      .        ,  .. -   ,   supervised   .</p><br>
<h3 id="5-benchmarking-neural-network-robustness-to-common-corruptions-and-perturbations">5. Benchmarking Neural Network Robustness to Common Corruptions and Perturbations</h3><br>
<p> : Dan Hendrycks, Thomas Dietterich (University of California, Oregon State University, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  ternaus)</p><br>
<img src="https://habrastorage.org/webt/fy/p3/zn/fyp3znumddg9tstty7aukiiuvwg.png" width="500" height="250"><br>
<p><br>
</p><br>
<p>   ICLR 2019    ,       DL,       .</p><br>
<p>    —       ImageNet,     . ,    adevrsarial          .</p><br>
<p><strong>  :</strong></p><br>
<ol>
<li>   .  ,     , ,    .<br>
 : GaussianNoise, ISONoise, Downscale, Defocus, MotionBlur, ZoomBlur, FrostedGlassBlur, JpegCompression, Snow, Fog, Rain, Elastic transoform, etc.</li>
<li>      ImageNet validation.     ImageNet-C</li>
<li>      ImageNet-P           .</li>
<li>      .</li>
<li>        : AlexNet, VGG-11, VGG-19, Resnet-50, Resnet-18, VGG-19+BN, etc</li>
</ol><br>
<p><strong>:</strong></p><br>
<ol>
<li>       . :capitan_obvious:</li>
<li>    .</li>
<li> CLAHE    inference  .</li>
<li>feature aggregation     DenseNet  Resnext .</li>
<li>    multiscale  .    — MSDNet, Multigrid (    )</li>
</ol><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a></p><br>
<h3 id="6-distilbert-a-distilled-version-of-bert-smaller-faster-cheaper-and-lighter">6. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</h3><br>
<p> : Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf (Hugging Face, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  yorko)</p><br>
<p> ,   .          NLP  environmental footprint.    (     ).          .  cross entropy loss     (   )   ,    ,          .   ,   .. ,    ,  .    : "I think this is a beginning of a beautiful [MASK]",   [MASK] BERT     day  life,       future, story  world   .   -  ,      ?  ,    ,     Murdock, tolerance, maternity     .</p><br>
<img src="https://habrastorage.org/webt/wg/xd/rx/wgxdrxth-vykjuhkxszaxakxdke.png" width="500" height="250"><br>
<p><br>
</p><br>
<p><strong> </strong><br>
   teacher-student  ,      - (<strong>teacher</strong>, BERT)    (<strong>student</strong>, DistilBERT),    ""  -.  student   distillation loss,  , cross entropy loss,       : L = Σ t_i * log(s_i).     ,   [MASK],      ,          : {t_i}  {s_i} — , -, -  -.  ,  rich training signal — -     ,             ,      -.</p><br>
<p><strong> DistilBERT</strong><br>
   ,   —   ,  .   DistilBERT —      BERT,    .   token-type embeddings  pooler, ,    .  ,  DistilBERT  40%  — 66 .   110   BERT</p><br>
<p><strong> DistilBERT</strong><br>
 DistilBERT  distillation loss     —   masked language modeling loss,    BERT   cosine embedding loss —           ( ,  ,      "" -   ,  "" ). :   ablation studies, ,   masked language modeling loss,    , ..    distillation loss  cosine embedding loss.   ,    RoBERTa   next sentence prediction   dynamic masking.</p><br>
<p>     ,  BERT (eng. wiki + Toronto Book Corpus) 90   8 V100 (16 GB).   RoBERTa    1024 V100 (32 GB).</p><br>
<p><strong></strong><br>
    BERT — "it performed surprisingly well",        DistilBERT —  GLUE  surprisingly well —     5  9   ,  BERT ,     SQuAD  IMDb —  .   ,    DistilBERT   60% —  .</p><br>
<p><strong> </strong><br>
  DistilBERT  iPhone 7 Plus.   70% ,  BERT-base (  ),     200 .  ablation studies:     ,      — distillation loss  cosine embedding loss.</p><br>
<p>     3          ,  DistilBERT —     BERT,   40%  ,   60%    "97%   "    BERT (        ML).</p><br>
<p>-,      BERT,     .</p><br>
<p><strong> :</strong><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> Jay Alammar</a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  , DistilBERT + Catalyst:   </a></p><br>
<h3 id="7-plug-and-play-language-models-a-simple-approach-to-controlled-text-generation">7. Plug and Play Language Models: A Simple Approach To Controlled Text Generation</h3><br>
<p> : Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu (Uber AI, Caltech, HKUST, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  Egor Timofeev)</p><br>
<p>              . ,           / /      (, .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">https://arxiv.org/pdf/1909.05858.pdf</a>).     ,         ,     , ,      .</p><br>
<p><strong></strong><br>
      (   x_prev    ),        p(x),      conditional LM (,    — CTRL)    p(x|a).</p><br>
<p>      : p(x|a) ∝ p(x)p(a|x),  p(x)  ,    (, GPT2),  p(a|x) —     .       —       ,   /.     ,       ,    .</p><br>
<p>  <strong></strong> :</p><br>
<ol>
<li>   ,  log(p(a|x)) ( ).     hidden state  .</li>
<li>     ,  hidden state      log(p(a|x)).   H_new.</li>
<li>  :           p(x).    ,    : -,        KL(H, H_new),  -,  .. post-norm fusion (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">https://arxiv.org/pdf/1809.00125.pdf</a>),   p(x)   non conditional LM  ,     .</li>
<li>     .</li>
</ol><br>
<p>          ,  p(a|x).</p><br>
<p><strong></strong><br>
      ,   -            topic relevance.    :  (GPT2) &lt;  +    &lt;&lt;       &lt;    + .</p><br>
<img src="https://habrastorage.org/webt/jx/zm/ye/jxzmyeaubsu6wtcp2np1zda32tk.png" width="500" height="250"><br>
<p><br>
</p><br>
<h3 id="8-deep-salience-representation-for-f0-estimation-in-polyphonic-music">8. Deep Salience Representation for F0 Estimation in Polyphonic Music</h3><br>
<p> : Rachel M. Bittner, Brian McFee, Justin Salamon, Peter Li, Juan Pablo Bello ( New York University, USA, 2017)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  nglaz)</p><br>
<p>   .  ,                .        ,     –    .       ,   -   .   constant-Q ,          (      )          .</p><br>
<img src="https://habrastorage.org/webt/7l/6y/c0/7l6yc0irzsti2kbks7avmvrb7w4.png" width="500" height="250"><br>
<p>    .  constant-Q     -   f_min  -    F.    f_min   f_min * h,      ,    ,     .    h   {0.5, 1, 2, 3, 4, 5},        .   ,          3- ,        2-  3-    (, ,  ). ,    ,     ,    ,   (0.5f, f, 2f, 3f, 4f, 5f),    .     ( 55)      .         ,           ,  dilated-.</p><br>
<p> , ,     constant-Q       F,           .</p><br>
<p>   F0 estimation,    ,          .  2017 ,   ,   state-of-the-art.           ,      .</p><br>
<h3 id="9-analyzing-and-improving-the-image-quality-of-stylegan">9. Analyzing and Improving the Image Quality of StyleGAN</h3><br>
<p> : Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila (NVIDIA, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  shiron8bit)</p><br>
<p>GAN-      ,     ,         .     ,   ,      ,   ,    ( FID)   :</p><br>
<ul>
<li>  droplet-like  (    / ),  AdaIN. </li>
<li>  ,   ProGAN-    /       end-to-end     MSG-GAN.     ,        /,            .</li>
<li> Path Length Regularization.</li>
<li>    :       W,      ,       stylegan2.</li>
</ul><br>
<img src="https://habrastorage.org/webt/f6/v3/7p/f6v37pcy3wcpw0epu5rz1-r24qk.png" width="500" height="250"><br>
<p><br>
</p><br>
<p><strong>Droplet-  AdaIN</strong><br>
       AdaIN-: adain   feature map,          ,  droplet —       .     AdaIN   :   (/)     ,      A ,     ( mu(y) / y_{b,i}  AdaIN)     B,  .          .</p><br>
<p><strong>  ProGAN</strong><br>
   MSG-GAN    skip connections,        .  stylegan   ,        ( )         downsampled  .        residual-,       skip connections    residual-   (   LAPGAN,      , feature maps  ). ,       ProGAN,        ,        ,        .</p><br>
<p><strong>Path Length Regularization</strong><br>
,    FID     ,          PPL (Perceptual Path Length —    vgg-      Z,     LPIPS),   Path Length ,      </p><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msubsup><mi>J</mi><mi>w</mi><mi>T</mi></msubsup><mi>y</mi><mo>=</mo><msub><mi mathvariant=&quot;normal&quot;>&amp;#x2207;</mi><mi>w</mi></msub><mo stretchy=&quot;false&quot;>(</mo><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mi>w</mi><mo stretchy=&quot;false&quot;>)</mo><mi>y</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.068ex" height="2.884ex" viewBox="0 -916.9 7779.3 1241.8" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-4A" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-54" x="929" y="488"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-77" x="785" y="-212"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-79" x="1255" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMAIN-3D" x="2030" y="0"></use><g transform="translate(3086,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMAIN-2207" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-77" x="1178" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMAIN-28" x="4526" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-67" x="4916" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMAIN-28" x="5396" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-77" x="5786" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMAIN-29" x="6502" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMATHI-79" x="6892" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/485122/&amp;usg=ALkJrhhAitf3paubKcuZi0YVmZdu4533HA#MJMAIN-29" x="7389" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msubsup><mi>J</mi><mi>w</mi><mi>T</mi></msubsup><mi>y</mi><mo>=</mo><msub><mi mathvariant="normal">∇</mi><mi>w</mi></msub><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><mi>w</mi><mo stretchy="false">)</mo><mi>y</mi><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1">J^T_w y = \nabla_w (g(w) y)</script></p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、gはジェネレータ自体、J_wは潜在空間変数のヤコビアンです。同時に、ヤコビアンの計算はバックプロップを介して行うことができます。また、計算を容易にするために、正規化関数は16バッチごとにしかカウントできないとも言われています。数値aは、ヤコビアンノルムの指数移動平均として計算されます。パスの長さの正規化を使用すると、隠れた空間Wのより「スムーズな」補間が可能になります。これにより、画像の品質が向上するだけでなく、可逆性が向上します（つまり、ジェネレーターを実行した後に特定の画像を与えるwを見つけることができます）。また、アニメーションとキーフレーム間の補間の観点からパースペクティブを開きます（新しいアーキテクチャでは、類似した画像の投影の間には、近接した画像の原因となる点があります）。この正則化の導入は、このアーキテクチャによって生成された画像の検出を簡素化する役割も果たしました。</font></font><br>
<p>   8 GPU   1024*1024   2  9    .</p></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja485104/index.html">インターホン用のユニバーサルRFIDキーの作成</a></li>
<li><a href="../ja485108/index.html">2020年1月10日のロシアのPMI認定スペシャリストの統計</a></li>
<li><a href="../ja485110/index.html">効果的なリモート作業の私の経験</a></li>
<li><a href="../ja485118/index.html">ロバートマーティンによる「クリーンコード」。概要。明確で美しいコードを書くには？</a></li>
<li><a href="../ja485120/index.html">非常に高速なJSON APIをアプリケーションに追加します。</a></li>
<li><a href="../ja485124/index.html">PHPとPHPUnitでの純粋なテスト</a></li>
<li><a href="../ja485126/index.html">Mu-mu、woof-woof、quack-quack：音響通信の進化</a></li>
<li><a href="../ja485128/index.html">Mikrotik CHRライセンスを節約</a></li>
<li><a href="../ja485132/index.html">Google Playインディーゲームフェスティバルに参加する</a></li>
<li><a href="../ja485134/index.html">タギルとエゴール：タギル・バレエフへのインタビュー</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêõ üë®‚Äçüé® üë©üèº‚Äçüé§ Random Forest, la m√©thode des principaux composants et l'optimisation des hyperparam√®tres: un exemple de r√©solution du probl√®me de classification en Python üöª ‚ìÇÔ∏è ‚¨ÖÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les sp√©cialistes du traitement et de l'analyse des donn√©es disposent de nombreux outils pour cr√©er des mod√®les de classification. L'une des m√©thodes l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Random Forest, la m√©thode des principaux composants et l'optimisation des hyperparam√®tres: un exemple de r√©solution du probl√®me de classification en Python</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/488342/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les sp√©cialistes du traitement et de l'analyse des donn√©es disposent de nombreux outils pour cr√©er des mod√®les de classification. </font><font style="vertical-align: inherit;">L'une des m√©thodes les plus populaires et les plus fiables pour d√©velopper de tels mod√®les est d'utiliser l'algorithme Random Forest (RF). </font><font style="vertical-align: inherit;">Afin d'essayer d'am√©liorer les performances d'un mod√®le construit √† l'aide de l'algorithme </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RF</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , vous pouvez utiliser l'optimisation de l'hyperparam√®tre du mod√®le ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyperparameter Tuning</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , HT). </font><font style="vertical-align: inherit;">
De plus, il existe une approche r√©pandue selon laquelle les donn√©es, avant d'√™tre transf√©r√©es au mod√®le, sont trait√©es √† l'aide de l' </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">analyse en composantes principales</font></a></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/tt/m5/h7/ttm5h7jbbx2u2wuc1var1azxwew.jpeg"></a><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, PCA). </font><font style="vertical-align: inherit;">Mais vaut-il la peine d'utiliser? </font><font style="vertical-align: inherit;">Le but principal de l'algorithme RF n'est-il pas d'aider l'analyste √† interpr√©ter l'importance des traits?</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Oui, l'utilisation de l'algorithme PCA peut conduire √† une l√©g√®re complication de l'interpr√©tation de chaque ¬´caract√©ristique¬ª dans l'analyse de ¬´l'importance des caract√©ristiques¬ª du mod√®le RF. Cependant, l'algorithme PCA r√©duit la dimension de l'espace des fonctionnalit√©s, ce qui peut entra√Æner une diminution du nombre de fonctionnalit√©s qui doivent √™tre trait√©es par le mod√®le RF. Veuillez noter que le volume des calculs est l'un des principaux inconv√©nients de l'algorithme de for√™t al√©atoire (c'est-√†-dire qu'il peut prendre beaucoup de temps pour terminer le mod√®le). L'application de l'algorithme PCA peut √™tre une partie tr√®s importante de la mod√©lisation, en particulier dans les cas o√π ils fonctionnent avec des centaines voire des milliers de fonctionnalit√©s. Par cons√©quent, si la chose la plus importante est de simplement cr√©er le mod√®le le plus efficace, et en m√™me temps vous pouvez sacrifier la pr√©cision de la d√©termination de l'importance des attributs, alors l'ACP peut valoir la peine d'√™tre essay√©e.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant au point. </font><font style="vertical-align: inherit;">Nous travaillerons avec un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ensemble de donn√©es sur le cancer du sein</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">Scikit-learn ¬´cancer du sein¬ª</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Nous allons cr√©er trois mod√®les et comparer leur efficacit√©. </font><font style="vertical-align: inherit;">√Ä savoir, nous parlons des mod√®les suivants:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le mod√®le de base bas√© sur l'algorithme RF (nous abr√©gerons ce mod√®le RF).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le m√™me mod√®le que le n ¬∞ 1, mais dans lequel une r√©duction de la dimension de l'espace caract√©ristique est appliqu√©e en utilisant la m√©thode des composants principaux (RF + PCA).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le m√™me mod√®le que le n ¬∞ 2, mais construit en utilisant l'optimisation hyperparam√©trique (RF + PCA + HT).</font></font></li>
</ol><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. Importer des donn√©es</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour commencer, chargez les donn√©es et cr√©ez une trame de donn√©es Pandas. </font><font style="vertical-align: inherit;">√âtant donn√© que nous utilisons un ensemble de donn√©es ¬´jouet¬ª pr√©-autoris√© de Scikit-learn, nous pouvons d√©j√† commencer le processus de mod√©lisation. </font><font style="vertical-align: inherit;">Mais m√™me lorsque vous utilisez de telles donn√©es, il est recommand√© de toujours commencer √† travailler en effectuant une analyse pr√©liminaire des donn√©es √† l'aide des commandes suivantes appliqu√©es au bloc de donn√©es ( </font></font><code>df</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">):</font></font><br>
<br>
<ul>
<li><code>df.head()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - pour jeter un oeil √† la nouvelle trame de donn√©es et voir si elle ressemble √† celle attendue.</font></font></li>
<li><code>df.info()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- pour d√©couvrir les caract√©ristiques des types de donn√©es et le contenu des colonnes. </font><font style="vertical-align: inherit;">Il peut √™tre n√©cessaire d'effectuer une conversion de type de donn√©es avant de continuer.</font></font></li>
<li><code>df.isna()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- pour vous assurer qu'il n'y a pas de valeurs dans les donn√©es </font></font><code>NaN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Les valeurs correspondantes, le cas √©ch√©ant, peuvent devoir √™tre trait√©es d'une mani√®re ou d'une autre, ou, si n√©cessaire, il peut √™tre n√©cessaire de supprimer des lignes enti√®res du bloc de donn√©es.</font></font></li>
<li><code>df.describe()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - conna√Ætre les valeurs minimales, maximales et moyennes des indicateurs dans les colonnes, conna√Ætre les indicateurs du carr√© moyen et de l'√©cart probable dans les colonnes.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans notre jeu de donn√©es, une colonne </font></font><code>cancer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(cancer) est la variable cible dont nous voulons pr√©dire la valeur √† l'aide du mod√®le. </font></font><code>0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">signifie ¬´pas de maladie¬ª. </font></font><code>1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- "la pr√©sence de la maladie".</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_breast_cancer<font></font>
columns = [<span class="hljs-string">'mean radius'</span>, <span class="hljs-string">'mean texture'</span>, <span class="hljs-string">'mean perimeter'</span>, <span class="hljs-string">'mean area'</span>, <span class="hljs-string">'mean smoothness'</span>, <span class="hljs-string">'mean compactness'</span>, <span class="hljs-string">'mean concavity'</span>, <span class="hljs-string">'mean concave points'</span>, <span class="hljs-string">'mean symmetry'</span>, <span class="hljs-string">'mean fractal dimension'</span>, <span class="hljs-string">'radius error'</span>, <span class="hljs-string">'texture error'</span>, <span class="hljs-string">'perimeter error'</span>, <span class="hljs-string">'area error'</span>, <span class="hljs-string">'smoothness error'</span>, <span class="hljs-string">'compactness error'</span>, <span class="hljs-string">'concavity error'</span>, <span class="hljs-string">'concave points error'</span>, <span class="hljs-string">'symmetry error'</span>, <span class="hljs-string">'fractal dimension error'</span>, <span class="hljs-string">'worst radius'</span>, <span class="hljs-string">'worst texture'</span>, <span class="hljs-string">'worst perimeter'</span>, <span class="hljs-string">'worst area'</span>, <span class="hljs-string">'worst smoothness'</span>, <span class="hljs-string">'worst compactness'</span>, <span class="hljs-string">'worst concavity'</span>, <span class="hljs-string">'worst concave points'</span>, <span class="hljs-string">'worst symmetry'</span>, <span class="hljs-string">'worst fractal dimension'</span>]<font></font>
dataset = load_breast_cancer()<font></font>
data = pd.DataFrame(dataset[<span class="hljs-string">'data'</span>], columns=columns)<font></font>
data[<span class="hljs-string">'cancer'</span>] = dataset[<span class="hljs-string">'target'</span>]<font></font>
display(data.head())<font></font>
display(data.info())<font></font>
display(data.isna().sum())<font></font>
display(data.describe())</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bce/fb8/b60/bcefb8b60462b7658b40e1e56f7744ab.png"></div><br>
<i><font color="#999999">      .       .  , cancer,   ,    . 0  ¬´ ¬ª. 1 ‚Äî ¬´ ¬ª</font></i><br>
 <br>
<h2><font color="#3AC1EF">2.        </font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, divisez les donn√©es √† l'aide de la fonction Scikit-learn </font></font><code>train_test_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Nous voulons donner au mod√®le autant de donn√©es d'entra√Ænement que possible. Cependant, nous devons disposer de suffisamment de donn√©es pour tester le mod√®le. En g√©n√©ral, nous pouvons dire que, √† mesure que le nombre de lignes de l'ensemble de donn√©es augmente, la quantit√© de donn√©es pouvant √™tre consid√©r√©e comme √©ducative augmente √©galement. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par exemple, s'il y a des millions de lignes, vous pouvez diviser l'ensemble en mettant en surbrillance 90% des lignes pour les donn√©es d'apprentissage et 10% pour les donn√©es de test. Mais l'ensemble de donn√©es de test ne contient que 569 lignes. Et ce n'est pas tant pour la formation et le test du mod√®le. Par cons√©quent, afin d'√™tre juste par rapport aux donn√©es de formation et de v√©rification, nous diviserons l'ensemble en deux parties √©gales - 50% - donn√©es de formation et 50% - donn√©es de v√©rification. Nous installons</font></font><code>stratify=y</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour garantir que les ensembles de donn√©es de formation et de test ont le m√™me rapport de 0 et 1 que l'ensemble de donn√©es d'origine.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
X = data.drop(<span class="hljs-string">'cancer'</span>, axis=<span class="hljs-number">1</span>)&nbsp;&nbsp;<font></font>
y = data[<span class="hljs-string">'cancer'</span>]&nbsp;<font></font>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.50</span>, random_state = <span class="hljs-number">2020</span>, stratify=y)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3. Mise √† l'√©chelle des donn√©es</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avant de proc√©der √† la mod√©lisation, vous devez ¬´centrer¬ª et ¬´normaliser¬ª les donn√©es en les </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mettant</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √† l' </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">√©chelle</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">La mise √† l'√©chelle est effectu√©e du fait que diff√©rentes quantit√©s sont exprim√©es dans diff√©rentes unit√©s. </font><font style="vertical-align: inherit;">Cette proc√©dure vous permet d'organiser un ¬´combat loyal¬ª entre les signes pour d√©terminer leur importance. </font><font style="vertical-align: inherit;">De plus, nous convertissons </font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le type de donn√©es Pandas </font></font><code>Series</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en tableau NumPy afin que plus tard le mod√®le puisse fonctionner avec les cibles correspondantes.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
ss = StandardScaler()<font></font>
X_train_scaled = ss.fit_transform(X_train)<font></font>
X_test_scaled = ss.transform(X_test)<font></font>
y_train = np.array(y_train)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4. Formation du mod√®le de base (mod√®le n ¬∞ 1, RF)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cr√©ez maintenant le mod√®le num√©ro 1. </font><font style="vertical-align: inherit;">Dans ce document, nous rappelons que seul l'algorithme Random Forest est utilis√©. </font><font style="vertical-align: inherit;">Il utilise toutes les fonctionnalit√©s et est configur√© en utilisant les valeurs par d√©faut (des d√©tails sur ces param√®tres peuvent √™tre trouv√©s dans la documentation de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sklearn.ensemble.RandomForestClassifier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Initialisez le mod√®le. </font><font style="vertical-align: inherit;">Apr√®s cela, nous la formerons sur les donn√©es √† l'√©chelle. </font><font style="vertical-align: inherit;">La pr√©cision du mod√®le peut √™tre mesur√©e sur les donn√©es d'entra√Ænement:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> recall_score<font></font>
rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled, y_train)<font></font>
display(rfc.score(X_train_scaled, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si nous voulons savoir quelles caract√©ristiques sont les plus importantes pour le mod√®le RF dans la pr√©diction du cancer du sein, nous pouvons visualiser et quantifier les indicateurs de l'importance des signes en faisant r√©f√©rence √† l'attribut </font></font><code>feature_importances_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">feats = {}
<span class="hljs-keyword">for</span> feature, importance <span class="hljs-keyword">in</span> zip(data.columns, rfc_1.feature_importances_):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;feats[feature] = importance<font></font>
importances = pd.DataFrame.from_dict(feats, orient=<span class="hljs-string">'index'</span>).rename(columns={<span class="hljs-number">0</span>: <span class="hljs-string">'Gini-Importance'</span>})<font></font>
importances = importances.sort_values(by=<span class="hljs-string">'Gini-Importance'</span>, ascending=<span class="hljs-literal">False</span>)<font></font>
importances = importances.reset_index()<font></font>
importances = importances.rename(columns={<span class="hljs-string">'index'</span>: <span class="hljs-string">'Features'</span>})<font></font>
sns.set(font_scale = <span class="hljs-number">5</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">1.7</span>)<font></font>
fig, ax = plt.subplots()<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">15</span>)<font></font>
sns.barplot(x=importances[<span class="hljs-string">'Gini-Importance'</span>], y=importances[<span class="hljs-string">'Features'</span>], data=importances, color=<span class="hljs-string">'skyblue'</span>)<font></font>
plt.xlabel(<span class="hljs-string">'Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'Features'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.title(<span class="hljs-string">'Feature Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
display(plt.show())<font></font>
display(importances)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a02/a8f/cd2/a02a8fcd28f87af338f364a70faeca3e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualisation de ¬´l'importance¬ª des signes</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/830/176/e1f/830176e1fc9ce63bfedf2d727619253b.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Indicateurs de signification</font></font></font></i><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5. La m√©thode des principaux composants</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voyons maintenant comment nous pouvons am√©liorer le mod√®le RF de base. En utilisant la technique de r√©duction de la dimension de l'espace d'entit√©, il est possible de pr√©senter l'ensemble de donn√©es initial √† travers moins de variables et en m√™me temps de r√©duire la quantit√© de ressources informatiques n√©cessaires pour assurer le fonctionnement du mod√®le. √Ä l'aide de l'ACP, vous pouvez √©tudier la variance cumul√©e de l'√©chantillon de ces caract√©ristiques afin de comprendre quelles caract√©ristiques expliquent la plupart de la variance dans les donn√©es. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous initialisons l'objet PCA ( </font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), indiquant le nombre de composants (fonctionnalit√©s) √† prendre en compte. Nous avons fix√© cet indicateur √† 30 afin de voir la variance expliqu√©e de tous les composants g√©n√©r√©s avant de d√©cider du nombre de composants dont nous avons besoin. Ensuite, nous transf√©rons aux </font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donn√©es mises </font><font style="vertical-align: inherit;">√† l' </font><font style="vertical-align: inherit;">√©chelle</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en utilisant la m√©thode </font></font><code>pca_test.fit()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Apr√®s cela, nous visualisons les donn√©es.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<font></font>
pca_test = PCA(n_components=<span class="hljs-number">30</span>)<font></font>
pca_test.fit(X_train_scaled)<font></font>
sns.set(style=<span class="hljs-string">'whitegrid'</span>)<font></font>
plt.plot(np.cumsum(pca_test.explained_variance_ratio_))<font></font>
plt.xlabel(<span class="hljs-string">'number of components'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'cumulative explained variance'</span>)<font></font>
plt.axvline(linewidth=<span class="hljs-number">4</span>, color=<span class="hljs-string">'r'</span>, linestyle = <span class="hljs-string">'--'</span>, x=<span class="hljs-number">10</span>, ymin=<span class="hljs-number">0</span>, ymax=<span class="hljs-number">1</span>)<font></font>
display(plt.show())<font></font>
evr = pca_test.explained_variance_ratio_<font></font>
cvr = np.cumsum(pca_test.explained_variance_ratio_)<font></font>
pca_df = pd.DataFrame()<font></font>
pca_df[<span class="hljs-string">'Cumulative Variance Ratio'</span>] = cvr<font></font>
pca_df[<span class="hljs-string">'Explained Variance Ratio'</span>] = evr<font></font>
display(pca_df.head(<span class="hljs-number">10</span>))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6eb/65f/acc/6eb65facc6c8b05f1e910d3b2b676d5e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s que le nombre de composants utilis√©s d√©passe 10, l'augmentation de leur nombre n'augmente pas consid√©rablement la variance expliqu√©e</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f12/e3c/915/f12e3c915d761e1d4623051dac74cd8d.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ce bloc de donn√©es contient des indicateurs tels que le ratio de variance cumul√©e (taille cumul√©e de la variance expliqu√©e des donn√©es) et le ratio de variance expliqu√©e (contribution de chaque composant au volume total de la variance expliqu√©e)</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
.Si vous regardez le bloc de donn√©es ci-dessus, il s'av√®re que l'utilisation de l'ACP pour passer de 30 variables √† 10 aux composants permet d'expliquer 95% de la dispersion des donn√©es. Les 20 autres composantes repr√©sentent moins de 5% de la variance, ce qui signifie que nous pouvons les refuser. Suivant cette logique, nous utilisons le PCA pour r√©duire le nombre de composants de 30 √† 10 pour</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et</font></font><code>X_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Nous √©crivons ces ensembles de donn√©es de ¬´dimension r√©duite¬ª cr√©√©s artificiellement dans</font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et en</font><font style="vertical-align: inherit;">dedans</font></font><code>X_test_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">pca = PCA(n_components=<span class="hljs-number">10</span>)<font></font>
pca.fit(X_train_scaled)<font></font>
X_train_scaled_pca = pca.transform(X_train_scaled)<font></font>
X_test_scaled_pca = pca.transform(X_test_scaled)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Chaque composante est une combinaison lin√©aire de variables sources avec des ¬´pond√©rations¬ª correspondantes. </font><font style="vertical-align: inherit;">Nous pouvons voir ces ¬´poids¬ª pour chaque composant en cr√©ant un bloc de donn√©es.</font></font><br>
<br>
<pre><code class="python hljs">pca_dims = []
<span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(pca_df)):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;pca_dims.append(<span class="hljs-string">'PCA Component {}'</span>.format(x))<font></font>
pca_test_df = pd.DataFrame(pca_test.components_, columns=columns, index=pca_dims)<font></font>
pca_test_df.head(<span class="hljs-number">10</span>).T</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/086/a28/ae4/086a28ae45e9048811cf813d4868902e.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cadre de donn√©es d'informations sur les composants</font></font></font></i><br>
 <br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6. Formation au mod√®le RF de base apr√®s application de la m√©thode des composants principaux aux donn√©es (mod√®le n ¬∞ 2, RF + PCA)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant , </font><font style="vertical-align: inherit;">nous pouvons passer √† une </font><font style="vertical-align: inherit;">autre base de </font><font style="vertical-align: inherit;">donn√©es mod√®le RF </font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et </font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et peut savoir de </font><font style="vertical-align: inherit;">savoir s'il y a une am√©lioration de la pr√©cision des pr√©visions √©mises par le mod√®le.</font></font><br>
<br>
<pre><code class="python hljs">rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled_pca, y_train)<font></font>
display(rfc.score(X_train_scaled_pca, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les mod√®les se comparent ci-dessous.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7. Optimisation des hyperparam√®tres. </font><font style="vertical-align: inherit;">Round 1: RandomizedSearchCV</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir trait√© les donn√©es en utilisant la m√©thode du composant principal, vous pouvez essayer d'utiliser l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optimisation des hyperparam√®tres du</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mod√®le afin d'am√©liorer la qualit√© des pr√©dictions produites par le mod√®le RF. Les hyperparam√®tres peuvent √™tre consid√©r√©s comme quelque chose comme des ¬´param√®tres¬ª du mod√®le. Les param√®tres parfaits pour un ensemble de donn√©es ne fonctionneront pas pour un autre - c'est pourquoi vous devez les optimiser. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez commencer avec l'algorithme RandomizedSearchCV, qui vous permet d'explorer assez approximativement un large √©ventail de valeurs. Des descriptions de tous les hyperparam√®tres pour les mod√®les RF peuvent √™tre trouv√©es </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ici</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au cours du travail, nous g√©n√©rons une entit√© </font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">qui contient, pour chaque hyperparam√®tre, une plage de valeurs √† tester. Ensuite, nous initialisons l'objet.</font></font><code>rs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en utilisant la fonction </font></font><code>RandomizedSearchCV()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, en lui passant le mod√®le RF </font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, le nombre d'it√©rations et le nombre de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">validations crois√©es</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qui doivent √™tre effectu√©es. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'hyperparam√®tre </font></font><code>verbose</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">permet de contr√¥ler la quantit√© d'informations affich√©es par le mod√®le lors de son fonctionnement (comme la sortie d'informations lors de la formation du mod√®le). </font><font style="vertical-align: inherit;">L'hyperparam√®tre </font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous permet de sp√©cifier le nombre de c≈ìurs de processeur que vous devez utiliser pour garantir le fonctionnement du mod√®le. </font><font style="vertical-align: inherit;">La d√©finition </font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d'une valeur </font></font><code>-1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entra√Ænera un mod√®le plus rapide, car cela utilisera tous les c≈ìurs de processeur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous serons engag√©s dans la s√©lection des hyperparam√®tres suivants:</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - le nombre d '"arbres" dans la "for√™t al√©atoire".</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - le nombre d'entit√©s pour s√©lectionner le fractionnement.</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - profondeur maximale des arbres.</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - le nombre minimum d'objets n√©cessaires pour qu'un n≈ìud d'arbre se divise.</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - le nombre minimum d'objets dans les feuilles.</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - utiliser pour construire des arbres de sous-√©chantillons avec retour.</font></font></li>
</ul><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<font></font>
n_estimators = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">100</span>, stop = <span class="hljs-number">1000</span>, num = <span class="hljs-number">10</span>)]<font></font>
max_features = [<span class="hljs-string">'log2'</span>, <span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">1</span>, stop = <span class="hljs-number">15</span>, num = <span class="hljs-number">15</span>)]<font></font>
min_samples_split = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
min_samples_leaf = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
bootstrap = [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]<font></font>
param_dist = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
rs = RandomizedSearchCV(rfc_2,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;param_dist,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_iter = <span class="hljs-number">100</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv = <span class="hljs-number">3</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose = <span class="hljs-number">1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_jobs=<span class="hljs-number">-1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random_state=<span class="hljs-number">0</span>)<font></font>
rs.fit(X_train_scaled_pca, y_train)<font></font>
rs.best_params_<font></font>
<span class="hljs-comment"># {'n_estimators': 700,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'min_samples_leaf': 2,</span>
<span class="hljs-comment"># 'max_features': 'log2',</span>
<span class="hljs-comment"># 'max_depth': 11,</span>
<span class="hljs-comment"># 'bootstrap': True}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec les valeurs des param√®tres </font></font><code>n_iter = 100</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et </font></font><code>cv = 3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, nous avons cr√©√© 300 mod√®les RF, en choisissant al√©atoirement des combinaisons des hyper </font><font style="vertical-align: inherit;">param√®tres </font><font style="vertical-align: inherit;">pr√©sent√©s ci-dessus. </font><font style="vertical-align: inherit;">Nous pouvons nous r√©f√©rer √† l'attribut </font></font><code>best_params_ </code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour plus d'informations sur un ensemble de param√®tres qui vous permet de cr√©er le meilleur mod√®le. </font><font style="vertical-align: inherit;">Mais √† ce stade, cela ne nous donne peut-√™tre pas les donn√©es les plus int√©ressantes sur les plages de param√®tres qui m√©ritent d'√™tre explor√©es lors de la prochaine phase d'optimisation. </font><font style="vertical-align: inherit;">Afin de d√©couvrir dans quelle plage de valeurs il vaut la peine de poursuivre la recherche, nous pouvons facilement obtenir une trame de donn√©es contenant les r√©sultats de l'algorithme RandomizedSearchCV.</font></font><br>
<br>
<pre><code class="python hljs">rs_df = pd.DataFrame(rs.cv_results_).sort_values(<span class="hljs-string">'rank_test_score'</span>).reset_index(drop=<span class="hljs-literal">True</span>)<font></font>
rs_df = rs_df.drop([<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_score_time'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_score_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'params'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split0_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split1_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split2_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_test_score'</span>],<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis=<span class="hljs-number">1</span>)<font></font>
rs_df.head(<span class="hljs-number">10</span>)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/617/b8c/20b/617b8c20b787acc3c76c23d9235b4b5a.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©sultats de l'algorithme RandomizedSearchCV</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Nous allons maintenant cr√©er des graphiques √† barres sur lesquels, sur l'axe X, sont les valeurs d'hyperparam√®tre, et sur l'axe Y sont les valeurs moyennes affich√©es par les mod√®les. </font><font style="vertical-align: inherit;">Cela permettra de comprendre quelles valeurs des hyperparam√®tres affichent en moyenne leurs meilleures performances.</font></font><br>
<br>
<pre><code class="python hljs">fig, axs = plt.subplots(ncols=<span class="hljs-number">3</span>, nrows=<span class="hljs-number">2</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">2</span>)<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">25</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_n_estimators'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'lightgrey'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.83</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'n_estimators'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_split'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'coral'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.85</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'min_samples_split'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_leaf'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'lightgreen'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'min_samples_leaf'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_features'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'wheat'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'max_features'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_depth'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'lightpink'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'max_depth'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_bootstrap'</span>,y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'skyblue'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'bootstrap'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
plt.show()</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/418/311/ba6/418311ba6c38bfcebbf152af810d6b58.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analyse des valeurs des hyperparam√®tres</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Si nous analysons les graphiques ci-dessus, nous pouvons remarquer des choses int√©ressantes qui parlent de la fa√ßon dont, en moyenne, chaque valeur d'un hyperparam√®tre affecte le mod√®le.</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: des valeurs de 300, 500, 700, apparemment, montrent les meilleurs r√©sultats moyens.</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: Les petites valeurs comme 2 et 7 semblent donner les meilleurs r√©sultats. </font><font style="vertical-align: inherit;">La valeur 23 semble √©galement bonne. Vous pouvez examiner plusieurs valeurs de cet hyperparam√®tre au-del√† de 2, ainsi que plusieurs valeurs d'environ 23.</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: On a le sentiment que les petites valeurs de cet hyperparam√®tre donnent de meilleurs r√©sultats. </font><font style="vertical-align: inherit;">Cela signifie que nous pouvons exp√©rimenter des valeurs comprises entre 2 et 7.</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: l'option </font></font><code>sqrt</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">donne le r√©sultat moyen le plus √©lev√©.</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: il n'y a pas de relation claire entre la valeur de l'hyperparam√®tre et le r√©sultat du mod√®le, mais on a le sentiment que les valeurs 2, 3, 7, 11, 15 semblent bonnes.</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: la valeur </font></font><code>False</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">affiche le meilleur r√©sultat moyen.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, en utilisant ces r√©sultats, nous pouvons passer au deuxi√®me cycle d'optimisation des hyperparam√®tres. </font><font style="vertical-align: inherit;">Cela r√©duira la gamme de valeurs qui nous int√©resse.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8. Optimisation des hyperparam√®tres. </font><font style="vertical-align: inherit;">Tour 2: GridSearchCV (pr√©paration finale des param√®tres pour le mod√®le n ¬∞ 3, RF + PCA + HT)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir appliqu√© l'algorithme RandomizedSearchCV, nous utiliserons l'algorithme GridSearchCV pour effectuer une recherche plus pr√©cise de la meilleure combinaison d'hyperparam√®tres. Les m√™mes hyperparam√®tres sont √©tudi√©s ici, mais maintenant nous appliquons une recherche plus ¬´approfondie¬ª pour leur meilleure combinaison. En utilisant l'algorithme GridSearchCV, chaque combinaison d'hyperparam√®tres est examin√©e. Cela n√©cessite beaucoup plus de ressources de calcul que l'utilisation de l'algorithme RandomizedSearchCV lorsque nous d√©finissons ind√©pendamment le nombre d'it√©rations de recherche. Par exemple, la recherche de 10 valeurs pour chacun des 6 hyperparam√®tres avec validation crois√©e en 3 blocs n√©cessitera 10 √ó 3 ou 3 000 000 de sessions de formation sur mod√®le. C'est pourquoi nous utilisons l'algorithme GridSearchCV apr√®s, apr√®s avoir appliqu√© RandomizedSearchCV, nous avons r√©tr√©ci les plages de valeurs des param√®tres √©tudi√©s.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Donc, en utilisant ce que nous avons d√©couvert √† l'aide de RandomizedSearchCV, nous examinons les valeurs des hyperparam√®tres qui se sont le mieux montr√©es:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<font></font>
n_estimators = [<span class="hljs-number">300</span>,<span class="hljs-number">500</span>,<span class="hljs-number">700</span>]<font></font>
max_features = [<span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">7</span>,<span class="hljs-number">11</span>,<span class="hljs-number">15</span>]<font></font>
min_samples_split = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">22</span>,<span class="hljs-number">23</span>,<span class="hljs-number">24</span>]<font></font>
min_samples_leaf = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<font></font>
bootstrap = [<span class="hljs-literal">False</span>]<font></font>
param_grid = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
gs = GridSearchCV(rfc_2, param_grid, cv = <span class="hljs-number">3</span>, verbose = <span class="hljs-number">1</span>, n_jobs=<span class="hljs-number">-1</span>)<font></font>
gs.fit(X_train_scaled_pca, y_train)<font></font>
rfc_3 = gs.best_estimator_<font></font>
gs.best_params_<font></font>
<span class="hljs-comment"># {'bootstrap': False,</span>
<span class="hljs-comment"># 'max_depth': 7,</span>
<span class="hljs-comment"># 'max_features': 'sqrt',</span>
<span class="hljs-comment"># 'min_samples_leaf': 3,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'n_estimators': 500}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ici, nous appliquons la validation crois√©e √† 3 blocs pour 540 (3 x 1 x 5 x 6 x 6 x 1) sessions de formation de mod√®le, ce qui donne 1620 sessions de formation de mod√®le. </font><font style="vertical-align: inherit;">Et maintenant, apr√®s avoir utilis√© RandomizedSearchCV et GridSearchCV, nous pouvons nous tourner vers l'attribut </font></font><code>best_params_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour savoir quelles valeurs d'hyperparam√®tres permettent au mod√®le de mieux fonctionner avec l'ensemble de donn√©es √† l'√©tude (ces valeurs peuvent √™tre vues au bas du bloc de code pr√©c√©dent) . </font><font style="vertical-align: inherit;">Ces param√®tres sont utilis√©s pour cr√©er le mod√®le num√©ro 3.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9. √âvaluation de la qualit√© des mod√®les sur les donn√©es de v√©rification</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez maintenant √©valuer les mod√®les cr√©√©s sur les donn√©es de v√©rification. </font><font style="vertical-align: inherit;">√Ä savoir, nous parlons de ces trois mod√®les d√©crits au tout d√©but du mat√©riau. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D√©couvrez ces mod√®les:</font></font><br>
<br>
<pre><code class="python hljs">y_pred = rfc.predict(X_test_scaled)<font></font>
y_pred_pca = rfc.predict(X_test_scaled_pca)<font></font>
y_pred_gs = gs.best_estimator_.predict(X_test_scaled_pca)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cr√©ez des matrices d'erreurs pour les mod√®les et d√©couvrez dans quelle mesure chacune d'elles est capable de pr√©dire le cancer du sein:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix<font></font>
conf_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_pred), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_baseline_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_pca), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_tuned_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_gs), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
display(conf_matrix_baseline)<font></font>
display(<span class="hljs-string">'Baseline Random Forest recall score'</span>, recall_score(y_test, y_pred))<font></font>
display(conf_matrix_baseline_pca)<font></font>
display(<span class="hljs-string">'Baseline Random Forest With PCA recall score'</span>, recall_score(y_test, y_pred_pca))<font></font>
display(conf_matrix_tuned_pca)<font></font>
display(<span class="hljs-string">'Hyperparameter Tuned Random Forest With PCA Reduced Dimensionality recall score'</span>, recall_score(y_test, y_pred_gs))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f48/a9e/92f/f48a9e92fd5fdca613d6073e00bae2c6.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©sultats des travaux des trois mod√®les</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ici, la ¬´compl√©tude¬ª m√©trique (rappel) est √©valu√©e. </font><font style="vertical-align: inherit;">Le fait est que nous avons affaire √† un diagnostic de cancer. </font><font style="vertical-align: inherit;">Par cons√©quent, nous sommes extr√™mement int√©ress√©s √† minimiser les pr√©visions fausses n√©gatives √©mises par les mod√®les. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Compte tenu de cela, nous pouvons conclure que le mod√®le RF de base a donn√© les meilleurs r√©sultats. </font><font style="vertical-align: inherit;">Son taux d'exhaustivit√© √©tait de 94,97%. </font><font style="vertical-align: inherit;">Dans l'ensemble de donn√©es de test, il y avait un record de 179 patients atteints de cancer. </font><font style="vertical-align: inherit;">Le mod√®le en a trouv√© 170.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sommaire</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cette √©tude fournit une observation importante. </font><font style="vertical-align: inherit;">Parfois, le mod√®le RF, qui utilise la m√©thode des composants principaux et l'optimisation √† grande √©chelle des hyperparam√®tres, peut ne pas fonctionner aussi bien que le mod√®le le plus ordinaire avec des param√®tres standard. </font><font style="vertical-align: inherit;">Mais ce n'est pas une raison pour se limiter aux mod√®les les plus simples. </font><font style="vertical-align: inherit;">Sans essayer diff√©rents mod√®les, il est impossible de dire lequel affichera le meilleur r√©sultat. </font><font style="vertical-align: inherit;">Et dans le cas des mod√®les utilis√©s pour pr√©dire la pr√©sence de cancer chez les patients, nous pouvons dire que meilleur est le mod√®le - plus de vies peuvent √™tre sauv√©es. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chers lecteurs! </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelles t√¢ches r√©solvez-vous en utilisant des m√©thodes d'apprentissage automatique?</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr488330/index.html">Anglais avec George Karlin: nous analysons l'ing√©nieux stand-up sur les unit√©s phras√©ologiques</a></li>
<li><a href="../fr488332/index.html">Z√©ro, un, deux, Freddy viendra te chercher</a></li>
<li><a href="../fr488336/index.html">Conseils d'utilisation de l'algorithme de r√©duction de la fonction d'onde</a></li>
<li><a href="../fr488338/index.html">Stages Google: Zurich, Londres et Silicon Valley</a></li>
<li><a href="../fr488340/index.html">Profession: D√©veloppeur Backend</a></li>
<li><a href="../fr488346/index.html">Installation de ou-tools avec SCIP et GLPK dans un environnement virtuel Python 3.7 sous Linux</a></li>
<li><a href="../fr488348/index.html">Webinaire ¬´Les dix principaux d√©fis agiles et les moyens de les surmonter en une heure¬ª 17 f√©vrier √† 20 h, heure de Moscou</a></li>
<li><a href="../fr488352/index.html">Comparaison des co√ªts VDI: sur site et cloud public</a></li>
<li><a href="../fr488356/index.html">Formation √† l'Universit√© technique maritime de Saint-P√©tersbourg pour les produits Dassault Syst√®mes</a></li>
<li><a href="../fr488360/index.html">Mythes du Big Data et culture num√©rique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚶🏿 🏂🏽 🔆 機械学習モデルの脆弱性と保護に関する提案 🔏 👩🏼‍💼 🚴🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="最近、専門家は機械学習モデルのセキュリティの問題にますます対処し、さまざまな保護方法を提供しています。静的データセットでトレーニングされた線形モデルやツリーモデルなどの一般的な従来のモデリングシステムのコンテキストで潜在的な脆弱性と防御を詳細に研究する時が来ました。この記事の著者はセキュリティの専門...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>機械学習モデルの脆弱性と保護に関する提案</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/458892/"><img src="https://habrastorage.org/webt/gn/da/kl/gndaklzm6lwmn9ijp2pb9sxnmza.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最近、専門家は機械学習モデルのセキュリティの問題にますます対処し、さまざまな保護方法を提供しています。</font><font style="vertical-align: inherit;">静的データセットでトレーニングされた線形モデルやツリーモデルなどの一般的な従来のモデリングシステムのコンテキストで潜在的な脆弱性と防御を詳細に研究する時が来ました。</font><font style="vertical-align: inherit;">この記事の著者はセキュリティの専門家ではありませんが、機械学習におけるデバッグ、説明、公平性、解釈可能性、プライバシーなどのトピックを厳密にフォローしています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、典型的な組織の典型的な機械学習システムに対する攻撃の可能性のあるいくつかのベクトルを提示し、保護のための暫定的なソリューションを提供し、いくつかの一般的な問題と最も有望なプラクティスを検討します。</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.データ破損攻撃</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データの歪みとは、モデルの予測を操作するために誰かが体系的にトレーニングデータを変更することを意味します（このような攻撃は「因果的」攻撃とも呼ばれます）。</font><font style="vertical-align: inherit;">データを歪めるには、攻撃者がトレーニングデータの一部またはすべてにアクセスできる必要があります。</font><font style="vertical-align: inherit;">また、多くの企業で適切な管理が行われていない場合、さまざまな従業員、コンサルタント、請負業者がそのようなアクセス権を持つ可能性があります。</font><font style="vertical-align: inherit;">一部またはすべてのトレーニングデータへの不正アクセスは、セキュリティ境界の外側の攻撃者によっても取得される可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データの破損に対する直接的な攻撃には、データセットのラベルの変更が含まれる場合があります。したがって、モデルの商用利用が何であれ、攻撃者は、たとえばラベルを変更して予測を管理できるため、攻撃者に大規模なローンや大きな割引を提供したり、小さな保険料を設定したりする方法をモデルで学習できます。攻撃者の利益のためにモデルに誤った予測をさせることは、モデルの「完全性」の違反と呼ばれることがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
攻撃者はまた、データ破損を使用してモデルをトレーニングし、意図的に人々のグループを差別して、彼らに資格のある大きなローン、大きな割引、または低い保険料を奪うこともできます。基本的に、この攻撃はDDoSに似ています。モデルに他の人に害を及ぼすような誤った予測をさせることは、モデルの「アクセシビリティ」の違反と呼ばれることがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データセットの既存の行の値を変更するよりもデータを変形する方が簡単に思えるかもしれませんが、データセットに無害に見える列または余分な列を追加することによって、ひずみを導入することもできます。これらの列の値が変更されると、モデルの予測が変更される可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、データが破損した場合の保護およびエキスパート（フォレンジック）ソリューションの可能性をいくつか見てみましょう。</font></font><br>
<br>
<ul>
<li><b>  </b>.     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>    ,  ,        .         .                . , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Aequitas,</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Themis</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">AIF360</a>.<br>
</li>
<li><b>Fair  private-</b>.  ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   </a> (learning fair representations — LFR)  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   </a> (private aggregation of teacher ensembles — PATE),          .             .<br>
</li>
<li><b>    (Reject on Negative Impact — RONI)</b>. RONI —        ,    .    RONI .   8 «<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  </a>». <br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">残留分析</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">モデル予測の不一致、特に従業員、コンサルタント、または請負業者に関連する不一致で、奇妙で目立つパターンを検索します。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">自己反射</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">従業員、コンサルタント、請負業者のモデルを評価して、異常に良い予測を特定します。</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
微分影響分析、残差分析、自己反映は、トレーニング中およびモデルのリアルタイム監視のフレームワークで実行できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.透かし攻撃</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
透かしは、ディープラーニングの安全性に関する文献から借用された用語であり、モデルから望ましい結果を得るために画像に特別なピクセルを追加することを指します。</font><font style="vertical-align: inherit;">顧客データまたはトランザクションデータを使用して同じことを行うことは完全に可能です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
外部からの従業員、コンサルタント、請負業者、または攻撃者が、リアルタイムで予測を行うモデルの本番用のコードにアクセスできるシナリオを考えます。そのような人は、コードを変更して、入力変数値の奇妙な、またはありそうもない組み合わせを認識して、望ましい予測結果を得ることができます。データの破損と同様に、透かし攻撃は、モデルの整合性またはアクセス可能性に違反するために使用される可能性があります。たとえば、整合性を侵害するために、攻撃者はモデルの本番用の評価コードに「ペイロード」を挿入できます。その結果、アドレス99での0歳の組み合わせが認識され、攻撃者に何らかの前向きな予測が導かれます。そして、モデルの可用性をブロックするために、彼は人為的な識別ルールを評価コードに挿入できます。これにより、モデルが特定のグループの人々に肯定的な結果を与えることができなくなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
透かしを使用した攻撃に対する保護的かつ専門的なアプローチには、次のものがあります。</font></font><br>
<br>
<ul>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">異常検出</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">オートコーダーは、</font><font style="vertical-align: inherit;">複雑で奇妙な、または他のデータとは異なる入力を識別することができる</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">不正検出モデル</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。</font><font style="vertical-align: inherit;">潜在的に、自動エンコーダは悪意のあるメカニズムをトリガーするために使用される透かしを検出できます。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データ整合性の制限</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">多くのデータベースでは、奇妙な、または非現実的な入力変数の組み合わせが許可されていないため、透かし攻撃を防ぐことができます。</font><font style="vertical-align: inherit;">同じ効果が</font><font style="vertical-align: inherit;">、リアルタイムで受信されるデータストリームの</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">整合性の制約</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に対しても機能し</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">差別化された暴露分析</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セクション1を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">バージョン管理</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">モデルの本番アプリケーションの評価コードは、他の重要なソフトウェア製品と同様に、バージョン付けして管理する必要があります。</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
異常検出、データ整合性の制限、および差分影響分析は、トレーニング中およびリアルタイムモデルモニタリングの一部として使用できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3.サロゲートモデルの反転</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
通常、「反転」とは、モデルに情報を配置するのではなく、モデルから不正な情報を取得することを指します。また、反転は「偵察リバースエンジニアリング攻撃」の一例です。攻撃者がモデルまたは他のエンドポイント（Webサイト、アプリケーションなど）のAPIから多くの予測を取得できる場合、攻撃者は自分の</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">代理モデルを</font></a><font style="vertical-align: inherit;">トレーニングできます</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。簡単に言えば、これは予測モデルのシミュレーションです！理論的には、攻撃者は受信した予測の生成に使用される入力データと予測自体の間で代理モデルをトレーニングできます。行うことができる予測の数に応じて、サロゲートモデルはモデルのかなり正確なシミュレーションになります。サロゲートモデルをトレーニングした後、攻撃者は「サンドボックス」を使用して、偽装（つまり、「模倣」）またはモデルの整合性に関する競争力のある例を使用した攻撃を計画するか、機密のトレーニングデータの一部の側面の回復を開始する可能性を獲得します。サロゲートモデルは、次のような予測と何らかの形で一致する外部データソースを使用してトレーニングすることもできます。した</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">著者のCOMPAS再犯モデルを備えた</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ProPublica</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
サロゲートモデルを使用してモデルを反転から保護するには、次のようなアプローチを使用できます。</font></font><br>
<br>
<ul>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">許可されたアクセス</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">予測を取得するには、追加の認証（2要素など）を要求します。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">予測頻度の調整（スロットル予測）</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">個々のユーザーからの多数のクイック予測を制限します。</font><font style="vertical-align: inherit;">人為的に増加する予測遅延の可能性を考慮してください。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「ホワイト」（ホワイトハット）の代用モデル</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">白いハッカーの演習として、次のことを試してください。本番アプリケーションの入力予測とモデル予測の間で独自の代理モデルをトレーニングし、以下の側面を注意深く観察します。</font></font><br>
<ul>
<li>    «»  ;  ,                .<br>
</li>
<li>  ,      «»  , ,  ,    .<br>
</li>
<li>    ,        ,     «»   .<br>
</li>
<li>,     «»   , ,     ,    .<br>
</li>
</ul><br>
</li>
</ul><br>
<h2>4.    </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
理論的には、専用のハッカーが試行錯誤（つまり、「インテリジェンス」または「感度分析」）を学習できます-代理モデルまたはソーシャルエンジニアリングを逆転させ、モデルを操作して目的の予測結果を得る方法または望ましくないものを回避する方法予測。特別に設計されたデータ文字列を使用してそのような目標を達成しようとすることは、敵対的攻撃と呼ばれます。 （時には整合性を調査するための攻撃）。攻撃者は敵対的攻撃を使用して、多額のローンや低保険料を取得したり、犯罪リスクの高い評価による仮釈放の拒否を回避したりできます。一部の人々は、予測から望ましくない結果を「回避」として除外するために、競争の例を使用すると呼びます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以下に説明する方法を試して、競合例を使用して攻撃を防御または検出してください。</font></font><br>
<br>
<ul>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アクティベーション分析</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">活性化分析では、予測モデルに内部メカニズムの比較が必要です。たとえば、ニューラルネットワークのニューロンの平均活性化や、ランダムフォレストの各エンドノードに関連する観測の割合などです。</font><font style="vertical-align: inherit;">次に、この情報を、実際の着信データストリームを使用したモデルの動作と比較します。</font><font style="vertical-align: inherit;">私の同僚の一人が言ったように：「</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">これは、ランダムフォレストで1つのエンドノードを見るのと同じです。これは、0.1％のトレーニングデータに相当しますが、1時間あたり75％のスコアラインに適してい</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。」</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">異常検出</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セクション2を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照してください</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">許可されたアクセス</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セクション3を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照してください</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li><b> </b>.               .    ,      .           ,  ,        .           ( )  ,          .   ,       .<br>
</li>
<li><b>Throttle-</b>: .<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  3</a>.<br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「白」の感度分析</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">感度分析を使用して独自の調査攻撃を実施し、どの変数値（またはそれらの組み合わせ）が予測に大きな変動を引き起こす可能性があるかを理解します。</font><font style="vertical-align: inherit;">新しいデータを評価するときは、これらの値または値の組み合わせを探します。</font><font style="vertical-align: inherit;">「白い」調査分析を実施するには、オープンソースパッケージ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cleverhansを</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用できます</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">白い代理モデル：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セクション3を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照してください</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
活性化分析または比較モデルは、トレーニング中およびモデルのリアルタイム監視の一部として使用できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.なりすまし</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
意図的なハッカーは、試行錯誤を通じて、サロゲートモデルまたはソーシャルエンジニアリングによる反転を通じて、どの入力データまたは特定の人々が望ましい予測結果を取得しているかを確認できます。攻撃者はこの人物になりすまして、予測の恩恵を受けることができます。なりすまし攻撃は「シミュレートされた」攻撃と呼ばれることもあり、モデルの観点から見ると、これはIDの盗難を連想させます。競合例のある攻撃の場合と同様に、なりすましでは、入力データはモデルに応じて人為的に変更されます。ただし、ランダムな値の組み合わせが詐欺に使用される可能性がある競合例と同じ攻撃とは異なり、偽装では、このタイプのオブジェクトに関連付けられた予測を取得するために情報が使用されます。別のシミュレートされたオブジェクト（囚人、クライアント、従業員、金融取引、患者、製品など）に関連付けられています。攻撃者が、モデルのどの特性について、大幅な割引や特典の提供が依存しているかを知ることができるとします。それから彼はあなたがそのような割引を得るためにあなたが使う情報を偽造することができます。攻撃者は彼の戦略を他の人と共有することができ、それはあなたの会社に大きな損失をもたらす可能性があります。攻撃者は彼の戦略を他の人と共有することができ、それはあなたの会社に大きな損失をもたらす可能性があります。攻撃者は彼の戦略を他の人と共有することができ、それはあなたの会社に大きな損失をもたらす可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2ステージモデルを使用している場合は、「アレルギー」攻撃に注意してください。攻撃者は、モデルの第1ステージの通常の入力データの文字列をシミュレートして、第2ステージを攻撃できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
なりすましを伴う攻撃に対する保護的かつ専門的なアプローチには、次のようなものがあります。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">活性化分析。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セクション4を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照してください</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">許可されたアクセス。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セクション3を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参照してください</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
<li>   .    (scoring)    ,     .          ,   (MDS)     .          ,     .<br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">脅威通知機能。</font></font><code>num_similar_queries</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルをトレーニングまたは実装した直後は役に立たない可能性があるが、評価中（または将来の再トレーニング中）に使用して脅威をモデルまたはパイプラインに通知できる</font><font style="vertical-align: inherit;">関数をパイプラインに保存し</font><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">たとえば、評価時に値が</font></font><code>num_similar_queries</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ゼロより大きい場合、評価のリクエストを送信して手動で分析できます。</font><font style="vertical-align: inherit;">将来的には、モデルを再トレーニングするときに、高い値の入力ラインに</font></font><code>num_similar_queries</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">負の予測結果</font><font style="vertical-align: inherit;">を与えるようにモデルを教えることができます</font><font style="vertical-align: inherit;">。</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アクティベーション分析、重複チェック、および潜在的な脅威の通知は、トレーニング中およびモデルのリアルタイム監視の一部として使用できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6.一般的な問題</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一般的な機械学習の使用によっては、より一般的なセキュリティの問題も発生します。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ブラックボックスと不必要な複雑さ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。解釈モデルとモデルの説明における最近の進歩により、正確で透過的な非線形分類器とリグレッサを使用できるようになりましたが、多くの機械学習プロセスはブラックボックスモデルに焦点を合わせ続けています。これらは、商用の機械学習の標準的なワークフローにおける、しばしば不必要な複雑さの1つのタイプにすぎません。潜在的に有害な複雑さの他の例としては、過度に特殊な仕様や多数のパッケージ依存関係があります。これは、少なくとも2つの理由で問題になる可能性があります。</font></font><br>
<br>
<ol>
<li>               « » ,       (        «» ).        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>    ,    ,    .          ,    1-5,   ,     .<br>
</li>
<li>                    .         ,         . ,          ,       ,         .  ,            ,          « ».<br>
</li>
</ol><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分散システムとモデル</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。幸いにも、残念ながら、私たちはビッグデータの時代に生きています。今日、多くの組織が分散データ処理および機械学習システムを使用しています。分散コンピューティングは、内部または外部からの攻撃の大きな標的になる可能性があります。データは、大規模な分散データストレージまたは処理システムの1つまたは複数の作業ノードでのみ歪む可能性があります。透かしの裏口は、大きなアンサンブルの1つのモデルにエンコードできます。実践者は、1つの単純なデータセットまたはモデルをデバッグする代わりに、大規模なコンピューティングクラスターに散在するデータまたはモデルを調査する必要があります。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分散型サービス拒否（DDoS）攻撃</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">予測モデリングサービスが組織の活動で重要な役割を果たす場合、正当なユーザーの予測の生成を遅らせたり停止したりするために、攻撃者が信じられないほど多数のリクエストで予測サービスを攻撃する場合は、少なくとも最も一般的な分散DDoS攻撃を考慮に入れてください。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.一般的な決定</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
セキュリティシステムの脆弱性を減らし、機械学習システムの公平性、制御性、透明性、信頼性を高めるために、いくつかの一般的な新旧の最も効果的な方法を使用できます。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">承認されたアクセスおよび頻度規制（スロットリング）予測</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。追加の認証や予測頻度の調整などの標準的なセキュリティ機能は、セクション1〜5で説明されている多くの攻撃ベクトルをブロックするのに非常に効果的です。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">比較モデル</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。予測で操作が行われたかどうかを判断するための比較モデルとして、古くて実績のあるモデリングパイプラインまたは透明性の高い他の解釈された予測ツールを使用できます。操作には、データの破損、透かし攻撃、または競合例が含まれます。テストしたモデルの予測と、より複雑で不透明なモデルの予測との差が大きすぎる場合は、そのような場合を書き留めます。それらを分析者に送るか、状況を分析または修正するために他の手段を講じます。ベンチマークとコンベヤが安全で、元の信頼できる状態から変化しないようにするには、深刻な予防策を講じる必要があります。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">解釈された、公正な、または私的なモデル</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。現在、方法があります（例：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">単調なGBM（M-GBM）、</font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スケーラブルなベイジアンルールリスト（SBRL）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">説明可能なニューラルネットワーク（XNN））</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）正確さと解釈可能性の両方を提供します。これらの正確で解釈可能なモデルは、機械学習の従来のブラックボックスよりも文書化およびデバッグが容易です。新しいタイプの公正でプライベートなモデル（LFR、PATEなど）は、競合例を使用した攻撃中にソーシャルエンジニアリングを使用して、観察可能な外部から見える人口統計学的特徴にあまり注意を払わない方法でトレーニングすることもできます。なりすまし。今後、新しい機械学習プロセスの作成を検討していますか？リスクの少ない解釈されたプライベートモデルまたはフェアモデルに基づいて構築することを検討してください。これらはデバッグが容易で、個々のオブジェクトの特性の変化に耐性がある可能性があります。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セキュリティモデルのデバッグ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデル</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">デバッグする</font></a><font style="vertical-align: inherit;">ための新しい領域は</font><font style="vertical-align: inherit;">、機械学習モデルのメカニズムと予測のエラーを検出し、それらを修正することに専念しています。サロゲートモデル、残差分析、感度分析などのデバッグツールを使用して、脆弱性を特定するためのホワイトトライアルや、発生する可能性のあるまたは発生する可能性のある攻撃を特定するための分析演習で使用できます。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルのドキュメントと説明方法</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。モデルドキュメントは、何十年もの間銀行で使用されてきたリスク削減戦略です。これにより、モデル所有者の構成が変化したときに、複雑なモデリングシステムに関する知識を保存および転送できます。従来、ドキュメントは透明度の高い線形モデルに使用されてきました。しかし、強力で正確な説明ツール（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SHAPツリー</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">や</font><font style="vertical-align: inherit;">ニューラルネットワークの</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ローカル関数の派生ベースの属性など</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）の登場により、以前から存在していたブラックボックスモデルのワークフローを少なくとも少し説明し、デバッグし、文書化することができます。明らかに、ドキュメントには既知、修正済み、または予想される脆弱性を含むすべてのセキュリティ対策方針が含まれているはずです。</font></font><br>
<br>
<b>       </b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。深刻な開業医は、ほとんどのモデルがデータセットの形式で現実の静的な「スナップショット」でトレーニングされていること、および現在の状態が以前に収集された情報から離れているため、予測の精度がリアルタイムで低下することを理解しています。今日、ほとんどのモデルの監視は、入力変数の分布におけるそのようなバイアスを特定することを目的としており、最終的には精度の低下につながります。モデルの監視は、セクション1〜5で説明した攻撃と、モデルのデバッグ時に明らかになるその他の潜在的な脅威を追跡するように設計する必要があります。これは常に安全性に直接関係しているわけではありませんが、差別化された効果についてモデルをリアルタイムで評価する必要もあります。モデルのドキュメント、すべてのモデリングアーティファクト、ソースコードと関連するメタデータは、管理、バージョン管理、セキュリティのチェック、およびそれらの貴重な商用資産を管理する必要があります。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">脅威通知機能</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。可能性のある脅威を通知する手段を備えたモデルまたはプロセスに、予備処理または後続処理の機能、ルール、およびステージを含めることができます。たとえば、モデル内の類似線の数。現在の行が従業員、請負業者、またはコンサルタントを表すかどうか。現在の行の値は、競合する例のある白い攻撃で得られたものと似ていますか？これらの関数は、モデルの最初のトレーニング中に必要な場合と必要でない場合があります。しかし、それらのスペースを節約することは、新しいデータの評価やその後のモデルの再トレーニングに非常に役立ちます。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">システム異常検知</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">予測モデル作成システム全体の運用統計（特定の期間の予測数、遅延、CPU、メモリとディスクの負荷、同時ユーザーの数など）のオートコーダーに基づいて異常を検出するメタモードをトレーニングし、このメタモデルを注意深く監視します異常。</font><font style="vertical-align: inherit;">異常は、問題が発生したかどうかを判断できます。</font><font style="vertical-align: inherit;">問題の原因を正確に追跡するには、フォローアップ調査または特別なメカニズムが必要になります。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.参考資料と詳細情報</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
機械学習のセキュリティに関する最新の学術文献の多くは、適応学習、ディープラーニング、暗号化に焦点を当てています。しかし、これまでのところ、著者は実際にこれをすべて行う実務家を知りません。したがって、最近公開された記事や投稿に加えて、有用な情報源であるネットワーク違反、ウイルス検出、スパムフィルタリング、および関連トピックに関する1990年代および2000年代初頭の記事を紹介します。機械学習モデルを保護するという興味深いトピックについて詳しく知りたい場合は、投稿の作成に使用された過去と現在の主要なリンクを以下に示します。</font></font><br>
<br>
<ul>
<li>,   . «  ». Machine Learning 81.2 (2010): 121-148. URL. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">https://people.eecs.berkeley.edu/<sub>~</sub>adj/publications/paper-files/SecML-MLJ2010.pdf</a><br>
</li>
<li>, . «  :    ». DZone (2018). URL. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">https://dzone.com/articles/security-attacks-analysis-of-machine-learning-mode</a><br>
</li>
<li>,   , . «     .  ,   ». O’Reilly Ideas (2019). URL. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">https://www.oreilly.com/ideas/you-created-a-machine-learning-application-now-make-sure-its-secure</a><br>
</li>
<li>, . «       :      ,        ».  11-  ACM     . ACM (2018). URL. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">https://arxiv.org/pdf/1811.01134.pdf</a><br>
</li>
</ul><br>
<h2></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
機械学習の科学と実践に関心を持つ人々は、機械学習によるハッキングの脅威と、機密性の侵害やアルゴリズムによる差別の脅威の増大が相まって、機械学習と人工知能に関する一般市民や政治への懐疑論を増大させる可能性があることを懸念しています。</font><font style="vertical-align: inherit;">私たちは皆、最近のAIの困難な時期を思い出す必要があります。</font><font style="vertical-align: inherit;">セキュリティの脆弱性、プライバシーの侵害、およびアルゴリズムによる差別が潜在的に組み合わされて、コンピュータートレーニングの研究への資金が削減されたり、この分野を規制する厳格な措置につながる可能性があります。</font><font style="vertical-align: inherit;">危機を回避し、その結果を混乱させないために、これらの重要な問題の議論と解決を続けましょう。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja458882/index.html">公演。主なことについて簡単に</a></li>
<li><a href="../ja458884/index.html">宇宙通信規格について少し</a></li>
<li><a href="../ja458886/index.html">最も有用なMail.ru Design Conf×Dribbble Meetup 2019論文by True Engineering</a></li>
<li><a href="../ja458888/index.html">夏のドロイドのMeetup</a></li>
<li><a href="../ja458890/index.html">サンプリングと計算の精度</a></li>
<li><a href="../ja458894/index.html">典型的な人々と彼らが住んでいるネットワーク</a></li>
<li><a href="../ja458896/index.html">関数型JavaScript：高次関数とは何ですか？なぜそれらが必要なのですか？</a></li>
<li><a href="../ja458900/index.html">モデムとしてのコンソールカートリッジ</a></li>
<li><a href="../ja458902/index.html">5つの一般的な初心者のPythonの間違い</a></li>
<li><a href="../ja458904/index.html">Rのアニメーション化された棒グラフを使用したNBAチームの勝利数の視覚化</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
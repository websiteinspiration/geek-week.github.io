<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚öõÔ∏è üêÅ üñ•Ô∏è Speed ‚Äã‚Äãup numpy, scikit and pandas 100 times with Rust and LLVM: interview with developer Weld üõë üò¶ ü§πüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, Habr! I present to you the translation of the article "Interview with Weld's main contributor: accelerating numpy, scikit and pandas as much as...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Speed ‚Äã‚Äãup numpy, scikit and pandas 100 times with Rust and LLVM: interview with developer Weld</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/497346/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hello, Habr! I present to you the translation of the article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Interview with Weld's main contributor: accelerating numpy, scikit and pandas as much as 100x with Rust and LLVM"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After working for several weeks with data science tools in Python and R, I began to wonder if there is any intermediate representation (IR) like CUDA that can be used in different languages. There must be something better than reimplementation and optimization of the same methods in each language. In addition to this, it would be nice to have a common runtime to optimize the entire program, rather than each function individually. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After several days of researching and testing various projects, I found </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Weld</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(you can read the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">academic article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To my surprise, one of the author Weld is </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Matei Zaharia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Matei Zaharia), the creator of Spark. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, I contacted </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Shoumik Palkar</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Weld's main contributor, and interviewed him. </font><font style="vertical-align: inherit;">Showmick is a graduate student at the Department of Computer Science at Stanford University, where he entered on the advice of Matey Zakharia. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weld is not yet ready for industrial use, but very promising. </font><font style="vertical-align: inherit;">If you are interested in the future of data science and Rust in particular, you will love this interview.</font></font><br>
<a name="habracut"></a><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Advertisement of the author of the original article</font></font></b><div class="spoiler_text"><img src="https://habrastorage.org/webt/9r/ca/bq/9rcabqje-oekzfhuecowkord13a.png" alt="image"><br>
  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"></a> ¬´Not a Monad Tutorial¬ª,   Weld    .  !<br>
<br>
    ,     mail@fcarrone.com           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow">@unbalancedparen</a>.<br>
</div></div><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What was Weld designed for, what problems does it solve?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weld's goal is to increase productivity for applications that use high-level APIs such as NumPy and Pandas. The main problem that he solves is cross-functional and cross-library optimizations not provided by other libraries today. In particular, many widely used libraries have modern implementations of algorithms for individual functions (for example, the fast join algorithm implemented in Pandas by C, or the quick matrix multiplication in NumPy), but they do not provide the possibility of optimizing the combination of these functions. For example, preventing unnecessary memory scans when performing matrix multiplication followed by aggregation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weld provides a common runtime environment that allows libraries to express computations in a common intermediate representation (IR). </font><font style="vertical-align: inherit;">This IR can then be optimized using the compiler optimizer, and then compiled on the fly (JIT) into parallel machine code with optimizations such as loop merging, vectorization, etc. </font><font style="vertical-align: inherit;">Weld's IR is initially parallel, so the programs expressed in it can always be trivially parallelized. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We also have a new project called Split annotations, which will be integrated with Weld and designed to reduce the barrier to the inclusion of such optimizations in existing libraries.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wouldn't it be easier to optimize numpy, pandas and scikit? </font><font style="vertical-align: inherit;">How much faster is it?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weld provides an optimization of the combination of functions in these libraries, while optimization of the libraries can accelerate the calls of only individual functions. In fact, many of these libraries are already very well optimized for each individual function, but provide performance below the limits of modern equipment, because they do not use parallelism or do not use the memory hierarchy efficiently.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For example, many NumPy functions for multidimensional arrays (ndarray) are implemented in the low-level C language, but a call to each function requires a full scan of the input data. If these arrays do not fit in the CPU caches, most of the execution time can be spent loading data from main memory, rather than performing calculations. Weld can view individual function calls and perform optimizations, such as combining loops that will store data in caches or CPU registers. Such optimizations can improve performance by more than an order of magnitude in multi-core systems, since they provide better scalability.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/pw/12/uo/pw12uohofii1vdbwzb8fdcucfus.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Integrations of Weld prototypes with Spark (top left), NumPy (top right) and TensorFlow (bottom left) show up to 30-fold improvement over their own infrastructure implementations without changes in the user application code. </font><font style="vertical-align: inherit;">Cross-library optimization of Pandas and NumPy (bottom right) can improve performance by two orders of magnitude.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What is Baloo?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Baloo is a library that implements a subset of the Pandas API using Weld. </font><font style="vertical-align: inherit;">It was developed by Radu Jica, a Master in CWI (Centrum Wiskunde &amp; Informatica, Amsterdam). </font><font style="vertical-align: inherit;">The goal of Baloo is to apply the above optimization types to Pandas to improve single-threaded performance, reduce memory usage, and ensure concurrency.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Does Weld / Baloo support external operations (like, say, Dask) for processing data that does not fit in memory?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weld and Baloo currently do not support external operations (out-of-core, external memory), although we will be happy to receive opensource-development in this direction!</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Why did you choose Rust and LLVM to implement Weld? </font><font style="vertical-align: inherit;">Did you come to Rust right away?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We chose Rust because:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It has a minimal runtime (in fact, it simply checks the boundaries of arrays) and is easy to embed in other languages ‚Äã‚Äãsuch as Java and Python</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It contains functional programming paradigms, such as pattern matching, which make writing code easier, for example, to optimize the pattern matching compiler</font></font></li>
<li>       ( Rust   crates),     .</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We chose LLVM because it is an open source compilation framework that is widely used and supported. We generate LLVM directly instead of C / C ++, so we do not need the C compiler. It also reduces compilation time, since we do not parse C / C ++ code. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Rust was not the first language Weld was implemented in. The first implementation was on Scala, which was chosen because of its algebraic data types and the presence of such a powerful feature as pattern matching. This simplified the writing of the optimizer, which is the main part of the compiler. Our original optimizer was made like Catalyst, an extensible optimizer in Spark SQL. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We moved away from Scala because it was too difficult to embed the JVM-based language in other runtimes and languages.</font></font><br>
<br>
<h4> Weld   CPU  GPU,         RAPIDS,   data science  Python  GPU?</h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main difference between Weld and systems such as RAPIDS is that it is aimed at optimizing applications containing different kernels (functions in CUDA terms) by compiling on the fly, and not at optimizing implementations of individual functions. For example, the Weld GPU backend will compile one single CUDA kernel optimized for the final application, instead of invoking separate kernels. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, Weld IR is hardware independent, which allows it to be used for both the GPU and the CPU, as well as non-standard equipment such as vector processors. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, Weld essentially intersects with other projects in the same field, including RAPIDS, and is created under their influence.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Runtime environments such as Bohrium (implements lazy computing in NumPy) and Numba (Python library, JIT code compiler) share Weld's high-level goals. </font><font style="vertical-align: inherit;">And optimizer systems like Spark SQL directly influence Weld design.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Does Weld have other uses besides data science library optimizations?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
One of the most exciting aspects of Weld IR is that it natively supports data concurrency. </font><font style="vertical-align: inherit;">This means that loop parallelization in Weld IR is always safe. </font><font style="vertical-align: inherit;">This makes Weld IR attractive for new types of equipment. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For example, NEC employees used Weld to run Python workloads on a custom high-bandwidth vector processor, simply adding a new backend to an existing Weld IR. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
IR can also be used to implement a layer of physical operations in a database. </font><font style="vertical-align: inherit;">And we plan to add features that will also allow us to compile a subset of Python into Weld code.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Are libraries ready for use in real projects? </font><font style="vertical-align: inherit;">And if not, when can you expect a finished result?</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Many of the examples and benchmarks on which we tested these libraries are taken from the real workload. Therefore, we would really like users to try the current version in their applications, and leave their feedback. And, best of all, they proposed their own patches. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In general, at the moment it cannot be said that in real applications everything will work out of the box. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Our next releases over the next few months will focus exclusively on the usability and reliability of Python libraries. Our goal is to make libraries good enough for inclusion in real projects. And also the ability to use non-Weld library versions in places where support has not yet been added.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As I noted in the first question, the Split annotations project ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">source code</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">academic article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) should simplify this transition. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Split annotations is a system that allows you to add annotations to existing code to determine how to split, transform, and parallelize it. It provides the optimization that we consider most effective in Weld (storing data chunks in CPU caches between function calls, instead of scanning the entire data set). But Split annotations are much easier to integrate than Weld, because they use existing library code without relying on the IR compiler. It also facilitates maintenance and debugging, which in turn improves reliability.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Libraries that do not yet have full Weld support can use Split annotations. </font><font style="vertical-align: inherit;">This will allow us to gradually add Weld support based on user feedback, while incorporating new optimizations.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en497334/index.html">The notorious bugs and how to avoid them on the example of ClickHouse</a></li>
<li><a href="../en497336/index.html">Computer brands of the 90s, part 3, final</a></li>
<li><a href="../en497338/index.html">What happened to transport last week - the crisis is developing</a></li>
<li><a href="../en497340/index.html">COVID-19: how to stop reading news and start analyzing data</a></li>
<li><a href="../en497342/index.html">Browser on guard of API requests: building secure communication between the front-end and the back-end</a></li>
<li><a href="../en497350/index.html">Violation of Terms of Service is not a crime yet</a></li>
<li><a href="../en497356/index.html">Separate customers by loyalty using RFM analysis</a></li>
<li><a href="../en497358/index.html">PhpStorm 2020.1: support composer.json, tools for PHPUnit, code coverage with PCOV and PHPDBG, Grazie and more</a></li>
<li><a href="../en497362/index.html">How the first American inventors funded their businesses</a></li>
<li><a href="../en497368/index.html">Hackintosh on Powermac G5 or how to assemble a workstation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
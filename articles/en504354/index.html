<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçü§ù‚Äçüë®üèº ‚òëÔ∏è üïé Reduce the size of the ML model without registration and SMS üëáüèΩ ‚ùî ü¶ñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anyone who encounters machine learning understands that this requires serious computing power. In this article, we will try to apply the algorithm dev...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Reduce the size of the ML model without registration and SMS</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/504354/"><img src="https://habrastorage.org/webt/u3/w2/jm/u3w2jmkqidenskb9-sgwysh2gy8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anyone who encounters machine learning understands that this requires serious computing power. In this article, we will try to apply the algorithm developed in MIT to compress a neural network, which will reduce the dimension of the weights of the trained model and will lead to both faster learning and faster model launch. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Neural networks have proven to be an excellent tool for solving a wide variety of tasks, but, unfortunately, their use requires significant computing power, which still may not be in a small business. There are many types of compression of neural networks that can be divided into hardware, low-level, and mathematical, but this article will discuss the method developed at MIT in 2019 and working directly with the neural network itself.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This method is called the ‚ÄúWinning Ticket Hypothesis‚Äù. </font><font style="vertical-align: inherit;">In general terms, it sounds like this: Any fully-connected neural network with randomly initialized weights contains a subnet with the same weights, and such a subnet trained separately can be equal in accuracy to the original network. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Formal proof and full article can be found </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">We are interested in the possibility of practical application. </font><font style="vertical-align: inherit;">In short, the algorithm is as follows:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We create a model, randomly initialize its parameters</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Learning a network of iterations j</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We cut off those network parameters that have the smallest value (the simplest task is to set some threshold value)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We reset the remaining parameters to their initial values, we get the subnet we need.</font></font></li>
</ol><br>
<a name="habracut"></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In theory, this algorithm needs to be repeated the nth number of steps, but for an example we will carry out only one iteration. </font><font style="vertical-align: inherit;">Create a simple fully connected network using tensorflow and Keras:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<font></font>
<font></font>
model = keras.Sequential([<font></font>
    keras.layers.Flatten(input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>)),<font></font>
    keras.layers.Dense(<span class="hljs-number">300</span>, activation=<span class="hljs-string">'relu'</span>),<font></font>
    keras.layers.Dense(<span class="hljs-number">150</span>, activation=<span class="hljs-string">'relu'</span>),<font></font>
    keras.layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">'softmax'</span>)<font></font>
])<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'SGD'</span>,<font></font>
              loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We will get the following network architecture: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/t6/c_/cy/t6c_cypjz1pyzbzlebveqxseiag.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And we will train it on the MNIST-fashion dataset of 60,000 images. </font><font style="vertical-align: inherit;">Its accuracy on the verification data will be equal to 0.8594. </font><font style="vertical-align: inherit;">We apply to the parameters of network 1 iteration of this algorithm. </font><font style="vertical-align: inherit;">In code, it looks like this:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span>
threshold = <span class="hljs-number">0.001</span><font></font>
<font></font>
<span class="hljs-comment">#       np.array</span><font></font>
weights = model.weights<font></font>
weights = np.asarray(weights)<font></font>
<font></font>
<span class="hljs-comment">#    </span>
first_h_layer_weights = weights[<span class="hljs-number">1</span>]<font></font>
second_h_layer_weights = weights[<span class="hljs-number">3</span>]<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">delete_from_layers</span>(<span class="hljs-params">one_d_array, threshold</span>):</span><font></font>
    index = []<font></font>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(one_d_array.shape[<span class="hljs-number">0</span>]):
        <span class="hljs-comment">#   ,       </span>
        <span class="hljs-keyword">if</span> abs(one_d_array[i]) &lt;= threshold:<font></font>
            index.append(i)<font></font>
    <span class="hljs-comment">#    ,   </span><font></font>
    new_layer = np.delete(one_d_array, index)<font></font>
    <span class="hljs-keyword">return</span> new_layer<font></font>
<font></font>
new_layer_weights = delete_from_layers(second_h_layer_weights, threshold)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thus, after executing this code, we will get rid of practically unused weights. </font><font style="vertical-align: inherit;">Two things are worth noting: in this example, the threshold was chosen empirically and this algorithm cannot be applied to the weights of the input and output layers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Having received new weights, it is necessary to redefine the original model, removing the excess. </font><font style="vertical-align: inherit;">As a result, we get:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yd/yp/uo/ydypuoqyvx--8f5bgzjr-yee97q.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can notice that the total number of parameters decreased by almost 2 times, which means that when training the first network, more than half of the parameters were simply unnecessary. </font><font style="vertical-align: inherit;">At the same time, the accuracy of the subnet is 0.8554, which is slightly lower than the main network. </font><font style="vertical-align: inherit;">Of course, this example is indicative, usually the network can be reduced by 10-20% of the initial number of parameters. </font><font style="vertical-align: inherit;">Here, even without applying this algorithm, it is clear that the original architecture was chosen too cumbersome. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In conclusion, we can say that this technique is not well developed at the moment, and in real problems, an attempt to optimize the model‚Äôs weights in this way can only lengthen the learning process, but the algorithm itself has quite a lot of potential.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en504338/index.html">USB over IP –≤ –¥–æ–º–∞—à–Ω–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö</a></li>
<li><a href="../en504342/index.html">–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å, –∫–æ—Ç–æ—Ä—É—é –≤—ã –Ω–µ –¥–∞–µ—Ç–µ, —Ç–∞–∫ –∂–µ –∑–Ω–∞—á–∏–º–∞, –∫–∞–∫ –∏ —Ç–∞, –∫–æ—Ç–æ—Ä—É—é –¥–∞–µ—Ç–µ</a></li>
<li><a href="../en504344/index.html">–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî CUSTOM SETUP / AWS Amplify + React Native</a></li>
<li><a href="../en504348/index.html">Monowheel: what happens during training, and how to accelerate this process</a></li>
<li><a href="../en504352/index.html">Ten companies that Figma helped achieve new design results and more</a></li>
<li><a href="../en504356/index.html">PHP 8 in eight pieces of code</a></li>
<li><a href="../en504358/index.html">PuppetConf 2016. Kubernetes for system administrators. Part 2</a></li>
<li><a href="../en504362/index.html">Quickly load large amounts of data in Google Colab</a></li>
<li><a href="../en504370/index.html">Office 365 & Microsoft Teams - Convenience of Collaboration and Impact on Security</a></li>
<li><a href="../es486176/index.html">Memo de correspondencia de correo electr√≥nico corporativo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
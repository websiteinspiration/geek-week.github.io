<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏹 ↗️ 🍙 ニューラルネットワークを使用してテキスト会話の感情を自動的に検出 🖖🏻 📍 👱</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="インタラクティブシステムの主なタスクの1つは、ユーザーが必要とする情報を提供することだけでなく、できるだけ多くの人間の答えを生成することです。そして、対談者の感情の認識は、単なるクールな機能ではなく、不可欠なものです。この記事では、コンピューター言語学の年次コンテストであるSemEval-2019タ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ニューラルネットワークを使用してテキスト会話の感情を自動的に検出</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
インタラクティブシステムの主なタスクの1つは、ユーザーが必要とする情報を提供することだけでなく、できるだけ多くの人間の答えを生成することです。そして、対談者の感情の認識は、単なるクールな機能ではなく、不可欠なものです。この記事では</font><font style="vertical-align: inherit;">、コンピューター言語学の年次コンテストで</font><font style="vertical-align: inherit;">ある</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">SemEval-2019タスク3“ EmoContext”</font></a><font style="vertical-align: inherit;">に参加した、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキスト会話の感情を決定するためのリカレントニューラルネットワークのアーキテクチャについて説明します</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。タスクは、チャットボットと人が参加した3つの発言の会話で感情（「幸せ」、「悲しい」、「怒り」、「その他」）を分類することでした。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
記事の最初の部分では、EmoContextで設定されたタスクと、主催者が提供するデータについて検討します。</font><font style="vertical-align: inherit;">2番目と3番目の部分では、テキストの予備処理と単語のベクトル表現の方法を分析します。</font><font style="vertical-align: inherit;">第4部では、競争で使用したLSTMアーキテクチャについて説明します。</font><font style="vertical-align: inherit;">コードは、Kerasライブラリを使用してPythonで記述されています。</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.トレーニングデータ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SemEval-2019のトラック「EmoContext」は、通信のコンテキストを考慮して、テキスト会話の感情の定義に特化していました。</font><font style="vertical-align: inherit;">この場合のコンテキストは、対話参加者のいくつかの連続した発言です。</font><font style="vertical-align: inherit;">会話には2人の参加者がいます。匿名ユーザー（彼は最初と3番目のレプリカを所有しています）とチャットボット</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ruuh</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（2番目のレプリカを所有しています）です。</font><font style="vertical-align: inherit;">3つのレプリカに基づいて、チャットボットに回答を書き込んだときにユーザーがどのような感情を感じたかを判断する必要があります（表1）。</font><font style="vertical-align: inherit;">全体として、データセットのマークアップには、「幸せ」、「悲しい」、「怒っている」、「その他」の4つの感情が含まれていました（表1）。</font><font style="vertical-align: inherit;">詳細な説明はここにあります：（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chatterjee et al。、2019</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">表1. EmoContextデータセットの例（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chatterjee et al。、2019</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font></font></i><br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ユーザー（ステージ1）</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">対話型ロボット（ステージ1）</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ユーザー（ステージ2）</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">真のクラス</font></font></th>
</tr>
<tr>
<td>I just qualified for the Nabard internship</td>
<td>WOOT! That’s great news. Congratulations!</td>
<td>I started crying</td>
<td></td>
</tr>
<tr>
<td>How dare you to slap my child</td>
<td>If you spoil my car, I will do that to you too</td>
<td>Just try to do that once</td>
<td></td>
</tr>
<tr>
<td>I was hurt by u more</td>
<td>You didn’t mean it.</td>
<td>say u love me</td>
<td></td>
</tr>
<tr>
<td>I will do night.</td>
<td>Alright. Keep me in loop.</td>
<td>Not giving WhatsApp no.</td>
<td></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
コンテストの間、主催者はいくつかのデータセットを提供しました。</font><font style="vertical-align: inherit;">トレーニングデータセット（Train）は、30,160の手動でマークされたテキストで構成されていました。</font><font style="vertical-align: inherit;">これらのテキストには、クラス「ハッピー」、「悲しい」、「怒っている」に属する約5000のオブジェクトと、クラス「その他」からの15000のテキストが含まれていました（表2）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
主催者は、開発（Dev）とテスト（Test）のデータセットも提供しました。トレーニングデータセットとは異なり、感情のクラスごとの分布は実際の生活に対応しました。「幸せ」、「悲しい」、「怒り、そして残りはクラス「その他」です。</font><font style="vertical-align: inherit;">マイクロソフトが提供するデータは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LinkedInの公式グループで</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ダウンロードできます</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">表2.データセット内の感情クラスラベルの分布（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chatterjee et al。、2019</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font></font></i><br>
<div class="scrollable-table"><table>
<tbody><tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データセット</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">幸福</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">悲しみ</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">怒り</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">その他の</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">合計</font></font></th>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニング</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14.07％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">18.11％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">18.26％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">49.56％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">30 160</font></font><br>
</td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">開発用</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.15％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4.54％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 5.45％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">84.86％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2755</font></font><br>
</td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テスト</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.16％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4.54％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.41％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 84.90％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5509</font></font><br>
</td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">リモート</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">33.33％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">33.33％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">33.33％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0％</font></font><br>
</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">90万</font></font><br>
</td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このデータに加えて、Twitterから90万の英語メッセージを収集して、遠隔データセット（感情ごとに30万ツイート）を作成しました。</font><font style="vertical-align: inherit;">それを作成するにあたり、私たちはGoらの戦略に従いました。</font><font style="vertical-align: inherit;">（2009）、＃angry、＃annoyed、＃happy、＃sad、＃surprisedなど、感情に関連する単語の存在に単純に関連付けられているフレームワーク。</font><font style="vertical-align: inherit;">用語のリストは、SemEval-2018 AIT DISC（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Duppada et al。、2018</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">の用語に基づいてい</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
EmoContextコンテストの主な品質指標は、3つのクラスの感情、つまり「幸せ」、「悲しい」、「怒り」のクラスの平均F1メジャーです。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocessData</span>(<span class="hljs-params">dataFilePath, mode</span>):</span><font></font>
	conversations = []<font></font>
	labels = []<font></font>
	<span class="hljs-keyword">with</span> io.open(dataFilePath, encoding=<span class="hljs-string">"utf8"</span>) <span class="hljs-keyword">as</span> finput:<font></font>
    	finput.readline()<font></font>
    	<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> finput:<font></font>
        	line = line.strip().split(<span class="hljs-string">'\t'</span>)
        	<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>):<font></font>
            	line[i] = tokenize(line[i])<font></font>
        	<span class="hljs-keyword">if</span> mode == <span class="hljs-string">"train"</span>:<font></font>
            	labels.append(emotion2label[line[<span class="hljs-number">4</span>]])<font></font>
        	conv = line[<span class="hljs-number">1</span>:<span class="hljs-number">4</span>]<font></font>
        	conversations.append(conv)<font></font>
	<span class="hljs-keyword">if</span> mode == <span class="hljs-string">"train"</span>:
    	<span class="hljs-keyword">return</span> np.array(conversations), np.array(labels)
	<span class="hljs-keyword">else</span>:
    	<span class="hljs-keyword">return</span> np.array(conversations)<font></font>
<font></font>
texts_train, labels_train = preprocessData(<span class="hljs-string">'./starterkitdata/train.txt'</span>, mode=<span class="hljs-string">"train"</span>)<font></font>
texts_dev, labels_dev = preprocessData(<span class="hljs-string">'./starterkitdata/dev.txt'</span>, mode=<span class="hljs-string">"train"</span>)<font></font>
texts_test, labels_test = preprocessData(<span class="hljs-string">'./starterkitdata/test.txt'</span>, mode=<span class="hljs-string">"train"</span>)
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.テキストの前処理</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニングの前に、エクフラシスツールを使用してテキストを前処理しました（Baziotis et al。、2017）。</font><font style="vertical-align: inherit;">これは、スペルを修正し、単語、セグメントを正規化し、特別なタグを使用してドロップ、正規化、または注釈を付ける必要があるトークンを決定するのに役立ちます。</font><font style="vertical-align: inherit;">前処理の段階で、次のことを行いました。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">URLとメール、日付と時刻、ニックネーム、パーセンテージ、通貨、数字は、対応するタグに置き換えられました。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">適切なラベルを付けた、繰り返しの、検閲された、細長い大文字の用語。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">長い単語は自動的に修正されました。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さらに、Emphasisには、ほとんどの絵文字、顔文字、複雑な表現、日付、時刻、通貨、頭字語を識別できるトークナイザーが含まれています。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">表3.テキスト前処理の例。</font></font></i><br>
<div class="scrollable-table"><table>
<tbody><tr>
<th> </th>
<th>  </th>
</tr>
<tr>
<td>I FEEL YOU… I'm breaking into million pieces <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td>
<td>&lt;allcaps&gt; i feel you &lt;/allcaps&gt;. &lt;repeated&gt; i am breaking into million pieces <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td>
</tr>
<tr>
<td>tired and I missed you too :‑(</td>
<td>tired and i missed you too &lt;sad&gt;</td>
</tr>
<tr>
<td>you should liiiiiiisten to this: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a></td>
<td>you should listen &lt;elongated&gt; to this: &lt;url&gt;</td>
</tr>
<tr>
<td>My apartment takes care of it. My rent is around $650.</td>
<td>my apartment takes care of it. my rent is around &lt;money&gt; .</td>
</tr>
</tbody></table></div><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> ekphrasis.classes.preprocessor <span class="hljs-keyword">import</span> TextPreProcessor
<span class="hljs-keyword">from</span> ekphrasis.classes.tokenizer <span class="hljs-keyword">import</span> SocialTokenizer
<span class="hljs-keyword">from</span> ekphrasis.dicts.emoticons <span class="hljs-keyword">import</span> emoticons
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<font></font>
<font></font>
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> io<font></font>
<font></font>
label2emotion = {<span class="hljs-number">0</span>: <span class="hljs-string">"others"</span>, <span class="hljs-number">1</span>: <span class="hljs-string">"happy"</span>, <span class="hljs-number">2</span>: <span class="hljs-string">"sad"</span>, <span class="hljs-number">3</span>: <span class="hljs-string">"angry"</span>}<font></font>
emotion2label = {<span class="hljs-string">"others"</span>: <span class="hljs-number">0</span>, <span class="hljs-string">"happy"</span>: <span class="hljs-number">1</span>, <span class="hljs-string">"sad"</span>: <span class="hljs-number">2</span>, <span class="hljs-string">"angry"</span>: <span class="hljs-number">3</span>}<font></font>
<font></font>
emoticons_additional = {<font></font>
	<span class="hljs-string">'(^・^)'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">':‑c'</span>: <span class="hljs-string">'&lt;sad&gt;'</span>, <span class="hljs-string">'=‑d'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">":'‑)"</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">':‑d'</span>: <span class="hljs-string">'&lt;laugh&gt;'</span>,
	<span class="hljs-string">':‑('</span>: <span class="hljs-string">'&lt;sad&gt;'</span>, <span class="hljs-string">';‑)'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">':‑)'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">':\\/'</span>: <span class="hljs-string">'&lt;sad&gt;'</span>, <span class="hljs-string">'d=&lt;'</span>: <span class="hljs-string">'&lt;annoyed&gt;'</span>,
	<span class="hljs-string">':‑/'</span>: <span class="hljs-string">'&lt;annoyed&gt;'</span>, <span class="hljs-string">';‑]'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">'(^ ^)'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">'angru'</span>: <span class="hljs-string">'angry'</span>, <span class="hljs-string">"d‑':"</span>:
    	<span class="hljs-string">'&lt;annoyed&gt;'</span>, <span class="hljs-string">":'‑("</span>: <span class="hljs-string">'&lt;sad&gt;'</span>, <span class="hljs-string">":‑["</span>: <span class="hljs-string">'&lt;annoyed&gt;'</span>, <span class="hljs-string">'( ? )'</span>: <span class="hljs-string">'&lt;happy&gt;'</span>, <span class="hljs-string">'x‑d'</span>: <span class="hljs-string">'&lt;laugh&gt;'</span>,<font></font>
}<font></font>
<font></font>
text_processor = TextPreProcessor(<font></font>
	<span class="hljs-comment"># terms that will be normalized</span>
	normalize=[<span class="hljs-string">'url'</span>, <span class="hljs-string">'email'</span>, <span class="hljs-string">'percent'</span>, <span class="hljs-string">'money'</span>, <span class="hljs-string">'phone'</span>, <span class="hljs-string">'user'</span>,
           	<span class="hljs-string">'time'</span>, <span class="hljs-string">'url'</span>, <span class="hljs-string">'date'</span>, <span class="hljs-string">'number'</span>],
	<span class="hljs-comment"># terms that will be annotated</span>
	annotate={<span class="hljs-string">"hashtag"</span>, <span class="hljs-string">"allcaps"</span>, <span class="hljs-string">"elongated"</span>, <span class="hljs-string">"repeated"</span>,
          	<span class="hljs-string">'emphasis'</span>, <span class="hljs-string">'censored'</span>},<font></font>
	fix_html=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># fix HTML tokens</span>
	<span class="hljs-comment"># corpus from which the word statistics are going to be used</span>
	<span class="hljs-comment"># for word segmentation</span>
	segmenter=<span class="hljs-string">"twitter"</span>,
	<span class="hljs-comment"># corpus from which the word statistics are going to be used</span>
	<span class="hljs-comment"># for spell correction</span>
	corrector=<span class="hljs-string">"twitter"</span>,<font></font>
	unpack_hashtags=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># perform word segmentation on hashtags</span>
	unpack_contractions=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># Unpack contractions (can't -&gt; can not)</span>
	spell_correct_elong=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># spell correction for elongated words</span>
	<span class="hljs-comment"># select a tokenizer. You can use SocialTokenizer, or pass your own</span>
	<span class="hljs-comment"># the tokenizer, should take as input a string and return a list of tokens</span>
	tokenizer=SocialTokenizer(lowercase=<span class="hljs-literal">True</span>).tokenize,
	<span class="hljs-comment"># list of dictionaries, for replacing tokens extracted from the text,</span>
	<span class="hljs-comment"># with other expressions. You can pass more than one dictionaries.</span><font></font>
	dicts=[emoticons, emoticons_additional]<font></font>
)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">tokenize</span>(<span class="hljs-params">text</span>):</span>
	text = <span class="hljs-string">" "</span>.join(text_processor.pre_process_doc(text))
	<span class="hljs-keyword">return</span> text    
</code></pre><br>
<h2>3.   </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ベクトル表現は、ディープラーニングを使用したNLPシステムの作成に対するほとんどのアプローチの不可欠な部分になっています。最も適切なベクトルマッピングモデルを決定するために、Word2Vec（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mikolov et al。、2013</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）、GloVe（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pennington et al。、2014</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）、FastText（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Joulin et al。、2017</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）、および事前トレーニング済みのDataStoriesベクトル（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Baziotis et al。 、2017</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">） Word2Vecは、意味的に関連する単語が同様のコンテキストで見つかると想定して、単語間の関係を見つけます。 Word2Vecは、ターゲット単語（CBOWアーキテクチャ）またはコンテキスト（Skip-Gramアーキテクチャ）を予測しようとします。つまり、損失関数を最小化し、GloVeは単語ベクトルを計算して、隣接行列の次元を減らします。 FastTextのロジックはWord2Vecのロジックに似ていますが、シンボリックn-gramを使用して単語ベクトルを構築し、その結果、未知の単語の問題を解決できる点が異なります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上記のすべてのモデルについて、著者が提供するデフォルトのトレーニングパラメーターを使用します。これらの各ベクトル表現に基づいて単純なLSTMモデル（dim = 64）をトレーニングし、交差検証を使用して分類効率を比較しました。 F1メジャーでの最良の結果は、事前トレーニング済みのDataStoriesベクトルによって示されました。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
選択したベクトル表示を単語の感情的な色で豊かにするために、自動的にラベルが付けられた</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">距離データセット</font></a><font style="vertical-align: inherit;">を使用してベクトルを微調整することにしました（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deriu et al。、2017</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">遠距離データセットを使用して、単純なLSTMネットワークをトレーニングし、「悪」、「悲しい」、「幸せ」のメッセージを分類しました。</font><font style="vertical-align: inherit;">埋め込み層は、ベクトルの重みの強い変化を避けるために、トレーニングの最初の反復中にフリーズされ、次の5回の反復では層が解凍されました。</font><font style="vertical-align: inherit;">トレーニング後、「遅延した」ベクトルは、後でニューラルネットワークで使用するために保存され</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、共有されました</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getEmbeddings</span>(<span class="hljs-params">file</span>):</span><font></font>
	embeddingsIndex = {}<font></font>
	dim = <span class="hljs-number">0</span>
	<span class="hljs-keyword">with</span> io.open(file, encoding=<span class="hljs-string">"utf8"</span>) <span class="hljs-keyword">as</span> f:
    	<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<font></font>
        	values = line.split()<font></font>
        	word = values[<span class="hljs-number">0</span>]<font></font>
        	embeddingVector = np.asarray(values[<span class="hljs-number">1</span>:], dtype=<span class="hljs-string">'float32'</span>)<font></font>
        	embeddingsIndex[word] = embeddingVector<font></font>
        	dim = len(embeddingVector)<font></font>
	<span class="hljs-keyword">return</span> embeddingsIndex, dim<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getEmbeddingMatrix</span>(<span class="hljs-params">wordIndex, embeddings, dim</span>):</span>
	embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number">1</span>, dim))
	<span class="hljs-keyword">for</span> word, i <span class="hljs-keyword">in</span> wordIndex.items():<font></font>
    	embeddingMatrix[i] = embeddings.get(word)<font></font>
	<span class="hljs-keyword">return</span> embeddingMatrix<font></font>
<font></font>
<font></font>
<span class="hljs-keyword">from</span> keras.preprocessing.text <span class="hljs-keyword">import</span> Tokenizer<font></font>
<font></font>
embeddings, dim = getEmbeddings(<span class="hljs-string">'emosense.300d.txt'</span>)<font></font>
tokenizer = Tokenizer(filters=<span class="hljs-string">''</span>)<font></font>
tokenizer.fit_on_texts([<span class="hljs-string">' '</span>.join(list(embeddings.keys()))])<font></font>
<font></font>
wordIndex = tokenizer.word_index<font></font>
print(<span class="hljs-string">"Found %s unique tokens."</span> % len(wordIndex))<font></font>
<font></font>
embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)<font></font>
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4.ニューラルネットワークアーキテクチャ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
リカレントニューラルネットワーク（RNN）は、一連のイベントの処理を専門とするニューラルネットワークのファミリです。従来のニューラルネットワークとは異なり、RNNは内部バランスを使用してシーケンスを処理するように設計されています。このため、計算グラフRNNには、現在のイベントに対する一連のイベントからの以前の情報の影響を反映するサイクルが含まれています。 LSTMニューラルネットワーク（Long Short-Term Memory）は、1997年にRNNの拡張として導入されました（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hochreiter and Schmidhuber、1997</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">） LSTM再帰セルは、勾配の爆発と減衰の問題を回避するような方法で接続されています。従来のLSTMは、シーケンスを一方向に処理するときに過去の情報のみを保存します。双方向で動作する双方向LSTMは、反対方向に情報を送信する2つの隠れたLSTMレイヤーの出力を結合します。一方は時間の経過とともに他方は反対であり、過去と未来の状態から同時にデータを受信します（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schuster and Paliwal、1997</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">図1：アーキテクチャの縮小バージョン。 LSTMモジュールは、第1ステージと第3ステージに同じ重みを使用します。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
説明したアプローチの簡略化した表現を図1に示します。ニューラルネットワークのアーキテクチャは、埋め込み層と2つの双方向LTSMモジュール（dim = 64）で構成されています。最初のLTSMモジュールは最初のユーザー（つまり、会話の1番目と3番目のレプリカ）の単語を分析し、2番目のモジュールは2番目のユーザー（2番目のレプリカ）の単語を分析します。最初の段階では、事前トレーニング済みのベクトル表現を使用する各ユーザーの単語が、対応する双方向LTSMモジュールに送られます。次に、結果として得られる3つの特徴マップを組み合わせてフラットな特徴ベクトルを作成し、完全に接続された非表示レイヤー（dim = 30）に転送します。これにより、抽出された特徴間の相互作用が分析されます。最後に、これらの特性は、softmaxアクティベーション関数を使用して出力層で処理され、最終的なクラスラベルが決定されます。オーバーフィッティングを減らすために、ベクトル表現のレイヤーの後、ガウスノイズを含む正則化レイヤーが追加され、ドロップアウトレイヤーが各LTSMモジュールに追加され（p = 0.2）、非表示の完全に接続されたレイヤー（p = 0.1）の前に（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Srivastava et al。、2014</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font></font><br>
 <br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Input, Dense, Embedding, Concatenate, Activation, \<font></font>
	Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise<font></font>
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Model<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">buildModel</span>(<span class="hljs-params">embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes,
           	noise=<span class="hljs-number">0.1</span>, dropout_lstm=<span class="hljs-number">0.2</span>, dropout=<span class="hljs-number">0.2</span></span>):</span>
	turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string">'int32'</span>)<font></font>
	turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string">'int32'</span>)<font></font>
	turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string">'int32'</span>)<font></font>
	embedding_dim = embeddings_matrix.shape[<span class="hljs-number">1</span>]<font></font>
	embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number">0</span>],<font></font>
                            	embedding_dim,<font></font>
                            	weights=[embeddings_matrix],<font></font>
                            	input_length=sequence_length,<font></font>
                            	trainable=<span class="hljs-literal">False</span>)<font></font>
    <font></font>
	turn1_branch = embeddingLayer(turn1_input)<font></font>
	turn2_branch = embeddingLayer(turn2_input)<font></font>
	turn3_branch = embeddingLayer(turn3_input)<font></font>
    <font></font>
	turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-literal">None</span>, sequence_length, embedding_dim))(turn1_branch)<font></font>
	turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-literal">None</span>, sequence_length, embedding_dim))(turn2_branch)<font></font>
	turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-literal">None</span>, sequence_length, embedding_dim))(turn3_branch)<font></font>
<font></font>
	lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm))<font></font>
	lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm))<font></font>
    <font></font>
	turn1_branch = lstm1(turn1_branch)<font></font>
	turn2_branch = lstm2(turn2_branch)<font></font>
	turn3_branch = lstm1(turn3_branch)<font></font>
    <font></font>
	x = Concatenate(axis=<span class="hljs-number">-1</span>)([turn1_branch, turn2_branch, turn3_branch])<font></font>
    <font></font>
	x = Dropout(dropout)(x)<font></font>
    <font></font>
	x = Dense(hidden_layer_dim, activation=<span class="hljs-string">'relu'</span>)(x)<font></font>
    <font></font>
	output = Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>)(x)<font></font>
    <font></font>
	model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output)<font></font>
    <font></font>
	model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=<span class="hljs-string">'adam'</span>, metrics=[<span class="hljs-string">'acc'</span>])<font></font>
    <font></font>
	<span class="hljs-keyword">return</span> model<font></font>
<font></font>
model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number">64</span>, hidden_layer_dim=<span class="hljs-number">30</span>, num_classes=<span class="hljs-number">4</span>)</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.結果</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最適なアーキテクチャの検索では、レイヤー内のニューロンの数、活性化関数、正則化パラメーターだけでなく、ニューラルネットワーク自体のアーキテクチャも実験しました。これは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">元の作品で</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">詳しく説明されて</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">い</font></a><font style="vertical-align: inherit;">ます。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
前のセクションで説明したアーキテクチャは、Trainデータセットでトレーニングし、Devデータセットで検証したときに最良の結果を示したため、コンテストの最終段階で使用されました。最後のテストデータセットでは、モデルは72.59％のミクロ平均F1メジャーを示し、すべての参加者の間で達成された最大結果は79.59％でした。それにもかかわらず、私たちの結果は主催者によって設定された58.68％のベース値よりもはるかに高かった。</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">単語のモデルおよびベクトル表現のソースコードは、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> GitHubで入手できます。</font></font><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">記事の完全版</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">タスクの説明と作業が</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ACLアンソロジーのウェブサイト上にあります。</font></font><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニングデータセット</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、公式のLinkedInグループからダウンロードできます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
引用：</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense,</span>
	title = <span class="hljs-string">"{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations"</span>,<font></font>
	author = <span class="hljs-string">"Smetanin, Sergey"</span>,<font></font>
	booktitle = <span class="hljs-string">"Proceedings of the 13th International Workshop on Semantic Evaluation"</span>,<font></font>
	year = <span class="hljs-string">"2019"</span>,<font></font>
	address = <span class="hljs-string">"Minneapolis, Minnesota, USA"</span>,<font></font>
	publisher = <span class="hljs-string">"Association for Computational Linguistics"</span>,<font></font>
	url = <span class="hljs-string">"https://www.aclweb.org/anthology/S19-2034"</span>,<font></font>
	pages = <span class="hljs-string">"210--214"</span>,<font></font>
}</code></pre></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja463031/index.html">生活し、学びます。パート3.継続教育または永遠の学生の年齢</a></li>
<li><a href="../ja463035/index.html">OpenStreetMap No. 471の世界からのニュース（07.23.2019-29.07.2019）</a></li>
<li><a href="../ja463037/index.html">インスピレーションを求めて、またはFから抜け出す方法</a></li>
<li><a href="../ja463039/index.html">日曜大工マニキュア掃除機</a></li>
<li><a href="../ja463041/index.html">定義済みまたは未定義？JavaScriptで配列を作成するニュアンス</a></li>
<li><a href="../ja463055/index.html">社内の管理者、開発者、無限の混乱、DevOpsの変革について</a></li>
<li><a href="../ja463057/index.html">Yiiフレームワーク2カスタム権利</a></li>
<li><a href="../ja463059/index.html">ITの3つの生活</a></li>
<li><a href="../ja463061/index.html">Figmaでレイアウトを準備するためのルール</a></li>
<li><a href="../ja463063/index.html">Goのインターフェースを扱います</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
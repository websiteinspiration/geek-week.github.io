<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍🎓 🖐🏻 😿 Pythonでの深層学習ライブラリの実装について 🤘🏼 👨🏿‍🏫 🧝</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ディープラーニングテクノロジーは、単純なニューラルネットワークからかなり複雑なアーキテクチャまで、短期間で大きな進歩を遂げました。これらのテクノロジーの急速な普及をサポートするために、さまざまなライブラリとディープラーニングプラットフォームが開発されています。そのようなライブラリの主な目的の1つは、...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pythonでの深層学習ライブラリの実装について</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/486686/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ディープラーニングテクノロジーは、単純なニューラルネットワークからかなり複雑なアーキテクチャまで、短期間で大きな進歩を遂げました。これらのテクノロジーの急速な普及をサポートするために、さまざまなライブラリとディープラーニングプラットフォームが開発されています。そのようなライブラリの主な目的の1つは、ニューラルネットワークモデルを作成およびトレーニングするためのシンプルなインターフェースを開発者に提供することです。このようなライブラリを使用すると、ユーザーはモデルの実装の微妙な問題ではなく、解決されるタスクにより多くの注意を払うことができます。これを行うには、いくつかのレベルの抽象化の背後にある基本的なメカニズムの実装を隠す必要がある場合があります。そして、これは、深層学習ライブラリの基礎となる基本原則の理解を複雑にします。</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><img src="https://habrastorage.org/webt/bp/yi/sl/bpyislfb1o7e-qh7exvklh1oxuw.jpeg"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちが翻訳を公開している記事は、ディープラーニングライブラリの低レベルのビルディングブロックのデバイスの機能を分析することを目的としています。</font><font style="vertical-align: inherit;">まず、ディープラーニングの本質について簡単に説明します。</font><font style="vertical-align: inherit;">これにより、それぞれのソフトウェアの機能要件を理解できます。</font><font style="vertical-align: inherit;">次に、NumPyを使用してPythonでシンプルだが機能するディープラーニングライブラリを開発する方法を検討します。</font><font style="vertical-align: inherit;">このライブラリは、単純なニューラルネットワークモデルのエンドツーエンドのトレーニングを提供できます。</font><font style="vertical-align: inherit;">途中で、深層学習フレームワークのさまざまなコンポーネントについて説明します。</font><font style="vertical-align: inherit;">私たちが検討するライブラリは非常に小さく、100行未満のコードです。</font><font style="vertical-align: inherit;">そしてこれはそれを理解することは非常に簡単になることを意味します。</font><font style="vertical-align: inherit;">私たちが扱う完全なプロジェクトコードは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ここにあります</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<a name="habracut"></a><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一般情報</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
通常、ディープラーニングライブラリ（TensorFlowやPyTorchなど）は、次の図に示すコンポーネントで構成されています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c49/b9f/396/c49b9f39652c0260a9e30ee4e5dea146.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">深層学習フレームワークの</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
コンポーネントこれらのコンポーネントを分析してみましょう。</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">▍オペレーター</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「オペレーター」と「レイヤー」（レイヤー）の概念は、通常、同じ意味で使用されます。</font><font style="vertical-align: inherit;">これらは、あらゆるニューラルネットワークの基本的な構成要素です。</font><font style="vertical-align: inherit;">演算子は、データを変換するベクトル関数です。</font><font style="vertical-align: inherit;">頻繁に使用される演算子の中で、線形層と畳み込み層、サブサンプリング層（プーリング）、半線形（ReLU）、シグモイド（シグモイド）アクティベーション関数などを区別できます。</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">▍オプティマイザ（オプティマイザ）</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
オプティマイザは、深層学習ライブラリの基盤です。</font><font style="vertical-align: inherit;">これらは、特定の基準を使用し、最適化の目標を考慮に入れてモデルパラメーターを調整する方法について説明しています。</font><font style="vertical-align: inherit;">よく知られているオプティマイザの中には、SGD、RMSProp、Adamがあります。</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">▍損失関数</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
損失関数は分析的で微分可能な数式であり、問​​題を解決するときに最適化の目標の代わりに使用されます。</font><font style="vertical-align: inherit;">たとえば、交差エントロピー関数と区分線形関数は通常、分類問題で使用されます。</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">▍初期化子</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
イニシャライザは、モデルパラメータの初期値を提供します。</font><font style="vertical-align: inherit;">パラメータがトレーニングの最初に持っているのはこれらの値です。</font><font style="vertical-align: inherit;">初期化に失敗すると、ネットワークの学習が遅くなるか、まったく学習しない可能性があるため、初期化子はニューラルネットワークのトレーニングで重要な役割を果たします。</font><font style="vertical-align: inherit;">ニューラルネットワークの重みを初期化するには多くの方法があります。</font><font style="vertical-align: inherit;">たとえば、正規分布から小さなランダムな値を割り当てることができます。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ここで</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あなたが初期化子の異なる種類について学ぶことができますページ。</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">▍レギュラライザー</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
レギュラライザは、ネットワークの再トレーニングを回避し、ネットワークが汎化能力を獲得するのに役立つツールです。明示的または暗黙的な方法でネットワークの再トレーニングを処理できます。明示的なメソッドには、重みの構造上の制限が含まれます。たとえば、それぞれのL1-NormとL2-Normを最小化すると、重みの値がよりよく分散され、より均等に分散されます。暗黙的なメソッドは、中間表現の変換を実行する特殊な演算子によって表されます。これは、たとえばパケット正規化手法（BatchNorm）を使用するなどの明示的な正規化によって、またはDropOutアルゴリズムとDropConnectアルゴリズムを使用してネットワーク接続を変更することによって行われます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上記のコンポーネントは通常、ライブラリのインターフェイス部分に属します。</font><font style="vertical-align: inherit;">ここで、「インターフェース部分」とは、ユーザーが対話できるエンティティを意味します。</font><font style="vertical-align: inherit;">ニューラルネットワークアーキテクチャを効率的に設計するための便利なツールを提供します。</font><font style="vertical-align: inherit;">ライブラリの内部メカニズムについて話すと、モデルのさまざまなパラメータを考慮して、損失関数の勾配の自動計算をサポートできます。</font><font style="vertical-align: inherit;">この手法は一般に自動微分（AD）と呼ばれます。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">自動微分</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各深層学習ライブラリは、ユーザーにいくつかの自動微分機能を提供します。これにより、モデルの構造の説明（計算のグラフ）に集中し、勾配を計算するタスクをADモジュールに転送する機会が彼に与えられます。すべてがどのように機能するかを知る例を見てみましょう。我々は、その入力変数、X1及びX₂に対して次の関数の偏導関数を計算すると仮定：</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y = SIN（、X1）+、X1 *X₂ </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I借り下図、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ここから</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、番組の計算グラフと連鎖ルールを使用して導関数の計算。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/605/635/189/605635189c56a2f87927ec1a0c5b6318.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">計算グラフとチェーンルールによる導関数の計算</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
ここに表示されているのは、自動微分の「逆モード」のようなものです。</font><font style="vertical-align: inherit;">よく知られているエラーの逆伝播アルゴリズムは、上にある関数が損失関数である場合の上記のアルゴリズムの特殊なケースです。</font><font style="vertical-align: inherit;">ADは、複雑な関数が基本的な算術演算と基本的な関数で構成されるという事実を利用しています。</font><font style="vertical-align: inherit;">その結果、これらの演算にチェーンルールを適用することにより、導関数を計算できます。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実装</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
前のセクションでは、ニューラルネットワークの作成とエンドツーエンドのトレーニング用に設計されたディープラーニングライブラリの作成に必要なコンポーネントを検討しました。例を複雑にしないために、ここでは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caffe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ライブラリの設計パターンを模倣しています</font><font style="vertical-align: inherit;">。ここでは、2つの抽象クラスを宣言しています- </font></font><code>Function</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><code>Optimizer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。さらに、クラス</font></font><code>Tensor</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">があります。これは、2つの多次元NumPy配列を含む単純な構造です。それらの1つはパラメーター値を格納するように設計されており、もう1つは勾配を格納するように設計されています。異なるレイヤー（演算子）のすべてのパラメーターはタイプになり</font></font><code>Tensor</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。先に進む前に、ライブラリの概要を見てみましょう。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d05/98c/068/d0598c068139ecda1f2aacbd9ea5f068.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ライブラリーUMLダイアグラム</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
この資料の執筆時点では、このライブラリーには、線形レイヤー、ReLUアクティベーション関数、SoftMaxLossレイヤー、およびSGDオプティマイザーの実装が含まれています。その結果、ライブラリを使用して、完全に接続されたレイヤーで構成され、非線形活性化関数を使用して分類モデルをトレーニングできることがわかります。さて、私たちが持っている抽象クラスについてのいくつかの詳細を見てみましょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
抽象クラス</font></font><code>Function</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、オペレーターのためのインターフェースを提供します。これが彼のコードです：</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span>&nbsp; <span class="hljs-title">Function</span>(<span class="hljs-params">object</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">raise</span> NotImplementedError<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">raise</span> NotImplementedError<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getParams</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> []</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すべての演算子は、抽象クラスの継承を通じて実装され</font></font><code>Function</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。各演算子は、メソッド</font></font><code>forward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">との</font><font style="vertical-align: inherit;">実装を提供する必要があります</font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。オペレーターに</font></font><code>getParams()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、パラメーター（ある場合）を返す</font><font style="vertical-align: inherit;">オプションのメソッドの実装が含まれる場合があり</font><font style="vertical-align: inherit;">ます。このメソッド</font></font><code>forward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は入力データを受け取り、オペレーターによる変換の結果を返します。さらに、勾配の計算に必要な内部問題を解決します。この方法</font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、オペレーターの出力に関する損失関数の偏微分を受け入れ、オペレーターの入力データとパラメーター（ある場合）に関する損失関数の偏微分の計算を実装します。メソッドに注意してください</font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">本質的に、私たちのライブラリに自動微分を実行する機能を提供します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべてを特定の例で処理するために、関数の実装を見てみましょう</font></font><code>Linear</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Linear</span>(<span class="hljs-params">Function</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,in_nodes,out_nodes</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.weights = Tensor((in_nodes,out_nodes))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.bias&nbsp; &nbsp; = Tensor((<span class="hljs-number">1</span>,out_nodes))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.type = <span class="hljs-string">'linear'</span><font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self,x</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output = np.dot(x,self.weights.data)+self.bias.data<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.input = x&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> output<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward</span>(<span class="hljs-params">self,d_y</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.weights.grad += np.dot(self.input.T,d_y)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.bias.grad&nbsp; &nbsp; += np.sum(d_y,axis=<span class="hljs-number">0</span>,keepdims=<span class="hljs-literal">True</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grad_input &nbsp; &nbsp; &nbsp; &nbsp; = np.dot(d_y,self.weights.data.T)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> grad_input<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getParams</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> [self.weights,self.bias]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このメソッド</font></font><code>forward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、ビューの変換を実装し</font></font><code>Y = X*W+b</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、結果を返します。さらに</font><font style="vertical-align: inherit;">、メソッドの</font><font style="vertical-align: inherit;">出力値に関する損失関数の</font></font><code>X</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">偏微分を計算する必要があるため</font><font style="vertical-align: inherit;">、入力値が保存されます</font><font style="vertical-align: inherit;">。この方法は、</font><font style="vertical-align: inherit;">入力値に対して算出偏導関数、受信</font><font style="vertical-align: inherit;">およびパラメータ</font><font style="vertical-align: inherit;">とを</font><font style="vertical-align: inherit;">。さらに、</font><font style="vertical-align: inherit;">前のレイヤーに転送される</font><font style="vertical-align: inherit;">入力値に対して計算された偏微分を返します</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">
抽象クラス</font><font style="vertical-align: inherit;">は、オプティマイザにインターフェースを提供します。</font></font><code>dY</code><font style="vertical-align: inherit;"></font><code>Y</code><font style="vertical-align: inherit;"></font><code>backward()</code><font style="vertical-align: inherit;"></font><code>backward()</code><font style="vertical-align: inherit;"></font><code>X</code><font style="vertical-align: inherit;"></font><code>W</code><font style="vertical-align: inherit;"></font><code>b</code><font style="vertical-align: inherit;"></font><code>X</code><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><code>Optimizer</code><font style="vertical-align: inherit;"></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Optimizer</span>(<span class="hljs-params">object</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,parameters</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.parameters = parameters<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">raise</span> NotImplementedError<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">zeroGrad</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.parameters:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p.grad = <span class="hljs-number">0.</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すべてのオプティマイザは、基本クラスからの継承によって実装され</font></font><code>Optimizer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">特定の最適化を記述するクラスは、メソッドの実装を提供する必要があります</font></font><code>step()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">このメソッドは、損失関数の最適化された値に関連して計算された偏導関数を使用してモデルパラメーターを更新します。</font><font style="vertical-align: inherit;">関数には、さまざまなモデルパラメータへのリンクが用意されています</font></font><code>__init__()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">勾配値をリセットするための汎用機能は、基本クラス自体に実装されていることに注意してください。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、これらすべてをよりよく理解するために、特定の例を考えてみましょう。これは、運動量の調整と重みの削減をサポートする確率勾配降下法（SGD）アルゴリズムの実装です。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SGD</span>(<span class="hljs-params">Optimizer</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,parameters,lr=<span class="hljs-number">.001</span>,weight_decay=<span class="hljs-number">0.0</span>,momentum = <span class="hljs-number">.9</span></span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().__init__(parameters)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.lr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = lr<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.weight_decay = weight_decay<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.momentum &nbsp; &nbsp; = momentum<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.velocity &nbsp; &nbsp; = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> parameters:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.velocity.append(np.zeros_like(p.grad))<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> p,v <span class="hljs-keyword">in</span> zip(self.parameters,self.velocity):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v = self.momentum*v+p.grad+self.weight_decay*p.data<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p.data=p.data-self.lr*v</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実際の問題の解決策</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで、ライブラリを使用して（ディープ）ニューラルネットワークモデルをトレーニングするために必要なものがすべて揃いました。</font><font style="vertical-align: inherit;">これには、次のエンティティが必要です。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデル：計算グラフ。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データと目標値：ネットワークトレーニング用のデータ。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">損失関数：最適化目標の代わりになります。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">オプティマイザ：モデルパラメータを更新するためのメカニズム。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次の疑似コードは、一般的なテストサイクルを示しています。</font></font><br>
<br>
<pre><code class="python hljs">model <span class="hljs-comment"># </span>
data,target <span class="hljs-comment"># </span>
loss_fn <span class="hljs-comment"># </span>
optim <span class="hljs-comment">#,         </span>
Repeat:<span class="hljs-comment">#   ,    ,     </span>
&nbsp;&nbsp;&nbsp;optim.zeroGrad() <span class="hljs-comment">#    </span>
&nbsp;&nbsp;&nbsp;output = model.forward(data) <span class="hljs-comment">#   </span>
&nbsp;&nbsp;&nbsp;loss &nbsp; = loss_fn(output,target) <span class="hljs-comment"># </span>
&nbsp;&nbsp;&nbsp;grad &nbsp; = loss.backward() <span class="hljs-comment">#      </span>
&nbsp;&nbsp;&nbsp;model.backward(grad) <span class="hljs-comment">#    </span>
&nbsp;&nbsp;&nbsp;optim.step() <span class="hljs-comment">#  </span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これはディープラーニングライブラリでは必要ありませんが、上記の機能を別のクラスに含めると便利な場合があります。</font><font style="vertical-align: inherit;">これにより、新しいモデルを学習するときに同じアクションを繰り返さないようにすることができます（このアイデアは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kerasの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ようなフレームワークの高レベルの抽象化の哲学に対応しています</font><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">これを実現するには、クラスを宣言し</font></font><code>Model</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Model</span>():</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.computation_graph = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.parameters&nbsp; &nbsp; &nbsp; &nbsp; = []<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">add</span>(<span class="hljs-params">self,layer</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.computation_graph.append(layer)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.parameters+=layer.getParams()<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__innitializeNetwork</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> f.type==<span class="hljs-string">'linear'</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights,bias = f.getParams()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights.data = <span class="hljs-number">.01</span>*np.random.randn(weights.data.shape[<span class="hljs-number">0</span>],weights.data.shape[<span class="hljs-number">1</span>])<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias.data&nbsp; &nbsp; = <span class="hljs-number">0.</span><font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self,data,target,batch_size,num_epochs,optimizer,loss_fn</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss_history = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.__innitializeNetwork()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data_gen = DataGenerator(data,target,batch_size)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itr = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> X,Y <span class="hljs-keyword">in</span> data_gen:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zeroGrad()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph: X=f.forward(X)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss = loss_fn.forward(X,Y)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grad = loss_fn.backward()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph[::<span class="hljs-number">-1</span>]: grad = f.backward(grad)&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss_history+=[loss]<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<span class="hljs-string">"Loss at epoch = {} and iteration = {}: {}"</span>.format(epoch,itr,loss_history[<span class="hljs-number">-1</span>]))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itr+=<span class="hljs-number">1</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> loss_history<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self,data</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X = data<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph: X = f.forward(X)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> X</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このクラスには、次の機能が含まれています。</font></font><br>
<br>
<ul>
<li>  :  <code>add()</code>   ,    .        <code>computation_graph</code>.</li>
<li> : ,   ,       ,    .</li>
<li> :    <code>fit()</code>       .       ,    .</li>
<li>  :  <code>predict()</code>   ,       ,   .</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このクラスはディープラーニングシステムの基本的な構成要素ではないため、別のモジュールに実装しました</font></font><code>utilities.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">このメソッド</font></font><code>fit()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font><code>DataGenerator</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、同じモジュールに実装され</font><font style="vertical-align: inherit;">ているクラス</font><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">使用する</font><font style="vertical-align: inherit;">ことに注意してください</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">このクラスはトレーニングデータのラッパーにすぎず、トレーニングの反復ごとにミニパッケージを生成します。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルトレーニング</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、ニューラルネットワークモデルが上記のライブラリを使用してトレーニングされる最後のコードを考えます。</font><font style="vertical-align: inherit;">らせん状に配置されたデータでマルチレイヤネットワークをトレーニングします。</font><font style="vertical-align: inherit;">私は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">この</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">出版物</font><font style="vertical-align: inherit;">に促され</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ました</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">このデータを生成して視覚化するためのコードは、ファイルにあります</font></font><code>utilities.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/895/eb0/856/895eb085662368f9c1d171153a301fb0.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3つのクラスがらせん状に配置されたデータ&nbsp;</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
前の図は、モデルをトレーニングするデータの視覚化を示しています。</font><font style="vertical-align: inherit;">このデータは非線形に分離可能です。</font><font style="vertical-align: inherit;">非表示層を持つネットワークが非線形決定境界を正しく検出できることを期待できます。</font><font style="vertical-align: inherit;">私たちが話し合ったすべてのものをまとめると、モデルをトレーニングするための次のコードフラグメントが得られます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> dl_numpy <span class="hljs-keyword">as</span> DL
<span class="hljs-keyword">import</span> utilities<font></font>
<font></font>
batch_size&nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-number">20</span>
num_epochs&nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-number">200</span>
samples_per_class = <span class="hljs-number">100</span>
num_classes &nbsp; &nbsp; &nbsp; = <span class="hljs-number">3</span>
hidden_units&nbsp; &nbsp; &nbsp; = <span class="hljs-number">100</span><font></font>
data,target &nbsp; &nbsp; &nbsp; = utilities.genSpiralData(samples_per_class,num_classes)<font></font>
model &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = utilities.Model()<font></font>
model.add(DL.Linear(<span class="hljs-number">2</span>,hidden_units))<font></font>
model.add(DL.ReLU())<font></font>
model.add(DL.Linear(hidden_units,num_classes))<font></font>
optim &nbsp; = DL.SGD(model.parameters,lr=<span class="hljs-number">1.0</span>,weight_decay=<span class="hljs-number">0.001</span>,momentum=<span class="hljs-number">.9</span>)<font></font>
loss_fn = DL.SoftmaxWithLoss()<font></font>
model.fit(data,target,batch_size,num_epochs,optim,loss_fn)<font></font>
predicted_labels = np.argmax(model.predict(data),axis=<span class="hljs-number">1</span>)<font></font>
accuracy &nbsp; &nbsp; &nbsp; &nbsp; = np.sum(predicted_labels==target)/len(target)<font></font>
print(<span class="hljs-string">"Model Accuracy = {}"</span>.format(accuracy))<font></font>
utilities.plot2DDataWithDecisionBoundary(data,target,model)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以下の画像は、トレーニングされたモデルの同じデータと決定的な境界を示しています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/502/b0b/84f/502b0b84fee2c960c918494e8d63e33a.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニング済みモデルのデータと決定の境界</font></font></font></i><br>
 <br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">概要</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
深層学習モデルの複雑さが増していることを考えると、それぞれのライブラリの機能を増やし、これらの機能を実装するために必要なコードの量を増やす傾向があります。ただし、そのようなライブラリの最も基本的な機能は、比較的コンパクトな形式で実装できます。私たちが作成したライブラリは、単純なネットワークのエンドツーエンドのトレーニングに使用できますが、それでも、多くの点で制限されています。マシンビジョン、音声認識、テキスト認識などの分野でディープラーニングフレームワークを使用できるようにする機能の分野の制限について話しています。もちろん、これはそのようなフレームワークの可能性に制限はありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
誰もが</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">プロジェクト</font></a><font style="vertical-align: inherit;">をフォークできると思います</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、ここで検討したコード、そして演習として、彼らがそこに何を見たいかを紹介します。</font><font style="vertical-align: inherit;">自分で実装しようとすることができるいくつかのメカニズムはここにあります：</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">演算子：畳み込み、サブサンプリング。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">オプティマイザ：Adam、RMSProp。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">レギュレーター：BatchNorm、DropOut。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この資料を読んで、ディープラーニングのために図書館の腸内で何が起こっているかを少なくとも目の隅から見ることができれば幸いです。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">読者の皆様！</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">どのディープラーニングライブラリを使用していますか？</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja486676/index.html">FPGAのデータセンターへの侵入の不可避性</a></li>
<li><a href="../ja486678/index.html">ASP.NET CoreのQuartz</a></li>
<li><a href="../ja486680/index.html">ML、VR、ロボット（および少しのクラウド）</a></li>
<li><a href="../ja486682/index.html">Docker Compose：Makefileを使用して簡素化する</a></li>
<li><a href="../ja486684/index.html">TDDの価値が誇張されていると信じている人への私の答え</a></li>
<li><a href="../ja486688/index.html">Node.js、Tor、Puppeteer、およびCheerio：匿名のWebスクレイピング</a></li>
<li><a href="../ja486690/index.html">高品質の矢印関数を作成するための5つのヒント</a></li>
<li><a href="../ja486692/index.html">使用したことのないChromeコンソールの機能</a></li>
<li><a href="../ja486694/index.html">OpenStreetMap No. 496の世界からのニュース（2020年1月14日、2020年1月20日）</a></li>
<li><a href="../ja486702/index.html">2月3日から9日までのモスクワでのデジタルイベント</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
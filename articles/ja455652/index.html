<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏾‍🔬 ♥️ 👩🏽‍⚖️ ディープラーニングと常識：チャットボットの開発 🧑 👩🏾‍🏫 👨🏼‍✈️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="サービスのユーザーが多いほど、支援が必要になる可能性が高くなります。テクニカルサポートチャットは明白ですが、かなり高価なソリューションです。ただし、機械学習テクノロジーを使用すれば、コストを節約できます。
 
 ボットは簡単な質問に答えることができます。さらに、チャットボットは、ユーザーの意図を判断...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ディープラーニングと常識：チャットボットの開発</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/455652/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">サービスのユーザーが多いほど、支援が必要になる可能性が高くなります。テクニカルサポートチャットは明白ですが、かなり高価なソリューションです。ただし、機械学習テクノロジーを使用すれば、コストを節約できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ボットは簡単な質問に答えることができます。さらに、チャットボットは、ユーザーの意図を判断し、コンテキストをキャプチャして、人間の介入なしにユーザーの問題のほとんどを解決できるように教えることができます。これを行うには、人気のアシスタントOlegの開発者であるVladislav BlinovとValery Baranovaがそれを理解するのを助けます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/rr/do/kw/rrdokweqzrtdqiogus2vahosksg.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
チャットボットの開発作業において、単純な方法からより複雑な方法に移り、実装の実際的な問題を分析し、どの程度の品質向上が得られ、どれだけの費用がかかるかを確認します。</font></font><br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/eL3dkh-WaSU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vladislav Blinov</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tinkoff</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の対話システムの上級開発者であり</font><font style="vertical-align: inherit;">、ML、NLP、DLなどの略語を使用することがよくあり</font><font style="vertical-align: inherit;">ます</font><font style="vertical-align: inherit;">。さらに、大学院では、機械学習とニューラルネットワークを通じてユーモアのモデリングを検討しています。</font></font><br>
<br>
<strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Valeria Baranovaは</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、PythonのNLPフィールドで5年以上クールなことを書い</font><strong><font style="vertical-align: inherit;">てい</font></strong><font style="vertical-align: inherit;">ます。現在、インタラクティブシステムのチームでTinkoffはチャットボットを作成し、学生向けの機械学習コースを教えています。彼は計算ユーモアの分野でも研究を行っています。つまり、ジョークを理解し、新しいジョークを思いつくようAIに教えます。バレリアとウラディスラフ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> UseData Confで</font><font style="vertical-align: inherit;">これについて</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">話し</font></a><font style="vertical-align: inherit;">ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tinkoff Bankのサービスは、何百万もの人々によって使用されています。</font><font style="vertical-align: inherit;">このような多数のユーザーに24時間体制のサポートを提供するには、大規模なスタッフが必要であり、サービスのコストが高くなります。</font><font style="vertical-align: inherit;">ユーザーのよくある質問にチャットボットを使用して自動的に回答できるのは当然のことのようです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ユーザーの意図または意図</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
チャットボットが最初に必要とする</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ことは、ユーザーが何を望んで</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">いる</font><strong><font style="vertical-align: inherit;">か</font></strong><font style="vertical-align: inherit;">を理解する</font><strong><font style="vertical-align: inherit;">こと</font></strong><font style="vertical-align: inherit;">です。</font><font style="vertical-align: inherit;">このタスクは、意図または意図の分類と呼ばれます。</font><font style="vertical-align: inherit;">さらに、このタスクのフレームワークでは、すべてのモデルとアプローチが考慮されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
インテントの分類の例を見てみましょう。</font><font style="vertical-align: inherit;">「100レラを転送する」と書くと、チャットボットOlegは、これが送金の意図、つまりユーザーが送金する意図であることを理解します。</font><font style="vertical-align: inherit;">むしろ、そのレラは100ルーブルの金額を転送する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
方法を比較し、ユーザーとの実際の対話で構成されるテストサンプルで作業の品質をテストします。</font><font style="vertical-align: inherit;">サンプルには、30,000を超えるマークされた例と170の意図があります。たとえば、映画館に行く、レストランを検索する、預金を開くまたは閉じるなどです。</font><font style="vertical-align: inherit;">また、オレグは多くのことについて彼自身の意見を持っています、そして彼はあなたとただチャットすることができます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">辞書分類</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
インテントを分類するタスクで実行できる最も簡単なことは</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、辞書</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><strong><font style="vertical-align: inherit;">使用すること</font></strong><font style="vertical-align: inherit;">です。</font><font style="vertical-align: inherit;">たとえば、ユーザーのフレーズに「翻訳」という単語が含まれている場合は、送金が必要であると考えてください。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そのような単純なアプローチの質を見てみましょう。</font></font><br>
<div class="scrollable-table"><table>
<tbody>
<tr>
<td> </td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">精度</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">想起</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f1スコア</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">送金</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.88</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.23</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.36</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">残り</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.97</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.99</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.98</font></font></td>
</tr>
</tbody>
</table></div><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分類子がユーザーの意図を単に「翻訳」という言葉で「送金」と定義した場合、品質はすでに非常に高くなります。</font><font style="vertical-align: inherit;">精度-88％、完全性は低いが、23％に等しい。</font><font style="vertical-align: inherit;">これは理解できます。「翻訳する」という言葉は、「誰かにお金を送金する」と言う可能性をすべて説明しているわけではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、このアプローチには利点があります。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ラベル付けされたサンプリングは必要ありません（モデルを研究しない場合、サンプリングは必要ありません）。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">辞書を上手くコンパイルすれば、高い精度を得ることができます（ただし、時間とリソースがかかります）。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、クラスのすべてのバリエーションを説明することは困難であるため、このようなソリューションの完全性は低くなる可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
反例を考えてみましょう。</font><font style="vertical-align: inherit;">送金インテントに加えて、「送金」には2番目のインテント「オペレーターへの送金」も含まれる場合があります。</font><font style="vertical-align: inherit;">オペレーターに新しい翻訳意図を追加すると、異なる結果が得られます。</font></font><br>
<div class="scrollable-table"><table>
<tbody>
<tr>
<td> </td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">精度</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">想起</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f1スコア</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">送金</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.70</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.23</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.34</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">残り</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.97</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.99</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.98</font></font></td>
</tr>
</tbody>
</table></div><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">精度は18ポイント低下しますが、当然ながら完全性は向上しません。</font><font style="vertical-align: inherit;">これは、より高度なアプローチが必要であることを示しています。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキスト分析</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
機械学習を使用する前に、テキストをベクトルとして表示する方法を理解する必要があります。</font><font style="vertical-align: inherit;">最も簡単な方法の1つは、</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf-idfベクトル</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><strong><font style="vertical-align: inherit;">使用すること</font></strong><font style="vertical-align: inherit;">です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
tf-idf-vectorは、ユーザーのフレーズ内の各単語の出現を考慮し、コレクション内の単語の出現の合計を考慮します。</font><font style="vertical-align: inherit;">さまざまなテキストで頻繁に見られる単語は、このベクトル表現では重みが小さくなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
tf-idf表現（この場合、ロジスティック回帰）の線形モデルの品質を見てみましょう。</font></font><br>
<div class="scrollable-table"><table>
<tbody>
<tr>
<td> </td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">精度</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">想起</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f1スコア</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">送金</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.74</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.86</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.80</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">残り</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.99</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.99</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.99</font></font></td>
</tr>
</tbody>
</table></div><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">その結果、</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">完全性が</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">大幅に</font><strong><font style="vertical-align: inherit;">向上し</font></strong><font style="vertical-align: inherit;">、辞書の使用と同等の精度が維持され、f1メジャー（精度と完全性の間の加重調和平均）も増加しました。</font><font style="vertical-align: inherit;">つまり、モデル自体は、どの単語がどのインテントに重要であるかをすでに理解しています。自分で何かを発明する必要はありません。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データの視覚化</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データの視覚化は、インテントがどのように見えるか、空間内でどのようにグループ化されているかを理解するのに役立ちます。</font><font style="vertical-align: inherit;">ただし、ディメンションが大きいため、tf-idf表現を直接視覚化することはできないため</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、ディメンション圧縮方法-t-SNEを使用し</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zx/gh/dc/zxghdc_rwrmjjqojzp9b5lao6tq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この方法とPCAの主な違いは、2次元空間に転送されるときに</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、オブジェクト間の相対距離が保持されること</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/1p/8w/xr/1p8wxr2sc5guuqktq4u7aqe88jk.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf-idfのt-SNE（トップ10インテント）、F1スコア0.92</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
上記は、コレクション内での出現によるトップ10インテントです。</font><font style="vertical-align: inherit;">どのインテントにも属していない緑色の点があり、異なる色でマークされている10個のクラスターは異なるインテントです。</font><font style="vertical-align: inherit;">それらのいくつかは非常によくグループ化されていることがわかります。</font><font style="vertical-align: inherit;">加重</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f1-measureは0.92です</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -これは非常に多く、すでに使用できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、tf-idfで線形分類子を使用します。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">同等の精度で、辞書を使用するよりもはるかに完全です。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">どの言葉がどの意図に対応するかを発明する必要はありません。&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、欠点もあります。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">語彙が限られているため、トレーニングサンプルに存在する単語についてのみ重みを取得できます。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">言い換えは考慮されません。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキスト内の単語の出現順序は考慮されません。</font></font></li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">言い換え</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
言い換えの問題をさらに詳しく考えてみましょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tf-idfベクトルは、単語で交差するテキストに対してのみ閉じることができます。</font><font style="vertical-align: inherit;">ベクトル間の近接度は、ベクトル間の角度の余弦によって計算できます。</font><font style="vertical-align: inherit;">ベクトル表現tf-idfのコサイン近接度は、特定の例で計算されます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/gf/7c/eb/gf7ceblapupg3xysxiyxgcjwo3o.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらは、tf-idfベクトル表現の非常に近いフレーズではありませんが、私たちにとっては、同じ意図と同じクラスです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これについて何ができますか？</font><font style="vertical-align: inherit;">たとえば、数字の代わりに、単語をベクトル全体として表すことができます。これは「単語の埋め込み」と呼ばれます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/rl/9n/xm/rl9nxmdp8sr_q7fwo7iokyj8hwy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この問題を解決するための最も人気のあるモデルの1つが2013年に提案されました。</font><font style="vertical-align: inherit;">これは</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">word2vec</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font><font style="vertical-align: inherit;">呼ば</font><font style="vertical-align: inherit;">れ、それ以来広く使用されています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Word2vecを学習する方法の1つは次のように機能します。テキストを取得し、コンテキストからいくつかの単語を取得してそれを破棄し、コンテキストから別のランダムな単語を取得して、両方の単語をワンホットベクトルとして提示します。ワンホットベクトルはディクショナリ次元別のベクトルであり、ディクショナリ内の単語のインデックスに対応する座標のみが値1、残りは0です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ow/ta/vc/owtavcymm3e4a1k28xltaxdguds.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、内層をアクティブ化せずに単純な単層ニューラルネットワークをトレーニングして、コンテキスト内の次の単語を予測します（つまり、単語ごと） 「Rocketman」は「夕方」という単語を予測します。出力では、すべての単語の確率分布を辞書から次のように取得します。単語が実際に何であるかがわかっているので、エラーを計算したり、重みを更新したりできます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/x6/m-/_e/x6m-_exb0v8m5mmge-q-mr9ez4a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
サンプルのトレーニングの結果として得られる更新された重みは、埋め込みという単語です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
数値の代わりに埋め込みを使用する利点は、最初に、</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">そのコンテキストが考慮されること</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。人気のある例：トランプとプーチンはどちらも大統領であり、テキストで一緒に使用されることが多いため、word2vecで接近しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニングサンプルで見つかった単語については、埋め込み行列を取得し、そのベクトルを単語のインデックスで取得して、埋め込みを取得します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニング中にモデルがそれらを認識しなかったため、マトリックス内の一部の単語が正しくない場合を除いて、すべてが順調であるように思われます。見慣れない単語（語彙外）の問題に対処するために、2014年にword2vec -fasttextの修正を思いつき</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ました</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fasttextは次のように機能します。単語が辞書にない場合は、シンボリックn-gramに分割されます。各n-gram埋め込みは、n-gramの埋め込み行列（word2vecのようにトレーニングされます）から取得され、埋め込みが平均化され、ベクトルが取得されます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/sz/ws/mx/szwsmx8vblcqrbumxrjbzz7nzvo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
合計すると、辞書にない単語のベクトルが得られます。これ</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で、よく知らない単語でも類似性</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><strong><font style="vertical-align: inherit;">計算</font></strong><font style="vertical-align: inherit;">でき</font><strong><font style="vertical-align: inherit;">ます</font></strong><font style="vertical-align: inherit;">。そして、非常に重要なのは、Facebook、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeepPavlov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">プロジェクトなど、ロシア語、英語、中国語のトレーニング済みモデルがあるため</font><font style="vertical-align: inherit;">、これをパイプラインにすばやく含めることができることです。</font></font><br>
<br>
<strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">しかし、欠点は残っています：</font></font></strong><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデルはテキストベクトル全体には使用されません。</font><font style="vertical-align: inherit;">共通のテキストベクトルを取得するには、平均、または平均とidf-weightsの乗算を考える必要があります。これは、タスクによって動作が異なります。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コンテキストに関係なく、1ワードのベクトルは1のままです。</font><font style="vertical-align: inherit;">Word2vecは、単語が出現するあらゆるコンテキストに対して1つの単語ベクトルをトレーニングします。</font><font style="vertical-align: inherit;">多値の単語（たとえば、言語など）の場合、1つの同じベクトルが存在します。</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/ob/i3/ap/obi3apyrva_kjktfpfjh7farkx8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際、これらのフレーズに共通する「in」しかない場合でも、fasttextの例のコサイン近接度は、tf-idfのコサイン近接度よりも高くなっています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/2p/lz/hq/2plzhqw0n1-8m4vrc71_zwokjla.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fasttextのt-SNE（トップ10インテント）、F1スコア：0.86</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
ただし、t-SNE分解でfasttextの結果を視覚化すると、tf-idfの場合よりもインテントのクラスターが割り当てられます。ここでのF1メジャーは0.92ではなく0.86です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実験を行いました：結合されたtf-idfとfasttextベクトル。品質は、tf-idfのみを使用する場合とまったく同じです。これはすべてのタスクに当てはまるわけではありません。tf-idfとfasttextを組み合わせたものがtf-idfだけよりもうまく機能する、またはfasttextがtf-idfよりもうまく機能するという問題があります。実験してみる必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
意図の数を増やしましょう（170あることを思い出してください）。以下は、tf-idfベクトルの上位30の意図のクラスターです。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/2k/a3/q9/2ka3q9iuylym9_cqdizf4dbtbfu.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf-idfのt-SNE（上位30インテント）、F1スコア0、85（10は0.92）</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
品質が7ポイント低下し、現在、顕著なクラスター構造は見られません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
意味的に、そして言葉で交差するより多くの意図が追加されたため、混乱し始めたテキストの例を見てみましょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
例：「そして、あなたが預金を開く場合、それに対する関心は何ですか？」</font><font style="vertical-align: inherit;">そして、「そして私は7パーセントで寄付を開きたいです。」</font><font style="vertical-align: inherit;">非常によく似たフレーズですが、意図は異なります。</font><font style="vertical-align: inherit;">前者の場合、人は預金の条件を知りたい、そして後者の場合、預金を開くことを望んでいます。</font><font style="vertical-align: inherit;">そのようなテキストを異なるクラスに分けるには、より複雑な</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ディープラーニング</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が必要です</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">言語モデル</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキストのベクトル、特に使用のコンテキストに依存する単語のベクトルを取得したいと考えています。そのようなベクトルを取得する標準的な方法は</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、言語モデルからの埋め込み</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><strong><font style="vertical-align: inherit;">使用すること</font></strong><font style="vertical-align: inherit;">です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
言語モデルは、言語モデリングの問題を解決します。そして、この仕事は何ですか？一連の単語があるとします。たとえば、「私は自分の前でのみ話します...」で、次の単語を予測しようとしています。言語モデルは、埋め込みのコンテキストを提供します。各単語のコンテキスト埋め込みとベクトルを取得すると、次の単語の確率を予測できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
辞書次元ベクトルがあり、各単語には次の確率が割り当てられています。私たちは再び、実際にどのような単語があったかを知っており、間違いを考慮してモデルをトレーニングします。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1i/yd/f1/1iydf1xm3j97nwwuys6jmrq1ate.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
言語モデルはたくさんありますが、昨年ブームはありましたか？</font><font style="vertical-align: inherit;">そして多くの異なるアーキテクチャが提案されてきました。</font><font style="vertical-align: inherit;">その1つが</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMo</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMo</font></font></h3><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoモデルのアイデアは、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最初にテキスト内の各単語に埋め込まれたシンボリックな単語を作成し、次に</font><font style="vertical-align: inherit;">、単語が発生するコンテキストを考慮して埋め込みが考慮されるように、</font><font style="vertical-align: inherit;">それらに</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LSTMネットワーク</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を適用する</font><strong><font style="vertical-align: inherit;">ことです</font></strong><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
記号的埋め込みがどのように取得されるかを考えてみましょう。単語を記号に分割し、各記号に埋め込みレイヤーを適用して、埋め込み行列を取得します。シンボルだけになると、そのような行列の次元は小さくなります。次に、NLPで通常行われているように、埋め込み行列に1次元のたたみ込みが適用され、最後に最大プーリングが行われて、1つのベクトルが取得されます。</font><strong><font style="vertical-align: inherit;">単語の一般的なベクトル</font></strong><font style="vertical-align: inherit;">を計算</font><font style="vertical-align: inherit;">する2層、いわゆる</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">高速道路ネットワーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">がこのベクトル</font><font style="vertical-align: inherit;">に</font><font style="vertical-align: inherit;">適用され</font><font style="vertical-align: inherit;">ます。</font></font><strong><font style="vertical-align: inherit;"></font></strong><font style="vertical-align: inherit;"></font><br>
<br>
<img src="https://habrastorage.org/webt/in/zp/zw/inzpzwr-5-in2jiuszhjrkimczs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さらに、モデルは、トレーニングセットで見つからなかった単語についても、埋め込みのある種の仮説を構築します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各単語のシンボリック埋め込みを受け取った後、2層のBiLSTMネットワークをそれらに適用します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vi/em/mb/viemmbyrjg0lboyuiq8bfbrgewy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2層のBiLSTMネットワークを適用した後、通常は最後の層の隠された状態が通常取られ、これはコンテキスト埋め込みであると考えられています。</font><font style="vertical-align: inherit;">しかし、ELMoには2つの機能があります。</font></font><br>
<br>
<ul>
<li><strong><font style="vertical-align: inherit;"></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最初のLSTM層の入力とその出力の間の</font><strong><font style="vertical-align: inherit;">残留接続</font></strong><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">LSTM入力は、グラデーションのフェージングの問題を回避するために出力に追加されます。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoの作成者は、各単語のシンボリック埋め込みと、最初のLSTMレイヤーの出力と2番目のLSTMレイヤーの出力を、タスクごとに選択されたいくつかの重みと組み合わせることを提案しています。</font><font style="vertical-align: inherit;">これは、LSTMの第1層と第2層を提供する低レベルの機能と高レベルの機能の両方を考慮するために必要です。&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちのタスクでは、これらの3つの埋め込みの単純な平均を使用して、各単語のコンテキスト埋め込みを取得しました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/8y/tl/pa/8ytlpa3lia0oxj461muadegcdyq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
言語モデルには次の利点があります。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">単語のベクトルは、単語が使用されるコンテキストに依存します。</font><font style="vertical-align: inherit;">つまり、たとえば、身体の部分と言語の用語の意味での「言語」という単語の場合、異なるベクトルが得られます。&nbsp;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">word2vecやfasttextの場合と同様に、たとえば、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeepPavlov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">プロジェクトからの多くのトレーニング済みモデルがあります</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">完成したモデルを使用して、タスクに適用してみることができます。&nbsp;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">単語ベクトルを平均化する方法を考える必要はもうありません。</font><font style="vertical-align: inherit;">ELMoモデルはすぐにすべてのテキストのベクトルを生成します。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">タスクの言語モデルを再トレーニングできます。これには、ULMFiTなど、さまざまな方法があります。&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
唯一のマイナスが残っています- </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">言語モデルは</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、同じクラス、つまり1つのインテントに属するテキストがベクトル空間で近くなることを</font><strong><font style="vertical-align: inherit;">保証</font></strong><font style="vertical-align: inherit;">し</font><strong><font style="vertical-align: inherit;">ません</font></strong><font style="vertical-align: inherit;">。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/hv/09/qf/hv09qfkirx8mbcfl8rvbsd11aiu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちのレストランの例では、ELMoモデルによるコサイン値が本当に高くなりました。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/m8/d0/ax/m8d0axjr1fysz33kaoi7ydg4kga.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoのt-SNE（上位10インテント）、F1スコア0.93（tf-idfによる0.92）</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
上位10インテントのクラスターもより顕著です。上の図では、10個のクラスターすべてがはっきりと表示されていますが、精度はわずかに向上しています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/fx/ws/uxfxws0f9y1bf-zdpjynmle3xqk.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoのt-SNE（上位30の意図）F1スコア0.86（tf-idfによる0.85）</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
上位30の意図では、クラスター構造が維持され、品質も1ポイント向上します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、そのようなモデルでは、提案が「預金を開いた場合、それらにどのような関心があるのか​​」という保証はありません。</font><font style="vertical-align: inherit;">また、「私は7％でコントリビューションを開きたい」とは、クラスは異なりますが、お互いにかけ離れています。</font><font style="vertical-align: inherit;">ELMoを使用すると、言語モデルを学習するだけで、意味的に類似したテキストであれば、それらは近くなります。</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoはクラスについて何も認識していませんが</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、クラスラベルを使用して、同じ意図のテキストベクトルを空間にまとめることができます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">シャムネットワーク</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキストのベクトル化のためのお気に入りのニューラルネットワークアーキテクチャと、2つの意図の例を取り上げます。例のそれぞれについて、埋め込みを取得し、それらの間の余弦距離を計算します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ah/sw/ha/ahswhaivfdofbehikcsi7qvhntk.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
&nbsp;コサイン距離は、1から先に出会ったコサイン近接度を引いたものに等しくなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このアプローチは、</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">シャムネットワーク</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と呼ばれ</font><strong><font style="vertical-align: inherit;">ます</font></strong><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
同じクラスのテキスト、たとえば、「送金する」と「お金を投げる」は、スペースの近くに置く必要があります。つまり、それらのベクトル間のコサイン距離はできるだけ小さく、理想的にはゼロにする必要があります。そして、異なる意図に関連するテキストは、可能な限り離れている必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、実際には、異なるクラスのオブジェクトが互いに十分に離れていないため、このトレーニング方法はあまり機能しません。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「トリプレット損失」</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と呼ばれる損失関数は、はるかによく機能します</font><font style="vertical-align: inherit;">。それはトリプレットと呼ばれるオブジェクトのトリプルを使用します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この図はトリプレットを示しています。青い円のアンカーオブジェクト、緑色のポジティブオブジェクト、赤い円のネガティブオブジェクトです。否定的なオブジェクトとアンカーは異なるクラスにあり、肯定的なオブジェクトとアンカーは1つにあります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/qw/38/lz/qw38lz9wpgcphm8w2ic55aqbhea.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニング後、ポジティブオブジェクトがネガティブオブジェクトよりもアンカーに近いことを確認します。これを行うには、オブジェクトのペア間のコサイン距離を考慮し、ハイパーパラメーター（「マージン」）を入力します。これは、ポジティブオブジェクトとネガティブオブジェクトの間にあると予想される距離です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lv/ib/b8/lvibb8qcivpp0evrqxgnyezlo0a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
損失関数は次のようになります。</font></font><br>
<br>
<p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mi>r</mi><mi>i</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi mathvariant=&quot;normal&quot;>&amp;#x005F;</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;>max</mo><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo>,</mo><mi>P</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2212;</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo>,</mo><mi>N</mi><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>]</mo><mo>.</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="57.393ex" height="2.634ex" viewBox="0 -809.3 24710.9 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-72" x="361" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-69" x="813" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-70" x="1158" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-6C" x="1662" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-65" x="1960" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-74" x="2427" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-5F" x="2788" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-6C" x="3289" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-6F" x="3587" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-73" x="4073" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-73" x="4542" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-3D" x="5289" y="0"></use><g transform="translate(6346,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-6D"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-61" x="833" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-78" x="1334" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-5B" x="8208" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-30" x="8487" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-2C" x="8987" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-6D" x="9432" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-61" x="10311" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-72" x="10840" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-67" x="11292" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-69" x="11772" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-6E" x="12118" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-2B" x="12940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-64" x="13941" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-69" x="14465" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-73" x="14810" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-74" x="15280" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-28" x="15641" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-41" x="16031" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-2C" x="16781" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-50" x="17226" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-29" x="17978" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-2212" x="18590" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-64" x="19590" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-69" x="20114" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-73" x="20459" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-74" x="20929" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-28" x="21290" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-41" x="21680" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-2C" x="22430" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMATHI-4E" x="22875" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-29" x="23764" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-5D" x="24153" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhiKGC5ZxBQ9GBUSZig6-2Yn9CeTMg#MJMAIN-2E" x="24432" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mi>r</mi><mi>i</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo movablelimits="true" form="prefix">max</mo><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>P</mi><mo stretchy="false">)</mo><mo>−</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>.</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1">triplet\_loss = \max[0, margin + dist(A, P)- dist(A, N)]. </script></p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
つまり、トレーニング中に、少なくともマージンでは、ポジティブオブジェクトがネガティブよりもアンカーに近いことがわかります。</font><font style="vertical-align: inherit;">損失関数がゼロの場合は機能し、トレーニングを終了します。それ以外の場合は、目的関数の最小化を続けます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルをトレーニングした後も、分類子は取得されません。これは、同じインテントにあるオブジェクトが近いベクトルを持つ可能性があるような埋め込みを取得するための単なる方法です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルを取得したら、埋め込みに加えて別の分類方法を使用できます。</font><font style="vertical-align: inherit;">埋め込みには顕著なクラスター構造があることをすでに達成している</font><font style="vertical-align: inherit;">ため</font><font style="vertical-align: inherit;">、</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KNNは最適です</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
kNNがテキストに対してどのように機能するかを思い出してください。テキスト要素を取り、その埋め込みを取得して、それをベクトル空間に変換し、次にその近傍が誰かを確認します。近隣の中で最も頻度の高いクラスを検討し、新しいオブジェクトはこのクラスに属していると結論付けます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
使用する埋め込みの次元は300であり、トレーニングサンプルには約500,000個のオブジェクトがあります。最近傍を見つけるための標準的な方法は、パフォーマンスの点で私たちに適していません。私たちは、使用</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HNSWの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">方法</font><font style="vertical-align: inherit;">- </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">階層ナビゲートスモールワールドを</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ナビゲート可能なスモールワールドは、遠くにある頂点間のエッジがほとんどなく、近くの頂点間のエッジが多い、接続されたグラフです。この場合、エッジの長さはコサイン距離によって決まります。トレーニングサンプルでは、​​意図のすべての例の間の距離を計算してから、非常に大きな距離をランダムに捨てて、グラフが接続されたままになるようにします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、グラフをレベルに分割するため、階層的という名前を付けます。各レベルには頂点の特定のサブセットのみが含まれ、次の各レベルには前のレベルにあるすべての頂点が含まれます。各レベルで、グラフの連結性を維持しながら、ランダムにエッジを排出します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、最初のレベルでランダムピークを取得し、その近傍のどれが近傍を探している点に最も近いかを確認し、ランダムピークの近傍に移動します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、次のレベルに移動し、最初のピークに最も近い可能性が最も高い近隣の必要な数を選択するまで、プロセスを繰り返します。これはおおよその方法です。つまり、いずれの場合も最も近い近傍を見つける保証はありませんが、非常に</font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">完全性</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が高く</font><font style="vertical-align: inherit;">、設定にもよりますが、</font><strong><font style="vertical-align: inherit;">約0.95-0.99</font></strong><font style="vertical-align: inherit;">です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さらに、最近傍法を使用する利点は、既存のインテントと重複しない新しいインテントを追加するときに、</font><strong><font style="vertical-align: inherit;">モデル全体を再トレーニングする必要</font></strong><font style="vertical-align: inherit;">が</font><strong><font style="vertical-align: inherit;">ない</font></strong><font style="vertical-align: inherit;">ことです。</font></font><strong><font style="vertical-align: inherit;"></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">新しい点をベクトル空間に追加するだけで、自動的に新しいクラスの分類を開始できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
シャムのネットワークをどのように成長させるか見てみましょう。</font><font style="vertical-align: inherit;">以下のグラフは、すべてのインテントが個別のクラスターを形成していることを示しています。</font><font style="vertical-align: inherit;">この場合、線形モデルでもスペースを適切に分離できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/db/2v/yx/db2vyx8eoubfaytjge3imauvgra.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">シャムのt-SNE（上位10の意図）、F1スコア0.95（ELMoによる0.93）</font></font></em><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ib/op/rzibopijmd5mqginmihafxfiivy.png" width="400"></div><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">シャムのt-SNE（上位30インテント）、F1スコア0.87（ELMoによる0.86）</font></font></em><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
10インテントの場合、ELMo言語モデルと比較して2ポイント増加し、30-1で、クラスター構造まだ保存されています。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">概要</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テンプレートと辞書を使用する方法は</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、2-5など、</font><b><font style="vertical-align: inherit;">意図がほとんどなく</font></b><font style="vertical-align: inherit;">、十分に分離可能であり、辞書またはテンプレートによって実際に記述されている場合は、まったく問題ありません。クラスに例がほとんどない場合はうまく機能します。私たちの場合は、20〜30の言い回しオプションしかないユーザーの意図かもしれません。その場合、複雑なモデルを作成しても意味がありません。辞書を使用することができます。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">より多くのインテントがあるが、それらが十分に分離されており、重複する単語がほとんどない場合は、tf-idfに加えて標準の線形モデルを使用できます</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。そのようなモデルはすぐに学習し、移動中は高品質になります。選択を操作してパラメーターを調整すると、品質はさらに向上します。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">言い換えを検討する必要がある場合は、word2vecとfasttextに注意してください。</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">これらは実際のモデルですが、私たちの特定のタスクではそれらは利益をもたらしませんでした。これらはテキスト分類タスクで試してみる価値があります。事前トレーニングされたモデルがあるため、さらに単純なベクトル表現を使用するのと同じくらい高速です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ELMoのトレーニングはもう少し時間がかかりそうです。データを再トレーニングする必要がある場合は、もちろん、技術的な詳細を把握する必要がありますが、これも長すぎませんが、品質を大幅に向上させることができます。</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoは、タスクがテキストのセマンティック機能を考慮する必要</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">がある場合、つまり、意味が近い文が同じクラスに属して</font><b><font style="vertical-align: inherit;">いる場合に特にうまく機能します</font></b><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
分類問題の異なるクラスのテキストが意味で強く交差している場合は、より高度なものを使用する必要があります。</font><font style="vertical-align: inherit;">私たちの場合、シャムのネットワークはうまくいきました。</font><font style="vertical-align: inherit;">少なくともこのようなネットワークをトレーニングするには、各クラスの多くの例が必要になるため、この方法を適用すると時間がかかります。</font><font style="vertical-align: inherit;">つまり、私たちのケースでは、それぞれの意図に多数の正と負の例を提示する必要がありました。</font><font style="vertical-align: inherit;">さらに、適切なニューラルアーキテクチャを考え出し、いくつかのオプションをテストする必要があります。</font><font style="vertical-align: inherit;">しかし、この作業は成果を上げ、品質が大幅に向上します。</font></font><br>
<div class="scrollable-table"><table>
<tbody>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F1スコア</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">〜2-5インテントの</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
異なる語彙</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">〜10インテントの</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
異なる語彙</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">〜30のインテントに関連する</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
語彙</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テンプレート、辞書</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MVP向け</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">良くない</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あなたは気に入らないでしょう</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ML + TF-IDF</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">うーん</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.92</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.85</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ML + fasttext</font></font></td>
<td>?</td>
<td>0,86</td>
<td>0,82</td>
</tr>
<tr>
<td>ELMo</td>
<td>??</td>
<td>0,93</td>
<td>0,86</td>
</tr>
<tr>
<td>siamese</td>
<td>???</td>
<td>0,95</td>
<td>0,87</td>
</tr>
</tbody>
</table></div><b> :</b><br>
<br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">rusvectores.org/ru/models</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">docs.deeppavlov.ai/en/master/intro/pretrained_vectors.html</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">www.mihaileric.com/posts/deep-contextualized-word-representations-elmo</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">omoindrot.github.io/triplet-loss</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">habr.com/ru/company/mailru/blog/338360</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">http://jalammar.github.io/illustrated-bert</a></li>
</ul><br>
<blockquote>   — «Deep Learning vs common sense» —       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">UseData Conf</a>.  ,    -   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a>  18        ,      ,          . <br>
<br>
       ,        ,    ,         ,   16   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">UseData Conf</a>.</blockquote></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja455642/index.html">Yandex.Cloudの分散メッセージキューサービスのアーキテクチャ</a></li>
<li><a href="../ja455644/index.html">実際にデータを使用</a></li>
<li><a href="../ja455646/index.html">セキュリティウィーク24：Androidスマートフォンの工場バックドア</a></li>
<li><a href="../ja455648/index.html">戦闘におけるMLライフサイクル</a></li>
<li><a href="../ja455650/index.html">ネジを分類するためのニューラルネットワークのトレーニング方法</a></li>
<li><a href="../ja455658/index.html">伝説のIntel Core i7-2600K：2019年のSandy Bridgeのテスト（パート3）</a></li>
<li><a href="../ja455662/index.html">デコーダーとしてカム機構を備えた大型機械式ディスプレイ</a></li>
<li><a href="../ja455666/index.html">ITサービス会社でのアウトバウンドセールスの構築</a></li>
<li><a href="../ja455668/index.html">HDLなしのFPGAで記述します。高レベル開発ツールの比較</a></li>
<li><a href="../ja455670/index.html">3Dプリンターが骨、血管、臓器を印刷する方法</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
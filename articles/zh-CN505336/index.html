<!doctype html>
<html class="no-js" lang="zh-CN">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛴️ 🤷🏽 🕴🏻 如何：马奈或莫奈？神经网络响应 ☀️ 🏬 🐩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="艺术家爱德华·马奈（Eduard Manet）和莫奈（Claude Monet）在他们的一生中感到困惑（这是一篇关于Arzamas 的非常有趣的文章）。这并不奇怪，因为他们都是印象派的创始人，并且以类似的方式写作。我听了Coursera的一门关于卷积神经网络的课程，决定尝试创建一个模型，该模型确定哪...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>如何：马奈或莫奈？神经网络响应</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/505336/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">艺术家爱德华·马奈（Eduard Manet）和莫奈（Claude Monet）在他们的一生中感到困惑（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这是一篇</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">关于Arzamas </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">的非常有趣的文章</font></a><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">这并不奇怪，因为他们都是印象派的创始人，并且以类似的方式写作。</font><font style="vertical-align: inherit;">我听了Coursera的一</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">门关于卷积神经网络</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的课程</font><font style="vertical-align: inherit;">，决定尝试</font><font style="vertical-align: inherit;">创建</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">一个</font></a><font style="vertical-align: inherit;">模型，该模型确定哪些艺术家绘画了这张照片。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在开始工作之前，我只知道马奈写过“可耻的”，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“奥林匹亚”</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“早餐在草地上”</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">在收集数据的过程中，很明显：</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">写作风格真的很相似</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">马奈（Manet）画更多肖像，莫奈（Monet）画风景</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">莫奈有一系列相似的绘画作品（例如，同一幅风景，在一天的不同时间绘出）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">莫奈的画比马奈画得多。 </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
绘画示例：</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Manet </font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/o1/s1/d3/o1s1d3imbbm_ki733tjbcnkvtoq.png" alt="图片"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Monet本文</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/xt/ql/xf/xtqlxf_u7tly0xjzyr1ln6x9vie.png" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
的代码可在</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github上找到</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
完整的数据集对于这两个图像处理任务来说都是很小的：一个类（Manet）的图像多于100张，另一类（Monet的图像，多于400张图像，尽管这不是他的全部画作）。</font><font style="vertical-align: inherit;">因此，我没想到在此类问题中通常可以看到很高的分类精度。</font><font style="vertical-align: inherit;">但是有趣的是可以达到什么水平。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">模型简单，无需其他数据处理</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
首先，我们将使用简单的CNN模型，并且不会处理数据（转售除外）。</font></font><br>
<br>
<pre><code class="python hljs">model_simple_cnn_wo_augm = tf.keras.models.Sequential([<font></font>
    tf.keras.layers.Conv2D(<span class="hljs-number">16</span>, (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(input_size, input_size, <span class="hljs-number">3</span>)),<font></font>
    tf.keras.layers.MaxPooling2D(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>),<font></font>
    tf.keras.layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>),<font></font>
    tf.keras.layers.MaxPooling2D(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>),<font></font>
    tf.keras.layers.Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>),<font></font>
    tf.keras.layers.MaxPooling2D(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>),<font></font>
    tf.keras.layers.Flatten(),<font></font>
    tf.keras.layers.Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">'relu'</span>),<font></font>
    tf.keras.layers.Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">'sigmoid'</span>)<font></font>
])<font></font>
<font></font>
train_datagen_wo_augm = ImageDataGenerator(rescale=<span class="hljs-number">1.0</span>/<span class="hljs-number">255.</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
根据训练结果，明显过拟合是明显的：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/us/ys/pa/usyspahxs01dhnz5676runzx6fs.png" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
验证AUC的最佳结果是0.883，但是训练样本中的AUC是0.997。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
为了应对过度拟合，让我们尝试添加数据预处理。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">简单的数据预处理模型</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
对于预处理，我们</font><font style="vertical-align: inherit;">在keras中</font><font style="vertical-align: inherit;">使用</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ImageDataGenerator</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">函数</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">我们添加旋转，垂直和水平移动，图像的“拉伸”和缩放，亮度和颜色的变化以及水平显示。</font></font><br>
<br>
<pre><code class="python hljs">train_datagen_with_augm = ImageDataGenerator(rescale=<span class="hljs-number">1.0</span>/<span class="hljs-number">255.</span>,<font></font>
                                  rotation_range=<span class="hljs-number">40</span>,<font></font>
      width_shift_range=<span class="hljs-number">0.2</span>,<font></font>
      height_shift_range=<span class="hljs-number">0.2</span>,<font></font>
      shear_range=<span class="hljs-number">0.2</span>,<font></font>
      zoom_range=<span class="hljs-number">0.2</span>,<font></font>
      brightness_range = [<span class="hljs-number">0.5</span>, <span class="hljs-number">1.5</span>],<font></font>
      channel_shift_range = <span class="hljs-number">100</span>,<font></font>
      horizontal_flip=<span class="hljs-literal">True</span>,<font></font>
      fill_mode=<span class="hljs-string">'nearest'</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我们保持模型和所有训练参数不变。</font><font style="vertical-align: inherit;">根据训练的结果，很明显训练和验证样本的度量值（AUC）非常接近，也就是说，预处理有助于消除过度拟合。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yd/r_/pt/ydr_ptvn0hr_q1vckkiq0vqzrhc.png" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
结果，测试样品的AUC为0.919，而验证值为0.909。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
前两个模型的结果：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/rw/u3/1y/rwu31yvitkeydbnbxtaiczepqkm.png" alt="图片"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">具有数据预处理和权重的简单模型</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
添加预处理消除了过度拟合。</font><font style="vertical-align: inherit;">尽管AUC还不错，但是数据的不平衡促使我尝试增加模型的权重。</font><font style="vertical-align: inherit;">我</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">从keras手册中</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用了</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">计算权重</font></a><font style="vertical-align: inherit;">的</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">方法</font></a><font style="vertical-align: inherit;">：</font></font><br>
<br>
<pre><code class="python hljs">weight_for_manet = (<span class="hljs-number">1</span> / manet_test_size)*(manet_test_size + monet_test_size)/<span class="hljs-number">2.0</span> 
weight_for_monet = (<span class="hljs-number">1</span> / monet_test_size)*(manet_test_size + monet_test_size)/<span class="hljs-number">2.0</span><font></font>
<font></font>
class_weight = {<span class="hljs-number">0</span>: weight_for_manet, <span class="hljs-number">1</span>: weight_for_monet}
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
计算结果是，类别0（Manet）的权重为2.50，类别1（Monet）的权重为0.62，</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
然后将class_weight变量添加到model.fit（）中，</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
但是训练结果与没有权重的版本没有显着差异：训练集中的AUC为0.892，验证-0.915。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
前三个模型的结果：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/sy/dz/r0/sydzr0c1x_kj_ndbs7gbumuzr84.png" alt="图片"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">转移学习：使用Inception V3模型</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
对于机器学习任务，我们的数据集很小，而对于深度学习则更多。</font><font style="vertical-align: inherit;">在这种情况下，转移学习方法可能会有所帮助。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这个想法是采用一个现成的模型，该模型已经在大型数据集上进行了训练，因此有机会学习数据中的更多模式。</font><font style="vertical-align: inherit;">之后，将网络的最后一层替换为适合我们任务的那一层，然后模型在我们的数据集上进行训练。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我使用了Inception V3模型（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wiki</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ Habr”上的文章</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">结果很好：训练样本的AUC为0.971，验证为0.970。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
所有模型的结果：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zx/ql/sm/zxqlsmwvrb4e-6z4s6pmdoppwzs.png" alt="图片"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">测试模型估计</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
让我们看看测试样本的结果是什么。</font><font style="vertical-align: inherit;">让我们比较两个模型-一个具有数据预处理的简单CNN和一个使用InceptionV3在迁移学习期间获得的模型。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
结果证实了使用转移学习训练的模型的优越性：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/u1/m6/ny/u1m6nyms-e4l4wfudhs36shdtbk.png" alt="图片"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">混淆矩阵和分类错误的示例</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
接受测试样本中的迁移学习模型做出的预测，并查看混淆矩阵。为此，我们选择阈值以便提供接近0.95的真实正向率（这是一个任意值）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
结果就是这样：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/s4/-g/wk/s4-gwkmhmsp2xutxq35ghh4y-lc.png" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
总计，正确的是从马奈（Manet）的绘画中确定出20个中的19个（真实否定率0.95），而莫奈的80个中有75个（正确的阳性率0.9375）是正确的。 TPR和TNR接近，我们希望实现这一目标，因为在此任务中，正确识别两位艺术家很重要。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
现在查看分类错误的图片。吴安德</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Andrew Ng）</font><font style="vertical-align: inherit;">在他的</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">书中</font></a><font style="vertical-align: inherit;">建议使用此技巧</font><font style="vertical-align: inherit;">。目的是试图了解为什么模型错误，以及是否可以修改模型以消除错误。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这是被分类为莫奈的马奈的照片：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/0b/1y/rm/0b1yrmzjsqaiityivl__cwjmftc.png" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这是被定义为马奈的莫奈的照片：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/tm/d7/34/tmd734laf0_aff3pdvzoogmuc2y.png" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我唯一的想法是将肖像（两幅带女人的画+一幅带狗的画，也算作肖像）定义为画鬃毛，因为 </font><font style="vertical-align: inherit;">他经常画肖像。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
但这是不准确的:)尽管莫奈实际上只画了很少的肖像（比风景少得多），但在同一测试样本上还是有他的画笔肖像，这些肖像是由模型正确确定的：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/pi/e5/qj/pie5qjdvp0vx2b8iulccqfvaolg.png" alt="图片"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">发现</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
考虑到较小的数据集和不同类对象的相似性，我最初希望AUC约为0.8。</font><font style="vertical-align: inherit;">但是，即使借助具有数据预处理功能的简单CNN模型，也有可能获得接近0.9的结果，并使用InceptionV3使用转移学习将其提高到0.97。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN505306/index.html">从游戏到电子商务项目。更改Technopark的两年计划</a></li>
<li><a href="../zh-CN505310/index.html">技术先进的公司与众不同之处以及技术支持如何帮助您的团队成长</a></li>
<li><a href="../zh-CN505314/index.html">Linux时间同步：NTP，Chrony和systemd-timesyncd</a></li>
<li><a href="../zh-CN505322/index.html">未来的调度员：他在服务公司中的角色将如何改变？</a></li>
<li><a href="../zh-CN505330/index.html">如何在3年内不从头开始创建加密货币</a></li>
<li><a href="../zh-CN505340/index.html">沃尔玛员工试图证明防盗AI不起作用</a></li>
<li><a href="../zh-CN505342/index.html">依赖注入和依赖倒置原理是不相同的</a></li>
<li><a href="../zh-CN505362/index.html">Vite-在Vue上没有捆绑的潜在客户开发</a></li>
<li><a href="../zh-CN505378/index.html">所有这些营销：如何与IT公司的联络点合作？</a></li>
<li><a href="../zh-CN505386/index.html">在Netgear Stora上安装Debian</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
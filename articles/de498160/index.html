<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔈 👩🏾‍🎓 😐 GlusterFS als externer Speicher für Kubernetes 🛂 🎈 👩🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Finden des optimalen Speichers ist ein ziemlich komplizierter Prozess, alles hat seine Vor- und Nachteile. Der Marktführer in dieser Kategorie ist...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>GlusterFS als externer Speicher für Kubernetes</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498160/"><img src="https://portworx.com/wp-content/uploads/2018/10/Twitter-Social-Graphic-68.png" alt="Bild"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Finden des optimalen Speichers ist ein ziemlich komplizierter Prozess, alles hat seine Vor- und Nachteile. </font><font style="vertical-align: inherit;">Der Marktführer in dieser Kategorie ist natürlich CEPH, aber es ist ein ziemlich komplexes System, wenn auch mit sehr umfangreichen Funktionen. </font><font style="vertical-align: inherit;">Für uns ist ein solches System redundant, da wir einen einfachen replizierten Speicher im Master-Master-Modus für einige Terabyte benötigten. </font><font style="vertical-align: inherit;">Nachdem wir viel Material studiert hatten, wurde beschlossen, das modischste Produkt auf dem Markt für die Schaltung zu testen, an der wir interessiert sind. </font><font style="vertical-align: inherit;">Aufgrund der Tatsache, dass keine vorgefertigte Lösung für einen solchen Plan gefunden wurde, möchte ich meine Best Practices zu diesem Thema teilen und die Probleme beschreiben, die im Bereitstellungsprozess aufgetreten sind.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tore</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was haben wir vom neuen Repository erwartet:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Möglichkeit, mit einer geraden Anzahl von Knoten für die Replikation zu arbeiten.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Einfache Installation, Einrichtung, Support</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das System muss erwachsen, erprobt und Benutzer sein</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Möglichkeit, den Speicherplatz ohne Ausfallzeiten zu erweitern</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Speicher muss mit Kubernetes kompatibel sein</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Es sollte ein automatisches Failover geben, wenn einer der Knoten abstürzt</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beim letzten Punkt haben wir viele Fragen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Einsatz</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für die Bereitstellung wurden zwei virtuelle Maschinen auf CentOs 8 erstellt. Jede von ihnen ist über eine zusätzliche Festplatte mit Speicher verbunden.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vorbereitende Vorbereitung</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für GlusterFS müssen Sie XFS einen separaten Datenträger zuweisen, damit das System in keiner Weise beeinträchtigt wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wählen Sie die Partition aus:</font></font><br>
<br>
<pre><code class="bash hljs">$ fdisk /dev/sdb<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): n<font></font>
Partition <span class="hljs-built_in">type</span><font></font>
   p   primary (0 primary, 0 extended, 4 free)<font></font>
   e   extended (container <span class="hljs-keyword">for</span> logical partitions)<font></font>
Select (default p): p<font></font>
Partition number (1-4, default 1):  1<font></font>
First sector (2048-16777215, default 2048): <font></font>
Last sector, +sectors or +size{K,M,G,T,P} (2048-16777215, default 16777215): <font></font>
&nbsp;<font></font>
Created a new partition 1 of <span class="hljs-built_in">type</span> ‘Linux’ and of size 8 GiB.<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): w <font></font>
<font></font>
The partition table has been altered.<font></font>
Calling ioctl() to re-read partition table. Syncing disks.<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In XFS formatieren und bereitstellen:</font></font><br>
<br>
<pre><code class="bash hljs">$ mkfs.xfs /dev/sdb1<font></font>
$ mkdir /gluster<font></font>
$ mount /dev/sdb1 /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um das Ganze abzurunden, legen Sie den Eintrag in / etc / fstab ab, um das Verzeichnis beim Systemstart automatisch bereitzustellen:</font></font><br>
<br>
<pre><code class="bash hljs">/dev/sdb1       /gluster        xfs     defaults        0       0</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Bezug auf die Installation wurden viele Artikel geschrieben. In diesem Zusammenhang werden wir nicht tief in den Prozess einsteigen, sondern nur überlegen, worauf es sich zu achten lohnt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Installieren Sie auf beiden Knoten die neueste Version von glusterfs und führen Sie sie aus:</font></font><br>
<br>
<pre><code class="bash hljs">$ wget -P /etc/yum.repos.d  https://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-rhel8.repo<font></font>
$ yum -y install yum-utils<font></font>
$ yum-config-manager --<span class="hljs-built_in">enable</span> PowerTools<font></font>
$ yum install -y glusterfs-server<font></font>
$ systemctl start glusterd<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als nächstes müssen Sie dem Glaster mitteilen, wo sich sein Nachbarknoten befindet. </font><font style="vertical-align: inherit;">Dies geschieht mit nur einem Knoten. </font><font style="vertical-align: inherit;">Ein wichtiger Punkt: Wenn Sie ein Domänennetzwerk haben, müssen Sie den Servernamen mit der Domäne angeben, andernfalls müssen Sie in Zukunft alles wiederholen.</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer probe gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn es erfolgreich war, überprüfen wir die Verbindung mit dem Befehl von beiden Servern:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer status<font></font>
Number of Peers: 1<font></font>
<font></font>
Hostname: gluster-02.example.com<font></font>
Uuid: a6de3b23-ee31-4394-8bff-0bd97bd54f46<font></font>
State: Peer <span class="hljs-keyword">in</span> Cluster (Connected)<font></font>
Other names:<font></font>
10.10.6.72<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt können Sie ein Volume erstellen, in das wir schreiben werden.</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume create main replica 2 gluster-01.example.com:/gluster/main gluster-02.example.com:/gluster/main force</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wo:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hauptname Volume </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Replikat - Typ Volume (weitere Details finden Sie in der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">offiziellen Dokumentation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 - Anzahl der Replikate </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Führen Sie Volume aus und überprüfen Sie die Leistung:</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume start main<font></font>
gluster volume status main</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für repliziertes Volume wird empfohlen, die folgenden Parameter festzulegen:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster volume <span class="hljs-built_in">set</span> main network.ping-timeout 5<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-type fixed<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-count 1<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main performance.quick-read on</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit diesen einfachen Schritten haben wir einen GlusterFS-Cluster erstellt. </font><font style="vertical-align: inherit;">Es bleibt eine Verbindung herzustellen und die Leistung zu überprüfen. </font><font style="vertical-align: inherit;">Ubuntu ist auf dem Client-Computer installiert. Zum Mounten müssen Sie den Client installieren:</font></font><br>
<br>
<pre><code class="bash hljs">$ add-apt-repository ppa:gluster/glusterfs-7<font></font>
$ apt install glusterfs-client<font></font>
$ mkdir /gluster<font></font>
$ mount.glusterfs gluster-01.example.com:/main /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Gluster mit einem der Knoten verbunden ist, gibt er die Adressen aller Knoten an und stellt automatisch eine Verbindung zu allen her. </font><font style="vertical-align: inherit;">Wenn der Client bereits eine Verbindung hergestellt hat, führt der Ausfall eines der Knoten nicht zum Anhalten. </font><font style="vertical-align: inherit;">Wenn der erste Knoten nicht verfügbar ist, kann im Falle einer Sitzungsunterbrechung keine Verbindung hergestellt werden. </font><font style="vertical-align: inherit;">Zu diesem Zweck können Sie beim Mounten den Parameter backupvolfile übergeben, der den zweiten Knoten angibt.</font></font><br>
<pre><code class="bash hljs">mount.glusterfs gluster-01.example.com:/main /gluster -o backupvolfile-server=gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein wichtiger Punkt: Gluster synchronisiert Dateien zwischen Knoten nur, wenn ihre Änderung über das bereitgestellte Volume erfolgte. </font><font style="vertical-align: inherit;">Wenn Sie Änderungen direkt an den Knoten vornehmen, ist die Datei nicht synchron.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stellen Sie eine Verbindung zu Kubernetes her</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu diesem Zeitpunkt begannen die Fragen: „Wie kann man es verbinden?“. </font><font style="vertical-align: inherit;">Und es gibt mehrere Möglichkeiten. </font><font style="vertical-align: inherit;">Betrachten Sie sie.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Heketi</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Am beliebtesten und empfohlenen ist die Verwendung eines externen Dienstes: heketi. </font><font style="vertical-align: inherit;">heketi ist eine Schicht zwischen Kubernetes und Gluster, mit der Sie Speicher über http verwalten und bearbeiten können. </font><font style="vertical-align: inherit;">Aber Heketi wird dieser einzige Punkt des Scheiterns sein, weil </font><font style="vertical-align: inherit;">Dienst ist nicht geclustert. </font><font style="vertical-align: inherit;">Die zweite Instanz dieses Dienstes kann nicht unabhängig arbeiten, weil </font><font style="vertical-align: inherit;">Änderungen werden in der lokalen Datenbank gespeichert. </font><font style="vertical-align: inherit;">Das Ausführen dieses Dienstes in Kubernetes ist ebenfalls nicht geeignet, da </font><font style="vertical-align: inherit;">Er benötigt eine statische Festplatte, auf der seine Datenbank gespeichert wird. </font><font style="vertical-align: inherit;">In dieser Hinsicht erwies sich diese Option als die unangemessenste.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Endpunkt bei Kubernetes</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie Kubernetes auf Systemen mit Paketmanagern haben, ist dies eine sehr praktische Option. </font><font style="vertical-align: inherit;">Der Punkt ist, dass für alle GlusteFS-Server in Kubernetes ein gemeinsamer Endpunkt erstellt wird. </font><font style="vertical-align: inherit;">Auf diesem Endpunkt ist ein Dienst aufgehängt, und wir werden bereits auf diesen Dienst gemountet. </font><font style="vertical-align: inherit;">Damit diese Option funktioniert, muss glusterfs-client auf jedem Kubernetes-Knoten installiert und sichergestellt werden, dass er bereitgestellt werden kann. </font><font style="vertical-align: inherit;">Stellen Sie in Kubernetes die folgende Konfiguration bereit:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: v1<font></font>
kind: Endpoints<font></font>
metadata: <font></font>
  name: glusterfs-cluster<font></font>
subsets:<font></font>
  - addresses:<font></font>
      <span class="hljs-comment">#  ip  </span>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.71</span><font></font>
    ports:<font></font>
      <span class="hljs-comment">#    1,    </span>
      - port: <span class="hljs-number">1</span><font></font>
  - addresses:<font></font>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.72</span><font></font>
    ports:<font></font>
      - port: <span class="hljs-number">1</span><font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: Service<font></font>
metadata:<font></font>
  name: glusterfs-cluster<font></font>
spec:<font></font>
  ports:<font></font>
  - port: <span class="hljs-number">1</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt können wir eine einfache Testbereitstellung erstellen und überprüfen, wie die Montage funktioniert. </font><font style="vertical-align: inherit;">Unten finden Sie ein Beispiel für eine einfache Testbereitstellung:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        glusterfs:<font></font>
          endpoints: glusterfs-cluster<font></font>
          path: main<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Option passte nicht zu uns, da wir auf allen Kubernetes-Knoten Container-Linux haben. </font><font style="vertical-align: inherit;">Der Paketmanager ist nicht vorhanden, daher konnte der Gluster-Client für die Bereitstellung nicht installiert werden. </font><font style="vertical-align: inherit;">In diesem Zusammenhang wurde die dritte Option gefunden, für die entschieden wurde, sie zu verwenden.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GlusterFS + NFS + Keepalived</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bis vor kurzem bot GlusterFS einen eigenen NFS-Server an, jetzt wird der externe Dienst nfs-ganesha für NFS verwendet. </font><font style="vertical-align: inherit;">Es wurde einiges darüber geschrieben, in diesem Zusammenhang werden wir herausfinden, wie man es konfiguriert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Repository muss manuell registriert werden. </font><font style="vertical-align: inherit;">Dazu fügen wir in der Datei /etc/yum.repos.d/nfs-ganesha.repo Folgendes hinzu:</font></font><br>
<br>
<pre><code class="bash hljs">[nfs-ganesha]<font></font>
name=nfs-ganesha<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/<span class="hljs-variable">$basearch</span>/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
[nfs-ganesha-noarch]<font></font>
name=nfs-ganesha-noarch<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/noarch/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und installieren:</font></font><br>
<br>
<pre><code class="bash hljs">yum -y install nfs-ganesha-gluster --nogpgcheck
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nach der Installation führen wir die Grundkonfiguration in der Datei /etc/ganesha/ganesha.conf durch.</font></font><br>
<br>
<pre><code class="json hljs"># create new<font></font>
NFS_CORE_PARAM {<font></font>
    # possible to mount with NFSv3 to NFSv4 Pseudo path<font></font>
    mount_path_pseudo = true;<font></font>
    # NFS protocol<font></font>
    Protocols = 3,4;<font></font>
}<font></font>
EXPORT_DEFAULTS {<font></font>
    # default access mode<font></font>
    Access_Type = RW;<font></font>
}<font></font>
EXPORT {<font></font>
    # uniq ID<font></font>
    Export_Id = 101;<font></font>
    # mount path of Gluster Volume<font></font>
    Path = <span class="hljs-attr">"/gluster/main"</span>;<font></font>
    FSAL {<font></font>
        # any name<font></font>
        name = GLUSTER;<font></font>
        # hostname or IP address of this Node<font></font>
        hostname=<span class="hljs-attr">"gluster-01.example.com"</span>;<font></font>
        # Gluster volume name<font></font>
        volume=<span class="hljs-attr">"main"</span>;<font></font>
    }<font></font>
    # config for root Squash<font></font>
    Squash=<span class="hljs-string">"No_root_squash"</span>;<font></font>
    # NFSv4 Pseudo path<font></font>
    Pseudo=<span class="hljs-string">"/main"</span>;<font></font>
    # allowed security options<font></font>
    SecType = <span class="hljs-string">"sys"</span>;<font></font>
}<font></font>
LOG {<font></font>
    # default log level<font></font>
    Default_Log_Level = WARN;<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir müssen den Dienst starten, nfs für unser Volume aktivieren und überprüfen, ob es aktiviert ist.</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start nfs-ganesha<font></font>
$ systemctl <span class="hljs-built_in">enable</span> nfs-ganesha<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main nfs.disable off<font></font>
$ gluster volume status main<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Infolgedessen sollte der Status anzeigen, dass der NFS-Server für unser Volume gestartet wurde. </font><font style="vertical-align: inherit;">Sie müssen mounten und überprüfen.</font></font><br>
<br>
<pre><code class="bash hljs">mkdir /gluster-nfs<font></font>
mount.nfs gluster-01.example.com:/main /gluster-nfs</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Option ist jedoch nicht fehlertolerant. Sie müssen daher eine VIP-Adresse festlegen, die zwischen unseren beiden Knoten übertragen wird und den Datenverkehr umschaltet, wenn einer der Knoten ausfällt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Installation von keepalived in CentOs erfolgt sofort über den Paketmanager.</font></font><br>
<br>
<pre><code class="bash hljs">$ yum install -y keepalived</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir konfigurieren den Dienst in der Datei /etc/keepalived/keepalived.conf:</font></font><br>
<br>
<pre><code class="json hljs">global_defs {<font></font>
    notification_email {<font></font>
        admin@example.com<font></font>
    }<font></font>
    notification_email_from alarm@example.com<font></font>
    smtp_server mail.example.com<font></font>
    smtp_connect_timeout <span class="hljs-number">30</span><font></font>
<font></font>
    vrrp_garp_interval <span class="hljs-number">10</span>
    vrrp_garp_master_refresh <span class="hljs-number">30</span><font></font>
}<font></font>
<font></font>
#C   ,   .    , VIP .<font></font>
vrrp_script chk_gluster {<font></font>
    script <span class="hljs-attr">"pgrep glusterd"</span><font></font>
    interval 2<font></font>
}<font></font>
<font></font>
vrrp_instance gluster {<font></font>
    interface ens192<font></font>
    state MASTER #     BACKUP<font></font>
    priority 200 #      ,  100<font></font>
    virtual_router_id 1<font></font>
    virtual_ipaddress {<font></font>
        10.10.6.70/24<font></font>
    }<font></font>
<font></font>
    unicast_peer {<font></font>
        10.10.6.72 #        <font></font>
    }<font></font>
<font></font>
    track_script {<font></font>
        chk_gluster<font></font>
    }<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt können wir den Dienst starten und überprüfen, ob der VIP auf dem Knoten angezeigt wird:</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start keepalived<font></font>
$ systemctl <span class="hljs-built_in">enable</span> keepalived<font></font>
$ ip addr<font></font>
1: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000<font></font>
    link/ether 00:50:56:97:55:eb brd ff:ff:ff:ff:ff:ff<font></font>
    inet 10.10.6.72/24 brd 10.10.6.255 scope global noprefixroute ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
    inet 10.10.6.70/24 scope global secondary ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn bei uns alles funktioniert hat, müssen Sie Kubernetes weiterhin PersistentVolume hinzufügen und einen Testdienst erstellen, um den Betrieb zu überprüfen.</font></font><br>
<br>
<pre><code class="python hljs">---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolume<font></font>
metadata:<font></font>
  name: gluster-nfs<font></font>
spec:<font></font>
  capacity:<font></font>
    storage: <span class="hljs-number">10</span>Gi<font></font>
  accessModes:<font></font>
    - ReadWriteMany<font></font>
  persistentVolumeReclaimPolicy: Retain<font></font>
  nfs:<font></font>
    server: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.70</span><font></font>
    path: /main<font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolumeClaim<font></font>
metadata:<font></font>
 name: gluster-nfs<font></font>
spec:<font></font>
 accessModes:<font></font>
 - ReadWriteMany<font></font>
 resources:<font></font>
   requests:<font></font>
     storage: <span class="hljs-number">10</span>Gi<font></font>
 volumeName: <span class="hljs-string">"gluster-nfs"</span><font></font>
<font></font>
---<font></font>
apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
  labels:<font></font>
    app: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        persistentVolumeClaim:<font></font>
          claimName: gluster-nfs<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei dieser Konfiguration bleibt der Hauptknoten im Falle eines Ausfalls etwa eine Minute lang im Leerlauf, bis der Mount im Timeout abfällt und wechselt. </font><font style="vertical-align: inherit;">Nehmen wir für eine Minute an, dass dies keine normale Situation ist und wir uns selten damit treffen werden. In diesem Fall schaltet das System jedoch automatisch um und arbeitet weiter. Wir können das Problem lösen und die Wiederherstellung durchführen, ohne uns um die einfache Situation kümmern zu müssen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zusammenfassung</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Artikel haben wir drei mögliche Optionen für die Verbindung von GlusterFS mit Kubernetes untersucht. In unserer Version ist es möglich, Kubernetes einen Provisioner hinzuzufügen, den wir jedoch noch nicht benötigen. </font><font style="vertical-align: inherit;">Die Ergebnisse von Leistungstests zwischen NFS und Gluster müssen noch auf denselben Knoten hinzugefügt werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dateien auf 1 MB:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1M count=1024; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 2.63496 s, 407 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 5.4527 s, 197 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dateien auf 1 KB:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1K count=1048576; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 70.0508 s, 15.3 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 6.95208 s, 154 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NFS funktioniert für jede Dateigröße gleich, der Geschwindigkeitsunterschied ist im Gegensatz zu GlusterFS, das bei kleinen Dateien stark beeinträchtigt ist, nicht besonders auffällig. </font><font style="vertical-align: inherit;">Gleichzeitig zeigt NFS bei großen Dateien eine 2-3-mal niedrigere Leistung als Gluster.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de498146/index.html">Sechs intelligente Sicherheitstrends, auf die Sie achten sollten</a></li>
<li><a href="../de498150/index.html">Klempnerprogrammierer oder die Geschichte eines Lecks und die Schwierigkeiten, damit umzugehen</a></li>
<li><a href="../de498154/index.html">Kalender der kostenlosen IT-Veranstaltungen online vom 20. bis 26. April</a></li>
<li><a href="../de498156/index.html">F #, Morphologie von Binärbildern</a></li>
<li><a href="../de498158/index.html">Remote Marathon Woche 1: Arbeitsplatz</a></li>
<li><a href="../de498162/index.html">Wir laden Sie zu einem IT-Praktikum bei der Alfa Bank ein</a></li>
<li><a href="../de498164/index.html">Produktstrategien für Übergangskosten</a></li>
<li><a href="../de498168/index.html">Neue neuronale Netzwerkarchitekturen</a></li>
<li><a href="../de498172/index.html">Java Digest für den 21. April</a></li>
<li><a href="../de498174/index.html">Wie Sie aufhören, sich Sorgen zu machen und an A / B-Tests glauben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
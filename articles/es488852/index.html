<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßô üçî üíÉüèº Configurar la funci√≥n de p√©rdida para una red neuronal basada en datos s√≠smicos ‚ôæ üëÆ üßõüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En un art√≠culo anterior, describimos un experimento para determinar la cantidad m√≠nima de secciones etiquetadas manualmente para entrenar una red neur...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Configurar la funci√≥n de p√©rdida para una red neuronal basada en datos s√≠smicos</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/488852/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">art√≠culo anterior,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> describimos un experimento para determinar la cantidad m√≠nima de secciones etiquetadas manualmente para entrenar una red neuronal utilizando datos s√≠smicos. </font><font style="vertical-align: inherit;">Hoy continuamos este tema eligiendo la funci√≥n de p√©rdida m√°s adecuada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se consideran dos clases b√°sicas de funciones: entrop√≠a cruzada binaria e intersecci√≥n sobre uni√≥n, en 6 variantes con selecci√≥n de par√°metros, as√≠ como combinaciones de funciones de diferentes clases. </font><font style="vertical-align: inherit;">Adem√°s, se considera la regularizaci√≥n de la funci√≥n de p√©rdida. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Spoiler: logr√≥ mejorar significativamente la calidad del pron√≥stico de la red.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/nq/rn/qt/nqrnqtl1xaabhj0vtklokcrbtpc.jpeg"><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Objetivos de investigaci√≥n empresarial</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No repetiremos la descripci√≥n de los detalles de la encuesta s√≠smica, los datos obtenidos y las tareas de su interpretaci√≥n. Todo esto se describe en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nuestro art√≠culo anterior</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La idea de este estudio fue motivada por los resultados de la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">competencia para la b√∫squeda de dep√≥sitos de sal en rodajas 2D</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Seg√∫n </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">los participantes de la competencia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , para resolver este problema, se utiliz√≥ un zool√≥gico completo de varias funciones de p√©rdida, adem√°s, con diferentes √©xitos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo tanto, nos preguntamos: ¬øes realmente posible que tales problemas en tales datos seleccionen la funci√≥n de p√©rdida y puedan dar una ganancia significativa en la calidad? ¬øO es esta caracter√≠stica solo para las condiciones de la competencia, cuando hay una lucha por el cuarto o quinto decimal para las m√©tricas predefinidas por los organizadores?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
T√≠picamente, en las tareas resueltas con la ayuda de redes neuronales, el ajuste del proceso de aprendizaje se basa principalmente en la experiencia del investigador y algunas heur√≠sticas. Por ejemplo, para los problemas de segmentaci√≥n de im√°genes, las funciones de p√©rdida se utilizan con mayor frecuencia, basadas en la evaluaci√≥n de la coincidencia de las formas de zonas reconocidas, la llamada Intersecci√≥n sobre Uni√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Intuitivamente, con base en una comprensi√≥n del comportamiento y los resultados de la investigaci√≥n, este tipo de funciones dar√°n mejores resultados que las que no est√°n definidas para im√°genes, como las de entrop√≠a cruzada. Sin embargo, los experimentos en busca de la mejor opci√≥n para este tipo de tarea en su conjunto y cada tarea individualmente contin√∫an.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los datos s√≠smicos preparados para la interpretaci√≥n tienen una serie de caracter√≠sticas que pueden tener un impacto significativo en el comportamiento de la funci√≥n de p√©rdida. </font><font style="vertical-align: inherit;">Por ejemplo, los horizontes que separan las capas geol√≥gicas son suaves, y cambian m√°s bruscamente solo en los lugares de las fallas. </font><font style="vertical-align: inherit;">Adem√°s, las zonas distinguidas tienen un √°rea suficientemente grande en relaci√≥n con la imagen, es decir </font><font style="vertical-align: inherit;">Las peque√±as manchas en los resultados de interpretaci√≥n se consideran con mayor frecuencia un error de reconocimiento. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como parte de este experimento, tratamos de encontrar respuestas a las siguientes preguntas locales:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øEs la funci√≥n de p√©rdida de la clase Intersecci√≥n sobre Uni√≥n realmente el mejor resultado para el problema considerado a continuaci√≥n? </font><font style="vertical-align: inherit;">Parece que la respuesta es obvia, pero ¬øcu√°l? </font><font style="vertical-align: inherit;">¬øY cu√°nto es lo mejor desde el punto de vista comercial?</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øEs posible mejorar los resultados combinando funciones de diferentes clases? </font><font style="vertical-align: inherit;">Por ejemplo, Intersecci√≥n sobre Uni√≥n y entrop√≠a cruzada con diferentes pesos.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øEs posible mejorar los resultados agregando a la funci√≥n de p√©rdida varias adiciones dise√±adas espec√≠ficamente para datos s√≠smicos?</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y a una pregunta m√°s global: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬øVale la pena molestarse con la selecci√≥n de la funci√≥n de p√©rdida para la interpretaci√≥n de datos s√≠smicos, o la ganancia en calidad no es comparable con la p√©rdida de tiempo para realizar tales estudios? </font><font style="vertical-align: inherit;">¬øQuiz√°s valga la pena elegir intuitivamente cualquier funci√≥n y gastar energ√≠a en la selecci√≥n de par√°metros de entrenamiento m√°s significativos?</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descripci√≥n general del experimento y los datos utilizados.</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para el experimento, asumimos la misma tarea de aislar capas geol√≥gicas en cortes 2D de un cubo s√≠smico (ver Figura 1). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w6/j3/gn/w6j3gnflms5vqyxc3mbjdnzsaam.png"> <br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 1. Ejemplo de un corte 2D (izquierda) y el resultado del marcado de las capas geol√≥gicas correspondientes (derecha) ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fuente</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Y el mismo conjunto de datos completamente etiquetados del sector holand√©s del Mar del Norte. Los datos s√≠smicos de origen est√°n disponibles en el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">repositorio s√≠smico abierto:</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sitio web del </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">Proyecto Pa√≠ses Bajos Offshore F3 Block</font></a><font style="vertical-align: inherit;"> . Una breve descripci√≥n se puede encontrar en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Silva et al. "Conjunto de datos de los Pa√≠ses Bajos: un nuevo conjunto de datos p√∫blicos para el aprendizaje autom√°tico en la interpretaci√≥n s√≠smica"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como en nuestro caso estamos hablando de cortes 2D, no utilizamos el cubo 3D original, sino el "corte" ya hecho, disponible aqu√≠:</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conjunto de datos de interpretaci√≥n de los Pa√≠ses Bajos F3</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante el experimento, resolvimos los siguientes problemas:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Observamos los datos de origen y seleccionamos los cortes, que son m√°s cercanos en calidad al marcado manual (similar al experimento anterior).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Registramos la arquitectura de la red neuronal, la metodolog√≠a y los par√°metros del entrenamiento, y el principio de seleccionar cortes para el entrenamiento y la validaci√≥n (similar al experimento anterior).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Elegimos las funciones de p√©rdida estudiadas.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seleccionamos los mejores par√°metros para las funciones de p√©rdida parametrizadas.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrenamos redes neuronales con diferentes funciones en el mismo volumen de datos y elegimos la mejor funci√≥n.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrenamos redes neuronales con diferentes combinaciones de la funci√≥n seleccionada con funciones de otra clase en la misma cantidad de datos.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrenamos redes neuronales con regularizaci√≥n de la funci√≥n seleccionada en la misma cantidad de datos.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A modo de comparaci√≥n, utilizamos los resultados de un experimento anterior en el que la funci√≥n de p√©rdida se eleg√≠a exclusivamente de forma intuitiva y era una combinaci√≥n de funciones de diferentes clases con coeficientes tambi√©n elegidos "a simple vista". </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A continuaci√≥n se presentan los resultados de este experimento en forma de m√©tricas estimadas y predichas por las redes de m√°scaras de corte.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 1. Selecci√≥n de datos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como datos iniciales, utilizamos l√≠neas y l√≠neas cruzadas ya preparadas de un cubo s√≠smico del sector holand√©s del Mar del Norte. </font><font style="vertical-align: inherit;">Como en el experimento anterior, simulando el trabajo del int√©rprete, para entrenar a la red, elegimos solo m√°scaras limpias, despu√©s de haber examinado todas las secciones. </font><font style="vertical-align: inherit;">Como resultado, se seleccionaron 700 l√≠neas cruzadas y 400 l√≠neas de ~ 1600 im√°genes de origen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 2. Fijar los par√°metros del experimento.</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta y las siguientes secciones son de inter√©s, en primer lugar, para los especialistas en ciencia de datos, por lo tanto, se utilizar√° la terminolog√≠a adecuada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para la capacitaci√≥n, elegimos el 5% del n√∫mero total de cortes, adem√°s, l√≠neas y l√≠neas cruzadas en partes iguales, es decir. 40 + 40. Las rebanadas se seleccionaron de manera uniforme en todo el cubo. Para la validaci√≥n, se utiliz√≥ 1 corte entre im√°genes adyacentes de la muestra de entrenamiento. Por lo tanto, la muestra de validaci√≥n consisti√≥ en 39 l√≠neas y 39 l√≠neas cruzadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
321 en l√≠nea y 621 en l√≠nea cruzada cayeron en la muestra retrasada, en la que se compararon los resultados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al igual que en el experimento anterior, no se realiz√≥ el preprocesamiento de la imagen y se utiliz√≥ la misma arquitectura UNet con los mismos par√°metros de entrenamiento.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las m√°scaras de corte objetivo se representaron como cubos binarios de dimensi√≥n HxWx10, donde la √∫ltima dimensi√≥n corresponde al n√∫mero de clases, y cada valor del cubo es 0 o 1, dependiendo de si este p√≠xel en la imagen pertenece o no a la clase de la capa correspondiente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada pron√≥stico de red era un cubo similar, cuyo valor se relaciona con la probabilidad de que un p√≠xel de imagen dado pertenezca a la clase de la capa correspondiente. En la mayor√≠a de los casos, este valor se convirti√≥ en la probabilidad misma mediante el uso de un sigmoide. Sin embargo, esto no debe hacerse para todas las funciones de p√©rdida, por lo tanto, la activaci√≥n no se utiliz√≥ para la √∫ltima capa de la red. En cambio, las conversiones correspondientes se realizaron en las funciones mismas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para reducir la influencia de la aleatoriedad de la elecci√≥n de los pesos iniciales en los resultados, la red se entren√≥ durante 1 era con entrop√≠a cruzada binaria en funci√≥n de las p√©rdidas. </font><font style="vertical-align: inherit;">Todos los dem√°s entrenamientos comenzaron con estos pesos recibidos.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 3. La elecci√≥n de las funciones de p√©rdida</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para el experimento, se seleccionaron 2 clases b√°sicas de funciones en 6 variantes: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entrop√≠a cruzada binaria</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entrop√≠a cruzada binaria;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entrop√≠a cruzada binaria ponderada;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entrop√≠a cruzada binaria balanceada.</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Intersecci√≥n sobre Uni√≥n</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Jaccard;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Tversky;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Lov√°sz.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">art√≠culo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> se proporciona una breve descripci√≥n de las funciones enumeradas con c√≥digo para Keras </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Aqu√≠ presentamos los m√°s importantes con enlaces (cuando sea posible) a una descripci√≥n detallada de cada funci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para nuestro experimento, la consistencia de la funci√≥n utilizada durante el entrenamiento es importante con la m√©trica mediante la cual evaluamos el resultado del pron√≥stico de la red en la muestra retrasada. </font><font style="vertical-align: inherit;">Por lo tanto, usamos nuestro c√≥digo implementado en TensorFlow y Numpy, escrito directamente usando las f√≥rmulas a continuaci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La siguiente notaci√≥n se usa en las f√≥rmulas:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pt - para la m√°scara objetivo binaria (Ground Truth);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pp: para la m√°scara de predicci√≥n de red.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para todas las funciones, a menos que se especifique lo contrario, se supone que la m√°scara de predicci√≥n de red contiene probabilidades para cada p√≠xel en la imagen, es decir. </font><font style="vertical-align: inherit;">valores en el intervalo (0, 1).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrop√≠a cruzada binaria</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Descripci√≥n: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fc/-1/ep/fc-1epf3rdg8gfdq0ycdtywgxee.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta funci√≥n busca acercar la distribuci√≥n del pron√≥stico de la red al objetivo, penalizando no solo las predicciones err√≥neas, sino tambi√©n las inciertas.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrop√≠a cruzada binaria ponderada</font></font></h3><br>
<img src="https://habrastorage.org/webt/gm/ud/n3/gmudn3reniryckosw6v_myxzyh0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta funci√≥n coincide con la entrop√≠a cruzada binaria con un valor beta de 1. Se recomienda para fuertes desequilibrios de clase. </font><font style="vertical-align: inherit;">Para beta&gt; 1, el n√∫mero de pron√≥sticos falsos negativos (Falso negativo) disminuye y la integridad (Recuperaci√≥n) aumenta, para beta &lt;1 el n√∫mero de pron√≥sticos falsos positivos (Falso positivo) disminuye y la precisi√≥n aumenta (Precisi√≥n).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrop√≠a cruzada binaria balanceada</font></font></h3><br>
<img src="https://habrastorage.org/webt/pd/pn/sd/pdpnsd3ah6jwiofykm1ftkggfec.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta funci√≥n es similar a la entrop√≠a cruzada ponderada, pero corrige la contribuci√≥n no solo de valores √∫nicos, sino tambi√©n de cero de la m√°scara de destino. </font><font style="vertical-align: inherit;">Coincide (hasta una constante) con entrop√≠a cruzada binaria en un valor de coeficiente beta = 0.5.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Jaccard </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El coeficiente Jacquard (tambi√©n conocido como Intersecci√≥n sobre Uni√≥n, IoU) determina la medida de la "similitud" de las dos √°reas. </font><font style="vertical-align: inherit;">El √≠ndice Dice hace lo mismo: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ej/ak/to/ejakto7j-ghcfffxulq6o6i7kz0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
no tiene sentido considerar ambas funciones. </font><font style="vertical-align: inherit;">Elegimos Jacquard. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el caso de que ambas √°reas se especifiquen utilizando m√°scaras binarias, la f√≥rmula anterior se puede reescribir f√°cilmente en t√©rminos de los valores de las m√°scaras: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/n-/6w/zh/n-6wzhefudinbxqnol6vaibdbaw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
para pron√≥sticos no binarios, la optimizaci√≥n del coeficiente Jacquard es una tarea no trivial. </font><font style="vertical-align: inherit;">Usaremos la misma f√≥rmula para las probabilidades en la m√°scara de pron√≥stico como una cierta imitaci√≥n del coeficiente inicial y, en consecuencia, la siguiente funci√≥n de p√©rdida:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/eq/yi/8f/eqyi8fefrizsnxxu909mlx9wmgm.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Tversky</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Descripci√≥n: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/pdf/1706.05721.pdf</font></font></a><br>
<br>
<img src="https://habrastorage.org/webt/hr/3k/cc/hr3kccuxmb3qfogjzaotqbz1ewa.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Esta funci√≥n es una versi√≥n parametrizada de la optimizaci√≥n del coeficiente Jacquard que coincide con ella en alpha = beta = 1 y con el √≠ndice Dice en alpha = beta = 0.5. </font><font style="vertical-align: inherit;">Para otros valores distintos de cero y no coincidentes, podemos cambiar el √©nfasis hacia la precisi√≥n o la integridad de la misma manera que en las funciones de entrop√≠a cruzada ponderada y equilibrada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El problema de cambio de √©nfasis puede reescribirse usando un solo coeficiente que se encuentra en el intervalo (0, 1). </font><font style="vertical-align: inherit;">La funci√≥n de p√©rdida resultante se ver√° as√≠:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fd/re/og/fdreog2gzjmosed7ggczhjwj9oo.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Lov√°sz</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es dif√≠cil dar una f√≥rmula para esta funci√≥n, ya que es una opci√≥n para optimizar el coeficiente Jacquard mediante un algoritmo basado en errores ordenados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Puede ver la descripci√≥n de la funci√≥n </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqu√≠</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , una de las opciones de c√≥digo est√° </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqu√≠</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬°Explicaci√≥n importante! </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para simplificar la comparaci√≥n de valores y gr√°ficos de aqu√≠ en adelante, bajo el t√©rmino "coeficiente Jacquard" entenderemos mejor la unidad menos el coeficiente en s√≠. </font><font style="vertical-align: inherit;">La p√©rdida de Jaccard es una forma de optimizar esta relaci√≥n, junto con la p√©rdida de Tversky y la p√©rdida de Lov√°sz.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 4. Elegir los mejores par√°metros para las funciones de p√©rdida parametrizadas</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para seleccionar la mejor funci√≥n de p√©rdida en el mismo conjunto de datos, se necesita un criterio de evaluaci√≥n. En su calidad, elegimos el n√∫mero promedio / medio de componentes conectados en las m√°scaras resultantes. Adem√°s, utilizamos el coeficiente Jacquard para las m√°scaras predictivas convertidas en argmax de una sola capa y nuevamente divididas en capas binarizadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El n√∫mero de componentes conectados (es decir, puntos s√≥lidos del mismo color) en cada pron√≥stico obtenido es un criterio indirecto para evaluar el volumen de su posterior refinamiento por parte del int√©rprete. Si este valor es 10, las capas se seleccionan correctamente y estamos hablando de un m√°ximo de correcci√≥n menor del horizonte. Si no hay muchos m√°s, solo necesita "limpiar" peque√±as √°reas de la imagen. Si hay sustancialmente m√°s de ellos, entonces todo es malo e incluso puede necesitar un redise√±o completo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El coeficiente Jacquard, a su vez, caracteriza la coincidencia de zonas de imagen asignadas a una clase y sus l√≠mites.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrop√≠a cruzada binaria ponderada</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seg√∫n los resultados de los experimentos, se seleccion√≥ el valor del par√°metro beta = 2: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/iu/uo/hs/iuuohsoebw2mam6axgianwbi_se.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 2. Comparaci√≥n de la calidad del pron√≥stico de la red para la funci√≥n de p√©rdida principal y los criterios seleccionados </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/dm/-c/3t/dm-c3teowwucpbfd2cckbspwbi0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 3. Estad√≠sticas para el n√∫mero de componentes conectados en t√©rminos del valor de la beta</font></font><br>
</i><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entrop√≠a cruzada binaria balanceada</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seg√∫n los resultados de los experimentos, se eligi√≥ el valor del par√°metro beta = 0.7: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ae/cl/p8/aeclp8omibpajaurlwmrg9sttai.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 4. Comparaci√≥n de la calidad del pron√≥stico de la red por la funci√≥n de p√©rdida principal y los criterios seleccionados </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/lj/r0/fm/ljr0fmrrxbyarastm-wudodn0w0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 5. Estad√≠sticas para el n√∫mero de componentes conectados</font></font><br>
</i><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P√©rdida de Tversky</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seg√∫n los resultados de los experimentos, se eligi√≥ el valor del par√°metro beta = 0.7: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/3a/rk/vt/3arkvtetkqy6i9k3ih8zyo8is78.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 6. Comparaci√≥n de la calidad del pron√≥stico de la red por la funci√≥n de p√©rdida principal y los criterios seleccionados </font></font><br>
</i><br>
<img src="https://habrastorage.org/webt/ct/qx/bh/ctqxbh-6f4hy2ek2k-phurk4zmg.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 7. Comparaci√≥n de la calidad del pron√≥stico de la red por la funci√≥n de p√©rdida principal y los criterios seleccionados</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Se pueden sacar dos conclusiones de las figuras anteriores. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Primero, los criterios seleccionados se correlacionan bastante bien entre s√≠, es decir </font><font style="vertical-align: inherit;">El coeficiente Jacquard es consistente con una estimaci√≥n del volumen de refinamiento necesario. </font><font style="vertical-align: inherit;">En segundo lugar, el comportamiento de las funciones de p√©rdida de entrop√≠a cruzada es l√≥gicamente diferente del comportamiento de los criterios, es decir. </font><font style="vertical-align: inherit;">usar la capacitaci√≥n solo en esta categor√≠a de funciones sin una evaluaci√≥n adicional de los resultados todav√≠a no vale la pena.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 5. Elegir la mejor funci√≥n de p√©rdida.</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora compare los resultados que mostraron las 6 funciones de p√©rdida seleccionadas en el mismo conjunto de datos. </font><font style="vertical-align: inherit;">Para completar, agregamos las predicciones de la red obtenidas en el experimento anterior. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/wc/xr/my/wcxrmy--zexfjmduml37g4smpvc.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 8. Comparaci√≥n de pron√≥sticos de redes capacitados con diferentes funciones de p√©rdida de acuerdo con los criterios seleccionados</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Tabla 1. Valores promedio de los criterios </font></font><br>
<br>
<img src="https://habrastorage.org/webt/kx/89/87/kx8987wn5narwnkfza5k2nemhbm.png"><br>
<br>
<img src="https://habrastorage.org/webt/6s/f4/_k/6sf4_kelwapket3g27sjs2eukyw.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 9. Comparaci√≥n de pron√≥sticos de redes por el n√∫mero de predicciones con un n√∫mero espec√≠fico de componentes conectados</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
De los diagramas y tablas presentados, se pueden sacar las siguientes conclusiones con respecto al uso de "solo" funciones de p√©rdida:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En nuestro caso, las funciones "Jacquard" de la clase Intersecci√≥n sobre Uni√≥n realmente muestran mejores valores que las de entrop√≠a cruzada. </font><font style="vertical-align: inherit;">Por otra parte, significativamente mejor.</font></font></li>
<li>              Lovazh loss.</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comparemos visualmente las previsiones para los sectores con uno de los mejores y peores valores de p√©rdida de Lovazh y el n√∫mero de componentes conectados. La m√°scara de destino se muestra en la esquina superior derecha, y el pron√≥stico obtenido en el experimento anterior en la esquina inferior derecha: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xp/xi/ra/xpxirarzwu1-6gfacc2c1cjh5yy.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 10. Pron√≥sticos de red para uno de los mejores segmentos </font></font><br>
 </i><br>
<img src="https://habrastorage.org/webt/xq/13/dr/xq13drinuno-gjldxvuknxurm-m.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 11. Pron√≥sticos de red para uno de los peores sectores</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Se puede ver que todas las redes funcionan igualmente bien en sistemas f√°cilmente reconocibles rebanadas Pero incluso en un segmento poco reconocible donde todas las redes est√°n equivocadas, el pron√≥stico para la p√©rdida de Lovazh es visualmente mejor que el pron√≥stico de otras redes. Aunque es una de las peores p√©rdidas para esta funci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Entonces, en este paso, hemos decidido un l√≠der claro: la p√©rdida de Lovazh, cuyos resultados se pueden describir de la siguiente manera:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alrededor del 60% de los pron√≥sticos son casi ideales, es decir </font><font style="vertical-align: inherit;">no requieren m√°s que ajustes a secciones individuales de los horizontes;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aproximadamente el 30% de los pron√≥sticos contienen no m√°s de 2 puntos adicionales, es decir </font><font style="vertical-align: inherit;">requieren mejoras menores;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aproximadamente el 1% de los pron√≥sticos contienen de 10 a 25 puntos adicionales, es decir </font><font style="vertical-align: inherit;">Requiere una mejora sustancial.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En este paso, solo reemplazando la funci√≥n de p√©rdida, logramos una mejora significativa en los resultados en comparaci√≥n con el experimento anterior. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬øTodav√≠a se puede mejorar mediante una combinaci√≥n de diferentes funciones? </font><font style="vertical-align: inherit;">Echale un vistazo.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 6. Elegir la mejor combinaci√≥n de funci√≥n de p√©rdida</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La combinaci√≥n de funciones de p√©rdida de diversa naturaleza se usa con bastante frecuencia. Sin embargo, encontrar la mejor combinaci√≥n no es f√°cil. Un buen ejemplo es el resultado de un experimento anterior, que result√≥ ser incluso peor que la funci√≥n "solo". El prop√≥sito de tales combinaciones es mejorar el resultado mediante la optimizaci√≥n de acuerdo con diferentes principios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Intentemos ordenar las diferentes opciones de la funci√≥n seleccionada en el paso anterior con otras, pero no con todas en una fila. Nos limitamos a combinaciones de funciones de diferentes tipos, en este caso, con funciones de entrop√≠a cruzada. No tiene sentido considerar combinaciones de funciones del mismo tipo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En total, verificamos 3 pares con 9 posibles coeficientes cada uno (de 0.1 \ 0.9 a 0.9 \ 0.1). En las siguientes figuras, el eje x muestra el coeficiente antes de la p√©rdida de Lovazh. El coeficiente antes de la segunda funci√≥n es igual a uno menos el coeficiente antes de la primera. El valor izquierdo es solo una funci√≥n de entrop√≠a cruzada, el valor derecho es solo la p√©rdida de Lovazh. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/gq/rq/-d/gqrq-d_mwnnwg5dgvyzysvlxzqw.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 12. Evaluaci√≥n de los resultados del pron√≥stico de redes capacitadas en BCE + Lovazh </font></font><br>
 </i><br>
<img src="https://habrastorage.org/webt/1p/as/9p/1pas9pcxuskc8hnyj2igbzjibkc.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 13. Evaluaci√≥n de los resultados del pron√≥stico de redes capacitadas en BCE + Lovazh </font></font></i><br>
 <br>
<img src="https://habrastorage.org/webt/dy/22/8z/dy228z6wlagamlmywmivsvbvzmg.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 14. Evaluaci√≥n de los resultados del pron√≥stico de las redes capacitadas en BBCE + Lovazh</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se puede ver que la funci√≥n "solo" seleccionada no se mejor√≥ al agregar entrop√≠a cruzada. Reducir algunos valores del coeficiente Jacquard en 1-2 mil√©simas puede ser importante en un entorno competitivo, pero no compensa el deterioro del negocio en el criterio para el n√∫mero de componentes conectados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para verificar el comportamiento t√≠pico de una combinaci√≥n de funciones de diferentes tipos, realizamos una serie similar de entrenamiento para la p√©rdida de Jaccard. Para un solo par, fue posible mejorar ligeramente los valores de ambos criterios simult√°neamente: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
0.8 * JaccardLoss + 0.2 * BBCE </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Promedio de componentes conectados: 11.5695 -&gt; 11.2895 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Promedio de Jaccard: 0.0307 -&gt; 0.0283 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero incluso estos valores son peores que la p√©rdida de Lovazh "solo".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo tanto, tiene sentido investigar combinaciones de funciones de diferente naturaleza en nuestros datos solo en condiciones de competencia o en presencia de tiempo y recursos libres. </font><font style="vertical-align: inherit;">Para lograr un aumento significativo en la calidad es poco probable que tenga √©xito.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarea 7. Regularizaci√≥n de la mejor funci√≥n de p√©rdida.</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En este paso, tratamos de mejorar la funci√≥n de p√©rdida previamente seleccionada con una adici√≥n dise√±ada espec√≠ficamente para datos s√≠smicos. Esta es la regularizaci√≥n descrita en el art√≠culo: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Redes neuronales para geof√≠sicos y su aplicaci√≥n a la interpretaci√≥n de datos s√≠smicos"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El art√≠culo menciona que las regularizaciones est√°ndar como la disminuci√≥n de los pesos en los datos s√≠smicos no funcionan bien. En cambio, se propone un enfoque basado en la norma de la matriz de gradiente, que tiene como objetivo suavizar los l√≠mites de las clases. El enfoque es l√≥gico si recordamos que los l√≠mites de las capas geol√≥gicas deber√≠an ser suaves.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sin embargo, cuando se usa dicha regularizaci√≥n, uno deber√≠a esperar cierto deterioro en los resultados por el criterio de Jacquard, ya que los l√≠mites de clase suavizados probablemente coincidan con posibles transiciones abruptas obtenidas con el marcado manual. Pero tenemos un criterio m√°s para la verificaci√≥n: por el n√∫mero de componentes conectados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Entrenamos 13 redes con la regularizaci√≥n descrita en el art√≠culo y el coeficiente en frente, tomando valores de 0.1 a 0.0001. Las siguientes figuras muestran algunas de las calificaciones para ambos criterios. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/hz/ud/no/hzudnopqafa6t6chsygeikxsvwy.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 15. Comparaci√≥n de la calidad del pron√≥stico de la red seg√∫n los criterios seleccionados </font></font><br>
 </i><br>
<img src="https://habrastorage.org/webt/rq/v7/2h/rqv72hpfiaplc9m3_nfurrxk3xq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 16. Estad√≠sticas para el n√∫mero de componentes conectados en t√©rminos de los valores de los coeficientes antes de la regularizaci√≥n</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se ve que la regularizaci√≥n con un coeficiente de 0.025 redujo significativamente las estad√≠sticas para el criterio para el n√∫mero de componentes conectados. Sin embargo, el criterio Jacquard en este caso se esperaba que aumentara a 0.0357. Sin embargo, este es un ligero aumento en comparaci√≥n con una reducci√≥n en el refinamiento manual. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/oa/-1/ow/oa-1owbvsfhyuzxqsugvjmlk1ro.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 17. Comparaci√≥n de los pron√≥sticos de la red por el n√∫mero de predicciones con el n√∫mero especificado de componentes conectados</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Finalmente, comparamos los l√≠mites de clase en el objetivo y las m√°scaras predichas para el peor corte seleccionado previamente. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/gh/sp/1o/ghsp1oiatktuohroonfpakr3teq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 18. Pron√≥stico de la red para uno de los peores cortes </font></font></i><br>
 <br>
<img src="https://habrastorage.org/webt/ge/0b/zg/ge0bzgqe3gpsuktjwgmxannuxca.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 19. Superposici√≥n de parte del horizonte de la m√°scara objetivo y pron√≥stico</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como se puede ver en las figuras, la m√°scara de pron√≥stico, por supuesto, est√° equivocada en algunos lugares, pero al mismo tiempo suaviza las oscilaciones de los horizontes objetivo, es decir. </font><font style="vertical-align: inherit;">corrige errores menores en el marcado inicial. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Resumen de caracter√≠sticas de la funci√≥n de p√©rdida seleccionada con regularizaci√≥n:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alrededor del 87% de los pron√≥sticos son casi ideales, es decir </font><font style="vertical-align: inherit;">no requieren m√°s que ajustes a secciones individuales de los horizontes;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aproximadamente el 10% de los pron√≥sticos contienen 1 lugar adicional, es decir </font><font style="vertical-align: inherit;">requieren mejoras menores;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alrededor del 3% de los pron√≥sticos contienen de 2 a 5 puntos adicionales, es decir </font><font style="vertical-align: inherit;">requieren un refinamiento un poco m√°s sustancial.</font></font></li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recomendaciones</font></font></h2><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Solo ajustando un par√°metro de aprendizaje, la funci√≥n de p√©rdida, pudimos mejorar significativamente la calidad del pron√≥stico de la red y reducir la cantidad de refinamiento necesario en aproximadamente tres veces. </font></font></li>
<li>             Intersection over Union (     Lovazh loss)      .            -,       .</li>
<li>    -,      .         , ..     .</li>
</ul><br>
<h2>  :</h2><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reinaldo Mozart Silva, Lais Baroni, Rodrigo S. Ferreira, Daniel Civitarese, Daniela Szwarcman, Emilio Vital Brazil. Netherlands Dataset: A New Public Dataset for Machine Learning in Seismic Interpretation</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lars Nieradzik. Losses for Image Segmentation</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Daniel Godoy. Understanding binary cross-entropy / log loss: a visual explanation</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali Gholipour. Tversky loss function for image segmentation using 3D fully convolutional deep networks</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Maxim Berman, Amal Rannen Triki, Matthew B. Blaschko. The Lovasz-Softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bas Peters, Eldad Haber, and Justin Granek. Neural-networks for geophysicists and their application to seismic data interpretation</a></li>
</ol></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es488842/index.html">Atrapa un electr√≥n: observa un proceso que toma una quintillon√©sima de segundo</a></li>
<li><a href="../es488844/index.html">Fronteras para los guardias fronterizos: el tribunal de los Estados Unidos ha establecido reglas para controlar dispositivos: discuta la situaci√≥n</a></li>
<li><a href="../es488846/index.html">Postgresso 19</a></li>
<li><a href="../es488848/index.html">CTO todo inicio</a></li>
<li><a href="../es488850/index.html">Usando RabbitMQ con MonsterMQ Parte 1</a></li>
<li><a href="../es488854/index.html">10. Fortinet Getting Started v6.0. Escolta</a></li>
<li><a href="../es488856/index.html">Bueno CRM y CRM. Todo es m√°s f√°cil de lo que piensas.</a></li>
<li><a href="../es488860/index.html">Sustituci√≥n de importaciones y construcci√≥n naval</a></li>
<li><a href="../es488866/index.html">Validaci√≥n de im√°genes con Gitlab CI / CD</a></li>
<li><a href="../es488868/index.html">Anuncio de Mobius 2020 Piter: ¬øqu√© entusiasma a los desarrolladores m√≥viles?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
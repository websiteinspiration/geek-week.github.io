<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📮 🏼 👩🏼‍🎨 Pourquoi l'hyperconvergence? Présentation et tests de Cisco HyperFlex 👨🏻‍🌾 👨🏿‍🌾 😀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En informatique, l'essentiel est trois lettres
 La tâche de toute infrastructure informatique est de fournir une plate-forme fiable pour les processus...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pourquoi l'hyperconvergence? Présentation et tests de Cisco HyperFlex</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/cti/blog/497024/"><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En informatique, l'essentiel est trois lettres</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La tâche de toute infrastructure informatique est de fournir une plate-forme fiable pour les processus commerciaux de l'entreprise. On estime traditionnellement que la qualité de l'infrastructure des technologies de l'information est évaluée selon trois paramètres principaux: accessibilité, sécurité, fiabilité. Cependant, l'évaluation de ce triple n'est en aucun cas liée à l'entreprise et aux revenus / pertes directs de l'entreprise. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trois lettres principales régissent l'informatique. Si les lettres «RUB» ne se trouvent pas en tête de la hiérarchie informatique, alors vous construisez votre infrastructure informatique de manière incorrecte. Bien sûr, il est difficile de construire directement l'informatique, à partir uniquement des revenus / dépenses, il existe donc une hiérarchie de «trois lettres» - des plus importantes aux plus privées. SLA, RPO, RTO, GRC - tout cela est connu des experts de l'industrie et a longtemps été utilisé dans la construction d'infrastructures. Malheureusement, ne pas toujours lier ces indicateurs dans une hiérarchie de bout en bout.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/oj/wm/6n/ojwm6n6_0mqymccxwojckh8q4fi.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De nombreuses entreprises construisent aujourd'hui des infrastructures pour l'avenir en utilisant la technologie d'hier sur l'architecture d'hier. </font><font style="vertical-align: inherit;">Et en même temps, l'accélération du développement de l'informatique montre que les services modernes changent fondamentalement non seulement les entreprises mais aussi la société - les gens de l'ère numérique sont habitués au fait que quelques secondes suffisent pour accéder à n'importe quelle information. </font><font style="vertical-align: inherit;">L'informatique issue d'une technologie incompréhensible est devenue monnaie courante pour les masses, comme les hamburgers ou les cafés. </font><font style="vertical-align: inherit;">Cela a ajouté de nouvelles lettres extrêmement importantes à l'informatique. </font><font style="vertical-align: inherit;">Ces lettres - TTM (Time to market) - la veille du lancement d'un service productif sur le marché.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ot/k1/ns/otk1nsmpnwofr1v2bzlexp5a9j8.png"><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sds</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D'un autre côté, un kraken est sorti des profondeurs de la technologie, retournant l'informatique et le style de vie traditionnels. Avec l'augmentation de la puissance de calcul des processeurs x86, les systèmes de stockage de logiciels sont devenus le premier tentacule. Les systèmes de stockage classiques étaient des pièces de fer très spécifiques remplies de «silicium personnalisé», divers accélérateurs matériels propriétaires et des logiciels spécialisés. Et il était administré par une personne spécialement formée qui était pratiquement adorée dans l'entreprise en tant que prêtre d'un culte obscur. Élargir le système de stockage opérant dans l'entreprise était tout un projet, avec beaucoup de calculs et d'approbations - après tout, c'est cher!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le coût élevé et la complexité ont stimulé la création de systèmes de stockage de logiciels en plus du matériel x86 habituel avec un système d'exploitation général commun - Windows, Linux, FreeBSD ou Solaris. Seuls les logiciels restaient du matériel personnalisé complexe, ne fonctionnant même pas dans le noyau, mais au niveau de l'utilisateur. Les premiers systèmes logiciels étaient bien sûr assez simples et limités en fonctionnalités, il s'agissait souvent de solutions de niche spécialisées, mais le temps passait. Et maintenant, même les grands fournisseurs de systèmes de stockage ont commencé à abandonner les solutions matérielles spécialisées - le TTM pour de tels systèmes ne pouvait plus résister à la concurrence, et le coût de l'erreur est devenu très élevé. En fait, à de rares exceptions près, même les systèmes de stockage classiques d'ici 2020 sont devenus les serveurs x86 les plus courants, juste avec de belles muselières en plastique et un tas d'étagères de disque.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le deuxième tentacule du kraken qui approche est l'apparition et l'adoption massive par le marché de la technologie de mémoire flash, qui est devenue un pilier en béton brisant le dos d'un éléphant.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les performances des disques magnétiques n'ont pas changé depuis de nombreuses années et les processeurs des contrôleurs de stockage ont complètement géré des centaines de disques. </font><font style="vertical-align: inherit;">Mais hélas, la quantité se transformera tôt ou tard en qualité - et le système de stockage est déjà à un niveau moyen, sans parler du niveau initial, il a une limite supérieure sur le nombre significatif de lecteurs flash. </font><font style="vertical-align: inherit;">Avec une certaine quantité (littéralement à partir de dix disques), les performances du système ne cessent de croître, mais elles peuvent également commencer à baisser en raison de la nécessité de traiter un volume toujours plus important. </font><font style="vertical-align: inherit;">Après tout, la puissance de traitement et le débit des contrôleurs ne changent pas avec l'augmentation de la capacité. </font><font style="vertical-align: inherit;">La solution, en théorie, était l'émergence de systèmes évolutifs qui peuvent assembler de nombreuses étagères indépendantes avec des disques et des ressources de processeur en un seul cluster qui regarde de l'extérieur comme un système de stockage multi-contrôleur unique. </font><font style="vertical-align: inherit;">Il ne restait qu'un pas.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyper convergence</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'étape la plus évidente vers l'avenir a été l'unification de points de stockage et de traitement des données auparavant disparates. En d'autres termes, pourquoi ne pas implémenter le stockage distribué non pas sur des serveurs séparés, mais directement sur les hôtes de virtualisation, refusant ainsi un réseau de stockage spécial et du matériel dédié, et donc combinant des fonctions. Le kraken s'est réveillé. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais permettez-moi de dire, vous voyez, parce que la combinaison est la convergence. D'où vient ce stupide préfixe hyper?</font></font><br>
<blockquote>        .        +  + .    .    ,      “ ”.<br>
…<br>
 ,  ,            ,        .       —       SDS.<br>
<br>
:<br>
<br>
<ul>
<li>  — , ,       ,   /.    .</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Système convergé - le tout à partir d'une seule source, d'un seul support, d'un seul numéro de partenaire. </font><font style="vertical-align: inherit;">À ne pas confondre avec l'auto-assemblage d'un fournisseur.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et il s'avère que le terme de notre architecture convergente est déjà pris. </font><font style="vertical-align: inherit;">Exactement la même situation qu'avec le superviseur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Système hyperconvergé - Un système convergé avec une architecture convergente.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les définitions sont extraites de l'article « </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Théorie générale et archéologie de la virtualisation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> », dans l'écriture duquel j'ai pris une part vivante. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qu'est-ce qui donne l'approche hyperconvergée dans l'application aux trois lettres mentionnées?</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Commencez avec un volume minimum (et un coût minimum)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La capacité de stockage augmente avec la puissance de calcul</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chaque nœud du système est son contrôleur - et le problème du «plafond de verre» est supprimé (les disques le peuvent, mais le contrôleur n'existe plus)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gestion du stockage considérablement simplifiée</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour le dernier paragraphe, les systèmes hyperconvergés sont très détestés par les administrateurs de stockage à l'ancienne mode qui sont utilisés pour administrer les files d'attente sur les ports Fibre Channel. </font><font style="vertical-align: inherit;">L'espace est alloué en quelques clics de souris depuis la console de gestion de l'infrastructure virtuelle. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En d'autres termes, seuls les nuages ​​sont plus rapides que les systèmes hyperconvergés lors du lancement d'un produit, mais les nuages ​​ne conviennent pas à tout le monde et / ou pas toujours. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si vous êtes un administrateur technicien et lisez-le jusqu'ici - réjouissez-vous, les mots généraux sont terminés et maintenant je vais vous parler de ma vision personnelle du système Cisco Hyperflex, que j'ai obtenue avec des pattes tenaces pour effectuer divers tests sur celui-ci.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cisco Hyperflex</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pourquoi Cisco</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cisco est principalement connu comme le fournisseur dominant sur le marché des équipements de réseau, mais en même temps, il est assez largement présent dans d'autres segments du marché des centres de données, offrant à la fois des solutions serveur et hyperconvergées, ainsi que des systèmes d'automatisation et de contrôle. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Étonnamment, d'ici 2020, il y a encore du monde: «Serveurs Cisco? Et de qui les prend-elle? »</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cisco a commencé à traiter avec des serveurs dès 2009, choisissant à cette époque la voie des solutions lames en pleine croissance. L'idée de Cisco était de mettre en œuvre l'approche des calculatrices anonymes. Le résultat a été un système UCS (Unified Computing System) composé de deux commutateurs spécialisés (ils s'appelaient Fabric Interconnect), et de 1 à 20 châssis (8 lames demi-taille) ou jusqu'à 160 serveurs. Dans le même temps, le châssis est devenu généralement stupide avec un morceau de fer alimenté, toute la logique et la commutation sont effectuées dans Fabric Interconnect; le châssis est juste un moyen d'héberger des serveurs et de les connecter au système. Fabric Interconnect est entièrement responsable de toutes les interactions du serveur avec le monde extérieur - Ethernet, FC et gestion. Il semblerait que les lames et les lames, ce qui est là, sauf pour la commutation externe, et pas comme tout le monde dans le châssis.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un moment clé dans la mise en place de ces mêmes «calculatrices anonymes». Dans le cadre du concept Cisco UCS, les serveurs n'ont pas de personnalité autre qu'un numéro de série. Ni MAC, ni WWN, ni rien d'autre. Le système de gestion UCS alimenté par Fabric Interconnect est basé sur des profils de serveur et des modèles. Après avoir connecté un ensemble de serveurs dans le châssis, ils doivent se voir attribuer un profil approprié, dans lequel toutes les adresses et identifiants d'identification sont définis. Bien sûr, si vous n'avez qu'une douzaine de serveurs, le jeu n'en vaut pas la peine. Mais quand il y en a au moins deux, voire trois douzaines, c'est un sérieux avantage. Il devient facile et rapide de migrer des configurations ou, plus important encore, de répliquer les configurations de serveurs en quantité appropriée, d'appliquer immédiatement les modifications à un grand nombre de serveurs,gérer essentiellement un ensemble de serveurs (par exemple, une batterie de serveurs de virtualisation) comme une entité unique. L'approche proposée dans le système UCS permet, avec la bonne approche, de simplifier sérieusement la vie des administrateurs, d'augmenter la flexibilité et de réduire considérablement les risques, de sorte que les lames UCS littéralement en 2-3 ans sont devenues la plate-forme de lame la plus vendue dans l'hémisphère occidental, et aujourd'hui elles sont mondiales l'une des deux plates-formes dominantes, avec HPE.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il est rapidement devenu clair que la même approche basée sur une usine universelle avec une gestion intégrée basée sur des politiques et des modèles est pleinement demandée et s'applique non seulement aux serveurs lames, mais également aux serveurs en rack. Et dans ce sens, les serveurs Cisco montés en rack connectés à Fabric Interconnect bénéficient des mêmes avantages qui rendent les serveurs lames si populaires. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aujourd'hui, je vais parler d'HyperFlex, une solution hyperconvergée Cisco basée sur des serveurs montés en rack connectés à Fabric Interconnect. Ce qui rend HyperFlex intéressant et mérite d'être considéré dans la revue:</font></font><br>
<br>
<ul>
<li>  Cisco   ,  , «» –        ,      HyperFlex;     , ,   ,         HyperFlex    ;</li>
<li>   –          ;  HyperFlex  ,    ,      ;          ,       .</li>
<li> «  » —     « »,       ,       ;</li>
<li>           Fabric Interconnect    Cisco   -,     SAN ,       native FC;</li>
<li>    “” –  ,  ,     ;</li>
<li>   Cisco      ,   ,            ,      ;</li>
<li>  ,      , Cisco        HCI,      , HyperFlex      ,   ,   .</li>
</ul><br>
<h3> </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HyperFlex est un véritable système hyperconvergé avec des VM de contrôleur dédiées. </font><font style="vertical-align: inherit;">Permettez-moi de vous rappeler que le principal avantage d'une telle architecture est sa portabilité potentielle pour différents hyperviseurs. </font><font style="vertical-align: inherit;">Aujourd'hui, Cisco a implémenté la prise en charge de VMware ESXi et Microsoft Hyper-V, mais il est possible qu'une des options KVM apparaisse à mesure que sa popularité augmente dans le segment des entreprises. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Considérons le mécanisme de travail sur l'exemple d'ESXi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les périphériques utilisant la technologie VM_DIRECT_PATH - disque de cache et disques de niveau de stockage - sont directement envoyés à la machine virtuelle du contrôleur (ci-après CVM). </font><font style="vertical-align: inherit;">Par conséquent, nous excluons l'effet de la pile de disques de l'hyperviseur sur les performances. </font><font style="vertical-align: inherit;">Des paquets VIB supplémentaires sont installés dans l'hyperviseur lui-même:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visière IO: fournit le point de montage de la banque de données NFS pour l'hyperviseur</font></font></li>
<li>VAAI:   VMware  API  « » </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les blocs de disques virtuels sont répartis uniformément sur tous les hôtes d'un cluster avec une granularité relativement faible. Lorsque la machine virtuelle sur l'hôte effectue certaines opérations sur le disque, via la pile de disques de l'hyperviseur, l'opération va au magasin de données, puis à IO Visor, puis elle se tourne vers le CVM responsable de ces blocs. Dans ce cas, CVM peut être situé sur n'importe quel hôte du cluster. Compte tenu des ressources très limitées d'IO Visor, il n'y a bien sûr pas de tables de métadonnées et le choix est déterminé mathématiquement. Ensuite, le CVM auquel la demande est parvenue la traite. Dans le cas de la lecture, il envoie des données soit depuis l'un des niveaux de cache (RAM, cache d'écriture, cache de lecture) soit depuis les disques de son hôte. Dans le cas d'un enregistrement, il écrit dans le journal local et duplique l'opération pour un (RF2) ou deux (RF3) CVM.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/k_/hq/eq/k_hqeqytlifhbevdrf8r7mk_rv0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Peut-être que cela suffit pour comprendre le principe du travail dans le cadre de cette publication, sinon je prendrai du pain auprès des formateurs Cisco et j'aurai honte. </font><font style="vertical-align: inherit;">Pas vraiment, mais encore assez.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Question sur les tests synthétiques</font></font></h3><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
- Navigateur, électroménagers! </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
- 36! </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
- Qu'est-ce que 36? </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
- Et les appareils? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aujourd'hui, quelque chose comme ça ressemble à la plupart des tests synthétiques des systèmes de stockage. Pourquoi donc? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jusqu'à relativement récemment, la plupart des systèmes de stockage étaient plats avec un accès uniforme. Qu'est-ce que ça veut dire? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'espace disque total disponible a été collecté à partir de disques ayant les mêmes caractéristiques. Par exemple, 300 disques de 15k. Et la performance était la même dans tout l'espace. Avec l'avènement de la technologie de stockage hiérarchisé, les systèmes de stockage sont devenus non stables - les performances varient au sein d'un même espace disque. Et ce n'est pas seulement différent, mais aussi imprévisible, selon les algorithmes et les capacités d'un modèle de stockage particulier.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et tout ne serait pas aussi intéressant si les systèmes hyperconvergés avec localisation des données n'apparaissaient pas. </font><font style="vertical-align: inherit;">En plus de l'inégalité de l'espace disque lui-même (fatigues, caches flash), il y a également un accès inégal à celui-ci - selon que l'une des copies de données se trouve sur les disques locaux du nœud ou qu'elle doit être accessible via le réseau. </font><font style="vertical-align: inherit;">Tout cela conduit au fait que le nombre de tests synthétiques peut être absolument nul et ne pas parler de quoi que ce soit pratiquement significatif. </font><font style="vertical-align: inherit;">Par exemple, la consommation de carburant d'une voiture selon une brochure publicitaire que vous ne pourrez jamais atteindre dans la vraie vie.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Question sur le dimensionnement</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le revers des numéros de test synthétiques était les numéros de taille et les spécifications sous le clavier de prévente. Les préventes dans ce cas sont divisées en deux catégories - certaines martèlent stupidement vos savoirs traditionnels dans le configurateur du fournisseur, et le second les prendra eux-mêmes, car ils comprennent comment cela fonctionne. Mais avec le second, vous devrez considérer en détail ce que vous avez écrit dans votre savoir traditionnel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous le savez, sans savoir traditionnel - le résultat de HZ. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/nk/li/uq/nkliuqyn2iv0ogsigw-nd_m94ky.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par expérience pratique - lors du dimensionnement d'un système hyperconvergé plutôt lourd dans une compétition avec l'un des clients, j'ai personnellement, après le pilote, pris les indicateurs de charge du système et les ai comparés avec ce qui était écrit dans le TOR. Il s'est avéré comme dans une blague:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Rabinovich, est-il vrai que vous avez gagné un million à la loterie? </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - Oh, qui vous a dit ça? </font><font style="vertical-align: inherit;">Pas un million, mais dix roubles, pas à la loterie, mais de préférence, et n'a pas gagné, mais perdu.</font></font></blockquote><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En d'autres termes, la situation GIGO classique - Garbage In Garbage Out - Garbage input = Garbage in the output. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le dimensionnement applicable pratique pour l'hyperconvergence est presque garanti de deux types: prenez-nous avec une marge, ou pendant longtemps nous conduirons un pilote et prendrons des indicateurs.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a un autre point avec le dimensionnement et l'évaluation des spécifications. Différents systèmes sont construits différemment et fonctionnent différemment avec les disques; leurs contrôleurs interagissent différemment. Par conséquent, il est pratiquement inutile de comparer «tête-à-tête» selon les spécifications le nombre et le volume de disques. Vous disposez d'une sorte de savoirs traditionnels au sein desquels vous comprenez le niveau de charge. Et puis il y a un certain nombre de boîtes de vitesses, dans lesquelles on vous propose différents systèmes qui répondent aux exigences de performance et de fiabilité. Quelle est la différence fondamentale, combien coûte un disque et quel type dans le système 1, et que dans le système 2, il y en a plus / moins si les deux réussissent à exécuter la tâche.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Étant donné que les performances sont souvent déterminées par des contrôleurs vivant sur les mêmes hôtes que les machines virtuelles, pour certains types de charges, elles peuvent nager de manière assez significative simplement parce que les processeurs de fréquences différentes sont situés dans des clusters différents, toutes choses étant égales par ailleurs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En d'autres termes, même l'architecte-archimage de prévente le plus expérimenté ne vous dira pas les spécifications plus précisément que vous formulez les exigences, et plus précisément, que «bien, quelque part SAM-VOSEM» sans projets pilotes.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/79/su/eq/79sueqtcnez6nz-kop4mp1i4qlq.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">À propos des instantanés</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HyperFlex peut effectuer ses instantanés natifs de machines virtuelles à l'aide de la technologie de redirection sur écriture. Et ici il faut s'arrêter séparément pour considérer différentes technologies de snapshots. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Initialement, il y avait des instantanés du type Copie sur écriture (CoW), et les instantanés natifs de VMware vSphere peuvent être pris comme exemple classique. Le principe de fonctionnement est le même avec vmdk au-dessus de VMFS ou NFS, qui avec des systèmes de fichiers natifs tels que VSAN. Après avoir créé un instantané CoW, les données d'origine (blocs ou fichiers vmdk) sont figées et lorsque vous essayez d'écrire dans des blocs figés, une copie est créée et les données sont écrites dans un nouveau bloc / fichier (fichier delta pour vmdk). Par conséquent, au fur et à mesure que l'arborescence de clichés se développe, le nombre d'accès au disque «parasites» qui n'ont aucune signification productive augmente, et</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">les baisses / retards de performances augmentent</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, des instantanés de redirection sur écriture (RoW) ont été inventés, dans lesquels au lieu de créer des copies de blocs avec des données, une copie des métadonnées est créée, et l'enregistrement se poursuit simplement sans retards et lectures et vérifications supplémentaires. Avec une implémentation correcte des instantanés RoW, l'effet sur les performances du système de disques est presque nul. Le deuxième effet du travail avec des métadonnées au lieu des données en direct elles-mêmes n'est pas seulement la création instantanée de clichés, mais aussi les clones de VM, qui immédiatement après la création ne prennent pas du tout d'espace (nous ne considérons pas la surcharge système pour les fichiers de service VM).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et le troisième point clé qui distingue radicalement RoW des instantanés CoW pour les systèmes productifs est la suppression instantanée des instantanés. Il semblerait que ce soit le cas? Cependant, vous devez vous rappeler comment fonctionnent les instantanés CoW et que la suppression d'un instantané n'est pas vraiment une suppression delta, mais sa validation. Et ici, le moment de son commit dépend extrêmement de la taille du delta accumulé et des performances du système de disque. Les instantanés RoW sont validés instantanément simplement parce que peu importe le nombre de téraoctets de différence accumulés, la suppression (validation) des instantanés RoW est une mise à jour de la table de métadonnées.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et ici, une application intéressante d'instantanés RoW apparaît - déposez le RPO à des valeurs de dizaines de minutes. Faire des sauvegardes toutes les 30 minutes est presque impossible dans le cas général, et dans la plupart des cas, elles sont effectuées une fois par jour, ce qui donne un RPO de 24 heures. Mais en même temps, nous pouvons simplement créer des instantanés RoW selon un calendrier, ce qui porte le RPO à 15-30 minutes et les stocker pendant un jour ou deux. Aucune pénalité pour les performances, dépense uniquement la capacité. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais il y a quelques nuances.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour le bon fonctionnement des instantanés natifs et l'intégration avec VMware, HyperFlex nécessite un instantané officiel appelé Sentinel. Le snapshot Sentinel est créé automatiquement lorsque vous créez pour la première fois un snapshot pour une VM donnée via HXConnect, et vous ne devez pas le supprimer, vous ne devez pas y "revenir", il vous suffit de supporter le fait que dans l'interface de la liste des snapshots, il s'agit du premier snapshot de service de Sentinel. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/6v/xv/fk/6vxvfkz6yuhzkylorocntklep1w.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les instantanés HyperFlex peuvent s'exécuter en mode cohérent avec les pannes ou en mode cohérent avec les applications. Le second type implique le "vidage des tampons" à l'intérieur de la machine virtuelle, il nécessite VMTools et il démarre si la case "Quiesce" est cochée dans le menu d'instantanés HXConnect.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En plus des instantanés HyperFlex, personne n'interdit l'utilisation d'instantanés VMware «natifs». </font><font style="vertical-align: inherit;">Il est utile pour une machine virtuelle spécifique de déterminer les instantanés que vous utiliserez et, à l'avenir, de vous concentrer sur cette technologie, en ne «dérangeant» pas différents instantanés pour une machine virtuelle. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le cadre du test, j'ai essayé de créer des instantanés et de vérifier leur FIO. </font><font style="vertical-align: inherit;">Et pourtant, oui, je peux confirmer que les instantanés sont vraiment RoW, ils n'affectent pas les performances. </font><font style="vertical-align: inherit;">Les instantanés sont vraiment créés rapidement (quelques secondes en fonction du profil de charge et de la taille de l'ensemble de données), je peux donner la recommandation suivante en fonction des résultats: si votre charge a beaucoup d'opérations d'écriture aléatoires, vous devriez commencer à créer un instantané à partir de l'interface HXConnect, avec la coche «Quiesce» et avec une préliminaire la présence d'un instantané Sentinel.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les tests</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Plateforme de test</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La plateforme suivante est tombée dans des pattes tenaces:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 x C220 M4 (2630v4 10c x 2,20 GHz, 256, 800 + 6 * 960)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vSphere 6.7</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HX Data Platform 4.0.2</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Test de patch clair</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quel genre de test sans CrystalDisk? C'est vrai, cela ne peut pas être, les gars normaux démarrent toujours un disque cristallisé! Eh bien, si c'est nécessaire, alors c'est nécessaire. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hp/tl/x5/hptlx5eb-ojjdbwet5l87h6wjx4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour le disque Crystal, une machine virtuelle spécialement créée avec 2 vCPU 4 Go et Windows 7 à bord a été créée. Oh, et j'en ai eu marre d'y mettre des patchs, je vais vous le dire! Le test a été réalisé dans les meilleures traditions des meilleures maisons de Londres et Paris - à savoir, un seul disque virtuel suivant-suivant-finition a été ajouté sans aucune réflexion et le test a été lancé. Oui, et en passant, bien sûr, CrystalDiskMark lui-même n'est pas impliqué dans les tests, il s'agit simplement d'une interface, mais charge directement le système de disques avec le package DiskSpd bien connu inclus dans le kit. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ns/wt/i9/nswti9u6hmne-srf37nniqjevzq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ce qui m'a frappé littéralement - pour une raison quelconque, tous ont sauté le choix des unités dans le coin supérieur droit. Et alle op!</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kg/3y/th/kg3ythef08dpqq3zcsrr20wmq8w.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Écoutez, honnêtement, je ne m'attendais pas à 75 000 IOPS et plus de 1 gigaoctet par seconde de la micromachine en mode suivant-suivant-finition! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour faire simple, toutes les entreprises en Russie n'ont pas des charges qui dépassent ces indicateurs au total. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D'autres tests ont été effectués à l'aide de VMware HCI Bench et Nutanix XRay, comme «idéologiquement hostiles» à HyperFlex, et en conséquence, il était prévu que nous ne ferions pas de prisonniers. Les chiffres se sont révélés extrêmement proches, de sorte que les résultats du package XRay ont été pris comme base simplement parce qu'il dispose d'un système de rapport plus pratique et de modèles de charge prêts à l'emploi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour ceux qui ne font confiance à personne et veulent un contrôle total sur le processus, je vous rappelle mon article sur la construction de votre propre système pour générer la charge sur une plate-forme hyperconvergée - "</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Test de performance des systèmes et SDS giperkonvergentnyh de leurs propres mains</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Achtung! </font><font style="vertical-align: inherit;">Uwaga! </font><font style="vertical-align: inherit;">Pozor!</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tous les autres résultats et leurs interprétations sont l'opinion de l'auteur de l'article, et sont donnés par eux-mêmes dans le cadre de l'étude du système. </font><font style="vertical-align: inherit;">La plupart des tests sont des synthétiques nus et ne s'appliquent qu'à la compréhension des indicateurs de limite dans des cas extrêmes et dégénérés, ce que vous n'atteindrez jamais dans la vie réelle.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Microbenchmark FourCorners</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le microtest à 4 côtés est conçu pour évaluer le système «rapidement» pour les performances théoriques ultimes et les performances de pointe des contrôleurs. L'application pratique de ce test est de vérifier le système immédiatement après le lancement pour toute erreur de configuration et d'environnement, en particulier les erreurs de réseau. Ceux. si vous utilisez régulièrement de tels systèmes, vous savez alors à quels chiffres vous devez vous attendre «si tout va bien». </font></font><br>
<br>
<img src="https://habrastorage.org/webt/im/wl/70/imwl70bqxpwhlum10vhlhm1kbk0.png"><br>
<br>
<img src="https://habrastorage.org/webt/61/xf/ss/61xfss1sc92seaez55-aq_shz2i.png"><br>
<br>
<img src="https://habrastorage.org/webt/4x/38/l7/4x38l7clygg4y5lavoks-lecrfs.png"><br>
<br>
<img src="https://habrastorage.org/webt/si/he/kg/sihekgnrrioansimgwwetryowme.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nombre final: 280k / 174k IOPS, 3,77 / 1,72 Go / s (lecture / écriture) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comment nos contrôleurs se sont-ils comportés?</font></font><br>
<br>
<img src="https://habrastorage.org/webt/-_/co/qv/-_coqvha1rwj6l78ng3fl_kowoi.png"><br>
<br>
<img src="https://habrastorage.org/webt/xu/hd/8s/xuhd8szlg-hrwoyeasjl-nqybbm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D'où on peut noter que la consommation totale de ressources pour 4 contrôleurs et 4 charges VM était de 49 cœurs de 2,2. Selon les statistiques VMware, l'utilisation CPU des contrôleurs était jusqu'à 80%, soit en fait, les performances étaient limitées par les performances des contrôleurs, et en particulier des processeurs. La vitesse des opérations séquentielles reposait spécifiquement sur la vitesse du réseau 10G. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essayons encore. Les performances de pointe sur un petit cluster à 4 nœuds avec les processeurs de 2,2 GHz les moins rapides sont de près de 300 000 IOPS à 4U de hauteur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La conversation «ici, nous avons 10, 20 ou même 40% plus / moins» est pratiquement dénuée de sens en raison de l'ordre des nombres. C'est comme commencer à mesurer "et je peux avoir une voiture 240, j'en ai 280" malgré le fait que la limite soit de 80.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
280k / 4 nœuds donne une performance de pointe de 70k / nœud, ce qui dépasse par exemple les chiffres de la calculatrice VMware VSAN, qui suppose que le nœud AF n'émet pas plus de 46k par groupe de disques. </font><font style="vertical-align: inherit;">Dans notre cas, ici, dans la terminologie VMware, il n'y a qu'un seul groupe de disques, qui s'exécute réellement à x1.8.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Effet de la taille du bloc de magasin de données</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors de la création d'un magasin de données HyperFlex, vous pouvez choisir la taille du bloc de données - 4k ou 8k. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qu'est-ce que cela affectera? </font><font style="vertical-align: inherit;">Exécutez le même test quadrangulaire. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/70/rc/vf/70rcvfpf8-l_zewvlxiawo6lgmm.png"><br>
<br>
<img src="https://habrastorage.org/webt/gd/s6/ys/gds6ysghq6zmspmh1aiprlngtni.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si l'image est presque identique à la lecture, le dossier au contraire importe. </font><font style="vertical-align: inherit;">Le test quadrangulaire utilise une charge de 8k. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nombre total: 280k / 280k, 172-158k / 200-180k (4k 8k). </font><font style="vertical-align: inherit;">Lorsque la taille du bloc correspond, + 15% des performances d'écriture sont obtenues. </font><font style="vertical-align: inherit;">Si vous prévoyez une quantité d'enregistrement importante avec un petit bloc (4k) dans la charge - créez une banque de données pour cette charge particulière avec un bloc 4k, sinon utilisez 8k.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OLTP Simulator</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une image beaucoup plus proche de la réalité est donnée par un autre test. </font><font style="vertical-align: inherit;">Dans ce cadre, deux générateurs sont lancés avec un profil proche d'un SGBD transactionnel et un niveau de charge de 6000 + 400 IOPS. </font><font style="vertical-align: inherit;">Ici, le retard est mesuré, qui devrait rester à un niveau bas stable. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/aw/tb/ty/awtbtyfcnnow6yydbgr28dpgiqc.png"><br>
<br>
<img src="https://habrastorage.org/webt/o9/kd/m1/o9kdm1zv2lksnqi1g7qk8o5gl7m.png"><br>
<br>
<img src="https://habrastorage.org/webt/cp/3n/oh/cp3noh9aqrp7y0kfrdgehpd19xe.png"><br>
<br>
<img src="https://habrastorage.org/webt/rn/qh/0j/rnqh0jmup291dks_4ir4eg1ssu8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le retard pour la charge VM était de 1,07 / 1,08 ms. </font><font style="vertical-align: inherit;">Dans l'ensemble un excellent résultat, mais ajoutons un peu de chaleur!</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Colocation de la base de données: haute intensité</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comment la base transactionnelle se comportera, en fonction des retards, si soudainement un voisin consécutif bruyant se forme. </font><font style="vertical-align: inherit;">Eh bien, très bruyant. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/0s/wg/1w/0swg1wykmap5tqivoahd3qymfbe.png"><br>
<br>
<img src="https://habrastorage.org/webt/kr/uy/xh/kruyxhmfiswvbc2tue7whwpwu60.png"><br>
<br>
<img src="https://habrastorage.org/webt/jw/3l/ib/jw3libpbrez473tlexzbilmepyy.png"><br>
<br>
<img src="https://habrastorage.org/webt/p1/4g/2j/p14g2jumznxoh8oyw2y1f3slyge.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainsi, la base OLTP sur le nœud 1 génère 4200 IOPS avec un retard de 0,85 ms. </font><font style="vertical-align: inherit;">Que se passe-t-il après qu'un système DSS commence soudainement à consommer des ressources dans des opérations séquentielles? </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deux générateurs sur les nœuds 2 et 3 chargent la plate-forme à 1,18 / 1,08 Go / s, respectivement, ces 2,26 Go / s au total. </font><font style="vertical-align: inherit;">Le retard sur OLTP augmente bien sûr et devient moins plat, mais la valeur moyenne reste de 1,85 ms, et la base reçoit ses 4200 IOPS sans aucun problème.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Impact de l'instantané</font></font></h3><br>
<img src="https://habrastorage.org/webt/n0/eo/w8/n0eow8pfcfna7kqwhrt0xblqq8g.png"><br>
<br>
<img src="https://habrastorage.org/webt/-a/0h/dl/-a0hdlvysga1zwnpwtyvb1zq1_c.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le système prend séquentiellement plusieurs instantanés une fois par heure sur une base OLTP. </font><font style="vertical-align: inherit;">Il n'y a rien de surprenant dans le calendrier, et de plus, c'est généralement un indicateur du fonctionnement des instantanés classiques VMware, car Nutanix XRay ne sait pas comment travailler avec des instantanés natifs, sauf le sien. </font><font style="vertical-align: inherit;">Vous n'avez pas besoin d'utiliser régulièrement des instantanés vSphere, car tous les yaourts ne sont pas également utiles. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les instantanés natifs HyperFlex fonctionnent beaucoup mieux, utilisez-les et vos cheveux deviendront doux et soyeux!</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ingestion de Big Data</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comment HyperFlex va-t-il digérer une grande quantité de données téléchargées séquentiellement? </font><font style="vertical-align: inherit;">Eh bien, disons 1 To. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/0f/ll/m7/0fllm7dze4walp1c2xff9msn-wg.png"><br>
<br>
<img src="https://habrastorage.org/webt/vx/go/ig/vxgoigfhqqpqguabodmsmklgmma.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le test a duré 27 minutes, y compris le clonage, le réglage et le démarrage des générateurs.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Évolutivité du débit</font></font></h3><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, chargez progressivement l'ensemble du cluster et regardez les nombres stables. Pour commencer par la lecture aléatoire, puis l'écriture. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/iu/kb/jy/iukbjyoms8btipiqv8ckw7-oikg.png"><br>
<br>
<img src="https://habrastorage.org/webt/zw/zj/gy/zwzjgyqeu9wn4ofiatztt5umy70.png"><br>
<br>
<img src="https://habrastorage.org/webt/zd/eu/r2/zdeur21emet_sylypa1p7btvg9c.png"><br>
<br>
<img src="https://habrastorage.org/webt/_u/z1/_p/_uz1_p1ht5ll4bihnaeuxj_znoa.png"><br>
<br>
<img src="https://habrastorage.org/webt/-c/ms/o4/-cmso46htkcgb6ixeetyowyninq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous voyons une image stable avec une diminution progressive des performances de la charge de la machine de 78k à 55-57k IOPS, avec des étagères lisses. Dans le même temps, il y a une augmentation constante des performances globales de 78 à 220k IOPS. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/to/cj/w0/tocjw0zga3ug1recbqb8oa133sq.png"><br>
<br>
<img src="https://habrastorage.org/webt/3z/nt/df/3zntdf3yigfx_acxr0ra6n5nwfa.png"><br>
<br>
<img src="https://habrastorage.org/webt/od/4x/jh/od4xjhnjcvxthkezbcrncc33c5a.png"><br>
<br>
<img src="https://habrastorage.org/webt/mu/zj/mz/muzjmzjtko49unkx1iwzzm_zzo0.png"><br>
<br>
<img src="https://habrastorage.org/webt/v4/wr/0j/v4wr0jbbzvpfz94majmfgisny1m.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'enregistrement est un peu moins lisse, mais toujours des étagères stables de 64k à 19-21k par voiture. Dans le même temps, la charge sur les contrôleurs est beaucoup plus faible. Si lors de la lecture le niveau de charge total du processeur est passé de 44 à 109, alors à l'enregistrement de 57 à 73 GHz.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ici, vous pouvez observer l'exemple le plus simple et le plus évident des caractéristiques des systèmes hyperconvergés - le seul consommateur n'est tout simplement pas en mesure d'utiliser complètement toutes les ressources du système, et lorsque la charge est ajoutée, il n'y a pas de baisse significative des performances. </font><font style="vertical-align: inherit;">La chute que nous assistons est déjà le résultat de charges synthétiques extrêmes conçues pour tout presser jusqu'à la dernière goutte, ce qui n'est presque jamais le cas dans un produit normal.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rompre OLTP</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À ce moment-là, il était devenu ennuyeux de voir à quel point HyperFlex était prévisible. </font><font style="vertical-align: inherit;">Besoin urgent de casser quelque chose! </font></font><br>
<br>
<img src="https://habrastorage.org/webt/nw/rq/da/nwrqdazu_dn_gpyg6cdu3z0paju.png"><br>
<br>
<img src="https://habrastorage.org/webt/wr/fw/ks/wrfwkshatwbjd5gr2rvvtevdf8s.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le point rouge marque le moment où la machine virtuelle du contrôleur s'arrête sur l'un des hôtes avec une charge. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Étant donné que par défaut, la reconstruction dans HyperFlex démarre immédiatement uniquement lorsque le disque est perdu et lorsque le nœud est perdu, le délai d'expiration est de 2 heures, le moment de la reconstruction forcée est marqué d'un point vert.</font></font><br>
<br>
<pre><code class="plaintext hljs">login as: admin<font></font>
 HyperFlex StorageController 4.0(2a)<font></font>
admin@192.168.***.***'s password:<font></font>
&lt;b&gt;admin@SpringpathController0VY9B6ERXT:~$&lt;/b&gt; stcli rebalance status<font></font>
rebalanceStatus:<font></font>
    percentComplete: 0<font></font>
    rebalanceState: cluster_rebalance_not_running<font></font>
rebalanceEnabled: True<font></font>
&lt;b&gt;admin@SpringpathController0VY9B6ERXT:~$&lt;/b&gt; stcli rebalance start -f<font></font>
msgstr: Successfully started rebalance<font></font>
params:<font></font>
msgid: Successfully started rebalance<font></font>
&lt;b&gt;admin@SpringpathController0VY9B6ERXT:~$&lt;/b&gt; stcli rebalance status<font></font>
rebalanceStatus:<font></font>
    percentComplete: 16<font></font>
    rebalanceState: cluster_rebalance_ongoing<font></font>
rebalanceEnabled: True<font></font>
&lt;b&gt;admin@SpringpathController0VY9B6ERXT:~$&lt;/b&gt;</code></pre><br>
<img src="https://habrastorage.org/webt/sh/ry/qo/shryqousd3rdr6w7pwmdemcjpzk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les opérations ont gelé pendant quelques secondes et se sont à nouveau poursuivies, remarquant presque la reconstruction. </font><font style="vertical-align: inherit;">Il est dans un état stable lorsqu'il est loin de la surcharge du cluster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pourquoi Cisco 2 heures n'est-il pas un problème, alors que les concurrents ont moins de numéros? </font><font style="vertical-align: inherit;">Cisco recommande fortement d'utiliser RF3 comme niveau de base de protection des données pour tout sauf les machines qui ne sont pas dommage. </font><font style="vertical-align: inherit;">Vous avez décidé d'installer des correctifs ou de faire quelque chose avec l'hôte, désactivez-le. </font><font style="vertical-align: inherit;">Et il y a une chance que juste à ce moment un autre hôte échoue - et alors dans le cas de RF2 tout deviendra un enjeu, et avec RF3 il y aura une copie active des données. </font><font style="vertical-align: inherit;">Et oui, en effet, il est tout à fait possible de survivre 2 heures dans un accident sur RF2 jusqu'à ce que la récupération en RF3 commence.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cassez-moi complètement!</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Briser - si briser. </font><font style="vertical-align: inherit;">Pleine charge. </font><font style="vertical-align: inherit;">Dans ce cas, j'ai créé un test avec un profil ressemblant plus ou moins à une charge réelle (70% lu, 20% aléatoire, 8k, 6d 128q). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/4k/6l/rr/4k6lrrwh29qbybibwy2_gvq9y-e.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Devinez où CVM a été désactivé et où la reconstruction a-t-elle commencé? </font></font><br>
<br>
<img src="https://habrastorage.org/webt/0h/ur/am/0huramdwazcpyvzycht-hn1bwks.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans la situation de la reconstruction, HyperFlex a plutôt bien fonctionné, sans provoquer une baisse catastrophique des performances ou une augmentation multiple des retards, même sous charge sous les tomates mêmes. </font><font style="vertical-align: inherit;">La seule chose que j'aimerais vraiment, c'est cher Cisco, faire tout de même le timeout à moins de 2 heures par défaut.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">résultats</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour conclure, je rappelle l'objectif du test: étudier le système Cisco HyperFlex aujourd'hui, sans regarder l'historique, étudier ses performances à l'aide de synthétiques et tirer des conclusions sur son applicabilité à un produit réel. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion 1</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , sur les performances. Les performances sont très bonnes et vous ne ferez aucun autre commentaire ici. Étant donné que j'avais un système de la génération précédente lors du test, je peux dire exactement une chose - sur HyperFlex All Flash, vous exécuterez en capacité, en processeur, en mémoire, mais pas en disques. Sauf peut-être 1% des applications surchargées, mais vous devez mener une conversation avec elles personnellement. Les instantanés natifs RoW fonctionnent. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion 2</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, selon disponibilité. Le système, après avoir détecté une panne, est assez bon (sans baisse des performances parfois); Il y a une légère plainte dans le délai d'attente par défaut de 2 heures avant de démarrer la récupération (si l'hôte est perdu), mais étant donné le RF3 hautement recommandé, c'est plus tatillon. La récupération après une défaillance du disque commence immédiatement. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion 3</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, en prix et en comparaison avec les concurrents. </font><font style="vertical-align: inherit;">Le prix du système peut varier plusieurs fois en fonction de la configuration d'un projet spécifique. </font><font style="vertical-align: inherit;">Une grande partie du coût du projet sera constituée de systèmes et de logiciels d'application sous licence, qui fonctionneront au-dessus de la plate-forme d'infrastructure. </font><font style="vertical-align: inherit;">Par conséquent, la seule façon de comparer avec les concurrents est de comparer des offres commerciales spécifiques qui répondent aux exigences techniques, spécifiquement pour votre entreprise pour un projet spécifique. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion finale</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : le système fonctionne, assez mature pour une utilisation dans le produit pour avril 2020, si les recommandations du vendeur sont lues et appliquées, plutôt que de fumer.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr497010/index.html">Investir en période de repli des marchés: 3 stratégies de comportement en bourse</a></li>
<li><a href="../fr497014/index.html">Qui êtes-vous, ingénieur QA ou testeur?</a></li>
<li><a href="../fr497016/index.html">13 avril Java Digest</a></li>
<li><a href="../fr497020/index.html">DocuSign, un service de signature numérique populaire, prend désormais en charge l'infrastructure GlobalSign</a></li>
<li><a href="../fr497022/index.html">Mise à jour de l'accès au réseau d'entreprise. Nouveaux commutateurs Gigabit ExtremeSwitching X435</a></li>
<li><a href="../fr497028/index.html">Bienvenue sur Robot Operating System MeetUp</a></li>
<li><a href="../fr497030/index.html">Expérience dans la mise en œuvre d'usines de réseau basées sur EVPN VXLAN et Cisco ACI et une petite comparaison</a></li>
<li><a href="../fr497032/index.html">Entreprise de services et crise: histoires de réussite. Comment pensez-vous que vous sortez des sentiers battus?</a></li>
<li><a href="../fr497034/index.html">Qu'est-ce que le nouveau SDK nRF Connect pour les pays nordiques? Évolution, révolution ou alternative?</a></li>
<li><a href="../fr497036/index.html">Quand arrêter le processus de reconnaissance de séquence vidéo?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
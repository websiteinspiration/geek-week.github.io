<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëêüèª üïπÔ∏è üë¶ C√≥mo hacer un modelado tem√°tico de un foro r√°pidamente o qu√© molesta a las personas con enfermedad cel√≠aca üèÖ üë©üèø ü§¥üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En este art√≠culo contar√© y mostrar√© un ejemplo de c√≥mo una persona con una m√≠nima experiencia en Data Science pudo recopilar datos del foro y hacer mo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>C√≥mo hacer un modelado tem√°tico de un foro r√°pidamente o qu√© molesta a las personas con enfermedad cel√≠aca</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/503398/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En este art√≠culo contar√© y mostrar√© un ejemplo de c√≥mo una persona con una m√≠nima experiencia en Data Science pudo recopilar datos del foro y hacer modelos tem√°ticos de publicaciones utilizando el modelo LDA, y revel√≥ temas dolorosos para personas con intolerancia cel√≠aca. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El a√±o pasado necesitaba mejorar urgentemente mi conocimiento en el campo del aprendizaje autom√°tico. Soy gerente de producto de Data Science, Machine Learning y AI, o de otra manera, Technical Product Manager AI / ML. Las habilidades comerciales y la capacidad de desarrollar productos, como suele ser el caso en proyectos destinados a usuarios que no est√°n en el campo t√©cnico, no son suficientes. Debe comprender los conceptos t√©cnicos b√°sicos de la industria de ML y, si es necesario, poder escribir un ejemplo usted mismo para demostrar el producto.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante aproximadamente 5 a√±os he estado desarrollando proyectos front-end, desarrollando aplicaciones web complejas en JS y React, pero nunca he tratado con el aprendizaje autom√°tico, las computadoras port√°tiles y los algoritmos. Por lo tanto, cuando vi las noticias de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otus de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que estaban abriendo un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">curso</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> experimental de cinco meses </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">sobre Machine Learning</font></a><font style="vertical-align: inherit;"> , sin dudarlo, decid√≠ someterme a una prueba de prueba y seguir el curso.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante cinco meses, cada semana hubo conferencias de dos horas y tareas para ellos. All√≠ aprend√≠ sobre los conceptos b√°sicos de ML: varios algoritmos de regresi√≥n, clasificaciones, conjuntos de modelos, aumento de gradiente e incluso tecnolog√≠as en la nube ligeramente afectadas. En principio, si escuchas atentamente cada conferencia, entonces hay suficientes ejemplos y explicaciones para la tarea. Pero a√∫n as√≠, a veces, como en cualquier otro proyecto de codificaci√≥n, tuve que recurrir a la documentaci√≥n. Dado mi empleo a tiempo completo, era bastante conveniente estudiar, ya que siempre pod√≠a revisar el registro de una conferencia en l√≠nea.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al final de la capacitaci√≥n de este curso, todos tuvieron que tomar el proyecto final. </font><font style="vertical-align: inherit;">La idea para el proyecto surgi√≥ de manera bastante espont√°nea, en ese momento comenc√© a entrenarme en emprendimiento en Stanford, donde ingres√© al equipo que trabajaba en el proyecto para personas con intolerancia cel√≠aca. </font><font style="vertical-align: inherit;">Durante la investigaci√≥n de mercado, me interes√≥ saber qu√© preocupaciones, de qu√© est√°n hablando, de qu√© se quejan las personas con esta caracter√≠stica. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A medida que avanzaba el estudio, encontr√© un foro en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">celiac.com</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">con una gran cantidad de material sobre la enfermedad cel√≠aca. </font><font style="vertical-align: inherit;">Era obvio que desplazarse manualmente y leer m√°s de 100 mil publicaciones no era pr√°ctico. </font><font style="vertical-align: inherit;">Entonces se me ocurri√≥ la idea de aplicar el conocimiento que recib√≠ en este curso: recopilar todas las preguntas y comentarios del foro sobre un tema determinado y hacer modelos tem√°ticos con las palabras m√°s comunes en cada uno de ellos.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Paso 1. Recolecci√≥n de datos del foro</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El foro consta de muchos temas de varios tama√±os. </font><font style="vertical-align: inherit;">En total, este foro tiene alrededor de 115,000 temas y alrededor de un mill√≥n de publicaciones, con comentarios sobre ellos. </font><font style="vertical-align: inherit;">Estaba interesado en el subtema espec√≠fico </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Hacer frente a la enfermedad cel√≠aca"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que literalmente significa </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">"Hacer frente a la enfermedad</font></a><font style="vertical-align: inherit;"> cel√≠aca", si en ruso significa m√°s "continuar viviendo con un diagn√≥stico de enfermedad cel√≠aca y de alguna manera hacer frente a las dificultades". </font><font style="vertical-align: inherit;">Este subtema contiene alrededor de 175,000 comentarios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La descarga de datos se produjo en dos etapas. </font><font style="vertical-align: inherit;">Para empezar, tuve que revisar todas las p√°ginas bajo el tema y recopilar todos los enlaces a todas las publicaciones, para que en el siguiente paso, ya pudiera recopilar un comentario.</font></font><br>
<br>
<pre><code class="python hljs">url_coping = <span class="hljs-string">'https://www.celiac.com/forums/forum/5-coping-with-celiac-disease/'</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como el foro result√≥ ser bastante antiguo, tuve mucha suerte y el sitio no tuvo ning√∫n problema de seguridad, por lo que para recopilar los datos, fue suficiente usar la combinaci√≥n </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Usuario-Agente</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">biblioteca fake_useragent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beautiful Soup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para trabajar con el marcado html y conocer el n√∫mero de p√°ginas:</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># Get total number of pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_count</span>(<span class="hljs-params">url</span>):</span>
    response = requests.get(url, headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
    soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
    last_page_section = soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsPagination_last'</span>})
    <span class="hljs-keyword">if</span> (last_page_section):<font></font>
        count_link = last_page_section.find(<span class="hljs-string">'a'</span>)
        <span class="hljs-keyword">return</span> int(count_link[<span class="hljs-string">'data-page'</span>])
    <span class="hljs-keyword">else</span>: 
        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><font></font>
<font></font>
coping_pages_count = get_pages_count(url_coping)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y luego descargue el DOM HTML de cada p√°gina para extraer datos de ellos de manera f√°cil y sencilla utilizando la biblioteca </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BeautifulSoup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Python </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># collect pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">retrieve_pages</span>(<span class="hljs-params">pages_count, url</span>):</span><font></font>
    pages = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(pages_count):<font></font>
        response = requests.get(<span class="hljs-string">'{}page/{}'</span>.format(url, page), headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
        soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
        pages.append(soup)<font></font>
    <span class="hljs-keyword">return</span> pages<font></font>
<font></font>
coping_pages = retrieve_pages(coping_pages_count, url_coping)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para descargar los datos, necesitaba determinar los campos necesarios para el an√°lisis: encontrar los valores de estos campos en el DOM y guardarlos en el diccionario. </font><font style="vertical-align: inherit;">Yo mismo proven√≠a del fondo de front-end, por lo que trabajar con el hogar y los objetos fue trivial para m√≠.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_post_info</span>(<span class="hljs-params">pages</span>):</span><font></font>
    posts = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> pages:<font></font>
        posts_list_soup = page.find(<span class="hljs-string">'ol'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataList'</span>}).findAll(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataItem'</span>})
        <span class="hljs-keyword">for</span> post_soup <span class="hljs-keyword">in</span> posts_list_soup:<font></font>
            post = {}<font></font>
            post[<span class="hljs-string">'id'</span>] = uuid.uuid4()
            <span class="hljs-comment"># collecting titles and urls</span>
            title_section = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_break ipsContained'</span>})
            <span class="hljs-keyword">if</span> (title_section):<font></font>
                title_section_a = title_section.find(<span class="hljs-string">'a'</span>)<font></font>
                post[<span class="hljs-string">'title'</span>] = title_section_a[<span class="hljs-string">'title'</span>]<font></font>
                post[<span class="hljs-string">'url'</span>] = title_section_a[<span class="hljs-string">'data-ipshover-target'</span>]
            <span class="hljs-comment"># collecting author &amp; last action</span>
            author_section = post_soup.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_meta'</span>})
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_a = post_soup.find(<span class="hljs-string">'a'</span>)<font></font>
                author_section_time = post_soup.find(<span class="hljs-string">'time'</span>)<font></font>
                post[<span class="hljs-string">'author'</span>] = author_section_a[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
                post[<span class="hljs-string">'last_action'</span>] = author_section_time[<span class="hljs-string">'datetime'</span>]
            <span class="hljs-comment"># collecting stats</span>
            stats_section = post_soup.find(<span class="hljs-string">'ul'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats'</span>})
            <span class="hljs-keyword">if</span> (stats_section):<font></font>
                stats_section_replies = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>})
                <span class="hljs-keyword">if</span> (stats_section_replies):<font></font>
                    post[<span class="hljs-string">'replies'</span>] = stats_section_replies.getText()<font></font>
                stats_section_views = post_soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_light'</span>})
                <span class="hljs-keyword">if</span> (stats_section_views):<font></font>
                    post[<span class="hljs-string">'views'</span>] = stats_section_views.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>}).getText()<font></font>
            posts.append(post)<font></font>
    <span class="hljs-keyword">return</span> posts
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En total, reun√≠ alrededor de 15,450 publicaciones en este tema.</font></font><br>
<br>
<pre><code class="python hljs">coping_posts_info = collect_post_info(coping_pages)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora podr√≠an transferirse al DataFrame para que permanecieran all√≠ maravillosamente, y al mismo tiempo los guard√≥ en un archivo csv para que no tuviera que esperar nuevamente cuando los datos se recopilaron del sitio si la computadora port√°til se rompi√≥ accidentalmente o redefin√≠ accidentalmente una variable donde. </font></font><br>
<br>
<pre><code class="python hljs">df_coping = pd.DataFrame(coping_posts_info, <font></font>
               columns =[<span class="hljs-string">'title'</span>, <span class="hljs-string">'url'</span>, <span class="hljs-string">'author'</span>, <span class="hljs-string">'last_action'</span>, <span class="hljs-string">'replies'</span>, <span class="hljs-string">'views'</span>]) <font></font>
<font></font>
<span class="hljs-comment"># format data</span>
df_coping[<span class="hljs-string">'replies'</span>] = df_coping[<span class="hljs-string">'replies'</span>].astype(int)<font></font>
df_coping[<span class="hljs-string">'views'</span>] = df_coping[<span class="hljs-string">'views'</span>].apply(<span class="hljs-keyword">lambda</span> x: int(x.replace(<span class="hljs-string">','</span>,<span class="hljs-string">''</span>)))<font></font>
df_coping.to_csv(<span class="hljs-string">'celiac_forum_coping.csv'</span>, sep=<span class="hljs-string">','</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de recopilar una colecci√≥n de publicaciones, proced√≠ a recopilar los comentarios ellos mismos.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_postpage_details</span>(<span class="hljs-params">pages, df</span>):</span><font></font>
    comments = []<font></font>
    <span class="hljs-keyword">for</span> i, page <span class="hljs-keyword">in</span> enumerate(pages):<font></font>
        articles = page.findAll(<span class="hljs-string">'article'</span>)
        <span class="hljs-keyword">for</span> k, article <span class="hljs-keyword">in</span> enumerate(articles):<font></font>
            comment = {<font></font>
                <span class="hljs-string">'url'</span>: df[<span class="hljs-string">'url'</span>][i]<font></font>
            }<font></font>
            <span class="hljs-keyword">if</span>(k == <span class="hljs-number">0</span>):<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">1</span>
            <span class="hljs-keyword">else</span>:<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">0</span>
            <span class="hljs-comment"># collecting comments</span>
            comment_section = article.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsComment_content'</span>})
            <span class="hljs-keyword">if</span> (comment_section):<font></font>
                comment_section_p = comment_section.find(<span class="hljs-string">'p'</span>)
                <span class="hljs-keyword">if</span>(comment_section_p):<font></font>
                    comment[<span class="hljs-string">'comment'</span>] = comment_section_p.getText()<font></font>
            comment[<span class="hljs-string">'date'</span>] = comment_section.find(<span class="hljs-string">'time'</span>)[<span class="hljs-string">'datetime'</span>]<font></font>
            author_section = article.find(<span class="hljs-string">'strong'</span>)
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_url = author_section.find(<span class="hljs-string">'a'</span>)
                <span class="hljs-keyword">if</span> (author_section_url):<font></font>
                    comment[<span class="hljs-string">'author'</span>] = author_section_url[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
            comments.append(comment)<font></font>
    <span class="hljs-keyword">return</span> comments<font></font>
<font></font>
coping_data = collect_postpage_details(coping_comments_pages, df_coping)<font></font>
df_coping_comments.to_csv(<span class="hljs-string">'celiac_forum_coping_comments_1.csv'</span>, sep=<span class="hljs-string">','</span>)<font></font>
<font></font>
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PASO 2 An√°lisis de datos y modelado tem√°tico</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el paso anterior, recopilamos datos del foro y recibimos los datos finales en forma de 153777 l√≠neas de preguntas y comentarios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero solo los datos recopilados no son interesantes, por lo que lo primero que quer√≠a hacer era un an√°lisis muy simple: derivaba estad√≠sticas de los 30 temas m√°s vistos y 30 temas m√°s comentados. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9o/ai/dj/9oaidjzovi7va3alxg7vdwkts84.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las publicaciones m√°s vistas no coincidieron con las m√°s comentadas. Los t√≠tulos de las publicaciones comentadas, incluso a primera vista, son notables. Sus nombres son m√°s emotivos: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Odio, odio, odio"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> o " </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comentarios arrogantes"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Guau, estoy en problemas"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Y los m√°s vistos tienen un formato de pregunta: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"¬øPuedo comer soya?", "¬øPor qu√© no puedo absorber el agua adecuadamente?"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">otro. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hicimos un an√°lisis de texto simple. </font><font style="vertical-align: inherit;">Para ir directamente a un an√°lisis m√°s complejo, debe preparar los datos antes de enviarlos a la entrada del modelo LDA para un desglose por tema. </font><font style="vertical-align: inherit;">Para hacer esto, elimine los comentarios que contengan menos de 30 palabras, para filtrar el spam y los comentarios cortos sin sentido. </font><font style="vertical-align: inherit;">Los llevamos a min√∫sculas.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># Let's get rid of text &lt; 30 words</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_text_words</span>(<span class="hljs-params">text, min_words = <span class="hljs-number">30</span></span>):</span><font></font>
    text = str(text)<font></font>
    <span class="hljs-keyword">return</span> len(text.split()) &gt; <span class="hljs-number">30</span>
filtered_comments = filtered_comments[filtered_comments[<span class="hljs-string">'comment'</span>].apply(filter_text_words)]<font></font>
comments_only = filtered_comments[<span class="hljs-string">'comment'</span>]<font></font>
comments_only= comments_only.apply(<span class="hljs-keyword">lambda</span> x: x.lower())<font></font>
comments_only.head()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eliminar palabras innecesarias para borrar nuestra selecci√≥n de texto</font></font><br>
<br>
<pre><code class="python hljs">stop_words = stopwords.words(<span class="hljs-string">'english'</span>)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">remove_stop_words</span>(<span class="hljs-params">tokens</span>):</span><font></font>
    new_tokens = []<font></font>
    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tokens:<font></font>
        token = []<font></font>
        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> t:
            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words:<font></font>
                token.append(word)<font></font>
        new_tokens.append(token)<font></font>
    <span class="hljs-keyword">return</span> new_tokens<font></font>
<font></font>
tokens = remove_stop_words(data_words)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tambi√©n agregamos bigrams y formamos una bolsa de palabras para resaltar frases estables, por ejemplo, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">como gluten_free, support_group</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y otras frases que, cuando se agrupan, tienen un cierto significado.</font></font><br>
<br>
<pre><code class="python hljs">
bigram = gensim.models.Phrases(tokens, min_count=<span class="hljs-number">5</span>, threshold=<span class="hljs-number">100</span>)<font></font>
bigram_mod = gensim.models.phrases.Phraser(bigram)<font></font>
bigram_mod.save(<span class="hljs-string">'bigram_mod.pkl'</span>)<font></font>
bag_of_words = [bigram_mod[w] <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens]
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'bigrams.pkl'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:<font></font>
    pickle.dump(bag_of_words, f)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora finalmente estamos listos para entrenar directamente el modelo LDA.</font></font><br>
<br>
<pre><code class="python hljs"><font></font>
id2word = corpora.Dictionary(bag_of_words)<font></font>
id2word.save(<span class="hljs-string">'id2word.pkl'</span>)<font></font>
id2word.filter_extremes(no_below=<span class="hljs-number">3</span>, no_above=<span class="hljs-number">0.4</span>, keep_n=<span class="hljs-number">3</span>*<span class="hljs-number">10</span>**<span class="hljs-number">6</span>)<font></font>
corpus = [id2word.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> bag_of_words]<font></font>
<font></font>
lda_model = gensim.models.ldamodel.LdaModel(<font></font>
    corpus, <font></font>
    id2word=id2word, <font></font>
    eval_every=<span class="hljs-number">20</span>,<font></font>
    random_state=<span class="hljs-number">42</span>,<font></font>
    num_topics=<span class="hljs-number">30</span>, <font></font>
    passes=<span class="hljs-number">5</span><font></font>
    )<font></font>
lda_model.save(<span class="hljs-string">'lda_default_2.pkl'</span>)<font></font>
topics = lda_model.show_topics(num_topics=<span class="hljs-number">30</span>, num_words=<span class="hljs-number">100</span>, formatted=<span class="hljs-literal">False</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al final de la capacitaci√≥n, finalmente obtenemos el resultado de los temas formados. Que adjunto al final de esta publicaci√≥n.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(lda_model.num_topics):<font></font>
    plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">10</span>))<font></font>
    plt.imshow(WordCloud(background_color=<span class="hljs-string">"white"</span>, max_words=<span class="hljs-number">100</span>, width=<span class="hljs-number">900</span>, height=<span class="hljs-number">900</span>, collocations=<span class="hljs-literal">False</span>)<font></font>
               .fit_words(dict(topics[t][<span class="hljs-number">1</span>])))<font></font>
    plt.axis(<span class="hljs-string">"off"</span>)<font></font>
    plt.title(<span class="hljs-string">"Topic #"</span> + themes_headers[t])<font></font>
    plt.show()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como puede ser notable, los temas resultaron ser muy distintos en contenido entre s√≠. </font><font style="vertical-align: inherit;">Seg√∫n ellos, queda claro de qu√© est√°n hablando las personas con intolerancia cel√≠aca. </font><font style="vertical-align: inherit;">B√°sicamente, sobre alimentos, ir a restaurantes, alimentos contaminados con gluten, dolores terribles, tratamiento, ir a m√©dicos, familiares, malentendidos y otras cosas que las personas tienen que enfrentar todos los d√≠as en relaci√≥n con su problema. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eso es todo. </font><font style="vertical-align: inherit;">Gracias a todos por su atenci√≥n. </font><font style="vertical-align: inherit;">Espero que encuentres este material interesante y √∫til. </font><font style="vertical-align: inherit;">Y, sin embargo, como no soy un desarrollador de DS, no juzgue estrictamente. </font><font style="vertical-align: inherit;">Si hay algo que agregar o mejorar, siempre agradezco las cr√≠ticas constructivas, escriba. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para ver 30 temas</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Precauci√≥n, muchas im√°genes</font></font></b>
                        <div class="spoiler_text"><img src="https://habrastorage.org/webt/cn/dy/tb/cndytbwrtz9ujkkh6xicy0mjyds.png"><br>
<br>
<img src="https://habrastorage.org/webt/no/n2/iq/non2iqgux8nvb5hnitr8n7yra_w.png"><br>
<br>
<img src="https://habrastorage.org/webt/dx/dh/nl/dxdhnlddgexrb_noeq8psjb7nps.png"><br>
<br>
<img src="https://habrastorage.org/webt/x1/_f/q6/x1_fq6omll0iigewzz0ba8tjvys.png"><br>
<br>
<img src="https://habrastorage.org/webt/7v/qy/fh/7vqyfh-uwk_bhypzdgisxxabzjs.png"><br>
<br>
<img src="https://habrastorage.org/webt/v7/1z/fn/v71zfn2kb0xj7rpsthrplgznzzw.png"><br>
<br>
<img src="https://habrastorage.org/webt/ab/tt/t7/abttt7c8aqydfc28gxyq9ai7a4q.png"><br>
<br>
<img src="https://habrastorage.org/webt/oz/hc/m7/ozhcm72ldjjenp5onkjydxgpvly.png"><br>
<br>
<img src="https://habrastorage.org/webt/fe/ex/lw/feexlw8tcrcwni5wmy8k8rv8k3e.png"><br>
<br>
<img src="https://habrastorage.org/webt/w0/hu/5j/w0hu5jix2zrewo2l9jnbkddd3tk.png"><br>
<br>
<img src="https://habrastorage.org/webt/zf/ye/kw/zfyekw6s6qfxuqwy-qxhv_dehrq.png"><br>
<br>
<img src="https://habrastorage.org/webt/l0/9s/vw/l09svwry19fhz1y-1-pooeo_vew.png"><br>
<br>
<img src="https://habrastorage.org/webt/pm/mt/bk/pmmtbkkybu50vhgttl-0kz4tcf4.png"><br>
<br>
<img src="https://habrastorage.org/webt/1h/hu/vr/1hhuvrmmfjxwfzh3fbhf9dbut38.png"><br>
<br>
<img src="https://habrastorage.org/webt/bw/is/ad/bwisadbn9a000lt6xp927szic2u.png"><br>
<br>
<img src="https://habrastorage.org/webt/iu/bf/4q/iubf4qt_juq9uip17rmngbr7wxe.png"><br>
<br>
<img src="https://habrastorage.org/webt/jk/of/sa/jkofsalh2hev8zx6jjlom0pnnxy.png"><br>
<br>
<img src="https://habrastorage.org/webt/js/bs/ls/jsbslsv_4ly4rwe7wir6xvcs6t4.png"><br>
<br>
<img src="https://habrastorage.org/webt/_e/ly/wr/_elywrkbtgk-4fvlnuzfr6zqq4o.png"><br>
<br>
<img src="https://habrastorage.org/webt/4j/x8/pa/4jx8paomlrca7t0syfunmtmlxk4.png"><br>
<br>
<img src="https://habrastorage.org/webt/y2/he/s1/y2hes1fvuepisygriea98m_yavw.png"><br>
<br>
<img src="https://habrastorage.org/webt/9k/xs/sr/9kxssr9rxlyeobjw12fwju0-xkq.png"><br>
<br>
<img src="https://habrastorage.org/webt/i-/sl/qd/i-slqdug6x9dkwybnfnxmdolho8.png"><br>
<br>
<img src="https://habrastorage.org/webt/nq/pk/x5/nqpkx5q6j8e_6mkpfak0ytkkvfc.png"><br>
<br>
<img src="https://habrastorage.org/webt/jv/3b/pa/jv3bpafludpki_2a-4pgajhreh0.png"><br>
<br>
<img src="https://habrastorage.org/webt/sw/-e/pn/sw-epnxhrwa4t7i6uksmggczs-8.png"><br>
<br>
<img src="https://habrastorage.org/webt/-y/qj/0t/-yqj0t-jkax-s09bivkgx8a3mqa.png"><br>
<br>
<img src="https://habrastorage.org/webt/ta/rp/4w/tarp4wr8bcui0zszwuzl7l9h8zo.png"><br>
<br>
<img src="https://habrastorage.org/webt/eo/xl/m2/eoxlm2i2z9weffxhgm-zzgszd3q.png"><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">    ¬´Machine Learning¬ª  OTUS</a>.<br>
<br>
<hr><br>
</div>
                    </div></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es503382/index.html">Rastrille caminando en un campo limpio o c√≥mo recopilar direcciones MAC de dispositivos Wi-Fi cercanos</a></li>
<li><a href="../es503386/index.html">Entrenador √°gil persona sana</a></li>
<li><a href="../es503388/index.html">Digitalizaci√≥n del p√°nico: DIT de Mosc√∫ contra moscovitas - una mesa redonda el 23 de mayo</a></li>
<li><a href="../es503390/index.html">¬øPor qu√© Intel apuesta al desarrollo de chips para el genio de Jim Keller?</a></li>
<li><a href="../es503394/index.html">Experiencia de inversi√≥n en acciones</a></li>
<li><a href="../es503402/index.html">C√≥mo recordar a todos en persona, o una b√∫squeda efectiva de rostros en una gran base de datos</a></li>
<li><a href="../es503404/index.html">Sistemas digitales sem√°nticos</a></li>
<li><a href="../es503406/index.html">Sem√°ntica y actividad</a></li>
<li><a href="../es503408/index.html">Blazor Client Side Online Store: Parte 7: actualizado a la versi√≥n 3.2.0 y pantalla de imagen agregada</a></li>
<li><a href="../es503410/index.html">Pol√≠gonos Otro Mundo: Sega Genesis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛷️ 🚿 😀 ML、VR、ロボット（および少しのクラウド） 🧒🏽 🕦 👃🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="みなさん、こんにちは！
 
 ロボット工学、機械学習（そしてこれを合わせてロボット学習です）、バーチャルリアリティ、そして少しのクラウドテクノロジーが交差する非常に退屈なプロジェクトについてお話したいと思います。そして、これらすべては実際に理にかなっています。結局のところ、ロボットに移動して何をすべ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ML、VR、ロボット（および少しのクラウド）</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/486680/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">みなさん、こんにちは！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ロボット工学、機械学習（そしてこれを合わせてロボット学習です）、バーチャルリアリティ、そして少しのクラウドテクノロジーが交差する非常に退屈なプロジェクトについてお話したいと思います。</font><font style="vertical-align: inherit;">そして、これらすべては実際に理にかなっています。</font><font style="vertical-align: inherit;">結局のところ、ロボットに移動して何をすべきかを示し、保存されたデータを使用してMLサーバーでウェイトをトレーニングすることは本当に便利です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
カットの下で、それが現在どのように機能するか、そして開発されなければならなかったそれぞれの側面についていくつかの詳細を伝えます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/t0/kx/wi/t0kxwiicqakswvomnrwz-iycc2o.jpeg"><br>
<a name="habracut"></a><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">何のために</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、少し明らかにする価値があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ディープラーニングで武装したロボットが、どこからでも仕事から人々を追い出そうとしているようです。</font><font style="vertical-align: inherit;">実際、すべてがそれほどスムーズではありません。</font><font style="vertical-align: inherit;">アクションが厳密に繰り返される場合、プロセスはすでに非常によく自動化されています。</font><font style="vertical-align: inherit;">「スマートロボット」、つまりコンピュータビジョンとアルゴリズムですでに十分なアプリケーションについて話しているとしましょう。</font><font style="vertical-align: inherit;">しかし、非常に複雑な話もたくさんあります。</font><font style="vertical-align: inherit;">ロボットは、対処しなければならないさまざまなオブジェクト、および環境の多様性にほとんど対応できません。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">キーポイント</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実装の点で、まだどこにも見られない3つの重要な点があります。 </font></font><br>
<br>
<ul>
<li>       (data-driven learning). ..   ,    ,     ,    . ,     .</li>
<li>   ()    </li>
<li>  -  (Human-machine collaboration) </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もう1つは重要です。なぜなら、今のところ、学習へのアプローチ、アルゴリズム、それらの背後、およびコンピューティングツールの変化を観察するからです。</font><font style="vertical-align: inherit;">知覚および制御アルゴリズムはより柔軟になります。</font><font style="vertical-align: inherit;">ロボットのアップグレードには費用がかかります。</font><font style="vertical-align: inherit;">また、一度に複数のロボットにサービスを提供する場合は、電卓をより効率的に使用できます。</font><font style="vertical-align: inherit;">この概念は「クラウドロボティクス」と呼ばれます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
後者の場合、すべてが簡単です。AIは、ビジネスで必要とされるすべての状況で100％の信頼性と精度を提供するのに十分に開発されていません。</font><font style="vertical-align: inherit;">したがって、時々ロボットの病棟を助けることができる監督者のオペレーターは、怪我をしません。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スキーム</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、説明されているすべての機能を提供するソフトウェア/ネットワークプラットフォームについて：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fd/6y/fi/fd6yfi2svby-3l7hkn9lxxt3neo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
コンポーネント：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ロボットは3Dビデオストリームをサーバーに送信し、それに応じて制御を受け取ります。 </font></font></li>
<li>    :  - ,      (, , , )</li>
<li>  ML  ( ),        ,   ,  .      —  3D   ,     . </li>
<li> -  ,  3D       ,   UI   .   — . </li>
</ol><br>
<h4> </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ロボットの機能には、自動モードと手動モードの2つのモードがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
手動モードでは、MLサービスがまだトレーニングされていない場合、ロボットは機能します。</font><font style="vertical-align: inherit;">次に、オペレーターの要求（ロボットを見ているときに奇妙な動作を見た）、またはMLサービス自体が異常を検出したときに、ロボットは自動から手動に変わります。</font><font style="vertical-align: inherit;">異常の検出については後で説明します。これは非常に重要な部分であり、提案されたアプローチを適用することは不可能です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
制御の進化は次のとおりです。</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ロボットのタスクは、人間が読める用語で構成され、パフォーマンスインジケーターが説明されます。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">オペレーターはVRでロボットに接続し、しばらくの間既存のワークフロー内でタスクを実行します</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MLパーツは、受信したデータでトレーニングされます</font></font><br>
</li>
<li>      ,     ML             <br>
</li>
<li>              <br>
</li>
</ol><br>
<h4>       3D</h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多くの場合、ロボットはROS（ロボットオペレーティングシステム）環境を使用します。これは、実際には「ノード」（ノード）を管理するためのフレームワークであり、それぞれがロボットの機能の一部を提供します。一般に、これはロボットをプログラミングする比較的便利な方法であり、本質的にWebアプリケーションのマイクロサービスアーキテクチャに似ています。 ROSの主な利点は業界標準であり、ロボットを作成するために必要なモジュールはすでに多数あります。産業用ロボットアームにもROSインターフェイスモジュールを搭載できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最も簡単なことは、サーバーパーツとROSの間にブリッジモデルを作成することです。たとえば、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">そのような</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。今回のプロジェクトでは、ROS「ノード」のより開発されたバージョンを使用します。これは、特定のロボットがリレーサーバーに接続できるレジスタのマイクロサービスにログインしてポーリングします。ソースコードは、ROSモジュールのインストール手順の例としてのみ提供されています。最初は、このフレームワーク（ROS）をマスターすると、すべてが非常に不親切に見えますが、ドキュメントはかなり良く、数週間後、開発者はその機能を非常に自信を持って使用し始めます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
興味深いことに-ロボットで直接生成する必要がある3Dデータストリームの圧縮の問題。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
デプスマップの圧縮はそれほど簡単ではありません。</font><font style="vertical-align: inherit;">RGBストリームが少し圧縮されていても、境界のピクセルの真から、またはオブジェクトの移動が許可されている場合の、非常に深刻な輝度の局所的な歪み。</font><font style="vertical-align: inherit;">目はほとんどこれに気づきませんが、3Dをレンダリングするときに同じ歪みが深度マップで許可されるとすぐに、すべてが非常に悪くなります：（</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">記事</font></a></font><br>
<br>
<img src="https://habrastorage.org/webt/kv/1l/6-/kv1l6-qgxaqxhsf1a-zl67hymtk.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
から</font><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">
エッジでのこれらの欠陥は3Dシーンを大きく損なうため、</font><font style="vertical-align: inherit;">空気中にゴミがたくさんあります。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
フレームごとの圧縮を使用し始めました-RGBのJPEGと小さなハックのデプスマップのPNG。</font><font style="vertical-align: inherit;">このメソッドは、25 Mbpsで640x480の3Dスキャナー解像度の30FPSストリームを圧縮します。</font><font style="vertical-align: inherit;">トラフィックがアプリケーションにとって重要な場合は、より良い圧縮も提供できます。</font><font style="vertical-align: inherit;">このストリームの圧縮にも使用できる市販の3Dストリームコーデックがあります。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">バーチャルリアリティコントロール</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
カメラとロボットのリファレンスフレームをキャリブレーションした後（および</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">キャリブレーションに関する記事</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を既に作成して</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">いる</font></a><font style="vertical-align: inherit;">）、ロボットアームを仮想現実で制御できます。</font><font style="vertical-align: inherit;">コントローラは、3D XYZの位置と方向の両方を設定します。</font><font style="vertical-align: inherit;">一部のロボルクでは、3つの座標で十分ですが、自由度が多いため、コントローラーによって指定されたツールの方向も送信する必要があります。</font><font style="vertical-align: inherit;">さらに、ポンプのオン/オフ、グリップ制御などのロボットコマンドを実行するための十分なコントローラーがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
当初、WebVRエンジンに基づく仮想現実Aフレーム用のJavaScriptフレームワークを使用することが決定されました。</font><font style="vertical-align: inherit;">そして、最初の結果（4座標アームの記事の最後にあるビデオデモ）はAフレームで得られました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際、WebVR（またはAフレーム）は、いくつかの理由で失敗したソリューションであることがわかりました。</font></font><br>
<br>
<ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">主にFireFox</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">との</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">互換性。</font></a><font style="vertical-align: inherit;">メモリ消費が16GBに達するまで、Aフレームフレームワークがテクスチャリソースを解放しなかったのはFireFoxでした（残りのブラウザは対応しました）。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VRコントローラーおよびヘルメットとの限られた相互作用。</font><font style="vertical-align: inherit;">したがって、たとえば、オペレータの肘などの位置を設定できるマークを追加することはできませんでした。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アプリケーションはマルチスレッドまたはいくつかのプロセスを必要としました。</font><font style="vertical-align: inherit;">あるスレッド/プロセスでは、ビデオフレームを別のスレッドでアンパックする必要がありました-描画。</font><font style="vertical-align: inherit;">その結果、すべてがワーカーを介して整理されましたが、開梱時間が30 msに達し、VRでのレンダリングは90FPSの頻度で行う必要があります。</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべての欠点により、フレームのレンダリングに割り当てられた10ミリ秒の時間がなく、VRに非常に不快なけいれんがあったという事実が生じました。おそらく、すべてを克服することができましたが、各ブラウザのアイデンティティは少し迷惑でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、OpenVRライブラリのC＃、OpenTK、およびC＃ポートに向けて出発することを決定しました。まだ代替案があります-Unity。彼らはUnityは初心者向けであると書いています... </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自由を得るために見つけられ、知られる必要があった最も重要なこと：</font></font><br>
<br>
<pre><code class="cs hljs">VRTextureBounds_t bounds = <span class="hljs-keyword">new</span> VRTextureBounds_t() { uMin = <span class="hljs-number">0</span>, vMin = <span class="hljs-number">0</span>, uMax = <span class="hljs-number">1f</span>, vMax = <span class="hljs-number">1f</span> }; <font></font>
OpenVR.Compositor.Submit(EVREye.Eye_Left, <span class="hljs-keyword">ref</span> leftTexture, <span class="hljs-keyword">ref</span> bounds, EVRSubmitFlags.Submit_Default);<font></font>
OpenVR.Compositor.Submit(EVREye.Eye_Right, <span class="hljs-keyword">ref</span> rightTexture, <span class="hljs-keyword">ref</span> bounds, EVRSubmitFlags.Submit_Default);
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
（これは、ヘルメットの左目と右目に2つのテクスチャを送信するためのコードです）</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。</font><font style="vertical-align: inherit;">さまざまな目が見ているテクスチャでOpenGLを描画し、それをメガネに送信します。</font><font style="vertical-align: inherit;">左目を赤で、右目を青で塗りつぶすことがわかったとき、喜びは限界を知りませんでした。</font><font style="vertical-align: inherit;">ほんの数日後、webSocketを介して送られる深度とRGBマップが、JSでは30ミリ秒ではなく10ミリ秒でポリゴンモデルに転送されました。</font><font style="vertical-align: inherit;">次に、コントローラーの座標とボタンに問い合わせ、ボタンのイベントシステムを入力し、ユーザークリックを処理し、UIのステートマシンを入力すると、エスプレッソからグラスをつかむことができます。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/EuBNaGZctf8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
現在、Realsense D435の品質はやや落ち込んでいますが、少なくとも</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Microsoftからこのような興味深い3Dスキャナー</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を提供するとすぐに合格</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">します</font></a><font style="vertical-align: inherit;">。その</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">3Dスキャナー</font></a><font style="vertical-align: inherit;">のポイントクラウドははるかに正確です。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">サーバ側</font></font></h4><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">リレーサーバー</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
主な機能要素はサーバーリレー（中央のサーバー）です。サーバーリレーは、3D画像とセンサーの読み取り値およびロボットの状態を含むビデオストリームをロボットから受信し、消費者に配信します。入力データ-パックされたフレームとセンサー読み取り値がTCP / IP経由で送信されます。コンシューマーへの配布は、Webソケット（ブラウザーを含む複数のコンシューマーにストリーミングするための非常に便利なメカニズム）によって実行されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さらに、ステージングサーバーはデータストリームをS3クラウドストレージに保存し、後でトレーニングに使用できるようにします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各リレーサーバーは、現在の接続を監視するのに便利な現在の状態を確認できるhttp APIをサポートしています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
リレータスクは、コンピューティングの観点からもトラフィックの観点からも非常に困難です。したがって、ここでは、リレーサーバーがさまざまなクラウドサーバーに展開されるというロジックに従いました。つまり、誰がどこに接続しているのかを追跡する必要があります（特に、ロボットとオペレーターが異なる地域にいる場合）。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">登録</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
最も信頼性の高いサーバーは、接続できるサーバーごとにロボットごとに設定するのが難しくなります（冗長性に影響はありません）。 ML管理サービスはロボットに関連付けられており、ロボットが接続されているロボットと対応するロボットに接続されているロボットを判断するためにリレーサーバーをポーリングします。もちろん、これには十分な権限があります。オペレーターのアプリケーションも同様に機能します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最も楽しい！ロボットのトレーニングはサービスであるため、そのサービスは内部の私たちにしか見えません。そのため、そのフロントエンドは私たちにとって可能な限り便利になる可能性があります！それら。これはブラウザのコンソールであり（シンプル</font><font style="vertical-align: inherit;">で</font><font style="vertical-align: inherit;">美しい</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">terminalJS</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ライブラリ</font><font style="vertical-align: inherit;">が</font><font style="vertical-align: inherit;">あり</font><font style="vertical-align: inherit;">、TABオートコンプリートや通話履歴の再生などの追加機能が必要な場合に変更するのは非常に簡単です）、次のようになります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/wl/vl/yo/wlvlyojuytiepjvhzexlxr-ixcq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは、もちろん、コマンドラインである理由については別のトピックですとても快適。ちなみに、このようなフロントエンドの単体テストは特に便利です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
http APIに加えて、このサービスは、一時トークン、ログイン/ログアウトオペレーター、管理者とロボット、セッションサポート、リレーサーバーとロボット間のトラフィック暗号化のためのセッション暗号化キーでユーザーを登録するためのメカニズムを実装します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これはすべて、Flaskを使用してPythonで行われます-ML開発者（つまり私たち）にとって非常に近いスタックです。</font><font style="vertical-align: inherit;">はい、さらに、マイクロサービス用の既存のCI / CDインフラストラクチャはFlaskと友好的な関係にあります。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">遅延の問題</font></font></h4> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
マニピュレータをリアルタイムで制御する場合は、最小遅延が非常に役立ちます。</font><font style="vertical-align: inherit;">遅延が大きくなりすぎると（300ミリ秒を超える）、仮想ヘルメット内の画像に基づいてマニピュレーターを制御することが非常に困難になります。</font><font style="vertical-align: inherit;">私たちのソリューションでは、フレームごとの圧縮（つまり、バッファリングがない）とGStreamerなどの標準ツールを使用していないため、中間サーバーを考慮しても、遅延は約150〜200ミリ秒です。</font><font style="vertical-align: inherit;">それらのネットワーク上の伝送時間は約80msです。</font><font style="vertical-align: inherit;">残りの遅延は、Realsense D435カメラと限られたキャプチャ周波数が原因です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、これは「トラッキング」モードで発生するフルハイトの問題であり、現実のマニピュレータが仮想現実のオペレータのコントローラに常に追随している場合に発生します。</font><font style="vertical-align: inherit;">特定のポイントXYZに移動するモードでは、遅延はオペレーターに問題を引き起こしません。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MLパーツ</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
サービスには、管理とトレーニングの2つのタイプがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニングサービスは、S3ストレージに格納されたデータを収集し、モデルの重みの再トレーニングを開始します。</font><font style="vertical-align: inherit;">トレーニングの最後に、重みが管理サービスに送信されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
管理サービスは、オペレーターのアプリケーションからの入力データと出力データの点で違いはありません。</font><font style="vertical-align: inherit;">同様に、入力RGBD（RGB +深度）ストリーム、センサー測定値、ロボットのステータス、出力-制御コマンド。</font><font style="vertical-align: inherit;">この同一性により、「データ駆動型トレーニング」の概念のフレームワークでトレーニングすることが可能であるように見えます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ロボットの状態（およびセンサーの読み取り値）は、MLのキーストーリーです。コンテキストを定義します。たとえば、ロボットには、その動作に特徴的なステートマシンがあり、これによって必要な制御の種類が大きく決まります。これらの2つの値は、各フレームとともに送信されます：ロボットの動作モードと状態ベクトル。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">そしてトレーニングについて少し：</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
記事の最後のデモでは、3Dシーンでオブジェクト（子供用の立方体）を見つける作業がありました。これは、ピックアンドプレイスアプリケーションの基本的なタスクです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニングは、手動制御で取得した「前後」のフレームとターゲット指定のペアに基づいていました</font></font><br>
<br>
<img src="https://habrastorage.org/webt/n6/v2/s3/n6v2s3v59u7eumxhdh3gxucngxq.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。2つの深度マップが存在するため、フレーム内で移動したオブジェクトのマスクを簡単に計算できます</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6a/vm/k-/6avmk-ue2jfndgwzy08zdb0qtqe.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。さらに、xyzがカメラ平面に投影され、キャプチャしたオブジェクトの近傍を選択できます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ha/_s/o-/ha_so-yh4xmxwsp4dkoo42tct9i.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際にこの近所で動作します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初に、キューブセグメンテーションのたたみ込みネットワークとしてUnetをトレーニングすることでXYを取得します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、奥行きを決定し、目の前に画像が異常かどうかを理解する必要があります。</font><font style="vertical-align: inherit;">これは、RGBの自動エンコーダと詳細な条件付き自動エンコーダを使用して行われます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自動エンコーダーをトレーニングするためのモデルアーキテクチャ：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/xf/q4/ex/xfq4exzon5b63cucrz6aqi8kflm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果として、作業のロジック：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">しきい値を超える「ヒートマップ」（オブジェクトの角度u = x / zv = y / z座標を決定）で最大値を検索します</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">次に、自動エンコーダーは、深さのすべての仮説について（min_depthからmax_depthまでの所定のステップで）見つかった点の近傍を再構築し、再構築と入力の間の不一致が最小になる深さを選択します</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">角度座標u、v、および深さがあるため、座標x、y、zを取得できます</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
正しく定義された深さを持つキューブの深さのマップの自動エンコーダ再構築の例：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/av/1t/bu/av1tbu5dyvflda-_-lpbdw0t0qs.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
部分的に、深さ検索方法のアイデアは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">自動エンコーダのセットに関する記事に</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">基づいてい</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このアプローチは、さまざまな形状のオブジェクトに適しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、一般に、RGBD画像からXYZオブジェクトを見つけるには、さまざまなアプローチがあります。もちろん、実際には大量のデータで最も正確な方法を選択する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
異常を検出するタスクもありました。これには、利用可能なマスクから学習するためのセグメンテーション畳み込みネットワークが必要です。次に、このマスクに従って、深度マップとRGBでの自動エンコーダ再構成の精度を評価できます。この不一致により、異常の存在を判断できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この方法により、フレーム内の以前には見えなかったオブジェクトの出現を検出できますが、それでも一次検索アルゴリズムでは検出されます。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">デモンストレーション</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
作成されたソフトウェアプラットフォーム全体のチェックとデバッグは、スタンドで行われました。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3DカメラRealsense D435</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4コーディネートDobot Magician</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VRヘルメットHTC Vive</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandexクラウド上のサーバー（AWSクラウドと比較してレイテンシが短縮されます）</font></font></li>
</ul><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/G5rBhaxHL_E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ビデオでは、VRピックアンドプレースでタスクを実行して、3Dシーンで立方体を見つける方法を説明します。</font><font style="vertical-align: inherit;">キューブでのトレーニングには約50の例で十分でした。</font><font style="vertical-align: inherit;">次にオブジェクトが変更され、約30の例が表示されます。</font><font style="vertical-align: inherit;">再トレーニング後、ロボットは新しいオブジェクトを見つけることができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
プロセス全体で約15分かかりましたが、そのうちの約半分がモデルの重みのトレーニングです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この動画では、YuMiがVRを制御しています。</font><font style="vertical-align: inherit;">オブジェクトを操作する方法を学ぶには、ツールの向きと場所を評価する必要があります。</font><font style="vertical-align: inherit;">数学は同様の原則に基づいて構築されていますが、現在テストと開発の段階にあります。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Q0yTey1srBM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ビッグデータとディープラーニングだけではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちは学習へのアプローチを変え、人々が新しいことを学ぶ方法に向かって移動します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際のアプリケーションで開発する「内部」の数学的装置は、状況に応じた解釈と制御の問題を目的としています。</font><font style="vertical-align: inherit;">ここでのコンテキストとは、ロボットセンサーから取得できる自然な情報、または現在のプロセスに関する外部情報です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、私たちがマスターする技術プロセスが増えるほど、「雲の中の脳」の構造が発達し、その個々の部分が訓練されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このアプローチの長所：</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">可変オブジェクトの操作方法を学習する可能性 </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">変化する環境での学習（例：移動ロボット）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">構造化されていないタスク</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">市場投入までの時間が短い。</font><font style="vertical-align: inherit;">オペレーターを使用して手動モードでもターゲットを実行できます</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
制限：</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信頼性の高い優れたインターネットの必要性</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">高精度を実現するには、追加の方法が必要です。たとえば、マニピュレーター自体のカメラ</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
現在、さまざまなオブジェクトの標準的なピックアンドプレースタスクへのアプローチの適用に取り組んでいます。</font><font style="vertical-align: inherit;">しかし、私たちには（当然のことながら）彼はもっと能力があるようです。</font><font style="vertical-align: inherit;">他にあなたの手を試すアイデアはありますか？</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
清聴ありがとうございました！</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja486670/index.html">ロシア連邦の電子パスポート、マルレソンバレエの2020番目の部分</a></li>
<li><a href="../ja486672/index.html">OpenVINOハッカソン：Raspberry Piでの音声と感情の認識</a></li>
<li><a href="../ja486674/index.html">先週のフロントエンドの世界からの新鮮な食材のダイジェストNo.400（2020年1月27日〜2020年2月2日）</a></li>
<li><a href="../ja486676/index.html">FPGAのデータセンターへの侵入の不可避性</a></li>
<li><a href="../ja486678/index.html">ASP.NET CoreのQuartz</a></li>
<li><a href="../ja486682/index.html">Docker Compose：Makefileを使用して簡素化する</a></li>
<li><a href="../ja486684/index.html">TDDの価値が誇張されていると信じている人への私の答え</a></li>
<li><a href="../ja486686/index.html">Pythonでの深層学習ライブラリの実装について</a></li>
<li><a href="../ja486688/index.html">Node.js、Tor、Puppeteer、およびCheerio：匿名のWebスクレイピング</a></li>
<li><a href="../ja486690/index.html">高品質の矢印関数を作成するための5つのヒント</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
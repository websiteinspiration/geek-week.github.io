<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôçüèª üîó üëÅÔ∏è Random Forest, o m√©todo dos componentes principais e otimiza√ß√£o de hiperpar√¢metros: um exemplo de solu√ß√£o do problema de classifica√ß√£o em Python üë©‚Äçüéì ü§ê üöñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Os especialistas em processamento e an√°lise de dados t√™m muitas ferramentas para criar modelos de classifica√ß√£o. Um dos m√©todos mais populares e confi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Random Forest, o m√©todo dos componentes principais e otimiza√ß√£o de hiperpar√¢metros: um exemplo de solu√ß√£o do problema de classifica√ß√£o em Python</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/488342/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Os especialistas em processamento e an√°lise de dados t√™m muitas ferramentas para criar modelos de classifica√ß√£o. </font><font style="vertical-align: inherit;">Um dos m√©todos mais populares e confi√°veis ‚Äã‚Äãpara desenvolver esses modelos √© usar o algoritmo Random Forest (RF). </font><font style="vertical-align: inherit;">Para tentar melhorar o desempenho de um modelo constru√≠do usando o algoritmo de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RF</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , voc√™ pode usar a otimiza√ß√£o do hiperpar√¢metro do modelo ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyperparameter Tuning</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , HT). </font><font style="vertical-align: inherit;">
Al√©m disso, existe uma abordagem ampla segundo a qual os dados, antes de serem transferidos para o modelo, s√£o processados ‚Äã‚Äãusando a </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">An√°lise de componentes principais</font></a></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/tt/m5/h7/ttm5h7jbbx2u2wuc1var1azxwew.jpeg"></a><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, PCA). </font><font style="vertical-align: inherit;">Mas vale a pena usar? </font><font style="vertical-align: inherit;">O principal objetivo do algoritmo de RF n√£o √© ajudar o analista a interpretar a import√¢ncia das caracter√≠sticas?</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sim, o uso do algoritmo PCA pode levar a uma ligeira complica√ß√£o da interpreta√ß√£o de cada "recurso" na an√°lise da "import√¢ncia dos recursos" do modelo de RF. No entanto, o algoritmo PCA reduz a dimens√£o do espa√ßo de recurso, o que pode levar a uma diminui√ß√£o no n√∫mero de recursos que precisam ser processados ‚Äã‚Äãpelo modelo de RF. Observe que o volume de c√°lculos √© uma das principais desvantagens do algoritmo de floresta aleat√≥ria (ou seja, pode levar muito tempo para concluir o modelo). A aplica√ß√£o do algoritmo PCA pode ser uma parte muito importante da modelagem, especialmente nos casos em que eles trabalham com centenas ou mesmo milhares de recursos. Como resultado, se o mais importante √© simplesmente criar o modelo mais eficaz e, ao mesmo tempo, voc√™ pode sacrificar a precis√£o de determinar a import√¢ncia dos atributos, ent√£o vale a pena tentar o PCA.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora ao ponto. </font><font style="vertical-align: inherit;">Trabalharemos com um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conjunto de dados de c√¢ncer de mama</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">Scikit-learn "c√¢ncer de mama"</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Criaremos tr√™s modelos e compararemos sua efic√°cia. </font><font style="vertical-align: inherit;">Ou seja, estamos falando dos seguintes modelos:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O modelo b√°sico baseado no algoritmo de RF (vamos abreviar esse modelo de RF).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O mesmo modelo que o n¬∫ 1, mas no qual uma redu√ß√£o na dimens√£o do espa√ßo de fei√ß√£o √© aplicada usando o m√©todo do componente principal (RF + PCA).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O mesmo modelo que o n¬∫ 2, mas constru√≠do usando a otimiza√ß√£o de hiperpar√¢metros (RF + PCA + HT).</font></font></li>
</ol><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. Importar dados</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para come√ßar, carregue os dados e crie um quadro de dados do Pandas. </font><font style="vertical-align: inherit;">Como usamos um conjunto de dados "de brinquedo" pr√©-limpo do Scikit-learn, depois disso j√° podemos iniciar o processo de modelagem. </font><font style="vertical-align: inherit;">Por√©m, mesmo ao usar esses dados, √© recomend√°vel que voc√™ sempre comece a trabalhar realizando uma an√°lise preliminar dos dados usando os seguintes comandos aplicados ao quadro de dados ( </font></font><code>df</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">):</font></font><br>
<br>
<ul>
<li><code>df.head()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - para dar uma olhada no novo quadro de dados e ver se parece com o esperado.</font></font></li>
<li><code>df.info()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- para descobrir os recursos dos tipos de dados e do conte√∫do da coluna. </font><font style="vertical-align: inherit;">Pode ser necess√°rio executar a convers√£o do tipo de dados antes de continuar.</font></font></li>
<li><code>df.isna()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- para garantir que n√£o haja valores nos dados </font></font><code>NaN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Os valores correspondentes, se houver, podem precisar ser processados ‚Äã‚Äãde alguma forma ou, se necess√°rio, pode ser necess√°rio remover linhas inteiras do quadro de dados.</font></font></li>
<li><code>df.describe()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - descobrir os valores m√≠nimos, m√°ximos e m√©dios dos indicadores nas colunas, descobrir os indicadores do quadrado m√©dio e desvio prov√°vel nas colunas.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em nosso conjunto de dados, uma coluna </font></font><code>cancer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(c√¢ncer) √© a vari√°vel de destino cujo valor queremos prever usando o modelo. </font></font><code>0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">significa "sem doen√ßa". </font></font><code>1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- "a presen√ßa da doen√ßa".</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_breast_cancer<font></font>
columns = [<span class="hljs-string">'mean radius'</span>, <span class="hljs-string">'mean texture'</span>, <span class="hljs-string">'mean perimeter'</span>, <span class="hljs-string">'mean area'</span>, <span class="hljs-string">'mean smoothness'</span>, <span class="hljs-string">'mean compactness'</span>, <span class="hljs-string">'mean concavity'</span>, <span class="hljs-string">'mean concave points'</span>, <span class="hljs-string">'mean symmetry'</span>, <span class="hljs-string">'mean fractal dimension'</span>, <span class="hljs-string">'radius error'</span>, <span class="hljs-string">'texture error'</span>, <span class="hljs-string">'perimeter error'</span>, <span class="hljs-string">'area error'</span>, <span class="hljs-string">'smoothness error'</span>, <span class="hljs-string">'compactness error'</span>, <span class="hljs-string">'concavity error'</span>, <span class="hljs-string">'concave points error'</span>, <span class="hljs-string">'symmetry error'</span>, <span class="hljs-string">'fractal dimension error'</span>, <span class="hljs-string">'worst radius'</span>, <span class="hljs-string">'worst texture'</span>, <span class="hljs-string">'worst perimeter'</span>, <span class="hljs-string">'worst area'</span>, <span class="hljs-string">'worst smoothness'</span>, <span class="hljs-string">'worst compactness'</span>, <span class="hljs-string">'worst concavity'</span>, <span class="hljs-string">'worst concave points'</span>, <span class="hljs-string">'worst symmetry'</span>, <span class="hljs-string">'worst fractal dimension'</span>]<font></font>
dataset = load_breast_cancer()<font></font>
data = pd.DataFrame(dataset[<span class="hljs-string">'data'</span>], columns=columns)<font></font>
data[<span class="hljs-string">'cancer'</span>] = dataset[<span class="hljs-string">'target'</span>]<font></font>
display(data.head())<font></font>
display(data.info())<font></font>
display(data.isna().sum())<font></font>
display(data.describe())</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bce/fb8/b60/bcefb8b60462b7658b40e1e56f7744ab.png"></div><br>
<i><font color="#999999">      .       .  , cancer,   ,    . 0  ¬´ ¬ª. 1 ‚Äî ¬´ ¬ª</font></i><br>
 <br>
<h2><font color="#3AC1EF">2.        </font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora divida os dados usando a fun√ß√£o Scikit-learn </font></font><code>train_test_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Queremos fornecer ao modelo o m√°ximo de dados de treinamento poss√≠vel. No entanto, precisamos ter dados suficientes √† disposi√ß√£o para testar o modelo. Em geral, podemos dizer que, √† medida que o n√∫mero de linhas no conjunto de dados aumenta, tamb√©m aumenta a quantidade de dados que podem ser considerados educacionais. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por exemplo, se houver milh√µes de linhas, voc√™ pode dividir o conjunto destacando 90% das linhas para dados de treinamento e 10% para dados de teste. Mas o conjunto de dados de teste cont√©m apenas 569 linhas. E isso n√£o √© muito para treinar e testar o modelo. Como resultado, para sermos justos em rela√ß√£o aos dados de treinamento e verifica√ß√£o, dividiremos o conjunto em duas partes iguais - 50% - dados de treinamento e 50% - dados de verifica√ß√£o. N√≥s instalamos</font></font><code>stratify=y</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para garantir que os conjuntos de dados de treinamento e teste tenham a mesma propor√ß√£o de 0 e 1 que o conjunto de dados original.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
X = data.drop(<span class="hljs-string">'cancer'</span>, axis=<span class="hljs-number">1</span>)&nbsp;&nbsp;<font></font>
y = data[<span class="hljs-string">'cancer'</span>]&nbsp;<font></font>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.50</span>, random_state = <span class="hljs-number">2020</span>, stratify=y)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3. Escala de dados</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Antes de prosseguir com a modelagem, voc√™ precisa ‚Äúcentralizar‚Äù e ‚Äúpadronizar‚Äù os dados, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">escalando-os</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">A escala √© realizada devido ao fato de que quantidades diferentes s√£o expressas em unidades diferentes. </font><font style="vertical-align: inherit;">Este procedimento permite que voc√™ organize uma "luta justa" entre os sinais para determinar sua import√¢ncia. </font><font style="vertical-align: inherit;">Al√©m disso, convertemos </font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">do tipo de dados Pandas </font></font><code>Series</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para o array NumPy para que mais tarde o modelo possa trabalhar com os destinos correspondentes.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
ss = StandardScaler()<font></font>
X_train_scaled = ss.fit_transform(X_train)<font></font>
X_test_scaled = ss.transform(X_test)<font></font>
y_train = np.array(y_train)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4. Treinamento do modelo b√°sico (modelo n¬∫ 1, RF)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora crie o n√∫mero do modelo 1. </font><font style="vertical-align: inherit;">Nele, lembramos que apenas o algoritmo Random Forest √© usado. </font><font style="vertical-align: inherit;">Ele usa todos os recursos e √© configurado com os valores padr√£o (detalhes sobre essas configura√ß√µes podem ser encontrados na documenta√ß√£o para </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sklearn.ensemble.RandomForestClassifier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Inicialize o modelo. </font><font style="vertical-align: inherit;">Depois disso, vamos trein√°-la em dados dimensionados. </font><font style="vertical-align: inherit;">A precis√£o do modelo pode ser medida nos dados de treinamento:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> recall_score<font></font>
rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled, y_train)<font></font>
display(rfc.score(X_train_scaled, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se estivermos interessados ‚Äã‚Äãem aprender quais recursos s√£o os mais importantes para o modelo de RF na previs√£o do c√¢ncer de mama, podemos visualizar e quantificar os indicadores da import√¢ncia dos sinais consultando o atributo </font></font><code>feature_importances_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">feats = {}
<span class="hljs-keyword">for</span> feature, importance <span class="hljs-keyword">in</span> zip(data.columns, rfc_1.feature_importances_):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;feats[feature] = importance<font></font>
importances = pd.DataFrame.from_dict(feats, orient=<span class="hljs-string">'index'</span>).rename(columns={<span class="hljs-number">0</span>: <span class="hljs-string">'Gini-Importance'</span>})<font></font>
importances = importances.sort_values(by=<span class="hljs-string">'Gini-Importance'</span>, ascending=<span class="hljs-literal">False</span>)<font></font>
importances = importances.reset_index()<font></font>
importances = importances.rename(columns={<span class="hljs-string">'index'</span>: <span class="hljs-string">'Features'</span>})<font></font>
sns.set(font_scale = <span class="hljs-number">5</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">1.7</span>)<font></font>
fig, ax = plt.subplots()<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">15</span>)<font></font>
sns.barplot(x=importances[<span class="hljs-string">'Gini-Importance'</span>], y=importances[<span class="hljs-string">'Features'</span>], data=importances, color=<span class="hljs-string">'skyblue'</span>)<font></font>
plt.xlabel(<span class="hljs-string">'Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'Features'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.title(<span class="hljs-string">'Feature Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
display(plt.show())<font></font>
display(importances)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a02/a8f/cd2/a02a8fcd28f87af338f364a70faeca3e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualiza√ß√£o da "import√¢ncia" dos signos</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/830/176/e1f/830176e1fc9ce63bfedf2d727619253b.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Indicadores de signific√¢ncia</font></font></font></i><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5. O m√©todo dos componentes principais</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora vamos perguntar como podemos melhorar o modelo b√°sico de RF. Utilizando a t√©cnica de reduzir a dimens√£o do espa√ßo de recurso, √© poss√≠vel apresentar o conjunto de dados inicial por meio de menos vari√°veis ‚Äã‚Äãe, ao mesmo tempo, reduzir a quantidade de recursos de computa√ß√£o necess√°rios para garantir a opera√ß√£o do modelo. Usando o PCA, voc√™ pode estudar a varia√ß√£o cumulativa da amostra desses recursos para entender quais recursos explicam a maior parte da varia√ß√£o nos dados. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inicializamos o objeto PCA ( </font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), indicando o n√∫mero de componentes (recursos) que precisam ser considerados. Definimos esse indicador como 30 para ver a varia√ß√£o explicada de todos os componentes gerados antes de decidir quantos componentes precisamos. Depois transferimos para os </font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dados escalados</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">usando o m√©todo </font></font><code>pca_test.fit()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Depois disso, visualizamos os dados.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<font></font>
pca_test = PCA(n_components=<span class="hljs-number">30</span>)<font></font>
pca_test.fit(X_train_scaled)<font></font>
sns.set(style=<span class="hljs-string">'whitegrid'</span>)<font></font>
plt.plot(np.cumsum(pca_test.explained_variance_ratio_))<font></font>
plt.xlabel(<span class="hljs-string">'number of components'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'cumulative explained variance'</span>)<font></font>
plt.axvline(linewidth=<span class="hljs-number">4</span>, color=<span class="hljs-string">'r'</span>, linestyle = <span class="hljs-string">'--'</span>, x=<span class="hljs-number">10</span>, ymin=<span class="hljs-number">0</span>, ymax=<span class="hljs-number">1</span>)<font></font>
display(plt.show())<font></font>
evr = pca_test.explained_variance_ratio_<font></font>
cvr = np.cumsum(pca_test.explained_variance_ratio_)<font></font>
pca_df = pd.DataFrame()<font></font>
pca_df[<span class="hljs-string">'Cumulative Variance Ratio'</span>] = cvr<font></font>
pca_df[<span class="hljs-string">'Explained Variance Ratio'</span>] = evr<font></font>
display(pca_df.head(<span class="hljs-number">10</span>))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6eb/65f/acc/6eb65facc6c8b05f1e910d3b2b676d5e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Depois que o n√∫mero de componentes usados ‚Äã‚Äãexcede 10, o aumento no n√∫mero n√£o aumenta muito a varia√ß√£o explicada</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f12/e3c/915/f12e3c915d761e1d4623051dac74cd8d.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este quadro de dados cont√©m indicadores como o √çndice Acumulado Varia√ß√£o (tamanho cumulativo da vari√¢ncia explicada dos dados) e Rela√ß√£o de vari√¢ncia explicada (contribui√ß√£o de cada componente para o volume total da vari√¢ncia explicada)</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Se voc√™ olhar para o quadro de dados acima, verifica-se que o uso do PCA para se deslocar de 30 vari√°veis para 10 aos componentes permite explicar 95% da dispers√£o dos dados. Os outros 20 componentes representam menos de 5% da varia√ß√£o, o que significa que podemos recus√°-los. Seguindo essa l√≥gica, usamos o PCA para reduzir o n√∫mero de componentes de 30 para 10 para</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font><code>X_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Escrevemos esses conjuntos de dados de "dimens√£o reduzida" criados artificialmente dentro</font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e dentro</font></font><code>X_test_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">pca = PCA(n_components=<span class="hljs-number">10</span>)<font></font>
pca.fit(X_train_scaled)<font></font>
X_train_scaled_pca = pca.transform(X_train_scaled)<font></font>
X_test_scaled_pca = pca.transform(X_test_scaled)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada componente √© uma combina√ß√£o linear de vari√°veis ‚Äã‚Äãde origem com os "pesos" correspondentes. </font><font style="vertical-align: inherit;">Podemos ver esses "pesos" para cada componente criando um quadro de dados.</font></font><br>
<br>
<pre><code class="python hljs">pca_dims = []
<span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(pca_df)):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;pca_dims.append(<span class="hljs-string">'PCA Component {}'</span>.format(x))<font></font>
pca_test_df = pd.DataFrame(pca_test.components_, columns=columns, index=pca_dims)<font></font>
pca_test_df.head(<span class="hljs-number">10</span>).T</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/086/a28/ae4/086a28ae45e9048811cf813d4868902e.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Informa√ß√µes sobre o componente Dataframe</font></font></font></i><br>
 <br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6. Treinar o modelo b√°sico de RF ap√≥s aplicar o m√©todo dos componentes principais aos dados (modelo n¬∫ 2, RF + PCA)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora podemos passar para outro dados b√°sicos RF-modelo </font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e pode descobrir sobre se h√° uma melhoria na precis√£o das previs√µes emitidas pelo modelo.</font></font><br>
<br>
<pre><code class="python hljs">rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled_pca, y_train)<font></font>
display(rfc.score(X_train_scaled_pca, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os modelos s√£o comparados abaixo.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7. Otimiza√ß√£o de hiperpar√¢metros. </font><font style="vertical-align: inherit;">Rodada 1: RandomizedSearchCV</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois de processar os dados usando o m√©todo do componente principal, voc√™ pode tentar usar a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">otimiza√ß√£o dos hiperpar√¢metros do</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> modelo para melhorar a qualidade das previs√µes produzidas pelo modelo de RF. Os hiperpar√¢metros podem ser considerados como algo como "configura√ß√µes" do modelo. As configura√ß√µes perfeitas para um conjunto de dados n√£o funcionar√£o para outro - √© por isso que voc√™ precisa otimiz√°-las. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ pode come√ßar com o algoritmo RandomizedSearchCV, que permite explorar bastante uma ampla gama de valores. Descri√ß√µes de todos os hiperpar√¢metros para modelos de RF podem ser encontradas </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqui</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No decorrer do trabalho, geramos uma entidade </font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que cont√©m, para cada hiperpar√¢metro, um intervalo de valores que precisam ser testados. Em seguida, inicializamos o objeto.</font></font><code>rs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">usando a fun√ß√£o </font></font><code>RandomizedSearchCV()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, passando o modelo de RF </font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, o n√∫mero de itera√ß√µes e o n√∫mero de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">valida√ß√µes cruzadas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que precisam ser executadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O hiperpar√¢metro </font></font><code>verbose</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">permite controlar a quantidade de informa√ß√µes exibidas pelo modelo durante sua opera√ß√£o (como a sa√≠da de informa√ß√µes durante o treinamento do modelo). </font><font style="vertical-align: inherit;">O hiperpar√¢metro </font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">permite especificar quantos n√∫cleos de processador voc√™ precisa usar para garantir a opera√ß√£o do modelo. </font><font style="vertical-align: inherit;">Definir esse </font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">valor </font></font><code>-1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">levar√° a um modelo mais r√°pido, pois isso usar√° todos os n√∫cleos do processador. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estaremos envolvidos na sele√ß√£o dos seguintes hiperpar√¢metros:</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - o n√∫mero de "√°rvores" na "floresta aleat√≥ria".</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - o n√∫mero de recursos para selecionar a divis√£o.</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - profundidade m√°xima das √°rvores.</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - o n√∫mero m√≠nimo de objetos necess√°rios para a divis√£o de um n√≥ da √°rvore.</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - o n√∫mero m√≠nimo de objetos nas folhas.</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - use para construir subamostras de √°rvores com retorno.</font></font></li>
</ul><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<font></font>
n_estimators = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">100</span>, stop = <span class="hljs-number">1000</span>, num = <span class="hljs-number">10</span>)]<font></font>
max_features = [<span class="hljs-string">'log2'</span>, <span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">1</span>, stop = <span class="hljs-number">15</span>, num = <span class="hljs-number">15</span>)]<font></font>
min_samples_split = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
min_samples_leaf = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
bootstrap = [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]<font></font>
param_dist = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
rs = RandomizedSearchCV(rfc_2,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;param_dist,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_iter = <span class="hljs-number">100</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv = <span class="hljs-number">3</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose = <span class="hljs-number">1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_jobs=<span class="hljs-number">-1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random_state=<span class="hljs-number">0</span>)<font></font>
rs.fit(X_train_scaled_pca, y_train)<font></font>
rs.best_params_<font></font>
<span class="hljs-comment"># {'n_estimators': 700,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'min_samples_leaf': 2,</span>
<span class="hljs-comment"># 'max_features': 'log2',</span>
<span class="hljs-comment"># 'max_depth': 11,</span>
<span class="hljs-comment"># 'bootstrap': True}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com os valores dos par√¢metros </font></font><code>n_iter = 100</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font><code>cv = 3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, criamos 300 modelos de RF, escolhendo aleatoriamente combina√ß√µes dos hiper </font><font style="vertical-align: inherit;">par√¢metros </font><font style="vertical-align: inherit;">apresentados acima. </font><font style="vertical-align: inherit;">Podemos consultar o atributo </font></font><code>best_params_ </code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para obter informa√ß√µes sobre um conjunto de par√¢metros que permitem criar o melhor modelo. </font><font style="vertical-align: inherit;">Mas, nesse est√°gio, isso pode n√£o nos fornecer os dados mais interessantes sobre os intervalos de par√¢metros que vale a pena explorar na pr√≥xima rodada de otimiza√ß√£o. </font><font style="vertical-align: inherit;">Para descobrir em qual faixa de valores vale a pena continuar pesquisando, podemos facilmente obter um quadro de dados contendo os resultados do algoritmo RandomizedSearchCV.</font></font><br>
<br>
<pre><code class="python hljs">rs_df = pd.DataFrame(rs.cv_results_).sort_values(<span class="hljs-string">'rank_test_score'</span>).reset_index(drop=<span class="hljs-literal">True</span>)<font></font>
rs_df = rs_df.drop([<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_score_time'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_score_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'params'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split0_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split1_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split2_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_test_score'</span>],<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis=<span class="hljs-number">1</span>)<font></font>
rs_df.head(<span class="hljs-number">10</span>)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/617/b8c/20b/617b8c20b787acc3c76c23d9235b4b5a.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados do algoritmo RandomizedSearchCV</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Agora, criaremos gr√°ficos de barras nos quais, no eixo X, s√£o os valores do hiperpar√¢metro e no eixo Y, os valores m√©dios mostrados pelos modelos. </font><font style="vertical-align: inherit;">Isso possibilitar√° entender quais valores dos hiperpar√¢metros, em m√©dia, apresentam seu melhor desempenho.</font></font><br>
<br>
<pre><code class="python hljs">fig, axs = plt.subplots(ncols=<span class="hljs-number">3</span>, nrows=<span class="hljs-number">2</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">2</span>)<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">25</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_n_estimators'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'lightgrey'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.83</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'n_estimators'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_split'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'coral'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.85</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'min_samples_split'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_leaf'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'lightgreen'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'min_samples_leaf'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_features'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'wheat'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'max_features'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_depth'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'lightpink'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'max_depth'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_bootstrap'</span>,y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'skyblue'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'bootstrap'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
plt.show()</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/418/311/ba6/418311ba6c38bfcebbf152af810d6b58.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An√°lise dos valores dos hiperpar√¢metros</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Se analisarmos os gr√°ficos acima, podemos notar algumas coisas interessantes que falam sobre como, em m√©dia, cada valor de um hiperpar√¢metro afeta o modelo.</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: valores de 300, 500, 700, aparentemente, mostram os melhores resultados m√©dios.</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: Valores pequenos como 2 e 7 parecem mostrar os melhores resultados. </font><font style="vertical-align: inherit;">O valor 23 tamb√©m parece bom.Voc√™ pode examinar v√°rios valores desse hiperpar√¢metro al√©m de 2, bem como v√°rios valores de cerca de 23.</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: H√° uma sensa√ß√£o de que pequenos valores desse hiperpar√¢metro fornecem melhores resultados. </font><font style="vertical-align: inherit;">Isso significa que podemos experimentar valores entre 2 e 7.</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: op√ß√£o </font></font><code>sqrt</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fornece o resultado m√©dio mais alto.</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: n√£o existe uma rela√ß√£o clara entre o valor do hiperpar√¢metro e o resultado do modelo, mas h√° a sensa√ß√£o de que os valores 2, 3, 7, 11, 15 parecem bons.</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: o valor </font></font><code>False</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mostra o melhor resultado m√©dio.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, usando essas descobertas, podemos avan√ßar para a segunda rodada de otimiza√ß√£o de hiperpar√¢metros. </font><font style="vertical-align: inherit;">Isso restringir√° o intervalo de valores nos quais estamos interessados.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8. Otimiza√ß√£o de hiperpar√¢metros. </font><font style="vertical-align: inherit;">Rodada 2: GridSearchCV (prepara√ß√£o final dos par√¢metros para o modelo n¬∫ 3, RF + PCA + HT)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois de aplicar o algoritmo RandomizedSearchCV, usaremos o algoritmo GridSearchCV para realizar uma pesquisa mais precisa da melhor combina√ß√£o de hiperpar√¢metros. Os mesmos hiperpar√¢metros s√£o investigados aqui, mas agora estamos aplicando uma pesquisa mais "completa" para sua melhor combina√ß√£o. Usando o algoritmo GridSearchCV, cada combina√ß√£o de hiperpar√¢metros √© examinada. Isso requer muito mais recursos computacionais do que usar o algoritmo RandomizedSearchCV quando definimos independentemente o n√∫mero de itera√ß√µes de pesquisa. Por exemplo, pesquisar 10 valores para cada um dos 6 hiperpar√¢metros com valida√ß√£o cruzada em 3 blocos exigir√° 10 x 3, ou 3.000.000 de sess√µes de treinamento em modelo. √â por isso que usamos o algoritmo GridSearchCV depois de aplicar o RandomizedSearchCV, reduzimos os intervalos dos valores dos par√¢metros estudados.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Portanto, usando o que descobrimos com a ajuda do RandomizedSearchCV, examinamos os valores dos hiperpar√¢metros que se mostraram melhores:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<font></font>
n_estimators = [<span class="hljs-number">300</span>,<span class="hljs-number">500</span>,<span class="hljs-number">700</span>]<font></font>
max_features = [<span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">7</span>,<span class="hljs-number">11</span>,<span class="hljs-number">15</span>]<font></font>
min_samples_split = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">22</span>,<span class="hljs-number">23</span>,<span class="hljs-number">24</span>]<font></font>
min_samples_leaf = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<font></font>
bootstrap = [<span class="hljs-literal">False</span>]<font></font>
param_grid = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
gs = GridSearchCV(rfc_2, param_grid, cv = <span class="hljs-number">3</span>, verbose = <span class="hljs-number">1</span>, n_jobs=<span class="hljs-number">-1</span>)<font></font>
gs.fit(X_train_scaled_pca, y_train)<font></font>
rfc_3 = gs.best_estimator_<font></font>
gs.best_params_<font></font>
<span class="hljs-comment"># {'bootstrap': False,</span>
<span class="hljs-comment"># 'max_depth': 7,</span>
<span class="hljs-comment"># 'max_features': 'sqrt',</span>
<span class="hljs-comment"># 'min_samples_leaf': 3,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'n_estimators': 500}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui, aplicamos a valida√ß√£o cruzada em 3 blocos para 540 (3 x 1 x 5 x 6 x 6 x 1) sess√µes de treinamento do modelo, o que fornece 1620 sess√µes de treinamento do modelo. </font><font style="vertical-align: inherit;">E agora, depois de usarmos RandomizedSearchCV e GridSearchCV, podemos usar o atributo </font></font><code>best_params_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para descobrir quais valores de hiperpar√¢metros permitem que o modelo funcione melhor com o conjunto de dados em estudo (esses valores podem ser vistos na parte inferior do bloco de c√≥digo anterior) . </font><font style="vertical-align: inherit;">Esses par√¢metros s√£o usados ‚Äã‚Äãpara criar o n√∫mero do modelo 3.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9. Avalia√ß√£o da qualidade dos modelos nos dados de verifica√ß√£o</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora voc√™ pode avaliar os modelos criados nos dados de verifica√ß√£o. </font><font style="vertical-align: inherit;">Ou seja, estamos falando desses tr√™s modelos descritos no in√≠cio do material. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Confira estes modelos:</font></font><br>
<br>
<pre><code class="python hljs">y_pred = rfc.predict(X_test_scaled)<font></font>
y_pred_pca = rfc.predict(X_test_scaled_pca)<font></font>
y_pred_gs = gs.best_estimator_.predict(X_test_scaled_pca)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Crie matrizes de erro para os modelos e descubra at√© que ponto cada um deles √© capaz de prever o c√¢ncer de mama:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix<font></font>
conf_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_pred), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_baseline_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_pca), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_tuned_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_gs), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
display(conf_matrix_baseline)<font></font>
display(<span class="hljs-string">'Baseline Random Forest recall score'</span>, recall_score(y_test, y_pred))<font></font>
display(conf_matrix_baseline_pca)<font></font>
display(<span class="hljs-string">'Baseline Random Forest With PCA recall score'</span>, recall_score(y_test, y_pred_pca))<font></font>
display(conf_matrix_tuned_pca)<font></font>
display(<span class="hljs-string">'Hyperparameter Tuned Random Forest With PCA Reduced Dimensionality recall score'</span>, recall_score(y_test, y_pred_gs))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f48/a9e/92f/f48a9e92fd5fdca613d6073e00bae2c6.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados do trabalho dos tr√™s modelos</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Aqui, a m√©trica ‚Äúcompletude‚Äù (recall) √© avaliada. </font><font style="vertical-align: inherit;">O fato √© que estamos lidando com um diagn√≥stico de c√¢ncer. </font><font style="vertical-align: inherit;">Portanto, estamos extremamente interessados ‚Äã‚Äãem minimizar as previs√µes negativas falsas emitidas pelos modelos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diante disso, podemos concluir que o modelo b√°sico de RF apresentou os melhores resultados. </font><font style="vertical-align: inherit;">Sua taxa de completude foi de 94,97%. </font><font style="vertical-align: inherit;">No conjunto de dados de teste, houve um registro de 179 pacientes com c√¢ncer. </font><font style="vertical-align: inherit;">O modelo encontrou 170 deles.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sum√°rio</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este estudo fornece uma observa√ß√£o importante. </font><font style="vertical-align: inherit;">√Äs vezes, o modelo de RF, que usa o m√©todo do componente principal e a otimiza√ß√£o em grande escala de hiperpar√¢metros, pode n√£o funcionar t√£o bem quanto o modelo mais comum com configura√ß√µes padr√£o. </font><font style="vertical-align: inherit;">Mas esse n√£o √© um motivo para se limitar apenas aos modelos mais simples. </font><font style="vertical-align: inherit;">Sem experimentar modelos diferentes, √© imposs√≠vel dizer qual deles apresentar√° o melhor resultado. </font><font style="vertical-align: inherit;">E no caso de modelos usados ‚Äã‚Äãpara prever a presen√ßa de c√¢ncer em pacientes, podemos dizer que, quanto melhor o modelo - mais vidas podem ser salvas. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Queridos leitores! </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quais tarefas voc√™ resolve usando m√©todos de aprendizado de m√°quina?</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt488330/index.html">Ingl√™s com George Karlin: analisamos o engenhoso posicionamento sobre unidades fraseol√≥gicas</a></li>
<li><a href="../pt488332/index.html">Zero, um, dois, Freddy vai busc√°-lo</a></li>
<li><a href="../pt488336/index.html">Dicas para usar o algoritmo de recolhimento da fun√ß√£o Wave</a></li>
<li><a href="../pt488338/index.html">Est√°gios do Google: Zurique, Londres e Vale do Sil√≠cio</a></li>
<li><a href="../pt488340/index.html">Profiss√£o: Backend Developer</a></li>
<li><a href="../pt488346/index.html">Instalando or-tools com SCIP e GLPK em um ambiente virtual Python 3.7 no Linux</a></li>
<li><a href="../pt488348/index.html">Webinar ‚ÄúOs dez principais desafios √°geis e como super√°-los em uma hora‚Äù 17 de fevereiro √†s 20:00, hor√°rio de Moscou</a></li>
<li><a href="../pt488352/index.html">Compara√ß√£o de custos de VDI: nuvem local versus nuvem p√∫blica</a></li>
<li><a href="../pt488356/index.html">Treinamento na Universidade T√©cnica Mar√≠tima do Estado de S√£o Petersburgo para produtos Dassault Syst√®mes</a></li>
<li><a href="../pt488360/index.html">Mitos sobre big data e cultura digital</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
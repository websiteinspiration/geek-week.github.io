<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüöí üèóÔ∏è üßõüèæ "Desculpe, eu reconheci ..." ou reconhe√ßa framboesas e controladores usando a API de detec√ß√£o de objetos do Tensorflow üò¢ üî∂ ü§ú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No final do ano passado, escrevi um artigo sobre como fiquei intrigado com a capacidade de reconhecer objetos em imagens usando redes neurais. Nesse a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>"Desculpe, eu reconheci ..." ou reconhe√ßa framboesas e controladores usando a API de detec√ß√£o de objetos do Tensorflow</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/494804/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No final do ano passado, escrevi </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">um artigo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sobre como fiquei intrigado com a capacidade de reconhecer objetos em imagens usando redes neurais. Nesse artigo, usando o PyTorch, categorizamos framboesas ou um controlador semelhante ao arduino em v√≠deo. E apesar do fato de gostar do PyTorch, virei-me para ele porque n√£o conseguia lidar com o TensorFlow imediatamente. Mas prometi voltar √† quest√£o do reconhecimento de objetos no v√≠deo. Parece que chegou a hora de cumprir a promessa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Neste artigo, tentaremos em nossa m√°quina local treinar novamente o modelo finalizado no Tensorflow 1.13 e a API de detec√ß√£o de objetos em nosso pr√≥prio conjunto de imagens e us√°-lo para reconhecer bagas e controladores no fluxo de v√≠deo de uma c√¢mera da Web usando OpenCV.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deseja melhorar sua habilidade de reconhecimento de frutos silvestres at√© o ver√£o? </font><font style="vertical-align: inherit;">Ent√£o voc√™ √© bem-vindo sob gato.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fu/do/rd/fudordve5xz-8gwdnbvlnkkjusm.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conte√∫do: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte I: introdu√ß√£o </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte II: treine o modelo no TenosrFlow </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte III: aplique o modelo no OpenCV </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte IV: conclus√£o</font></font></a><br>
<a name="I"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte I: Introdu√ß√£o</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quem leu o artigo anterior sobre o PyTorch j√° sabe que sou amador em quest√µes de redes neurais. Portanto, n√£o perceba este artigo como a verdade suprema. De qualquer forma, espero poder ajudar algu√©m a lidar com o b√°sico do reconhecimento de v√≠deo usando a API de detec√ß√£o de objetos do Tensorflow. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desta vez, n√£o tentei fazer um tutorial, portanto, o artigo ser√° mais curto que o normal.</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para come√ßar, o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tutorial oficial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sobre o uso da API de detec√ß√£o de objetos em uma m√°quina local, para dizer o m√≠nimo, n√£o √© exaustivo. Como iniciante, eu era completamente inadequado e tinha que me concentrar nos artigos do blog.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para ser sincero, gostaria de experimentar o TensorFlow 2.0, mas na maioria das publica√ß√µes, no momento em que este artigo foi escrito, os problemas de migra√ß√£o n√£o foram completamente resolvidos. </font><font style="vertical-align: inherit;">Portanto, no final, eu decidi pelo TF 1.13.2.</font></font><br>
<a name="II"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte II: ensinando um modelo no TensorFlow </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eu desenhei instru√ß√µes para ensinar o modelo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">neste artigo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , ou melhor, desde o primeiro semestre, at√© a aplica√ß√£o do JavaScript </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(se voc√™ n√£o fala ingl√™s, pode ver um artigo sobre o mesmo t√≥pico </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">em Habr√©</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√â verdade que, no meu caso, existem v√°rias diferen√ßas:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eu usei o Linux porque o Anaconda para Linux j√° criou protobuf e pycocoapi, ent√£o n√£o precisei constru√≠-los.</font></font></li>
<li>   TensorFlow 1.13.2,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Object Detection API 1.13</a> ,       TensorFlow 1.13.2.   master        TF 1.15,         1.13.</li>
<li>      numpy ‚Äî 1.17.5,  1.18    .</li>
<li>  faster_rcnn_inception_v2_coco    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">ssd_mobilenet_v2_coco</a>,    ,     .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Por precau√ß√£o, direi que n√£o usei um acelerador gr√°fico. O treinamento foi realizado apenas nas capacidades do processador. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um conjunto de imagens, um arquivo de configura√ß√£o, um gr√°fico salvo e um script para reconhecer imagens usando o OpenCV, como sempre, podem ser baixados do </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Passadas 23 horas de treinamento de modelos, todo o ch√° da casa j√° foi tomado, ‚ÄúO qu√™? Onde? Quando?" inspecionado e agora minha paci√™ncia finalmente chegou ao fim. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Paramos o treinamento e salvamos o modelo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Instale o OpenCV no mesmo ambiente do "Anaconda" com o seguinte comando:</font></font><br>
<br>
<pre><code class="plaintext hljs">conda install -c conda-forge opencv</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eventualmente, instalei a vers√£o 4.2 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m disso, as instru√ß√µes </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">deste artigo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> n√£o ser√£o mais necess√°rias. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois de salvar o modelo, cometi um erro que n√£o era √≥bvio para mim: tentei imediatamente substituir o arquivo graph.pbtxt usado anteriormente na pasta training / na fun√ß√£o:</font></font><br>
<br>
<pre><code class="python hljs">cv2.dnn.readNetFromTensorflow()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Infelizmente, isso n√£o funciona dessa maneira e teremos que fazer mais uma manipula√ß√£o para obter o graph.pbtxt para o OpenCV. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Muito provavelmente, o fato de agora aconselhar n√£o √© uma maneira muito boa, mas para mim funciona. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Baixe </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_ssd.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e tamb√©m </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_common.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> coloque-os na pasta onde est√° localizado o gr√°fico salvo (eu tenho essa pasta inference_graph). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, v√° para o console nesta pasta e execute a partir dele um comando com aproximadamente o seguinte conte√∫do:</font></font><br>
<br>
<pre><code class="plaintext hljs">python tf_text_graph_ssd.py --input frozen_inference_graph.pb --config pipeline.config --output graph.pbtxt</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E isso √© tudo o que resta para carregar nosso modelo no OpenCV.</font></font><br>
<br>
<a name="III"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte III: aplique o modelo no OpenCV </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como no artigo sobre PyTorch sobre o trabalho com o OpenCV, tomei como base o c√≥digo do programa </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">desta publica√ß√£o</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fiz pequenas altera√ß√µes para simplific√°-lo um pouco mais, mas como n√£o entendo completamente o c√≥digo, n√£o vou comentar. </font><font style="vertical-align: inherit;">Funciona e agrad√°vel. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Est√° claro que o c√≥digo poderia ter sido melhor, mas ainda n√£o tenho tempo para me sentar nos tutoriais do OpenCV</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C√≥digo OpenCV</font></font></b>
                        <div class="spoiler_text"><pre><code class="python hljs">
<span class="hljs-comment"># USAGE</span>
<span class="hljs-comment"># based on this code https://proglib.io/p/real-time-object-detection/</span>
<span class="hljs-comment"># import the necessary packages</span>
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> VideoStream
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> FPS
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> imutils
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> cv2<font></font>
<font></font>
prototxt=<span class="hljs-string">"graph.pbtxt"</span>
model=<span class="hljs-string">"frozen_inference_graph.pb"</span>
min_confidence = <span class="hljs-number">0.5</span><font></font>
<font></font>
<span class="hljs-comment"># initialize the list of class labels MobileNet SSD was trained to</span>
<span class="hljs-comment"># detect, then generate a set of bounding box colors for each class</span>
CLASSES = [<span class="hljs-string">"background"</span>, <span class="hljs-string">"duino"</span>,<span class="hljs-string">"raspb"</span>]<font></font>
COLORS = [(<span class="hljs-number">40</span>,<span class="hljs-number">50</span>,<span class="hljs-number">60</span>),((<span class="hljs-number">140</span>,<span class="hljs-number">55</span>,<span class="hljs-number">130</span>)),(<span class="hljs-number">240</span>,<span class="hljs-number">150</span>,<span class="hljs-number">25</span>)]<font></font>
<font></font>
<span class="hljs-comment"># load our serialized model from disk</span>
print(<span class="hljs-string">"[INFO] loading model..."</span>)<font></font>
<font></font>
net =cv2.dnn.readNetFromTensorflow(model,prototxt)<font></font>
<font></font>
<span class="hljs-comment"># initialize the video stream, allow the cammera sensor to warmup,</span>
<span class="hljs-comment"># and initialize the FPS counter</span>
print(<span class="hljs-string">"[INFO] starting video stream..."</span>)<font></font>
vs = VideoStream(src=<span class="hljs-number">0</span>).start()<font></font>
time.sleep(<span class="hljs-number">0.5</span>)<font></font>
fps = FPS().start()<font></font>
<font></font>
<span class="hljs-comment"># loop over the frames from the video stream</span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
	<span class="hljs-comment"># grab the frame from the threaded video stream and resize it</span>
	<span class="hljs-comment"># to have a maximum width of 400 pixels</span><font></font>
	frame = vs.read()<font></font>
	frame = imutils.resize(frame, width=<span class="hljs-number">300</span>)<font></font>
<font></font>
	<span class="hljs-comment"># grab the frame dimensions and convert it to a blob</span>
	(h, w) = frame.shape[:<span class="hljs-number">2</span>]<font></font>
	blob = cv2.dnn.blobFromImage(frame, size=(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>), swapRB=<span class="hljs-literal">True</span>)<font></font>
<font></font>
	<span class="hljs-comment"># pass the blob through the network and obtain the detections and</span>
	<span class="hljs-comment"># predictions</span><font></font>
	net.setInput(blob)<font></font>
	detections = net.forward()<font></font>
<font></font>
	<span class="hljs-comment"># loop over the detections</span>
	<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.arange(<span class="hljs-number">0</span>, detections.shape[<span class="hljs-number">2</span>]):
		<span class="hljs-comment"># extract the confidence (i.e., probability) associated with</span>
		<span class="hljs-comment"># the prediction</span>
		<span class="hljs-keyword">print</span> (detections)<font></font>
		confidence = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">2</span>]<font></font>
<font></font>
		<span class="hljs-keyword">if</span> confidence &gt; min_confidence:
			<span class="hljs-comment"># extract the index of the class label from the</span>
			<span class="hljs-comment"># `detections`, then compute the (x, y)-coordinates of</span>
			<span class="hljs-comment"># the bounding box for the object</span>
			idx = int(detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">1</span>])<font></font>
			box = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">3</span>:<span class="hljs-number">7</span>] * np.array([w, h, w, h])<font></font>
			(startX, startY, endX, endY) = box.astype(<span class="hljs-string">"int"</span>)<font></font>
<font></font>
			<span class="hljs-comment"># draw the prediction on the frame</span>
			label = <span class="hljs-string">"{}: {:.2f}%"</span>.format(CLASSES[idx],<font></font>
				confidence * <span class="hljs-number">100</span>)<font></font>
			cv2.rectangle(frame, (startX, startY), (endX, endY),<font></font>
				COLORS[idx], <span class="hljs-number">2</span>)<font></font>
			y = startY - <span class="hljs-number">15</span> <span class="hljs-keyword">if</span> startY - <span class="hljs-number">15</span> &gt; <span class="hljs-number">15</span> <span class="hljs-keyword">else</span> startY + <span class="hljs-number">15</span>
			cv2.putText(frame, label, (startX, y+<span class="hljs-number">3</span>),<font></font>
				cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, COLORS[idx], <span class="hljs-number">1</span>)<font></font>
<font></font>
	<span class="hljs-comment"># show the output frame</span>
	cv2.imshow(<span class="hljs-string">"Frame"</span>, frame)<font></font>
	key = cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span><font></font>
<font></font>
	<span class="hljs-comment"># if the `q` key was pressed, break from the loop</span>
	<span class="hljs-keyword">if</span> key == ord(<span class="hljs-string">"q"</span>):
		<span class="hljs-keyword">break</span><font></font>
<font></font>
	<span class="hljs-comment"># update the FPS counter</span><font></font>
	fps.update()<font></font>
<font></font>
<span class="hljs-comment"># stop the timer and display FPS information</span><font></font>
fps.stop()<font></font>
print(<span class="hljs-string">"[INFO] elapsed time: {:.2f}"</span>.format(fps.elapsed()))<font></font>
print(<span class="hljs-string">"[INFO] approx. FPS: {:.2f}"</span>.format(fps.fps()))<font></font>
<font></font>
<span class="hljs-comment"># do a bit of cleanup</span><font></font>
cv2.destroyAllWindows()<font></font>
vs.stop()<font></font>
</code></pre><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ent√£o, est√° tudo pronto. Lan√ßamos o modelo, apontamos as lentes para o meu velho CraftDuino e apreciamos o resultado: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/bw/hj/yd/bwhjyd9pddoeop9yaz7fxbqozzo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√Ä primeira vista, n√£o √© nada ruim, mas √© apenas √† primeira vista. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parece que em 23 horas, o modelo foi treinado novamente, portanto, apresenta erros graves ao definir objetos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui est√° uma demonstra√ß√£o visual: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/1w/3y/gf/1w3ygfo-ufytpuyct1kaarpsgls.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como voc√™ pode ver, n√£o apenas uma faca, mas mesmo apenas um fundo preto, este modelo define-o como um controlador semelhante ao arduino. Talvez isso ocorra porque nos dados de treinamento havia imagens escuras com o Arduino e seus an√°logos, nas quais o modelo conseguiu esbarrar em 23 horas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, tive que carregar meu computador por mais 8 horas e treinar um novo modelo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As coisas est√£o muito melhores com ela. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui est√° um exemplo com o CraftDuino:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_c/8m/62/_c8m62y2q6as-l8sun5ah5ivppk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Framboesas vivas n√£o est√£o √† m√£o. </font><font style="vertical-align: inherit;">Eu tive que imprimir fotos. </font><font style="vertical-align: inherit;">Na tela do telefone ou monitor, voc√™ tamb√©m pode reconhecer, mas no papel era mais conveniente. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/63/_k/ou/63_koujmchte7jor0ulqzxcvgcs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos verificar como o modelo reconhece o Arduino nano, que no devido tempo</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Drzugrik</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para mim, soldei meu mega dispositivo com sensores: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ub/33/61/ub3361ozwkiwvl2sosx6yldvsou.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
como voc√™ pode ver, ele reconhece muito bem, mas com um √¢ngulo muito ruim e com ilumina√ß√£o quente, ele reconhece alguns fragmentos como framboesas. Mas, na verdade, era dif√≠cil capturar uma moldura com erro na lente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora vamos verificar como ela classifica os objetos nos quais n√£o foi treinada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Novamente, um exemplo com uma faca e um fundo preto: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/io/ja/6a/ioja6aexferclondu4228nsr06y.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
desta vez tudo funciona como deveria. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos oferecer nosso modelo para reconhecer o pequeno controlador Canny 3, sobre o qual escrevi em um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artigo anterior</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xp/ay/14/xpay14o7clhp1y1twu4vyltiay4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como nosso modelo n√£o sabe nada, exceto framboesas e controladores do tipo arduino, podemos dizer que o modelo reconheceu o controlador Canny com bastante √™xito.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√â verdade que, como no caso do Arduino nano, muito depende do √¢ngulo e da ilumina√ß√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com a luz quente de uma l√¢mpada incandescente e com um √¢ngulo malsucedido, o controlador pode n√£o apenas ser reconhecido, mas tamb√©m definido como framboesa. </font><font style="vertical-align: inherit;">√â verdade que, como no caso anterior, esses √¢ngulos ainda precisavam tentar capturar a lente. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/01/ut/h_/01uth_-raiwnzasg7ypn-aoxezs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bem, o √∫ltimo caso √© uma esp√©cie de rever√™ncia para o artigo sobre a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classifica√ß√£o de imagens no PyTorch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Como na √∫ltima vez, o computador de placa √∫nica Raspberry Pi 2 e seu logotipo s√£o compat√≠veis em um quadro. </font><font style="vertical-align: inherit;">Diferentemente do artigo anterior, no qual resolvemos o problema de classifica√ß√£o e escolhemos um objeto mais prov√°vel para a imagem, neste caso, o logotipo e o pr√≥prio Raspberry s√£o reconhecidos.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vx/fv/us/vxfvusfgitn6vk1pe6o4rvoen9i.png"><br>
<br>
<a name="IV"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Parte IV: Conclus√£o </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Concluindo, quero dizer que, apesar da inexperi√™ncia desse pequeno exemplo de trabalho com a API de detec√ß√£o de objetos do Tensorflow, demorou dois dias de folga e parte de segunda-feira, n√£o me arrependo. Quando pelo menos um pouco de compreens√£o de como usar tudo se torna insanamente curioso. No processo de aprendizagem, voc√™ come√ßa a considerar o modelo como um modelo vivo, acompanha seus sucessos e fracassos. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Portanto, recomendo a todos que n√£o est√£o familiarizados com isso um dia tentar reconhecer algo pr√≥prio.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m disso, como ele aumentou no processo, voc√™ nem precisa comprar uma webcam real. O fato √© que, durante a prepara√ß√£o do artigo, eu consegui quebrar minha webcam (quebrei o mecanismo de foco) e j√° pensei que teria que abandonar tudo. Mas, com a ajuda do Droidcam, voc√™ pode usar um smartphone em vez de uma webcam (n√£o conte para publicidade). Al√©m disso, a qualidade da fotografia acabou sendo muito melhor do que a de uma c√¢mera quebrada, e isso influenciou bastante a qualidade do reconhecimento de objetos na imagem. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A prop√≥sito, como o Anaconda tem uma compila√ß√£o normal de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pycocotools</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Encontrei-o apenas para Linux e fiquei com pregui√ßa de alternar entre sistemas operacionais. Preparei este artigo inteiro apenas usando software de c√≥digo aberto. </font><font style="vertical-align: inherit;">Havia an√°logos do Word e do Photoshop e at√© um driver para a impressora. </font><font style="vertical-align: inherit;">A primeira vez na minha vida isso aconteceu. </font><font style="vertical-align: inherit;">Verificou-se que as vers√µes modernas do Linux OS e dos aplicativos podem ser muito convenientes, mesmo para quem usa o Microsoft OS h√° mais de 25 anos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS Se algu√©m souber executar corretamente a API de detec√ß√£o de objeto </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
para Tensorflow vers√£o 2 e superior, cancele a inscri√ß√£o em PM ou em um coment√°rio. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tenha um bom dia e boa sa√∫de!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt488468/index.html">Apresentando o FastAPI</a></li>
<li><a href="../pt488470/index.html">Kim Dotcom: Caught, a pessoa mais procurada online. Parte 4</a></li>
<li><a href="../pt488472/index.html">Leitura de fim de semana: 10 materiais sobre dispositivos de √°udio - de r√°dios sovi√©ticos a plugues com cancelamento de ru√≠do</a></li>
<li><a href="../pt488474/index.html">Sobre cor, som e ‚Äúexplora√ß√£o de multid√µes‚Äù como um tipo separado de beleza</a></li>
<li><a href="../pt494800/index.html">Engenharia reversa do protocolo de transceptor USB USB IR</a></li>
<li><a href="../pt494806/index.html">Cyber ‚Äã‚Äãvisa 2019 como tend√™ncias 2020 - hackers mudaram o foco</a></li>
<li><a href="../pt494808/index.html">Analista de produto: o que faz, quanto ganha, quais benef√≠cios os neg√≥cios trazem</a></li>
<li><a href="../pt494810/index.html">Introdu√ß√£o ao 3D: conceitos b√°sicos do Three.js</a></li>
<li><a href="../pt494814/index.html">Slurm √© √∫til?</a></li>
<li><a href="../pt494818/index.html">Como escolher um terminal de negocia√ß√£o para trabalhar na bolsa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
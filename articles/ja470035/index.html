<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⏳ 🔻 🙃 妄想ジェネレータ：ニューラルネットワークを使用して任意の言語でテキストを作成します 👖 🖲️ 🤾🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、ハブル。
 
 この記事は少し「金曜日」の形式になりますが、今日はNLPを扱います。本が地下道で売られているNLPではなく、自然言語処理が自然言語を処理しているもの。このような処理の例として、ニューラルネットワークを使用したテキスト生成を使用します。ロシア語や英語からC ++まで、あらゆ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>妄想ジェネレータ：ニューラルネットワークを使用して任意の言語でテキストを作成します</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470035/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは、ハブル。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事は少し「金曜日」の形式になりますが、今日はNLPを扱います。</font><font style="vertical-align: inherit;">本が地下道で売られているNLPではなく、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">自然言語処理</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">自然言語を処理して</font></a><font style="vertical-align: inherit;">いるもの。</font><font style="vertical-align: inherit;">このような処理の例として、ニューラルネットワークを使用したテキスト生成を使用します。</font><font style="vertical-align: inherit;">ロシア語や英語からC ++まで、あらゆる言語のテキストを作成できます。</font><font style="vertical-align: inherit;">結果は非常に興味深いものです。写真から推測できます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vc/cy/we/vccywe4c6r0vbryvvx3qiale_j8.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
何が起こるかに興味がある人のために、結果とソースコードはカットの下にあります。</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データの準備</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
処理には、ニューラルネットワークの特別なクラス、いわゆるリカレントニューラルネットワーク（RNN）を使用します。このネットワークは、通常のセルに加えて、メモリセルがあるという点で通常のネットワークとは異なります。これにより、すべての思考を「ゼロから」開始することもないため、より複雑な構造のデータを分析することができます。コードの記述には、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LSTM</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（Long Short-Term Memory）</font><font style="vertical-align: inherit;">ネットワークを使用します。</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">それらはKeras</font></a><font style="vertical-align: inherit;">によって既にサポートされているためです。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ay/ox/ou/ayoxourylcbidznetfkphgdv5ni.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
解決する必要がある次の問題は、実際には、テキストの操作です。そして、ここには2つのアプローチがあります-シンボルまたは単語全体を入力に送信することです。最初のアプローチの原理は単純です。テキストは短いブロックに分割され、「入力」はテキストのフラグメントであり、「出力」は次の文字です。たとえば、最後のフレーズの場合、「入力はテキストの一部です」などです</font><font style="vertical-align: inherit;">
。したがって、ニューラルネットワークは入力でテキストのフラグメントを受け取り、出力でそれが形成する文字を受け取ります。</font><font style="vertical-align: inherit;">
2番目のアプローチは基本的に同じで、単語の代わりに単語全体のみが使用されます。まず、単語の辞書が作成され、ネットワーク入力で単語の代わりに数字が入力されます。</font><font style="vertical-align: inherit;">
もちろん、これはかなり単純化された説明です。テキスト生成の例は</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">すでにそこにあります</font></a></font><br>
<br>
<code>input:    output: ""<br>
input:    : output: ""<br>
input:    : output:""<br>
input:    : output: ""<br>
input:    : output: "".<br>
</code><br><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ケラスでは、1つ目はそれほど詳細に説明されていません。2つ目は、英語のチュートリアルではすべて、シェイクスピアのようなかなりネイティブなテキストを使用しているため、ネイティブでは理解が困難です。</font><font style="vertical-align: inherit;">まあ、私達は私達の偉大で強力なものでニューラルネットワークをテストしています。もちろん、より明確で理解しやすいでしょう。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ネットワークトレーニング</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
入力テキストとして、私は... Habrのコメントを使用しました。ソースファイルのサイズは1 MBです（もちろん実際にはもっと多くのコメントがありますが、一部のみを使用する必要がありました。そうしないと、ネットワークは1週間トレーニングされ、読者は金曜日までにこのテキストを見ることができませんでした）。ニューラルネットワークの入力に入力されるのは文字だけであり、ネットワークは言語についても、その構造についても「認識」していないことを思い出してください。さあ、ネットワークトレーニングを始めましょう。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5分のトレーニング：</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
これまでのところ明確なものは何もありませんが、認識できる文字の組み合わせはすでに確認できます：</font><b><font style="vertical-align: inherit;">15分のトレーニング：</font></b><font style="vertical-align: inherit;"> 
結果はすでにかなり良くなっています：</font><b><font style="vertical-align: inherit;">1時間のトレーニング：</font></b></font><br>
<br>
<code>                          .                   .                                                     .          «                   <br>
</code><br>
<b><font style="vertical-align: inherit;"></font></b><br>
<br><font style="vertical-align: inherit;"></font><br>
<br>
<code>                                                                                                                                <br>
</code><br>
<b><font style="vertical-align: inherit;"></font></b><br>
<br>
<code>                                                                  « » —                                                            «     » » —             </code><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
何らかの理由で、すべてのテキストにドットや大文字が含まれていないことが判明しましたが、おそらくutf-8処理が正しく行われていません。しかし全体として、それは印象的です。シンボルコードのみを分析して記憶することにより、プログラムは実際に「独立して」ロシア語の単語を学習し、非常に信頼できる見栄えのテキストを生成できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
同様に興味深いのは、プログラムがテキストスタイルを非常によく記憶しているという事実です。次の例では、いくつかの法律のテキストが指示として使用されました。ネットワークトレーニング時間5分。</font><font style="vertical-align: inherit;">
そしてここでは、医薬品の医療用注釈が入力セットとして使用されました。ネットワークトレーニング時間5分。</font></font><br>
<br>
<code>  ""  ,  ,  ,  ,  ,  , ,  ,                <br>
</code><br><font style="vertical-align: inherit;"></font><br>
<br>
<code> <br>
    <br>
                                         ,    ,            <br>
</code><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここではほとんどすべてのフレーズが表示されます。</font><font style="vertical-align: inherit;">これは、元のテキストが短く、ニューラルネットワークが一部のフレーズを実際に「記憶」しているためです。</font><font style="vertical-align: inherit;">この影響は「再トレーニング」と呼ばれ、回避する必要があります。</font><font style="vertical-align: inherit;">理想的には、大規模なデータセットでニューラルネットワークをテストする必要がありますが、この場合のトレーニングには何時間もかかる可能性があり、残念ながら、追加のスーパーコンピューターはありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このようなネットワークを使用する楽しい例は、名前の生成です。</font><font style="vertical-align: inherit;">男性と女性の名前のリストをファイルにアップロードしたので、サイエンスフィクションの小説に非常に適した非常に興味深い新しいオプション、Rlar、Laaa、Aria、Arera、Aelia、Ninran、Airを取得しました。</font><font style="vertical-align: inherit;">それらの中の何かがエフレモフとアンドロメダ星雲のスタイルを感じています...</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C ++</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
おもしろいことは、概して、ニューラルネットワークは覚えているようなものです。</font><font style="vertical-align: inherit;">次のステップは、プログラムがソースコードをどのように処理するかを確認することでした。</font><font style="vertical-align: inherit;">テストとして、さまざまなC ++ソースを取得し、それらを1つのテキストファイルに結合しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
正直なところ、結果はロシア語の場合よりもさらに驚かされました。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5分間のトレーニング</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
くそー、それはほとんど本当のC ++です。</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-keyword">if</span> ( snd_pcm_state_channels = <span class="hljs-number">0</span> ) {<font></font>
        errortext_ = <span class="hljs-string">"rtapialsa::probedeviceopen: esror stream_.buffer stream!"</span>;<font></font>
        errortext_ = errorstream_.str();<font></font>
        <span class="hljs-keyword">goto</span> unlock;<font></font>
}<font></font>
<font></font>
<span class="hljs-keyword">if</span> ( stream_.mode == input &amp;&amp; stream_.mode == output || <span class="hljs-literal">false</span>;
        <span class="hljs-keyword">if</span> ( stream_.state == stream_stopped ) {
        <span class="hljs-keyword">for</span> ( <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;stream_.nuserbuffer[i] ) {
        <span class="hljs-keyword">for</span> (j=<span class="hljs-number">0</span>; j&lt;info.channels;<font></font>
      }<font></font>
    }<font></font>
}<font></font>
</code></pre><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">30分のトレーニング</font></font></b><br>
<br>
<pre><code class="cpp hljs">
<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">maxirecorder::stopstream</span><span class="hljs-params">()</span>
</span>{
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; ainchannels; i++ ) {
        <span class="hljs-keyword">int</span> input=(stream, null;<font></font>
        conternallock( pthread_cond_wate);<font></font>
        <span class="hljs-comment">// this should not ported to the device is a structure are is and the stream the buffer of the interleaved as and the probe the arauliored format for the the stream os and the software and the supported of the is so a a is set the directsound of allocates the reset and real the read the setup the buffer</span>
        <span class="hljs-comment">// this is the setup to the the devices.</span>
        <span class="hljs-comment">// asio will open the supported by the supported buffer are asioned structure.</span>
        <span class="hljs-comment">// this should not have to setup the counting and the proper in the position we mast it alw the aftware configuration.</span>
        <span class="hljs-comment">// this is the the stream and probe the supported be audio for sched/ond changed to this the sample rate it in the counting the fres</span>
        <span class="hljs-comment">// mecorend.</span>
            windevoppart( null, <span class="hljs-number">0</span>, &amp;phase );<font></font>
            possint=&gt;buffersize( <span class="hljs-number">1</span>, bufferlist);<font></font>
        }<font></font>
        }<font></font>
}<font></font>
<span class="hljs-comment">///*********************************************</span>
<span class="hljs-keyword">void</span> maxirecorder::abortdevice( device ) {
    <span class="hljs-keyword">if</span> (<span class="hljs-built_in">cout</span> &lt;&lt; aindeff( thread_cont_start);
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; sample_rates[<span class="hljs-number">0</span>]) {
        <span class="hljs-keyword">if</span> (count == <span class="hljs-keyword">int</span>) {
            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">"checksing of convernion allocation handler ("</span> &lt;&lt; device &lt;&lt; <span class="hljs-string">")."</span>;<font></font>
          errortext_ = errorstream_.str();<font></font>
          <span class="hljs-keyword">return</span> failure;<font></font>
      }<font></font>
    }<font></font>
  }<font></font>
<font></font>
  <span class="hljs-keyword">if</span> ( stream_.userbuffer[i] ) {<font></font>
    errortext_ = <span class="hljs-string">"rtapicore::probedeviceopen: system error ("</span> &lt;&lt; geterrorcode( result ) &lt;&lt; <span class="hljs-string">") getting stream configuration info state."</span>;<font></font>
    error( rterror::warning );<font></font>
    <span class="hljs-keyword">return</span>;<font></font>
  }<font></font>
<font></font>
  <span class="hljs-keyword">if</span> ( stream_.mode == output || stream_.mode == duplex ) {<font></font>
    callbackinfo *info = (<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span> *) callback( stream_.userbuffer[<span class="hljs-number">1</span>], stream_.convertinfo[<span class="hljs-number">0</span>] );
    <span class="hljs-keyword">return</span> info;<font></font>
  }<font></font>
<font></font>
  <span class="hljs-comment">// setup buffer callback for conversion on do any the supported be audio bet that al alinums be of support of the supported buffer</span>
  <span class="hljs-comment">// the buffer size a stream and buffers.</span><font></font>
  info.name = dsdevices[ device ];<font></font>
  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<font></font>
}</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ご覧のとおり、プログラムは関数全体を書くことを「学習」しています。同時に、アスタリスクの付いたコメントで関数を完全に「人道的に」分離し、コードにコメントを配置しました。そのような速度で新しいプログラミング言語を学びたい...もちろん、コードにエラーがあり、もちろんコンパイルされません。ちなみに、私はコードをフォーマットしていませんでした。プログラムは、ブラケットとインデントを「自分自身」にすることも学びました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、これらのプログラムには主なものはありません- </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">意味</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、したがって、まるで夢の中で書かれたかのように、または完全に健康な人によって書かれていないかのように、超現実的に見えます </font><font style="vertical-align: inherit;">それにもかかわらず、結果は印象的です。</font><font style="vertical-align: inherit;">そして、おそらく異なるテキストの生成についてのより深い研究は、実際の患者のいくつかの精神疾患をよりよく理解するのに役立つでしょう。</font><font style="vertical-align: inherit;">ちなみに、コメントで示唆されているように、文法的には関連するが完全に無意味なテキスト（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">統合失調症</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）で</font><font style="vertical-align: inherit;">人が話すような精神疾患</font><font style="vertical-align: inherit;">が存在します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
レクリエーションニューラルネットワークは非常に有望であると考えられており、これは、メモリを持たないMLPなどの「通常の」ネットワークと比較して、実際に大きな前進です。実際、かなり複雑な構造を格納および処理するためのニューラルネットワークの機能は印象的です。これらのテストの後で、単純なニューラルネットワークが簡単に覚えて再現できるとしても、将来AIが「人類にとって最大のリスク」になる可能性があると書いたとき、Ilon Maskはおそらく何かで正しいと最初に思いましたかなり複雑なパターンですが、何十億ものコンポーネントのネットワークで何ができますか？しかし、その一方で、何</font><i><font style="vertical-align: inherit;">を考える</font></i><font style="vertical-align: inherit;">か</font><i><font style="vertical-align: inherit;">を</font></i><font style="vertical-align: inherit;">忘れないでください</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私たちのニューラルネットワークはできません。本質的に、記号の意味を理解せずに記号のシーケンスを機械的に記憶するだけです。これは重要な点です。たとえスーパーコンピュータと巨大なデータセットでニューラルネットワークをトレーニングしたとしても、せいぜい100％正しいが完全に無意味な文を生成する方法を学ぶことになるでしょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、それは哲学から削除されません、記事はまだ開業医のためです。自分で実験したい人のために</font><font style="vertical-align: inherit;">、Python 3.7の</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ソースコード</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">はネタバレの下にあります。このコードは、さまざまなgithubプロジェクトからのコンパイルであり、最良のコードのサンプルではありませんが、そのタスクを実行しているようです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
プログラムの使用にはプログラミングのスキルは必要ありません。Pythonのインストール方法を知っていれば十分です。コマンドラインから開始する例：</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 -モデルの作成とトレーニングおよびテキストの生成：</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
python。\ Keras_textgen.py --text = text_habr.txt --epochs = 10 --out_len = 4000- </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 モデルを学習しないテキスト生成のみ：</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
python。\ Keras_textgen.py --text = text_habr.txt --epochs = 10 --out_len = 4000-生成</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">keras_textgen.py</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-comment"># Force CPU</span>
os.environ[<span class="hljs-string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="hljs-string">"-1"</span>
os.environ[<span class="hljs-string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="hljs-string">'3'</span>  <span class="hljs-comment"># 0 = all messages are logged, 3 - INFO, WARNING, and ERROR messages are not printed</span><font></font>
<font></font>
<font></font>
<span class="hljs-keyword">from</span> keras.callbacks <span class="hljs-keyword">import</span> LambdaCallback
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Dropout, Embedding, LSTM, TimeDistributed
<span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> RMSprop
<span class="hljs-keyword">from</span> keras.utils.data_utils <span class="hljs-keyword">import</span> get_file
<span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter
<span class="hljs-keyword">import</span> pickle
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> io
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> argparse<font></font>
<font></font>
<font></font>
<span class="hljs-comment"># Transforms text to vectors of integer numbers representing in text tokens and back. Handles word and character level tokenization.</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Vectorizer</span>:</span><font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, text, word_tokens, pristine_input, pristine_output</span>):</span><font></font>
        self.word_tokens = word_tokens<font></font>
        self._pristine_input = pristine_input<font></font>
        self._pristine_output = pristine_output<font></font>
<font></font>
        tokens = self._tokenize(text)<font></font>
        <span class="hljs-comment"># print('corpus length:', len(tokens))</span><font></font>
        token_counts = Counter(tokens)<font></font>
        <span class="hljs-comment"># Sort so most common tokens come first in our vocabulary</span>
        tokens = [x[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> token_counts.most_common()]<font></font>
        self._token_indices = {x: i <span class="hljs-keyword">for</span> i, x <span class="hljs-keyword">in</span> enumerate(tokens)}<font></font>
        self._indices_token = {i: x <span class="hljs-keyword">for</span> i, x <span class="hljs-keyword">in</span> enumerate(tokens)}<font></font>
        self.vocab_size = len(tokens)<font></font>
        print(<span class="hljs-string">'Vocab size:'</span>, self.vocab_size)<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_tokenize</span>(<span class="hljs-params">self, text</span>):</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self._pristine_input:<font></font>
            text = text.lower()<font></font>
        <span class="hljs-keyword">if</span> self.word_tokens:
            <span class="hljs-keyword">if</span> self._pristine_input:
                <span class="hljs-keyword">return</span> text.split()
            <span class="hljs-keyword">return</span> Vectorizer.word_tokenize(text)
        <span class="hljs-keyword">return</span> text<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_detokenize</span>(<span class="hljs-params">self, tokens</span>):</span>
        <span class="hljs-keyword">if</span> self.word_tokens:
            <span class="hljs-keyword">if</span> self._pristine_output:
                <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span>.join(tokens)
            <span class="hljs-keyword">return</span> Vectorizer.word_detokenize(tokens)
        <span class="hljs-keyword">return</span> <span class="hljs-string">''</span>.join(tokens)<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">vectorize</span>(<span class="hljs-params">self, text</span>):</span>
        <span class="hljs-string">"""Transforms text to a vector of integers"""</span><font></font>
        tokens = self._tokenize(text)<font></font>
        indices = []<font></font>
        <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> tokens:
            <span class="hljs-keyword">if</span> token <span class="hljs-keyword">in</span> self._token_indices:<font></font>
                indices.append(self._token_indices[token])<font></font>
            <span class="hljs-keyword">else</span>:<font></font>
                print(<span class="hljs-string">'Ignoring unrecognized token:'</span>, token)
        <span class="hljs-keyword">return</span> np.array(indices, dtype=np.int32)<font></font>
<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">unvectorize</span>(<span class="hljs-params">self, vector</span>):</span>
        <span class="hljs-string">"""Transforms a vector of integers back to text"""</span>
        tokens = [self._indices_token[index] <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> vector]
        <span class="hljs-keyword">return</span> self._detokenize(tokens)<font></font>
<font></font>
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">word_detokenize</span>(<span class="hljs-params">tokens</span>):</span>
        <span class="hljs-comment"># A heuristic attempt to undo the Penn Treebank tokenization above. Pass the</span>
        <span class="hljs-comment"># --pristine-output flag if no attempt at detokenizing is desired.</span><font></font>
        regexes = [<font></font>
            <span class="hljs-comment"># Newlines</span>
            (re.compile(<span class="hljs-string">r'[ ]?\\n[ ]?'</span>), <span class="hljs-string">r'\n'</span>),
            <span class="hljs-comment"># Contractions</span>
            (re.compile(<span class="hljs-string">r"\b(can)\s(not)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(d)\s('ye)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(gim)\s(me)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(gon)\s(na)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(got)\s(ta)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(lem)\s(me)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(mor)\s('n)\b"</span>), <span class="hljs-string">r'\1\2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(wan)\s(na)\b"</span>), <span class="hljs-string">r'\1\2'</span>),
            <span class="hljs-comment"># Ending quotes</span>
            (re.compile(<span class="hljs-string">r"([^' ]) ('ll|'re|'ve|n't)\b"</span>), <span class="hljs-string">r"\1\2"</span>),<font></font>
            (re.compile(<span class="hljs-string">r"([^' ]) ('s|'m|'d)\b"</span>), <span class="hljs-string">r"\1\2"</span>),<font></font>
            (re.compile(<span class="hljs-string">r'[ ]?”'</span>), <span class="hljs-string">r'"'</span>),
            <span class="hljs-comment"># Double dashes</span>
            (re.compile(<span class="hljs-string">r'[ ]?--[ ]?'</span>), <span class="hljs-string">r'--'</span>),
            <span class="hljs-comment"># Parens and brackets</span>
            (re.compile(<span class="hljs-string">r'([\[\(\{\&lt;]) '</span>), <span class="hljs-string">r'\1'</span>),<font></font>
            (re.compile(<span class="hljs-string">r' ([\]\)\}\&gt;])'</span>), <span class="hljs-string">r'\1'</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([\]\)\}\&gt;]) ([:;,.])'</span>), <span class="hljs-string">r'\1\2'</span>),
            <span class="hljs-comment"># Punctuation</span>
            (re.compile(<span class="hljs-string">r"([^']) ' "</span>), <span class="hljs-string">r"\1' "</span>),<font></font>
            (re.compile(<span class="hljs-string">r' ([?!\.])'</span>), <span class="hljs-string">r'\1'</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([^\.])\s(\.)([\]\)}&gt;"\']*)\s*$'</span>), <span class="hljs-string">r'\1\2\3'</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([#$]) '</span>), <span class="hljs-string">r'\1'</span>),<font></font>
            (re.compile(<span class="hljs-string">r' ([;%:,])'</span>), <span class="hljs-string">r'\1'</span>),
            <span class="hljs-comment"># Starting quotes</span>
            (re.compile(<span class="hljs-string">r'(“)[ ]?'</span>), <span class="hljs-string">r'"'</span>)<font></font>
        ]<font></font>
<font></font>
        text = <span class="hljs-string">' '</span>.join(tokens)
        <span class="hljs-keyword">for</span> regexp, substitution <span class="hljs-keyword">in</span> regexes:<font></font>
            text = regexp.sub(substitution, text)<font></font>
        <span class="hljs-keyword">return</span> text.strip()<font></font>
<font></font>
<span class="hljs-meta">    @staticmethod</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">word_tokenize</span>(<span class="hljs-params">text</span>):</span>
        <span class="hljs-comment"># Basic word tokenizer based on the Penn Treebank tokenization script, but</span>
        <span class="hljs-comment"># setup to handle multiple sentences. Newline aware, i.e. newlines are</span>
        <span class="hljs-comment"># replaced with a specific token. You may want to consider using a more robust</span>
        <span class="hljs-comment"># tokenizer as a preprocessing step, and using the --pristine-input flag.</span><font></font>
        regexes = [<font></font>
            <span class="hljs-comment"># Starting quotes</span>
            (re.compile(<span class="hljs-string">r'(\s)"'</span>), <span class="hljs-string">r'\1 “ '</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([ (\[{&lt;])"'</span>), <span class="hljs-string">r'\1 “ '</span>),
            <span class="hljs-comment"># Punctuation</span>
            (re.compile(<span class="hljs-string">r'([:,])([^\d])'</span>), <span class="hljs-string">r' \1 \2'</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([:,])$'</span>), <span class="hljs-string">r' \1 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r'\.\.\.'</span>), <span class="hljs-string">r' ... '</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([;@#$%&amp;])'</span>), <span class="hljs-string">r' \1 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r'([?!\.])'</span>), <span class="hljs-string">r' \1 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"([^'])' "</span>), <span class="hljs-string">r"\1 ' "</span>),
            <span class="hljs-comment"># Parens and brackets</span>
            (re.compile(<span class="hljs-string">r'([\]\[\(\)\{\}\&lt;\&gt;])'</span>), <span class="hljs-string">r' \1 '</span>),
            <span class="hljs-comment"># Double dashes</span>
            (re.compile(<span class="hljs-string">r'--'</span>), <span class="hljs-string">r' -- '</span>),
            <span class="hljs-comment"># Ending quotes</span>
            (re.compile(<span class="hljs-string">r'"'</span>), <span class="hljs-string">r' ” '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"([^' ])('s|'m|'d) "</span>), <span class="hljs-string">r"\1 \2 "</span>),<font></font>
            (re.compile(<span class="hljs-string">r"([^' ])('ll|'re|'ve|n't) "</span>), <span class="hljs-string">r"\1 \2 "</span>),
            <span class="hljs-comment"># Contractions</span>
            (re.compile(<span class="hljs-string">r"\b(can)(not)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(d)('ye)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(gim)(me)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(gon)(na)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(got)(ta)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(lem)(me)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(mor)('n)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),<font></font>
            (re.compile(<span class="hljs-string">r"\b(wan)(na)\b"</span>), <span class="hljs-string">r' \1 \2 '</span>),
            <span class="hljs-comment"># Newlines</span>
            (re.compile(<span class="hljs-string">r'\n'</span>), <span class="hljs-string">r' \\n '</span>)<font></font>
        ]<font></font>
<font></font>
        text = <span class="hljs-string">" "</span> + text + <span class="hljs-string">" "</span>
        <span class="hljs-keyword">for</span> regexp, substitution <span class="hljs-keyword">in</span> regexes:<font></font>
            text = regexp.sub(substitution, text)<font></font>
        <span class="hljs-keyword">return</span> text.split()<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_create_sequences</span>(<span class="hljs-params">vector, seq_length, seq_step</span>):</span>
    <span class="hljs-comment"># Take strips of our vector at seq_step intervals up to our seq_length</span>
    <span class="hljs-comment"># and cut those strips into seq_length sequences</span><font></font>
    passes = []<font></font>
    <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, seq_length, seq_step):<font></font>
        pass_samples = vector[offset:]<font></font>
        num_pass_samples = pass_samples.size // seq_length<font></font>
        pass_samples = np.resize(pass_samples,<font></font>
                                 (num_pass_samples, seq_length))<font></font>
        passes.append(pass_samples)<font></font>
    <span class="hljs-comment"># Stack our sequences together. This will technically leave a few "breaks"</span>
    <span class="hljs-comment"># in our sequence chain where we've looped over are entire dataset and</span>
    <span class="hljs-comment"># return to the start, but with large datasets this should be neglegable</span>
    <span class="hljs-keyword">return</span> np.concatenate(passes)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span>  <span class="hljs-title">shape_for_stateful_rnn</span>(<span class="hljs-params">data, batch_size, seq_length, seq_step</span>):</span>
    <span class="hljs-string">"""
    Reformat our data vector into input and target sequences to feed into our RNN. Tricky with stateful RNNs.
    """</span>
    <span class="hljs-comment"># Our target sequences are simply one timestep ahead of our input sequences.</span>
    <span class="hljs-comment"># e.g. with an input vector "wherefore"...</span>
    <span class="hljs-comment"># targets:   h e r e f o r e</span>
    <span class="hljs-comment"># predicts   ^ ^ ^ ^ ^ ^ ^ ^</span>
    <span class="hljs-comment"># inputs:    w h e r e f o r</span>
    inputs = data[:<span class="hljs-number">-1</span>]<font></font>
    targets = data[<span class="hljs-number">1</span>:]<font></font>
<font></font>
    <span class="hljs-comment"># We split our long vectors into semi-redundant seq_length sequences</span><font></font>
    inputs = _create_sequences(inputs, seq_length, seq_step)<font></font>
    targets = _create_sequences(targets, seq_length, seq_step)<font></font>
<font></font>
    <span class="hljs-comment"># Make sure our sequences line up across batches for stateful RNNs</span><font></font>
    inputs = _batch_sort_for_stateful_rnn(inputs, batch_size)<font></font>
    targets = _batch_sort_for_stateful_rnn(targets, batch_size)<font></font>
<font></font>
    <span class="hljs-comment"># Our target data needs an extra axis to work with the sparse categorical</span>
    <span class="hljs-comment"># crossentropy loss function</span><font></font>
    targets = targets[:, :, np.newaxis]<font></font>
    <span class="hljs-keyword">return</span> inputs, targets<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_batch_sort_for_stateful_rnn</span>(<span class="hljs-params">sequences, batch_size</span>):</span>
    <span class="hljs-comment"># Now the tricky part, we need to reformat our data so the first</span>
    <span class="hljs-comment"># sequence in the nth batch picks up exactly where the first sequence</span>
    <span class="hljs-comment"># in the (n - 1)th batch left off, as the RNN cell state will not be</span>
    <span class="hljs-comment"># reset between batches in the stateful model.</span>
    num_batches = sequences.shape[<span class="hljs-number">0</span>] // batch_size<font></font>
    num_samples = num_batches * batch_size<font></font>
    reshuffled = np.zeros((num_samples, sequences.shape[<span class="hljs-number">1</span>]), dtype=np.int32)
    <span class="hljs-keyword">for</span> batch_index <span class="hljs-keyword">in</span> range(batch_size):
        <span class="hljs-comment"># Take a slice of num_batches consecutive samples</span><font></font>
        slice_start = batch_index * num_batches<font></font>
        slice_end = slice_start + num_batches<font></font>
        index_slice = sequences[slice_start:slice_end, :]<font></font>
        <span class="hljs-comment"># Spread it across each of our batches in the same index position</span><font></font>
        reshuffled[batch_index::batch_size, :] = index_slice<font></font>
    <span class="hljs-keyword">return</span> reshuffled<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_data</span>(<span class="hljs-params">data_file, word_tokens, pristine_input, pristine_output, batch_size, seq_length=<span class="hljs-number">50</span>, seq_step=<span class="hljs-number">25</span></span>):</span>
    <span class="hljs-keyword">global</span> vectorizer<font></font>
<font></font>
    <span class="hljs-keyword">try</span>:
        <span class="hljs-keyword">with</span> open(data_file, encoding=<span class="hljs-string">'utf-8'</span>) <span class="hljs-keyword">as</span> input_file:<font></font>
            text = input_file.read()<font></font>
    <span class="hljs-keyword">except</span> FileNotFoundError:<font></font>
        print(<span class="hljs-string">"No input.txt in data_dir"</span>)<font></font>
        sys.exit(<span class="hljs-number">1</span>)<font></font>
<font></font>
    skip_validate = <span class="hljs-literal">True</span>
    <span class="hljs-comment"># try:</span>
    <span class="hljs-comment">#     with open(os.path.join(data_dir, 'validate.txt'), encoding='utf-8') as validate_file:</span>
    <span class="hljs-comment">#         text_val = validate_file.read()</span>
    <span class="hljs-comment">#         skip_validate = False</span>
    <span class="hljs-comment"># except FileNotFoundError:</span>
    <span class="hljs-comment">#     pass  # Validation text optional</span><font></font>
<font></font>
    <span class="hljs-comment"># Find some good default seed string in our source text.</span>
    <span class="hljs-comment"># self.seeds = find_random_seeds(text)</span>
    <span class="hljs-comment"># Include our validation texts with our vectorizer</span>
    all_text = text <span class="hljs-keyword">if</span> skip_validate <span class="hljs-keyword">else</span> <span class="hljs-string">'\n'</span>.join([text, text_val])<font></font>
<font></font>
    vectorizer = Vectorizer(all_text, word_tokens, pristine_input, pristine_output)<font></font>
    data = vectorizer.vectorize(text)<font></font>
    x, y = shape_for_stateful_rnn(data, batch_size, seq_length, seq_step)<font></font>
    print(<span class="hljs-string">"Word_tokens:"</span>, word_tokens)<font></font>
    print(<span class="hljs-string">'x.shape:'</span>, x.shape)<font></font>
    print(<span class="hljs-string">'y.shape:'</span>, y.shape)<font></font>
<font></font>
    <span class="hljs-keyword">if</span> skip_validate:
        <span class="hljs-keyword">return</span> x, y, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, vectorizer<font></font>
<font></font>
    data_val = vectorizer.vectorize(text_val)<font></font>
    x_val, y_val = shape_for_stateful_rnn(data_val, batch_size,<font></font>
                                          seq_length, seq_step)<font></font>
    print(<span class="hljs-string">'x_val.shape:'</span>, x_val.shape)<font></font>
    print(<span class="hljs-string">'y_val.shape:'</span>, y_val.shape)
    <span class="hljs-keyword">return</span> x, y, x_val, y_val, vectorizer<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_model</span>(<span class="hljs-params">batch_size, vocab_size, embedding_size=<span class="hljs-number">64</span>, rnn_size=<span class="hljs-number">128</span>, num_layers=<span class="hljs-number">2</span></span>):</span>
    <span class="hljs-comment"># Conversely if your data is large (more than about 2MB), feel confident to increase rnn_size and train a bigger model (see details of training below).</span>
    <span class="hljs-comment"># It will work significantly better. For example with 6MB you can easily go up to rnn_size 300 or even more.</span><font></font>
    model = Sequential()<font></font>
    model.add(Embedding(vocab_size, embedding_size, batch_input_shape=(batch_size, <span class="hljs-literal">None</span>)))
    <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> range(num_layers):<font></font>
        model.add(LSTM(rnn_size, stateful=<span class="hljs-literal">True</span>, return_sequences=<span class="hljs-literal">True</span>))<font></font>
        model.add(Dropout(<span class="hljs-number">0.2</span>))<font></font>
    model.add(TimeDistributed(Dense(vocab_size, activation=<span class="hljs-string">'softmax'</span>)))<font></font>
    model.compile(loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>, optimizer=<span class="hljs-string">'rmsprop'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-keyword">return</span> model<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">model, x, y, x_val, y_val, batch_size, num_epochs</span>):</span>
    print(<span class="hljs-string">'Training...'</span>)
    <span class="hljs-comment"># print("Shape:", x.shape, y.shape)</span>
    <span class="hljs-comment"># print(num_epochs, batch_size, x[0], y[0])</span><font></font>
    train_start = time.time()<font></font>
    validation_data = (x_val, y_val) <span class="hljs-keyword">if</span> (x_val <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>
    callbacks = <span class="hljs-literal">None</span><font></font>
    model.fit(x, y, validation_data=validation_data,<font></font>
                    batch_size=batch_size,<font></font>
                    shuffle=<span class="hljs-literal">False</span>,<font></font>
                    epochs=num_epochs,<font></font>
                    verbose=<span class="hljs-number">1</span>,<font></font>
                    callbacks=callbacks)<font></font>
    <span class="hljs-comment"># self.update_sample_model_weights()</span><font></font>
    train_end = time.time()<font></font>
    print(<span class="hljs-string">'Training time'</span>, train_end - train_start)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_preds</span>(<span class="hljs-params">preds, temperature=<span class="hljs-number">1.0</span></span>):</span>
    <span class="hljs-string">"""
    Samples an unnormalized array of probabilities. Use temperature to
    flatten/amplify the probabilities.
    """</span><font></font>
    preds = np.asarray(preds).astype(np.float64)<font></font>
    <span class="hljs-comment"># Add a tiny positive number to avoid invalid log(0)</span><font></font>
    preds += np.finfo(np.float64).tiny<font></font>
    preds = np.log(preds) / temperature<font></font>
    exp_preds = np.exp(preds)<font></font>
    preds = exp_preds / np.sum(exp_preds)<font></font>
    probas = np.random.multinomial(<span class="hljs-number">1</span>, preds, <span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> np.argmax(probas)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate</span>(<span class="hljs-params">model, vectorizer, seed, length=<span class="hljs-number">100</span>, diversity=<span class="hljs-number">0.5</span></span>):</span><font></font>
    seed_vector = vectorizer.vectorize(seed)<font></font>
<font></font>
    <span class="hljs-comment"># Feed in seed string</span>
    print(<span class="hljs-string">"Seed:"</span>, seed, end=<span class="hljs-string">' '</span> <span class="hljs-keyword">if</span> vectorizer.word_tokens <span class="hljs-keyword">else</span> <span class="hljs-string">''</span>)<font></font>
    model.reset_states()<font></font>
    preds = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> char_index <span class="hljs-keyword">in</span> np.nditer(seed_vector):<font></font>
        preds = model.predict(np.array([[char_index]]), verbose=<span class="hljs-number">0</span>)<font></font>
<font></font>
    sampled_indices = []  <span class="hljs-comment"># np.array([], dtype=np.int32)</span>
    <span class="hljs-comment"># Sample the model one token at a time</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(length):<font></font>
        char_index = <span class="hljs-number">0</span>
        <span class="hljs-keyword">if</span> preds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
            char_index = sample_preds(preds[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>], diversity)<font></font>
        sampled_indices.append(char_index)  <span class="hljs-comment"># = np.append(sampled_indices, char_index)</span>
        preds = model.predict(np.array([[char_index]]), verbose=<span class="hljs-number">0</span>)<font></font>
    sample = vectorizer.unvectorize(sampled_indices)<font></font>
    <span class="hljs-keyword">return</span> sample<font></font>
<font></font>
<font></font>
<font></font>
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<font></font>
<font></font>
    batch_size = <span class="hljs-number">32</span>  <span class="hljs-comment"># Batch size for each train</span>
    num_epochs = <span class="hljs-number">10</span>  <span class="hljs-comment"># Number of epochs of training</span>
    out_len = <span class="hljs-number">200</span>  <span class="hljs-comment"># Length of the output phrase</span>
    seq_length = <span class="hljs-number">50</span>  <span class="hljs-comment"># 50  # Determines, how long phrases will be used for training</span>
    use_words = <span class="hljs-literal">False</span>   <span class="hljs-comment"># Use words instead of characters (slower speed, bigger vocabulary)</span>
    data_file = <span class="hljs-string">"text_habr.txt"</span>  <span class="hljs-comment"># Source text file</span>
    seed = <span class="hljs-string">"A"</span>  <span class="hljs-comment"># Initial symbol of the text</span><font></font>
<font></font>
    parser = argparse.ArgumentParser()<font></font>
    parser.add_argument(<span class="hljs-string">"-t"</span>, <span class="hljs-string">"--text"</span>, action=<span class="hljs-string">"store"</span>, required=<span class="hljs-literal">False</span>, dest=<span class="hljs-string">"text"</span>, help=<span class="hljs-string">"Input text file"</span>)<font></font>
    parser.add_argument(<span class="hljs-string">"-e"</span>, <span class="hljs-string">"--epochs"</span>, action=<span class="hljs-string">"store"</span>, required=<span class="hljs-literal">False</span>, dest=<span class="hljs-string">"epochs"</span>, help=<span class="hljs-string">"Number of training epochs"</span>)<font></font>
    parser.add_argument(<span class="hljs-string">"-p"</span>, <span class="hljs-string">"--phrase_len"</span>, action=<span class="hljs-string">"store"</span>, required=<span class="hljs-literal">False</span>, dest=<span class="hljs-string">"phrase_len"</span>, help=<span class="hljs-string">"Phrase analyse length"</span>)<font></font>
    parser.add_argument(<span class="hljs-string">"-o"</span>, <span class="hljs-string">"--out_len"</span>, action=<span class="hljs-string">"store"</span>, required=<span class="hljs-literal">False</span>, dest=<span class="hljs-string">"out_len"</span>, help=<span class="hljs-string">"Output text length"</span>)<font></font>
    parser.add_argument(<span class="hljs-string">"-g"</span>, <span class="hljs-string">"--generate"</span>, action=<span class="hljs-string">"store_true"</span>, required=<span class="hljs-literal">False</span>, dest=<span class="hljs-string">'generate'</span>, help=<span class="hljs-string">"Generate output only without training"</span>)<font></font>
    args = parser.parse_args()<font></font>
    <span class="hljs-keyword">if</span> args.text <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
        data_file = args.text<font></font>
    <span class="hljs-keyword">if</span> args.epochs <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
        num_epochs = int(args.epochs)<font></font>
    <span class="hljs-keyword">if</span> args.phrase_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
        seq_length = int(args.phrase_len)<font></font>
    <span class="hljs-keyword">if</span> args.out_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
        out_len = int(args.out_len)<font></font>
<font></font>
    <span class="hljs-comment"># Load text data</span>
    pristine_input, pristine_output = <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span><font></font>
    x, y, x_val, y_val, vectorizer = load_data(data_file, use_words, pristine_input, pristine_output, batch_size, seq_length)<font></font>
<font></font>
    model_file = data_file.lower().replace(<span class="hljs-string">'.txt'</span>, <span class="hljs-string">'.h5'</span>)<font></font>
<font></font>
    <span class="hljs-keyword">if</span> args.generate <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>:
        <span class="hljs-comment"># Make model</span><font></font>
        model = make_model(batch_size, vectorizer.vocab_size)<font></font>
        <span class="hljs-comment"># Train model</span><font></font>
        train(model, x, y, x_val, y_val, batch_size, num_epochs)<font></font>
        <span class="hljs-comment"># Save model to file</span><font></font>
        model.save(filepath=model_file)<font></font>
<font></font>
    model = keras.models.load_model(model_file)<font></font>
    predict_model = make_model(<span class="hljs-number">1</span>, vectorizer.vocab_size)<font></font>
    predict_model.set_weights(model.get_weights())<font></font>
<font></font>
    <span class="hljs-comment"># Generate phrases</span><font></font>
    res = generate(predict_model, vectorizer, seed=seed, length=out_len)<font></font>
    print(res)<font></font>
</code></pre><br>
</div></div><br><font style="vertical-align: inherit;"><s><font style="vertical-align: inherit;">これは、Habrで記事を書くのに役立つ</font></s><font style="vertical-align: inherit;"> 
、とても</font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ファンキーで</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実用的なテキストジェネレータで</font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あることがわかりました</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。特に興味深いのは、大きなテキストとトレーニングの多数の反復でテストすることです。もし誰かが高速のコンピューターにアクセスできれば、結果を見るのは興味深いでしょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トピックをさらに詳しく知りたい場合は、RNNと詳細な例の使用に関する適切な説明が</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://karpathy.github.io/2015/05/21/rnn-effectiveness/にあり</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS：そして最後に、いくつかの詩;）テキストの書式設定と星の追加でさえ、「それ自体である」というのは私によって行われなかったことに注目するのは興味深いことです。次のステップは、絵を描いたり音楽を作ったりする可能性をチェックすることです。ニューラルネットワークはここで非常に有望だと思います。</font></font><br>
<br>
<i>x x x<br>
<br>
     —       .<br>
    <br>
   .<br>
<br>
x x x<br>
<br>
      <br>
   ,<br>
   <br>
    .<br>
<br>
    ,<br>
    ,<br>
     .<br>
<br>
      ,<br>
      .<br>
     <br>
   .<br>
<br>
x x x<br>
<br>
   <br>
   .<br>
 , ,    <br>
  .<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
o </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
フライトで牛乳を</font><font style="vertical-align: inherit;">楽しみながら和琴</font><font style="vertical-align: inherit;">で</font><font style="vertical-align: inherit;">楽しんでください</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ああ、あなたはバラです</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。あなたの手に雲</font><font style="vertical-align: inherit;">の</font><font style="vertical-align: inherit;">光が</font><font style="vertical-align: inherit;">輝い</font><font style="vertical-align: inherit;">ています。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして夜明けに</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
、私はあなたのよう</font><font style="vertical-align: inherit;">に転がりました</font><font style="vertical-align: inherit;">、私の騎士！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼は骨で</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
は</font><font style="vertical-align: inherit;">なく夕方に仕え、</font><font style="vertical-align: inherit;">ターニャの夜には</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
、一種の悲しみのように、</font><font style="vertical-align: inherit;">青く</font><font style="vertical-align: inherit;">光っていました。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
そして、言葉による学習のモードの最後の数節。ここで韻は消えたが、何らかの意味が現れた（？）。</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">そしてあなたは、炎から、</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
星です。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
遠くの人と話しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
明日、あなたは、あなたを心配しています。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「雨が降り、</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして殺人者の故郷へ、姫姫</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
、</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼の顔のために。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
xxx </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
o羊飼い、</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
春に</font><font style="vertical-align: inherit;">チャンバー</font><font style="vertical-align: inherit;">を木立に振ります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
家の中心を通って池に行きます</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
とマウスの</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
元気なニジニノヴゴロドの鐘。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、恐れることはありません。朝の風、</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
道から、鉄の棒</font><font style="vertical-align: inherit;">
で、貧しいラキットの</font><font style="vertical-align: inherit;">
池</font><font style="vertical-align: inherit;">で</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
カキを曲げ</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">て</font><font style="vertical-align: inherit;">考えました</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja470021/index.html">GRASPテンプレートのコンテキストにおける貧弱でリッチなモデル</a></li>
<li><a href="../ja470023/index.html">テレボットライブラリパート3を使用して、Pythonでテレグラムボットの支払いを作成しています</a></li>
<li><a href="../ja470027/index.html">VKハッカソン2019（現状のまま）</a></li>
<li><a href="../ja470029/index.html">極度の教育学：長期治療で子供と一緒に働くことについて「教える」</a></li>
<li><a href="../ja470033/index.html">F＃2：FSI環境</a></li>
<li><a href="../ja470037/index.html">F＃3：テキストのフォーマット</a></li>
<li><a href="../ja470047/index.html">彼女が振り返ったのか、またはAWS経由で自分のデータセンターに振り返ったかを確認しました。</a></li>
<li><a href="../ja470051/index.html">神経科学：私たちの脳が最もよく機能するとき、テクノロジーがどのようにそれを助けることができるか</a></li>
<li><a href="../ja470055/index.html">Visual Studio for MacでのソリューションレベルのNuGetパッケージ管理の紹介</a></li>
<li><a href="../ja470057/index.html">Visual Studio for Mac：5つのクールな新機能</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤶🏾 🤽 🤟🏾 Ensembel dari jaringan saraf dengan PyTorch dan Sklearn ⛳️ 👩‍👩‍👧 👧🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jaringan saraf cukup populer. Keuntungan utama mereka adalah bahwa mereka dapat menggeneralisasi data yang agak rumit di mana algoritma lain menunjukk...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Ensembel dari jaringan saraf dengan PyTorch dan Sklearn</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/489058/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jaringan saraf cukup populer. </font><font style="vertical-align: inherit;">Keuntungan utama mereka adalah bahwa mereka dapat menggeneralisasi data yang agak rumit di mana algoritma lain menunjukkan kualitas rendah. </font><font style="vertical-align: inherit;">Tetapi bagaimana jika kualitas jaringan saraf masih belum memuaskan?</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dan di sini ansambel datang untuk menyelamatkan ...</font></font></p><br>
<h3 id="chto-takoe-ansambli"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apa itu ansambel</font></font></h3><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ensembel algoritma pembelajaran mesin adalah penggunaan beberapa model (tidak harus berbeda), bukan satu. </font><font style="vertical-align: inherit;">Artinya, pertama-tama kita melatih masing-masing model, dan kemudian menggabungkan prediksi mereka. </font><font style="vertical-align: inherit;">Ternyata model kami bersama-sama membentuk satu model yang lebih kompleks (dalam hal kemampuan generalisasi - kemampuan untuk "memahami" data), yang sering disebut </font></font><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">metamodel</font></font></em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Paling sering, metamodel dilatih bukan pada sampel data awal kami, tetapi pada prediksi model lain. </font><font style="vertical-align: inherit;">Tampaknya memperhitungkan pengalaman semua model, dan ini membantu mengurangi kesalahan.</font></font></p><a name="habracut"></a><br>
<h3 id="plan"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rencana</font></font></h3><br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pertama kita melihat satu model PyTorch sederhana dan mendapatkan kualitasnya.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kemudian kami akan mengumpulkan beberapa model menggunakan Scikit-belajar dan belajar bagaimana mencapai level yang lebih tinggi</font></font></li>
</ol><br>
<h2 id="odna-edinstvennaya-model"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Satu model tunggal</font></font></h2><br>
<p>,     Digits  Sklearn,           :</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_digits
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
<font></font>
<span class="hljs-comment"># ,  </span>
x, y = load_digits(n_class=<span class="hljs-number">10</span>, return_X_y=<span class="hljs-literal">True</span>)</code></pre><br>
<p>,    :</p><br>
<pre><code class="python hljs">print(x.shape)
<span class="hljs-meta">&gt;&gt;&gt; </span>(<span class="hljs-number">1797</span>, <span class="hljs-number">64</span>)<font></font>
print(np.unique(y))<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>array([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>])</code></pre><br>
<pre><code class="python hljs">index = <span class="hljs-number">0</span><font></font>
<font></font>
print(y[index])<font></font>
plt.imshow(x[index].reshape(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>), cmap=<span class="hljs-string">"Greys"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/o4/ij/xw/o4ijxwehip-ohrmx0drg7ma3kje.png" alt="Jari kaki yang indah"></p><br>
<pre><code class="python hljs">x[index]
<span class="hljs-meta">&gt;&gt;&gt; </span>array([ <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">5.</span>, <span class="hljs-number">13.</span>,  <span class="hljs-number">9.</span>,  <span class="hljs-number">1.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>, <span class="hljs-number">13.</span>, <span class="hljs-number">15.</span>, <span class="hljs-number">10.</span>,
       <span class="hljs-number">15.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">3.</span>, <span class="hljs-number">15.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">0.</span>, <span class="hljs-number">11.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">4.</span>,
       <span class="hljs-number">12.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">9.</span>,  <span class="hljs-number">8.</span>,
        <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">4.</span>, <span class="hljs-number">11.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>, <span class="hljs-number">12.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">2.</span>, <span class="hljs-number">14.</span>,  <span class="hljs-number">5.</span>,
       <span class="hljs-number">10.</span>, <span class="hljs-number">12.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">6.</span>, <span class="hljs-number">13.</span>, <span class="hljs-number">10.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>])</code></pre><br>
<p>,     0  15. ,  :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
<font></font>
<span class="hljs-comment">#      </span>
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.2</span>,<font></font>
                                                    shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-number">42</span>)<font></font>
print(x_train.shape)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>(<span class="hljs-number">1437</span>, <span class="hljs-number">64</span>)<font></font>
print(x_test.shape)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>(<span class="hljs-number">360</span>, <span class="hljs-number">64</span>)</code></pre><br>
<p> StandardScaler:        -1  1.      ,       —  score       score'   :</p><br>
<pre><code class="python hljs">scaler = StandardScaler()<font></font>
scaler.fit(x_train)</code></pre><br>
<p>   :</p><br>
<pre><code class="python hljs">x_train_scaled = scaler.transform(x_train)<font></font>
x_test_scaled = scaler.transform(x_test)</code></pre><br>
<h3 id="vremya-torcha"> Torch'!</h3><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset, DataLoader
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam</code></pre><br>
<p>      :</p><br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SimpleCNN</span>(<span class="hljs-params">nn.Module</span>):</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
    super(SimpleCNN, self).__init__()<font></font>
<font></font>
    <span class="hljs-comment">#  </span>
    self.conv1 = nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>)<font></font>
    self.conv1_s = nn.Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">2</span>)<font></font>
    self.conv2 = nn.Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<font></font>
    self.conv2_s = nn.Conv2d(in_channels=<span class="hljs-number">6</span>, out_channels=<span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<font></font>
    self.conv3 = nn.Conv2d(in_channels=<span class="hljs-number">6</span>, out_channels=<span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<font></font>
    self.conv3_s = nn.Conv2d(in_channels=<span class="hljs-number">10</span>, out_channels=<span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<font></font>
<font></font>
    self.flatten = nn.Flatten()<font></font>
    <span class="hljs-comment">#   </span>
    self.fc1 = nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)<font></font>
<font></font>
  <span class="hljs-comment">#   ""   </span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><font></font>
    x = F.relu(self.conv1(x))<font></font>
    x = F.relu(self.conv1_s(x))<font></font>
    x = F.relu(self.conv2(x))<font></font>
    x = F.relu(self.conv2_s(x))<font></font>
    x = F.relu(self.conv3(x))<font></font>
    x = F.relu(self.conv3_s(x))<font></font>
<font></font>
    x = self.flatten(x)<font></font>
    x = self.fc1(x)<font></font>
    x = F.softmax(x)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> x</code></pre><br>
<p>   :</p><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">64</span> <span class="hljs-comment">#  </span>
learning_rate = <span class="hljs-number">1e-3</span> <span class="hljs-comment">#  </span>
epochs = <span class="hljs-number">200</span> <span class="hljs-comment">#   </span></code></pre><br>
<p>    ,    PyTorch:</p><br>
<pre><code class="python hljs">x_train_tensor = torch.tensor(x_train_scaled.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>).astype(np.float32))<font></font>
x_test_tensor = torch.tensor(x_test_scaled.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>).astype(np.float32))<font></font>
<font></font>
y_train_tensor = torch.tensor(y_train.astype(np.long))<font></font>
y_test_tensor = torch.tensor(y_test.astype(np.long))</code></pre><br>
<p> PyTorch      ,    —   .   — ,     X  y   ( ),  DataLoader — ,       &lt;X, y&gt;   64 :</p><br>
<pre><code class="python hljs">train_dataset = TensorDataset(x_train_tensor, y_train_tensor)<font></font>
train_loader = DataLoader(train_dataset, batch_size=batch_size)<font></font>
<font></font>
test_dataset = TensorDataset(x_test_tensor, y_test_tensor)<font></font>
test_loader = DataLoader(test_dataset, batch_size=batch_size)</code></pre><br>
<p>,     :</p><br>
<pre><code class="python hljs">simple_cnn = SimpleCNN().cuda() <span class="hljs-comment">#   gpu,   ,  </span><font></font>
criterion = nn.CrossEntropyLoss()<font></font>
optimizer = Adam(simple_cnn.parameters(), lr=learning_rate)</code></pre><br>
<p>  :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs): <span class="hljs-comment">#  200 </span><font></font>
  simple_cnn.train()<font></font>
  train_samples_count = <span class="hljs-number">0</span> <span class="hljs-comment">#   ,     </span>
  true_train_samples_count = <span class="hljs-number">0</span> <span class="hljs-comment">#    </span>
  running_loss = <span class="hljs-number">0</span><font></font>
<font></font>
  <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_loader:<font></font>
    x_data = batch[<span class="hljs-number">0</span>].cuda() <span class="hljs-comment">#      gpu</span>
    y_data = batch[<span class="hljs-number">1</span>].cuda()<font></font>
<font></font>
    y_pred = simple_cnn(x_data)<font></font>
    loss = criterion(y_pred, y_data)<font></font>
<font></font>
    optimizer.zero_grad()<font></font>
    loss.backward()<font></font>
    optimizer.step() <span class="hljs-comment">#   </span><font></font>
<font></font>
    running_loss += loss.item()<font></font>
<font></font>
    y_pred = y_pred.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">False</span>)<font></font>
    true_classified = (y_pred == y_data).sum().item() <span class="hljs-comment">#       </span><font></font>
    true_train_samples_count += true_classified<font></font>
    train_samples_count += len(x_data) <span class="hljs-comment">#   </span><font></font>
<font></font>
  train_accuracy = true_train_samples_count / train_samples_count<font></font>
  print(<span class="hljs-string">f"[<span class="hljs-subst">{epoch}</span>] train loss: <span class="hljs-subst">{running_loss}</span>, accuracy: <span class="hljs-subst">{round(train_accuracy, <span class="hljs-number">4</span>)}</span>"</span>) <span class="hljs-comment">#  </span><font></font>
<font></font>
  <span class="hljs-comment">#   </span><font></font>
  simple_cnn.eval()<font></font>
  test_samples_count = <span class="hljs-number">0</span>
  true_test_samples_count = <span class="hljs-number">0</span>
  running_loss = <span class="hljs-number">0</span><font></font>
<font></font>
  <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> test_loader:<font></font>
    x_data = batch[<span class="hljs-number">0</span>].cuda()<font></font>
    y_data = batch[<span class="hljs-number">1</span>].cuda()<font></font>
<font></font>
    y_pred = simple_cnn(x_data)<font></font>
    loss = criterion(y_pred, y_data)<font></font>
<font></font>
    loss.backward()<font></font>
<font></font>
    running_loss += loss.item()<font></font>
<font></font>
    y_pred = y_pred.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">False</span>)<font></font>
    true_classified = (y_pred == y_data).sum().item()<font></font>
    true_test_samples_count += true_classified<font></font>
    test_samples_count += len(x_data)<font></font>
<font></font>
  test_accuracy = true_test_samples_count / test_samples_count<font></font>
  print(<span class="hljs-string">f"[<span class="hljs-subst">{epoch}</span>] test loss: <span class="hljs-subst">{running_loss}</span>, accuracy: <span class="hljs-subst">{round(test_accuracy, <span class="hljs-number">4</span>)}</span>"</span>)</code></pre><br>
<div class="spoiler"><b class="spoiler_title">,  </b><div class="spoiler_text"><p>-   Torch'  ,          .   .    20 .</p><br>
<pre><code class="plaintext hljs">[180] train loss: 40.52328181266785, accuracy: 0.6966<font></font>
[180] test loss: 10.813781499862671, accuracy: 0.6583<font></font>
[181] train loss: 40.517325043678284, accuracy: 0.6966<font></font>
[181] test loss: 10.811877608299255, accuracy: 0.6611<font></font>
[182] train loss: 40.517088294029236, accuracy: 0.6966<font></font>
[182] test loss: 10.814386487007141, accuracy: 0.6611<font></font>
[183] train loss: 40.515315651893616, accuracy: 0.6966<font></font>
[183] test loss: 10.812204122543335, accuracy: 0.6611<font></font>
[184] train loss: 40.5108939409256, accuracy: 0.6966<font></font>
[184] test loss: 10.808713555335999, accuracy: 0.6639<font></font>
[185] train loss: 40.50885498523712, accuracy: 0.6966<font></font>
[185] test loss: 10.80833113193512, accuracy: 0.6639<font></font>
[186] train loss: 40.50892996788025, accuracy: 0.6966<font></font>
[186] test loss: 10.809209108352661, accuracy: 0.6639<font></font>
[187] train loss: 40.508036971092224, accuracy: 0.6966<font></font>
[187] test loss: 10.806900978088379, accuracy: 0.6667<font></font>
[188] train loss: 40.507275462150574, accuracy: 0.6966<font></font>
[188] test loss: 10.79791784286499, accuracy: 0.6611<font></font>
[189] train loss: 40.50368785858154, accuracy: 0.6966<font></font>
[189] test loss: 10.799399137496948, accuracy: 0.6667<font></font>
[190] train loss: 40.499858379364014, accuracy: 0.6966<font></font>
[190] test loss: 10.795265793800354, accuracy: 0.6611<font></font>
[191] train loss: 40.498780846595764, accuracy: 0.6966<font></font>
[191] test loss: 10.796114206314087, accuracy: 0.6639<font></font>
[192] train loss: 40.497228503227234, accuracy: 0.6966<font></font>
[192] test loss: 10.790620803833008, accuracy: 0.6639<font></font>
[193] train loss: 40.44325613975525, accuracy: 0.6973<font></font>
[193] test loss: 10.657087206840515, accuracy: 0.7<font></font>
[194] train loss: 39.62049174308777, accuracy: 0.7495<font></font>
[194] test loss: 10.483307123184204, accuracy: 0.7222<font></font>
[195] train loss: 39.24516046047211, accuracy: 0.7613<font></font>
[195] test loss: 10.462445378303528, accuracy: 0.7278<font></font>
[196] train loss: 39.16947162151337, accuracy: 0.762<font></font>
[196] test loss: 10.488057255744934, accuracy: 0.7222<font></font>
[197] train loss: 39.196797251701355, accuracy: 0.7634<font></font>
[197] test loss: 10.502906918525696, accuracy: 0.7222<font></font>
[198] train loss: 39.395434617996216, accuracy: 0.7537<font></font>
[198] test loss: 10.354896545410156, accuracy: 0.7472<font></font>
[199] train loss: 39.331292152404785, accuracy: 0.7509<font></font>
[199] test loss: 10.367400050163269, accuracy: 0.7389</code></pre><br>
<p> ,   :        .</p></div></div><br>
<p>,    :  <strong>74%</strong>   . Not great, not terrible.</p><br>
<h2 id="vremya-uluchsheniy"> !</h2><br>
<p>  Bagging.       :   ,  ,       .       :      "" ,      - .     .</p><br>
<p> sklearn   <code>ensembles</code>,        .   — ,  <code>BaggingClassifier</code>:</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> sklearn
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> BaggingClassifier</code></pre><br>
<p>  <em> </em>.   sklearn,   — ,   <code>sklearn.base.BaseEstimator</code>.     ,       .       <code>fit</code> (  ),  <code>predict_proba</code>,     ( ,                 ),   <code>predict</code> (   ),      .</p><br>
<p>       ,     ""   .</p><br>
<p>   .   ,     ,       .</p><br>
<p>-,           (    2  — <code>get_params</code>  <code>set_params</code>),         ,     .  ,       <code>net_type</code>,    <code>__init__</code>     <code>net_type</code>.</p><br>
<p>-,       ,     ,       ( sklearn       ,       )      <code>copy</code>, <code>deepcopy</code>    . ,  ,           ()  ,    ,    .</p><br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PytorchModel</span>(<span class="hljs-params">sklearn.base.BaseEstimator</span>):</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, net_type, net_params, optim_type, optim_params, loss_fn,
               input_shape, batch_size=<span class="hljs-number">32</span>, accuracy_tol=<span class="hljs-number">0.02</span>, tol_epochs=<span class="hljs-number">10</span>,
               cuda=True</span>):</span>
    self.net_type = net_type <span class="hljs-comment">#    </span>
    self.net_params = net_params <span class="hljs-comment">#  </span>
    self.optim_type = optim_type <span class="hljs-comment">#    </span>
    self.optim_params = optim_params <span class="hljs-comment">#  </span>
    self.loss_fn = loss_fn <span class="hljs-comment">#   loss'</span><font></font>
<font></font>
    self.input_shape = input_shape <span class="hljs-comment">#   </span>
    self.batch_size = batch_size <span class="hljs-comment">#  </span>
    self.accuracy_tol = accuracy_tol <span class="hljs-comment">#  ,    -- </span>
    self.tol_epochs = tol_epochs <span class="hljs-comment">#      </span>
    self.cuda = cuda <span class="hljs-comment">#    gpu</span></code></pre><br>
<p> :  <code>fit</code>.  ,         —  ,  Loss,    .   :   ,      ?          . , 200 (   ).      ,     .   — ,   accuracy  .     ,    accuracy        .     ,       (<code>tol_epochs</code>)      (  accuracy   ,   <code>accuracy_tol</code>).</p><br>
<pre><code class="python hljs">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, X, y</span>):</span>
    self.net = self.net_type(**self.net_params) <span class="hljs-comment">#        </span>
    <span class="hljs-comment"># `**self.net_params` ,   -            </span>
    <span class="hljs-keyword">if</span> self.cuda:<font></font>
      self.net = self.net.cuda() <span class="hljs-comment">#    gpu,    </span>
    self.optim = self.optim_type(self.net.parameters(), **self.optim_params) <span class="hljs-comment">#   ,  </span>
    <span class="hljs-comment">#         </span><font></font>
<font></font>
    uniq_classes = np.sort(np.unique(y)) <span class="hljs-comment">#   </span>
    self.classes_ = uniq_classes <span class="hljs-comment">#      sklearn --      `classes_`</span><font></font>
<font></font>
    X = X.reshape(<span class="hljs-number">-1</span>, *self.input_shape) <span class="hljs-comment">#         </span>
    <span class="hljs-comment">#       DataLoader</span><font></font>
    x_tensor = torch.tensor(X.astype(np.float32))<font></font>
    y_tensor = torch.tensor(y.astype(np.long))<font></font>
    train_dataset = TensorDataset(x_tensor, y_tensor)<font></font>
    train_loader = DataLoader(train_dataset, batch_size=self.batch_size,<font></font>
                              shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">False</span>)<font></font>
    last_accuracies = [] <span class="hljs-comment">#    accuracy    `tol_epochs` </span>
    epoch = <span class="hljs-number">0</span>
    keep_training = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">while</span> keep_training:<font></font>
      self.net.train() <span class="hljs-comment">#        (,    BatchNormalization)</span>
      train_samples_count = <span class="hljs-number">0</span> <span class="hljs-comment">#    </span>
      true_train_samples_count = <span class="hljs-number">0</span> <span class="hljs-comment">#     </span><font></font>
<font></font>
      <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_loader:<font></font>
        x_data, y_data = batch[<span class="hljs-number">0</span>], batch[<span class="hljs-number">1</span>]
        <span class="hljs-keyword">if</span> self.cuda:<font></font>
          x_data = x_data.cuda()<font></font>
          y_data = y_data.cuda()<font></font>
<font></font>
        <span class="hljs-comment">#    </span><font></font>
        y_pred = self.net(x_data)<font></font>
        loss = self.loss_fn(y_pred, y_data)<font></font>
<font></font>
        <span class="hljs-comment">#   </span><font></font>
        self.optim.zero_grad()<font></font>
        loss.backward()<font></font>
        self.optim.step()<font></font>
<font></font>
        y_pred = y_pred.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">False</span>) <span class="hljs-comment">#    ,     </span>
        true_classified = (y_pred == y_data).sum().item() <span class="hljs-comment">#     </span><font></font>
        true_train_samples_count += true_classified<font></font>
        train_samples_count += len(x_data)<font></font>
<font></font>
      train_accuracy = true_train_samples_count / train_samples_count <span class="hljs-comment">#  accuracy</span><font></font>
      last_accuracies.append(train_accuracy)<font></font>
<font></font>
      <span class="hljs-keyword">if</span> len(last_accuracies) &gt; self.tol_epochs:<font></font>
        last_accuracies.pop(<span class="hljs-number">0</span>)<font></font>
<font></font>
      <span class="hljs-keyword">if</span> len(last_accuracies) == self.tol_epochs:<font></font>
        accuracy_difference = max(last_accuracies) - min(last_accuracies) <span class="hljs-comment"># ,     accuracy   `tol_epochs` </span>
        <span class="hljs-keyword">if</span> accuracy_difference &lt;= self.accuracy_tol:<font></font>
          keep_training = <span class="hljs-literal">False</span> <span class="hljs-comment">#   ,  </span></code></pre><br>
<p>       .   —    ,    Loss,     - :</p><br>
<pre><code class="python hljs">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_proba</span>(<span class="hljs-params">self, X, y=None</span>):</span>
    <span class="hljs-comment">#   ,    fit,  DataLoader,     </span>
    X = X.reshape(<span class="hljs-number">-1</span>, *self.input_shape)<font></font>
    x_tensor = torch.tensor(X.astype(np.float32))<font></font>
    <span class="hljs-keyword">if</span> y:<font></font>
      y_tensor = torch.tensor(y.astype(np.long))<font></font>
    <span class="hljs-keyword">else</span>:<font></font>
      y_tensor = torch.zeros(len(X), dtype=torch.long)<font></font>
    test_dataset = TensorDataset(x_tensor, y_tensor)<font></font>
    test_loader = DataLoader(test_dataset, batch_size=self.batch_size,<font></font>
                              shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    self.net.eval() <span class="hljs-comment">#    ,   `train`,     BatchNormalization,    -    </span>
    predictions = [] <span class="hljs-comment"># ,   </span>
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> test_loader:<font></font>
      x_data, y_data = batch[<span class="hljs-number">0</span>], batch[<span class="hljs-number">1</span>]
      <span class="hljs-keyword">if</span> self.cuda:<font></font>
        x_data = x_data.cuda()<font></font>
        y_data = y_data.cuda()<font></font>
<font></font>
      y_pred = self.net(x_data)<font></font>
<font></font>
      predictions.append(y_pred.detach().cpu().numpy()) <span class="hljs-comment">#   ,    numpy-      </span><font></font>
<font></font>
    predictions = np.concatenate(predictions) <span class="hljs-comment">#          </span>
    <span class="hljs-keyword">return</span> predictions</code></pre><br>
<p>    :</p><br>
<pre><code class="python hljs">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self, X, y=None</span>):</span>
    predictions = self.predict_proba(X, y) <span class="hljs-comment">#   </span>
    predictions = predictions.argmax(axis=<span class="hljs-number">1</span>) <span class="hljs-comment">#    ,    </span>
    <span class="hljs-keyword">return</span> predictions</code></pre><br>
<div class="spoiler"><b class="spoiler_title">   </b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PytorchModel</span>(<span class="hljs-params">sklearn.base.BaseEstimator</span>):</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, net_type, net_params, optim_type, optim_params, loss_fn,
               input_shape, batch_size=<span class="hljs-number">32</span>, accuracy_tol=<span class="hljs-number">0.02</span>, tol_epochs=<span class="hljs-number">10</span>,
               cuda=True</span>):</span><font></font>
    self.net_type = net_type<font></font>
    self.net_params = net_params<font></font>
    self.optim_type = optim_type<font></font>
    self.optim_params = optim_params<font></font>
    self.loss_fn = loss_fn<font></font>
<font></font>
    self.input_shape = input_shape<font></font>
    self.batch_size = batch_size<font></font>
    self.accuracy_tol = accuracy_tol<font></font>
    self.tol_epochs = tol_epochs<font></font>
    self.cuda = cuda<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, X, y</span>):</span><font></font>
    self.net = self.net_type(**self.net_params)<font></font>
    <span class="hljs-keyword">if</span> self.cuda:<font></font>
      self.net = self.net.cuda()<font></font>
    self.optim = self.optim_type(self.net.parameters(), **self.optim_params)<font></font>
<font></font>
    uniq_classes = np.sort(np.unique(y))<font></font>
    self.classes_ = uniq_classes<font></font>
<font></font>
    X = X.reshape(<span class="hljs-number">-1</span>, *self.input_shape)<font></font>
    x_tensor = torch.tensor(X.astype(np.float32))<font></font>
    y_tensor = torch.tensor(y.astype(np.long))<font></font>
    train_dataset = TensorDataset(x_tensor, y_tensor)<font></font>
    train_loader = DataLoader(train_dataset, batch_size=self.batch_size,<font></font>
                              shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">False</span>)<font></font>
    last_accuracies = []<font></font>
    epoch = <span class="hljs-number">0</span>
    keep_training = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">while</span> keep_training:<font></font>
      self.net.train()<font></font>
      train_samples_count = <span class="hljs-number">0</span>
      true_train_samples_count = <span class="hljs-number">0</span><font></font>
<font></font>
      <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_loader:<font></font>
        x_data, y_data = batch[<span class="hljs-number">0</span>], batch[<span class="hljs-number">1</span>]
        <span class="hljs-keyword">if</span> self.cuda:<font></font>
          x_data = x_data.cuda()<font></font>
          y_data = y_data.cuda()<font></font>
<font></font>
        y_pred = self.net(x_data)<font></font>
        loss = self.loss_fn(y_pred, y_data)<font></font>
<font></font>
        self.optim.zero_grad()<font></font>
        loss.backward()<font></font>
        self.optim.step()<font></font>
<font></font>
        y_pred = y_pred.argmax(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">False</span>)<font></font>
        true_classified = (y_pred == y_data).sum().item()<font></font>
        true_train_samples_count += true_classified<font></font>
        train_samples_count += len(x_data)<font></font>
<font></font>
      train_accuracy = true_train_samples_count / train_samples_count<font></font>
      last_accuracies.append(train_accuracy)<font></font>
<font></font>
      <span class="hljs-keyword">if</span> len(last_accuracies) &gt; self.tol_epochs:<font></font>
        last_accuracies.pop(<span class="hljs-number">0</span>)<font></font>
<font></font>
      <span class="hljs-keyword">if</span> len(last_accuracies) == self.tol_epochs:<font></font>
        accuracy_difference = max(last_accuracies) - min(last_accuracies)<font></font>
        <span class="hljs-keyword">if</span> accuracy_difference &lt;= self.accuracy_tol:<font></font>
          keep_training = <span class="hljs-literal">False</span><font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_proba</span>(<span class="hljs-params">self, X, y=None</span>):</span>
    X = X.reshape(<span class="hljs-number">-1</span>, *self.input_shape)<font></font>
    x_tensor = torch.tensor(X.astype(np.float32))<font></font>
    <span class="hljs-keyword">if</span> y:<font></font>
      y_tensor = torch.tensor(y.astype(np.long))<font></font>
    <span class="hljs-keyword">else</span>:<font></font>
      y_tensor = torch.zeros(len(X), dtype=torch.long)<font></font>
    test_dataset = TensorDataset(x_tensor, y_tensor)<font></font>
    test_loader = DataLoader(test_dataset, batch_size=self.batch_size,<font></font>
                              shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    self.net.eval()<font></font>
    predictions = []<font></font>
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> test_loader:<font></font>
      x_data, y_data = batch[<span class="hljs-number">0</span>], batch[<span class="hljs-number">1</span>]
      <span class="hljs-keyword">if</span> self.cuda:<font></font>
        x_data = x_data.cuda()<font></font>
        y_data = y_data.cuda()<font></font>
<font></font>
      y_pred = self.net(x_data)<font></font>
<font></font>
      predictions.append(y_pred.detach().cpu().numpy())<font></font>
<font></font>
    predictions = np.concatenate(predictions)<font></font>
    <span class="hljs-keyword">return</span> predictions<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self, X, y=None</span>):</span><font></font>
    predictions = self.predict_proba(X, y)<font></font>
    predictions = predictions.argmax(axis=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> predictions</code></pre></div></div><br>
<p>,    :</p><br>
<pre><code class="python hljs">base_model = PytorchModel(net_type=SimpleCNN, net_params=dict(), optim_type=Adam,<font></font>
                          optim_params={<span class="hljs-string">"lr"</span>: <span class="hljs-number">1e-3</span>}, loss_fn=nn.CrossEntropyLoss(),<font></font>
                          input_shape=(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>), batch_size=<span class="hljs-number">32</span>, accuracy_tol=<span class="hljs-number">0.02</span>,<font></font>
                          tol_epochs=<span class="hljs-number">10</span>, cuda=<span class="hljs-literal">True</span>)<font></font>
<font></font>
base_model.fit(x_train_scaled, y_train) <span class="hljs-comment">#  </span><font></font>
<font></font>
preds = base_model.predict(x_test_scaled) <span class="hljs-comment">#    </span>
true_classified = (preds == y_test).sum() <span class="hljs-comment">#    </span>
test_accuracy = true_classified / len(y_test) <span class="hljs-comment"># accuracy</span><font></font>
<font></font>
print(<span class="hljs-string">f"Test accuracy: <span class="hljs-subst">{test_accuracy}</span>"</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>Test accuracy: <span class="hljs-number">0.7361111111111112</span></code></pre><br>
<p>    .</p><br>
<pre><code class="python hljs">meta_classifier = BaggingClassifier(base_estimator=base_model, n_estimators=<span class="hljs-number">10</span>) <span class="hljs-comment"># ,        </span><font></font>
<font></font>
meta_classifier.fit(x_train_scaled.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">64</span>), y_train) <span class="hljs-comment">#    ,     ,  reshape'</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>BaggingClassifier(<font></font>
           base_estimator=PytorchModel(accuracy_tol=<span class="hljs-number">0.02</span>, batch_size=<span class="hljs-number">32</span>,<font></font>
              cuda=<span class="hljs-literal">True</span>, input_shape=(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>),<font></font>
              loss_fn=CrossEntropyLoss(),<font></font>
              net_params={},<font></font>
              net_type=&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">__main__</span>.<span class="hljs-title">SimpleCNN</span>'&gt;,
              <span class="hljs-title">optim_params</span>={'<span class="hljs-title">lr</span>':</span> <span class="hljs-number">0.001</span>},<font></font>
              optim_type=&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> '<span class="hljs-title">torch</span>.<span class="hljs-title">optim</span>.<span class="hljs-title">adam</span>.<span class="hljs-title">Adam</span>'&gt;,
              <span class="hljs-title">tol_epochs</span>=10),
          <span class="hljs-title">bootstrap</span>=<span class="hljs-title">True</span>, <span class="hljs-title">bootstrap_features</span>=<span class="hljs-title">False</span>, <span class="hljs-title">max_features</span>=1.0,
          <span class="hljs-title">max_samples</span>=1.0, <span class="hljs-title">n_estimators</span>=10, <span class="hljs-title">n_jobs</span>=<span class="hljs-title">None</span>,
          <span class="hljs-title">oob_score</span>=<span class="hljs-title">False</span>, <span class="hljs-title">random_state</span>=<span class="hljs-title">None</span>, <span class="hljs-title">verbose</span>=0,
          <span class="hljs-title">warm_start</span>=<span class="hljs-title">False</span>)</span></code></pre><br>
<p>       <code>score</code>  accuracy  :</p><br>
<pre><code class="python hljs">print(meta_classifier.score(x_test_scaled.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">64</span>), y_test))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.95</span></code></pre><br>
<h2 id="nekotorye-vyvody-i-kuda-dvigatsya-dalshe">     </h2><br>
<p>      ,   .      .          . , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"> </a>,         (      "" -  ). </p><br>
<h3 id="chto-mozhno-uluchshit">  ?</h3><br>
<p>-, . ,    Loss'  -       .</p><br>
<p>-,   Boosting.    Bagging'  ,     ,      .      ( )    .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">   sklearn</a>,      Loss   - .</p><br>
<p> ,       .     ,   "" .        ,      .</p><br>
<h3 id="terpelivomu-chitatelyu"> </h3><br>
<p>,      .            — - , , ,  , ,          .</p><br>
<p>   .   , Data science'     .       Computer vision,    . (      —  !)       — <strong>FARADAY Lab</strong>.  —         ,   .</p><br>
<p> c:</p><br>
<h3 id="poleznye-ssylki"> </h3><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">Jupyter-notebook  </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">Bagging</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">  sklearn.ensemble.BaggingClassifier</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">Sklearn: ensemble methods</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">  PyTorch</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">Sklearn: StandardScaler</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">Sklearn: BaseEstimator</a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id489042/index.html">Pembukaan kembali Grand Store: memuat data ke Android menggunakan coroutine</a></li>
<li><a href="../id489044/index.html">Fisika teks. Bagian 1. Simbol</a></li>
<li><a href="../id489046/index.html">Mengemudi Sendiri GAZ66 Monster Truck 1/16</a></li>
<li><a href="../id489048/index.html">Pencatatan dan penelusuran kueri adalah praktik terbaik. Laporan Yandex</a></li>
<li><a href="../id489050/index.html">Windows vs Sysmon</a></li>
<li><a href="../id489060/index.html">Analisis: apa perbedaan antara investasi berisiko tinggi dan risiko rendah</a></li>
<li><a href="../id489062/index.html">Kinerja Parquet Apache I / O paralel yang luar biasa dalam Python</a></li>
<li><a href="../id489068/index.html">Digital Keabadian - Suatu Pendekatan Teknik</a></li>
<li><a href="../id489070/index.html">Biayanya 354 pasang kaus kaki. Pilihan hadiah untuk 23 Februari</a></li>
<li><a href="../id489072/index.html">Keuntungan 3CX dalam membangun jaringan terdistribusi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
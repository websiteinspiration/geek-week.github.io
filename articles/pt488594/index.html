<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚭 🆚 👧 Pandas e outros para dados espessos 👨🏽‍🚒 🖊️ 🙏🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, falarei sobre alguns truques simples que são úteis ao trabalhar com dados que não cabem na memória da máquina local, mas ainda são peque...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pandas e outros para dados espessos</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488594/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neste artigo, falarei sobre alguns truques simples que são úteis ao trabalhar com dados que não cabem na memória da máquina local, mas ainda são pequenos demais para serem chamados de Grandes. </font><font style="vertical-align: inherit;">Seguindo a analogia em inglês (grande, mas não grande), chamaremos esses dados de grossos. </font><font style="vertical-align: inherit;">Estamos falando de tamanhos de unidades e dezenas de gigabytes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[Isenção de responsabilidade] Se você gosta de SQL, tudo o que está escrito abaixo pode causar emoções negativas, provavelmente negativas, na Holanda existem 49262 Tesla, dos quais 427 são táxis, é melhor não ler mais [/ Isenção de responsabilidade].</font></font><br>
<br>
<img src="https://habrastorage.org/webt/-s/ac/gl/-sacgl0hwmynxnpiov5s_coofa4.png" alt="imagem"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O ponto de partida foi </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">um artigo no hub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> com uma descrição de um conjunto de dados interessante - uma lista completa de veículos registrados na Holanda, 14 milhões de linhas, tudo, desde tratores de caminhão a bicicletas elétricas a velocidades acima de 25 km / h. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O conjunto é interessante, leva 7 GB, </font><font style="vertical-align: inherit;">você pode </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">baixá-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> lo no site da organização responsável. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A tentativa de conduzir os dados como estão nos pandas para filtrá-los e limpá-los terminou em um fiasco (senhores dos hussardos SQL, eu avisei!). Os pandas caíram devido à falta de memória na área de trabalho com 8 GB. Com um pouco de derramamento de sangue, a questão pode ser resolvida se você se lembrar de que os pandas podem ler arquivos csv em pedaços de tamanho moderado. O tamanho do fragmento nas linhas é determinado pelo parâmetro chunksize.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para ilustrar o trabalho, escreveremos uma função simples que faz uma solicitação e determina quantos carros Tesla existem no total e qual proporção deles trabalha em táxis. Sem truques com a leitura de fragmentos, esse pedido primeiro consome toda a memória, depois sofre por um longo tempo e, no final, a rampa cai. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com a leitura de fragmentos, nossa função será mais ou menos assim:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pandas_chunky_query</span>():</span>
    print(<span class="hljs-string">'reading csv file with pandas in chunks'</span>)<font></font>
    filtered_chunk_list=[]<font></font>
    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> pd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>, chunksize=<span class="hljs-number">1E+6</span>):<font></font>
        filtered_chunk=chunk[chunk[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        filtered_chunk_list.append(filtered_chunk)<font></font>
    model_df = pd.concat(filtered_chunk_list)<font></font>
    print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Especificando um milhão de linhas perfeitamente razoáveis, você pode executar a consulta em 1:46 e usando 1965 M de memória em seu pico. Todos os números de um desktop idiota com algo antigo, de oito núcleos, com cerca de 8 GB de memória e no sétimo Windows. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7d/id/0-/7did0-qetjm9v9wrlaouudevkss.png" alt="imagem"><br>
<br>
<img src="https://habrastorage.org/webt/8n/ch/go/8nchgo5c-tr54min7qwpfvgwuuq.png" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se você alterar o tamanho do pedaço, o consumo máximo de memória o seguirá literalmente, o tempo de execução não mudará muito. Para linhas de 0,5 M, a solicitação leva 1:44 e 1063 MB, para 2M 1:53 e 3762 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A velocidade não é muito agradável, ainda menos agradável é que a leitura do arquivo em fragmentos obriga a escrever adaptado para esta função, trabalhando com listas de fragmentos que devem ser coletados em um quadro de dados. Além disso, o formato csv em si não é muito feliz, o que ocupa muito espaço e é lido lentamente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como podemos conduzir dados para uma rampa, um formato Apachev muito mais compacto pode ser usado para armazenamento</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">parquet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> onde há compressão e, graças ao esquema de dados, é muito mais rápido ler quando é lido. E a rampa é capaz de trabalhar com ele. Só agora não pode lê-los em fragmentos. O que fazer? </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Vamos nos divertir, pegar o </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">acordeão do botão</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dask e acelerar! </font></font></i><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dask!</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Um substituto para a rampa pronta para uso, capaz de ler arquivos grandes, capaz de trabalhar em paralelo em vários núcleos e usar cálculos preguiçosos. Para minha surpresa sobre Dask on Habré, existem apenas 4 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicações</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Então, pegamos o traço, colocamos o csv original nele e, com uma conversão mínima, colocamos no chão. Ao ler, o dask jura pela ambiguidade dos tipos de dados em algumas colunas, por isso os definimos explicitamente (por uma questão de clareza, o mesmo foi feito para a rampa, o tempo de operação é mais alto levando em conta esse fator, o dicionário com tipos é cortado para todas as consultas para maior clareza), o resto é para si . Além disso, para verificação, fazemos pequenas melhorias no piso, ou seja, tentamos reduzir os tipos de dados aos mais compactos, substituir um par de colunas pelo texto sim / não pelos booleanos e converter outros dados para os tipos mais econômicos (para o número de cilindros do motor, o uint8 é definitivamente suficiente). Salvamos o piso otimizado separadamente e vemos o que obtemos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A primeira coisa que agrada ao trabalhar com o Dask é que não precisamos escrever nada supérfluo simplesmente porque temos dados espessos. Se você não prestar atenção ao fato de que o dask é importado, e não a rampa, tudo parece o mesmo que processar um arquivo com cem linhas na rampa (além de alguns apitos decorativos para criação de perfil).</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading CSV file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>)<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts().compute())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Agora compare o impacto do arquivo de origem no desempenho ao trabalhar com o dasko. Primeiro, lemos o mesmo arquivo csv que ao trabalhar com a rampa. O mesmo cerca de dois minutos e dois gigabytes de memória (1:38 2096 Mb). Parece, valeu a pena beijar nos arbustos? </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9a/oy/al/9aoyalzd1a62bw31uivvy699xme.png" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora alimente o arquivo de parquet não otimizado do quadro. A solicitação foi processada em aproximadamente 54 segundos, consumindo 1388 MB de memória, e o próprio arquivo da solicitação agora é 10 vezes menor (cerca de 700 MB). Aqui os bônus já são visíveis convexamente. A utilização da CPU de centenas de por cento é paralelização em vários núcleos.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1u/sz/_x/1usz_xafa2hng3nogb2fbp9zspm.png" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O parquet previamente otimizado com tipos de dados ligeiramente modificados na forma compactada é de apenas 1 MB a menos, o que significa que, sem dicas, tudo é compactado com bastante eficiência. </font><font style="vertical-align: inherit;">O aumento da produtividade também não é particularmente significativo. </font><font style="vertical-align: inherit;">A solicitação leva os mesmos 53 segundos e consome um pouco menos de memória - 1332 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com base nos resultados de nossos exercícios, podemos dizer o seguinte:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se seus dados forem "gordos" e você estiver acostumado a uma rampa - o tamanho do pedaço ajudará a rampa a digerir esse volume, a velocidade será suportável. </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se você deseja reduzir mais velocidade, economize espaço durante o armazenamento e não fique retido usando apenas uma rampa; então, o crepúsculo com parquet é uma boa combinação. </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finalmente, sobre computação preguiçosa. Um dos recursos do dask é que ele usa cálculos preguiçosos, ou seja, os cálculos não são executados imediatamente como são encontrados no código, mas quando são realmente necessários ou quando você o solicitou explicitamente usando o método de computação. Por exemplo, em nossa função, o dask não lê todos os dados na memória quando indicamos ler o arquivo. Ele os lê mais tarde, e apenas as colunas relacionadas à solicitação.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Isso é facilmente visto no exemplo a seguir. </font><font style="vertical-align: inherit;">Pegamos um arquivo pré-filtrado no qual deixamos apenas 12 colunas dos 64 iniciais; o parquet compactado leva 203 MB. </font><font style="vertical-align: inherit;">Se você executar nossa solicitação regular, ela será executada em 8,8 segundos e o pico de uso da memória será de cerca de 300 MB, o que corresponde a um décimo do arquivo compactado se você o exceder em um csv simples. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/jg/we/bq/jgwebqzk7enoz6z6rwiearbofgs.png" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se exigirmos explicitamente que você leia o arquivo e execute a solicitação, o consumo de memória será quase 10 vezes maior. </font><font style="vertical-align: inherit;">Modificamos levemente nossa função lendo explicitamente o arquivo:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading parquet file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_parquet(<span class="hljs-string">'C:\Open_data\RDW_filtered.parquet'</span> ).compute()<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]
        <span class="hljs-comment">#print(model_df.head())</span>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E aqui está o que obtemos: 10,5 segundos e 3568 MB de memória (!) </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w5/5w/aj/w55wajaohsdjyevm1hxbgpvns2a.png" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais uma vez, estamos convencidos de que o dask - é competente para lidar com suas próprias tarefas, e mais uma vez entrar nele com microgerenciamento não faz muito sentido.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt488584/index.html">O que você deseja saber antes de escrever um aplicativo para o Apple Watch: nossa experiência</a></li>
<li><a href="../pt488586/index.html">The Ember Times - Edição 135</a></li>
<li><a href="../pt488588/index.html">C ++ 20 aprovado! O que esperar e o que preparar para os desenvolvedores em C ++ 23</a></li>
<li><a href="../pt488590/index.html">FOSS News No. 3 - Revisão de notícias gratuitas e de código aberto de 10 a 16 de fevereiro de 2020</a></li>
<li><a href="../pt488592/index.html">Uma carta aberta do Mail.ru sobre o jogo "Allods II: Senhor das Almas"</a></li>
<li><a href="../pt488596/index.html">O Google desenvolveu um algoritmo para cortar automaticamente vídeos em objetos importantes no quadro</a></li>
<li><a href="../pt488598/index.html">O mundo está pronto para uma pandemia?</a></li>
<li><a href="../pt488600/index.html">Como os provedores se preocupam com a segurança do cliente</a></li>
<li><a href="../pt488602/index.html">iOS MEETUP # 2 da FUNCORP e como manter um desenvolvedor atualizado</a></li>
<li><a href="../pt488604/index.html">O resumo de materiais frescos do mundo da interface da última semana nº 402 (10 a 16 de fevereiro de 2020)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍆 🗒️ 👍🏻 畳み込みニューラルネットワークへの没入：転移学習 🧑🏿‍🤝‍🧑🏿 🧘🏼 🥫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ロシア語の完全なコースはこのリンクで見つけることができます。
 元の英語コースはこのリンクから入手できます。
 


 コンテンツ
 

1. セバスチャン・トランとのインタビュー
2. 前書き
3. 転移学習モデル
4. MobileNet
5. CoLab：猫と犬のトレーニング転送
6. 畳み込...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>畳み込みニューラルネットワークへの没入：転移学習</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/467967/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ロシア語の完全なコースは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このリンク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で見つけることができます</font><font style="vertical-align: inherit;">。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
元の英語コースは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このリンクから</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">入手できます</font><font style="vertical-align: inherit;">。</font></font></p><br>
<p><img src="https://habrastorage.org/webt/wu/ie/7c/wuie7cgpktklm4bytoweu7ki0oq.jpeg"></p><a name="habracut"></a><br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コンテンツ</font></font></h1><br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">セバスチャン・トランとのインタビュー</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">前書き</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">転移学習モデル</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MobileNet</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CoLab：猫と犬のトレーニング転送</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">畳み込みニューラルネットワークに飛び込む</font></font></li>
<li> :     </li>
<li></li>
</ol><br>
<h1>   </h1><br>
<p> —  6        (transfer learning).             .                . ,        ?    -         ?<br>
 —            "<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">    </a>".         ,      ( , )            .      ,     ()        .     Tensorflow      .<br>
 — ,  Tensorflow       ,        .       .<br>
 — -!  ,           .<br>
 —    ,          -      -              ?<br>
 —  —     ,    .    ,              . ,         ,   100     100     ,             .<br>
 — ,   !      -   .</p><br>
<h1></h1><br>
<p> —    !<br>
 —                .     ,        —  70% .          dropout (  ),       80%.<br>
 —   ,  80%    , 20%-     .   ?     ,    ?         (  ),            .     ,         95%  .  !</p><br>
<h1>  </h1><br>
<p> 2012    AlexNet                 ImageNet Large Scale Visual recognition challenge.</p><br>
<p><img src="https://habrastorage.org/webt/fs/xx/di/fsxxdicwkitfkxibie8kkjcyexu.png"></p><br>
<p>           ,     AlexNet        ImageNet.</p><br>
<p><img src="https://habrastorage.org/webt/oe/t0/ov/oet0ovye40p1cziih64hpmbhuus.png"></p><br>
<p>       ,      ,  AlexNet — Inception  ResNet.<br>
,          ,        ImageNet         ? </p><br>
<p>,     !   transfer learning (  ).         ,                 ,       .     transfer learning —         .</p><br>
<p> ,                 :</p><br>
<p><img src="https://habrastorage.org/webt/3j/-g/g3/3j-gg3yxm9kvrtphiswnho2jgtc.png"></p><br>
<p>    ,          . ,    ImageNet  1000   . FashionMNIST  10 .         2  —   .</p><br>
<p><img src="https://habrastorage.org/webt/5e/pm/ej/5epmejbamklkdfgzzw9v8rzb1ts.png"></p><br>
<p>         ,      ,        .</p><br>
<p><img src="https://habrastorage.org/webt/cg/mk/fz/cgmkfzxqmyqbdzsmvfdppjhsl9e.png"></p><br>
<p>    ,           .        —             .<br>
   " " (freezing the model).</p><br>
<p><img src="https://habrastorage.org/webt/8z/oz/0n/8zoz0nenaad4-lgezhhia25k_18.png"></p><br>
<p>""           ,     . </p><br>
<p>        ,              ,    .</p><br>
<p>   ""   ,            .   ,           . -             , ,   ,        ,     .</p><br>
<p><img src="https://habrastorage.org/webt/wp/uz/km/wpuzkmnan5rahfg3irexdsvrstm.png"></p><br>
<p>         ,         ""      .</p><br>
<p>,        ,           !      .</p><br>
<h1>MobileNet</h1><br>
<p>    ,      ,        ImageNet — AlexNet, Inception, Resonant.                 .                .          ,          .</p><br>
<p>         MobileNet. MobileNet       ,             .   MobileNet               .</p><br>
<p>MobileNet     Google      ImageNet. </p><br>
<p>  MobileNet    1 000     ImageNet,   MobileNet 1 000  ,  ,    —   .</p><br>
<p><img src="https://habrastorage.org/webt/he/2f/ox/he2foxizd_xmt7rijxumteg-94k.png"></p><br>
<p>           :</p><br>
<p><img src="https://habrastorage.org/webt/1b/o2/no/1bo2nop9cpz3ebag_jcyfrgje7w.png"></p><br>
<p> Tensorflow         Keras-     .</p><br>
<p>  MobileNet      ImageNet,          ,      .    MobileNet    RGB-   224224px. </p><br>
<p>TensorFlow       ,   TensorFlow Hub. </p><br>
<p><img src="https://habrastorage.org/webt/o5/we/9d/o5we9dvkdtaomahwj4nzomgquca.png"></p><br>
<p>TensorFlow Hub                  .</p><br>
<p> TensorFlow Hub      :</p><br>
<p><img src="https://habrastorage.org/webt/1h/ai/hg/1haihgg1llinsfv_wyhde4z0egy.png"></p><br>
<p>  URL                     .           .          ,     :</p><br>
<p><img src="https://habrastorage.org/webt/uh/cr/5e/uhcr5esktfnxtxwxfgutvttxbxk.png"></p><br>
<p>             .</p><br>
<h1>CoLab:  Vs    </h1><br>
<p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">CoLab  </a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">CoLab  </a>.</p><br>
<p>TensorFlow Hub      ,      .</p><br>
<p>                 .     ,      ,   ,          .</p><br>
<p>       .</p><br>
<p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>      .</p><br>
<p><strong>   Colab</strong></p><br>
<ol>
<li> TensorFlow Hub-  ;</li>
<li> TensorFlow Hub-      ;</li>
<li>       TensorFlow Hub.</li>
</ol><br>
<p>             <code>Runtime -&gt; Reset all runtimes...</code></p><br>
<p><strong> </strong></p><br>
<p>          TensorFlow,      .       TnsorFlow  TensorFlow Hub  .</p><br>
<p> dev- TensorFlow     .          ,     TensorFlow         <code>Runtime -&gt; Reset all runtimes...</code>.         .</p><br>
<pre><code class="python hljs">!pip install tf-nightly-gpu<font></font>
!pip install <span class="hljs-string">"tensorflow_hub==0.4.0"</span>
!pip install -U tensorflow_datasets</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Requirement already satisfied: absl-py&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.8.0)<font></font>
Requirement already satisfied: protobuf&gt;=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.1)<font></font>
Requirement already satisfied: google-pasta&gt;=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.1.7)<font></font>
Collecting tf-estimator-nightly (from tf-nightly-gpu)<font></font>
  Downloading https://files.pythonhosted.org/packages/ea/72/f092fc631ef2602fd0c296dcc4ef6ef638a6a773cb9fdc6757fecbfffd33/tf_estimator_nightly-1.14.0.dev2019092201-py2.py3-none-any.whl (450kB)<font></font>
     |████████████████████████████████| 450kB 45.9MB/s <font></font>
Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.16.5)<font></font>
Requirement already satisfied: wrapt&gt;=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.11.2)<font></font>
Requirement already satisfied: astor&gt;=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.8.0)<font></font>
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.0.1)<font></font>
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.33.6)<font></font>
Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications&gt;=1.0.8-&gt;tf-nightly-gpu) (2.8.0)<font></font>
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly&lt;1.16.0a0,&gt;=1.15.0a0-&gt;tf-nightly-gpu) (3.1.1)<font></font>
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly&lt;1.16.0a0,&gt;=1.15.0a0-&gt;tf-nightly-gpu) (41.2.0)<font></font>
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly&lt;1.16.0a0,&gt;=1.15.0a0-&gt;tf-nightly-gpu) (0.15.6)<font></font>
Installing collected packages: tb-nightly, tf-estimator-nightly, tf-nightly-gpu<font></font>
Successfully installed tb-nightly-1.15.0a20190911 tf-estimator-nightly-1.14.0.dev2019092201 tf-nightly-gpu-1.15.0.dev20190821<font></font>
Collecting tensorflow_hub==0.4.0<font></font>
  Downloading https://files.pythonhosted.org/packages/10/5c/6f3698513cf1cd730a5ea66aec665d213adf9de59b34f362f270e0bd126f/tensorflow_hub-0.4.0-py2.py3-none-any.whl (75kB)<font></font>
     |████████████████████████████████| 81kB 5.0MB/s <font></font>
Requirement already satisfied: protobuf&gt;=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (3.7.1)<font></font>
Requirement already satisfied: numpy&gt;=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (1.16.5)<font></font>
Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (1.12.0)<font></font>
Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.4.0-&gt;tensorflow_hub==0.4.0) (41.2.0)<font></font>
Installing collected packages: tensorflow-hub<font></font>
  Found existing installation: tensorflow-hub 0.6.0<font></font>
    Uninstalling tensorflow-hub-0.6.0:<font></font>
      Successfully uninstalled tensorflow-hub-0.6.0<font></font>
Successfully installed tensorflow-hub-0.4.0<font></font>
Collecting tensorflow_datasets<font></font>
  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)<font></font>
     |████████████████████████████████| 2.3MB 4.9MB/s <font></font>
Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)<font></font>
Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.11.2)<font></font>
Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.0)<font></font>
Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.16.5)<font></font>
Requirement already satisfied, skipping upgrade: requests&gt;=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.21.0)<font></font>
Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1)<font></font>
Requirement already satisfied, skipping upgrade: protobuf&gt;=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.7.1)<font></font>
Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (5.4.8)<font></font>
Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.2.1)<font></font>
Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.8.0)<font></font>
Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.14.0)<font></font>
Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.0)<font></font>
Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)<font></font>
Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.1.0)<font></font>
Requirement already satisfied, skipping upgrade: idna&lt;2.9,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (2.8)<font></font>
Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (2019.6.16)<font></font>
Requirement already satisfied, skipping upgrade: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (3.0.4)<font></font>
Requirement already satisfied, skipping upgrade: urllib3&lt;1.25,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (1.24.3)<font></font>
Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.6.1-&gt;tensorflow_datasets) (41.2.0)<font></font>
Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata-&gt;tensorflow_datasets) (1.6.0)<font></font>
Installing collected packages: tensorflow-datasets<font></font>
Successfully installed tensorflow-datasets-1.2.0</code></pre><br>
<p>         .   —  <code>tensorflow_hub</code>,           .</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> matplotlib.pylab <span class="hljs-keyword">as</span> plt<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
tf.enable_eager_execution()<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow_hub <span class="hljs-keyword">as</span> hub
<span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">WARNING:tensorflow:<font></font>
<font></font>
  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.<font></font>
<font></font>
  Please upgrade your code to TensorFlow 2.0:<font></font>
    * https://www.tensorflow.org/beta/guide/migration_guide<font></font>
<font></font>
  Or install the latest stable TensorFlow 1.X release:<font></font>
    * `pip install -U "tensorflow==1.*"`<font></font>
<font></font>
  Otherwise your code may be broken by the change.</code></pre><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> logging<font></font>
logger = tf.get_logger()<font></font>
logger.setLevel(logging.ERROR)</code></pre><br>
<p><strong> 1:  TensorFlow Hub MobileNet  </strong></p><br>
<p>   CoLab    ,    Keras  .</p><br>
<p>,    — MobileNet v2 ( MobileNet        tf2     tfhub.dev).</p><br>
<p><strong> </strong></p><br>
<p> MobileNet-     Keras-. MobileNet       224224   3   (RGB).</p><br>
<pre><code class="python hljs">CLASSIFIER_URL = <span class="hljs-string">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2"</span>
IMAGE_RES = <span class="hljs-number">224</span><font></font>
<font></font>
model = tf.keras.Sequential([<font></font>
     hub.KerasLayer(CLASSIFIER_URL, input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number">3</span>))<font></font>
])</code></pre><br>
<p><strong>    </strong></p><br>
<p>MobileNet      ImageNet. ImageNet  1000        —  .                  ImageNet    .</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> PIL.Image <span class="hljs-keyword">as</span> Image<font></font>
<font></font>
grace_hopper = tf.keras.utils.get_file(<span class="hljs-string">'image.jpg'</span>, <span class="hljs-string">'https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg'</span>)<font></font>
grace_hopper = Image.open(grace_hopper).resize((IMAGE_RES, IMAGE_RES))<font></font>
grace_hopper</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg<font></font>
65536/61306 [================================] - 0s 0us/step</code></pre><br>
<p><img src="https://habrastorage.org/webt/8g/gn/0u/8ggn0ur3pmnr_rxvezfdo4vrwcc.png"></p><br>
<pre><code class="python hljs">grace_hopper = np.array(grace_hopper)/<span class="hljs-number">255.0</span>
grace_hopper.shape</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">(224, 224, 3)</code></pre><br>
<p> ,        ()   .        —  .</p><br>
<pre><code class="python hljs">result = model.predict(grace_hopper[np.newaxis, ...])<font></font>
result.shape</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">(1, 1001)</code></pre><br>
<p>     1 001 ,            .</p><br>
<p>          <code>argmax</code>.            —    ,        ?</p><br>
<pre><code class="python hljs">predicted_class = np.argmax(result[<span class="hljs-number">0</span>], axis=<span class="hljs-number">-1</span>)<font></font>
predicted_class</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">653</code></pre><br>
<p><strong> </strong></p><br>
<p>              ImageNet            .</p><br>
<pre><code class="python hljs">labels_path = tf.keras.utils.get_file(<span class="hljs-string">'ImageNetLabels.txt'</span>,<span class="hljs-string">'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'</span>)<font></font>
imagenet_labels = np.array(open(labels_path).read().splitlines())<font></font>
<font></font>
plt.imshow(grace_hopper)<font></font>
plt.axis(<span class="hljs-string">'off'</span>)<font></font>
predicted_class_name = imagenet_labels[predicted_class]<font></font>
_ = plt.title(<span class="hljs-string">"Prediction: "</span> + predicted_class_name.title())</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt<font></font>
16384/10484 [==============================================] - 0s 0us/step</code></pre><br>
<p><img src="https://habrastorage.org/webt/ai/1k/rt/ai1krt6mkpcafhb5jx8ozf6mq8s.png"></p><br>
<p>!      .</p><br>
<p><strong> 2:  TensorFlow Hub-      </strong></p><br>
<p>      MobileNet  ,          .</p><br>
<p><strong> </strong></p><br>
<p>   TensorFlow Datasets       .</p><br>
<pre><code class="python hljs">splits = tfds.Split.ALL.subsplit(weighted=(<span class="hljs-number">80</span>, <span class="hljs-number">20</span>))<font></font>
<font></font>
splits, info = tfds.load(<span class="hljs-string">'cats_vs_dogs'</span>, with_info=<span class="hljs-literal">True</span>, as_supervised=<span class="hljs-literal">True</span>, split = splits)<font></font>
<font></font>
(train_examples, validation_examples) = splits<font></font>
<font></font>
num_examples = info.splits[<span class="hljs-string">'train'</span>].num_examples<font></font>
num_classes = info.features[<span class="hljs-string">'label'</span>].num_classes</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Downloading and preparing dataset cats_vs_dogs (786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/2.0.1...<font></font>
<font></font>
/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings<font></font>
  InsecureRequestWarning)<font></font>
<font></font>
WARNING:absl:1738 images were corrupted and were skipped<font></font>
<font></font>
Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/2.0.1. Subsequent calls will reuse this data.<font></font>
</code></pre><br>
<p>          .</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> i, example_image <span class="hljs-keyword">in</span> enumerate(train_examples.take(<span class="hljs-number">3</span>)):<font></font>
  print(<span class="hljs-string">"Image {} shape: {}"</span>.format(i+<span class="hljs-number">1</span>, example_image[<span class="hljs-number">0</span>].shape))</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Image 1 shape: (500, 343, 3)<font></font>
Image 2 shape: (375, 500, 3)<font></font>
Image 3 shape: (375, 500, 3)</code></pre><br>
<p>          ,      MobileNet — 224 x 224.</p><br>
<p> <code>.repeat()</code>  <code>steps_per_epoch</code>   ,     15     , ..            .</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">format_image</span>(<span class="hljs-params">image, label</span>):</span>
  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES)) / <span class="hljs-number">255.0</span>
  <span class="hljs-keyword">return</span> image, label<font></font>
<font></font>
BATCH_SIZE = <span class="hljs-number">32</span><font></font>
<font></font>
train_batches = train_examples.shuffle(num_examples//<span class="hljs-number">4</span>).map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number">1</span>)<font></font>
validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number">1</span>)</code></pre><br>
<p><strong>    </strong></p><br>
<p>,            MobileNet ,   1 000   . ImageNet       ,                ,     .</p><br>
<pre><code class="python hljs">image_batch, label_batch = next(iter(train_batches.take(<span class="hljs-number">1</span>)))<font></font>
image_batch = image_batch.numpy()<font></font>
label_batch = label_batch.numpy()<font></font>
<font></font>
result_batch = model.predict(image_batch)<font></font>
<font></font>
predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=<span class="hljs-number">-1</span>)]<font></font>
predicted_class_names</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">array(['Persian cat', 'mink', 'Siamese cat', 'tabby',<font></font>
       'Bouvier des Flandres', 'dishwasher', 'Yorkshire terrier',<font></font>
       'tiger cat', 'tabby', 'Egyptian cat', 'Egyptian cat', 'tabby',<font></font>
       'dalmatian', 'Persian cat', 'Border collie', 'Newfoundland',<font></font>
       'tiger cat', 'Siamese cat', 'Persian cat', 'Egyptian cat', 'tabby',<font></font>
       'tiger cat', 'Labrador retriever', 'German shepherd', 'Eskimo dog',<font></font>
       'kelpie', 'mink', 'Norwegian elkhound', 'Labrador retriever',<font></font>
       'Egyptian cat', 'computer keyboard', 'boxer'], dtype='&lt;U30')</code></pre><br>
<p>       .                    .</p><br>
<pre><code class="python hljs">plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">9</span>))
<span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> range(<span class="hljs-number">30</span>):<font></font>
  plt.subplot(<span class="hljs-number">6</span>, <span class="hljs-number">5</span>, n+<span class="hljs-number">1</span>)<font></font>
  plt.subplots_adjust(hspace=<span class="hljs-number">0.3</span>)<font></font>
  plt.imshow(image_batch[n])<font></font>
  plt.title(predicted_class_names[n])<font></font>
  plt.axis(<span class="hljs-string">'off'</span>)<font></font>
_ = plt.suptitle(<span class="hljs-string">"ImageNet predictions"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/fc/af/w-/fcafw-kdtzotffq7k-nihlntuda.png"></p><br>
<p><strong> 3:     TensorFlow Hub</strong></p><br>
<p>   TensorFlow Hub        .</p><br>
<p>            ,   ,          .</p><br>
<p> TensorFlow Hub        (  ),       .         .    MobileNet v2    ,                   TensorFlow Lite. </p><br>
<p>         ,            ,     .</p><br>
<p> ,     TensorFlow Hub (   )   <code>feature_extractor</code>.    ,               ().          ,         .      .</p><br>
<pre><code class="python hljs">URL = <span class="hljs-string">'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2'</span>
feature_extractor = hub.KerasLayer(URL, input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number">3</span>))</code></pre><br>
<p>   <code>feature_extractor</code>        (  ). 32 —  , 1280 —         TensorFlow Hub.</p><br>
<pre><code class="python hljs">feature_batch = feature_extractor(image_batch)<font></font>
print(feature_batch.shape)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">(32, 1280)</code></pre><br>
<p>""       ,          .</p><br>
<pre><code class="python hljs">feature_extractor.trainable = <span class="hljs-literal">False</span></code></pre><br>
<p><strong>  </strong></p><br>
<p>    TensorFlow Hub  <code>tf.keras.Sequential</code>-    .</p><br>
<pre><code class="python hljs">model = tf.keras.Sequential([<font></font>
  feature_extractor,<font></font>
  layers.Dense(<span class="hljs-number">2</span>, activation=<span class="hljs-string">'softmax'</span>)<font></font>
])<font></font>
<font></font>
model.summary()</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Model: "sequential_1"<font></font>
_________________________________________________________________<font></font>
Layer (type)                 Output Shape              Param #   <font></font>
=================================================================<font></font>
keras_layer_1 (KerasLayer)   (None, 1280)              2257984   <font></font>
_________________________________________________________________<font></font>
dense (Dense)                (None, 2)                 2562      <font></font>
=================================================================<font></font>
Total params: 2,260,546<font></font>
Trainable params: 2,562<font></font>
Non-trainable params: 2,257,984<font></font>
_________________________________________________________________</code></pre><br>
<p><strong> </strong></p><br>
<p>     ,       <code>compile</code>   <code>fit</code>  .</p><br>
<pre><code class="python hljs">model.compile(<font></font>
    optimizer=<span class="hljs-string">'adam'</span>,<font></font>
    loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,<font></font>
    metrics=[<span class="hljs-string">'accuracy'</span>]<font></font>
)<font></font>
<font></font>
EPOCHS = <span class="hljs-number">6</span><font></font>
history = model.fit(train_batches,<font></font>
                    epochs=EPOCHS,<font></font>
                    validation_data=validation_batches)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Epoch 1/6<font></font>
582/582 [==============================] - 77s 133ms/step - loss: 0.2381 - acc: 0.9346 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00<font></font>
Epoch 2/6<font></font>
582/582 [==============================] - 70s 120ms/step - loss: 0.1827 - acc: 0.9618 - val_loss: 0.1629 - val_acc: 0.9670<font></font>
Epoch 3/6<font></font>
582/582 [==============================] - 69s 119ms/step - loss: 0.1733 - acc: 0.9660 - val_loss: 0.1623 - val_acc: 0.9666<font></font>
Epoch 4/6<font></font>
582/582 [==============================] - 69s 118ms/step - loss: 0.1677 - acc: 0.9676 - val_loss: 0.1627 - val_acc: 0.9677<font></font>
Epoch 5/6<font></font>
582/582 [==============================] - 68s 118ms/step - loss: 0.1636 - acc: 0.9689 - val_loss: 0.1634 - val_acc: 0.9675<font></font>
Epoch 6/6<font></font>
582/582 [==============================] - 69s 118ms/step - loss: 0.1604 - acc: 0.9701 - val_loss: 0.1643 - val_acc: 0.9668</code></pre><br>
<p>         ~97%      . !           ,         ~87%.    ,  MobileNet           ,         ImageNet.</p><br>
<p>   MobileNet  Keras    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>.</p><br>
<p>             .</p><br>
<pre><code class="python hljs">acc = history.history[<span class="hljs-string">'acc'</span>]<font></font>
val_acc = history.history[<span class="hljs-string">'val_acc'</span>]<font></font>
<font></font>
loss = history.history[<span class="hljs-string">'loss'</span>]<font></font>
val_loss = history.history[<span class="hljs-string">'val_loss'</span>]<font></font>
<font></font>
epochs_range = range(EPOCHS)<font></font>
<font></font>
plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<font></font>
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<font></font>
plt.plot(epochs_range, acc, label=<span class="hljs-string">'  '</span>)<font></font>
plt.plot(epochs_range, val_acc, label=<span class="hljs-string">'  '</span>)<font></font>
plt.legend(loc=<span class="hljs-string">'lower right'</span>)<font></font>
plt.title(<span class="hljs-string">'     '</span>)<font></font>
<font></font>
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<font></font>
plt.plot(epochs_range, loss, label=<span class="hljs-string">'  '</span>)<font></font>
plt.plot(epochs_range, val_loss, label=<span class="hljs-string">'  '</span>)<font></font>
plt.legend(loc=<span class="hljs-string">'upper right'</span>)<font></font>
plt.title(<span class="hljs-string">'     '</span>)<font></font>
plt.show()</code></pre><br>
<p><img src="https://habrastorage.org/webt/o7/5c/7a/o75c7aieqvmudmyglkroiddrm90.png"></p><br>
<p>  ,   ,                    .</p><br>
<p>       ,           ,              .</p><br>
<p>       - MobileNet,           .              (  augmentation),    .                  .</p><br>
<p><strong>  </strong></p><br>
<p>             :</p><br>
<pre><code class="python hljs">class_names = np.array(info.features[<span class="hljs-string">'label'</span>].names)<font></font>
class_names</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">array(['cat', 'dog'], dtype='&lt;U3')</code></pre><br>
<p>            :</p><br>
<pre><code class="python hljs">predicted_batch = model.predict(image_batch)<font></font>
predicted_batch = tf.squeeze(predicted_batch).numpy()<font></font>
predicted_ids = np.argmax(predicted_batch, axis=<span class="hljs-number">-1</span>)<font></font>
predicted_class_names = class_names[predicted_ids]<font></font>
predicted_class_names</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">array(['cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat',<font></font>
       'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat',<font></font>
       'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat',<font></font>
       'cat', 'dog', 'cat', 'cat', 'dog'], dtype='&lt;U3')</code></pre><br>
<p>      :</p><br>
<pre><code class="python hljs">print(<span class="hljs-string">": "</span>, label_batch)<font></font>
print(<span class="hljs-string">": "</span>, predicted_ids)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">:  [0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1]<font></font>
:  [0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1]</code></pre><br>
<pre><code class="python hljs">plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">9</span>))
<span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> range(<span class="hljs-number">30</span>):<font></font>
  plt.subplot(<span class="hljs-number">6</span>, <span class="hljs-number">5</span>, n+<span class="hljs-number">1</span>)<font></font>
  plt.subplots_adjust(hspace=<span class="hljs-number">0.3</span>)<font></font>
  plt.imshow(image_batch[n])<font></font>
  color = <span class="hljs-string">"blue"</span> <span class="hljs-keyword">if</span> predicted_ids[n] == label_batch[n] <span class="hljs-keyword">else</span> <span class="hljs-string">"red"</span><font></font>
  plt.title(predicted_class_names[n].title(), color=color)<font></font>
  plt.axis(<span class="hljs-string">'off'</span>)<font></font>
_ = plt.suptitle(<span class="hljs-string">"  (: , : )"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/dc/ox/4w/dcox4wk3fek_1e2j9ltjmvai1ia.png"></p><br>
<h1>    </h1><br>
<p>      ,        . ,   ,          .     ,      ,  ,        .    ,      ,        .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>,   ,       .</p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/50f/d7a/3eb/50fd7a3eb31650740807d84eb8ff1da2.gif" alt="画像"></p><br>
<p>                 .                       .       AlexNet  2012 ,     ,           ImageNet Large-Scale Visual Recognition Challenge. C              ,             .               ,                 .</p><br>
<p>                  ,          ,            .                 ,            , ,   Inception,   .                     .            ,    ,         ,         ,         .</p><br>
<p>      "   Python" <br>
François Chollet.   ,        .    Keras,     ,   " " TensorFlow, MXNET  Theano.   ,        ,            .           ,       .</p><br>
<p><strong>  </strong></p><br>
<p>           ,    ,           .</p><br>
<p>            (training accuracy)     .         ,          ,        , ,   Inception,                .</p><br>
<p>          ,       ,      .   Inception v3 (     ImageNet)     ,    Kaggle.         Inception,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">    </a>,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Inception v3</a>      .</p><br>
<p>    10  ()     32 ,    2292293.           0.3195,     — 0.6377.     <code>ImageDataGenerator</code>     ,      .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">GitHub </a>.</p><br>
<p><strong>  </strong></p><br>
<p>            ,    ""   ,      .               .</p><br>
<p>,              Inception v3 ,        .</p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/d4c/ac1/6f5/d4cac16f506f3d14ab4cca070f4d876b.jpg" alt="画像"></p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/222/102/eda/222102eda480f7108db0c9869ab46057.jpg" alt="画像"></p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/ca8/176/7c0/ca81767c0f5cae4748f1db6cee625e01.jpg" alt="画像"></p><br>
<p>   —     .             .</p><br>
<p>        ,              ()   .        (),       , ,  ,      .          ,      ,        ,     ,       .</p><br>
<p>  ReLU-    .    ,     <code>ReLU(z) = max(0, z)</code>     .</p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/9e3/b87/e17/9e3b87e175577fe97da51fd1a2b50eac.png" alt="画像"></p><br>
<p>         ,   ,   ,        ,      ,           ,   , ,   ..            ,            .     "" ()     ,            ,     ,             .</p><br>
<p><strong>   </strong></p><br>
<p>        ""        .               . </p><br>
<p>  ,     Inveption V3      :</p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/00e/a03/d78/00ea03d78e161d7f6fff59ba1a133309.jpg" alt="画像"></p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/247/875/0da/2478750da1a4eb167f8dc1c9c55252d6.jpg" alt="画像"></p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/4a9/635/bd8/4a9635bd81a0d2e46435a05c39d3457a.jpg" alt="画像"></p><br>
<p>             ,         . ,                   ,      ,           ,   ..          ,       ,                .            ,       ,  ,           "" ( ,      ).</p><br>
<p><strong>    </strong></p><br>
<p>      ,         , ,      .      ,                  .</p><br>
<p>    Class Activation Map (  ).      CAM       .       2D              ,                 .</p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/2f8/95e/f8b/2f895ef8b9086c9ea56745ce0f441ef9.jpg" alt="画像"></p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/6ff/392/e60/6ff392e60f007791bee52e439099759f.jpg" alt="画像"></p><br>
<p><img src="https://habrastorage.org/getpro/habr/post_images/fe9/896/210/fe9896210055693195c21a96b74f3188.jpg" alt="画像"></p><br>
<p>      ,     .    ,    ,        Mixed-  Inception V3-,        .        () ,           .</p><br>
<p>    ,          ,        .          <strong></strong>,            ,        .       ,          .   ,                 ,        ,    ,        .</p><br>
<p>          ,      ""  -          .               .             .</p><br>
<p>   ,           ,                   .</p><br>
<h1> :     </h1><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Colab  </a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Colab  </a>.</p><br>
<p><strong>TensorFlow Hub</strong></p><br>
<p>TensorFlow Hub      ,      .</p><br>
<p>                 .     ,      ,   ,          .</p><br>
<p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>      .</p><br>
<p>             <code>Runtime -&gt; Reset all runtimes...</code></p><br>
<p><strong></strong></p><br>
<p> ,    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
tf.enable_eager_execution()<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow_hub <span class="hljs-keyword">as</span> hub
<span class="hljs-keyword">import</span> tensorflow_datasets <span class="hljs-keyword">as</span> tfds<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">WARNING:tensorflow:<font></font>
The TensorFlow contrib module will not be included in TensorFlow 2.0.<font></font>
For more information, please see:<font></font>
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md<font></font>
  * https://github.com/tensorflow/addons<font></font>
  * https://github.com/tensorflow/io (for I/O related ops)<font></font>
If you depend on functionality not listed there, please file an issue.</code></pre><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> logging<font></font>
logger = tf.get_logger()<font></font>
logger.setLevel(logging.ERROR)</code></pre><br>
<p><strong>      TensorFlow Datasets</strong></p><br>
<p>           TensorFlow Datasets.   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a>,       — <code>tf_flowers</code>.        ,       .                <code>tfds.splits</code>   (70%)   (30%).        <code>tfds.load</code>.    <code>tfds.load</code> ,            ,      .</p><br>
<pre><code class="python hljs">splits = tfds.Split.TRAIN.subsplit([<span class="hljs-number">70</span>, <span class="hljs-number">30</span>])<font></font>
<font></font>
(training_set, validation_set), dataset_info = tfds.load(<span class="hljs-string">'tf_flowers'</span>, with_info=<span class="hljs-literal">True</span>, as_supervised=<span class="hljs-literal">True</span>, split=splits)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Downloading and preparing dataset tf_flowers (218.21 MiB) to /root/tensorflow_datasets/tf_flowers/1.0.0...<font></font>
<font></font>
Dl Completed...<font></font>
1/|/100% 1/1 [00:07&lt;00:00, 3.67s/ url]<font></font>
Dl Size...<font></font>
218/|/100% 218/218 [00:07&lt;00:00, 30.69 MiB/s]<font></font>
Extraction completed...<font></font>
1/|/100% 1/1 [00:07&lt;00:00, 7.05s/ file]<font></font>
<font></font>
Dataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/1.0.0. Subsequent calls will reuse this data.</code></pre><br>
<p><strong>     </strong></p><br>
<p>,      ,    ()         ,      ,          —   .</p><br>
<pre><code class="python hljs">num_classes = dataset_info.features[<span class="hljs-string">'label'</span>].num_classes<font></font>
<font></font>
num_training_examples = <span class="hljs-number">0</span>
num_validation_examples = <span class="hljs-number">0</span><font></font>
<font></font>
<span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> training_set:<font></font>
  num_training_examples += <span class="hljs-number">1</span><font></font>
<font></font>
<span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> validation_set:<font></font>
  num_validation_examples += <span class="hljs-number">1</span><font></font>
<font></font>
print(<span class="hljs-string">'Total Number of Classes: {}'</span>.format(num_classes))<font></font>
print(<span class="hljs-string">'Total Number of Training Images: {}'</span>.format(num_training_examples))<font></font>
print(<span class="hljs-string">'Total Number of Validation Images: {} \n'</span>.format(num_validation_examples))</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Total Number of Classes: 5<font></font>
Total Number of Training Images: 2590<font></font>
Total Number of Validation Images: 1080 </code></pre><br>
<p>       —  .</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> i, example <span class="hljs-keyword">in</span> enumerate(training_set.take(<span class="hljs-number">5</span>)):<font></font>
  print(<span class="hljs-string">'Image {} shape: {} label: {}'</span>.format(i+<span class="hljs-number">1</span>, example[<span class="hljs-number">0</span>].shape, example[<span class="hljs-number">1</span>]))</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Image 1 shape: (226, 240, 3) label: 0<font></font>
Image 2 shape: (240, 145, 3) label: 2<font></font>
Image 3 shape: (331, 500, 3) label: 2<font></font>
Image 4 shape: (240, 320, 3) label: 0<font></font>
Image 5 shape: (333, 500, 3) label: 1</code></pre><br>
<p><strong>     </strong></p><br>
<p>         — ,   MobilNet v2     — 224224     (grayscale).     <code>image</code> ()  <code>label</code> ()       .</p><br>
<pre><code class="python hljs">IMAGE_RES = <span class="hljs-number">224</span><font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">format_image</span>(<span class="hljs-params">image, label</span>):</span>
  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/<span class="hljs-number">255.0</span>
  <span class="hljs-keyword">return</span> image, label<font></font>
<font></font>
BATCH_SIZE = <span class="hljs-number">32</span><font></font>
<font></font>
train_batches = training_set.shuffle(num_training_examples//<span class="hljs-number">4</span>).map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number">1</span>)<font></font>
<font></font>
validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number">1</span>)</code></pre><br>
<p><strong>    TensorFlow Hub</strong></p><br>
<p>   TensorFlow Hub   . ,                      ,         .</p><br>
<p><strong>   </strong></p><br>
<p>     <code>feature_extractor</code>  MobileNet v2. ,      TensorFlow Hub (   )   .          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a>.   <code>tf2-preview/mobilenet_v2/feature_vector</code>,     URL       MobileNet v2 .   <code>feature_extractor</code>   <code>hub.KerasLayer</code>      <code>input_shape</code>.</p><br>
<pre><code class="python hljs">URL = <span class="hljs-string">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"</span><font></font>
feature_extractor = hub.KerasLayer(URL,<font></font>
                                   input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number">3</span>))</code></pre><br>
<p><strong>   </strong></p><br>
<p>                  ,   :</p><br>
<pre><code class="python hljs">feature_extractor.trainable = <span class="hljs-literal">False</span></code></pre><br>
<p><strong>  </strong></p><br>
<p>              ,   .            .          .</p><br>
<pre><code class="python hljs">model = tf.keras.Sequential([<font></font>
  feature_extractor,<font></font>
  layers.Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>)<font></font>
])<font></font>
<font></font>
model.summary()</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Model: "sequential"<font></font>
_________________________________________________________________<font></font>
Layer (type)                 Output Shape              Param #   <font></font>
=================================================================<font></font>
keras_layer (KerasLayer)     (None, 1280)              2257984   <font></font>
_________________________________________________________________<font></font>
dense (Dense)                (None, 5)                 6405      <font></font>
=================================================================<font></font>
Total params: 2,264,389<font></font>
Trainable params: 6,405<font></font>
Non-trainable params: 2,257,984</code></pre><br>
<p><strong> </strong></p><br>
<p>           ,           .</p><br>
<pre><code class="python hljs">model.compile(<font></font>
  optimizer=<span class="hljs-string">'adam'</span>,<font></font>
  loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,<font></font>
  metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
<font></font>
EPOCHS = <span class="hljs-number">6</span><font></font>
<font></font>
history = model.fit(train_batches,<font></font>
                    epochs=EPOCHS,<font></font>
                    validation_data=validation_batches)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Epoch 1/6<font></font>
81/81 [==============================] - 17s 216ms/step - loss: 0.7765 - acc: 0.7170 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00<font></font>
Epoch 2/6<font></font>
81/81 [==============================] - 12s 147ms/step - loss: 0.3806 - acc: 0.8757 - val_loss: 0.3485 - val_acc: 0.8833<font></font>
Epoch 3/6<font></font>
81/81 [==============================] - 12s 146ms/step - loss: 0.3011 - acc: 0.9031 - val_loss: 0.3190 - val_acc: 0.8907<font></font>
Epoch 4/6<font></font>
81/81 [==============================] - 12s 147ms/step - loss: 0.2527 - acc: 0.9205 - val_loss: 0.3031 - val_acc: 0.8917<font></font>
Epoch 5/6<font></font>
81/81 [==============================] - 12s 148ms/step - loss: 0.2177 - acc: 0.9371 - val_loss: 0.2933 - val_acc: 0.8972<font></font>
Epoch 6/6<font></font>
81/81 [==============================] - 12s 146ms/step - loss: 0.1905 - acc: 0.9456 - val_loss: 0.2870 - val_acc: 0.9000</code></pre><br>
<p>        ~90%  6  ,     !   ,    ,           ~76%  80  .        ,  MobilNet v2                .</p><br>
<p><strong>         </strong></p><br>
<p>              .</p><br>
<pre><code class="python hljs">acc = history.history[<span class="hljs-string">'acc'</span>]<font></font>
val_acc = history.history[<span class="hljs-string">'val_acc'</span>]<font></font>
<font></font>
loss = history.history[<span class="hljs-string">'loss'</span>]<font></font>
val_loss = history.history[<span class="hljs-string">'val_loss'</span>]<font></font>
<font></font>
epochs_range = range(EPOCHS)<font></font>
<font></font>
plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<font></font>
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<font></font>
plt.plot(epochs_range, acc, label=<span class="hljs-string">'Training Accuracy'</span>)<font></font>
plt.plot(epochs_range, val_acc, label=<span class="hljs-string">'Validation Accuracy'</span>)<font></font>
plt.legend(loc=<span class="hljs-string">'lower right'</span>)<font></font>
plt.title(<span class="hljs-string">'Training and Validation Accuracy'</span>)<font></font>
<font></font>
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<font></font>
plt.plot(epochs_range, loss, label=<span class="hljs-string">'Training Loss'</span>)<font></font>
plt.plot(epochs_range, val_loss, label=<span class="hljs-string">'Validation Loss'</span>)<font></font>
plt.legend(loc=<span class="hljs-string">'upper right'</span>)<font></font>
plt.title(<span class="hljs-string">'Training and Validation Loss'</span>)<font></font>
plt.show()</code></pre><br>
<p><img src="https://habrastorage.org/webt/ox/nb/hy/oxnbhyqanark0qrt1xmeqg3qv4a.png"></p><br>
<p>  ,   ,                    .</p><br>
<p>       ,           ,              .</p><br>
<p>       - MobileNet,           .              (  augmentation),    .                  .</p><br>
<p><strong> </strong></p><br>
<p>             NumPy.     ,      .</p><br>
<pre><code class="python hljs">class_names = np.array(dataset_info.features[<span class="hljs-string">'label'</span>].names)<font></font>
<font></font>
print(class_names)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">['dandelion' 'daisy' 'tulips' 'sunflowers' 'roses']</code></pre><br>
<p><strong>        </strong></p><br>
<p>  <code>next()</code>   <code>image_batch</code> ( )   <code>label_batch</code> ( ).   <code>image_batch</code>  <code>label_batch</code>  NumPy     <code>.numpy()</code>.    <code>.predict()</code>      .        <code>np.argmax()</code>   .            .</p><br>
<pre><code class="python hljs">image_batch, label_batch = next(iter(train_batches))<font></font>
<font></font>
image_batch = image_batch.numpy()<font></font>
label_batch = label_batch.numpy()<font></font>
<font></font>
predicted_batch = model.predict(image_batch)<font></font>
predicted_batch = tf.squeeze(predicted_batch).numpy()<font></font>
<font></font>
predicted_ids = np.argmax(predicted_batch, axis=<span class="hljs-number">-1</span>)<font></font>
predicted_class_names = class_names[predicted_ids]<font></font>
<font></font>
print(predicted_class_names)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">['sunflowers' 'roses' 'tulips' 'tulips' 'daisy' 'dandelion' 'tulips'<font></font>
 'sunflowers' 'daisy' 'daisy' 'tulips' 'daisy' 'daisy' 'tulips' 'tulips'<font></font>
 'tulips' 'dandelion' 'dandelion' 'tulips' 'tulips' 'dandelion' 'roses'<font></font>
 'daisy' 'daisy' 'dandelion' 'roses' 'daisy' 'tulips' 'dandelion'<font></font>
 'dandelion' 'roses' 'dandelion']</code></pre><br>
<p><strong>     </strong></p><br>
<pre><code class="python hljs">print(<span class="hljs-string">"Labels:           "</span>, label_batch)<font></font>
print(<span class="hljs-string">"Predicted labels: "</span>, predicted_ids)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Labels:            [3 4 2 2 1 0 2 3 1 1 2 1 1 2 2 2 0 0 2 2 0 4 1 1 0 4 1 2 0 0 4 0]<font></font>
Predicted labels:  [3 4 2 2 1 0 2 3 1 1 2 1 1 2 2 2 0 0 2 2 0 4 1 1 0 4 1 2 0 0 4 0]</code></pre><br>
<p><strong>  </strong></p><br>
<pre><code class="python hljs">plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">9</span>))
<span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> range(<span class="hljs-number">30</span>):<font></font>
  plt.subplot(<span class="hljs-number">6</span>,<span class="hljs-number">5</span>,n+<span class="hljs-number">1</span>)<font></font>
  plt.subplots_adjust(hspace = <span class="hljs-number">0.3</span>)<font></font>
  plt.imshow(image_batch[n])<font></font>
  color = <span class="hljs-string">"blue"</span> <span class="hljs-keyword">if</span> predicted_ids[n] == label_batch[n] <span class="hljs-keyword">else</span> <span class="hljs-string">"red"</span><font></font>
  plt.title(predicted_class_names[n].title(), color=color)<font></font>
  plt.axis(<span class="hljs-string">'off'</span>)<font></font>
_ = plt.suptitle(<span class="hljs-string">"Model predictions (blue: correct, red: incorrect)"</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/e1/q-/rg/e1q-rgvnr6qns8-vvrcr8yzbexi.png"></p><br>
<p><strong>     Inception-</strong></p><br>
<p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> TensorFlow Hub</a>     <code>tf2-preview/inception_v3/feature_vector</code>.        Inception V3 .      ,      Inception V3     .  ,  Inception V3       299299 .   Inception V3    MobileNet V2.</p><br>
<pre><code class="python hljs">IMAGE_RES = <span class="hljs-number">299</span><font></font>
<font></font>
(training_set, validation_set), dataset_info = tfds.load(<span class="hljs-string">'tf_flowers'</span>, with_info=<span class="hljs-literal">True</span>, as_supervised=<span class="hljs-literal">True</span>, split=splits)<font></font>
train_batches = training_set.shuffle(num_training_examples//<span class="hljs-number">4</span>).map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number">1</span>)<font></font>
validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number">1</span>)<font></font>
<font></font>
URL = <span class="hljs-string">"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4"</span><font></font>
feature_extractor = hub.KerasLayer(URL,<font></font>
  input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number">3</span>),<font></font>
  trainable=<span class="hljs-literal">False</span>)<font></font>
<font></font>
model_inception = tf.keras.Sequential([<font></font>
  feature_extractor,<font></font>
  tf.keras.layers.Dense(num_classes, activation=<span class="hljs-string">'softmax'</span>)<font></font>
])<font></font>
<font></font>
model_inception.summary()</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Model: "sequential_1"<font></font>
_________________________________________________________________<font></font>
Layer (type)                 Output Shape              Param #   <font></font>
=================================================================<font></font>
keras_layer_1 (KerasLayer)   (None, 2048)              21802784  <font></font>
_________________________________________________________________<font></font>
dense_1 (Dense)              (None, 5)                 10245     <font></font>
=================================================================<font></font>
Total params: 21,813,029<font></font>
Trainable params: 10,245<font></font>
Non-trainable params: 21,802,784</code></pre><br>
<pre><code class="python hljs">model_inception.compile(<font></font>
  optimizer=<span class="hljs-string">'adam'</span>, <font></font>
  loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,<font></font>
  metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
<font></font>
EPOCHS = <span class="hljs-number">6</span><font></font>
<font></font>
history = model_inception.fit(train_batches,<font></font>
                    epochs=EPOCHS,<font></font>
                    validation_data=validation_batches)</code></pre><br>
<p>:</p><br>
<pre><code class="plaintext hljs">Epoch 1/6<font></font>
81/81 [==============================] - 44s 541ms/step - loss: 0.7594 - acc: 0.7309 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00<font></font>
Epoch 2/6<font></font>
81/81 [==============================] - 35s 434ms/step - loss: 0.3927 - acc: 0.8772 - val_loss: 0.3945 - val_acc: 0.8657<font></font>
Epoch 3/6<font></font>
81/81 [==============================] - 35s 434ms/step - loss: 0.3074 - acc: 0.9120 - val_loss: 0.3586 - val_acc: 0.8769<font></font>
Epoch 4/6<font></font>
81/81 [==============================] - 35s 434ms/step - loss: 0.2588 - acc: 0.9282 - val_loss: 0.3385 - val_acc: 0.8796<font></font>
Epoch 5/6<font></font>
81/81 [==============================] - 35s 436ms/step - loss: 0.2252 - acc: 0.9375 - val_loss: 0.3256 - val_acc: 0.8824<font></font>
Epoch 6/6<font></font>
81/81 [==============================] - 35s 435ms/step - loss: 0.1996 - acc: 0.9440 - val_loss: 0.3164 - val_acc: 0.8861</code></pre><br>
<h1></h1><br>
<p>                  .          :</p><br>
<ul>
<li><strong> :</strong> ,                .              .</li>
<li><strong> :</strong>       . ""     ,       ,      .</li>
<li><strong>MobileNet:</strong>       Google,                  . MobileNet              .</li>
</ul><br>
<p>             MobileNet      .                     .                   MobileNet    .</p><br>
<p>…   call-to-action — ,     share :)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">YouTube</a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Telegram</a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a><br>
  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Ojok</a>.</p></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja467953/index.html">安価な仮想サーバーのテスト</a></li>
<li><a href="../ja467957/index.html">ファイゲンバウム定数の背後にあるもの</a></li>
<li><a href="../ja467959/index.html">ブラウザの宇宙論と量子ゆらぎ</a></li>
<li><a href="../ja467961/index.html">React.jsを使用してSmartTV用に開発する際の問題とニュアンス</a></li>
<li><a href="../ja467965/index.html">Vivaldi 2.8-メニューをお願いします</a></li>
<li><a href="../ja467969/index.html">iOS 13のモーダルモーダル画面プレゼンテーション</a></li>
<li><a href="../ja467973/index.html">プラットフォームの誕生</a></li>
<li><a href="../ja467975/index.html">Huawei Dorado V6：四川熱</a></li>
<li><a href="../ja467977/index.html">Vue.jsのStyled-Componentsを使用したアプリケーションの作成</a></li>
<li><a href="../ja467979/index.html">広告の統合：それはどのように機能しますか？</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
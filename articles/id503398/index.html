<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>〽️ 👩🏾‍🎨 👋🏾 Bagaimana membuat pemodelan tematik suatu forum dengan cepat atau apa yang mengganggu penderita penyakit celiac 🐽 🔥 🕗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam artikel ini saya akan memberi tahu dan menunjukkan contoh bagaimana seseorang dengan pengalaman Ilmu Data minimal mampu mengumpulkan data dari f...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Bagaimana membuat pemodelan tematik suatu forum dengan cepat atau apa yang mengganggu penderita penyakit celiac</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/503398/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam artikel ini saya akan memberi tahu dan menunjukkan contoh bagaimana seseorang dengan pengalaman Ilmu Data minimal mampu mengumpulkan data dari forum dan membuat pemodelan tematik posting menggunakan model LDA, dan mengungkapkan topik menyakitkan bagi orang-orang dengan intoleransi seliaka. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tahun lalu saya perlu segera meningkatkan pengetahuan saya di bidang pembelajaran mesin. Saya seorang manajer produk untuk Ilmu Data, Pembelajaran Mesin dan AI, atau dengan cara lain Manajer Produk Teknis AI / ML. Keterampilan bisnis dan kemampuan untuk mengembangkan produk, seperti biasanya dalam proyek yang ditujukan untuk pengguna yang tidak berada di bidang teknis, tidak cukup. Anda perlu memahami konsep teknis dasar industri ML, dan jika perlu, dapat menulis sendiri contoh untuk mendemonstrasikan produk.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selama sekitar 5 tahun saya telah mengembangkan proyek-proyek Front-end, mengembangkan aplikasi web yang kompleks pada JS dan React, tetapi saya tidak pernah berurusan dengan pembelajaran mesin, laptop dan algoritma. Karena itu, ketika saya melihat berita dari </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otus</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bahwa mereka membuka </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kursus</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eksperimental lima bulan </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">tentang Pembelajaran Mesin</font></a><font style="vertical-align: inherit;"> , tanpa ragu-ragu, saya memutuskan untuk menjalani uji coba dan melanjutkan kursus.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selama lima bulan, setiap minggu ada kuliah dan pekerjaan rumah selama dua jam untuk mereka. Di sana saya belajar tentang dasar-dasar ML: berbagai algoritma regresi, klasifikasi, ansambel model, peningkatan gradien, dan bahkan teknologi cloud yang sedikit terpengaruh. Pada prinsipnya, jika Anda mendengarkan dengan seksama setiap ceramah, maka ada cukup banyak contoh dan penjelasan untuk pekerjaan rumah. Tapi tetap saja, kadang-kadang, seperti dalam proyek pengkodean lainnya, saya harus beralih ke dokumentasi. Mengingat pekerjaan penuh waktu saya, cukup mudah untuk belajar, karena saya selalu dapat merevisi catatan kuliah online.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada akhir pelatihan kursus ini, semua orang harus mengambil tugas akhir. </font><font style="vertical-align: inherit;">Gagasan untuk proyek tersebut muncul secara spontan, pada saat itu saya memulai pelatihan kewirausahaan di Stanford, di mana saya bergabung dengan tim yang mengerjakan proyek untuk orang-orang dengan intoleransi seliaka. </font><font style="vertical-align: inherit;">Selama riset pasar, saya tertarik untuk mengetahui kekhawatiran apa, apa yang mereka bicarakan, keluhan orang-orang dengan fitur ini. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ketika penelitian berlanjut, saya menemukan forum di </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">celiac.com</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dengan sejumlah besar bahan pada penyakit celiac. </font><font style="vertical-align: inherit;">Jelas bahwa menggulir secara manual dan membaca lebih dari 100 ribu posting tidak praktis. </font><font style="vertical-align: inherit;">Maka muncul ide bagi saya, untuk menerapkan pengetahuan yang saya terima dalam kursus ini: untuk mengumpulkan semua pertanyaan dan komentar dari forum dari topik tertentu dan membuat pemodelan tematik dengan kata-kata yang paling umum di masing-masingnya.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Langkah 1. Pengumpulan data dari forum</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Forum ini terdiri dari banyak topik dengan berbagai ukuran. </font><font style="vertical-align: inherit;">Secara total, forum ini memiliki sekitar 115.000 topik dan sekitar satu juta posting, dengan komentar tentangnya. </font><font style="vertical-align: inherit;">Saya tertarik pada subtopik khusus </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Mengatasi Penyakit Celiac"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , yang secara harfiah berarti "Mengatasi penyakit Celiac", jika dalam bahasa Rusia, itu berarti lebih "melanjutkan hidup dengan diagnosis penyakit celiac dan entah bagaimana mengatasi kesulitan". </font><font style="vertical-align: inherit;">Sub-topik ini berisi sekitar 175.000 komentar. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pengunduhan data terjadi dalam dua tahap. </font><font style="vertical-align: inherit;">Untuk memulainya, saya harus membaca semua halaman di bawah topik dan mengumpulkan semua tautan ke semua posting, sehingga pada langkah berikutnya, saya sudah bisa mengumpulkan komentar.</font></font><br>
<br>
<pre><code class="python hljs">url_coping = <span class="hljs-string">'https://www.celiac.com/forums/forum/5-coping-with-celiac-disease/'</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Karena forum ini ternyata sudah sangat tua, saya sangat beruntung dan situsnya tidak memiliki masalah keamanan, jadi untuk mengumpulkan data, cukup menggunakan kombinasi </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agen-Pengguna</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dari </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fake_useragent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">perpustakaan </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beautiful Soup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> untuk bekerja dengan markup html dan mengetahui jumlah halaman:</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># Get total number of pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_count</span>(<span class="hljs-params">url</span>):</span>
    response = requests.get(url, headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
    soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
    last_page_section = soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsPagination_last'</span>})
    <span class="hljs-keyword">if</span> (last_page_section):<font></font>
        count_link = last_page_section.find(<span class="hljs-string">'a'</span>)
        <span class="hljs-keyword">return</span> int(count_link[<span class="hljs-string">'data-page'</span>])
    <span class="hljs-keyword">else</span>: 
        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><font></font>
<font></font>
coping_pages_count = get_pages_count(url_coping)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dan kemudian unduh HTML DOM dari setiap halaman untuk dengan mudah dan mudah menarik data dari mereka menggunakan pustaka </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BeautifulSoup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Python </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># collect pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">retrieve_pages</span>(<span class="hljs-params">pages_count, url</span>):</span><font></font>
    pages = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(pages_count):<font></font>
        response = requests.get(<span class="hljs-string">'{}page/{}'</span>.format(url, page), headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
        soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
        pages.append(soup)<font></font>
    <span class="hljs-keyword">return</span> pages<font></font>
<font></font>
coping_pages = retrieve_pages(coping_pages_count, url_coping)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk mengunduh data, saya perlu menentukan bidang yang diperlukan untuk analisis: menemukan nilai bidang ini di DOM dan menyimpannya dalam kamus. </font><font style="vertical-align: inherit;">Saya sendiri datang dari latar belakang Front-end, jadi bekerja dengan rumah dan benda-benda sepele bagi saya.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_post_info</span>(<span class="hljs-params">pages</span>):</span><font></font>
    posts = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> pages:<font></font>
        posts_list_soup = page.find(<span class="hljs-string">'ol'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataList'</span>}).findAll(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataItem'</span>})
        <span class="hljs-keyword">for</span> post_soup <span class="hljs-keyword">in</span> posts_list_soup:<font></font>
            post = {}<font></font>
            post[<span class="hljs-string">'id'</span>] = uuid.uuid4()
            <span class="hljs-comment"># collecting titles and urls</span>
            title_section = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_break ipsContained'</span>})
            <span class="hljs-keyword">if</span> (title_section):<font></font>
                title_section_a = title_section.find(<span class="hljs-string">'a'</span>)<font></font>
                post[<span class="hljs-string">'title'</span>] = title_section_a[<span class="hljs-string">'title'</span>]<font></font>
                post[<span class="hljs-string">'url'</span>] = title_section_a[<span class="hljs-string">'data-ipshover-target'</span>]
            <span class="hljs-comment"># collecting author &amp; last action</span>
            author_section = post_soup.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_meta'</span>})
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_a = post_soup.find(<span class="hljs-string">'a'</span>)<font></font>
                author_section_time = post_soup.find(<span class="hljs-string">'time'</span>)<font></font>
                post[<span class="hljs-string">'author'</span>] = author_section_a[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
                post[<span class="hljs-string">'last_action'</span>] = author_section_time[<span class="hljs-string">'datetime'</span>]
            <span class="hljs-comment"># collecting stats</span>
            stats_section = post_soup.find(<span class="hljs-string">'ul'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats'</span>})
            <span class="hljs-keyword">if</span> (stats_section):<font></font>
                stats_section_replies = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>})
                <span class="hljs-keyword">if</span> (stats_section_replies):<font></font>
                    post[<span class="hljs-string">'replies'</span>] = stats_section_replies.getText()<font></font>
                stats_section_views = post_soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_light'</span>})
                <span class="hljs-keyword">if</span> (stats_section_views):<font></font>
                    post[<span class="hljs-string">'views'</span>] = stats_section_views.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>}).getText()<font></font>
            posts.append(post)<font></font>
    <span class="hljs-keyword">return</span> posts
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secara total, saya mengumpulkan sekitar 15.450 posting dalam topik ini.</font></font><br>
<br>
<pre><code class="python hljs">coping_posts_info = collect_post_info(coping_pages)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang mereka dapat ditransfer ke DataFrame sehingga mereka berbaring di sana dengan indah, dan pada saat yang sama menyimpannya dalam file csv sehingga Anda tidak perlu menunggu lagi ketika data dikumpulkan dari situs jika notebook secara tidak sengaja rusak atau saya secara tidak sengaja mendefinisikan ulang variabel di mana. </font></font><br>
<br>
<pre><code class="python hljs">df_coping = pd.DataFrame(coping_posts_info, <font></font>
               columns =[<span class="hljs-string">'title'</span>, <span class="hljs-string">'url'</span>, <span class="hljs-string">'author'</span>, <span class="hljs-string">'last_action'</span>, <span class="hljs-string">'replies'</span>, <span class="hljs-string">'views'</span>]) <font></font>
<font></font>
<span class="hljs-comment"># format data</span>
df_coping[<span class="hljs-string">'replies'</span>] = df_coping[<span class="hljs-string">'replies'</span>].astype(int)<font></font>
df_coping[<span class="hljs-string">'views'</span>] = df_coping[<span class="hljs-string">'views'</span>].apply(<span class="hljs-keyword">lambda</span> x: int(x.replace(<span class="hljs-string">','</span>,<span class="hljs-string">''</span>)))<font></font>
df_coping.to_csv(<span class="hljs-string">'celiac_forum_coping.csv'</span>, sep=<span class="hljs-string">','</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setelah mengumpulkan koleksi posting, saya melanjutkan untuk mengumpulkan komentar sendiri.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_postpage_details</span>(<span class="hljs-params">pages, df</span>):</span><font></font>
    comments = []<font></font>
    <span class="hljs-keyword">for</span> i, page <span class="hljs-keyword">in</span> enumerate(pages):<font></font>
        articles = page.findAll(<span class="hljs-string">'article'</span>)
        <span class="hljs-keyword">for</span> k, article <span class="hljs-keyword">in</span> enumerate(articles):<font></font>
            comment = {<font></font>
                <span class="hljs-string">'url'</span>: df[<span class="hljs-string">'url'</span>][i]<font></font>
            }<font></font>
            <span class="hljs-keyword">if</span>(k == <span class="hljs-number">0</span>):<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">1</span>
            <span class="hljs-keyword">else</span>:<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">0</span>
            <span class="hljs-comment"># collecting comments</span>
            comment_section = article.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsComment_content'</span>})
            <span class="hljs-keyword">if</span> (comment_section):<font></font>
                comment_section_p = comment_section.find(<span class="hljs-string">'p'</span>)
                <span class="hljs-keyword">if</span>(comment_section_p):<font></font>
                    comment[<span class="hljs-string">'comment'</span>] = comment_section_p.getText()<font></font>
            comment[<span class="hljs-string">'date'</span>] = comment_section.find(<span class="hljs-string">'time'</span>)[<span class="hljs-string">'datetime'</span>]<font></font>
            author_section = article.find(<span class="hljs-string">'strong'</span>)
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_url = author_section.find(<span class="hljs-string">'a'</span>)
                <span class="hljs-keyword">if</span> (author_section_url):<font></font>
                    comment[<span class="hljs-string">'author'</span>] = author_section_url[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
            comments.append(comment)<font></font>
    <span class="hljs-keyword">return</span> comments<font></font>
<font></font>
coping_data = collect_postpage_details(coping_comments_pages, df_coping)<font></font>
df_coping_comments.to_csv(<span class="hljs-string">'celiac_forum_coping_comments_1.csv'</span>, sep=<span class="hljs-string">','</span>)<font></font>
<font></font>
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LANGKAH 2 Analisis Data dan Pemodelan Tematik</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada langkah sebelumnya, kami mengumpulkan data dari forum dan menerima data akhir dalam bentuk 153777 baris pertanyaan dan komentar. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tetapi data yang dikumpulkan tidak menarik, jadi hal pertama yang ingin saya lakukan adalah analitik yang sangat sederhana: Saya memperoleh statistik untuk 30 topik yang paling banyak dilihat dan 30 topik yang paling banyak dikomentari. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9o/ai/dj/9oaidjzovi7va3alxg7vdwkts84.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Posting yang paling banyak dilihat tidak sesuai dengan yang paling banyak dikomentari. Judul posting yang dikomentari, bahkan pada pandangan pertama, terlihat. Nama mereka lebih emosional: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Aku benci, aku benci, aku benci"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> atau " </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">komentar sombong"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> atau </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Wow, aku dalam masalah</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><i><font style="vertical-align: inherit;">"</font></i><font style="vertical-align: inherit;"> Dan yang paling banyak ditonton memiliki format pertanyaan: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Bisakah saya makan kedelai?", "Mengapa saya tidak bisa menyerap air dengan baik?"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lain. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami melakukan analisis teks sederhana. </font><font style="vertical-align: inherit;">Untuk langsung ke analisis yang lebih kompleks, Anda perlu menyiapkan data itu sendiri sebelum mengirimkannya ke input model LDA untuk pengelompokan berdasarkan topik. </font><font style="vertical-align: inherit;">Untuk melakukan ini, singkirkan komentar yang mengandung kurang dari 30 kata, untuk menyaring spam dan komentar pendek yang tidak berarti. </font><font style="vertical-align: inherit;">Kami membawanya ke huruf kecil.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># Let's get rid of text &lt; 30 words</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_text_words</span>(<span class="hljs-params">text, min_words = <span class="hljs-number">30</span></span>):</span><font></font>
    text = str(text)<font></font>
    <span class="hljs-keyword">return</span> len(text.split()) &gt; <span class="hljs-number">30</span>
filtered_comments = filtered_comments[filtered_comments[<span class="hljs-string">'comment'</span>].apply(filter_text_words)]<font></font>
comments_only = filtered_comments[<span class="hljs-string">'comment'</span>]<font></font>
comments_only= comments_only.apply(<span class="hljs-keyword">lambda</span> x: x.lower())<font></font>
comments_only.head()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hapus kata berhenti yang tidak perlu untuk menghapus pilihan teks kami</font></font><br>
<br>
<pre><code class="python hljs">stop_words = stopwords.words(<span class="hljs-string">'english'</span>)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">remove_stop_words</span>(<span class="hljs-params">tokens</span>):</span><font></font>
    new_tokens = []<font></font>
    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tokens:<font></font>
        token = []<font></font>
        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> t:
            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words:<font></font>
                token.append(word)<font></font>
        new_tokens.append(token)<font></font>
    <span class="hljs-keyword">return</span> new_tokens<font></font>
<font></font>
tokens = remove_stop_words(data_words)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami juga menambahkan bigrams dan membentuk sekumpulan kata untuk menyorot frasa stabil, misalnya, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seperti gluten_free, support_group</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , dan frasa lain yang, ketika dikelompokkan, memiliki arti tertentu.</font></font><br>
<br>
<pre><code class="python hljs">
bigram = gensim.models.Phrases(tokens, min_count=<span class="hljs-number">5</span>, threshold=<span class="hljs-number">100</span>)<font></font>
bigram_mod = gensim.models.phrases.Phraser(bigram)<font></font>
bigram_mod.save(<span class="hljs-string">'bigram_mod.pkl'</span>)<font></font>
bag_of_words = [bigram_mod[w] <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens]
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'bigrams.pkl'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:<font></font>
    pickle.dump(bag_of_words, f)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang kami akhirnya siap untuk langsung melatih model LDA itu sendiri.</font></font><br>
<br>
<pre><code class="python hljs"><font></font>
id2word = corpora.Dictionary(bag_of_words)<font></font>
id2word.save(<span class="hljs-string">'id2word.pkl'</span>)<font></font>
id2word.filter_extremes(no_below=<span class="hljs-number">3</span>, no_above=<span class="hljs-number">0.4</span>, keep_n=<span class="hljs-number">3</span>*<span class="hljs-number">10</span>**<span class="hljs-number">6</span>)<font></font>
corpus = [id2word.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> bag_of_words]<font></font>
<font></font>
lda_model = gensim.models.ldamodel.LdaModel(<font></font>
    corpus, <font></font>
    id2word=id2word, <font></font>
    eval_every=<span class="hljs-number">20</span>,<font></font>
    random_state=<span class="hljs-number">42</span>,<font></font>
    num_topics=<span class="hljs-number">30</span>, <font></font>
    passes=<span class="hljs-number">5</span><font></font>
    )<font></font>
lda_model.save(<span class="hljs-string">'lda_default_2.pkl'</span>)<font></font>
topics = lda_model.show_topics(num_topics=<span class="hljs-number">30</span>, num_words=<span class="hljs-number">100</span>, formatted=<span class="hljs-literal">False</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di akhir pelatihan, kami akhirnya mendapatkan hasil dari topik yang terbentuk. Yang saya lampirkan di akhir posting ini.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(lda_model.num_topics):<font></font>
    plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">10</span>))<font></font>
    plt.imshow(WordCloud(background_color=<span class="hljs-string">"white"</span>, max_words=<span class="hljs-number">100</span>, width=<span class="hljs-number">900</span>, height=<span class="hljs-number">900</span>, collocations=<span class="hljs-literal">False</span>)<font></font>
               .fit_words(dict(topics[t][<span class="hljs-number">1</span>])))<font></font>
    plt.axis(<span class="hljs-string">"off"</span>)<font></font>
    plt.title(<span class="hljs-string">"Topic #"</span> + themes_headers[t])<font></font>
    plt.show()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Karena mungkin terlihat, topik ternyata cukup berbeda dalam konten satu sama lain. </font><font style="vertical-align: inherit;">Menurut mereka, menjadi jelas apa yang orang bicarakan dengan intoleransi seliaka. </font><font style="vertical-align: inherit;">Pada dasarnya, tentang makanan, pergi ke restoran, makanan yang terkontaminasi dengan gluten, rasa sakit yang mengerikan, perawatan, pergi ke dokter, keluarga, kesalahpahaman dan hal-hal lain yang harus dihadapi setiap hari sehubungan dengan masalah mereka. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Itu saja. </font><font style="vertical-align: inherit;">Terima kasih atas perhatiannya. </font><font style="vertical-align: inherit;">Saya harap Anda menemukan bahan ini menarik dan bermanfaat. </font><font style="vertical-align: inherit;">Namun, karena saya bukan pengembang DS, jangan menilai dengan ketat. </font><font style="vertical-align: inherit;">Jika ada sesuatu untuk ditambahkan atau ditingkatkan, saya selalu menerima kritik membangun, tulis. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk melihat 30 topik</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perhatian, banyak gambar</font></font></b>
                        <div class="spoiler_text"><img src="https://habrastorage.org/webt/cn/dy/tb/cndytbwrtz9ujkkh6xicy0mjyds.png"><br>
<br>
<img src="https://habrastorage.org/webt/no/n2/iq/non2iqgux8nvb5hnitr8n7yra_w.png"><br>
<br>
<img src="https://habrastorage.org/webt/dx/dh/nl/dxdhnlddgexrb_noeq8psjb7nps.png"><br>
<br>
<img src="https://habrastorage.org/webt/x1/_f/q6/x1_fq6omll0iigewzz0ba8tjvys.png"><br>
<br>
<img src="https://habrastorage.org/webt/7v/qy/fh/7vqyfh-uwk_bhypzdgisxxabzjs.png"><br>
<br>
<img src="https://habrastorage.org/webt/v7/1z/fn/v71zfn2kb0xj7rpsthrplgznzzw.png"><br>
<br>
<img src="https://habrastorage.org/webt/ab/tt/t7/abttt7c8aqydfc28gxyq9ai7a4q.png"><br>
<br>
<img src="https://habrastorage.org/webt/oz/hc/m7/ozhcm72ldjjenp5onkjydxgpvly.png"><br>
<br>
<img src="https://habrastorage.org/webt/fe/ex/lw/feexlw8tcrcwni5wmy8k8rv8k3e.png"><br>
<br>
<img src="https://habrastorage.org/webt/w0/hu/5j/w0hu5jix2zrewo2l9jnbkddd3tk.png"><br>
<br>
<img src="https://habrastorage.org/webt/zf/ye/kw/zfyekw6s6qfxuqwy-qxhv_dehrq.png"><br>
<br>
<img src="https://habrastorage.org/webt/l0/9s/vw/l09svwry19fhz1y-1-pooeo_vew.png"><br>
<br>
<img src="https://habrastorage.org/webt/pm/mt/bk/pmmtbkkybu50vhgttl-0kz4tcf4.png"><br>
<br>
<img src="https://habrastorage.org/webt/1h/hu/vr/1hhuvrmmfjxwfzh3fbhf9dbut38.png"><br>
<br>
<img src="https://habrastorage.org/webt/bw/is/ad/bwisadbn9a000lt6xp927szic2u.png"><br>
<br>
<img src="https://habrastorage.org/webt/iu/bf/4q/iubf4qt_juq9uip17rmngbr7wxe.png"><br>
<br>
<img src="https://habrastorage.org/webt/jk/of/sa/jkofsalh2hev8zx6jjlom0pnnxy.png"><br>
<br>
<img src="https://habrastorage.org/webt/js/bs/ls/jsbslsv_4ly4rwe7wir6xvcs6t4.png"><br>
<br>
<img src="https://habrastorage.org/webt/_e/ly/wr/_elywrkbtgk-4fvlnuzfr6zqq4o.png"><br>
<br>
<img src="https://habrastorage.org/webt/4j/x8/pa/4jx8paomlrca7t0syfunmtmlxk4.png"><br>
<br>
<img src="https://habrastorage.org/webt/y2/he/s1/y2hes1fvuepisygriea98m_yavw.png"><br>
<br>
<img src="https://habrastorage.org/webt/9k/xs/sr/9kxssr9rxlyeobjw12fwju0-xkq.png"><br>
<br>
<img src="https://habrastorage.org/webt/i-/sl/qd/i-slqdug6x9dkwybnfnxmdolho8.png"><br>
<br>
<img src="https://habrastorage.org/webt/nq/pk/x5/nqpkx5q6j8e_6mkpfak0ytkkvfc.png"><br>
<br>
<img src="https://habrastorage.org/webt/jv/3b/pa/jv3bpafludpki_2a-4pgajhreh0.png"><br>
<br>
<img src="https://habrastorage.org/webt/sw/-e/pn/sw-epnxhrwa4t7i6uksmggczs-8.png"><br>
<br>
<img src="https://habrastorage.org/webt/-y/qj/0t/-yqj0t-jkax-s09bivkgx8a3mqa.png"><br>
<br>
<img src="https://habrastorage.org/webt/ta/rp/4w/tarp4wr8bcui0zszwuzl7l9h8zo.png"><br>
<br>
<img src="https://habrastorage.org/webt/eo/xl/m2/eoxlm2i2z9weffxhgm-zzgszd3q.png"><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">    «Machine Learning»  OTUS</a>.<br>
<br>
<hr><br>
</div>
                    </div></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id503382/index.html">Menyapu berjalan di bidang yang bersih atau cara mengumpulkan alamat MAC dari perangkat Wi-Fi terdekat</a></li>
<li><a href="../id503386/index.html">Pelatih lincah orang sehat</a></li>
<li><a href="../id503388/index.html">Digitalisasi kepanikan: DIT Moskwa melawan Moskow - sebuah meja bundar pada 23 Mei</a></li>
<li><a href="../id503390/index.html">Mengapa Intel bertaruh pada pengembangan chip untuk jenius Jim Keller?</a></li>
<li><a href="../id503394/index.html">Pengalaman Investasi Saham</a></li>
<li><a href="../id503402/index.html">Bagaimana cara mengingat semua orang secara langsung, atau pencarian wajah yang efektif dalam database besar</a></li>
<li><a href="../id503404/index.html">Sistem Digital Semantik</a></li>
<li><a href="../id503406/index.html">Semantik dan aktivitas</a></li>
<li><a href="../id503408/index.html">Toko Online Sisi Klien Blazor: Bagian 7 - Diperbarui untuk merilis versi 3.2.0 dan tampilan gambar yang ditambahkan</a></li>
<li><a href="../id503410/index.html">Poligon Dunia Lain: Sega Genesis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
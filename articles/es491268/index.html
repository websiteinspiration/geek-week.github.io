<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§• ü§∏üèª üôáüèø M√©todos de Monte Carlo para las cadenas de Markov (MCMC). Introducci√≥n üë©üèΩ‚Äç‚öïÔ∏è üß£ üèÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! 
 
 Le recordamos que anteriormente anunciamos el libro " Aprendizaje autom√°tico sin palabras adicionales ", y ahora ya est√° a la venta . A...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>M√©todos de Monte Carlo para las cadenas de Markov (MCMC). Introducci√≥n</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/491268/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hola Habr! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le recordamos que anteriormente anunciamos el libro " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aprendizaje autom√°tico sin palabras adicionales</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ", y ahora ya est√° </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a la venta</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . A pesar del hecho de que para los principiantes en MO, el libro puede convertirse en un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">escritorio</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , algunos temas a√∫n no se tocaron. Por lo tanto, estamos ofreciendo a todos los interesados ‚Äã‚Äãuna traducci√≥n de un art√≠culo de Simon Kerstens sobre la esencia de los algoritmos </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MCMC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> con la implementaci√≥n de dicho algoritmo en Python.</font></font><br>
<a name="habracut"></a> <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los m√©todos de Monte Carlo para las cadenas de Markov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (MCMC) son una clase poderosa de m√©todos para el muestreo a partir de distribuciones de probabilidad que se conocen solo hasta una cierta constante (desconocida) de normalizaci√≥n. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sin embargo, antes de profundizar en el MCMC, analicemos por qu√© incluso podr√≠a necesitar hacer tal selecci√≥n. La respuesta es: puede interesarle las muestras de la muestra (por ejemplo, para determinar par√°metros desconocidos utilizando el m√©todo de derivaci√≥n bayesiano) o para aproximar los valores esperados de las funciones en relaci√≥n con la distribuci√≥n de probabilidad (por ejemplo, calcular cantidades termodin√°micas a partir de la distribuci√≥n de estados en f√≠sica estad√≠stica). A veces solo nos interesa el modo de distribuci√≥n de probabilidad. En este caso, lo obtenemos por el m√©todo de optimizaci√≥n num√©rica, por lo que no es necesario hacer una selecci√≥n completa.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Resulta que el muestreo de cualquier distribuci√≥n de probabilidad, excepto las m√°s primitivas, es una tarea dif√≠cil. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El m√©todo de transformaci√≥n inversa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es una t√©cnica elemental para el muestreo de distribuciones de probabilidad, que, sin embargo, requiere el uso de una funci√≥n de distribuci√≥n acumulativa, y para usarla, a su vez, debe conocer la constante de normalizaci√≥n, que generalmente es desconocida. En principio, se puede obtener una constante de normalizaci√≥n por integraci√≥n num√©rica, pero este m√©todo r√°pidamente se vuelve impracticable con un aumento en el n√∫mero de dimensiones. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Muestreo de desviaciones</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No requiere una distribuci√≥n normalizada, pero para implementarla de manera efectiva, se necesita saber mucho sobre la distribuci√≥n que nos interesa. Adem√°s, este m√©todo sufre severamente por la maldici√≥n de las dimensiones, esto significa que su efectividad disminuye r√°pidamente con un aumento en el n√∫mero de variables. Es por eso que necesita organizar de manera inteligente la recepci√≥n de muestras representativas de su distribuci√≥n, sin necesidad de conocer la constante de normalizaci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los algoritmos MCMC son una clase de m√©todos dise√±ados espec√≠ficamente para esto. Vuelven al </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">art√≠culo hist√≥rico de Metr√≥polis y otros</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ; Metropolis desarroll√≥ el primer algoritmo MCMC que lleva </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">su nombre</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y dise√±ado para calcular el estado de equilibrio de un sistema bidimensional de esferas duras. De hecho, los investigadores estaban buscando un m√©todo universal que nos permitiera calcular los valores esperados encontrados en la f√≠sica estad√≠stica. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este art√≠culo cubrir√° los conceptos b√°sicos del muestreo MCMC. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CADENAS MARKOV</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora que entendemos por qu√© necesitamos muestrear, pasemos al coraz√≥n de MCMC: las cadenas de Markov. ¬øQu√© es una cadena de Markov? Sin entrar en detalles t√©cnicos, podemos decir que una cadena de Markov es una secuencia aleatoria de estados en un determinado espacio de estados, donde la probabilidad de elegir un determinado estado depende solo del estado actual de la cadena, pero no de su historia pasada: esta cadena carece de memoria. Bajo ciertas condiciones, una cadena de Markov tiene una distribuci√≥n estacionaria √∫nica de estados, a la que converge, superando un cierto n√∫mero de estados. Despu√©s de tal cantidad de estados en una cadena de Markov, se obtiene una distribuci√≥n invariable. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para tomar muestras de una distribuci√≥n, </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">el algoritmo MCMC crea y simula una cadena de Markov cuya distribuci√≥n estacionaria es</font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">; esto significa que despu√©s del per√≠odo inicial de "semilla", los estados de dicha cadena de Markov se distribuyen de acuerdo con el principio </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Por lo tanto, solo tendremos que guardar el estado para obtener muestras </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para fines educativos, consideremos un espacio de estado discreto y un "tiempo" discreto. La cantidad clave que caracteriza una cadena de Markov es un operador de transici√≥n que </font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indica la probabilidad de estar en un estado </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a la vez </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, siempre que la cadena est√© en un estado </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a la vez </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora solo por diversi√≥n (y como demostraci√≥n) tejemos r√°pidamente una cadena de Markov con una distribuci√≥n estacionaria √∫nica. Comencemos con algunas importaciones y configuraciones para gr√°ficos:</font></font><br>
<br>
<pre><code class="python hljs">%matplotlib notebook<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
plt.rcParams[<span class="hljs-string">'figure.figsize'</span>] = [<span class="hljs-number">10</span>, <span class="hljs-number">6</span>]<font></font>
np.random.seed(<span class="hljs-number">42</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La cadena de Markov girar√° alrededor del espacio de estado discreto formado por tres condiciones clim√°ticas: </font></font><br>
<br>
<pre><code class="python hljs">state_space = (<span class="hljs-string">"sunny"</span>, <span class="hljs-string">"cloudy"</span>, <span class="hljs-string">"rainy"</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En un espacio de estado discreto, el operador de transici√≥n es solo una matriz. </font><font style="vertical-align: inherit;">En nuestro caso, las columnas y filas corresponden al clima soleado, nublado y lluvioso. </font><font style="vertical-align: inherit;">Elijamos valores relativamente razonables para las probabilidades de todas las transiciones:</font></font><br>
<br>
<pre><code class="python hljs">transition_matrix = np.array(((<span class="hljs-number">0.6</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.1</span>),<font></font>
                              (<span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.3</span>),<font></font>
                              (<span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las filas indican los estados en los que el circuito puede estar ubicado actualmente, y las columnas indican los estados en los que puede ir el circuito. </font><font style="vertical-align: inherit;">Si damos el paso de "tiempo" de la cadena de Markov en una hora, entonces, siempre que est√© soleado ahora, hay un 60% de posibilidades de que el clima soleado contin√∫e durante la pr√≥xima hora. </font><font style="vertical-align: inherit;">Tambi√©n hay un 30% de posibilidades de que haya un clima nublado en la pr√≥xima hora, y un 10% de posibilidades de que llueva inmediatamente despu√©s de un clima soleado. </font><font style="vertical-align: inherit;">Tambi√©n significa que los valores en cada fila suman uno. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conduzcamos un poco nuestra cadena de Markov:</font></font><br>
<br>
<pre><code class="python hljs">n_steps = <span class="hljs-number">20000</span>
states = [<span class="hljs-number">0</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_steps):<font></font>
    states.append(np.random.choice((<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), p=transition_matrix[states[<span class="hljs-number">-1</span>]]))<font></font>
states = np.array(states)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Podemos observar c√≥mo la cadena de Markov converge a una distribuci√≥n estacionaria, calculando la probabilidad emp√≠rica de cada uno de los estados en funci√≥n de la longitud de la cadena:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">despine</span>(<span class="hljs-params">ax, spines=(<span class="hljs-params"><span class="hljs-string">'top'</span>, <span class="hljs-string">'left'</span>, <span class="hljs-string">'right'</span></span>)</span>):</span>
    <span class="hljs-keyword">for</span> spine <span class="hljs-keyword">in</span> spines:<font></font>
        ax.spines[spine].set_visible(<span class="hljs-literal">False</span>)<font></font>
<font></font>
fig, ax = plt.subplots()<font></font>
width = <span class="hljs-number">1000</span>
offsets = range(<span class="hljs-number">1</span>, n_steps, <span class="hljs-number">5</span>)
<span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> enumerate(state_space):<font></font>
    ax.plot(offsets, [np.sum(states[:offset] == i) / offset <font></font>
            <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> offsets], label=label)<font></font>
ax.set_xlabel(<span class="hljs-string">"number of steps"</span>)<font></font>
ax.set_ylabel(<span class="hljs-string">"likelihood"</span>)<font></font>
ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
despine(ax, (<span class="hljs-string">'top'</span>, <span class="hljs-string">'right'</span>))<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/vu/tg/xv/vutgxvc3lq1-sang725fmek1ibm.png"><br>
 <br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HONOR DE TODAS LAS MCMC: ALGORITMO DE METROPOLIS-HASTINGS</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Por supuesto, todo esto es muy interesante, pero volviendo al proceso de muestreo de una distribuci√≥n de probabilidad arbitraria </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Puede ser discreto, en cuyo caso continuaremos hablando sobre la matriz de transici√≥n </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, o continuo, en cuyo caso </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ser√° un n√∫cleo de transici√≥n. En lo sucesivo, hablaremos sobre distribuciones continuas, pero todos los conceptos que consideramos aqu√≠ tambi√©n son aplicables a casos discretos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si pudi√©ramos dise√±ar el n√∫cleo de transici√≥n de tal manera que ya se dedujera el siguiente estado </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, entonces esto podr√≠a ser limitado, ya que nuestra cadena de Markov ... tomar√≠a muestras directamente </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Desafortunadamente, para lograr esto, necesitamos la capacidad de tomar muestras de</font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lo que no podemos hacer; de lo contrario, no leer√≠as eso, ¬øverdad? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La soluci√≥n consiste en dividir el n√∫cleo de transici√≥n </font></font><img src="https://habrastorage.org/webt/7_/os/ja/7_osja2wwom8x6f29sp5ecxnrwc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en dos partes: el paso de propuesta y el paso de aceptaci√≥n / rechazo. Aparece una distribuci√≥n auxiliar en el paso de muestra</font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de donde se seleccionan los posibles estados siguientes de la cadena. No solo podemos hacer una selecci√≥n de esta distribuci√≥n, sino que tambi√©n podemos elegir arbitrariamente la distribuci√≥n en s√≠. Sin embargo, al dise√±ar, uno debe esforzarse por llegar a una configuraci√≥n en la que las muestras tomadas de esta distribuci√≥n se correlacionen m√≠nimamente con el estado actual y al mismo tiempo tengan buenas posibilidades de pasar por la fase de recepci√≥n. El paso anterior de recepci√≥n / descarte es la segunda parte del n√∫cleo de transici√≥n; en esta etapa, los errores contenidos en los estados de prueba seleccionados se corrigen </font></font><img src="https://habrastorage.org/webt/dq/wo/ba/dqwoba_pfa-ktifmo9zviggtesm.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Aqu√≠, se calcula la probabilidad de una recepci√≥n exitosa </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y se toma una muestra </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">con una probabilidad tal como el siguiente estado en la cadena. Obteniendo el siguiente estado </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de</font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">luego se realiza de la siguiente manera: primero, </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">se toma el </font><font style="vertical-align: inherit;">estado de prueba </font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Luego se toma como el siguiente estado con probabilidad </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o se descarta con probabilidad </font></font><img src="https://habrastorage.org/webt/cr/_w/sd/cr_wsdxfgphyie2qbzl977pvfgq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, y en el √∫ltimo caso, el estado actual se copia y se usa como el siguiente. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En consecuencia, hemos </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ty/vg/w-/tyvgw-g_ij7vgrpzoxtt7t3enmw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
condici√≥n suficiente para la cadena de Markov ten√≠a </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">como una distribuci√≥n estacionaria es la siguiente: El n√∫cleo de transici√≥n debe presentar </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">equilibrio detallado</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> o como escritura en la literatura f√≠sica, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la reversibilidad microsc√≥pica</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hf/bg/oy/hfbgoyr944ikp5ce_menl-sg0da.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esto significa que la probabilidad de estar en un estado </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y moverse de all√≠ a</font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">debe ser igual a la probabilidad del proceso inverso, es decir, poder </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y entrar en un estado </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Los n√∫cleos de transici√≥n de la mayor√≠a de los algoritmos MCMC satisfacen esta condici√≥n. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para que el n√∫cleo de transici√≥n de dos partes obedezca al equilibrio detallado, es necesario elegir correctamente </font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, es decir, para asegurarse de que le permite corregir cualquier asimetr√≠a en el flujo de probabilidad de / </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ao </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Metropolis-Hastings algoritmo utiliza criterio de admisibilidad metr√≥polis: </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/mh/dm/z2/mhdmz27voos90zkz5_-zexopsdc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y aqu√≠ comienza la magia: </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">solo conocemos una constante, pero no importa, ya que esta constante desconocida anula la expresi√≥n para</font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! Es esta propiedad paccpacc la que garantiza el funcionamiento de algoritmos basados ‚Äã‚Äãen el algoritmo de Metropolis-Hastings en distribuciones no normalizadas. Con frecuencia se utilizan distribuciones auxiliares sim√©tricas c </font></font><img src="https://habrastorage.org/webt/b2/ss/pz/b2sspzujgmdn_uwizxwjjokkg5w.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, en cuyo caso el algoritmo Metropolis-Hastings se reduce al algoritmo Metropolis original (menos general) desarrollado en 1953. En el algoritmo original </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hd/3k/vq/hd3kvqg9l2jqltan97_gfmzutsi.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En este caso, el n√∫cleo de transici√≥n completo de Metropolis-Hastings se puede escribir como </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IMPLEMENTAMOS EL ALGORITMO METROPOLIS-HASTINGS EN PYTHON</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bueno, ahora que hemos descubierto c√≥mo funciona el algoritmo Metropolis-Hastings, pasemos a su implementaci√≥n. Primero, establecemos la probabilidad logar√≠tmica de la distribuci√≥n a partir de la cual vamos a hacer una selecci√≥n, sin constantes de normalizaci√≥n; se supone que no los conocemos. A continuaci√≥n, trabajamos con la distribuci√≥n normal est√°ndar:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_prob</span>(<span class="hljs-params">x</span>):</span>
     <span class="hljs-keyword">return</span> <span class="hljs-number">-0.5</span> * np.sum(x ** <span class="hljs-number">2</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A continuaci√≥n, elegimos una distribuci√≥n auxiliar sim√©trica. </font><font style="vertical-align: inherit;">En general, el rendimiento del algoritmo Metropolis-Hastings se puede mejorar al incluir en la distribuci√≥n auxiliar la informaci√≥n que ya conoce sobre la distribuci√≥n de la que desea realizar una selecci√≥n. </font><font style="vertical-align: inherit;">Un enfoque simplificado se ve as√≠: tomamos el estado actual </font></font><code>x</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y seleccionamos una muestra de </font></font><img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, es decir, establecemos un cierto tama√±o de paso </font></font><code>Œî</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y vamos a la izquierda o derecha de nuestro estado actual por no m√°s de </font></font><img src="https://habrastorage.org/webt/q1/n2/d_/q1n2d_lbzpbqtvbmbgiha503cmo.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">proposal</span>(<span class="hljs-params">x, stepsize</span>):</span>
    <span class="hljs-keyword">return</span> np.random.uniform(low=x - <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             high=x + <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             size=x.shape)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finalmente, calculamos la probabilidad de que la propuesta sea aceptada:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">p_acc_MH</span>(<span class="hljs-params">x_new, x_old, log_prob</span>):</span>
    <span class="hljs-keyword">return</span> min(<span class="hljs-number">1</span>, np.exp(log_prob(x_new) - log_prob(x_old)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora ponemos todo esto en una implementaci√≥n verdaderamente breve de la etapa de muestreo para el algoritmo Metropolis-Hastings:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_MH</span>(<span class="hljs-params">x_old, log_prob, stepsize</span>):</span><font></font>
    x_new = proposal(x_old, stepsize)<font></font>
    <span class="hljs-comment">#   ,     :</span>
    <span class="hljs-comment">#       [0,1]  </span>
    <span class="hljs-comment">#     </span><font></font>
    accept = np.random.random() &lt; p_acc(x_new, x_old, log_prob)<font></font>
    <span class="hljs-keyword">if</span> accept:
        <span class="hljs-keyword">return</span> accept, x_new
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> accept, x_old</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s del siguiente estado en la cadena de Markov, </font></font><code>x_new</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o </font></font><code>x_old</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tambi√©n devolvemos informaci√≥n sobre si se adopt√≥ el paso MCMC. </font><font style="vertical-align: inherit;">Esto nos permitir√° rastrear la din√°mica de la recolecci√≥n de muestras. </font><font style="vertical-align: inherit;">En conclusi√≥n de esta implementaci√≥n, escribimos una funci√≥n que llamar√° iterativamente </font></font><code>sample_MH</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y, por lo tanto, construir√° una cadena de Markov:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_MH_chain</span>(<span class="hljs-params">init, stepsize, n_total, log_prob</span>):</span><font></font>
<font></font>
    n_accepted = <span class="hljs-number">0</span><font></font>
    chain = [init]<font></font>
<font></font>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(n_total):<font></font>
        accept, state = sample_MH(chain[<span class="hljs-number">-1</span>], log_prob, stepsize)<font></font>
        chain.append(state)<font></font>
        n_accepted += accept<font></font>
    <font></font>
    acceptance_rate = n_accepted / float(n_total)<font></font>
    <font></font>
    <span class="hljs-keyword">return</span> chain, acceptance_rate</code></pre><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PROBANDO NUESTRO ALGORITMO DE METROPOLIS-HASTINGS E INVESTIGANDO SU COMPORTAMIENTO</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Probablemente, ahora no puede esperar para ver todo esto en acci√≥n. </font><font style="vertical-align: inherit;">Haremos esto, tomaremos algunas decisiones informadas sobre los argumentos </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">chain, acceptance_rate = build_MH_chain(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">3.0</span>, <span class="hljs-number">10000</span>, log_prob)<font></font>
chain = [state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain]<font></font>
print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
last_states = <span class="hljs-string">", "</span>.join(<span class="hljs-string">"{:.5f}"</span>.format(state) 
                        <span class="hljs-keyword">for</span> state <span class="hljs-keyword">in</span> chain[<span class="hljs-number">-10</span>:])<font></font>
print(<span class="hljs-string">"Last ten states of chain: "</span> + last_states)<font></font>
Acceptance rate: <span class="hljs-number">0.722</span>
Last ten states of chain: <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.08692</span>, <span class="hljs-number">0.92728</span>, <span class="hljs-number">-0.46215</span>, <span class="hljs-number">0.08655</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span></code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Las cosas son buenas. Entonces, ¬øfuncion√≥? Logramos tomar muestras en aproximadamente el 71% de los casos, y tenemos una cadena de estados. Los primeros estados en los que la cadena a√∫n no ha convergido a su distribuci√≥n estacionaria deben descartarse. Verifiquemos si las condiciones que hemos elegido tienen una distribuci√≥n normal:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_samples</span>(<span class="hljs-params">chain, log_prob, ax, orientation=<span class="hljs-string">'vertical'</span>, normalize=True,
                 xlims=(<span class="hljs-params"><span class="hljs-number">-5</span>, <span class="hljs-number">5</span></span>), legend=True</span>):</span>
    <span class="hljs-keyword">from</span> scipy.integrate <span class="hljs-keyword">import</span> quad<font></font>
    <font></font>
    ax.hist(chain, bins=<span class="hljs-number">50</span>, density=<span class="hljs-literal">True</span>, label=<span class="hljs-string">"MCMC samples"</span>,<font></font>
           orientation=orientation)<font></font>
    <span class="hljs-comment">#     PDF</span>
    <span class="hljs-keyword">if</span> normalize:<font></font>
        Z, _ = quad(<span class="hljs-keyword">lambda</span> x: np.exp(log_prob(x)), -np.inf, np.inf)
    <span class="hljs-keyword">else</span>:<font></font>
        Z = <span class="hljs-number">1.0</span>
    xses = np.linspace(xlims[<span class="hljs-number">0</span>], xlims[<span class="hljs-number">1</span>], <span class="hljs-number">1000</span>)<font></font>
    yses = [np.exp(log_prob(x)) / Z <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xses]
    <span class="hljs-keyword">if</span> orientation == <span class="hljs-string">'horizontal'</span>:<font></font>
        (yses, xses) = (xses, yses)<font></font>
    ax.plot(xses, yses, label=<span class="hljs-string">"true distribution"</span>)
    <span class="hljs-keyword">if</span> legend:<font></font>
        ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
    <font></font>
fig, ax = plt.subplots()<font></font>
plot_samples(chain[<span class="hljs-number">500</span>:], log_prob, ax)<font></font>
despine(ax)<font></font>
ax.set_yticks(())<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/yo/rx/59/yorx59lirnkyju_dymptouaaokw.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬°Se ve genial! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬øQu√© pasa con los par√°metros </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">? Primero discutimos el tama√±o del paso: determina qu√© tan lejos se puede eliminar el estado de prueba del estado actual del circuito. Por lo tanto, este es un par√°metro de distribuci√≥n auxiliar </font></font><code>q</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que controla qu√© tan grandes ser√°n los pasos aleatorios tomados por la cadena de Markov. Si el tama√±o del paso es demasiado grande, los estados de prueba a menudo terminan en la cola de la distribuci√≥n, donde los valores de probabilidad son bajos. El mecanismo de muestreo de Metropolis-Hastings descarta la mayor√≠a de estos pasos, como resultado de lo cual las tasas de recepci√≥n se reducen y la convergencia disminuye significativamente. Ver por ti mismo:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_and_display</span>(<span class="hljs-params">init_state, stepsize, n_total, n_burnin, log_prob</span>):</span><font></font>
    chain, acceptance_rate = build_MH_chain(init_state, stepsize, n_total, log_prob)<font></font>
    print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
    fig, ax = plt.subplots()<font></font>
    plot_samples([state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain[n_burnin:]], log_prob, ax)<font></font>
    despine(ax)<font></font>
    ax.set_yticks(())<font></font>
    plt.show()<font></font>
    <font></font>
sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">30</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.116</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/0g/4-/-r/0g4--rezypxzaqta-pkugq3gi3w.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No muy bien, ¬øverdad? Ahora parece que es mejor establecer un tama√±o de paso peque√±o. Resulta que esta tampoco es una decisi√≥n inteligente, ya que la cadena de Markov investigar√° la distribuci√≥n de probabilidad muy lentamente y, por lo tanto, tampoco converger√° tan r√°pido como con un tama√±o de paso bien elegido:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.992</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/bf/qh/xi/bfqhxistqravnn7xug43ubowgmu.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Independientemente de c√≥mo elija el par√°metro de tama√±o de paso, la cadena de Markov finalmente converge a una distribuci√≥n estacionaria. Pero esto puede llevar mucho tiempo. El tiempo durante el cual simularemos la cadena de Markov est√° </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">determinado </font><font style="vertical-align: inherit;">por el par√°metro </font><font style="vertical-align: inherit;">; simplemente determina cu√°ntos estados de la cadena de Markov (y, por lo tanto, las muestras seleccionadas) finalmente tendremos. Si la cadena converge lentamente, entonces debe incrementarse </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para que la cadena de Markov tenga tiempo de "olvidar" el estado inicial. Por lo tanto, dejaremos el tama√±o del paso peque√±o y aumentaremos el n√∫mero de muestras aumentando el par√°metro </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">500000</span>, <span class="hljs-number">25000</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.990</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/fs/ba/27/fsba27vppyvfqnwdnnr0ifdp3w4.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estamos avanzando hacia la meta m√°s lentamente ... </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CONCLUSIONES</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Considerando todo lo anterior, espero que ahora haya comprendido intuitivamente la esencia del algoritmo Metropolis-Hastings, sus par√°metros, y entienda por qu√© esta es una herramienta extremadamente √∫til para seleccionar entre las distribuciones de probabilidad no est√°ndar que puede encontrar en la pr√°ctica. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le recomiendo que experimente con el c√≥digo que se proporciona </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqu√≠.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- para que te acostumbres al comportamiento del algoritmo en varias circunstancias y lo entiendas m√°s profundamente. </font><font style="vertical-align: inherit;">¬°Prueba la distribuci√≥n auxiliar asim√©trica! </font><font style="vertical-align: inherit;">¬øQu√© suceder√° si no configura el criterio de aceptaci√≥n correctamente? </font><font style="vertical-align: inherit;">¬øQu√© sucede si intentas tomar muestras de una distribuci√≥n bimodal? </font><font style="vertical-align: inherit;">¬øPuedes encontrar una manera de ajustar autom√°ticamente el tama√±o del paso? </font><font style="vertical-align: inherit;">¬øCu√°les son las trampas aqu√≠? </font><font style="vertical-align: inherit;">¬°Responda estas preguntas usted mismo!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es491258/index.html">Chicas de TI, ¬øde d√≥nde eres? Construyamos un mapa</a></li>
<li><a href="../es491260/index.html">Normalizaci√≥n de texto en tareas de reconocimiento de voz.</a></li>
<li><a href="../es491262/index.html">Ojo por ojo. Problemas biom√©tricos</a></li>
<li><a href="../es491264/index.html">Introducci√≥n a SSD. Parte 4. F√≠sica</a></li>
<li><a href="../es491266/index.html">SurfingAttack: tel√©fonos inteligentes comprometidos con asistentes de sonido [+ video]</a></li>
<li><a href="../es491276/index.html">C√≥mo elud√≠ la prohibici√≥n de la API de mensajes a trav√©s de la documentaci√≥n de Vkontakte</a></li>
<li><a href="../es491278/index.html">CLRium # 7: Informes, pr√°ctica, mentores</a></li>
<li><a href="../es491280/index.html">La historia de c√≥mo desarroll√© un lenguaje de programaci√≥n.</a></li>
<li><a href="../es491282/index.html">C√≥mo aumentar la productividad del equipo (y reducir los errores) utilizando manifestaciones</a></li>
<li><a href="../es491284/index.html">An√°lisis: qu√© es el an√°lisis fundamental</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§æüèº üë©üèº‚Äçü§ù‚Äçüë®üèΩ üéÄ Using ML Algorithms to Classify Multipage Documents: VTB Experience üê£ üìß üéπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As part of the credit conveyors of legal entities, banks request originals of various documents from companies. Often scans of these documents come in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Using ML Algorithms to Classify Multipage Documents: VTB Experience</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/497484/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As part of the credit conveyors of legal entities, banks request originals of various documents from companies. Often scans of these documents come in the form of a single multi-page file - ‚Äústream‚Äù. For ease of use, flows need to be segmented into separate documents (single-page or multi-page) and classified. Under the cut, we talk about the application of machine learning algorithms in the classification of already segmented documents.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/nx/pw/ht/nxpwht7ju1u1dkqjvgwpo3liabk.jpeg"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The type of document is determined by both text and visual information. For example, a passport or work book is easy to distinguish visually without analyzing the text inside. Moreover, the quality of text recognition in such documents is rather low if non-specialized solutions are used. Therefore, the visual component carries much more relevant information for classification. The lease agreement and the charter of the company may be visually similar, however, the textual information that they contain is significantly different. As a result, the task of classifying documents is reduced to a data fusion model, which should combine two sources of unstructured data: a visual representation of the document and the results of recognition of text information.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note that in banking, the classification of documents is also used in the conveyors of individuals on scans or photographs of documents, for sorting the accumulated funds of documents, for filtering customer reviews in order to improve the quality of service, for sorting payment documents, for additional filtering of news flows, etc. .&nbsp;</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT Model</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To solve our problem, we used the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT (Bidirectional Encoder Representations from Transformer)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> model - this is a language model based on a multilayer bidirectional coding </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformer</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . The transformer receives a sequence of tokens (codes of words or parts of words) as an input and, after internal transformations, produces a coded representation of this sequence - a set of embeddings. Further, these embeddings can be used to solve various problems. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/ed5/d53/ca1/ed5d53ca1f9da10c0d39093d5f6aeaa1.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformer Model Architecture</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If in more detail, then a sequence of tokens is fed to the input, summed with the codes of the positions of these tokens and codes of the segments (offers) in which the tokens are located. For each input sequence, the Transformer generates a context-sensitive representation (a set of embeddings for the entire sequence) based on the adaptive mechanism of ‚Äúattention‚Äù. Each output embedding encoded "attention" of some tokens relative to others. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/mb/p9/nv/mbp9nvuozjmotfflq6qmio5b5l0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We encode the word it, part of the ‚Äúattention‚Äù mechanism focused on The Animal and fixed part of its representation in the it encoding (from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Illustrated Transfomer blog</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The BERT model is built in two steps: pre-training and file tuning. During pre-training, the model solves two problems: MLM (Masked Language Model) and NSP (Next Sentence Prediction). In the MLM task, a certain proportion of tokens in the input sequence is randomly labeled (masked), and the task is to restore the values ‚Äã‚Äãof the tokens that have been masked. The NSP task is a binary classification on pairs of sentences when it is necessary to predict whether the second sentence is a logical continuation of the first. During the tuning, pre-trained Transformers retrain on these specific tasks. Transformer based tuning has proven itself in many NLP ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Natural Language Processing</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) </font><font style="vertical-align: inherit;">tasks </font><font style="vertical-align: inherit;">: automatic chat bots, translators, text analyzers, and others. </font><i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">Transformer</font></a></i></font><br>
<br>
<img src="https://habrastorage.org/webt/uw/pv/0e/uwpv0eqwrvlyanjei4wztuouudc.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> circuitry</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">for an automatic translator from French to English (from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Illustrated Transfomer blog</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Before the BERT model appeared, methods for paging scans were used: convolutional signs from pictures (obtained using </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> convolutional neural networks </font><font style="vertical-align: inherit;">), frequency text attributes ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) , thematic text tags ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LDA</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> topics), convolutional text tags (1-D convolution), word </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">embeddings</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ( </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">WordToVec</font></a><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GloVe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) and their combinations.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Previously developed methods give good quality. </font><font style="vertical-align: inherit;">But the closer the quality is selected to the maximum, the more difficult it is to improve it. </font><font style="vertical-align: inherit;">As we will show later, when we already had a quality close to maximum, the use of the BERT model helped to make it even higher.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since we work mainly with Russian texts, we used the BERT model, pre-trained on some cases of Russian texts ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RuBERT, Russian, cased</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from DeepPavlov).&nbsp;</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Our dataset&nbsp;</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Description</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The selection of documents on which we solved the classification problem consists of scans of corporate documents of companies accumulated by VTB Bank over many years. Multi-page corporate documents were segmented semi-automatically from the scanned stream, and their pages were classified by paid solutions. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Most scans are black and white, and a small proportion are color (mainly due to color prints).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Customers of business units identified 10 main categories of documents (about 30,000 already segmented multi-page documents, ~ 129,000 pages). </font><font style="vertical-align: inherit;">Documents had to be cleaned manually due to errors during segmentation. </font><font style="vertical-align: inherit;">One category ‚ÄúOther‚Äù was also introduced, into which all other categories of less significant documents were combined (about 300 categories, ~ 43,000 multi-page documents already segmented, ~ 128,000 pages). </font><font style="vertical-align: inherit;">As a result, we will build a classifier with 11 classes. </font><font style="vertical-align: inherit;">We also added about 18,000 images from the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ImageNet dataset</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to the </font><font style="vertical-align: inherit;">‚ÄúOther‚Äù category </font><font style="vertical-align: inherit;">(for ‚Äúprotection from the fool‚Äù). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main 10 categories are:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lease contract</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Extract from the register of participants</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Company Charter</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certificate of registration with the tax authority</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Questionnaire for legal entities</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Russian passport</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Incorporation sheet</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certificate of state registration of legal entity</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Orders / Orders</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Decisions / Protocols</font></font><br>
</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Various other identification cards (foreign passports, migration cards, etc.), other certificates, IP questionnaires, statements, acts, powers of attorney, questionnaires, decisions of the arbitral tribunal, images from ImageNet, and others were included in the Other category. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The train was taken about 81% of already segmented multi-page documents (of the number of all such documents), dev - 9%, test - 10%. </font><font style="vertical-align: inherit;">For the purity of the experiment, the selection was divided so that the pages of any segmented multi-page document fell entirely in one part: either train, or dev, or test.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certified-Stitched Pages</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Often, corporate clients do not provide originals, but copies of documents, many of which are certified by a notary public or by company executives. </font><font style="vertical-align: inherit;">In addition, multi-page documents are often stapled, prescribe the firmware date, and again certified on the last page.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Therefore, in our dataset there are many such multi-page documents, where on the last scan (page) there are seals, dates and other information regarding the firmware or details of the witnesses, but not related to the class of the document. </font><font style="vertical-align: inherit;">Below are the last pages of two different multi-page documents segmented from the stream, which are almost impossible to classify correctly if you do not look at the rest of the pages. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/oo/gl/va/ooglvahkozchwcnzh_s846-l1uk.jpeg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Identical last pages of documents of various classes</font></font></i><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scan quality</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Although document scanning usually takes place at bank offices (using good copying equipment), customers often bring repeatedly scanned copies of documents. </font><font style="vertical-align: inherit;">And the quality of such copies suffers greatly: on scans there is a lot of noise and artifacts that can appear from poor quality of toners, from holograms and textures on many documents and for other reasons.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Orientation</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are a lot of documents in the dataset with the wrong orientation of the scan, this is especially true for ID cards and text documents created in landscape mode. </font><font style="vertical-align: inherit;">But basically, the text is rotated by a multiple of 90 degrees (¬± 5 degrees). </font><font style="vertical-align: inherit;">When extracting the text, we additionally determined the ‚Äúcorrect‚Äù orientation of the picture so that most of the text was oriented vertically.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Baseline</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since most documents begin to scan from the first page, there is usually enough information on it to determine the class, and many multi-page documents differ well in one first page. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Therefore, we will build our baseline classifier for multi-page documents only on their first pages.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note that although we do not consider the problem of segmentation of multi-page streams (PSS - Page Stream Segmentation) in this article, but if we add the remaining pages of documents to the training of our classifier, and not just the first, we can easily </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">obtain a solution to the problem of PSS segmentation with binary classification</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : for pages from the stream, two classes are predicted in turn: ‚Äúnew document‚Äù or ‚Äúsame document‚Äù.&nbsp;</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preprocessing</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since many images of scans are large, and this affects the processing speed, we initially compress all scans so that both image sizes (width and height) are no more than 2000 pixels. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To extract text from images, we used the free </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tesseract 4.0</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> package </font><font style="vertical-align: inherit;">from Google. </font><font style="vertical-align: inherit;">Version 4.0 (and higher) of this package works pretty well with noise (unlike previous versions), so we did not remove noise from texts, but determined the ‚Äúcorrect‚Äù orientation before extracting text from the scan image, for which we also used special functions in Tesseract 4.0.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Convolutional classifier in pictures</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
From each document, we obtained convolutional signs using a pre-trained convolutional neural network ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ResNet34</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). For this, the outputs of the last convolutional layer ‚Äî a vector of 512 convolutional signs ‚Äî were taken. Before running through a neural network, pictures of scans from train underwent some augmentation to resist retraining. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a model of the classifier on convolutional signs, logistic regression and boostings were tried with the selection of parameters on dev. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The quality of the best convolutional classifier model on test was about 76.1% (accuracy) on logistic regression.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This method allowed us to classify scans that are apparently well different from each other. But to run the pictures through the neural network, they were compressed to the size of the input of the neural network (ResNet34 has a size of 224x224 pixels at the input), and therefore the classification quality is low: the fine print of documents becomes unreadable, and the classifier can ‚Äúcatch‚Äù only for some convolutional signs, obtained from a large font, some objects on a page with a special arrangement, etc., but such a classifier does not take into account the essence of the text. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ik/9e/9k/ik9e9kshvecqqnmxpkydjgghrwq.jpeg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The scan of the first page of the lease agreement and the first page of the charter of the company are visually well different</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But we are solving the problem of classifying corporate documents, where many types of documents contain mostly textual information, and it is difficult to distinguish visually - it is difficult to visually ‚Äúcatch‚Äù only on ‚Äúelongated spots‚Äù of lines with identical document headers: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/-2/yf/i-/-2yfi-huofcgcclpwevjxawhhty.jpeg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reduced copies of scans of certificates from two different categories visually almost indistinguishable</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
We assume that text attributes will improve quality, and therefore add text attributes, or rather, create a text classifier for the baseline model.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Text classifier</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For the baseline model, we will build a text classifier only on the signs TF-IDF (Term Frequency - Inverse Document Frequency) on texts extracted from scans. </font><font style="vertical-align: inherit;">Before compiling the thermal matrix TF-IDF, the texts were reduced to lower case; </font><font style="vertical-align: inherit;">punctuation, stop words were deleted from texts; </font><font style="vertical-align: inherit;">words were checked for spelling and reduced to the initial form by lemmatization (Pymystem3 package).&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a classifier model, we tried again logistic regression and boostings, the parameters were selected on dev. </font><font style="vertical-align: inherit;">Since the thermal matrices are large in size and very sparse, logistic regression showed good quality, and the quality was 85.4% (accuracy) per test.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ensemble of classifiers</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To obtain the ensemble, we took a blend of convolutional and text classifiers with weights selected on the dev sample. That is, for each scan S we take with the weight Œ± the probability set Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (11-digit by the number of categories), issued by the convolutional classifier, we also take the 11-digit probability set Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , issued by the text classifier, with the weight 1 ‚Äì Œ±, and summarize these weighted sets to get the output of the mixed baseline classifier: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (S) = Œ± Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> + (1 - Œ±) Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF</font></font></sub><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
As a result, we got the quality of the mixed classifier 90.2% (accuracy) on test. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Classifier results: convolutional (Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), text based on tf-idf (Y</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) and their ensemble (Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 76.1%</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf-idf</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 85.4%</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 90.2%</font></font><br>
</li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Two-step classification</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When analyzing the results of the ensemble of classifiers, it turned out that he often makes mistakes on scans from the ‚ÄúPassport (RF)‚Äù category, classifying passports as ‚ÄúOther‚Äù, since this category contains a lot of identity cards. </font><font style="vertical-align: inherit;">Moreover, their scans, as well as passport scans, are also often of poor quality, which interferes with the qualitative classification. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Therefore, we decided to carry out the classification in two steps.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Step 1</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We transferred to the category ‚ÄúPassport of the Russian Federation‚Äù all identification cards from the category ‚ÄúOther‚Äù in accordance with the initial splitting into train, dev and test. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main 10 categories:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lease contract</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Extract from the register of participants</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Company Charter</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certificate of registration with the tax authority</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Questionnaire for legal entities</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Passport of the Russian Federation + various ID cards (foreign passports, migration cards, etc.)</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Incorporation sheet</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Certificate of state registration of legal entity</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Orders / Orders</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Decisions / Protocols</font></font><br>
</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Category "Other":</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Other evidence</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IP questionnaires</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Statements</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acts</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Power of attorney</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Questionnaires</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Decisions of the arbitration court, etc.</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We trained an ensemble of classifiers on such a modified sample.&nbsp;</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Step 2&nbsp;</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a second step, we conducted a binary classification within category 6 obtained in the first step: ‚ÄúPassport of the Russian Federation‚Äù (class 1) versus ‚ÄúVarious identity cards‚Äù (class 0). </font><font style="vertical-align: inherit;">To do this, by analogy, we trained convolutional and text classifiers (in both models there was a logistic regression) and weighed their outputs, having received the ensemble. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The overall classification quality at two steps turned out to be 95.7% (accuracy) per test. </font><font style="vertical-align: inherit;">In this case, the quality meets the requirements of our business customers (threshold - 95%).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT signs</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We built a two-step classification, similar to what we did above, but at each step, instead of the TF-IDF features, we used text embedding of pages obtained from the RuBERT model. For each page, the text was tokenized, and a sequence of the first 256 tokens was supplied to the input of the RuBERT model (with pad padding up to 512, i.e., to the size of the model input).&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For greater efficiency, before receiving text embeddings, we pre-trained the Masked Language Model (MLM) model on the texts from our dataset, similar to how the authors of the BERT model did it: when we fed a sequence of tokens to the input of the RuBERT model, we replaced a certain fraction with the [MASK] token taken tokens. For the purity of the experiment, pre-training was carried out only on texts from train. Token sequences were taken on all pages of segmented documents, and not just on the first. The beginning of the sequences was randomly selected from the tokenized text. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the stage of embedding, the average vector of the resulting outputs of the RuBERT model was taken as the text embedding of the page.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pre-training gave an improvement in a two-step classification: when using text embeddings obtained from the RuBERT model, the quality increased to 96.3% (accuracy) by test. </font><font style="vertical-align: inherit;">Note the fact that the closer accuracy is to 100%, the more difficult it is to improve. </font><font style="vertical-align: inherit;">Therefore, the resulting increase of 0.6% can be considered significant. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An increase in the length of the input token sequences to 512 (up to the input size of the BERT model) did not produce a noticeable increase.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What we got</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The final scheme of the model: </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/eb1/bdf/818/eb1bdf8183c5015c50d5316f6092d921.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The quality of all tested models:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 76.1%,</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 85.4%,</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 90.2%,</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF + 2steps</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 95.7%,</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + RuBERT + 2steps</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - 96.3%,</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
where Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is a convolutional classifier, Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is a text classifier on the attributes of TF-IDF.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - ensemble of classifiers (Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (S) = Œ± Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> + (1 - Œ±) Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TF-IDF,</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œ± = 0.45). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + TF-IDF + 2steps</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - two-step classification: 1) ID cards are transferred to the category ‚ÄúPassports of the Russian Federation + ID cards‚Äù, and an ensemble of classifiers is built on the resulting sample with 11 classes; 2) in the category ‚ÄúPassports of the Russian Federation + Identity Cards‚Äù, an ensemble of classifiers with two classes is being built: class 1 - the Passport of the Russian Federation, class 0 - Identity Cards. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN + RuBERT + 2steps</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- two-step classification; </font><font style="vertical-align: inherit;">instead of TF-IDF signs, text embeddings of the RuBERT model pre-trained on our dataset are taken.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en497470/index.html">How to Eject Viruses on the Corona SDK</a></li>
<li><a href="../en497476/index.html">Top 8 JavaScript Data Structures</a></li>
<li><a href="../en497478/index.html">Network simulator tutorial ns-3. Chapter 4</a></li>
<li><a href="../en497480/index.html">Video Lectures: unix way</a></li>
<li><a href="../en497482/index.html">Authentication in Kubernetes with Dex: fasten LDAP</a></li>
<li><a href="../en497486/index.html">Data division. year 2013. Retrospective</a></li>
<li><a href="../en497488/index.html">Automate HR processes using Microsoft Teams, PowerApps and Power Automate. Employee withdrawal requests</a></li>
<li><a href="../en497490/index.html">Difficulties in paternity of seahorses: genetic metamorphoses of the immune system</a></li>
<li><a href="../en497492/index.html">Application on TSD and communication with 1C: Enterprise 8.3 through HTTP-Service. Part 1.1 (Detailed Description of the API)</a></li>
<li><a href="../en497504/index.html">How Quarkus Integrates MicroProfile and Spring</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
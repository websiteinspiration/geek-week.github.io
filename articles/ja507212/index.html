<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😥 👸🏽 👉🏿 MLエージェントを使用した「自分で遊ぶ」方法を使用してUnityでスマートゲームのライバルをトレーニングする 🤲 🔏 🛌🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、ハブル！
 
 私たちの定期的な読者が知っているように、私たちはUnity に関する書籍を長く成功裏に出版しています。トピックの調査の一環として、特にML-Agents Toolkitに関心がありました。今日、私たちはあなたに、「自分で」の方法を使用してゲームエージェントを効果的にトレー...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>MLエージェントを使用した「自分で遊ぶ」方法を使用してUnityでスマートゲームのライバルをトレーニングする</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/507212/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは、ハブル！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちの定期的な読者が知っているように、私たちは</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">Unity </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に関する書籍</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">長く成功裏に</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">出版し</font></a><font style="vertical-align: inherit;">てい</font><font style="vertical-align: inherit;">ます。トピックの調査の一環として、特に</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ML-Agents Toolkitに</font></a><font style="vertical-align: inherit;">関心がありました</font><font style="vertical-align: inherit;">。今日、私たちはあなたに、「自分で」の方法を使用してゲームエージェントを効果的にトレーニングする方法に関するUnityブログの記事の翻訳を注目しています。特に、この記事は、この方法が従来の強化学習よりも効果的である理由を理解するのに役立ちます。</font><font style="vertical-align: inherit;">
読書を楽しむ！</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br>
<img src="https://habrastorage.org/webt/vb/sz/5m/vbsz5musziyq5yighwu_iq0eggu.png"><br>
<br><font style="vertical-align: inherit;"></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、この記事では、セルフプレイテクノロジー（自分で遊ぶ）の概要を示し、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ML-Agents Toolkit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">からサッカーデモ環境で安定した効果的なトレーニングを提供する方法を示します</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unity ML-Agents ToolkitのTennisおよびSoccerデモ環境では、エージェントはライバルのように互いに競い合っています。このような競争の激しいシナリオでエージェントをトレーニングすることは、非常に重要な作業です。実際、ML-Agents Toolkitの以前のリリースでは、エージェントが自信を持って学習するために、賞の真剣な調査が必要でした。では</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、バージョン0.14</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ユーザーが自己再生に基づく強化学習（RL）を使用してエージェントをトレーニングできる機能が追加されました。これは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI Five</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">や</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeepMindのAlphaStar</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">など、最も高度な強化学習の成果の1つを達成するために重要なメカニズム</font><font style="vertical-align: inherit;">です。エージェントの現在お​​よび過去のハイポスタシスを互いに作業ピットで自己再生します。したがって、私たちはエージェントの敵を手に入れます。エージェントは、従来の強化学習アルゴリズムを使用して徐々に改善できます。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">完全に訓練されたエージェント</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、高度な人間のプレイヤーとうまく競争することができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自己再生は、人間の視点から見た競争と同じ原則に基づいて構築された学習環境を提供します。たとえば、テニスを習得した人は、自分とほぼ同じレベルで相手をスパーリングすることを選択します。相手が強すぎたり弱すぎたりすると、ゲームをマスターするのにあまり便利ではないからです。自分のスキルを開発するという観点からは、初心者のテニスプレーヤーが、たとえば就学前の子供やNovak Djokovicよりも、同じ初心者を倒すほうがはるかに価値がある場合があります。前者はボールを打つことさえできず、後者はあなたが打つことができるようなサーブをあなたに与えません。初心者が十分な強さを身につけたら、次のレベルに進むか、より深刻なトーナメントに申し込み、より熟練した対戦相手と対戦することができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、自分自身でゲームのダイナミクスに関連する技術的な微妙な点を検討し、ゲーム自体を説明するような方法でリファクタリングされた仮想環境であるテニスとサッカーでの作業例も検討します。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ゲームで自分とゲームのストーリー</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分と遊ぶ現象は長い歴史があり、ゲームで人と競争するように設計された人工ゲームエージェントの開発の実践に反映されています。</font><font style="vertical-align: inherit;">このシステムを最初に使用したのはアーサーサミュエルで、1950年代にチェスシミュレータを開発し、</font><font style="vertical-align: inherit;">1959年に</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">この作品</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を発表</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">しまし</font></a><font style="vertical-align: inherit;">た。</font><font style="vertical-align: inherit;">このシステムは、TD-GammonでGerald Tesauroによって達成された強化学習の画期的な結果の先駆けとなりました。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">公開された合計</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1995年に。 TD-GammonはTD（λ）時間差アルゴリズムを使用して、エージェントと一緒に遊ぶ機能を使ってエージェントを訓練し、エージェントがバックギャモンをプレーしてプロの人と競争できるようにしました。場合によっては、TD-Gammonが世界クラスのプレーヤーよりもポジションについて自信を持ってビジョンを持っていることが観察されています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分と遊ぶことは、RLに関連する多くの象徴的な成果に反映されています。自分でプレイすることは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">チェス</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">をプレイするエージェントの開発</font><font style="vertical-align: inherit;">と超人的な能力、エリート</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DOTA 2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">エージェント</font><font style="vertical-align: inherit;">、そして</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">レスリング</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">や</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">かくれんぼ</font></a><font style="vertical-align: inherit;">などのゲームの複雑な戦略と対抗戦略</font><font style="vertical-align: inherit;">の開発に役立ちました。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">自分で遊んで得られる結果では、ゲームエージェントが専門家を驚かせる戦略を選択することがよくあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分で遊ぶことで、エージェントのプログラマーの創造性とは独立した特定の創造性が得られます。</font><font style="vertical-align: inherit;">エージェントは、ゲームのルールのみを受け取り、次に、勝ったか負けたかに関する情報を受け取ります。</font><font style="vertical-align: inherit;">さらに、これらの基本原則に基づいて、エージェントは有能な行動を発達させる必要があります。</font><font style="vertical-align: inherit;">TD-Gammonの作成者によると、そのような学習へのアプローチは解放され、「プログラムは人間の傾向や偏見によって制約されないという意味で、誤って信頼できないことが判明する可能性があります。」</font><font style="vertical-align: inherit;">この自由のおかげで、エージェントは、エンジニアが特定のゲームについて考える方法を完全に変える素晴らしいゲーム戦略を発見します。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">競争力強化トレーニング</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
強化学習の従来のタスクのフレームワーク内で、エージェントは総報酬を最大化する一連の行動を開発しようとしています。やりがいのある信号は、エージェントのタスクをエンコードします。そのようなタスクには、たとえば、コースの計画やアイテムの収集などがあります。エージェントの行動は環境の制約を受けます。たとえば、重力、障害物、エージェント自身が行ったアクションの相対的な影響、たとえば自分の動きに力を加えることなどです。これらの要因はエージェントの行動を制限し、高い報酬を受け取るためにエージェントが処理することを学ぶ必要がある外力です。したがって、エージェントは環境のダイナミクスと競合し、最大の報酬が達成されるように状態から状態に正確に移動する必要があります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/if/jf/xi/ifjfxil_iqm9pznr61qbpxujs38.png"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">左側に典型的な強化トレーニングシナリオを示します。エージェントは環境内で行動し、次の状態に移行して報酬を受け取ります。トレーニングシナリオは右側に示されています。このシナリオでは、エージェントはライバルと競争します。ライバルは、エージェントの観点からは、実際には環境の要素です。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
競争ゲームの場合、エージェントは環境のダイナミクスだけでなく、別の（おそらく知的）エージェントとも競合します。対戦相手は環境に組み込まれていると想定でき、エージェントの行動は、エージェントが「見る」次の状態と、エージェントが受け取る報酬に直接影響します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zl/kv/xo/zlkvxoa9_bt0cdsthmddwll-fvc.png"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MLエージェントツールキットのテニスの例</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ML-Agents Tennisのデモを考えてみましょう。青いラケット（左）が学習エージェントで、紫（右）が相手です。ネット上にボールを投げるには、エージェントは、相手から飛んでくるボールの軌道を考慮し、環境条件（重力）を考慮して、飛ぶボールの角度と速度を調整する必要があります。しかし、対戦相手との対戦では、ネット越しにボールを投げるのは戦闘の半分に過ぎません。強い対戦相手は、たまらない一撃で応答することができ、その結果、エージェントは負けます。弱い相手はボールをネットに打ち込むかもしれません。対戦相手がサーブを返すことができるため、ゲームは続行されます。いずれにせよ、次の状態と対応する報酬の両方は、環境条件と対戦相手の両方に依存します。ただし、これらすべての状況で、エージェントは同じ売り込みを行います。したがって、競争ゲームのトレーニングとして、エージェントによるライバル行動のポンピングは複雑な問題です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
適切な対戦相手の考慮事項は簡単ではありません。上記から明らかなように、対戦相手の相対的な強さは特定のゲームの結果に大きく影響します。対戦相手が強すぎる場合、エージェントは最初からプレイする方法を学ぶのが難しい場合があります。一方、対戦相手が弱すぎる場合、エージェントは勝つことを学ぶことができますが、これらのスキルは、より強いまたは単に異なる対戦相手との競争では役に立たない場合があります。したがって、エージェントとほぼ同じ強さの（対抗できないが乗り越えられない）対戦相手が必要です。さらに、ゲームが完了するたびにエージェントのスキルが向上するため、対戦相手の力も同程度に上げる必要があります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fn/vk/pt/fnvkptgsipqopi2iiyflsa5ec_a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分で遊ぶ場合、過去のスナップショットまたは現在の状態のエージェントが環境に組み込まれた対戦相手です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは私たち自身とのゲームが重宝するところです！エージェント自身は、希望する対戦相手の両方の要件を満たします。彼は間違いなく自分とほぼ同じ強さであり、彼のスキルは時間とともに向上します。この場合、エージェント自身のポリシーが環境に組み込まれます（図を参照）。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">徐々に複雑さを増す教育</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（カリキュラム学習）に</font><font style="vertical-align: inherit;">精通し</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ている</font></a><font style="vertical-align: inherit;">人は</font><font style="vertical-align: inherit;">、システムがカリキュラムを自然に発展させていると想定できることを示しています。その後、エージェントはより強力な対戦相手と戦うことを学びます。したがって、自分でプレイすると、環境自体を使用して、競合ゲームの競合エージェントをトレーニングできます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次の2つのセクションでは、特にML-Agents Toolkitでの自分とのゲームの実装と使用に関して、競争力のあるエージェントのトレーニングの技術的な詳細について検討します。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実用的な考慮事項</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分で遊ぶためのフレームワークに関して、いくつかの実際的な問題が発生します。</font><font style="vertical-align: inherit;">特に、エージェントが特定のプレイスタイルでのみ勝利することを学習する再トレーニングが可能です。また、遷移関数の不安定性（つまり、常に変化する対戦相手）によって発生する可能性がある学習プロセスに固有の不安定性もあります。</font><font style="vertical-align: inherit;">最初の問題は、エージェントにさまざまなタイプの敵と戦うための一般的な理解と能力を持たせたいために発生します。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2番目の問題はテニス環境で説明できます。さまざまな対戦相手がさまざまな速度と角度でボールを打つことになります。学習エージェントの観点から見ると、これは、学習するにつれて、同じ決定が異なる結果につながり、したがって、エージェントはその後の異なる状況になることを意味します。従来の強化学習では、定常遷移関数が暗示されています。残念ながら、最初の問題を解決するためにエージェントに対してさまざまな対戦相手を用意したので、私たちは不注意で2番目の問題を悪化させることがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これに対処するために、過去のエージェントポリシーでバッファを維持し、そこから長期にわたって「学生」の潜在的なライバルを選択します。</font><font style="vertical-align: inherit;">過去のポリシーからエージェントを選択すると、多様な対戦相手の選択ができます。</font><font style="vertical-align: inherit;">さらに、エージェントが固定対戦相手と長時間トレーニングできるようにすることで、遷移機能を安定させ、より一貫した学習環境を作成します。</font><font style="vertical-align: inherit;">最後に、これらのアルゴリズムの側面は、次のセクションで説明するハイパーパラメーターを使用して制御できます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実装と使用の詳細</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分自身と遊ぶためのハイパーパラメーターを選択する場合、まず第一に、対戦相手のレベル、最終的なポリシーの普遍性、トレーニングの安定性の間の妥協点に留意してください。ゆっくりと変化する、またはまったく変化しない、したがって結果のばらつきが少ない対戦相手のグループとの競争でのトレーニングは、急速に変化するさまざまなライバルとの競争でのトレーニングよりも安定したプロセスです。使用可能なハイパーパラメーターを使用すると、現在のエージェントポリシーがサンプルの対戦相手の1つとして後で使用するために保存される頻度、新しい対戦相手が保存される頻度、その後スパーリング用に選択される頻度、新しい対戦相手が選択される頻度、保存される対戦相手の数、および確率を制御できますこの場合、生徒はプールから選択された対戦相手ではなく、自分の分身に対してプレーする必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
競争ゲームでは、環境によって発行された「累積」賞は、学習の進捗状況を追跡するためのおそらく最も有益な指標ではありません。実際のところ、累積賞は完全に相手のレベルに依存します。特定のゲームスキルを持つエージェントは、スキルの低い対戦相手またはスキルの高い対戦相手に応じて、それぞれ多かれ少なかれ報酬を受け取ります。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELOレーティングシステムの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">実装を提案し</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。これにより、特定の母集団からの2人のプレイヤーの相対的なゲームスキルを、ゼロの金額でプレイするときに計算できます。 1回のトレーニング実行中、この値は着実に増加するはずです。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TensorBoard</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を使用して、他の学習指標、たとえば賞全体と一緒に追跡できます</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">サッカーで自分と遊ぶ</font></font></h3> <br>
<img src="https://habrastorage.org/webt/gl/m_/rh/glm_rhop1whkyve0i-wpubxfpqw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
信頼性の高いトレーニングプロセスが組み込まれていないため、ML-Agent Toolkitの最新リリースには、サッカー学習環境のエージェントポリシーは含まれていません。</font><font style="vertical-align: inherit;">ただし、自分自身でゲームを使用し、リファクタリングを行うことで、重要な動作についてエージェントをトレーニングできます。</font><font style="vertical-align: inherit;">最も重要な変更は、エージェントの特性からの「ゲームポジション」の削除です。</font><font style="vertical-align: inherit;">以前のサッカー環境では、「ゴールキーパー」と「ストライカー」がはっきりと目立っていたため、ゲームプレイ全体がより論理的に見えました。</font><font style="vertical-align: inherit;">では</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、この動画</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">役割の振る舞いが自発的にどのように形成されるかを確認できる新しい環境が提示されます。この環境では、一部のエージェントが攻撃者として行動し始め、他のエージェントがゴールキーパーとして行動し始めます。現在、エージェント自身がこれらのポジションを再生することを学んでいます！ 4つのエージェントすべての報酬関数は、得点されたゴールの+1.0および失点されたゴールの-1.0として定義され、ステップごとに-0.0003の追加のペナルティ-このペナルティは、エージェントの攻撃を刺激するために提供されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここでは、サッカー学習環境のエージェント自体が協調行動を学習することを再度強調します。このため、マルチエージェントの行動や役割の割り当てに関連する明示的なアルゴリズムは使用されません。</font><font style="vertical-align: inherit;">この結果は、タスクが適切に定式化されていれば、比較的単純なアルゴリズムを使用して、エージェントを複雑な動作でトレーニングできることを示しています。</font><font style="vertical-align: inherit;">このための最も重要な条件は、エージェントがチームメイトを観察できることです。つまり、エージェントはチームメイトの相対的な位置に関する情報を受け取ります。</font><font style="vertical-align: inherit;">ボールに積極的な戦いを強いると、エージェントは間接的にチームメイトに守備に移動するように伝えます。</font><font style="vertical-align: inherit;">それどころか、守備から遠ざかると、エージェントはチームメイトに攻撃を挑発します。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">次は何ですか</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このリリースの新機能を使用したことがある場合は、それらについてお知らせください。</font><font style="vertical-align: inherit;">発見されたバグについて話し合うことができる</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ML-Agents GitHubの問題</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ページと</font><font style="vertical-align: inherit;">、</font><font style="vertical-align: inherit;">一般的な質問と問題が議論さ</font><font style="vertical-align: inherit;">れている</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unity ML-Agentsフォーラム</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ページ</font><font style="vertical-align: inherit;">に</font><font style="vertical-align: inherit;">注意を向けます</font><font style="vertical-align: inherit;">。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja507200/index.html">データサイエンティストがあなたをだます7つの方法</a></li>
<li><a href="../ja507202/index.html">Avito Analyticsミートアップ</a></li>
<li><a href="../ja507204/index.html">工業デザインインテリアキッチン：スケッチからボックス内の製品まで</a></li>
<li><a href="../ja507206/index.html">建築Yメッセンジャー</a></li>
<li><a href="../ja507210/index.html">大量のデータを処理するときの最新のJavaのパフォーマンス、パート2</a></li>
<li><a href="../ja507214/index.html">インタラクティブPDFフォーム、または新しいスキルABBYY FineReader PDFを作成および変更する方法</a></li>
<li><a href="../ja507218/index.html">私を読んでください、またはテキストが最後まで読んでいない理由</a></li>
<li><a href="../ja507222/index.html">誰もがマスクを着用すべき理由</a></li>
<li><a href="../ja507224/index.html">視覚テストで死角をなくす方法</a></li>
<li><a href="../ja507226/index.html">OCR for PDF in .NET-アクセスできないPDFドキュメントからテキストを抽出する方法</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
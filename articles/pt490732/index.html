<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äçü§ù‚Äçüë®üèª üë®üèº‚Äç‚öïÔ∏è üë©üèæ‚Äçü§ù‚Äçüë®üèø Reconhecimento de Fala: Um Curso Introdut√≥rio Muito Curto ‚úãüèø ü§±üèΩ üë©üèª‚Äç‚öïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√â quase imposs√≠vel dizer ao leigo o mais simples poss√≠vel sobre o trabalho de reconhecimento de fala por computador e convert√™-lo em texto. Nem uma √∫n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Reconhecimento de Fala: Um Curso Introdut√≥rio Muito Curto</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/toshibarus/blog/490732/"><img src="https://habrastorage.org/webt/tz/sh/ll/tzshllxzf2iddwai7sredy3edie.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√â quase imposs√≠vel dizer ao leigo o mais simples poss√≠vel sobre o trabalho de reconhecimento de fala por computador e convert√™-lo em texto. </font><font style="vertical-align: inherit;">Nem uma √∫nica hist√≥ria √© completa sem f√≥rmulas complexas e termos matem√°ticos. </font><font style="vertical-align: inherit;">Vamos tentar explicar da maneira mais clara e simplista poss√≠vel o modo como o smartphone entende a fala, quando os carros aprenderem a reconhecer a voz humana e em que √°reas inesperadas essa tecnologia √© usada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aviso necess√°rio: se voc√™ √© um desenvolvedor ou, especialmente, um matem√°tico, √© improv√°vel que voc√™ aprenda algo novo no post e at√© se queixe da natureza cient√≠fica insuficiente do material. </font><font style="vertical-align: inherit;">Nosso objetivo √© apresentar aos leitores n√£o iniciados as tecnologias da fala da maneira mais simples e contar como e por que a Toshiba adotou a cria√ß√£o da sua IA de voz.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Marcos importantes na hist√≥ria do reconhecimento de fala</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A hist√≥ria do reconhecimento da fala humana por m√°quinas eletr√¥nicas come√ßou um pouco mais cedo do que se costuma pensar: na maioria dos casos, √© uma contagem regressiva desde 1952, mas, na verdade, um dos primeiros dispositivos que responderam aos comandos de voz foi o rob√¥ Televox, sobre o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">qual j√° escrevemos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Criado em 1927 nos EUA, o rob√¥ Herbert Televox era um dispositivo simples no qual v√°rios rel√©s reagiam a sons de diferentes frequ√™ncias. O rob√¥ tinha tr√™s diapas√µes, cada um dos quais era respons√°vel por seu tom. Dependendo de qual diapas√£o funcionou, um ou outro rel√© foi ativado.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/90/pq/4i/90pq4ixpys3c8uevjp-ovvydfny.jpeg" alt="imagem"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De fato, todo o "preenchimento" da Televox, incluindo o sistema de reconhecimento de comando, estava localizado em um rack na √°rea do corpo do "rob√¥". Era imposs√≠vel fechar a tampa; caso contr√°rio, os diapas√µes n√£o poderiam "ouvir" corretamente os sons. Fonte: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acme Telepictures / Wikimedia</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Era poss√≠vel se comunicar com a Televox como sinais separados com um apito e em breves sinais verbais - seus diapas√µes tamb√©m eram dispostos em uma sequ√™ncia de sons. O criador do rob√¥, Roy Wensley, at√© fez uma demonstra√ß√£o fant√°stica para aqueles tempos, dizendo o comando ‚ÄúGergelim, aberto‚Äù, atrav√©s do qual a Televox ligou o rel√© respons√°vel por abrir a porta. Sem tecnologia digital, redes neurais, IA e aprendizado de m√°quina - apenas tecnologia anal√≥gica!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A pr√≥xima inven√ß√£o chave que abriu o caminho para o verdadeiro reconhecimento da fala humana foi a m√°quina Audrey, desenvolvida em 1952 no Bell Labs Innovation Forge. O enorme Audrey consumia muita eletricidade e era do tamanho de um bom gabinete, mas toda a sua funcionalidade se resumia ao reconhecimento de n√∫meros falados de zero a nove. Apenas dez palavras, sim, mas n√£o vamos esquecer que Audrey era uma m√°quina anal√≥gica. </font></font><br>
<img src="https://habrastorage.org/webt/vd/1q/eb/vd1qebrer6czotgwty3tdyfp15i.png" alt="imagem"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Infelizmente, a hist√≥ria n√£o preservou fotografias p√∫blicas de Audrey, existe apenas um conceito. Simples no papel, dif√≠cil de traduzir - de acordo com as mem√≥rias dos contempor√¢neos, os componentes de Audrey ocupavam um gabinete inteiro. Fonte: Bell Labs</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Funcionou assim: o locutor falou n√∫meros no microfone, fazendo intervalos de pelo menos 350 ms entre as palavras, Audrey converteu os sons que ouvia em sinais el√©tricos e os comparou com amostras gravadas na mem√≥ria anal√≥gica. De acordo com os resultados da compara√ß√£o, o carro destacou o n√∫mero no painel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Foi um avan√ßo, mas n√£o houve benef√≠cio real de Audrey - a m√°quina reconheceu a voz de seu criador com uma precis√£o de 97%, enquanto outros falantes especialmente treinados receberam uma precis√£o de 70-80%. Estranhos que entraram em contato com Audrey, por mais que tentassem, viram seu n√∫mero no placar em apenas 50% dos casos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apesar dos resultados revolucion√°rios da √©poca, Audrey n√£o encontrou e n√£o encontrou aplica√ß√£o pr√°tica. </font><font style="vertical-align: inherit;">Supunha-se que o sistema pudesse ser adaptado em vez das operadoras de telefonia, mas, no entanto, os servi√ßos humanos eram mais convenientes, mais r√°pidos e muito mais confi√°veis ‚Äã‚Äãdo que Audrey.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rQco1sa9AwU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apresenta√ß√£o semelhante √† Audrey, apenas m√°quinas muito menores - IBM Shoebox. </font><font style="vertical-align: inherit;">A velocidade da caixa de sapatos √© claramente vis√≠vel. </font><font style="vertical-align: inherit;">A m√°quina tamb√©m pode executar opera√ß√µes matem√°ticas simples de adi√ß√£o e subtra√ß√£o</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No in√≠cio dos anos 60, o trabalho de cria√ß√£o de m√°quinas para reconhecimento de fala foi realizado no Jap√£o, Reino Unido, EUA e at√© na URSS, onde eles inventaram um algoritmo muito importante para a transforma√ß√£o din√¢mica da linha do tempo (DTW), com a ajuda da qual foi poss√≠vel construir um sistema com cerca de 200 palavras. Mas todos os desenvolvimentos foram semelhantes entre si, e o princ√≠pio do reconhecimento tornou-se uma desvantagem comum: as palavras foram percebidas como impress√µes digitais sonoras integrais e, em seguida, foram verificadas na base de amostras (dicion√°rio). Quaisquer mudan√ßas na velocidade, timbre e clareza da pron√∫ncia das palavras afetaram significativamente a qualidade do reconhecimento. Os cientistas t√™m uma nova tarefa: ensinar a m√°quina a ouvir sons individuais, fonemas ou s√≠labas e depois criar palavras a partir deles. Essa abordagem tornaria poss√≠vel nivelar o efeito da altera√ß√£o do alto-falante quando, dependendo do alto-falante, o n√≠vel de reconhecimento variasse acentuadamente.</font></font><br>
<br>
<i> ‚Äî     ,           . ,   ¬´ ¬ª  ¬´¬ª       ¬´¬ª.   ¬´¬ª   ¬´ ¬ª  ¬´ ¬ª      ¬´¬ª,    ‚Äî  ¬´¬ª.  ,  ,   . </i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em 1971, a Ag√™ncia de Projetos de Pesquisa Avan√ßada do Departamento de Defesa (DARPA) lan√ßou um programa de cinco anos com um or√ßamento de US $ 15 milh√µes, encarregado de criar um sistema de reconhecimento que tivesse pelo menos mil palavras. Em 1976, a Universidade Carnegie Mellon introduziu o Harpy, capaz de operar um dicion√°rio de 1011 palavras. Harpy n√£o comparou as palavras completamente ouvidas com as amostras, mas as dividiu em alofones (uma amostra do som de um fonema, dependendo das letras ao seu redor). Esse foi outro sucesso, confirmando que o futuro est√° no reconhecimento de fonemas individuais, e n√£o em palavras inteiras. No entanto, entre as desvantagens da Harpy, havia um n√≠vel extremamente baixo de reconhecimento correto de alofones (pron√∫ncia de fonemas) - cerca de 47%. Com um erro t√£o alto, a parcela de erros aumentou ap√≥s o volume do dicion√°rio.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/32KKg3aP3Vw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descri√ß√£o de como a Harpy funciona. O v√≠deo do programa n√£o sobreviveu.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
A experi√™ncia de Harpy mostrou que a cria√ß√£o de dicion√°rios de impress√µes digitais hol√≠sticas do som √© in√∫til - apenas aumenta o tempo de reconhecimento e reduz drasticamente a precis√£o, de modo que pesquisadores de todo o mundo adotaram um caminho diferente - o reconhecimento de fonemas. Em meados da d√©cada de 1980, a m√°quina IBM Tangora aprendeu a entender a fala de qualquer falante com sotaque, dialeto e pron√∫ncia, exigindo apenas um treinamento de 20 minutos, durante o qual um banco de dados de amostras de fonemas e alofones foi acumulado. O uso do </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo oculto de Markov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tamb√©m aumentou o vocabul√°rio do IBM Tangora para impressionantes 20.000 palavras - 20 vezes mais do que Harpy, e j√° √© compar√°vel ao vocabul√°rio do adolescente.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos os sistemas de reconhecimento de fala da d√©cada de 1950 a meados da d√©cada de 90 n√£o sabiam ler a linguagem natural falada de uma pessoa - eles tinham que pronunciar as palavras separadamente, fazendo uma pausa entre elas. Um evento verdadeiramente revolucion√°rio foi a introdu√ß√£o do modelo oculto de Markov, desenvolvido na d√©cada de 1980 - um modelo estat√≠stico que construiu suposi√ß√µes precisas sobre elementos desconhecidos com base nos conhecidos. Simplificando, com apenas alguns fonemas reconhecidos em uma palavra, o modelo oculto de Markov seleciona com muita precis√£o os fonemas ausentes, aumentando significativamente a precis√£o do reconhecimento de fala.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em 1996, o primeiro programa comercial apareceu, capaz de distinguir n√£o palavras individuais, mas um fluxo cont√≠nuo de fala natural - IBM MedSpeak / Radiology. A IBM era um produto especializado usado na medicina para descrever em poucas palavras os resultados de um raio-x emitido por um m√©dico durante o estudo. Aqui, o poder dos computadores finalmente se tornou suficiente para reconhecer palavras individuais "on the fly". Al√©m disso, os algoritmos se tornaram mais perfeitos, o reconhecimento correto de micro-pausas entre as palavras faladas apareceu.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O primeiro mecanismo universal para o reconhecimento da fala natural foi o programa Dragon NaturallySpeaking, em 1997. Ao trabalhar com ela, o locutor (ou seja, o usu√°rio) n√£o precisou receber treinamento ou operar com um vocabul√°rio espec√≠fico, como no caso do MedSpeak, qualquer pessoa, mesmo uma crian√ßa, poderia trabalhar com o NaturallySpeaking, o programa n√£o estabeleceu nenhuma regra de pron√∫ncia. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xj/m6/w-/xjm6w-kpgryltox7wquuvpl8db4.png" alt="imagem"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apesar da singularidade do Dragon NaturallySpeaking, os navegadores de TI n√£o demonstraram muito entusiasmo por reconhecer a fala natural. Entre as defici√™ncias, foram observados erros de reconhecimento e processamento incorreto de comandos endere√ßados ao pr√≥prio programa. Fonte: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">itWeek</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vale ressaltar que o mecanismo de reconhecimento estava pronto na d√©cada de 1980, mas devido √† falta de energia do computador, o desenvolvimento da Dragon Systems (agora de propriedade da Nuance Communications) n√£o teve tempo para determinar os espa√ßos entre as palavras em tempo real, o que √© necess√°rio para o reconhecimento da fala natural. </font><font style="vertical-align: inherit;">Sem isso, as palavras "enquanto estavam sendo tratadas", por exemplo, podiam ser ouvidas pelo computador como "aleijadas". </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√Ä frente estava a crescente popularidade de sistemas de reconhecimento de voz, redes neurais, o surgimento da pesquisa por voz do Google em dispositivos m√≥veis e, finalmente, o assistente de voz Siri, n√£o apenas convertendo a fala em texto, mas tamb√©m respondendo adequadamente √†s consultas constru√≠das de maneira natural.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como ouvir o que foi dito e pensar no que era inaud√≠vel?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Atualmente, a melhor ferramenta para criar um mecanismo de reconhecimento de fala √© a rede neural recorrente (RNN), na qual s√£o constru√≠dos todos os servi√ßos modernos para reconhecimento de voz, m√∫sica, imagens, rostos, objetos e texto. A RNN permite que voc√™ entenda as palavras com extrema precis√£o, al√©m de prever a palavra mais prov√°vel no contexto do contexto, se n√£o for reconhecida. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A classifica√ß√£o temporal do modelo de rede neural (CTC) seleciona fonemas individuais no fluxo de √°udio gravado (palavra, frase) e os organiza na ordem em que foram pronunciados. Ap√≥s an√°lise repetida, o CTC identifica claramente certos fonemas, e sua grava√ß√£o de texto √© comparada com o banco de dados de palavras na rede neural e depois se transforma em uma palavra reconhecida.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As redes neurais s√£o assim chamadas porque o princ√≠pio de seu trabalho √© semelhante ao trabalho do c√©rebro humano. O treinamento em redes neurais √© muito semelhante ao treinamento humano. Por exemplo, para que uma crian√ßa muito pequena aprenda a reconhecer carros e distingui-los das motocicletas, √© necess√°rio chamar v√°rias vezes sua aten√ß√£o para v√°rios carros e pronunciar a palavra correspondente: este √© grande e vermelho - o carro e esse preto baixo - o carro, mas isso e estas s√£o motocicletas. Em algum momento, a crian√ßa descobrir√° padr√µes e sinais comuns para carros diferentes e aprender√° a reconhecer corretamente onde est√° o carro, onde o jipe, onde a motocicleta e o ATV, mesmo que de passagem os veja em um cartaz publicit√°rio na rua. Da mesma forma, a rede neural precisa ser treinada com base em exemplos - para fazer centenas e milhares de variantes de pron√∫ncia de cada palavra, letra, fonema "aprender".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma rede neural recorrente para reconhecimento de fala √© boa porque, ap√≥s um longo treinamento na base de v√°rias pron√∫ncias, aprende com alta precis√£o a distinguir fonemas e formar palavras a partir deles, independentemente da qualidade e natureza da pron√∫ncia. E at√© ‚Äúpense‚Äù com alta precis√£o, dentro do contexto da palavra, palavras que n√£o puderam ser reconhecidas sem ambiguidade devido a ru√≠dos de fundo ou pron√∫ncia imprecisa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mas h√° uma nuance nas previs√µes da RNN - uma rede neural recorrente pode "pensar" em uma palavra que falta apenas confiando no contexto mais pr√≥ximo de cerca de cinco palavras. Fora deste espa√ßo, a an√°lise n√£o ser√° realizada. E √†s vezes ele √© t√£o necess√°rio! Por exemplo, para reconhecimento, pronunciamos a frase ‚ÄúO grande poeta russo Alexander Sergeyevich </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pushkin</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Äù, Em que a palavra‚Äú Pushkin ‚Äù(especialmente em it√°lico) foi dita t√£o inaud√≠vel que a IA n√£o a reconheceu com precis√£o. Mas uma rede neural recorrente, baseada na experi√™ncia adquirida durante o treinamento, pode sugerir que a palavra "Pushkin" seja encontrada com mais frequ√™ncia ao lado das palavras "russo", "poeta", "Alexander" e "Sergeyevich". Essa √© uma tarefa bastante simples para uma RNN treinada em textos em russo, porque um contexto muito espec√≠fico nos permite fazer suposi√ß√µes com a maior precis√£o.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E se o contexto √© vago? Tomemos outro texto em que uma palavra n√£o pode ser reconhecida: ‚ÄúNosso tudo, Alexander Sergeyevich Pushkin, morreu tragicamente no auge de sua vida ap√≥s um duelo com Dantes. O Festival de Teatro Pushkin recebeu o nome do poeta. ‚Äù Se voc√™ remover a palavra "Pushkinsky", a RNN simplesmente n√£o consegue adivinhar, com base no contexto da proposta, porque apenas menciona um festival de teatro e uma refer√™ncia ao nome de um poeta desconhecido - existem in√∫meras op√ß√µes poss√≠veis! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√â aqui que entra em cena a arquitetura de mem√≥ria de longo prazo (LSTM) para redes neurais recorrentes, criada em 1997 (um </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">artigo detalhado sobre LSTM</font></a><font style="vertical-align: inherit;"> ) </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Foi desenvolvido especialmente para adicionar a capacidade da RNN de levar em considera√ß√£o o contexto remoto do evento que est√° sendo processado - os resultados da solu√ß√£o de problemas anteriores (ou seja, reconhecimento de palavras) passam por todo o processo de reconhecimento, independentemente do tempo do mon√≥logo, e s√£o levados em considera√ß√£o em cada caso de d√∫vida. Al√©m disso, a dist√¢ncia de remo√ß√£o quase n√£o afeta a efici√™ncia da arquitetura. Com a ajuda do LSTM, se necess√°rio, uma rede de palavras levar√° em conta toda a experi√™ncia dispon√≠vel no √¢mbito da tarefa: em nosso exemplo, a RNN analisar√° a frase anterior, descobrir√° que Pushkin e Dantes foram mencionados anteriormente, portanto, ‚ÄúPelo nome do poeta‚Äù provavelmente aponta para um deles. Como n√£o h√° evid√™ncias da exist√™ncia do Festival de Teatro de Dantes,estamos falando de Pushkinsky (tanto mais que a impress√£o sonora de uma palavra n√£o reconhecida √© muito semelhante) - esse festival estava na base do treinamento da rede neural.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/P325_hrGsDI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Confiss√£o de um assistente de voz." </font><font style="vertical-align: inherit;">Quando uma rede neural bem treinada entra em a√ß√£o, um assistente de voz pode descobrir exatamente o que precisa ser feito com "chinelos verdes"</font></font></i><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como o reconhecimento de fala faz do mundo um lugar melhor?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em cada caso, o aplicativo √© diferente - ajuda algu√©m a se comunicar com os gadgets e, de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">acordo com</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mais da metade dos usu√°rios de smartphones da </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">PricewaterhouseCooper,</font></a><font style="vertical-align: inherit;"> d√° comandos de voz aos dispositivos - entre adultos (25 a 49 anos), a porcentagem daqueles que usam constantemente interfaces de voz, mesmo superior ao dos jovens (18-25) - 65% contra 59%. </font><font style="vertical-align: inherit;">E na R√∫ssia, pelo menos uma vez, pelo menos 71% da popula√ß√£o se comunicou com Siri, Google Assitant ou Alice. </font><font style="vertical-align: inherit;">45 milh√µes de russos se comunicam constantemente com o Yandex de Alice e o Yandex.Maps / Yandex.Navigator representam apenas 30% dos pedidos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O reconhecimento de fala realmente ajuda algu√©m no trabalho - por exemplo, como dissemos acima, para m√©dicos: na medicina desde 1996 (quando o IBM MedSpeak foi lan√ßado), o reconhecimento √© usado para registrar anamnese e estudar imagens - um m√©dico pode continuar trabalhando sem se distrair com grava√ß√µes em computador ou cart√£o de papel. A prop√≥sito, o trabalho sobre ditado em medicina √© realizado n√£o apenas no Ocidente - na R√∫ssia, h√° um programa Voice2Med do "Center for Speech Technologies".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Existem outros exemplos, incluindo o nosso. A organiza√ß√£o de um neg√≥cio da Toshiba envolve a inclus√£o total, isto √©, igualdade de direitos e oportunidades para pessoas com v√°rias condi√ß√µes de sa√∫de, inclusive para funcion√°rios com defici√™ncia auditiva. Temos um programa corporativo chamado Universal Design Advisor System, no qual pessoas com v√°rios tipos de defici√™ncias participam do desenvolvimento dos produtos Toshiba, fazendo sugest√µes para melhorar sua conveni√™ncia para pessoas com defici√™ncias - ou seja, n√£o assumimos como podemos melhorar, mas operamos com experi√™ncia real e avalia√ß√µes de funcion√°rios.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alguns anos atr√°s, na sede da Toshiba no Jap√£o, enfrentamos uma tarefa muito interessante, exigindo o desenvolvimento de um novo sistema de reconhecimento de fala. Durante a opera√ß√£o do Universal Design Advisor System, recebemos um insight importante: os funcion√°rios com defici√™ncia auditiva desejam participar de discuss√µes em reuni√µes e palestras em tempo real e n√£o se limitam a ler a transcri√ß√£o processada horas ou dias depois. Iniciar o reconhecimento de voz por meio de um smartphone nesses casos fornece um resultado muito fraco, ent√£o os especialistas da Toshiba tiveram que come√ßar a desenvolver um sistema de reconhecimento especializado. E, √© claro, imediatamente tivemos problemas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A conversa difere enormemente da fala escrita - n√£o falamos da maneira como escrevemos cartas, e uma conversa real traduzida em texto parece muito desleixada e at√© ileg√≠vel. Ou seja, mesmo se convertermos conversas no plano da manh√£ em texto com alta precis√£o, obteremos um hash incoerente repleto de parasitas verbais, interjei√ß√µes e "aaa", "uh" e "mmm". Para se livrar da transcri√ß√£o de sons, palavras e express√µes de emo√ß√µes desnecess√°rias no texto, decidimos desenvolver uma IA capaz de reconhecer com precis√£o m√°xima nem sempre os elementos necess√°rios do discurso coloquial, incluindo a colora√ß√£o emocional de algumas palavras (por exemplo, "sim, bem" pode parecer ceticismo ou como surpresa sincera, e estes s√£o significados literalmente opostos).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6z/vv/od/6zvvodwnihcvdqdqfv4uuprbtb4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parece um laptop com um conjunto de perif√©ricos para reconhecimento de voz usando o Toshiba AI (√† esquerda) e um aplicativo com os resultados para dispositivos finais (√† direita). Fonte: Toshiba</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
LSTM foi √∫til aqui, sem o qual a precis√£o do reconhecimento era insuficiente para que o texto recebido fosse lido e entendido sem esfor√ßo. Al√©m disso, o LSTM foi √∫til n√£o apenas para uma previs√£o mais precisa das palavras no contexto, mas tamb√©m para o processamento correto de pausas no meio de frases e interjei√ß√µes-parasitas - por isso ensinamos √† rede neural esses parasitas e pausas que s√£o naturais para a fala coloquial.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Isso significa que agora a rede neural pode remover interjei√ß√µes de transcri√ß√µes? </font><font style="vertical-align: inherit;">Sim, pode, mas isso n√£o √© necess√°rio. </font><font style="vertical-align: inherit;">O fato √© que (outra percep√ß√£o recebida) as pessoas com defici√™ncia auditiva s√£o guiadas, inclusive pelos movimentos dos l√°bios do falante. </font><font style="vertical-align: inherit;">Se os l√°bios se moverem, mas o texto correspondente a esses movimentos n√£o aparecer na tela, h√° uma sensa√ß√£o de que o sistema de reconhecimento perdeu parte da conversa. </font><font style="vertical-align: inherit;">Ou seja, para algu√©m que n√£o pode ouvir, √© importante obter o m√°ximo de informa√ß√µes poss√≠vel sobre a conversa, incluindo pausas infelizes e mejometia. </font><font style="vertical-align: inherit;">Portanto, o mecanismo da Toshiba deixa esses elementos na transcri√ß√£o, mas em tempo real diminui o brilho das letras, deixando claro que esses s√£o detalhes opcionais para a compreens√£o do texto.</font></font><br>
<br>
<div class="oembed"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.toshiba-clip.com/en/detail/7655</font></font></a></div><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â assim que o resultado do reconhecimento em tempo real aparece no dispositivo cliente. </font><font style="vertical-align: inherit;">As partes do mon√≥logo que n√£o s√£o significativas s√£o pintadas de cinza.Agora, o</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Toshiba AI trabalha com fala em ingl√™s, japon√™s e chin√™s, e at√© mesmo a tradu√ß√£o entre idiomas em tempo real √© poss√≠vel. </font><font style="vertical-align: inherit;">N√£o √© necess√°rio us√°-lo para abreviar rapidamente - a IA pode ser adaptada para trabalhar com assistentes de voz, que finalmente aprendem a perceber adequadamente interjei√ß√µes, pausas e gaguejos quando uma pessoa pronuncia um comando. </font><font style="vertical-align: inherit;">Em mar√ßo de 2019, o sistema foi usado com sucesso para adicionar legendas √† transmiss√£o da Conven√ß√£o Nacional da IPSJ no Jap√£o. </font><font style="vertical-align: inherit;">Em um futuro pr√≥ximo - a transforma√ß√£o da Toshiba AI em um servi√ßo p√∫blico e experi√™ncias com a implementa√ß√£o do reconhecimento de voz na produ√ß√£o.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt490720/index.html">Motor! ou O que √© f√≠sica de jogo</a></li>
<li><a href="../pt490722/index.html">F√©rias de g√™nero em TI. Como observar</a></li>
<li><a href="../pt490726/index.html">Autentica√ß√£o em equipamentos de rede por SSH usando chaves p√∫blicas</a></li>
<li><a href="../pt490728/index.html">Semana 10 de seguran√ßa: Confer√™ncia RSA e conscientiza√ß√£o sobre seguran√ßa cibern√©tica</a></li>
<li><a href="../pt490730/index.html">Raiz de confian√ßa Intel x86: perda de confian√ßa</a></li>
<li><a href="../pt490734/index.html">Ovos de P√°scoa nos mapas topogr√°ficos da Su√≠√ßa</a></li>
<li><a href="../pt490736/index.html">9 ferramentas claras para aprender e aprimorar o vocabul√°rio em ingl√™s</a></li>
<li><a href="../pt490738/index.html">Princ√≠pio de substitui√ß√£o de Lisk</a></li>
<li><a href="../pt490740/index.html">Deserte *** *** n√£o √© apenas randomiza√ß√£o</a></li>
<li><a href="../pt490742/index.html">Uma nova era na rob√≥tica come√ßou</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
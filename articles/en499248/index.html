<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùáÔ∏è üë®‚Äçüëß‚Äçüëß üëäüèæ How we recognize personal protective equipment üß• üéÆ üïï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Probably, you have been wondering all your life how to train a neural network to recognize people in helmets and orange vests! No? But we will tell yo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>How we recognize personal protective equipment</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/499248/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Probably, you have been wondering all your life how to train a neural network to recognize people in helmets and orange vests! No? But we will tell you anyway. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Our name is Tatyana Voronova and Elvira Dyaminova. We are engaged in data analysis in the Center 2M company, we work a lot with the most real factories and enterprises. Due to safety violations, they suffer multimillion-dollar losses, employees are injured, so it would be nice to be able to detect such violations systematically and as early as possible. Best of all - automatically. So we have problems associated with recognizing personal protective equipment (PPE) on video and identifying people or equipment in the danger zone.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/2u/-q/gv2u-qjuorn0awf-hlwjbuu3dc4.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For the most part, orders come to us for determining helmets (more precisely, their absence) and workwear. </font><font style="vertical-align: inherit;">We have already gained experience in carrying out such tasks and now we can describe the problems we have encountered and how to solve them.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since under the terms of cooperation we do not have the right to publish footage from customer‚Äôs objects, we will illustrate the article with images from the Internet, on which people in helmets often smile and look great. </font><font style="vertical-align: inherit;">Unfortunately, in the public domain not for all the features of the tasks that we face in reality, you can find good examples. </font><font style="vertical-align: inherit;">In particular, in life people in helmets are less likely to smile, and the problem of bald workers (we will talk about it a little later) on the Internet has not really been revealed! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Image from the Internet (size 1920x1280):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/f9/9q/nb/f99qnblemmbik0caykgir0zfiag.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The recognition of PPE can be reduced to one of two classical problems of computer vision: classification of images and detection of objects. In practice, it turned out that it was better not to use one of these approaches, but to choose the most suitable for each particular case, as well as flexibly combine them. For example, we can first determine where people are in the image, then classify the images cut by silhouette into classes ‚Äúin workwear‚Äù and ‚Äúwithout‚Äù, and detect the presence of a helmet by the second pass. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On pre-cut figures of people, the classification of the presence of helmets and workwear looks like this (view of the original picture): </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The result of the work of the models for the classification of workwear and helmets</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/su/ad/lg/suadlgvrpviurbpxflbg6y3bm8s.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On the same previously selected human figures, the application of the approach this time with detection for helmets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The result of the model for the classification of workwear and a model for detecting helmets:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/jb/8l/qjjb8lebwt3t-6xttueihk2gaqw.jpeg" alt="image"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stage one: human detection</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The quality of definition of small objects (helmets / glasses / gloves) on large frames is so-so. It is much easier for a computer, like a person, to first understand where people are, and only then to figure out what they are wearing. So, it all starts with identifying the people in the frame. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result of the experiments, we found out that the Faster R-CNN neural network with Inception v2 as a feature extraction is well suited for detecting people. TensorFlow already has </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pre-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> trained </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">neural networks</font></a><font style="vertical-align: inherit;"> for detecting objects. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For us, Faster R-CNN Inception v2 (trained on the COCO dataset) is the basic method that we try first when solving such problems. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Initially, we detect people on the frame (and then on the found people we find PPE):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/xp/gy/ukxpgyllgs-olfg9xgbpmzkuwly.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note that we have increased the bounding box ‚Äúwith a person‚Äù along </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the y axis</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/8x/dp/ad8xdpfnx8f1fke9afg9u5q-9xs.jpeg" alt="image"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this photograph, the worker was shot in good light and against a contrasting background (with images found on the Internet, this happens all the time). </font><font style="vertical-align: inherit;">Therefore, the bounding box with the person was well built. </font><font style="vertical-align: inherit;">However, in our practice there are frequent cases (especially in conditions of insufficient visibility) when the detection model cuts off a helmet in a person, after which it is useless to look for it on a cropped image. </font><font style="vertical-align: inherit;">In this regard, along the y axis, we increase the predicted bounding box by 15% before moving on to the second stage.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When detecting people, we encounter small unpleasant problems. Firstly, when two people walk or stand behind each other, often they begin to be detected as one person. Secondly, it happens that a static object enters the field of view of the camera, in which the model can recognize a person, like a hydrant. These problems can be solved in various ways. For example, how we did it: reconcile and accept them, since in general, the model is suitable for us in terms of productivity and quality. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A more fundamental problem is that industrial premises in which there is a ‚Äúdanger zone‚Äù are often huge and, accordingly, the people in the frames are very small. Our basic method based on Faster R-CNN Inception v2 showed poor results in such cases, and in the end we tried</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster R-CNN Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The results were impressive, people were well recognized even in the distance, but the speed was much lower than the base model. </font><font style="vertical-align: inherit;">With sufficient resources and the need for high accuracy, you can use </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster R-CNN Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Second stage: determination of malicious violators</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depending on the task, the following are often used:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Image Classification Model - Inception v3</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Object Detection Model - Faster R-CNN Inception v2</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification of workwear and helmets</font></font></h3> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We tested different neural network architectures to classify images, and eventually settled on Inception v3, deciding to take advantage of the fact that it is designed to work with variable image sizes. We already had a lot of cut out pictures with people, and it was not difficult to calculate the median values ‚Äã‚Äãfor height and width. So we came to the conclusion that for the training of classifiers began to bring images to a size of 150x400.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order to train the network to recognize PPE, first of all, it is necessary to collect a dataset from labeled examples. </font><font style="vertical-align: inherit;">In this process, there are subtleties, the realization of which comes with experience. </font><font style="vertical-align: inherit;">For example, it is better to remove people who are cut above the hips from the dataset. </font><font style="vertical-align: inherit;">This will bring the dataset closer to the real conditions, since most of the time people are seen at full height on video from surveillance cameras. </font><font style="vertical-align: inherit;">Cases of overlapping, of course, also happen, but full silhouettes for the target sample are much more characteristic. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Examples from our workwear dataset:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k8/22/sh/k822shy7m4ddtteqqjp1mfs09b8.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We have not invented anything specific as a metric; we use recall and precision. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Model for classifying the presence / absence of workwear: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Results on a validation sample</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/lw/ql/hu/lwqlhu_7-efmfxzrxug-d64pafq.jpeg" alt="image"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PPE detection</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The classification model works faster than the model for detecting objects, but due to the fact that safety glasses and gloves are small in the image, it is difficult to create a good classifier for such PPE. </font><font style="vertical-align: inherit;">Therefore, we trained the Faster R-CNN neural network on a dataset with six classes:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">glasses / not_glasses</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gloves / not_gloves</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">helmet / not_helmet</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/pw/iy/i_/pwiyi_nep5v7k8wlrz6yxvz8ug4.jpeg" alt="image"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Data collection and markup</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main problems were related to the helmets dataset. It was a fascinating way: we went through bald people, people with helmets in their hands, and even through bald people with helmets in their hands. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since at the very beginning of the journey we didn‚Äôt have many frames from real conditions, we collected the dataset as best we could: filmed ourselves, took images from the Internet or from construction sites. A little later, we began to receive a lot of videos from various enterprises, so we began to enrich the dataset only with frames of real conditions. At some point, the number of tagged images exceeded 5k, and the quality from adding new examples ceased to improve, in this regard, we revised the approach to markup.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We will describe the stages of improving the helmet dataset using the example of images from the Internet, so the angle and quality do not quite match what we had. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition to the above image, cropped above the hips, we removed images in which the helmets are cropped more than half to avoid confusion with caps.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/zh/eu/dlzheusrhwz0grtyrxdxalkkupq.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We also faced the fact that if a person has a helmet in his hands, then often the model did not see any violations: is there a helmet? There is. Therefore, we removed from the training dataset all frames in which a person holds a helmet with his hand, even if the helmet is on his head at that moment. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In general, we tried to remove images with a lit background or in dark rooms, and then we minimized the number of photos taken by us, leaving mostly footage from the production. As a result, we reduced the dataset by half. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, we enriched the dataset with bald people, otherwise they will always be in helmets, even if this is not so, and with blondes with squares, for which, with a certain angle, the detector also determines the helmet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After removing unsuitable images, we proceeded directly to the markup (for detecting objects). It turned out to be not so simple. It turns out that the quality of the final detector largely depends on what exactly the area in the image is marked as a "helmet" or "gloves". Initially, we allocated helmets and goggles without grabbing faces, and gloves with grabbing hands. However, with experience, we gradually improved our approach by looking at errors of the first and second kind, where people hold helmets in their hands, and something round on something long turns out to be a ‚Äúglove‚Äù. Now, when marking helmets and glasses, we try to grab the face to the tip of the nose, and when marking gloves, on the contrary, we limited ourselves to a brush.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/us/re/kausredcadkqks_cn012broh2qq.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result of our manipulations on the dataset, we got the following results. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Model for detecting the presence / absence of PPE using helmets as an example: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Results on a validation sample before the start of ‚Äúglobal work‚Äù on the dataset</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/oo/rx/k-/oorxk-v05lijjyljtrp5lvtbsq4.jpeg" alt="image"></div><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Final results on the validation sample</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/y1/nn/0u/y1nn0uy66v5qmwji-zk2rwotnle.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The completeness of the recognition of helmets slightly subsided, but at the same time, the metrics for detecting violations improved, and this is what we wanted to achieve. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Model for classifying the presence / absence of helmets: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Results on a validation sample before the start of ‚Äúglobal work‚Äù on the dataset</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wi/eu/fp/wieufpwnxltfvgf1kvkvisr3fk4.jpeg" alt="image"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Final results on the validation sample</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ct/d1/etctd1ymh_9jmjvc3lgaz_mw47o.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It should be noted that we do not have a division into goggles and glasses for vision, they go under the same tag ‚Äúglasses‚Äù, and gloves of light shades can be perceived as a bare brush. </font><font style="vertical-align: inherit;">We tried to maximize the color gamut of helmets and work clothes in our datasets, but for reliability we added the simplest and most reliable technique to this: if necessary, to detect gloves, we tell customers that bright colors help increase accuracy. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the moment, we have universal models that we use for the initial show to the customer. </font><font style="vertical-align: inherit;">However, it should be understood that it is impossible to create a universal model for everyone, it is necessary to adapt to each customer, identify and take into account new nuances, enrich datasets or create them anew to meet specific requirements.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kl/-l/9t/kl-l9tfsjdr528i4xgl5flmtqjk.jpeg" alt="image"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonus</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Typically, customers want to process as many cameras as possible, using as few resources as possible. </font><font style="vertical-align: inherit;">Butch, of course, is a good thing, but additional tricks to optimize the process are not prohibited. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For example, my colleagues and I from the Moscow IBM client center had a hypothesis that putting several people cut out together to further detect helmets would increase the number of cameras per server with an unprincipled loss in accuracy. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a basis, we decided to take the size of 1000x600 for the canvas on which people will be "applied". </font><font style="vertical-align: inherit;">Two layout options were initially considered:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fixed width and height (200x600), with this approach, there are 5 people on the frame.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fixed width and height (125x600), 8 people.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This decision was due to the fact that with fixed data, we know exactly the number of people in the photo, which gives us a forecast of the load. </font><font style="vertical-align: inherit;">However, during the development, we considered such an option:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fixed height and proportional width (*** x600), different number of persons.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It was assumed that with increasing sizes and maintaining proportions, the results will be better compared to other layout options. </font><font style="vertical-align: inherit;">The number of persons ranged from 3 to 5 (+/‚Äì). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, we obtained that the option with a fixed width and height (200x600) is the best among those considered. </font><font style="vertical-align: inherit;">Of course, this method is not suitable for detecting glasses and gloves, because the objects are small, but for detecting helmets / lack of helmets, this method showed good results. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For example, in a validation sample:</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/wg/zy/arwgzypgxzuk6ykdrj57p851-co.jpeg" alt="image"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lw/y5/iilwy5ihzrc57ezgdnjp3gs646s.jpeg" alt="image"></div><br>
<i> :   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link">tvoronova</a>),  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link">elviraa</a>)</i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en499238/index.html">Soldering at home: stream recording</a></li>
<li><a href="../en499240/index.html">Through thorns to the stars, or data analysis in the affairs of heaven</a></li>
<li><a href="../en499242/index.html">Researchers transmitted data from a desktop PC through vibrations across a table</a></li>
<li><a href="../en499244/index.html">Synergetic organizations. Part II</a></li>
<li><a href="../en499246/index.html">Investigation of the logistic function as a law of industry development</a></li>
<li><a href="../en499252/index.html">Creating a pseudo-three-dimensional racing game</a></li>
<li><a href="../en499254/index.html">PyConRu 2020 Program Committee Member answers questions about Python: an up-to-date look and a bit of parseltang</a></li>
<li><a href="../en499262/index.html">Final online hackathon for self-employed SMZhack: projects that will hit the people</a></li>
<li><a href="../en499268/index.html">Spatial awareness: what can Hololens glasses do?</a></li>
<li><a href="../en499272/index.html">Soldering components 0201. Nervous, please move away from the screens</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
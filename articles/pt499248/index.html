<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóΩ üôÖüèæ ‚òùüèø Como reconhecemos equipamentos de prote√ß√£o individual üë®üèª‚Äçüîß üë®üèø‚ÄçüöÄ ‚¨áÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Provavelmente, voc√™ sempre se perguntou como treinar uma rede neural para reconhecer pessoas de capacete e colete laranja! N√£o? Mas n√≥s lhe contaremos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Como reconhecemos equipamentos de prote√ß√£o individual</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/499248/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Provavelmente, voc√™ sempre se perguntou como treinar uma rede neural para reconhecer pessoas de capacete e colete laranja! N√£o? Mas n√≥s lhe contaremos assim mesmo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nosso nome √© Tatyana Voronova e Elvira Dyaminova. Estamos envolvidos na an√°lise de dados na empresa Center 2M, trabalhamos muito com as f√°bricas e empresas mais reais. Devido a viola√ß√µes de seguran√ßa, elas sofrem perdas multimilion√°rias, os funcion√°rios ficam feridos, por isso seria bom poder detectar essas viola√ß√µes sistematicamente e o mais cedo poss√≠vel. O melhor de tudo - automaticamente. Portanto, temos problemas associados ao reconhecimento de equipamentos de prote√ß√£o individual (EPI) em v√≠deo e √† identifica√ß√£o de pessoas ou equipamentos na zona de perigo.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/2u/-q/gv2u-qjuorn0awf-hlwjbuu3dc4.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Na maioria das vezes, chegam-nos pedidos para determinar capacetes (mais precisamente, sua aus√™ncia) e roupas de trabalho. </font><font style="vertical-align: inherit;">J√° adquirimos experi√™ncia na execu√ß√£o de tais tarefas e agora podemos descrever os problemas que encontramos e como resolv√™-los.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como, nos termos da coopera√ß√£o, n√£o temos o direito de publicar imagens dos objetos do cliente, ilustraremos o artigo com imagens da Internet, nas quais as pessoas de capacete geralmente sorriem e ficam √≥timas. </font><font style="vertical-align: inherit;">Infelizmente, no dom√≠nio p√∫blico, n√£o para todos os recursos das tarefas que enfrentamos na realidade, voc√™ pode encontrar bons exemplos. </font><font style="vertical-align: inherit;">Em particular, na vida as pessoas de capacete t√™m menos probabilidade de sorrir, e o problema dos trabalhadores carecas (falaremos sobre isso um pouco mais tarde) na Internet ainda n√£o foi revelado! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imagem da Internet (tamanho 1920x1280):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/f9/9q/nb/f99qnblemmbik0caykgir0zfiag.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O reconhecimento de EPI pode ser reduzido a um dos dois problemas cl√°ssicos da vis√£o computacional: classifica√ß√£o de imagens e detec√ß√£o de objetos. Na pr√°tica, descobriu-se que era melhor n√£o usar uma dessas abordagens, mas escolher a mais adequada para cada caso espec√≠fico, al√©m de combin√°-las de maneira flex√≠vel. Por exemplo, podemos primeiro determinar onde as pessoas est√£o na imagem, depois classificar as imagens cortadas por silhueta nas classes "em roupas de trabalho" e "sem" e detectar a presen√ßa de um capacete pela segunda passagem. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nas figuras pr√©-cortadas de pessoas, a classifica√ß√£o da presen√ßa de capacetes e macac√µes se parece com esta (vista da figura original): </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O resultado do trabalho dos modelos para a classifica√ß√£o de macac√µes e capacetes</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/su/ad/lg/suadlgvrpviurbpxflbg6y3bm8s.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nas mesmas figuras humanas previamente selecionadas, a aplica√ß√£o da abordagem desta vez com detec√ß√£o de capacetes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O resultado do modelo para a classifica√ß√£o de vestu√°rio de trabalho e um modelo para detectar capacetes:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/jb/8l/qjjb8lebwt3t-6xttueihk2gaqw.jpeg" alt="imagem"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Etapa um: detec√ß√£o humana</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A qualidade da defini√ß√£o de objetos pequenos (capacetes / √≥culos / luvas) em arma√ß√µes grandes √© mais ou menos. √â muito mais f√°cil para um computador, como uma pessoa, primeiro entender onde as pessoas est√£o e s√≥ ent√£o descobrir o que est√° vestindo. Ent√£o, tudo come√ßa com a identifica√ß√£o das pessoas no quadro. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado das experi√™ncias, descobrimos que a rede neural Faster R-CNN com o Inception v2 como uma extra√ß√£o de recursos √© adequada para detectar pessoas. O TensorFlow j√° possui </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">redes neurais pr√©-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> treinadas </font><font style="vertical-align: inherit;">para detectar objetos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para n√≥s, o Faster R-CNN Inception v2 (treinado no conjunto de dados COCO) √© o m√©todo b√°sico que tentamos primeiro ao resolver esses problemas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inicialmente, detectamos pessoas no quadro (e depois nas pessoas encontradas encontramos EPI):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/xp/gy/ukxpgyllgs-olfg9xgbpmzkuwly.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Observe que aumentamos a caixa delimitadora "com uma pessoa" ao longo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">do eixo y</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/8x/dp/ad8xdpfnx8f1fke9afg9u5q-9xs.jpeg" alt="imagem"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nesta fotografia, o trabalhador foi baleado com boa luz e em um fundo contrastante (com imagens encontradas na Internet, isso acontece o tempo todo). </font><font style="vertical-align: inherit;">Portanto, a caixa delimitadora com a pessoa foi bem constru√≠da. </font><font style="vertical-align: inherit;">No entanto, em nossa pr√°tica, existem casos frequentes (especialmente em condi√ß√µes de visibilidade insuficiente) quando o modelo de detec√ß√£o corta um capacete em uma pessoa, ap√≥s o que √© in√∫til procur√°-lo em uma imagem cortada. </font><font style="vertical-align: inherit;">Nesse sentido, ao longo do eixo y, aumentamos a caixa delimitadora prevista em 15% antes de passar para o segundo est√°gio.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ao detectar pessoas, encontramos pequenos problemas desagrad√°veis. Em primeiro lugar, quando duas pessoas andam ou ficam atr√°s uma da outra, geralmente come√ßam a ser detectadas como uma pessoa. Em segundo lugar, acontece que um objeto est√°tico entra no campo de vis√£o da c√¢mera, no qual o modelo pode reconhecer uma pessoa, como um hidrante. Esses problemas podem ser resolvidos de v√°rias maneiras. Por exemplo, como fizemos: reconcilie-os e aceite-os, pois, em geral, o modelo √© adequado para n√≥s em termos de produtividade e qualidade. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um problema mais fundamental √© que as instala√ß√µes industriais nas quais existe uma ‚Äúzona de perigo‚Äù costumam ser enormes e, consequentemente, as pessoas nos quadros s√£o muito pequenas. Nosso m√©todo b√°sico baseado no Faster R-CNN Inception v2 mostrou resultados ruins nesses casos e, no final, tentamos</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nas R-CNN mais r√°pidas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Os resultados foram impressionantes, as pessoas foram bem reconhecidas mesmo √† dist√¢ncia, mas a velocidade foi muito menor que o modelo b√°sico. </font><font style="vertical-align: inherit;">Com recursos suficientes e a necessidade de alta precis√£o, voc√™ pode usar o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster R-CNN Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Segunda etapa: determina√ß√£o de violadores maliciosos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dependendo da tarefa, o seguinte √© frequentemente usado:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelo de Classifica√ß√£o de Imagem - Inicia√ß√£o v3</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelo de Detec√ß√£o de Objetos - Inicia√ß√£o R-CNN mais r√°pida v2</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classifica√ß√£o de vestu√°rio de trabalho e capacetes</font></font></h3> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Testamos diferentes arquiteturas de rede neural para classificar imagens e, finalmente, decidimos pelo Inception v3, decidindo aproveitar o fato de que ele foi projetado para funcionar com tamanhos de imagem vari√°veis. J√° t√≠nhamos muitas fotos recortadas com as pessoas e n√£o era dif√≠cil calcular os valores medianos para altura e largura. Ent√£o chegamos √† conclus√£o de que, para o treinamento dos classificadores, come√ßamos a trazer imagens para um tamanho de 150x400.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para treinar a rede para reconhecer o EPI, primeiro √© necess√°rio coletar um conjunto de dados a partir de exemplos rotulados. </font><font style="vertical-align: inherit;">Nesse processo, existem sutilezas, cuja realiza√ß√£o vem com a experi√™ncia. </font><font style="vertical-align: inherit;">Por exemplo, √© melhor remover as pessoas cortadas acima dos quadris do conjunto de dados. </font><font style="vertical-align: inherit;">Isso aproximar√° o conjunto de dados das condi√ß√µes reais, pois na maioria das vezes as pessoas s√£o vistas em altura total em v√≠deo das c√¢meras de vigil√¢ncia. </font><font style="vertical-align: inherit;">Casos de sobreposi√ß√£o, √© claro, tamb√©m acontecem, mas silhuetas completas para a amostra-alvo s√£o muito mais caracter√≠sticas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exemplos do nosso conjunto de dados de vestu√°rio de trabalho:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k8/22/sh/k822shy7m4ddtteqqjp1mfs09b8.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
N√£o inventamos nada espec√≠fico como m√©trica; usamos recall e precis√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelo para classificar a presen√ßa / aus√™ncia de roupas de trabalho: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultados em uma amostra de valida√ß√£o</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/lw/ql/hu/lwqlhu_7-efmfxzrxug-d64pafq.jpeg" alt="imagem"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Detec√ß√£o de EPI</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O modelo de classifica√ß√£o funciona mais r√°pido que o modelo para detectar objetos, mas devido ao fato de os √≥culos e luvas de seguran√ßa serem pequenos na imagem, √© dif√≠cil criar um bom classificador para esses EPIs. </font><font style="vertical-align: inherit;">Portanto, treinamos a rede neural Faster R-CNN em um conjunto de dados com seis classes:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">glasses / not_glasses</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">luvas / n√£o_ luvas</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">capacete / not_helmet</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/pw/iy/i_/pwiyi_nep5v7k8wlrz6yxvz8ug4.jpeg" alt="imagem"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Coleta e marca√ß√£o de dados</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os principais problemas estavam relacionados ao conjunto de dados dos capacetes. Era uma maneira fascinante: passamos por pessoas carecas, com capacetes nas m√£os e at√© mesmo por pessoas carecas com capacetes nas m√£os. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como no come√ßo da jornada n√£o t√≠nhamos muitos quadros de condi√ß√µes reais, coletamos o conjunto de dados da melhor maneira poss√≠vel: filmamos, tiramos fotos da Internet ou de locais de constru√ß√£o. Um pouco mais tarde, come√ßamos a receber muitos v√≠deos de v√°rias empresas e come√ßamos a enriquecer o conjunto de dados apenas com quadros de condi√ß√µes reais. Em algum momento, o n√∫mero de imagens marcadas excedeu 5k e a qualidade da adi√ß√£o de novos exemplos deixou de melhorar. Nesse sentido, revisamos a abordagem da marca√ß√£o.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos descrever os est√°gios de melhoria do conjunto de dados do capacete usando o exemplo de imagens da Internet, para que o √¢ngulo e a qualidade n√£o correspondam exatamente ao que t√≠nhamos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m da imagem acima, cortada acima dos quadris, removemos imagens nas quais os capacetes s√£o cortados mais da metade para evitar confus√£o com as tampas.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/zh/eu/dlzheusrhwz0grtyrxdxalkkupq.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tamb√©m enfrentamos o fato de que, se uma pessoa tem um capacete nas m√£os, muitas vezes o modelo n√£o v√™ viola√ß√µes: existe um capacete? H√° sim. Portanto, removemos do conjunto de dados de treinamento todos os quadros em que uma pessoa segura um capacete com a m√£o, mesmo que o capacete esteja em sua cabe√ßa naquele momento. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em geral, tentamos remover imagens com um fundo iluminado ou em salas escuras e minimizamos o n√∫mero de fotos tiradas por n√≥s, deixando principalmente imagens da produ√ß√£o. Como resultado, reduzimos o conjunto de dados pela metade. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m disso, enriquecemos o conjunto de dados com pessoas carecas, caso contr√°rio, elas sempre estar√£o em capacetes, mesmo que n√£o seja assim, e com loiras com quadrados, para as quais, com um determinado √¢ngulo, o detector tamb√©m determina o capacete.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ap√≥s remover imagens inadequadas, prosseguimos diretamente para a marca√ß√£o (para detec√ß√£o de objetos). Acabou n√£o sendo t√£o simples. Acontece que a qualidade do detector final depende em grande parte do que exatamente a √°rea da imagem √© marcada como "capacete" ou "luvas". Inicialmente, alocamos capacetes e √≥culos de prote√ß√£o sem agarrar rostos e luvas com as m√£os seguras. No entanto, com a experi√™ncia, aprimoramos gradualmente nossa abordagem, observando erros do primeiro e do segundo tipo, onde as pessoas seguram capacetes nas m√£os e algo em torno de algo longo acaba sendo uma "luva". Agora, ao marcar capacetes e √≥culos, tentamos agarrar o rosto at√© a ponta do nariz e, ao contr√°rio, ao marcar luvas, nos limitamos a um pincel.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/us/re/kausredcadkqks_cn012broh2qq.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado de nossas manipula√ß√µes no conjunto de dados, obtivemos os seguintes resultados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelo para detectar a presen√ßa / aus√™ncia de EPI usando capacetes como exemplo: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados em uma amostra de valida√ß√£o antes do in√≠cio do "trabalho global" no conjunto de dados</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/oo/rx/k-/oorxk-v05lijjyljtrp5lvtbsq4.jpeg" alt="imagem"></div><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados finais na amostra de valida√ß√£o</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/y1/nn/0u/y1nn0uy66v5qmwji-zk2rwotnle.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A completude do reconhecimento de capacetes diminuiu um pouco, mas ao mesmo tempo, as m√©tricas para detectar viola√ß√µes melhoraram, e √© isso que quer√≠amos alcan√ßar. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelo para classificar a presen√ßa / aus√™ncia de capacetes: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados em uma amostra de valida√ß√£o antes do in√≠cio do "trabalho global" no conjunto de dados</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wi/eu/fp/wieufpwnxltfvgf1kvkvisr3fk4.jpeg" alt="imagem"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados finais na amostra de valida√ß√£o</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ct/d1/etctd1ymh_9jmjvc3lgaz_mw47o.jpeg" alt="imagem"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deve-se notar que n√£o temos uma divis√£o em √≥culos e √≥culos para vis√£o, eles ficam sob a mesma etiqueta ‚Äú√≥culos‚Äù e luvas de tons claros podem ser percebidas como uma escova nua. </font><font style="vertical-align: inherit;">Tentamos maximizar a gama de cores de capacetes e roupas de trabalho em nossos conjuntos de dados, mas, para garantir a confiabilidade, adicionamos a t√©cnica mais simples e mais confi√°vel: se necess√°rio, para detectar luvas, informamos aos clientes que cores brilhantes ajudam a aumentar a precis√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No momento, temos modelos universais que usamos para o show inicial para o cliente. </font><font style="vertical-align: inherit;">No entanto, deve-se entender que √© imposs√≠vel criar um modelo universal para todos, √© necess√°rio adaptar-se a cada cliente, identificar e levar em conta novas nuances, enriquecer conjuntos de dados ou cri√°-los novamente para atender a requisitos espec√≠ficos.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kl/-l/9t/kl-l9tfsjdr528i4xgl5flmtqjk.jpeg" alt="imagem"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B√¥nus</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Normalmente, os clientes desejam processar o maior n√∫mero poss√≠vel de c√¢meras, usando o m√≠nimo de recursos poss√≠vel. </font><font style="vertical-align: inherit;">Butch, √© claro, √© uma coisa boa, mas truques adicionais para otimizar o processo n√£o s√£o proibidos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por exemplo, meus colegas e eu do centro de clientes IBM em Moscou t√≠nhamos a hip√≥tese de que reunir v√°rias pessoas cortadas para detectar mais capacetes aumentaria o n√∫mero de c√¢meras por servidor com uma perda sem precis√£o de precis√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como base, decidimos usar o tamanho de 1000x600 para a tela na qual as pessoas ser√£o "aplicadas". </font><font style="vertical-align: inherit;">Duas op√ß√µes de layout foram inicialmente consideradas:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Largura e altura fixas (200x600), com essa abordagem, h√° 5 pessoas no quadro.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Largura e altura fixas (125x600), 8 pessoas.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essa decis√£o se deve ao fato de que, com dados fixos, sabemos exatamente o n√∫mero de pessoas na foto, o que nos fornece uma previs√£o da carga. </font><font style="vertical-align: inherit;">No entanto, durante o desenvolvimento, consideramos essa op√ß√£o:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Altura fixa e largura proporcional (*** x600), n√∫mero diferente de pessoas.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Supunha-se que, com tamanhos crescentes e manuten√ß√£o de propor√ß√µes, os resultados ser√£o melhores em compara√ß√£o com outras op√ß√µes de layout. </font><font style="vertical-align: inherit;">O n√∫mero de pessoas variou de 3 a 5 (+/‚Äì). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, obtivemos que a op√ß√£o com largura e altura fixas (200x600) √© a melhor dentre as consideradas. </font><font style="vertical-align: inherit;">Obviamente, este m√©todo n√£o √© adequado para detectar √≥culos e luvas, porque os objetos s√£o pequenos, mas para detectar capacetes / falta de capacetes, esse m√©todo mostrou bons resultados. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por exemplo, em uma amostra de valida√ß√£o:</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/wg/zy/arwgzypgxzuk6ykdrj57p851-co.jpeg" alt="imagem"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lw/y5/iilwy5ihzrc57ezgdnjp3gs646s.jpeg" alt="imagem"></div><br>
<i> :   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">tvoronova</a>),  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">elviraa</a>)</i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt499238/index.html">Solda em casa: grava√ß√£o em fluxo</a></li>
<li><a href="../pt499240/index.html">Atrav√©s de espinhos para as estrelas, ou an√°lise de dados nos assuntos do c√©u</a></li>
<li><a href="../pt499242/index.html">Pesquisadores transmitiram dados de um PC de mesa atrav√©s de vibra√ß√µes em uma mesa</a></li>
<li><a href="../pt499244/index.html">Organiza√ß√µes sin√©rgicas. parte II</a></li>
<li><a href="../pt499246/index.html">Investiga√ß√£o da fun√ß√£o log√≠stica como lei do desenvolvimento da ind√∫stria</a></li>
<li><a href="../pt499252/index.html">Criando um jogo de corrida pseudo-tridimensional</a></li>
<li><a href="../pt499254/index.html">Membro do Comit√™ de Programa PyConRu 2020 responde a perguntas sobre Python: uma apar√™ncia atualizada e um pouco de parseltang</a></li>
<li><a href="../pt499262/index.html">Hackathon final online para SMZhack aut√¥nomo: projetos que atingir√£o as pessoas</a></li>
<li><a href="../pt499268/index.html">Consci√™ncia espacial: o que os √≥culos Hololens podem fazer?</a></li>
<li><a href="../pt499272/index.html">–ü–∞–π–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ 0201. –°–ª–∞–±–æ–Ω–µ—Ä–≤–Ω—ã—Ö –ø—Ä–æ—Å—å–±–∞ —É–¥–∞–ª–∏—Ç—å—Å—è –æ—Ç —ç–∫—Ä–∞–Ω–æ–≤</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📙 🍵 🎲 Python + OpenCV + Keras：30分でテキスト認識 🤛🏻 👘 🚟</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちはHabr。
 
 よく知られている60,000の手書き数字MNISTを実験した後、類似した何かがあるかどうか、しかし数字だけでなく文字もサポートしているかどうかという論理的な疑問が生じました。結局のところ、ご存知のように、Extended MNIST（EMNIST）が存在し、そのようなベー...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Python + OpenCV + Keras：30分でテキスト認識</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466565/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちはHabr。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
よく知られている60,000の手書き数字MNISTを実験した後、類似した何かがあるかどうか、しかし数字だけでなく文字もサポートしているかどうかという論理的な疑問が生じました。結局のところ、ご存知のように、Extended MNIST（EMNIST）が存在し、そのようなベースと呼ばれています。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
誰かがこのデータベースの使い方に興味があれば、簡単なテキスト認識を行うことができます。猫へようこそ。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kq/bl/4r/kqbl4rtgmtvz1xl50tzbulmdmlw.png"><br>
<a name="habracut"></a><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：この例は実験的で教育的なものであり、私はそれが何をもたらすかを知りたいと思っていました。</font><font style="vertical-align: inherit;">私は2番目のFineReaderを計画していなかったし、計画もしていなかったので、ここでは多くのことはもちろん実装されていません。</font><font style="vertical-align: inherit;">そのため、「なぜ」「すでに良い」などの主張は認められません。</font><font style="vertical-align: inherit;">おそらくすでにPython用の既製のOCRライブラリがあるはずですが、自分で作成するのは興味深いことでした。</font><font style="vertical-align: inherit;">ちなみに、実際のFineReaderがどのように作成されたかを確認したい人のために、2014年のHabrに関するブログには、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2の2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">つの記事があります</font><font style="vertical-align: inherit;">（もちろん、企業のブログのように、ソースコードと詳細はありません）。</font><font style="vertical-align: inherit;">さて、始めましょう。ここではすべてがオープンで、すべてがオープンソースです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
例として、プレーンテキストを取り上げます。</font><font style="vertical-align: inherit;">ここに1つあります：</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは世界</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それで何ができるか見てみましょう。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">テキストを文字に分割する</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初のステップは、テキストを別々の文字に分割することです。 OpenCVはこのために役立ちます。より正確には、findContours関数です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像（cv2.imread）を開き、b / w（cv2.cvtColor + cv2.threshold）に変換し、少し増やし（cv2.erode）、輪郭を見つけます。</font></font><br>
<br>
<pre><code class="python hljs">image_file = <span class="hljs-string">"text.png"</span><font></font>
img = cv2.imread(image_file)<font></font>
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<font></font>
ret, thresh = cv2.threshold(gray, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<font></font>
img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), np.uint8), iterations=<span class="hljs-number">1</span>)<font></font>
<font></font>
<span class="hljs-comment"># Get contours</span><font></font>
contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)<font></font>
<font></font>
output = img.copy()<font></font>
<font></font>
<span class="hljs-keyword">for</span> idx, contour <span class="hljs-keyword">in</span> enumerate(contours):<font></font>
    (x, y, w, h) = cv2.boundingRect(contour)<font></font>
    <span class="hljs-comment"># print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])</span>
    <span class="hljs-comment"># hierarchy[i][0]: the index of the next contour of the same level</span>
    <span class="hljs-comment"># hierarchy[i][1]: the index of the previous contour of the same level</span>
    <span class="hljs-comment"># hierarchy[i][2]: the index of the first child</span>
    <span class="hljs-comment"># hierarchy[i][3]: the index of the parent</span>
    <span class="hljs-keyword">if</span> hierarchy[<span class="hljs-number">0</span>][idx][<span class="hljs-number">3</span>] == <span class="hljs-number">0</span>:<font></font>
        cv2.rectangle(output, (x, y), (x + w, y + h), (<span class="hljs-number">70</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)<font></font>
<font></font>
<font></font>
cv2.imshow(<span class="hljs-string">"Input"</span>, img)<font></font>
cv2.imshow(<span class="hljs-string">"Enlarged"</span>, img_erode)<font></font>
cv2.imshow(<span class="hljs-string">"Output"</span>, output)<font></font>
cv2.waitKey(<span class="hljs-number">0</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
等高線の階層ツリーを取得します（パラメーターcv2.RETR_TREE）。最初に画像の一般的な輪郭、次に文字の輪郭、次に内側の輪郭が表示されます。文字の輪郭だけが必要なので、「輪郭」が全体の輪郭であることを確認します。これは簡略化されたアプローチであり、実際のスキャンでは機能しない可能性がありますが、スクリーンショットを認識することは重要ではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7j/zi/pg/7jzipgqvc9ebvxgu2j7c_ubr-rw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のステップは、以前に28x28の正方形にスケーリングした各文字を保存することです（MNISTベースはこの形式で保存されます）。 OpenCVはnumpyに基づいて構築されているため、クロップとスケーリングのために配列を操作する関数を使用できます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">letters_extract</span>(<span class="hljs-params">image_file: str, out_size=<span class="hljs-number">28</span></span>) -&gt; List[Any]:</span><font></font>
    img = cv2.imread(image_file)<font></font>
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<font></font>
    ret, thresh = cv2.threshold(gray, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<font></font>
    img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), np.uint8), iterations=<span class="hljs-number">1</span>)<font></font>
<font></font>
    <span class="hljs-comment"># Get contours</span><font></font>
    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)<font></font>
<font></font>
    output = img.copy()<font></font>
<font></font>
    letters = []<font></font>
    <span class="hljs-keyword">for</span> idx, contour <span class="hljs-keyword">in</span> enumerate(contours):<font></font>
        (x, y, w, h) = cv2.boundingRect(contour)<font></font>
        <span class="hljs-comment"># print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])</span>
        <span class="hljs-comment"># hierarchy[i][0]: the index of the next contour of the same level</span>
        <span class="hljs-comment"># hierarchy[i][1]: the index of the previous contour of the same level</span>
        <span class="hljs-comment"># hierarchy[i][2]: the index of the first child</span>
        <span class="hljs-comment"># hierarchy[i][3]: the index of the parent</span>
        <span class="hljs-keyword">if</span> hierarchy[<span class="hljs-number">0</span>][idx][<span class="hljs-number">3</span>] == <span class="hljs-number">0</span>:<font></font>
            cv2.rectangle(output, (x, y), (x + w, y + h), (<span class="hljs-number">70</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)<font></font>
            letter_crop = gray[y:y + h, x:x + w]<font></font>
            <span class="hljs-comment"># print(letter_crop.shape)</span><font></font>
<font></font>
            <span class="hljs-comment"># Resize letter canvas to square</span><font></font>
            size_max = max(w, h)<font></font>
            letter_square = <span class="hljs-number">255</span> * np.ones(shape=[size_max, size_max], dtype=np.uint8)
            <span class="hljs-keyword">if</span> w &gt; h:
                <span class="hljs-comment"># Enlarge image top-bottom</span>
                <span class="hljs-comment"># ------</span>
                <span class="hljs-comment"># ======</span>
                <span class="hljs-comment"># ------</span>
                y_pos = size_max//<span class="hljs-number">2</span> - h//<span class="hljs-number">2</span>
                letter_square[y_pos:y_pos + h, <span class="hljs-number">0</span>:w] = letter_crop
            <span class="hljs-keyword">elif</span> w &lt; h:
                <span class="hljs-comment"># Enlarge image left-right</span>
                <span class="hljs-comment"># --||--</span>
                x_pos = size_max//<span class="hljs-number">2</span> - w//<span class="hljs-number">2</span>
                letter_square[<span class="hljs-number">0</span>:h, x_pos:x_pos + w] = letter_crop
            <span class="hljs-keyword">else</span>:<font></font>
                letter_square = letter_crop<font></font>
<font></font>
            <span class="hljs-comment"># Resize letter to 28x28 and add letter and its X-coordinate</span><font></font>
            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))<font></font>
<font></font>
    <span class="hljs-comment"># Sort array in place by X-coordinate</span>
    letters.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>], reverse=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> letters
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後に、X座標で文字を並べ替えます。ご覧のとおり、結果をタプル（x、w、文字）の形式で保存し、文字間のスペースからスペースを選択できるようにします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すべてが機能することを確認します。</font></font><br>
<br>
<pre><code class="python hljs">cv2.imshow(<span class="hljs-string">"0"</span>, letters[<span class="hljs-number">0</span>][<span class="hljs-number">2</span>])<font></font>
cv2.imshow(<span class="hljs-string">"1"</span>, letters[<span class="hljs-number">1</span>][<span class="hljs-number">2</span>])<font></font>
cv2.imshow(<span class="hljs-string">"2"</span>, letters[<span class="hljs-number">2</span>][<span class="hljs-number">2</span>])<font></font>
cv2.imshow(<span class="hljs-string">"3"</span>, letters[<span class="hljs-number">3</span>][<span class="hljs-number">2</span>])<font></font>
cv2.imshow(<span class="hljs-string">"4"</span>, letters[<span class="hljs-number">4</span>][<span class="hljs-number">2</span>])<font></font>
cv2.waitKey(<span class="hljs-number">0</span>)</code></pre><br>
<img src="https://habrastorage.org/webt/j-/uw/yh/j-uwyhhh8l0yrapth5u6fy9na0u.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
文字は認識の準備ができています。畳み込みネットワークを使用して文字を認識します。このタイプのネットワークは、このようなタスクに適しています。 </font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">認識のためのニューラルネットワーク（CNN）</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
元のEMNISTデータセットには62種類の文字（A..Z、0..9など）があります。</font></font><br>
<br>
<pre><code class="python hljs">emnist_labels = [<span class="hljs-number">48</span>, <span class="hljs-number">49</span>, <span class="hljs-number">50</span>, <span class="hljs-number">51</span>, <span class="hljs-number">52</span>, <span class="hljs-number">53</span>, <span class="hljs-number">54</span>, <span class="hljs-number">55</span>, <span class="hljs-number">56</span>, <span class="hljs-number">57</span>, <span class="hljs-number">65</span>, <span class="hljs-number">66</span>, <span class="hljs-number">67</span>, <span class="hljs-number">68</span>, <span class="hljs-number">69</span>, <span class="hljs-number">70</span>, <span class="hljs-number">71</span>, <span class="hljs-number">72</span>, <span class="hljs-number">73</span>, <span class="hljs-number">74</span>, <span class="hljs-number">75</span>, <span class="hljs-number">76</span>, <span class="hljs-number">77</span>, <span class="hljs-number">78</span>, <span class="hljs-number">79</span>, <span class="hljs-number">80</span>, <span class="hljs-number">81</span>, <span class="hljs-number">82</span>, <span class="hljs-number">83</span>, <span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">86</span>, <span class="hljs-number">87</span>, <span class="hljs-number">88</span>, <span class="hljs-number">89</span>, <span class="hljs-number">90</span>, <span class="hljs-number">97</span>, <span class="hljs-number">98</span>, <span class="hljs-number">99</span>, <span class="hljs-number">100</span>, <span class="hljs-number">101</span>, <span class="hljs-number">102</span>, <span class="hljs-number">103</span>, <span class="hljs-number">104</span>, <span class="hljs-number">105</span>, <span class="hljs-number">106</span>, <span class="hljs-number">107</span>, <span class="hljs-number">108</span>, <span class="hljs-number">109</span>, <span class="hljs-number">110</span>, <span class="hljs-number">111</span>, <span class="hljs-number">112</span>, <span class="hljs-number">113</span>, <span class="hljs-number">114</span>, <span class="hljs-number">115</span>, <span class="hljs-number">116</span>, <span class="hljs-number">117</span>, <span class="hljs-number">118</span>, <span class="hljs-number">119</span>, <span class="hljs-number">120</span>, <span class="hljs-number">121</span>, <span class="hljs-number">122</span>]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、ニューラルネットワークは62の出力を持ち、認識「1」がネットワークの対応する出力になると、入力で28x28の画像を受け取ります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ネットワークモデルを作成します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> optimizers
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization
<span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> SGD, RMSprop, Adam
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> backend <span class="hljs-keyword">as</span> K
<span class="hljs-keyword">from</span> keras.constraints <span class="hljs-keyword">import</span> maxnorm
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_model</span>():</span><font></font>
    model = Sequential()<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">'valid'</span>, input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>), activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<font></font>
    model.add(Dropout(<span class="hljs-number">0.25</span>))<font></font>
    model.add(Flatten())<font></font>
    model.add(Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Dropout(<span class="hljs-number">0.5</span>))<font></font>
    model.add(Dense(len(emnist_labels), activation=<span class="hljs-string">'softmax'</span>))<font></font>
    model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=<span class="hljs-string">'adadelta'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-keyword">return</span> model</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ご覧のとおり、これは画像の特定の機能（フィルター32と64の数）を強調する古典的な畳み込みネットワークであり、その「出力」に「線形」MLPネットワークが接続されており、最終的な結果を形成しています。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワークのトレーニング</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最長の段階、ネットワークトレーニングに進みます。</font><font style="vertical-align: inherit;">これを行うに</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、リンクから</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ダウンロードできるEMNISTデータベース</font><font style="vertical-align: inherit;">（アーカイブサイズ536Mb）を使用します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データベースを読み取るには、idx2numpyライブラリを使用します。</font><font style="vertical-align: inherit;">トレーニングと検証のためのデータを準備します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> idx2numpy<font></font>
<font></font>
emnist_path = <span class="hljs-string">'/home/Documents/TestApps/keras/emnist/'</span>
X_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-train-images-idx3-ubyte'</span>)<font></font>
y_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-train-labels-idx1-ubyte'</span>)<font></font>
<font></font>
X_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-test-images-idx3-ubyte'</span>)<font></font>
y_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-test-labels-idx1-ubyte'</span>)<font></font>
<font></font>
X_train = np.reshape(X_train, (X_train.shape[<span class="hljs-number">0</span>], <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<font></font>
X_test = np.reshape(X_test, (X_test.shape[<span class="hljs-number">0</span>], <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<font></font>
<font></font>
print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels))<font></font>
<font></font>
k = <span class="hljs-number">10</span>
X_train = X_train[:X_train.shape[<span class="hljs-number">0</span>] // k]<font></font>
y_train = y_train[:y_train.shape[<span class="hljs-number">0</span>] // k]<font></font>
X_test = X_test[:X_test.shape[<span class="hljs-number">0</span>] // k]<font></font>
y_test = y_test[:y_test.shape[<span class="hljs-number">0</span>] // k]<font></font>
<font></font>
<span class="hljs-comment"># Normalize</span><font></font>
X_train = X_train.astype(np.float32)<font></font>
X_train /= <span class="hljs-number">255.0</span><font></font>
X_test = X_test.astype(np.float32)<font></font>
X_test /= <span class="hljs-number">255.0</span><font></font>
<font></font>
x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))<font></font>
y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニングと検証用に2セット用意しました。</font><font style="vertical-align: inherit;">文字自体は表示が簡単な通常の配列</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lb/uj/yt/lbujytoizk2gxviahqxz5emvgay.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
です。トレーニングにはデータセットの1/10（パラメーターk）のみを使用</font><font style="vertical-align: inherit;">します。</font><font style="vertical-align: inherit;">それ以外の場合、プロセスには少なくとも10時間かかります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ネットワークトレーニングを開始し、プロセスの最後にトレーニング済みモデルをディスクに保存します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># Set a learning rate reduction</span>
learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor=<span class="hljs-string">'val_acc'</span>, patience=<span class="hljs-number">3</span>, verbose=<span class="hljs-number">1</span>, factor=<span class="hljs-number">0.5</span>, min_lr=<span class="hljs-number">0.00001</span>)<font></font>
<font></font>
<span class="hljs-comment"># Required for learning_rate_reduction:</span><font></font>
keras.backend.get_session().run(tf.global_variables_initializer())<font></font>
<font></font>
model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=<span class="hljs-number">64</span>, epochs=<span class="hljs-number">30</span>)<font></font>
<font></font>
model.save(<span class="hljs-string">'emnist_letters.h5'</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
学習プロセス自体は約30分かかります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vu/xv/_s/vuxv_s6hsxg1q0gxcqapd0o3bv8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは一度だけ行う必要があります。その後、すでに保存されているモデルファイルを使用します。</font><font style="vertical-align: inherit;">トレーニングが完了すると、すべての準備が整い、テキストを認識できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">認識</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
認識のために、モデルをロードし、predict_classes関数を呼び出します。</font></font><br>
<br>
<pre><code class="python hljs">model = keras.models.load_model(<span class="hljs-string">'emnist_letters.h5'</span>)<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_predict_img</span>(<span class="hljs-params">model, img</span>):</span>
    img_arr = np.expand_dims(img, axis=<span class="hljs-number">0</span>)<font></font>
    img_arr = <span class="hljs-number">1</span> - img_arr/<span class="hljs-number">255.0</span>
    img_arr[<span class="hljs-number">0</span>] = np.rot90(img_arr[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>)<font></font>
    img_arr[<span class="hljs-number">0</span>] = np.fliplr(img_arr[<span class="hljs-number">0</span>])<font></font>
    img_arr = img_arr.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<font></font>
<font></font>
    result = model.predict_classes([img_arr])<font></font>
    <span class="hljs-keyword">return</span> chr(emnist_labels[result[<span class="hljs-number">0</span>]])</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結局のところ、データセット内の画像は最初に回転されていたため、認識前に画像を回転させる必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
入力で画像を含むファイルを受け取り、出力で1行を与える最後の関数は、わずか10行のコードを使用します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img_to_str</span>(<span class="hljs-params">model: Any, image_file: str</span>):</span><font></font>
    letters = letters_extract(image_file)<font></font>
    s_out = <span class="hljs-string">""</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(letters)):<font></font>
        dn = letters[i+<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] - letters[i][<span class="hljs-number">0</span>] - letters[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">if</span> i &lt; len(letters) - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        s_out += emnist_predict_img(model, letters[i][<span class="hljs-number">2</span>])
        <span class="hljs-keyword">if</span> (dn &gt; letters[i][<span class="hljs-number">1</span>]/<span class="hljs-number">4</span>):<font></font>
            s_out += <span class="hljs-string">' '</span>
    <span class="hljs-keyword">return</span> s_out</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここでは、以前に保存した文字幅を使用して、文字間の間隔が文字の1/4より大きい場合にスペースを追加します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
使用例：</font></font><br>
<pre><code class="python hljs">model = keras.models.load_model(<span class="hljs-string">'emnist_letters.h5'</span>)<font></font>
s_out = img_to_str(model, <span class="hljs-string">"hello_world.png"</span>)<font></font>
print(s_out)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果：</font></font><br>
<img src="https://habrastorage.org/webt/ck/r5/iq/ckr5iqlfoiokza60cleu3w1x-hg.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
面白い機能-ニューラルネットワークは文字「O」と数字「0」を「混同」しましたが、これは驚くことではありません。</font><font style="vertical-align: inherit;">EMNISTのオリジナルセットには、</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">手書きの</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文字と数字が</font><font style="vertical-align: inherit;">含まれ</font><font style="vertical-align: inherit;">ていますが、これらは印刷されたものと</font><font style="vertical-align: inherit;">は完全には異なり</font><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">理想的には、画面のテキストを認識するには、画面のフォントに基づいて別のセットを準備し、その上でニューラルネットワークをトレーニングする必要があります。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ご覧のとおり、ポットを燃やすのは神ではなく、かつての図書館の助けを借りて「魔法」のように思われていたものは非常にシンプルになっています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pythonはクロスプラットフォームなので、コードはWindows、Linux、OSXのどこでも機能します。</font><font style="vertical-align: inherit;">KerasはiOS / Androidに移植されているようです。理論的には、トレーニング済みモデルは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モバイルデバイス</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で使用でき</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自分で実験したい人のために、ソースコードはネタバレの下にあります。</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">keras_emnist.py</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"># Code source: dmitryelj@gmail.com</span><font></font>
<font></font>
<span class="hljs-keyword">import</span> os
<span class="hljs-comment"># Force CPU</span>
<span class="hljs-comment"># os.environ["CUDA_VISIBLE_DEVICES"] = "-1"</span>
<span class="hljs-comment"># Debug messages</span>
<span class="hljs-comment"># 0 = all messages are logged (default behavior)</span>
<span class="hljs-comment"># 1 = INFO messages are not printed</span>
<span class="hljs-comment"># 2 = INFO and WARNING messages are not printed</span>
<span class="hljs-comment"># 3 = INFO, WARNING, and ERROR messages are not printed</span>
os.environ[<span class="hljs-string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="hljs-string">'3'</span><font></font>
<font></font>
<font></font>
<span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> imghdr
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pathlib
<span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> optimizers
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization
<span class="hljs-keyword">from</span> keras.optimizers <span class="hljs-keyword">import</span> SGD, RMSprop, Adam
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> backend <span class="hljs-keyword">as</span> K
<span class="hljs-keyword">from</span> keras.constraints <span class="hljs-keyword">import</span> maxnorm
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> io <span class="hljs-keyword">as</span> spio
<span class="hljs-keyword">import</span> idx2numpy  <span class="hljs-comment"># sudo pip3 install idx2numpy</span>
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">import</span> time<font></font>
<font></font>
<font></font>
<span class="hljs-comment"># Dataset:</span>
<span class="hljs-comment"># https://www.nist.gov/node/1298471/emnist-dataset</span>
<span class="hljs-comment"># https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip</span><font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cnn_print_digit</span>(<span class="hljs-params">d</span>):</span><font></font>
    print(d.shape)<font></font>
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">28</span>):<font></font>
        s = <span class="hljs-string">""</span>
        <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(<span class="hljs-number">28</span>):<font></font>
            s += <span class="hljs-string">"{0:.1f} "</span>.format(d[<span class="hljs-number">28</span>*y + x])<font></font>
        print(s)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cnn_print_digit_2d</span>(<span class="hljs-params">d</span>):</span><font></font>
    print(d.shape)<font></font>
    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(d.shape[<span class="hljs-number">0</span>]):<font></font>
        s = <span class="hljs-string">""</span>
        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(d.shape[<span class="hljs-number">1</span>]):<font></font>
            s += <span class="hljs-string">"{0:.1f} "</span>.format(d[x][y])<font></font>
        print(s)<font></font>
<font></font>
<font></font>
emnist_labels = [<span class="hljs-number">48</span>, <span class="hljs-number">49</span>, <span class="hljs-number">50</span>, <span class="hljs-number">51</span>, <span class="hljs-number">52</span>, <span class="hljs-number">53</span>, <span class="hljs-number">54</span>, <span class="hljs-number">55</span>, <span class="hljs-number">56</span>, <span class="hljs-number">57</span>, <span class="hljs-number">65</span>, <span class="hljs-number">66</span>, <span class="hljs-number">67</span>, <span class="hljs-number">68</span>, <span class="hljs-number">69</span>, <span class="hljs-number">70</span>, <span class="hljs-number">71</span>, <span class="hljs-number">72</span>, <span class="hljs-number">73</span>, <span class="hljs-number">74</span>, <span class="hljs-number">75</span>, <span class="hljs-number">76</span>, <span class="hljs-number">77</span>, <span class="hljs-number">78</span>, <span class="hljs-number">79</span>, <span class="hljs-number">80</span>, <span class="hljs-number">81</span>, <span class="hljs-number">82</span>, <span class="hljs-number">83</span>, <span class="hljs-number">84</span>, <span class="hljs-number">85</span>, <span class="hljs-number">86</span>, <span class="hljs-number">87</span>, <span class="hljs-number">88</span>, <span class="hljs-number">89</span>, <span class="hljs-number">90</span>, <span class="hljs-number">97</span>, <span class="hljs-number">98</span>, <span class="hljs-number">99</span>, <span class="hljs-number">100</span>, <span class="hljs-number">101</span>, <span class="hljs-number">102</span>, <span class="hljs-number">103</span>, <span class="hljs-number">104</span>, <span class="hljs-number">105</span>, <span class="hljs-number">106</span>, <span class="hljs-number">107</span>, <span class="hljs-number">108</span>, <span class="hljs-number">109</span>, <span class="hljs-number">110</span>, <span class="hljs-number">111</span>, <span class="hljs-number">112</span>, <span class="hljs-number">113</span>, <span class="hljs-number">114</span>, <span class="hljs-number">115</span>, <span class="hljs-number">116</span>, <span class="hljs-number">117</span>, <span class="hljs-number">118</span>, <span class="hljs-number">119</span>, <span class="hljs-number">120</span>, <span class="hljs-number">121</span>, <span class="hljs-number">122</span>]<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_model</span>():</span><font></font>
    model = Sequential()<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">'valid'</span>, input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>), activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<font></font>
    model.add(Dropout(<span class="hljs-number">0.25</span>))<font></font>
    model.add(Flatten())<font></font>
    model.add(Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Dropout(<span class="hljs-number">0.5</span>))<font></font>
    model.add(Dense(len(emnist_labels), activation=<span class="hljs-string">'softmax'</span>))<font></font>
    model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=<span class="hljs-string">'adadelta'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-keyword">return</span> model<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_model2</span>():</span><font></font>
    model = Sequential()<font></font>
    <span class="hljs-comment"># In Keras there are two options for padding: same or valid. Same means we pad with the number on the edge and valid means no padding.</span>
    model.add(Convolution2D(filters=<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>, input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>)))<font></font>
    model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<font></font>
    model.add(Convolution2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>))<font></font>
    model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<font></font>
    model.add(Convolution2D(<span class="hljs-number">128</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, padding=<span class="hljs-string">'same'</span>))<font></font>
    model.add(MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))
    <span class="hljs-comment"># model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))</span>
    <span class="hljs-comment"># model.add(MaxPooling2D((2, 2)))</span>
    <span class="hljs-comment">## model.add(Dropout(0.25))</span><font></font>
    model.add(Flatten())<font></font>
    model.add(Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Dropout(<span class="hljs-number">0.5</span>))<font></font>
    model.add(Dense(len(emnist_labels), activation=<span class="hljs-string">'softmax'</span>))<font></font>
    model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=<span class="hljs-string">'adadelta'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-keyword">return</span> model<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_model3</span>():</span><font></font>
    model = Sequential()<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">'same'</span>, input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>), activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<font></font>
    model.add(Dropout(<span class="hljs-number">0.25</span>))<font></font>
<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(Convolution2D(filters=<span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), padding=<span class="hljs-string">'same'</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), strides=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<font></font>
    model.add(Dropout(<span class="hljs-number">0.25</span>))<font></font>
<font></font>
    model.add(Flatten())<font></font>
    model.add(Dense(<span class="hljs-number">512</span>, activation=<span class="hljs-string">"relu"</span>))<font></font>
    model.add(Dropout(<span class="hljs-number">0.5</span>))<font></font>
    model.add(Dense(len(emnist_labels), activation=<span class="hljs-string">"softmax"</span>))<font></font>
    model.compile(loss=<span class="hljs-string">'categorical_crossentropy'</span>, optimizer=RMSprop(lr=<span class="hljs-number">0.001</span>, rho=<span class="hljs-number">0.9</span>, epsilon=<span class="hljs-number">1e-08</span>, decay=<span class="hljs-number">0.0</span>), metrics=[<span class="hljs-string">'accuracy'</span>])
    <span class="hljs-keyword">return</span> model<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_train</span>(<span class="hljs-params">model</span>):</span><font></font>
    t_start = time.time()<font></font>
<font></font>
    emnist_path = <span class="hljs-string">'D:\\Temp\\1\\'</span>
    X_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-train-images-idx3-ubyte'</span>)<font></font>
    y_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-train-labels-idx1-ubyte'</span>)<font></font>
<font></font>
    X_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-test-images-idx3-ubyte'</span>)<font></font>
    y_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string">'emnist-byclass-test-labels-idx1-ubyte'</span>)<font></font>
<font></font>
    X_train = np.reshape(X_train, (X_train.shape[<span class="hljs-number">0</span>], <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<font></font>
    X_test = np.reshape(X_test, (X_test.shape[<span class="hljs-number">0</span>], <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<font></font>
<font></font>
    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels))<font></font>
<font></font>
    <span class="hljs-comment"># Test:</span>
    k = <span class="hljs-number">10</span>
    X_train = X_train[:X_train.shape[<span class="hljs-number">0</span>] // k]<font></font>
    y_train = y_train[:y_train.shape[<span class="hljs-number">0</span>] // k]<font></font>
    X_test = X_test[:X_test.shape[<span class="hljs-number">0</span>] // k]<font></font>
    y_test = y_test[:y_test.shape[<span class="hljs-number">0</span>] // k]<font></font>
<font></font>
    <span class="hljs-comment"># Normalize</span><font></font>
    X_train = X_train.astype(np.float32)<font></font>
    X_train /= <span class="hljs-number">255.0</span><font></font>
    X_test = X_test.astype(np.float32)<font></font>
    X_test /= <span class="hljs-number">255.0</span><font></font>
<font></font>
    x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))<font></font>
    y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))<font></font>
<font></font>
    <span class="hljs-comment"># Set a learning rate reduction</span>
    learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor=<span class="hljs-string">'val_acc'</span>, patience=<span class="hljs-number">3</span>, verbose=<span class="hljs-number">1</span>, factor=<span class="hljs-number">0.5</span>, min_lr=<span class="hljs-number">0.00001</span>)<font></font>
<font></font>
    <span class="hljs-comment"># Required for learning_rate_reduction:</span><font></font>
    keras.backend.get_session().run(tf.global_variables_initializer())<font></font>
<font></font>
    model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=<span class="hljs-number">64</span>, epochs=<span class="hljs-number">30</span>)<font></font>
    print(<span class="hljs-string">"Training done, dT:"</span>, time.time() - t_start)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_predict</span>(<span class="hljs-params">model, image_file</span>):</span>
    img = keras.preprocessing.image.load_img(image_file, target_size=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>), color_mode=<span class="hljs-string">'grayscale'</span>)<font></font>
    emnist_predict_img(model, img)<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emnist_predict_img</span>(<span class="hljs-params">model, img</span>):</span>
    img_arr = np.expand_dims(img, axis=<span class="hljs-number">0</span>)<font></font>
    img_arr = <span class="hljs-number">1</span> - img_arr/<span class="hljs-number">255.0</span>
    img_arr[<span class="hljs-number">0</span>] = np.rot90(img_arr[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>)<font></font>
    img_arr[<span class="hljs-number">0</span>] = np.fliplr(img_arr[<span class="hljs-number">0</span>])<font></font>
    img_arr = img_arr.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<font></font>
<font></font>
    result = model.predict_classes([img_arr])<font></font>
    <span class="hljs-keyword">return</span> chr(emnist_labels[result[<span class="hljs-number">0</span>]])<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">letters_extract</span>(<span class="hljs-params">image_file: str, out_size=<span class="hljs-number">28</span></span>):</span><font></font>
    img = cv2.imread(image_file)<font></font>
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<font></font>
    ret, thresh = cv2.threshold(gray, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<font></font>
    img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), np.uint8), iterations=<span class="hljs-number">1</span>)<font></font>
<font></font>
    <span class="hljs-comment"># Get contours</span><font></font>
    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)<font></font>
<font></font>
    output = img.copy()<font></font>
<font></font>
    letters = []<font></font>
    <span class="hljs-keyword">for</span> idx, contour <span class="hljs-keyword">in</span> enumerate(contours):<font></font>
        (x, y, w, h) = cv2.boundingRect(contour)<font></font>
        <span class="hljs-comment"># print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])</span>
        <span class="hljs-comment"># hierarchy[i][0]: the index of the next contour of the same level</span>
        <span class="hljs-comment"># hierarchy[i][1]: the index of the previous contour of the same level</span>
        <span class="hljs-comment"># hierarchy[i][2]: the index of the first child</span>
        <span class="hljs-comment"># hierarchy[i][3]: the index of the parent</span>
        <span class="hljs-keyword">if</span> hierarchy[<span class="hljs-number">0</span>][idx][<span class="hljs-number">3</span>] == <span class="hljs-number">0</span>:<font></font>
            cv2.rectangle(output, (x, y), (x + w, y + h), (<span class="hljs-number">70</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">1</span>)<font></font>
            letter_crop = gray[y:y + h, x:x + w]<font></font>
            <span class="hljs-comment"># print(letter_crop.shape)</span><font></font>
<font></font>
            <span class="hljs-comment"># Resize letter canvas to square</span><font></font>
            size_max = max(w, h)<font></font>
            letter_square = <span class="hljs-number">255</span> * np.ones(shape=[size_max, size_max], dtype=np.uint8)
            <span class="hljs-keyword">if</span> w &gt; h:
                <span class="hljs-comment"># Enlarge image top-bottom</span>
                <span class="hljs-comment"># ------</span>
                <span class="hljs-comment"># ======</span>
                <span class="hljs-comment"># ------</span>
                y_pos = size_max//<span class="hljs-number">2</span> - h//<span class="hljs-number">2</span>
                letter_square[y_pos:y_pos + h, <span class="hljs-number">0</span>:w] = letter_crop
            <span class="hljs-keyword">elif</span> w &lt; h:
                <span class="hljs-comment"># Enlarge image left-right</span>
                <span class="hljs-comment"># --||--</span>
                x_pos = size_max//<span class="hljs-number">2</span> - w//<span class="hljs-number">2</span>
                letter_square[<span class="hljs-number">0</span>:h, x_pos:x_pos + w] = letter_crop
            <span class="hljs-keyword">else</span>:<font></font>
                letter_square = letter_crop<font></font>
<font></font>
            <span class="hljs-comment"># Resize letter to 28x28 and add letter and its X-coordinate</span><font></font>
            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))<font></font>
<font></font>
    <span class="hljs-comment"># Sort array in place by X-coordinate</span>
    letters.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>], reverse=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    <span class="hljs-comment"># cv2.imshow("Input", img)</span>
    <span class="hljs-comment"># # cv2.imshow("Gray", thresh)</span>
    <span class="hljs-comment"># cv2.imshow("Enlarged", img_erode)</span>
    <span class="hljs-comment"># cv2.imshow("Output", output)</span>
    <span class="hljs-comment"># cv2.imshow("0", letters[0][2])</span>
    <span class="hljs-comment"># cv2.imshow("1", letters[1][2])</span>
    <span class="hljs-comment"># cv2.imshow("2", letters[2][2])</span>
    <span class="hljs-comment"># cv2.imshow("3", letters[3][2])</span>
    <span class="hljs-comment"># cv2.imshow("4", letters[4][2])</span>
    <span class="hljs-comment"># cv2.waitKey(0)</span>
    <span class="hljs-keyword">return</span> letters<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">img_to_str</span>(<span class="hljs-params">model: Any, image_file: str</span>):</span><font></font>
    letters = letters_extract(image_file)<font></font>
    s_out = <span class="hljs-string">""</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(letters)):<font></font>
        dn = letters[i+<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] - letters[i][<span class="hljs-number">0</span>] - letters[i][<span class="hljs-number">1</span>] <span class="hljs-keyword">if</span> i &lt; len(letters) - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        s_out += emnist_predict_img(model, letters[i][<span class="hljs-number">2</span>])
        <span class="hljs-keyword">if</span> (dn &gt; letters[i][<span class="hljs-number">1</span>]/<span class="hljs-number">4</span>):<font></font>
            s_out += <span class="hljs-string">' '</span>
    <span class="hljs-keyword">return</span> s_out<font></font>
<font></font>
<font></font>
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:<font></font>
<font></font>
    <span class="hljs-comment"># model = emnist_model()</span>
    <span class="hljs-comment"># emnist_train(model)</span>
    <span class="hljs-comment"># model.save('emnist_letters.h5')</span><font></font>
<font></font>
    model = keras.models.load_model(<span class="hljs-string">'emnist_letters.h5'</span>)<font></font>
    s_out = img_to_str(model, <span class="hljs-string">"hello_world.png"</span>)<font></font>
    print(s_out)<font></font>
</code></pre><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
いつものように、すべての成功した実験。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja466555/index.html">gitlab.comで大規模な問題の解決策を見つけることから学んだ6つの教訓。パート1</a></li>
<li><a href="../ja466557/index.html">サイトのレイアウトを作成し、極端にとどまらない方法</a></li>
<li><a href="../ja466559/index.html">Letは新しいVarです</a></li>
<li><a href="../ja466561/index.html">完全に透明な選択肢が必要ですか？- 私はそれらを持つ</a></li>
<li><a href="../ja466563/index.html">KOST：クラウドアプリケーションを開発するための新しいテクノロジースタックに含まれるもの</a></li>
<li><a href="../ja466567/index.html">プロバイダー用ツールキット：トラフィックとその構成を操作するシステムに関するテーマ別ウェビナー</a></li>
<li><a href="../ja466569/index.html">モスクワ取引所でのIPO：なぜそれが必要なのか、誰がそれを行い、どのように株を買うのか</a></li>
<li><a href="../ja466571/index.html">Tesseract OCRのヒント-OCRパフォーマンスを向上させるために独自の語彙を作成します</a></li>
<li><a href="../ja466573/index.html">将来の雇用主への質問</a></li>
<li><a href="../ja466575/index.html">PythonからDLLに2次元リストを渡す</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
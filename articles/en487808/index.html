<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôåüèº üîì üôáüèº Recurrent Neural Networks (RNN) with Keras üßú üë®üèº üïñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Translation of the Recursive Neural Network Guide from Tensorflow.org. The material discusses both the built-in capabilities of Keras / Tensorflow 2.0...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Recurrent Neural Networks (RNN) with Keras</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487808/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Translation of the Recursive Neural Network Guide from Tensorflow.org. </font><font style="vertical-align: inherit;">The material discusses both the built-in capabilities of Keras / Tensorflow 2.0 for quick meshing, as well as the possibility of customizing layers and cells. </font><font style="vertical-align: inherit;">Cases and limitations of the use of the CuDNN core are also considered, which allows to accelerate the process of learning the neural network.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/xt/_q/nj/xt_qnjgfjengqoqd4gizkq4j_wk.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Recursive neural networks (RNNs) are a class of neural networks that are good for modeling serial data, such as time series or natural language. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If schematically, the RNN layer uses a loop </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to iterate over a time-ordered sequence, while storing in an internal state, encoded information about the steps that he has already seen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras RNN API is designed with a focus on: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ease of use</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : built-in layers </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">allow you to quickly build a recursive model without having to make complex configuration settings. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Easy customization</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : You can also define your own layer of RNN cells (inner part of the loop</font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) with custom behavior and use it with a common layer of `tf.keras.layers.RNN` (the` for` loop itself). </font><font style="vertical-align: inherit;">This will allow you to quickly prototype various research ideas in a flexible manner, with a minimum of code.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation</font></font></h2><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> collections
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Building a simple model</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras has three built-in RNN layers:</font></font><br>
<br>
<ol>
<li><code>tf.keras.layers.SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, a fully-connected RNN in which the output of the previous time step should be passed to the next step.</font></font></li>
<li><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, first proposed in the article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Studying phrases using RNN codec for statistical machine translation</font></font></a></li>
<li><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, first proposed in the article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Long-term Short-Term Memory</font></font></a></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In early 2015, Keras introduced the first reusable open source Python and LSTM and GRU implementations. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The following is an example of a </font></font><code>Sequential</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">model that processes sequences of integers by nesting each integer in a 64-dimensional vector, then processing sequences of vectors using a layer </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()
<span class="hljs-comment">#   Embedding      1000, </span>
<span class="hljs-comment">#     64.</span>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#   LSTM  128  .</span>
model.add(layers.LSTM(<span class="hljs-number">128</span>))<font></font>
<font></font>
<span class="hljs-comment">#   Dense  10    softmax.</span>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Outputs and Statuses</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
By default, the output of the RNN layer contains one vector per element. This vector is the output of the last RNN cell containing information about the entire input sequence. The dimension of this output </font></font><code>(batch_size, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, where </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">corresponds to the argument </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passed to the layer constructor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The RNN layer can also return the entire output sequence for each element (one vector for each step), if you specify </font></font><code>return_sequences=True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. The dimension of this output is </font></font><code>(batch_size, timesteps, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#  GRU  3D   (batch_size, timesteps, 256)</span>
model.add(layers.GRU(<span class="hljs-number">256</span>, return_sequences=<span class="hljs-literal">True</span>))<font></font>
<font></font>
<span class="hljs-comment">#  SimpleRNN  2D   (batch_size, 128)</span>
model.add(layers.SimpleRNN(<span class="hljs-number">128</span>))<font></font>
<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, the RNN layer can return its final internal state (s). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The returned states can be used later to resume execution of the RNN or </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to initialize another RNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . This setting is usually used in the encoder-decoder model, sequence to sequence, where the final state of the encoder is used for the initial state of the decoder. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order for the RNN layer to return its internal state, set the parameter </font></font><code>return_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to value </font></font><code>True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">when creating the layer. Note that there are </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 state tensors, and </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">only one. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To adjust the initial state of a layer, simply call the layer with an additional argument </font></font><code>initial_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note that the dimension must match the dimension of the layer element, as in the following example.</font></font><br>
<br>
<pre><code class="python hljs">encoder_vocab = <span class="hljs-number">1000</span>
decoder_vocab = <span class="hljs-number">2000</span><font></font>
<font></font>
encoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=<span class="hljs-number">64</span>)(encoder_input)<font></font>
<font></font>
<span class="hljs-comment">#       </span><font></font>
output, state_h, state_c = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, return_state=<span class="hljs-literal">True</span>, name=<span class="hljs-string">'encoder'</span>)(encoder_embedded)<font></font>
encoder_state = [state_h, state_c]<font></font>
<font></font>
decoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=<span class="hljs-number">64</span>)(decoder_input)<font></font>
<font></font>
<span class="hljs-comment">#  2     LSTM    </span><font></font>
decoder_output = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, name=<span class="hljs-string">'decoder'</span>)(decoder_embedded, initial_state=encoder_state)<font></font>
output = layers.Dense(<span class="hljs-number">10</span>)(decoder_output)<font></font>
<font></font>
model = tf.keras.Model([encoder_input, decoder_input], output)<font></font>
model.summary()<font></font>
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN layers and RNN cells</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The RNN API, in addition to the built-in RNN layers, also provides cell-level APIs. </font><font style="vertical-align: inherit;">Unlike RNN layers, which process entire packets of input sequences, an RNN cell processes only one time step. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The cell is inside the cycle of the </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN layer. </font><font style="vertical-align: inherit;">Wrapping a cell with a layer </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gives you a layer capable of processing sequence packets, e.g. </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mathematically, </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">it gives the same result as </font></font><code>LSTM(10)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">In fact, the implementation of this layer inside TF v1.x was only to create the corresponding RNN cell and wrap it in the RNN layer. </font><font style="vertical-align: inherit;">However, the use of embedded layers </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">allows the use of CuDNN that can give you better performance.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are three built-in RNN cells, each of which corresponds to its own RNN layer.</font></font><br>
<br>
<ul>
<li><code>tf.keras.layers.SimpleRNNCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">matches the layer </font></font><code>SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.GRUCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">matches the layer </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.LSTMCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">matches the layer </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Abstraction of a cell together with a common class </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">makes it very easy to implement custom RNN architectures for your research.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cross-batch save state</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When processing long sequences (possibly endless), you might want to use the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cross-batch statefulness</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pattern </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Usually, the internal state of the RNN layer is reset with each new data packet (i.e. each example that sees the layer is assumed to be independent of the past). The layer will maintain state only for the duration of processing this element. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, if you have very long sequences, it is useful to break them down into shorter ones and transfer them to the RNN layer in turn without resetting the layer state. Thus, a layer can store information about the entire sequence, although it will only see one subsequence at a time. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can do this by setting `stateful = True` in the constructor.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If you have the sequence `s = [t0, t1, ... t1546, t1547]`, you can split it for example into:</font></font><br>
<br>
<pre><code class="python hljs">s1 = [t0, t1, ... t100]<font></font>
s2 = [t101, ... t201]<font></font>
...<font></font>
s16 = [t1501, ... t1547]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then you can process it with:</font></font><br>
<br>
<pre><code class="python hljs">lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> sub_sequences:<font></font>
  output = lstm_layer(s)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When you want to clean the condition, use </font></font><code>layer.reset_states()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<blockquote><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Note:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In this case, it is assumed that the example </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in this package is a continuation of the example of the </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">previous package. </font><font style="vertical-align: inherit;">This means that all packages contain the same number of elements (package size). </font><font style="vertical-align: inherit;">For example, if the package contains </font></font><code>[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, the next package should contain </font></font><code>[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here is a complete example:</font></font><br>
<br>
<pre><code class="python hljs">paragraph1 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph2 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph3 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
<font></font>
lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)<font></font>
output = lstm_layer(paragraph1)<font></font>
output = lstm_layer(paragraph2)<font></font>
output = lstm_layer(paragraph3)<font></font>
<font></font>
<span class="hljs-comment"># reset_states()      initial_state.</span>
<span class="hljs-comment">#  initial_state   ,      .</span>
lstm_layer.reset_states()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bidirectional RNN</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For sequences other than time series (e.g. texts), it often happens that the RNN model works better if it processes the sequence not only from beginning to end, but also vice versa. For example, to predict the next word in a sentence, it is often useful to know the context around the word, and not just the words in front of it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras provides a simple API for creating such bidirectional RNNs: a wrapper </font></font><code>tf.keras.layers.Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">64</span>, return_sequences=<span class="hljs-literal">True</span>), <font></font>
                               input_shape=(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)))<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">32</span>)))<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Under the hood, the </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">transferred RNN layer </font></font><code>go_backwards</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">will be copied </font><font style="vertical-align: inherit;">and the field of the </font><font style="vertical-align: inherit;">newly copied layer will be </font><font style="vertical-align: inherit;">turned over </font><font style="vertical-align: inherit;">, and thus the input data will be processed in the reverse order. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The output of ` </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN by default will be the sum of the output of the forward layer and the output of the reverse layer. </font><font style="vertical-align: inherit;">If you need other merge behavior, e.g. </font><font style="vertical-align: inherit;">concatenation, change the `merge_mode` parameter in the` Bidirectional` wrapper constructor.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Performance Optimization and CuDNN Core in TensorFlow 2.0</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In TensorFlow 2.0, the built-in LSTM and GRU layers are usable by default CuDNN cores if a graphics processor is available. </font><font style="vertical-align: inherit;">With this change, the previous layers </font></font><code>keras.layers.CuDNNLSTM/CuDNNGRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">are outdated, and you can build your model without worrying about the equipment on which it will work. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since the CuDNN kernel is built with some assumptions, this means that the layer </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">will not be able to use the CuDNN kernel layer if you change the default settings of the built-in LSTM or GRU layers</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">E.g.</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changing a function </font></font><code>activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from </font></font><code>tanh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to something else.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changing a function </font></font><code>recurrent_activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from </font></font><code>sigmoid</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to something else.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Usage </font></font><code>recurrent_dropout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&gt; 0.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setting it </font></font><code>unroll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to True, which causes LSTM / GRU to decompose the internal </font></font><code>tf.while_loop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">into a deployed loop </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Set </font></font><code>use_bias</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to False.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Using masks when the input data is not right justified (if the mask matches the right strictly right data, CuDNN can still be used. This is the most common case).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When possible use CuDNN kernels</font></font></h3><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">64</span>
<span class="hljs-comment">#    MNIST    (batch_size, 28, 28).</span>
<span class="hljs-comment">#     (28, 28) (   ).</span>
input_dim = <span class="hljs-number">28</span><font></font>
<font></font>
units = <span class="hljs-number">64</span>
output_size = <span class="hljs-number">10</span>  <span class="hljs-comment">#   0  9</span><font></font>
<font></font>
<span class="hljs-comment">#  RNN </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_model</span>(<span class="hljs-params">allow_cudnn_kernel=True</span>):</span>
  <span class="hljs-comment"># CuDNN     ,     .</span>
  <span class="hljs-comment">#   `LSTM(units)`    CuDNN,</span>
  <span class="hljs-comment">#   RNN(LSTMCell(units))   non-CuDNN .</span>
  <span class="hljs-keyword">if</span> allow_cudnn_kernel:
    <span class="hljs-comment">#  LSTM      CuDNN.</span>
    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(<span class="hljs-literal">None</span>, input_dim))
  <span class="hljs-keyword">else</span>:
    <span class="hljs-comment">#  LSTMCell  RNN    CuDNN.</span><font></font>
    lstm_layer = tf.keras.layers.RNN(<font></font>
        tf.keras.layers.LSTMCell(units),<font></font>
        input_shape=(<span class="hljs-literal">None</span>, input_dim))<font></font>
  model = tf.keras.models.Sequential([<font></font>
      lstm_layer,<font></font>
      tf.keras.layers.BatchNormalization(),<font></font>
      tf.keras.layers.Dense(output_size)]<font></font>
  )<font></font>
  <span class="hljs-keyword">return</span> model
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Loading the MNIST dataset</font></font></h3><br>
<pre><code class="python hljs">mnist = tf.keras.datasets.mnist<font></font>
<font></font>
(x_train, y_train), (x_test, y_test) = mnist.load_data()<font></font>
x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span>
sample, sample_label = x_train[<span class="hljs-number">0</span>], y_train[<span class="hljs-number">0</span>]</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Create an instance of the model and compile it</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We have chosen </font></font><code>sparse_categorical_crossentropy</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">as a function of losses. </font><font style="vertical-align: inherit;">The output of the model has a dimension </font></font><code>[batch_size, 10]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">The answer of the model is an integer vector, each of the numbers is in the range from 0 to 9.</font></font><br>
<br>
<pre><code class="python hljs">model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
<font></font>
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
              optimizer=<span class="hljs-string">'sgd'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<pre><code class="python hljs">model.fit(x_train, y_train,<font></font>
          validation_data=(x_test, y_test),<font></font>
          batch_size=batch_size,<font></font>
          epochs=<span class="hljs-number">5</span>)</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Build a new model without CuDNN core</font></font></h3><br>
<pre><code class="python hljs">slow_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">False</span>)<font></font>
slow_model.set_weights(model.get_weights())<font></font>
slow_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
                   optimizer=<span class="hljs-string">'sgd'</span>, <font></font>
                   metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
slow_model.fit(x_train, y_train, <font></font>
               validation_data=(x_test, y_test), <font></font>
               batch_size=batch_size,<font></font>
               epochs=<span class="hljs-number">1</span>)  <span class="hljs-comment">#         .</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As you can see, the model built with CuDNN is much faster for training than the model using the usual TensorFlow core. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The same model with CuDNN support can be used for output in a single-processor environment. </font><font style="vertical-align: inherit;">Annotation </font></font><code>tf.device</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">simply indicates the device used. </font><font style="vertical-align: inherit;">The model will run by default on the CPU if the GPU is not available. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You just do not need to worry about the hardware you are working on. </font><font style="vertical-align: inherit;">Isn't that cool?</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">'CPU:0'</span>):<font></font>
  cpu_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
  cpu_model.set_weights(model.get_weights())<font></font>
  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, <span class="hljs-number">0</span>)), axis=<span class="hljs-number">1</span>)<font></font>
  print(<span class="hljs-string">'Predicted result is: %s, target result is: %s'</span> % (result.numpy(), sample_label))<font></font>
  plt.imshow(sample, cmap=plt.get_cmap(<span class="hljs-string">'gray'</span>))
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN with list / dictionary input, or nested input</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nested structures allow you to include more information in one time step. </font><font style="vertical-align: inherit;">For example, a video frame may contain audio and video input simultaneously. </font><font style="vertical-align: inherit;">The dimension of the data in this case may be:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In another example, handwritten data can have both x and y coordinates for the current pen position, as well as pressure information. </font><font style="vertical-align: inherit;">So the data can be represented as follows:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The following code builds an example of a custom RNN cell that works with such structured input.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Define a user cell supporting nested input / output</font></font></h3><br>
<pre><code class="python hljs">NestedInput = collections.namedtuple(<span class="hljs-string">'NestedInput'</span>, [<span class="hljs-string">'feature1'</span>, <span class="hljs-string">'feature2'</span>])<font></font>
NestedState = collections.namedtuple(<span class="hljs-string">'NestedState'</span>, [<span class="hljs-string">'state1'</span>, <span class="hljs-string">'state2'</span>])<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NestedCell</span>(<span class="hljs-params">tf.keras.layers.Layer</span>):</span><font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, unit_1, unit_2, unit_3, **kwargs</span>):</span><font></font>
    self.unit_1 = unit_1<font></font>
    self.unit_2 = unit_2<font></font>
    self.unit_3 = unit_3<font></font>
    self.state_size = NestedState(state1=unit_1, <font></font>
                                  state2=tf.TensorShape([unit_2, unit_3]))<font></font>
    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))<font></font>
    super(NestedCell, self).__init__(**kwargs)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build</span>(<span class="hljs-params">self, input_shapes</span>):</span>
    <span class="hljs-comment"># #  input_shape  2 , [(batch, i1), (batch, i2, i3)]</span>
    input_1 = input_shapes.feature1[<span class="hljs-number">1</span>]<font></font>
    input_2, input_3 = input_shapes.feature2[<span class="hljs-number">1</span>:]<font></font>
<font></font>
    self.kernel_1 = self.add_weight(<font></font>
        shape=(input_1, self.unit_1), initializer=<span class="hljs-string">'uniform'</span>, name=<span class="hljs-string">'kernel_1'</span>)<font></font>
    self.kernel_2_3 = self.add_weight(<font></font>
        shape=(input_2, input_3, self.unit_2, self.unit_3),<font></font>
        initializer=<span class="hljs-string">'uniform'</span>,<font></font>
        name=<span class="hljs-string">'kernel_2_3'</span>)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span>(<span class="hljs-params">self, inputs, states</span>):</span>
    <span class="hljs-comment">#     [(batch, input_1), (batch, input_2, input_3)]</span>
    <span class="hljs-comment">#     [(batch, unit_1), (batch, unit_2, unit_3)]</span><font></font>
    input_1, input_2 = tf.nest.flatten(inputs)<font></font>
    s1, s2 = states<font></font>
<font></font>
    output_1 = tf.matmul(input_1, self.kernel_1)<font></font>
    output_2_3 = tf.einsum(<span class="hljs-string">'bij,ijkl-&gt;bkl'</span>, input_2, self.kernel_2_3)<font></font>
    state_1 = s1 + output_1<font></font>
    state_2_3 = s2 + output_2_3<font></font>
<font></font>
    output = [output_1, output_2_3]<font></font>
    new_states = NestedState(state1=state_1, state2=state_2_3)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> output, new_states
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Build an RNN Model with Nested Input / Output</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's build a Keras model that uses a layer </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and a custom cell that we just defined.</font></font><br>
<br>
<pre><code class="python hljs">unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Train the model on randomly generated data</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since we don‚Äôt have a good dataset for this model, we use random data generated by the Numpy library for demonstration.</font></font><br>
<br>
<pre><code class="python hljs">input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))<font></font>
input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))<font></font>
target_1_data = np.random.random((batch_size * num_batch, unit_1))<font></font>
target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))<font></font>
input_data = [input_1_data, input_2_data]<font></font>
target_data = [target_1_data, target_2_data]<font></font>
<font></font>
model.fit(input_data, target_data, batch_size=batch_size)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
With a layer, </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">you only need to determine the mathematical logic of a single step within the sequence, and the layer </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">will handle the iteration of the sequence for you. </font><font style="vertical-align: inherit;">This is an incredibly powerful way to quickly prototype new types of RNNs (e.g. the LSTM variant). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">After verification, the translation will also appear on Tensorflow.org. </font><font style="vertical-align: inherit;">If you want to participate in translating the documentation of the Tensorflow.org website into Russian, please contact in a personal or comments. </font><font style="vertical-align: inherit;">Any corrections and comments are appreciated.</font></font></i></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en487798/index.html">How we migrated from Oracle JDK and Java Web Start to AdoptOpenJDK and OpenWebStart</a></li>
<li><a href="../en487800/index.html">Why is it important to tell the applicant what went wrong during the interview (and how to do it right)</a></li>
<li><a href="../en487802/index.html">Uninterruptible APC Smart UPS, and how to cook them</a></li>
<li><a href="../en487804/index.html">Growth Teams Meetup at Raiffeisenbank</a></li>
<li><a href="../en487806/index.html">Creating a small Deno API</a></li>
<li><a href="../en487812/index.html">Testing Polish LED Spectrum Led E27</a></li>
<li><a href="../en487814/index.html">Speed ‚Äã‚Äãand reliability are higher, and the price is lower. New Kingston KC2000 Solid State Drives</a></li>
<li><a href="../en487822/index.html">AvitoTech On Tour: Android meetup in Nizhny Novgorod</a></li>
<li><a href="../en487824/index.html">Overview of LED lamps Spectrum Led GU10 from Europe</a></li>
<li><a href="../en487826/index.html">Overview of LED lamps from Poland Spectrum Led E14</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
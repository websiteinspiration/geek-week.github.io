<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ§šğŸ½ ğŸ¦” ğŸ˜“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†é¡ï¼šå°è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãŸã‚ã®7ã¤ã®å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ ğŸ—ï¸ ğŸ¤¸ğŸ¼ ğŸ§—ğŸ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="æ–‡æ›¸ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†é¡ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã§æœ€ã‚‚é‡è¦ãªã‚¿ã‚¹ã‚¯ã®1ã¤ã§ã™ã€‚
 

ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®åˆ†é¡ã€ã‚¹ãƒ‘ãƒ ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ä¸é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆã®æ¤œç´¢ãªã©ã€å¤šãã®ç”¨é€”ãŒã‚ã‚Šã¾ã™ã€‚
 

å¤§ä¼æ¥­ã¯å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åé›†ã«å•é¡ŒãŒãªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’æœ€åˆã‹ã‚‰å­¦ç¿’ã™ã‚‹ã“ã¨ã¯å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã§ã™...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†é¡ï¼šå°è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãŸã‚ã®7ã¤ã®å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/504744/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">æ–‡æ›¸ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†é¡ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã§æœ€ã‚‚é‡è¦ãªã‚¿ã‚¹ã‚¯ã®1ã¤ã§ã™ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®åˆ†é¡ã€ã‚¹ãƒ‘ãƒ ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ä¸é©åˆ‡ãªã‚³ãƒ¡ãƒ³ãƒˆã®æ¤œç´¢ãªã©ã€å¤šãã®ç”¨é€”ãŒã‚ã‚Šã¾ã™ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">å¤§ä¼æ¥­ã¯å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åé›†ã«å•é¡ŒãŒãªã„ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’æœ€åˆã‹ã‚‰å­¦ç¿’ã™ã‚‹ã“ã¨ã¯å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã§ã™ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ãŸã ã—ã€å®Ÿéš›ã®ã»ã¨ã‚“ã©ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã¾ã‚Œã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã«ã¯è³¢ãã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã“ã®è¨˜äº‹ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå°ã•ã„å ´åˆã§ã‚‚ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†é¡ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã®å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚</font></font></p><a name="habracut"></a><br>
<h1 id="vvedenie-v-klassifikaciyu-dokumentov"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ã®æ¦‚è¦</font></font></h1><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">æ–‡æ›¸åˆ†é¡ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€èº«ä½“ã®æ´—æµ„ã¨æº–å‚™ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™ã€‚</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
æ¬¡ã«ã€ã“ã®ãƒœãƒ‡ã‚£ã¯ä»»æ„ã®ã‚¿ã‚¤ãƒ—ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã€ãã®å¾Œãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã§ãã¾ã™ã€‚</font></font></p><br>
<p><img src="https://habrastorage.org/webt/0m/lv/zj/0mlvzjouu8auhmcda3uo0cd5apa.png"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã“ã®è¨˜äº‹ã§ã¯ã€ã“ã®å›³ã®ã€Œãƒ†ã‚­ã‚¹ãƒˆã‚’æç¤ºã™ã‚‹ã€ã‚¹ãƒ†ãƒƒãƒ—ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚</font></font></p><br>
<h1 id="testovyy-nabor-dannyh-dlya-klassifikacii"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">åˆ†é¡ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</font></font></h1><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">æœ¬å½“ã§ã™ã‹ï¼Ÿ</font><font style="vertical-align: inherit;">Kaggleç½å®³</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ãƒ„ã‚¤ãƒ¼ãƒˆ</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">ã‚’å«ã‚€NLP</font></a><font style="vertical-align: inherit;">ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">å•é¡Œã¯ã€ã©ã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒå®Ÿéš›ã®ç½å®³ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã€ã©ã®ãƒ„ã‚¤ãƒ¼ãƒˆãŒãã†ã§ã¯ãªã‹ã£ãŸã‹ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã™ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">è¨˜äº‹ã‚’æ®µéšçš„ã«ç¹°ã‚Šè¿”ã™å ´åˆã¯ã€è¨˜äº‹ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚</font></font></p><br>
<p>    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<font></font>
<font></font>
tweet= pd.read_csv(<span class="hljs-string">'../input/nlp-getting-started/train.csv'</span>)<font></font>
test=pd.read_csv(<span class="hljs-string">'../input/nlp-getting-started/test.csv'</span>)<font></font>
<font></font>
tweet.head(<span class="hljs-number">3</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/yd/dy/gt/yddygt-a7pqftvtfjirycicwi8g.png"></p><br>
<p>   ,  , ,     .</p><br>
<p>        .</p><br>
<pre><code class="python hljs">print(<span class="hljs-string">'There are {} rows and {} columns in train'</span>.format(tweet.shape[<span class="hljs-number">0</span>],tweet.shape[<span class="hljs-number">1</span>]))<font></font>
print(<span class="hljs-string">'There are {} rows and {} columns in test'</span>.format(test.shape[<span class="hljs-number">0</span>],test.shape[<span class="hljs-number">1</span>]))</code></pre><br>
<p>    8000 .</p><br>
<p>      ,      280 .</p><br>
<h1 id="podgotovka-tekstovyh-dannyh">  </h1><br>
<p>,       NLP,      .</p><br>
<p>    , ,   ,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"> </a>.</p><br>
<p> ,  :</p><br>
<ul>
<li><strong></strong> â€”       .</li>
<li><strong>  -</strong> â€”    Â«aÂ»  Â«theÂ».</li>
<li><strong></strong> â€”         (Â«studiesÂ», Â«studingÂ» â†’ Â«studyÂ»).</li>
</ul><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocess_news</span>(<span class="hljs-params">df</span>):</span>
    <span class="hljs-string">'''Function to preprocess and create corpus'''</span><font></font>
    new_corpus=[]<font></font>
<font></font>
    lem=WordNetLemmatizer()<font></font>
    <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> df[<span class="hljs-string">"question_text"</span>]:<font></font>
        words=[w <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> word_tokenize(text) <span class="hljs-keyword">if</span> (w <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop)]<font></font>
<font></font>
        words=[lem.lemmatize(w) <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words]<font></font>
<font></font>
        new_corpus.append(words)<font></font>
    <span class="hljs-keyword">return</span> new_corpus<font></font>
<font></font>
corpus=preprocess_news(df)</code></pre><br>
<p>  ,     ,         .</p><br>
<h1 id="predstavlenie-teksta"> </h1><br>
<p>        ,       .</p><br>
<p>    .</p><br>
<h2 id="countvectorizer">CountVectorizer</h2><br>
<p>CountVectorizer â€”        .</p><br>
<p>        ,    ,   .</p><br>
<p>   :</p><br>
<pre><code class="python hljs">text = [<span class="hljs-string">"She sells seashells in the seashore"</span>]
<span class="hljs-comment"># create the transform</span><font></font>
vectorizer = CountVectorizer()<font></font>
<span class="hljs-comment"># tokenize and build vocab</span><font></font>
vectorizer.fit(text)<font></font>
<span class="hljs-comment"># summarize</span><font></font>
print(vectorizer.vocabulary_)<font></font>
<span class="hljs-comment"># encode document</span><font></font>
vector = vectorizer.transform(text)<font></font>
<span class="hljs-comment"># summarize encoded vector</span><font></font>
print(vector.shape)<font></font>
print(type(vector))<font></font>
print(vector.toarray())</code></pre><br>
<p><img src="https://habrastorage.org/webt/xk/so/d0/xksod0v5t3znz-uue66kdntoljc.png"></p><br>
<p>  , CountVectorizer            <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow">Numpy</a>,    .</p><br>
<p>   ,       ,     .</p><br>
<pre><code class="python hljs">vector=vectorizer.transform([<span class="hljs-string">"I sell seashells in the seashore"</span>])<font></font>
vector.toarray()</code></pre><br>
<p><img src="https://habrastorage.org/webt/en/ni/f7/ennif7o_8j97wfkltyg57et9gt4.png"></p><br>
<p>  , :</p><br>
<ul>
<li>   3  4 ,        .     ,      .</li>
</ul><br>
<p>,     â€”  Â«sellsÂ»  Â«sheÂ». </p><br>
<p>      CountVectorizer,       .</p><br>
<pre><code class="python hljs">vec=CountVectorizer(max_df=<span class="hljs-number">10</span>,max_features=<span class="hljs-number">10000</span>)<font></font>
vec.fit(df.question_text.values)<font></font>
vector=vec.transform(df.question_text.values)</code></pre><br>
<p> ,   CountVectorizer    ,       :</p><br>
<ul>
<li><strong>max_features</strong> â€”      n      ,   .</li>
<li><strong>min_df</strong> â€”        ,       .</li>
<li><strong>max_df</strong> â€”        ,       .</li>
</ul><br>
<p>         (     ).</p><br>
<h2 id="tfidfvectorizer">TfidfVectorizer</h2><br>
<p>      Countvectorizer   ,   ,   "the"     (       )         .</p><br>
<p>    â€” TfidfVectorizer.</p><br>
<p>  â€”    <strong>Term frequency-inverse document frequency</strong> (  â€”   ).</p><br>
<ul>
<li><p><strong>  (Term Frequency)</strong> â€” ,       . </p><br>
</li>
<li><p><strong>   (Inverse Document Frequency)</strong> â€”   ,     .</p><br>
</li>
</ul><br>
<p>   :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> TfidfVectorizer
<span class="hljs-comment"># list of text documents</span>
text = [<span class="hljs-string">"She sells seashells by the seashore"</span>,<span class="hljs-string">"The sea."</span>,<span class="hljs-string">"The seashore"</span>]
<span class="hljs-comment"># create the transform</span><font></font>
vectorizer = TfidfVectorizer()<font></font>
<span class="hljs-comment"># tokenize and build vocab</span><font></font>
vectorizer.fit(text)<font></font>
<span class="hljs-comment"># summarize</span><font></font>
print(vectorizer.vocabulary_)<font></font>
print(vectorizer.idf_)<font></font>
<span class="hljs-comment"># encode document</span>
vector = vectorizer.transform([text[<span class="hljs-number">0</span>]])
<span class="hljs-comment"># summarize encoded vector</span><font></font>
print(vector.shape)<font></font>
print(vector.toarray())</code></pre><br>
<p><img src="https://habrastorage.org/webt/tx/l4/fg/txl4fgsvwqmhwombgecznkixpzy.png"></p><br>
<p>   6          ,       Â«theÂ»,   4 .</p><br>
<p>      0  1,          -   .</p><br>
<h2 id="word2vec">Word2vec</h2><br>
<p>       ,     .</p><br>
<p> (embeddings)          .</p><br>
<p>   <strong>    n- </strong>.</p><br>
<p><img src="https://habrastorage.org/webt/cd/e1/t2/cde1t2jupmsnm-ma8nhw8hqbd54.png"></p><br>
<p>Word2Vec    Google       <strong>  </strong>    .</p><br>
<p>   ,    .</p><br>
<p> ,    ,   .</p><br>
<p>       Â«The cat sat on the matÂ».</p><br>
<p><img src="https://habrastorage.org/webt/5h/mw/hr/5hmwhruv3de3xfpnmohswga3cwk.png"></p><br>
<p>Word2vec     :</p><br>
<ul>
<li><p><strong>  </strong> (Continuous Bag of Words, CBoW) â€”       ,    <strong>   </strong>.</p><br>
</li>
<li><p><strong>Skip-Gram</strong>   â€”      <strong>   </strong>.</p><br>
</li>
</ul><br>
<p>     ,  ,    ,     .   word2vec   python:</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> gensim
<span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> Word2Vec<font></font>
<font></font>
model = gensim.models.Word2Vec(corpus, <font></font>
                               min_count = <span class="hljs-number">1</span>, size = <span class="hljs-number">100</span>, window = <span class="hljs-number">5</span>)</code></pre><br>
<p>,     word2vec.</p><br>
<p>      :</p><br>
<ul>
<li><strong>size</strong> â€”       .</li>
<li><strong>min_count</strong> â€”&nbsp;          .</li>
<li><strong>window</strong> â€”     ,     .      .</li>
</ul><br>
<p>                        .</p><br>
<p>    .</p><br>
<p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<p>    ,   gensim.</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span>  gensim.models.KeyedVectors <span class="hljs-keyword">import</span> load_word2vec_format<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_word2vec</span>():</span><font></font>
    word2vecDict = load_word2vec_format(<font></font>
        <span class="hljs-string">'../input/word2vec-google/GoogleNews-vectors-negative300.bin'</span>,<font></font>
        binary=<span class="hljs-literal">True</span>, unicode_errors=<span class="hljs-string">'ignore'</span>)<font></font>
    embeddings_index = dict()<font></font>
    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> word2vecDict.wv.vocab:<font></font>
        embeddings_index[word] = word2vecDict.word_vec(word)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> embeddings_index</code></pre><br>
<p>   :</p><br>
<pre><code class="python hljs">w2v_model=load_word2vec()<font></font>
w2v_model[<span class="hljs-string">'London'</span>].shape</code></pre><br>
<p><img src="https://habrastorage.org/webt/gb/uu/sx/gbuusxmiquwmrr9pbd7qoaqt75m.png"></p><br>
<p>  ,   300- .</p><br>
<p>(       â€”   ,       .      ,  ,        . <em>. </em>)<br>
         ,         .</p><br>
<h2 id="fasttext">FastText</h2><br>
<p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow">Genism</a> â€” FastText.</p><br>
<p>    Facebook          .</p><br>
<p>   Continuous Bag of Words  Skip-Gram.<br>
      FastText  ,   <strong>    n-</strong>.</p><br>
<p>,  ,  Â«orangeÂ».</p><br>
<p>    Â«oraÂ», Â«ranÂ», Â«angÂ», Â«ngeÂ» (     ).</p><br>
<p><strong>   ( )  Â«orangeÂ»    n-</strong>.</p><br>
<p>         ,         n-     .</p><br>
<p> ,   Â«stupedofantabulouslyfantasticÂ», , ,       , genism     ,     .</p><br>
<p>FastText  <strong>        ,    ,     </strong>.</p><br>
<p>          Â«fantasticÂ»  Â«fantabulousÂ».</p><br>
<p>        ,     .</p><br>
<p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<p>         n- .</p><br>
<p>             .</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> FastText <font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_fasttext</span>():</span><font></font>
<font></font>
    print(<span class="hljs-string">'loading word embeddings...'</span>)<font></font>
    embeddings_index = {}<font></font>
    f = open(<span class="hljs-string">'../input/fasttext/wiki.simple.vec'</span>,encoding=<span class="hljs-string">'utf-8'</span>)
    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(f):<font></font>
        values = line.strip().rsplit(<span class="hljs-string">' '</span>)<font></font>
        word = values[<span class="hljs-number">0</span>]<font></font>
        coefs = np.asarray(values[<span class="hljs-number">1</span>:], dtype=<span class="hljs-string">'float32'</span>)<font></font>
        embeddings_index[word] = coefs<font></font>
    f.close()<font></font>
    print(<span class="hljs-string">'found %s word vectors'</span> % len(embeddings_index))<font></font>
<font></font>
    <span class="hljs-keyword">return</span> embeddings_index<font></font>
<font></font>
embeddings_index=load_fastext()</code></pre><br>
<p><img src="https://habrastorage.org/webt/l-/ia/wu/l-iawudxzoi4rnndmj0zmasjxbw.png"></p><br>
<p>    :</p><br>
<pre><code class="python hljs">embeddings_index[<span class="hljs-string">'london'</span>].shape</code></pre><br>
<p><img src="https://habrastorage.org/webt/gb/uu/sx/gbuusxmiquwmrr9pbd7qoaqt75m.png"></p><br>
<h2 id="glove">GloVe</h2><br>
<p>GloVe (global vectors for word representation)  Â«    Â».</p><br>
<p>    ,   .</p><br>
<p>     ,          .</p><br>
<p>    word2vec,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<p>        .<br>
      .</p><br>
<p>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<p>      .</p><br>
<p>   ,     .</p><br>
<p>          n- .</p><br>
<p> :</p><br>
<p><img src="https://habrastorage.org/webt/hx/-l/q9/hx-lq9qnhhpuvdwg-etp21bhebw.png"></p><br>
<p>          .</p><br>
<p>   .</p><br>
<p>   :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">load_glove</span>():</span><font></font>
    embedding_dict = {}<font></font>
    path = <span class="hljs-string">'../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'</span>
    <span class="hljs-keyword">with</span> open(path, <span class="hljs-string">'r'</span>) <span class="hljs-keyword">as</span> f:
        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<font></font>
            values = line.split()<font></font>
            word = values[<span class="hljs-number">0</span>]<font></font>
            vectors = np.asarray(values[<span class="hljs-number">1</span>:], <span class="hljs-string">'float32'</span>)<font></font>
            embedding_dict[word] = vectors<font></font>
    f.close()<font></font>
<font></font>
    <span class="hljs-keyword">return</span> embedding_dict<font></font>
<font></font>
embeddings_index = load_glove()</code></pre><br>
<p>,    ,            GloVe.</p><br>
<p>   - .</p><br>
<pre><code class="python hljs">embeddings_index[<span class="hljs-string">'london'</span>].shape</code></pre><br>
<h2 id="universalnoe-kodirovanie-predlozheniy">  </h2><br>
<p><img src="https://habrastorage.org/webt/oe/yy/2v/oeyy2vuxk4hgt6hnb_kips0kb4k.png"></p><br>
<p>          .<br>
      <strong> </strong>.<br>
    . </p><br>
<p>     ,           .</p><br>
<p>:</p><br>
<ul>
<li>  .</li>
<li>  .</li>
<li>  .</li>
</ul><br>
<p>       ,        .</p><br>
<p>             .</p><br>
<p>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<p>      Tensorflow.</p><br>
<pre><code class="python hljs">module_url = <span class="hljs-string">"../input/universalsentenceencoderlarge4"</span>
<span class="hljs-comment"># Import the Universal Sentence Encoder's TF Hub module</span>
embed = hub.load(module_url)</code></pre><br>
<p>        .</p><br>
<pre><code class="python hljs">sentence_list=df.question_text.values.tolist()<font></font>
sentence_emb=embed(sentence_list)[<span class="hljs-string">'outputs'</span>].numpy()</code></pre><br>
<p>          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<h2 id="elmo-bert-i-drugie">Elmo, BERT  </h2><br>
<p>          ,    . </p><br>
<p> <strong>       </strong>.</p><br>
<p>   Â«stickÂ»,   Â«Â», Â«Â»  ,          ,     .</p><br>
<p>    NLP    BERT            ,    .      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"></a>.</p><br>
<h1 id="klassifikaciya-teksta"> </h1><br>
<p>      ,      Keras    .</p><br>
<p>     ,           .</p><br>
<p>       ,         <strong>Keras Tokenizer</strong>  <em>pad_sequences</em>.</p><br>
<pre><code class="python hljs">MAX_LEN=<span class="hljs-number">50</span><font></font>
tokenizer_obj=Tokenizer()<font></font>
tokenizer_obj.fit_on_texts(corpus)<font></font>
sequences=tokenizer_obj.texts_to_sequences(corpus)<font></font>
<font></font>
tweet_pad=pad_sequences(sequences,<font></font>
                        maxlen=MAX_LEN,<font></font>
                        truncating=<span class="hljs-string">'post'</span>,<font></font>
                        padding=<span class="hljs-string">'post'</span>)</code></pre><br>
<p>      .</p><br>
<pre><code class="python hljs">word_index=tokenizer_obj.word_index<font></font>
print(<span class="hljs-string">'Number of unique words:'</span>,len(word_index))</code></pre><br>
<p>        ,        .</p><br>
<p>           .</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">prepare_matrix</span>(<span class="hljs-params">embedding_dict, emb_size=<span class="hljs-number">300</span></span>):</span><font></font>
    num_words = len(word_index)<font></font>
    embedding_matrix = np.zeros((num_words, emb_size))<font></font>
<font></font>
    <span class="hljs-keyword">for</span> word, i <span class="hljs-keyword">in</span> tqdm(word_index.items()):
        <span class="hljs-keyword">if</span> i &gt; num_words:
            <span class="hljs-keyword">continue</span><font></font>
<font></font>
    emb_vec = embedding_dict.get(word)<font></font>
    <span class="hljs-keyword">if</span> emb_vec <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
        embedding_matrix[i] = emb_vec<font></font>
<font></font>
    <span class="hljs-keyword">return</span> embedding_matrix</code></pre><br>
<p>            .</p><br>
<p>         <strong>trainable=False</strong>,    .</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">new_model</span>(<span class="hljs-params">embedding_matrix</span>):</span><font></font>
    inp = Input(shape=(MAX_LEN,))<font></font>
<font></font>
    x = Embedding(num_words, embedding_matrix.shape[<span class="hljs-number">1</span>], weights=[embedding_matrix],<font></font>
                  trainable=<span class="hljs-literal">False</span>)(inp)<font></font>
<font></font>
    x = Bidirectional(<font></font>
        LSTM(<span class="hljs-number">60</span>, return_sequences=<span class="hljs-literal">True</span>, name=<span class="hljs-string">'lstm_layer'</span>, <font></font>
             dropout=<span class="hljs-number">0.1</span>, recurrent_dropout=<span class="hljs-number">0.1</span>))(x)<font></font>
<font></font>
    x = GlobalAveragePool1D()(x)<font></font>
    x = Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">"sigmoid"</span>)(x)<font></font>
    model = Model(inputs=inp, outputs=x)<font></font>
<font></font>
    model.compile(loss=<span class="hljs-string">'binary_crossentropy'</span>,<font></font>
                  optimizer=<span class="hljs-string">'adam'</span>,<font></font>
                  metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
<font></font>
    <span class="hljs-keyword">return</span> model</code></pre><br>
<p> ,  ,   word2vec:</p><br>
<pre><code class="python hljs">embeddings_index=load_word2vec()<font></font>
embedding_matrix=prepare_matrix(embeddings_index)<font></font>
model=new_model(embedding_matrix)<font></font>
<font></font>
history=model.fit(X_train,y_train,<font></font>
                  batch_size=<span class="hljs-number">8</span>,<font></font>
                  epochs=<span class="hljs-number">5</span>,<font></font>
                  validation_data=(X_test,y_test),<font></font>
                  verbose=<span class="hljs-number">2</span>)</code></pre><br>
<p><img src="https://habrastorage.org/webt/n5/qz/xz/n5qzxzykpo93h1nu0-co2rvtpa4.png"></p><br>
<p>          ,     .</p><br>
<h2 id="sravnenie"></h2><br>
<p>          ?</p><br>
<p> Neptune         .</p><br>
<p><img src="https://habrastorage.org/webt/kx/dd/s8/kxdds87tadwh-cvh6dnh9fgpywk.png"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®GloVeæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ä»–ã®2ã¤ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ˆã‚Šã‚‚ã‚ãšã‹ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚ </font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ãƒ¢ãƒ‡ãƒ«ã‚’ã•ã‚‰ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚Œã°ã€ã‚ˆã‚Šå¤šãã®æˆæœãŒå¾—ã‚‰ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚</font></font></p><br>
<p><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã“ã“</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã§å®Ÿé¨“ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™</font><font style="vertical-align: inherit;">ã€‚</font></font></p><br>
<h1 id="zaklyuchenie"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">çµè«–</font></font></h1><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã“ã®è¨˜äº‹ã§ã¯ã€å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ“ä½œã™ã‚‹ã¨ãã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã®å±æ€§ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã•ã¾ã–ã¾ãªæ–¹æ³•ã‚’èª¿ã¹ã¦å®Ÿè£…ã—ã¾ã—ãŸã€‚ </font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">å½¼ã‚‰ãŒã‚ãªãŸã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§é‡å®ã™ã‚‹ã¨æ€ã„ã¾ã™ã€‚</font></font></p></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja504732/index.html">ãƒ‡ã‚¸ã‚¿ãƒ«ã‚½ãƒ©ãƒ­ã‚°ãƒ©ãƒ•ã‚£ãƒ¼</a></li>
<li><a href="../ja504734/index.html">PHPãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆNo.181ï¼ˆ2020å¹´5æœˆ18æ—¥-6æœˆ1æ—¥ï¼‰</a></li>
<li><a href="../ja504736/index.html">ãƒã‚·ãƒ³ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒ©ã‚¸ã‚¨ãƒ¼ã‚¿ãƒ¼ã®æ¬ é™¥ã‚’è¦‹ã¤ã‘ã‚‹</a></li>
<li><a href="../ja504740/index.html">ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã«ãŠã‘ã‚‹ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é€²åŒ–</a></li>
<li><a href="../ja504742/index.html">ãƒã‚¤ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«ãŠã‚ˆã³ãƒãƒ«ãƒã‚¹ãƒšã‚¯ãƒˆãƒ«è¡›æ˜Ÿã‹ã‚‰ã®ç„¡æ–™ã§å…¥æ‰‹å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®æ¯”è¼ƒ</a></li>
<li><a href="../ja504748/index.html">Djangoã®ã‚ªãƒ³ã‚¶ãƒ•ãƒ©ã‚¤ã§ã®ç°¡å˜ãªé¡”èªè­˜</a></li>
<li><a href="../ja504752/index.html">åˆ—è»Šã‚’è§£æ”¾ã—ã¾ã™ã€‚Yandexãƒ¬ãƒãƒ¼ãƒˆ</a></li>
<li><a href="../ja504754/index.html">Metastocle-åˆ†æ•£å‹ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹</a></li>
<li><a href="../ja504756/index.html">æ©Ÿæ¢°å­¦ç¿’ã‚’å­¦ã¶å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“</a></li>
<li><a href="../ja504758/index.html">ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã€PonyFinalãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢ã«ã‚ˆã‚‹æ–°ãŸãªæ”»æ’ƒã®å±é™ºæ€§ã‚’è­¦å‘Š</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥇 🚵🏾 👩🏽‍🏭 Pengenalan Bicara: Kursus Pengantar yang Sangat Singkat 🧔 👉🏿 🏖️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hampir mustahil untuk memberi tahu orang awam sesederhana mungkin tentang pekerjaan pengenalan ucapan komputer dan mengubahnya menjadi teks. Tidak ada...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pengenalan Bicara: Kursus Pengantar yang Sangat Singkat</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/toshibarus/blog/490732/"><img src="https://habrastorage.org/webt/tz/sh/ll/tzshllxzf2iddwai7sredy3edie.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hampir mustahil untuk memberi tahu orang awam sesederhana mungkin tentang pekerjaan pengenalan ucapan komputer dan mengubahnya menjadi teks. </font><font style="vertical-align: inherit;">Tidak ada satu cerita pun tentang ini yang lengkap tanpa rumus dan istilah matematika yang rumit. </font><font style="vertical-align: inherit;">Kami akan mencoba menjelaskan sejelas dan sesederhana mungkin bagaimana ponsel cerdas Anda memahami ucapan, ketika mobil telah belajar mengenali suara manusia dan di area tak terduga apa teknologi ini digunakan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Peringatan yang diperlukan: jika Anda seorang pengembang atau, terutama, ahli matematika, Anda tidak akan belajar sesuatu yang baru dari pos dan bahkan mengeluh tentang sifat ilmiah yang tidak memadai dari materi tersebut. </font><font style="vertical-align: inherit;">Tujuan kami adalah untuk memperkenalkan pembaca yang belum tahu tentang teknologi bicara dengan cara yang paling sederhana dan memberi tahu bagaimana dan mengapa Toshiba mengambil kreasi suaranya AI.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tonggak penting dalam sejarah pengenalan ucapan</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sejarah pengenalan pembicaraan manusia oleh mesin elektronik dimulai sedikit lebih awal daripada kebiasaan untuk berpikir: dalam kebanyakan kasus lazim untuk menghitung mundur dari tahun 1952, tetapi pada kenyataannya salah satu perangkat pertama yang menanggapi perintah suara adalah robot Televox, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yang sudah kita tulis</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dibuat pada tahun 1927 di AS, robot Herbert Televox adalah perangkat sederhana di mana berbagai relay bereaksi terhadap suara frekuensi yang berbeda. Robot itu memiliki tiga garpu tala, masing-masing bertanggung jawab atas nadanya. Tergantung pada garpu tala yang bekerja, satu atau yang lain relay diaktifkan.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/90/pq/4i/90pq4ixpys3c8uevjp-ovvydfny.jpeg" alt="gambar"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bahkan, seluruh "pengisian" Televox, termasuk sistem pengenalan perintah, terletak di rak di area tubuh "robot". Mustahil untuk menutup penutupnya, jika garpu tala tidak benar "mendengar" suara. Sumber: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acme Telepictures / Wikimedia.</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Mungkin untuk berkomunikasi dengan Televox sebagai sinyal terpisah dengan peluit, dan dalam isyarat verbal pendek - garpu tala mereka juga diletakkan dalam urutan suara. Pencipta robot, Roy Wensley, bahkan menggelar demonstrasi fantastis untuk masa itu, mengatakan perintah "Sesame, open", di mana Televox menyalakan relay yang bertanggung jawab untuk membuka pintu. Tidak ada teknologi digital, jaringan saraf, AI dan pembelajaran mesin - hanya teknologi analog!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Penemuan kunci berikutnya yang membuka jalan bagi pengakuan sejati ucapan manusia adalah mesin Audrey, yang dikembangkan pada tahun 1952 di Bell Labs Innovation Forge. Audrey yang besar mengkonsumsi banyak listrik dan ukuran kabinet yang bagus, tetapi semua fungsinya turun untuk mengenali angka yang diucapkan dari nol menjadi sembilan. Hanya sepuluh kata, ya, tapi jangan lupa bahwa Audrey adalah mesin analog. </font></font><br>
<img src="https://habrastorage.org/webt/vd/1q/eb/vd1qebrer6czotgwty3tdyfp15i.png" alt="gambar"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sayangnya, kisah Audrey belum melestarikan foto publik, hanya ada konsep. Sederhana di atas kertas, sulit diterjemahkan - menurut memoar orang-orang sezaman, komponen Audrey menempati seluruh kabinet. Sumber: Bell Labs</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ini bekerja seperti ini: penyiar berbicara angka ke mikrofon, membuat interval setidaknya 350 ms antara kata-kata, Audrey mengubah suara yang didengarnya menjadi sinyal listrik dan membandingkannya dengan sampel yang direkam dalam memori analog. Menurut hasil perbandingan, mobil menyoroti nomor di dasbor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Itu adalah terobosan, tetapi tidak ada manfaat nyata dari Audrey - mesin mengenali suara penciptanya dengan akurasi 97%, pembicara terlatih lainnya menerima akurasi 70-80%. Orang asing yang pertama kali menghubungi Audrey, tidak peduli seberapa keras mereka mencoba, melihat nomor mereka di papan skor hanya dalam 50% kasus.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Terlepas dari hasil revolusioner pada masanya, Audrey tidak menemukan, dan tidak dapat menemukan aplikasi praktis. </font><font style="vertical-align: inherit;">Diasumsikan bahwa sistem dapat diadaptasi daripada operator telepon, namun demikian, layanan manusia lebih nyaman, lebih cepat dan jauh lebih dapat diandalkan daripada Audrey.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/rQco1sa9AwU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Presentasi mirip dengan Audrey, hanya jauh lebih kecil, mesin - IBM Shoebox. </font><font style="vertical-align: inherit;">Kecepatan kotak sepatu terlihat jelas. </font><font style="vertical-align: inherit;">Mesin juga bisa melakukan operasi matematika sederhana penjumlahan dan pengurangan</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada awal 1960-an, pekerjaan membuat mesin untuk pengenalan suara dilakukan di Jepang, Inggris, Amerika Serikat dan bahkan Uni Soviet, di mana mereka menciptakan algoritma yang sangat penting untuk transformasi dinamis timeline (DTW), dengan bantuan yang memungkinkan untuk membangun sistem yang tahu sekitar 200 kata. Tetapi semua perkembangan itu mirip satu sama lain, dan prinsip pengakuan menjadi kelemahan umum: kata-kata dianggap sebagai sidik jari suara yang tidak terpisahkan, dan kemudian mereka diverifikasi dengan basis sampel (kamus). Setiap perubahan dalam kecepatan, warna nada dan kejelasan pengucapan kata-kata secara signifikan mempengaruhi kualitas pengakuan. Para ilmuwan memiliki tugas baru: mengajar mesin untuk mendengar suara, fonem atau suku kata individu dan kemudian membuat kata-kata dari mereka. Pendekatan semacam itu akan memungkinkan untuk meratakan efek mengubah pembicara, ketika, tergantung pada pembicara, tingkat pengakuan bervariasi tajam.</font></font><br>
<br>
<i> —     ,           . ,   « »  «»       «».   «»   « »  « »      «»,    —  «».  ,  ,   . </i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada tahun 1971, Badan Proyek Penelitian Lanjutan (DARPA) Departemen Pertahanan meluncurkan program lima tahun dengan anggaran $ 15 juta, di mana tugasnya adalah menciptakan sistem pengakuan yang tahu setidaknya 1.000 kata. Pada 1976, Universitas Carnegie Mellon memperkenalkan Harpy, yang mampu mengoperasikan kamus berisi 1011 kata. Harpy tidak membandingkan kata-kata yang sepenuhnya didengar dengan sampel, tetapi membaginya menjadi alofon (sampel suara fonem tergantung pada huruf di sekitarnya). Ini adalah keberhasilan lain, yang menegaskan bahwa masa depan terletak pada pengenalan fonem-fonem individual, dan bukan keseluruhan kata-kata. Namun, di antara kekurangan Harpy adalah tingkat pengakuan alofon yang sangat rendah (pengucapan fonem) - sekitar 47%. Dengan kesalahan yang begitu tinggi, bagian kesalahan bertambah setelah volume kamus.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/32KKg3aP3Vw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deskripsi tentang cara kerja Harpy. Video program tidak bertahan.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pengalaman Harpy telah menunjukkan bahwa membangun kamus sidik jari suara holistik tidak berguna - hanya meningkatkan waktu pengenalan dan secara drastis mengurangi keakuratan, sehingga para peneliti di seluruh dunia telah mengambil jalur yang berbeda - mengenali fonem yang mengenali. Pada pertengahan 1980-an, mesin IBM Tangora dapat belajar memahami ucapan setiap pembicara dengan aksen, dialek, dan pelafalan, hanya membutuhkan pelatihan 20 menit, di mana basis data fonem dan sampel alofon dikumpulkan. Penggunaan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">model Markov tersembunyi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> juga meningkatkan kosakata IBM Tangora menjadi 20.000 kata yang mengesankan - 20 kali lebih banyak dari yang Harpy miliki, dan sudah sebanding dengan kosakata remaja itu.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Semua sistem pengenalan ucapan dari tahun 1950-an hingga pertengahan 1990-an tidak tahu cara membaca bahasa lisan alami seseorang - mereka harus mengucapkan kata-kata secara terpisah, berhenti di antara mereka. Peristiwa yang benar-benar revolusioner adalah pengenalan model Markov tersembunyi yang dikembangkan pada 1980-an - model statistik yang membangun asumsi yang tepat tentang unsur-unsur yang tidak diketahui berdasarkan unsur-unsur yang diketahui. Sederhananya, dengan hanya beberapa fonem yang dikenali dalam satu kata, model Markov yang tersembunyi dengan sangat akurat memilih fonem yang hilang, dengan demikian sangat meningkatkan keakuratan pengenalan suara.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada tahun 1996, program komersial pertama kali muncul, yang mampu membedakan bukan kata-kata individual, tetapi aliran ucapan alami yang berkelanjutan - IBM MedSpeak / Radiology. IBM adalah produk khusus yang digunakan dalam pengobatan untuk menggambarkan proses rontgen yang disampaikan oleh seorang dokter selama penelitian. Di sini, kekuatan komputer akhirnya menjadi cukup untuk mengenali kata-kata individual "dengan cepat". Plus, algoritme menjadi lebih sempurna, pengenalan jeda mikro yang benar antara kata-kata yang diucapkan telah muncul.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mesin universal pertama untuk mengenali ucapan alami adalah program Dragon NaturallySpeaking pada tahun 1997. Saat bekerja dengannya, penyiar (yaitu pengguna) tidak perlu menjalani pelatihan atau beroperasi dengan kosa kata tertentu, seperti dalam kasus MedSpeak, siapa pun, bahkan anak kecil, dapat bekerja dengan NaturallySpeaking, program tidak menetapkan aturan pengucapan. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xj/m6/w-/xjm6w-kpgryltox7wquuvpl8db4.png" alt="gambar"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Meskipun keunikan Dragon NaturallySpeaking, browser TI tidak menunjukkan banyak antusiasme untuk mengenali ucapan alami. Di antara kekurangannya, kesalahan pengakuan dan pemrosesan perintah yang salah ditujukan untuk program itu sendiri dicatat. Sumber: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">itWeek</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Perlu dicatat bahwa mesin pengenalan siap kembali pada 1980-an, tetapi karena daya komputer tidak memadai, pengembangan Sistem Naga (sekarang dimiliki oleh Nuance Communications) tidak punya waktu untuk menentukan ruang antara kata-kata dengan cepat, yang diperlukan untuk mengenali ucapan alami. </font><font style="vertical-align: inherit;">Tanpa ini, kata-kata "selagi dirawat", misalnya, dapat didengar oleh komputer sebagai "lumpuh." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di depan semakin populernya sistem pengenalan suara, jaringan saraf, munculnya pencarian suara Google di perangkat seluler dan, akhirnya, asisten suara Siri, tidak hanya mengubah pidato menjadi teks, tetapi juga secara memadai menanggapi pertanyaan yang dibuat dengan cara alami.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bagaimana cara mendengar apa yang dikatakan dan memikirkan apa yang tidak terdengar?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saat ini, alat terbaik untuk membuat mesin pengenalan suara adalah jaringan saraf berulang (RNN), di mana semua layanan modern untuk mengenali suara, musik, gambar, wajah, objek, teks dibangun. RNN memungkinkan Anda untuk memahami kata-kata dengan akurasi ekstrim, serta memprediksi kata yang paling mungkin dalam konteks konteks jika itu tidak dikenali. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Klasifikasi temporal jaringan saraf model (CTC) memilih fonem individu dalam aliran audio yang direkam (kata, frasa) dan mengaturnya sesuai urutan pengucapannya. Setelah analisis berulang, CTC dengan sangat jelas mengidentifikasi fonem tertentu, dan rekaman teks mereka dibandingkan dengan database kata-kata dalam jaringan saraf dan kemudian berubah menjadi kata yang dikenal.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jaringan saraf disebut demikian karena prinsip kerja mereka mirip dengan kerja otak manusia. Pelatihan jaringan saraf sangat mirip dengan pelatihan manusia. Misalnya, agar anak yang sangat kecil belajar mengenali mobil dan membedakannya dari sepeda motor, Anda perlu setidaknya beberapa kali menarik perhatiannya ke berbagai mobil dan setiap kali mengucapkan kata yang sesuai: ini besar dan merah - mobil, dan hitam rendah ini - mobil, tapi ini dan ini adalah sepeda motor. Pada titik tertentu, anak akan menemukan pola dan rambu-rambu umum untuk mobil yang berbeda, dan akan belajar mengenali dengan benar di mana mobil itu, di mana jip, di mana sepeda motor, dan di mana ATV, bahkan jika lewat melihatnya melihat mereka di poster iklan di jalan. Dengan cara yang sama, jaringan saraf perlu dilatih dengan basis contoh - memaksanya untuk "mempelajari" ratusan dan ribuan varian pengucapan untuk setiap kata, huruf, fonem.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jaringan saraf berulang untuk pengenalan ucapan baik karena setelah lama melatih dasar berbagai pengucapan, ia akan belajar membedakan fonem dari kata-kata dan membuat kata-kata dari mereka terlepas dari kualitas dan sifat pelafalan. Dan bahkan "berpikir" dengan akurasi tinggi, dalam konteks kata, kata-kata yang tidak dapat dikenali secara jelas karena suara latar belakang atau pengucapan kabur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tetapi ada nuansa dengan prediksi RNN - jaringan saraf berulang dapat "memikirkan" kata yang hilang hanya dengan mengandalkan konteks terdekat sekitar lima kata. Di luar ruang ini, analisis tidak akan dilakukan. Dan terkadang dia sangat diperlukan! Sebagai contoh, untuk pengakuan, kami mengucapkan ungkapan “Penyair besar Rusia, Alexander Sergeyevich </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pushkin</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">", Di mana kata" Pushkin "(khususnya dalam huruf miring) diucapkan begitu tidak terdengar sehingga AI tidak dapat mengenalinya secara akurat. Tetapi jaringan saraf berulang, berdasarkan pengalaman yang diperoleh selama pelatihan, dapat menyarankan bahwa kata "Pushkin" paling sering ditemukan di sebelah kata "Rusia", "penyair", "Alexander" dan "Sergeyevich". Ini adalah tugas yang cukup sederhana untuk RNN ​​yang terlatih dalam teks-teks Rusia, karena konteks yang sangat spesifik memungkinkan kita untuk membuat asumsi dengan akurasi tertinggi.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dan jika konteksnya tidak jelas? Ambillah teks lain di mana satu kata tidak dapat dikenali: “Segalanya kami, Alexander Sergeyevich Pushkin, secara tragis meninggal di masa puncak hidupnya setelah duel dengan Dantes. Festival Teater Pushkin dinamai sesuai nama penyair. " Jika Anda menghapus kata "Pushkinsky", RNN tidak dapat menebaknya, berdasarkan konteks proposal, karena hanya menyebutkan festival teater dan referensi nama penyair yang tidak dikenal - ada banyak pilihan yang memungkinkan! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di sinilah arsitektur memori jangka pendek (LSTM) jangka panjang untuk jaringan saraf berulang, dibuat pada tahun 1997 ( </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">artikel rinci tentang LSTM</font></a><font style="vertical-align: inherit;"> ) ikut </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">berperan.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Ini secara khusus dikembangkan untuk menambah kemampuan RNN untuk memperhitungkan konteks yang jauh dari peristiwa yang sedang diproses - hasil dari penyelesaian masalah sebelumnya (yaitu, pengenalan kata) melewati seluruh proses pengenalan, tidak peduli berapa lama monolog itu, dan diperhitungkan dalam setiap kasus keraguan. Selain itu, jarak pemindahan hampir tidak berpengaruh pada efisiensi arsitektur. Dengan bantuan LSTM, jika perlu, jaringan kata akan memperhitungkan semua pengalaman yang tersedia dalam kerangka tugas: dalam contoh kami, RNN akan melihat pada kalimat sebelumnya dan menemukan bahwa Pushkin dan Dantes disebutkan sebelumnya, oleh karena itu, "Dengan Nama Penyair" kemungkinan besar menunjuk pada salah satunya. Karena tidak ada bukti keberadaan Festival Teater Dantes,kita berbicara tentang Pushkinsky (terlebih lagi karena jejak suara dari kata yang tidak dikenal sangat mirip) - festival semacam itu adalah di pangkalan untuk melatih jaringan saraf.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/P325_hrGsDI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Pengakuan asisten suara." </font><font style="vertical-align: inherit;">Ketika jaringan saraf yang terlatih berperan, seorang asisten suara dapat mengetahui dengan tepat apa yang harus dilakukan dengan “sandal hijau”</font></font></i><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bagaimana pengenalan ucapan membuat dunia menjadi tempat yang lebih baik?</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam setiap kasus, aplikasinya berbeda - ini membantu seseorang berkomunikasi dengan gadget, dan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menurut PricewaterhouseCooper</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , lebih dari setengah pengguna smartphone memberikan perintah suara ke perangkat - di antara orang dewasa (25-49 tahun), persentase mereka yang terus-menerus menggunakan antarmuka suara, bahkan lebih tinggi daripada di antara orang muda (18-25) - 65% berbanding 59%. </font><font style="vertical-align: inherit;">Dan di Rusia setidaknya sekali, setidaknya 71% dari populasi berkomunikasi dengan Siri, Google Assitant atau Alice. </font><font style="vertical-align: inherit;">45 juta orang Rusia terus berkomunikasi dengan Yandex dari Alice, dan Yandex.Maps / Yandex.Navigator hanya menyumbang 30% dari permintaan.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pengenalan ucapan benar-benar membantu seseorang di tempat kerja - misalnya, seperti yang kami katakan di atas, kepada dokter: dalam kedokteran sejak tahun 1996 (ketika IBM MedSpeak keluar), pengakuan digunakan untuk merekam anamnesis dan mempelajari gambar - dokter dapat terus bekerja tanpa terganggu oleh rekaman di komputer atau kartu kertas. Ngomong-ngomong, dikte dalam bidang kedokteran dilakukan tidak hanya di Barat - di Rusia ada program Voice2Med dari "Pusat Teknologi Pidato".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ada contoh lain, termasuk contoh kita sendiri. Pengorganisasian bisnis Toshiba melibatkan penyertaan penuh, yaitu hak dan peluang yang sama bagi orang-orang dengan berbagai kondisi kesehatan, termasuk bagi karyawan dengan gangguan pendengaran. Kami memiliki program korporat bernama Universal Design Advisor System, di mana orang-orang dengan berbagai jenis cacat berpartisipasi dalam pengembangan produk-produk Toshiba, memberikan saran untuk meningkatkan kenyamanan mereka bagi para penyandang cacat - yaitu, kami tidak berasumsi bagaimana kami bisa melakukan yang lebih baik, tetapi beroperasi dengan pengalaman nyata. dan ulasan karyawan.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beberapa tahun yang lalu, di kantor pusat Toshiba di Jepang, kami menghadapi tugas yang sangat menarik, membutuhkan pengembangan sistem pengenalan suara yang baru. Selama pengoperasian Sistem Penasihat Desain Universal, kami menerima wawasan penting: karyawan dengan gangguan pendengaran ingin berpartisipasi dalam diskusi di rapat dan kuliah secara real time, dan tidak terbatas pada membaca transkrip yang diproses beberapa jam atau beberapa hari kemudian. Memulai pengenalan suara melalui smartphone dalam kasus-kasus seperti itu memberikan hasil yang sangat lemah, sehingga spesialis Toshiba harus mulai mengembangkan sistem pengenalan khusus. Dan, tentu saja, kami segera mengalami masalah.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Percakapan sangat berbeda dari ucapan tertulis - kami tidak berbicara seperti kami menulis surat, dan percakapan nyata yang diterjemahkan ke dalam teks terlihat sangat ceroboh dan bahkan tidak dapat dibaca. Yaitu, bahkan jika kita mengubah percakapan pada glider pagi menjadi teks dengan akurasi tinggi, kita akan mendapatkan mishmash yang penuh dengan kata-kata parasit, kata seru dan "aaa", "uh" dan "mmm" yang bijaksana. Untuk menghilangkan transkripsi suara yang tidak perlu, kata-kata dan ekspresi emosi dalam teks, kami memutuskan untuk mengembangkan AI yang mampu secara maksimal mengenali secara akurat unsur-unsur yang tidak perlu dari ucapan sehari-hari, termasuk pewarnaan emosional dari beberapa kata (misalnya, "ya, baik" mungkin terdengar seperti skeptisisme atau bagaimana kejutan yang tulus, dan ini adalah arti yang berlawanan).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6z/vv/od/6zvvodwnihcvdqdqfv4uuprbtb4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sepertinya laptop dengan seperangkat peripheral untuk pengenalan suara menggunakan Toshiba AI (kiri) dan aplikasi dengan hasil untuk perangkat akhir (kanan). Sumber: Toshiba</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
LSTM sangat berguna di sini, yang tanpanya akurasi pengenalan tidak cukup untuk teks yang diterima untuk dibaca dan dipahami tanpa usaha. Selain itu, LSTM berguna tidak hanya untuk prediksi kata-kata yang lebih akurat dalam konteks, tetapi juga untuk pemrosesan jeda yang benar di tengah-tengah kalimat dan interjeksi-parasit - untuk ini kami mengajarkan jaringan saraf ini parasit dan jeda yang alami untuk percakapan sehari-hari.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apakah ini berarti bahwa sekarang jaringan syaraf dapat menghapus interjeksi dari transkrip? </font><font style="vertical-align: inherit;">Ya, itu bisa, tetapi ini tidak perlu. </font><font style="vertical-align: inherit;">Faktanya adalah bahwa (wawasan lain yang diterima) orang-orang dengan gangguan pendengaran dibimbing, termasuk oleh gerakan bibir pembicara. </font><font style="vertical-align: inherit;">Jika bibir bergerak, tetapi teks yang sesuai dengan gerakan ini tidak muncul di layar, ada perasaan bahwa sistem pengenalan telah melewatkan bagian dari percakapan. </font><font style="vertical-align: inherit;">Artinya, bagi seseorang yang tidak bisa mendengar, penting untuk mendapatkan informasi sebanyak mungkin tentang percakapan, termasuk jeda yang ditakdirkan dan mejometia. </font><font style="vertical-align: inherit;">Oleh karena itu, mesin Toshiba meninggalkan elemen-elemen ini dalam transkrip, tetapi secara real time meredupkan kecerahan huruf, membuatnya jelas bahwa ini adalah detail opsional untuk memahami teks.</font></font><br>
<br>
<div class="oembed"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.toshiba-clip.com/en/detail/7655</font></font></a></div><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Begitulah hasil pengakuan dengan cepat terlihat pada perangkat klien. </font><font style="vertical-align: inherit;">Bagian-bagian dari monolog yang tidak berarti dicat abu-abu.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Sekarang Toshiba AI bekerja dengan bahasa Inggris, Jepang, dan Cina, dan bahkan penerjemahan antar bahasa dapat dilakukan. </font><font style="vertical-align: inherit;">Tidak perlu menggunakannya untuk singkatan dengan cepat - AI dapat diadaptasi untuk bekerja dengan asisten suara, yang akhirnya belajar untuk cukup memahami interjeksi, jeda dan gagap ketika seseorang mengucapkan perintah. </font><font style="vertical-align: inherit;">Pada bulan Maret 2019, sistem ini berhasil digunakan untuk menambahkan subtitle ke siaran Konvensi Nasional IPSJ di Jepang. </font><font style="vertical-align: inherit;">Dalam waktu dekat - transformasi AI Toshiba menjadi layanan publik dan pengalaman dengan penerapan pengenalan suara dalam produksi.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id490720/index.html">Motor! atau Apa itu fisika game</a></li>
<li><a href="../id490722/index.html">Liburan jender di bidang TI. Bagaimana cara mencatat</a></li>
<li><a href="../id490726/index.html">Otentikasi pada peralatan jaringan melalui SSH menggunakan kunci publik</a></li>
<li><a href="../id490728/index.html">Minggu Keamanan 10: Konferensi RSA dan Kesadaran Cybersecurity</a></li>
<li><a href="../id490730/index.html">Intel x86 Root of Trust: hilangnya kepercayaan</a></li>
<li><a href="../id490734/index.html">Telur paskah di peta topografi Swiss</a></li>
<li><a href="../id490736/index.html">9 alat yang jelas untuk belajar dan memompa kosakata bahasa Inggris</a></li>
<li><a href="../id490738/index.html">Prinsip substitusi yang cepat</a></li>
<li><a href="../id490740/index.html">Kerusakan seksual bukan hanya pengacakan</a></li>
<li><a href="../id490742/index.html">Era baru dalam robotika telah dimulai</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧟 👩‍💼 ☎️ コンピューターが画像を驚くほどよく認識する方法を学習した方法 🕡 🙏🏼 👨🏼‍💻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="2012年の重要な科学研究により、画像認識ソフトウェアの分野が変わりました
 
 
 今日、たとえば、Googleフォトを開いて「ビーチ」と書いたり、過去10年間に訪れたさまざまなビーチの写真をたくさん見ることができます。また、写真に署名したことはありません。Googleは写真に基づいてビーチを認識...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>コンピューターが画像を驚くほどよく認識する方法を学習した方法</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455331/"><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2012年の重要な科学研究により、画像認識ソフトウェアの分野が変わりました</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/0d6/b8d/67e/0d6b8d67e771c94acab7f0ed50a54ba4.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今日、たとえば、Googleフォトを開いて「ビーチ」と書いたり、過去10年間に訪れたさまざまなビーチの写真をたくさん見ることができます。また、写真に署名したことはありません。Googleは写真に基づいてビーチを認識します。この一見つまらない機能は、「深い畳み込みニューラルネットワーク」と呼ばれる技術に基づいています。これにより、前の世代の技術では利用できなかった複雑な方法を使用してプログラムが画像を理解できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
近年、研究者たちは、より深いニューラルネットワーク（NS）を構築し、かつてないほど大きなデータセットでそれらをトレーニングするにつれて、ソフトウェアの精度が向上することを発見しました。これにより、計算能力に対する飽くなきニーズが生まれ、NvidiaやAMDなどのGPUメーカーが充実しました。数年前、Googleは国会用に独自の特別なチップを開発しましたが、他の企業はそれに追いついています。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
たとえばテスラでは、ディープラーニングのエキスパートであるAndrei Karpatiがオートパイロットプロジェクトの責任者に任命されました。現在、自動車メーカーは、オートパイロットの将来のバージョンでNSの作業を加速するために独自のチップを開発しています。またはAppleを例にとると、最新のiPhoneの中心であるA11およびA12チップに</font><font style="vertical-align: inherit;">は、NSを高速化し、画像認識および音声認識アプリケーションの動作を向上さ</font><font style="vertical-align: inherit;">せる</font><font style="vertical-align: inherit;">ニューラルエンジン</font><font style="vertical-align: inherit;">「</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルプロセッサ</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">」があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私がこの記事のためにインタビューした専門家は、特定の仕事へのディープラーニングブームの始まりを追跡します。主な著者であるAlex Krizhevskyにちなんで名付けられたAlexNet。 「2012年はAlexNetの取り組みが発表された画期的な年だったと</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">思い</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2012年まで、ディープニューラルネットワーク（GSS）は、モスクワ地域の世界ではちょっとした逆境でした。</font><font style="vertical-align: inherit;">しかし、その後、トロント大学のクリジェフスキーと彼の同僚は、画像認識のための権威ある競争に参加し、彼らのプログラムはそれ以前に開発されたすべてのものを根本的に正確に上回った。</font><font style="vertical-align: inherit;">ほぼ瞬時に、STSは画像認識の主要なテクノロジーになりました。</font><font style="vertical-align: inherit;">このテクノロジーを使用している他の研究者は、すぐに認識精度のさらなる改善を示しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、ディープラーニングについて詳しく説明します。</font><font style="vertical-align: inherit;">NSとは何か、それらがどのようにトレーニングされるのか、なぜそのようなコンピューティングリソースが必要なのかを説明します。</font><font style="vertical-align: inherit;">次に、特定のタイプのNS（ディープコンボリューションネットワーク）が画像をよく理解する理由を説明します。</font><font style="vertical-align: inherit;">心配しないでください、多くの写真があります。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューロンが1つある簡単な例</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「ニューラルネットワーク」の概念は漠然としているかもしれないので、簡単な例から始めましょう。国会に、緑、黄、赤の信号に基づいて車を運転するかどうかを決定させたいとします。 NSは、単一のニューロンでこの問題を解決できます。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/c00/2d0/dda/c002d0dda45d5fef70ab7a156ad8e7cd.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューロンは入力データ（1-オン、0-オフ）を受け取り、適切な重みを乗算し、重みのすべての値を合計します。次に、ニューロンは、ニューロンの「アクティブ化」のしきい値を定義するオフセットを追加します。この場合、出力が正の場合、ニューロンがアクティブになっていると考えられます-逆もまた同様です。ニューロンは、「緑-赤-0.5&gt; 0」という不等式に相当します。それが真であることが判明した場合、つまり、緑はオンで赤はオンではない場合、車は移動するはずです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際のNSでは、人工ニューロンは別のステップを踏みます。</font><font style="vertical-align: inherit;">重み付けされた入力を合計し、オフセットを追加することにより、ニューロンは非線形活性化関数を使用します。</font><font style="vertical-align: inherit;">多くの場合、シグモイドが使用されます。常に0から1の値を生成するS字型の関数です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アクティベーション関数を使用しても、単純な信号機モデルの結果は変わりません（必要なのは、0ではなく0.5のしきい値だけです）。</font><font style="vertical-align: inherit;">しかし、NSがより複雑な関数をモデル化するには、活性化関数の非線形性が必要です。</font><font style="vertical-align: inherit;">活性化関数がない場合、任意の複雑なNSはそれぞれ、入力データの線形結合に削減されます。</font><font style="vertical-align: inherit;">線形関数は、現実世界の複雑な現象をモデル化することはできません。</font><font style="vertical-align: inherit;">非線形活性化関数により、NSは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あらゆる数学関数</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を近似</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">できます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ネットワークの例</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、関数を近似するには多くの方法があります。 NSは、小さな代数、大量のデータ、および一連のコンピューティング能力を使用してそれらを「トレーニング」する方法を知っているという事実によって際立っています。特定のタスクのためにNSを直接プログラミングする代わりに、かなり一般的なNSから始めて、マークアップされた一連の例を調べ、できるだけ多くの例に正しいラベルが付けられるようにNSを変更するソフトウェアを作成できます。期待されるのは、最終的なNSがデータを要約し、以前はデータベースになかった例の正しいラベルを生成することです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この目標に至るプロセスは、AlexNetよりもずっと前に始まりました。 1986年に、3人の研究者が</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">画期的な</font></a><font style="vertical-align: inherit;">研究を発表しました</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">on backpropagation-複雑なNSの数学的トレーニングを実現するのに役立つテクノロジー。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
バックプロパゲーションがどのように機能するかを想像するために、Michael Nielsenが優れた</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">オンラインGO教科書</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で説明した単純なNSを見てみましょう</font><font style="vertical-align: inherit;">。ネットワークの目的は、28x28ピクセルの解像度で手書きの数字の画像を処理し、数字0、1、2などが書き込まれているかどうかを正しく判断することです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各画像は28 * 28 = 784の入力量で、それぞれ0から1までの実数で、ピクセルがどれだけ明るいか暗いかを示します。 Nielsenはこの種のNAを作成しました。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/fbf/85e/fe1/fbf85efe11ae6dc62ccd0257e2325229.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
中央と右列の各円は、前のセクションで調べたものと同様のニューロンです。各ニューロンは、入力の加重平均を取り、オフセットを追加し、アクティブ化関数を適用します。左側の円はニューロンではなく、ネットワーク入力を表しています。また、図には8つの入力円しか表示されていませんが、実際には、784個あります（各ピクセルに1つ）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
右側の10個のニューロンはそれぞれ独自の番号を「トリガー」する必要があります。最初のニューロンは手書きの0が入力されたときに（この場合のみ）オンになり、2番目のニューロンは手書きの1が表示されたときに（そしてそれだけ）オンになります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各ニューロンは、前の層の各ニューロンからの入力を認識します。</font><font style="vertical-align: inherit;">したがって、中央の15個のニューロンのそれぞれが784個の入力値を受け取ります。</font><font style="vertical-align: inherit;">これらの15個のニューロンのそれぞれには、784個の入力値のそれぞれに対する重みパラメーターがあります。</font><font style="vertical-align: inherit;">つまり、このレイヤーのみに15 * 784 = 11 760の重みパラメーターがあります。</font><font style="vertical-align: inherit;">同様に、出力層には10個のニューロンが含まれ、それぞれが中間層の15個すべてのニューロンから入力を受け取り、さらに15 * 10 = 150の重みパラメーターを追加します。</font><font style="vertical-align: inherit;">さらに、ネットワークには25の変位変数があります— 25のニューロンのそれぞれに1つです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワークのトレーニング</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トレーニングの目的は、これらの11,935パラメータを微調整して、ネットワークが手書きの数字の画像を提供するときに、目的の出力ニューロン（およびそれのみ）がアクティブになる可能性を最大化することです。</font><font style="vertical-align: inherit;">これは、よく知られている一連の画像MNISTを使用して行うことができます。MNISTでは、28x28ピクセルの解像度で60,000のマークされた画像があります。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/16d/dab/2ee/16ddab2ee3bcd9e22d96f267e473a2f4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MNISTセットの60,000枚の画像のうち160枚は</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Nielsenで、74行の通常のPythonコードを使用してネットワークをトレーニングする方法を示しています</font><i><font style="vertical-align: inherit;">-MO</font></i><font style="vertical-align: inherit;">用のライブラリはありません。</font><font style="vertical-align: inherit;">学習は、これらの11,935個のパラメーター、重み、オフセットのそれぞれにランダムな値を選択することから始まります。</font><font style="vertical-align: inherit;">次に、プログラムは画像の例を使用して、それぞれの2つの段階を実行します。</font></font><br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 順方向伝搬ステップは、入力画像と現在のパラメーターに基づいてネットワーク出力を計算します。</font></font></li>
<li>               ,        .</li>
</ol><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
例。ネットワークが次の画像を受け取ったと仮定します。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/e22/129/af7/e22129af76f6376aaa204ae02164a790.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
適切に調整されている場合、ピン「7」は1になり、他の9つの結論は0になります。ただし、代わりに、出力「0」のネットワークの値が0.8であるとします。多すぎる！トレーニングアルゴリズムは、「0」の原因となるニューロンの入力の重みを変更して、次にこの画像が処理されるときに0に近づくようにします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このため、バックプロパゲーションアルゴリズムは、各入力重みの誤差勾配を計算します。これは、入力重量の特定の変化に対して出力エラーがどのように変化するかを示す尺度です。次に、アルゴリズムは勾配を使用して、各入力の重みをどれだけ変更するかを決定します。勾配が大きいほど、変更は強くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
言い換えると、トレーニングプロセスは、出力層のニューロンを「トレーニング」して、間違った答えにプッシュする入力（中間層のニューロン）に注意を向けず、正しい方向にプッシュする入力に注意を向けます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アルゴリズムは、他のすべての出力ニューロンに対してこのステップを繰り返します。これらの値を下げるために、ニューロン「1」、「2」、「3」、「4」、「5」、「6」、「8」、「9」（ただし「7」ではない）の入力の重みを減らします。出力ニューロン。出力値が高いほど、入力の重みに対する出力エラーの勾配が大きくなり、その重みは減少します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
また、その逆の場合、アルゴリズムは出力「7」の入力データの重みを増やします。これにより、次にこの画像が与えられたときにニューロンがより高い値を生成します。繰り返しになりますが、値が大きい入力ほど重みが大きくなるため、出力ニューロン「7」は次回これらの入力により注意を向けます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、アルゴリズムは中間層に対して同じ計算を実行する必要があります。各入力の重みを、ネットワークエラーを減らす方向に変更します。ここでも、出力「7」を1に近づけ、残りを0にします。ただし、各中間ニューロンには接続があります2つの側面で問題を複雑にするすべての10日間の休暇。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、各平均ニューロンの誤差勾配は、入力値だけでなく、次の層の誤差勾配にも依存します。ネットワークの後の層の誤差勾配が反対方向に伝播し、前の層の勾配を計算するために使用されるため、アルゴリズムは逆伝播と呼ばれます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
また、各中間ニューロンは、10日間すべてのオフの入力です。したがって、トレーニングアルゴリズムは、特定の入力重みの変化がすべての出力の平均誤差にどのように影響するかを反映する誤差勾配を計算する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
バックプロパゲーションは、丘を登るアルゴリズムです。丘を通過するたびに、出力値が特定の画像の正しい値に近づきますが、少しだけです。</font><font style="vertical-align: inherit;">アルゴリズムが見る例が多いほど、トレーニング例の最大数を正しく分類する最適なパラメーターのセットに向かって丘が高く登ります。</font><font style="vertical-align: inherit;">高精度を実現するには数千の例が必要であり、アルゴリズムはこのセットの各画像を何十回も循環させてから、その効果の増大を停止する必要がある場合があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nielsenは、これらの74行をPythonに実装する方法を示しています。</font><font style="vertical-align: inherit;">驚くべきことに、そのような単純なプログラムでトレーニングされたネットワークは、MNISTデータベースからの手書き数字の95％以上を認識できます。</font><font style="vertical-align: inherit;">追加の改善により、単純な2層ネットワークは98％以上の数値を認識できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">画期的なAlexNet </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
バックプロパゲーションのテーマの開発は1980年代に行われるはずであり、国会に基づくMOの急速な進歩をもたらしたと考えるかもしれませんが、これは起こりませんでした。</font><font style="vertical-align: inherit;">1990年代から2000年代の初めには、この技術に取り組む人々もいましたが、国会への関心は2010年代の初めまで勢いをつけませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">、ImageNetコンペティションで</font></a><font style="vertical-align: inherit;">追跡できます</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-スタンフォードフェイフェイリーのコンピューターサイエンティストが主催するMOでの年次大会。ライバルには毎年、トレーニング用に100万枚以上の同じ画像セットが与えられ、それぞれに「消防車」や「キノコ」から「チーター」まで、1000以上のカテゴリで手動でラベルが付けられています。参加者のソフトウェアは、セットに含まれていない他の画像を分類する可能性について判断されます。プログラムはいくつかの推測を与えることができ、最初の5つの推測の少なくとも1つが人が付けたマークと一致する場合、その作業は成功したと見なされます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
競争は2010年に始まり、深いNSは最初の2年間は大きな役割を果たしませんでした。最高のチームはさまざまなMOテクニックを使用し、かなり平均的な結果を達成しました。 2010年には、チームは28のエラー率で勝利しました。2011年には、25％のエラーで勝利しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして2012年に来た。トロント大学のチームが</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">入札を</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">行い、</font><font style="vertical-align: inherit;">後に筆頭執筆者のアレックスクリジェフスキーに敬意を表してアレックスネットと呼ばれ、ライバルたちをはるかに後世に残した。ディープNSを使用して、チームは16％のエラー率を達成しました。最も近い競合他社の場合、この数字は26でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
手書き認識の記事で説明されているNSには、25のニューロンとほぼ12,000の2つの層があります。 AlexNetははるかに大きく複雑でした。8つのトレーニング可能なレイヤー、65万個のニューロン、6千万個のパラメーターです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このサイズのNSをトレーニングするには、非常に高い処理能力が必要です。AlexNetは、最新のGPUで利用可能な大規模な並列化を利用するように設計されています。研究者たちは、ネットワークのトレーニング作業を2つのGPUに分割する方法を見つけました。それでも、厳しい最適化にもかかわらず、ネットワークトレーニングは、2012年に利用可能になったハードウェア（3 GBのメモリを搭載したNvidia GTX 580のペア）で5〜6日かかりました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AlexNetの結果の例を調査して、この画期的な進歩がどれほど深刻であったかを理解することは有用です。画像の例とネットワークの最初の5つの推測を分類別に示した科学的研究の画像を次に示します</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/d36/1ee/3b6/d361ee3b61cc19de787edda63d6e1e65.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。AlexNetは最初の画像の目盛りを認識できましたが、そこには小さなフォームしかありません。このソフトウェアはヒョウを正しく識別しただけでなく、ジャガー、チーター、ユキヒョウ、エジプトのマウなど、他の近いオプションも提供しました。 AlexNetは、シデの写真に「agaric」というタグを付けました。 「キノコ」だけがネットワークの2番目のバージョンでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「エラー」AlexNetも印象的です。彼女は、チェリーの束の後ろに立っているダルマチア人の写真を「ダルメシアン」とマークしましたが、公式のラベルは「チェリー」でした。 AlexNetは、写真にある種のベリーが含まれていることを認識しました。最初の5つのオプションには、「ブドウ」と「エルダーベリー」がありました。チェリーは認識されませんでした。木の上に座っているマダガスカルキツネザルの写真に、AlexNetは木の上に住んでいる小さな哺乳類のリストをもたらしました。私を含む多くの人々がここに間違った署名をしたと思います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
作業の質は印象的で、ソフトウェアが通常のオブジェクトをさまざまな向きや環境で認識できることが実証されました。 GNSはすぐに画像認識の最も人気のある技術になり、それ以来MOの世界はそれを放棄していません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「2012年のGOベースの手法が成功したため、2013年の競技者のほとんどは、深い畳み込みニューラルネットワークに切り替えました」と</font><font style="vertical-align: inherit;">ImageNetのスポンサー</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は書いてい</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">その後の数年間、この傾向は続き、受賞者は、AlexNetチームによって最初に適用された基本的なテクノロジーに基づいて取り組みました。</font><font style="vertical-align: inherit;">2017年までに、より深いNSを使用するライバルは、エラーのパーセンテージを3未満に大幅に減らしました。</font><font style="vertical-align: inherit;">タスクの複雑さを考えると、コンピューターはある程度、多くの人よりもうまく解決することを学ばなければなりません。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/433/872/5e1/4338725e10f14ecf679878fb267394c9.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">異なる年の画像の分類におけるエラーの割合</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">畳み込みネットワーク：概念</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
技術的には、AlexNetは畳み込みNSでした。このセクションでは、畳み込みニューラルネットワーク（SNA）の機能と、このテクノロジが最新のパターン認識アルゴリズムに不可欠となった理由を説明します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以前に考えられていた手書き認識の単純なネットワークは完全に接続されていました。第1層の各ニューロンは、第2層の各ニューロンの入力でした。このような構造は、28x28ピクセルの画像で数字を認識する単純なタスクで非常にうまく機能します。しかし、それはうまくスケーリングしません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
MNIST手書き数字データベースでは、すべての文字が中央揃えになっています。たとえば、7は常に上部と右側にいくつかの暗いピクセルがあり、左下隅は常に白であるため、これは学習を大幅に簡略化します。ゼロでは、ほとんどの場合、中央に白い点があり、端に暗いピクセルがあります。シンプルで完全に接続されたネットワークは、このようなパターンを非常に簡単に認識できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、大きな画像のどこにでも配置できる数字を認識できるNSを作成したいとしましょう。完全に接続されたネットワークは、画像の異なる部分にあるフォームの類似の特徴を認識する効果的な方法がないため、このようなタスクではうまく機能しません。トレーニングデータセットで7のほとんどが左上隅にある場合、ネットワークは左上隅の7を画像の他のどの部分よりも認識しやすくなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
理論的には、この問題は、可能な位置のそれぞれに各桁の多くの例があることを確認することで解決できます。しかし実際には、これはリソースの大きな浪費になります。画像サイズとネットワーク深度が増加すると、リンクの数、および重みパラメータの数が爆発的に増加します。適切な精度を達成するには、さらに多くのトレーニング画像（および計算能力）が必要になります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークが画像の1つの場所にある形状を認識することを学習する場合、この知識を適用して画像の他の部分の同じ形状を認識できる必要があります。 SNAは、この問題に対するエレガントなソリューションを提供します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「ステンシルを取り、画像のすべての場所に貼り付けるようなものです」とAI研究者のJai Teng氏は述べています。 -犬の写真が描かれたステンシルがあり、それを画像の右上隅に最初に添付して、そこに犬がいるかどうかを確認しますか？そうでない場合は、ステンシルを少しシフトします。画像全体についても同様です。犬の絵がどこにあってもかまいません。ステンシルは彼女と一致します。犬の独自の分類を学習するためにネットワークの各部分を必要としない。」</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
大きな画像を取り、それを28x28ピクセルの正方形に分割したとします。</font><font style="vertical-align: inherit;">次に、以前に調べた手書きを認識する、完全に接続されたネットワークの各四角形にフィードできます。</font><font style="vertical-align: inherit;">正方形の少なくとも1つで出力「7」がトリガーされた場合、これは画像全体に7があることを示します。</font><font style="vertical-align: inherit;">これはまさに畳み込みネットワークが行うことです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlexNetでのたたみ込みネットワークのしくみ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
畳み込みネットワークでは、このような「ステンシル」は特徴検出器として知られ、それらが研究する領域は受容野として知られています。実際の特徴検出器は、一辺が28ピクセルの正方形よりもはるかに小さいフィールドで機能します。 AlexNetでは、最初の畳み込み層の特徴検出器は、サイズが11x11ピクセルの受容野で機能しました。その後の層では、受容野は3〜5ユニット幅でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
トラバーサル中、入力画像の標識の検出器は、標識のマップを生成します。2次元の格子では、画像のさまざまな部分で検出器がどれだけ強くアクティブ化されたかが記録されます。通常、畳み込み層には複数の検出器があり、それぞれが異なるパターンを検索して画像をスキャンします。 AlexNetは、最初のレイヤーに96個のフィーチャー検出器を備えており、96個のフィーチャーカードを配布しました。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/94f/1a0/c3d/94f1a0c3deacf7903606f4ecaf040b20.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これをよりよく理解するには、ネットワークをトレーニングした後、96個のAlexNetファーストレイヤー検出器のそれぞれによって調査されたパターンの視覚的表現を検討してください。水平線または垂直線、明るい色から暗い色への変化、チェスパターン、および他の多くの形態を探す検出器があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
カラー画像は通常、ピクセルごとに3つの数値（赤、緑、青の値）を持つピクセルマップとして表されます。 AlexNetの最初のレイヤーはこのビューを受け取り、96の数字を使用してビューに変換します。この画像の各「ピクセル」には、各特徴検出器に1つずつ、96個の値があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この例では、96個の値の最初の値が、画像内のいずれかの点がこのパターンに一致するかどうかを示しています。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/260/3fa/933/2603fa9332cbf509d9afd9dc1870e53a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2番目の値は、一部のイメージポイントがそのようなパターンと一致する</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/a0b/736/b01/a0b736b01ab683e1dfbd229e29904500.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
かどうかを示します。3番目の値は、一部のイメージポイントがそのようなパターンと一致するかどうかを示します</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bd9/a72/09c/bd9a7209cb808f24e18d54327974a0e7.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。最初のAlexNetレイヤーの93個の特徴検出器についても同様です。最初のレイヤーは画像の新しい表現を提供します。各ピクセルは96次元のベクトルです（この表現は4倍に削減されることについては後で説明します）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これはAlexNetの最初の層です。次に、さらに4つの畳み込み層があり、それぞれが前の1つの出力を入力として受け取ります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
見てきたように、最初のレイヤーは、水平線と垂直線、明から暗への移行、曲線などの基本的なパターンを示しています。 2番目のレベルでは、これらをやや複雑なフォームを認識するためのビルディングブロックとして使用します。たとえば、2番目のレイヤーは、曲線を見つける1番目のレイヤーの特徴検出器の出力の組み合わせで円を見つける特徴検出器を持つことができます。 3番目のレイヤーは、2番目のレイヤーの機能を組み合わせることにより、さらに複雑な形状を見つけます。 4番目と5番目は、さらに複雑なパターンを見つけます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
研究者のマシューツァイラーとロブファーガスは2014年</font><font style="vertical-align: inherit;">に</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">優れた</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">研究を発表</font><font style="vertical-align: inherit;">しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼らの作品から取った次のスライドショーでは、最初の写真を除く各写真に2つの半分があります。右側には、特定の機能検出器を強力にアクティブ化したサムネイルの例が表示されます。それらは9つにまとめられ、各グループはその検出器に対応しています。左側は、このサムネイルのどのピクセルが一致に最も関与しているかを示すマップです。犬、ロゴ、ホイールなどに強く反応する機能検出器があるため、これは5番目のレイヤーで特に明白です。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/a2c/beb/74e/a2cbeb74e2f71a9b1b84fbea587294b2.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1番目のレイヤー-単純なパターンと形状</font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/701/ebd/501/701ebd5013d881b6892c66c3fb63d77f.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。2番目のレイヤー-小さな構造が表示され始めます</font></font></i><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">。3番目のレイヤーの</font></i><i><font style="vertical-align: inherit;">特徴</font></i><i><font style="vertical-align: inherit;">検出器は、車のホイール、ハニカム、さらには人々のシルエットなど、より複雑な形状を認識でき</font></i><i><font style="vertical-align: inherit;">ます。</font></i></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/34d/283/91a/34d28391a4bb2d0804e15d12992208ba.png"><br>
<i><font style="vertical-align: inherit;"></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/41a/ee2/cb6/41aee2cb61324edc33313a0b01c874b5.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4番目のレイヤーでは、犬の顔や鳥の足などの複雑なフォームを区別できます。5番目のレイヤーでは、</font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/04b/96a/baa/04b96abaa00cf8ed2dcb994d56a5af3f.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">非常に複雑なフォームを認識できます。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
画像を見ると、後続の各レイヤーが次第に複雑化するパターンを認識することができます。最初のレイヤーは、何にも似ていない単純なパターンを認識します。 2番目は、テクスチャと単純な形状を認識します。 3番目のレイヤーでは、ホイールや赤オレンジ色の球体（トマト、てんとう虫、その他）などの認識可能なフォームが表示されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初の層では、受容野の側面は11で、後の層では3から5です。ただし、後のレイヤーは前のレイヤーによって生成されたフィーチャマップを認識するため、それぞれの「ピクセル」は元の画像のいくつかのピクセルを表します。したがって、各層の受容野には、前の層よりも最初の画像の大きな部分が含まれます。これは、後のレイヤーのサムネイルが前のレイヤーよりも複雑に見える理由の一部です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ネットワークの5番目の最後の層は、非常に広い範囲の要素を認識することができます。たとえば、5番目のレイヤーに対応する画像の右上隅から選択した次の画像を見てください。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/e82/3fb/895/e823fb8956c1b12d92b32607c41837ec.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
右側の9つの写真は同じではない場合があります。しかし、左側の9つのヒートマップを見ると、この機能検出器は写真の前景にあるオブジェクトに集中していないことがわかります。代わりに、彼はそれらのそれぞれの背景にある草に集中しています！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
明らかに、草の検出器は、特定しようとしているカテゴリの1つが「草」である場合に役立ちますが、他の多くのカテゴリにも役立ちます。 5つの畳み込み層の後、AlexNetは、手書き認識のためのネットワークのように、3つの層が完全に接続されています。これらのレイヤーは、5つの畳み込みレイヤーによって生成された各機能マップを調べ、画像を1000の可能なカテゴリの1つに分類しようとします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そのため、背景に草がある場合、画像に野生動物が含まれる可能性が高くなります。</font><font style="vertical-align: inherit;">一方、背景に草があると、家の中の家具のイメージになりにくい。</font><font style="vertical-align: inherit;">これらおよびその他の第5層の特徴検出器は、写真のありそうな内容に関する大量の情報を提供します。</font><font style="vertical-align: inherit;">ネットワークの最後の層は、この情報を総合して、図に一般的に何が描かれているのかについての事実に基づいた推測を提供します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">畳み込み層の違い：一般的な入力の重み</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
畳み込み層の特徴検出器が印象的なパターン認識を示すことを確認しましたが、これまでのところ、畳み込みネットワークが実際にどのように機能するかについては説明していません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
畳み込み層（SS）はニューロンで構成されます。それらは、他のニューロンと同様に、入力で加重平均を取り、アクティベーション関数を使用します。パラメータは、バックプロパゲーションテクニックを使用してトレーニングされます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、以前のNSとは異なり、SSは完全に接続されていません。各ニューロンは、前の層のニューロンのごく一部から入力を受け取ります。そして、重要なことに、畳み込みネットワークニューロンには共通の入力重みがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初のAlexNet SSの最初のニューロンをさらに詳しく見てみましょう。この層の受容野のサイズは11x11ピクセルであるため、最初のニューロンは画像の1隅にある11x11ピクセルの正方形を調べます。このニューロンは、この121ピクセルから入力を受け取り、各ピクセルには、赤、緑、青の3つの値があります。したがって、一般に、ニューロンには363個の入力パラメーターがあります。他のニューロンと同様に、これは363個のパラメーターの加重平均を取り、活性化関数をそれらに適用します。また、入力パラメーターは363であるため、重みパラメーターも363が必要です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
第1層の第2ニューロンは第1層と同様です。彼は11x11ピクセルの正方形も研究していますが、彼の受容野は最初のものと比べて4ピクセルシフトしています。 2つのフィールドは7ピクセルのオーバーラップがあるため、ネットワークは2つの正方形の接合部にある興味深いパターンを見失うことはありません。 2番目のニューロンは、11x11の正方形を記述する363個のパラメーターも取り、それぞれに重みを掛け、活性化関数を追加して適用します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、363個の重みの個別のセットを使用する代わりに、2番目のニューロンは最初のニューロンと同じ重みを使用します。最初のニューロンの左上のピクセルは、2番目の左上のピクセルと同じ重みを使用します。したがって、両方のニューロンが同じパターンを探しています。それらの受容野は、互いに対して単純に4ピクセルシフトしています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
当然、3つ以上のニューロンがあります。55x55の格子には3025のニューロンがあります。それらのそれぞれは、最初の2つと同じ363の重みのセットを使用します。すべてのニューロンが一緒に機能検出器を形成し、画像をスキャンして、どこにでも配置できる目的のパターンを探します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初のAlexNetレイヤーには96個の特徴検出器があることに注意してください。今述べた3025ニューロンは、これらの96個の検出器の1つを構成します。残りの95個はそれぞれ、3025個のニューロンの個別のグループです。 3025ニューロンの各グループは、363の重みの共通セットを使用しますが、95グループのそれぞれに独自の重みがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HFは、完全に接続されたネットワークに使用されるのと同じ逆伝播を使用してトレーニングされますが、畳み込み構造により、学習プロセスがより効率的かつ効果的になります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「コンボリューションを使用することは本当に役立ちます-パラメータは再利用できます」と、モスクワ地方の専門家で作家のショーン・ゲリッシュは言った。</font><font style="vertical-align: inherit;">これにより、ネットワークが学習する必要のある入力の重みの数が大幅に減少し、より少ないトレーニング例でより良い結果を生成できるようになります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像の一部で学習すると、画像の他の部分の同じパターンの認識が向上します。</font><font style="vertical-align: inherit;">これにより、ネットワークは、はるかに少ないトレーニング例で高いパフォーマンスを実現できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">人々は、深い畳み込みネットワークの力をすぐに理解しました。</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AlexNetの仕事は、モスクワ地方の学界で大きな反響を呼んだが、その重要性はIT業界ですぐに理解された。 Googleは特に彼女に興味を持っていました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2013年、GoogleはAlexNetの作者によって設立されたスタートアップを買収しました。同社はこのテクノロジーを使用して、Googleフォトに新しい写真検索機能を追加しました。 「私たちは高度な研究を行い、6か月余り後にそれを運用しました」とGoogleのチャックローゼンバーグは書いています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一方、中に</font><font style="vertical-align: inherit;">2013年には、GoogleがGoogleストリートビューのサービスの写真とアドレスを認識するためにGSSを使用する方法を説明してきました。 「私たちのシステムは、これらの画像から約1億の物理アドレスを抽出するのに役立ちました」と著者らは書いています。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
研究者たちは、NSの効果は深さが増すにつれて高まることを発見しました。 「このアプローチの有効性はSNAの深さとともに増加し、トレーニングしたアーキテクチャの中で最も深いものが最良の結果を示すことがわかりました」とGoogleストリートビューチームは書いています。 「私たちの実験は、より深いアーキテクチャはより高い精度を生み出すことができるが、効率が低下することを示唆しています。」</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、AlexNetの後、ネットワークはより深くなり始めました。グーグルチームは、AlexNetが2012年に勝利した2年後の2014年に競争に入札しました。これもディープSNAに基づいていましたが、グールジは22層のはるかに深いネットワークを使用してエラー率を達成しました6.7％-これは、AlexNetの16％と比較して大きな改善でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、同時に、より深いネットワークは、トレーニングデータのより大きなセットでのみよりよく機能しました。したがって、Gerrishは、ImageNetデータセットと競争がSNAの成功に大きな役割を果たしたと言います。 ImageNetコンテストでは、参加者には100万枚の画像が与えられ、1,000のカテゴリに分類するよう求められます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「トレーニング用に100万枚の画像がある場合、各クラスには1,000枚の画像が含まれます」とGerish氏は述べています。そのような大規模なデータセットがなければ、彼は「ネットワークをトレーニングするためのオプションが多すぎるだろう」と述べました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
近年、専門家は、より深く、より正確なネットワークをトレーニングするために、膨大な量のデータを収集することにますます焦点を合わせています。</font><font style="vertical-align: inherit;">そのため、ロボモービルを開発している企業は公道を走ることに集中しています。これらの旅行の画像とビデオは本社に送信され、企業のNSのトレーニングに使用されます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">深層学習ブームの計算</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
より深いネットワークとより大きなデータセットがNSパフォーマンスを向上させることができるという事実の発見は、ますます大きな計算能力に対する飽くなき渇望を生み出しました。 AlexNetの成功の主な要素の1つは、並列化可能なGPUで効率的に実行できるNSトレーニングで行列学習が使用されるという考えでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「NSはよく並列化されています」とMOの研究者であるJai Tenは言いました。ビデオカードに驚異的な並列処理能力を提供するグラフィックスカードは、NSに役立つことが証明されています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「GPUの作業の中心部分である非常に高速な行列乗算は、国会の作業の中心部分であることが判明しました」とTenは述べました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべては、GPU、Nvidia、およびAMDの主要メーカーで成功しています。両社は、MOアプリケーションのニーズに合わせて特別に調整された新しいチップを開発しました。現在、これらの会社のGPU販売の大部分を占めるのはAIアプリケーションです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2016年、Googleは、国会で運用するように設計された特別なチップ、Tensor Processing Unit（TPU）の作成を発表しました。 「Googleは2006年に特殊用途向け集積回路（ASIC）の作成を検討していましたが、この状況は2013年に緊急になりました」と</font><font style="vertical-align: inherit;">同社の広報担当者</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">昨年</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">書いてい</font></a><font style="vertical-align: inherit;">ます。 「当時、NSのコンピューティングパワーに対する需要が急速に高まっているため、データセンターの数を2倍にする必要があるかもしれないことに気づきました。」</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初は、Google独自のサービスだけがTPUにアクセスできましたが、後で会社はすべての人がクラウドコンピューティングプラットフォームを通じてこのテクノロジーを使用できるようにしました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、GoogleだけがAIチップに取り組んでいる会社ではありません。</font><font style="vertical-align: inherit;">ほんのいくつかの例：最新バージョンのiPhoneチップ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">には</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、NSでの操作用に最適化され</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">た</font></a><font style="vertical-align: inherit;">「ニューラルコア」があります。</font><font style="vertical-align: inherit;">Intelは</font><font style="vertical-align: inherit;">GO向けに最適化された独自のチップラインを</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">開発</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">しています。</font><font style="vertical-align: inherit;">テスラは最近</font><font style="vertical-align: inherit;">、自社のNSチップを支持して、Nvidiaからのチップの拒否を</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">発表しまし</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">た。</font><font style="vertical-align: inherit;">Amazonも</font><font style="vertical-align: inherit;">AIチップに</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">取り組ん</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">でいる</font><font style="vertical-align: inherit;">と噂されています</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ディープニューラルネットワークが理解しにくい理由</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークのしくみについて説明しましたが、ニューラルネットワークがなぜうまく機能するのかは説明しませんでした。膨大な数の行列計算により、コンピューターシステムがジャガーとチーターを、エルダーベリーとスグリをどのように区別できるかは明らかではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
おそらく、国会の最も顕著な品質は、彼らがそうしないということです。畳み込みは、NSがハイフネーションを理解することを可能にします-彼らは画像の右上隅からの画像が別の画像の左上隅の画像と類似しているかどうかを知ることができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし同時に、SNAは形状について何も考えていません。 45度回転したり2倍にしたりすると、2つの画像の類似性を認識できません。 SNAはオブジェクトの3次元構造を理解しようとせず、異なる照明条件を考慮することもできません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし同時に、NSは正面と側面の両方から撮られた犬の写真を認識することができ、犬が画像の小さな部分を占めるか、大きな部分を占めるかは問題ではありません。</font><font style="vertical-align: inherit;">どうやってやっているの？</font><font style="vertical-align: inherit;">十分なデータがある場合は、直接列挙による統計的アプローチでタスクに対処できることがわかります。</font><font style="vertical-align: inherit;">SNAは、特定の画像が異なる角度または異なる条件でどのように見えるかを「想像」できるように設計されていませんが、十分な数のラベル付きの例を使用して、単純な繰り返しで画像のすべての可能なバリエーションを学習できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
人間の視覚システムが同様に機能するという証拠があります。</font><font style="vertical-align: inherit;">2、3枚の写真を見てください。最初の写真を注意深く調べ、次に2番目の写真を開きます。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/d43/861/b2d/d43861b2ddeebcec572cab31c9ddb81a.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最初の写真</font></font></i><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2枚目の写真</font></font></b><div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/529/451/bde/529451bde2016793fd9cfe4ec092b46a.png"><br>
</div></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像の作成者は誰かの写真を撮り、目と口をひっくり返しました。人間の視覚システムはこの位置で目と口を見るのに慣れているため、逆さまに見ると写真は比較的正常に見えます。しかし、写真を正しい向きで見ると、顔が奇妙に歪んでいることがすぐにわかります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは、人間の視覚システムがNSと同じ粗雑なパターン認識技術に基づいていることを示唆しています。ほぼ常に1つの方向で見えるもの（人の目）を見ると、通常の方向でそれをはるかによく認識できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
NSは、利用可能なすべてのコンテキストを使用して画像を適切に認識します。たとえば、車は通常道路を走行します。ドレスは通常、女性の体に着用するか、クローゼットに掛けます。航空機は通常、空を背景に撃たれるか、滑走路を支配します。 NSにこれらの相関関係を具体的に教える人はいませんが、十分な数のラベル付きの例があれば、ネットワーク自体がそれらを学習できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2015年、Googleの研究者たちはNSをよりよく理解しようとして、「逆向きに実行しました」。 NSのトレーニングに画像を使用する代わりに、トレーニングされたNSを使用して画像を変更しました。たとえば、ランダムノイズを含む画像から始めて、徐々にそれを変更して、NSの出力ニューロンの1つを強くアクティブにしました。実際、彼らはNSに、認識されるように教えられたカテゴリの1つを「描く」ように依頼しました。興味深い事例の1つとして、ダンベルを認識するように訓練されたNSをアクティブにする画像をNSに生成させました。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/ece/817/a18/ece817a18e8c2fc63281cb0a1773ac91.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「もちろん、ここにはダンベルがありますが、それを持ち上げる筋肉の筋肉体の存在がなければ、ダンベルの1つの画像が完全であるようには見えません」とGoogleの研究者たちは書いています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一見奇妙に見えますが、実際は人の行動とそれほど変わりません。</font><font style="vertical-align: inherit;">画像に小さなオブジェクトやぼやけたオブジェクトが表示された場合、その周囲で手掛かりを探して、そこで何が発生するかを理解します。</font><font style="vertical-align: inherit;">人々は、明らかに、周りの世界の複雑な概念的理解を使用して、写真について異なる方法で話します。</font><font style="vertical-align: inherit;">しかし、最終的には、STSは画像に描かれているコンテキスト全体を最大限に活用するため、画像を適切に認識します。これは、人々が画像を行う方法と大差ありません。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja455312/index.html">珍しいチップの1ビットの全加算器</a></li>
<li><a href="../ja455314/index.html">サービスネットワークとは</a></li>
<li><a href="../ja455316/index.html">Bluetoothスタックを変更して、AAC、aptX、およびLDACコーデックなしでヘッドフォンのサウンドを改善します</a></li>
<li><a href="../ja455319/index.html">ワークフロー3Dアーティスト。大量の情報に溺れてはいけない。パート1</a></li>
<li><a href="../ja455321/index.html">日曜大工のホームオートメーション</a></li>
<li><a href="../ja455335/index.html">ペティペティジョイ＃3：詩</a></li>
<li><a href="../ja455337/index.html">最新のWindowsアップデートにPythonを追加したのは誰ですか？</a></li>
<li><a href="../ja455339/index.html">墓掘り、SQL Server、長年のアウトソーシング、最初のプロジェクト</a></li>
<li><a href="../ja455341/index.html">ITIL 4認定について知られていること</a></li>
<li><a href="../ja455343/index.html">Cisco 200-125 CCNA v3.0のトレーニング。9日目。スイッチの物理的な世界。パート2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
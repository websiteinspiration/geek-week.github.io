<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💪 👩🏾‍🏫 👎🏻 私は2週間で自分のdipfakeと$ 552を作成しました 🧑🏿‍🤝‍🧑🏼 👼🏽 😮</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="このビデオを作成することで、たくさんのことを学びました
 
Dipfake テクノロジーは、ディープニューラルネットワークを使用して、ビデオ内のある人を別の人に説得力をもって置き換えます。このテクノロジーには悪意のある使用の潜在的な可能性があり、ますます一般的になっています。この傾向の社会的および政...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>私は2週間で自分のdipfakeと$ 552を作成しました</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482684/"><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このビデオを作成することで、たくさんのことを学びました</font></font></h3><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/N6y0CA2Mcx8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
テクノロジー</font><font style="vertical-align: inherit;">は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ディープニューラルネットワーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">使用して</font><font style="vertical-align: inherit;">、ビデオ内のある人を別の人に説得力をもって置き換えます。このテクノロジーには悪意のある使用の潜在的な可能性があり、ますます一般的になっています。この傾向の社会的および政治的影響に関して、多くの良い記事がすでに書かれています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、これはそれらの1つではありません。代わりに、このテクノロジーを詳しく見ていきます。dipheyソフトウェアはどのように機能しますか？それらを作成するのはどれほど難しいですか、そして結果はどれほど良いですか？</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私は自分のディップビデオを作成して、これらの質問に答えるのが最善であると判断しました。編集者は私にソフトウェアを試してみるのに数日、クラウドコンピューティングに支払うために1000ドルをくれました。数週間後、記事の冒頭のビデオで結果を紹介しました。マークザッカーバーグが議会に向かって話しているビデオから始めて、彼の顔をスタートレック：次世代の司令官中尉（ブレントスピナー）に置き換えました。合計$ 552が使われました。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ビデオは完璧ではなかった。</font><font style="vertical-align: inherit;">データの顔のすべての詳細は送信されず、よく見ると、端にアーティファクトが表示されています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それでも、私のような初心者が説得力のあるビデオをすばやく簡単に作成できることは非常に注目に値します。</font><font style="vertical-align: inherit;">ディープテクノロジーテクノロジーは、今後数年間でより良く、より速く、より安価になると信じるすべての理由があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、私を手がかりにして、私の道を歩んでいきます。</font><font style="vertical-align: inherit;">ディープフェイクビデオを作成するために必要なすべての手順を説明します。</font><font style="vertical-align: inherit;">その過程で、このテクノロジーがどのように機能し、どのような制限があるのか​​を説明します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfeyksは多くの計算能力とデータを必要とします</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらのビデオはディープニューラルネットワークを使用して作成されているため、これらをビデオを「二重の偽物」と呼びます。過去10年間、コンピューター科学者は、ニューロンの層を追加することでニューラルネットワークがより強力になることを発見しました。しかし、ディープニューラルネットワークの可能性を最大限に引き出すには、大量のデータと巨大な計算能力が必要です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
dipfakesにも同じことが言えます。このプロジェクトでは、4つの強力なグラフィックカードを搭載した仮想マシンをレンタルしました。そして、これらすべての馬を使っても、モデルを訓練するのにほぼ1週間かかりました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mark ZuckerbergとDataの大量の画像も必要でした。私は38秒の長さのビデオを取得しましたが、トレーニングにはZuckerbergとDataの両方のはるかに長いビデオが必要でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これを行うために、私は彼らの顔を含む多数のビデオをダウンロードしました。スタートレックのクリップを含む14のクリップと、マークザッカーバーグの9つのクリップです。後者の中には、正式なレポート、テレビでのいくつかのインタビュー、さらにはザッカーバーグが彼の庭でバーベキューを準備しているビデオでさえありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべてのクリップをiMovieにアップロードし、ZuckerbergとDataの顔が含まれていないフレームを削除しました。</font><font style="vertical-align: inherit;">一番長い通路もバラバラに切りました。</font><font style="vertical-align: inherit;">dipfakeプログラムには、膨大な数の画像だけでなく、多数の異なる画像が必要です。</font><font style="vertical-align: inherit;">表情や照明条件を変えて、さまざまな角度から顔を撮影する必要がありました。</font><font style="vertical-align: inherit;">Zuckerbergがレポートを読み取る1時間のビデオは、同じ光の中で同じ角度から撮影され、同じ表情を示すため、5分のセグメントよりも価値のあるショットを生成できません。</font><font style="vertical-align: inherit;">そこで、数時間のビデオをデータで9分、ザッカーバーグで最大7分にトリミングしました。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faceswap：dipfakesを作成するためのソフトウェアパッケージ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、ソフトウェアを使用してdipfakeを実行します。まず、プログラムDeepFaceLabを使用してみましたが、かなりラフなビデオを作成することができました。次に、SFWdeepfakesフォーラムでアドバイスを求めたところ、Faceswapで何人かからアドバイスを受けました。人々は、このプログラムにはより多くの機能、より良いドキュメント、より良いオンラインサポートがあると指摘しました。私は彼らのアドバイスに従うことにしました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
FaceswapはLinux、Windows、Macで動作します。パッケージには、元のビデオのインポートから完成したdipfakeビデオの作成まで、dipfakeの作成のすべての段階で作業するためのツールが含まれています。ソフトウェアは直感的ではありませんが、プロセスのすべてのステップをカバーする詳細なトレーニング資料が付属しています。素材はFaceswapのクリエーターであるMatt Torahによって書かれました。MattTorahは、DiscordのDeepfakeチャンネルでチャットするのにも大いに役立ちました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswapには強力なグラフィックカードが必要です。私のMacBook Proはそれを処理できないことがわかっていました。編集オフィスの技術者に、クラウドサービスの大手プロバイダーからLinux仮想マシンをレンタルするよう依頼しました。私は、Nvidia K80 GPUと12GBのビデオメモリを備えた仮想マシンから始めました。数日後、2つのGPUを搭載したモデルに切り替え、次に4つのGPUに切り替えました。彼女には、それぞれ16 Gbのメモリを備えた4つのNvidia T4 Tensor Core GPU（さらに48のCPUと192 RAMがあり、ほとんどアイドル状態でした）がありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2週間の作業の後、522ドルの請求書を受け取りました。</font><font style="vertical-align: inherit;">もちろん、私はコンピュータを借りるのに便利なようにかなりの金額を費やしました。</font><font style="vertical-align: inherit;">Torahは私に、現時点でdipfakeの最も有益なハードウェアオプションは、8 GBのメモリを搭載したNvidia GTX 1070または1080カードであると語っていました。</font><font style="vertical-align: inherit;">そのような使用済みカードは数百ドルの費用がかかります。</font><font style="vertical-align: inherit;">1つの1080カードでは、4つのGPUほど高速なニューラルネットワークは学習できませんが、数週間待つことをいとわない場合は、同様の結果が得られます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswapのワークフローは、3つの基本的なステップで構成されています。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 抽出：ビデオをフレームにカットし、各フレームで顔を見つけ、各顔の位置を揃えて慎重にトリミングした画像を表示します。</font></font></li>
<li> :      -.                ,      .</li>
<li> :  ,    ,   ,   .          ,     ,     .</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3つのステップのそれぞれについて、人と機械にはまったく異なる時間が必要です。画像検索ソフトウェアは数分間実行されますが、結果を確認するのに数時間かかる場合があります。ソフトウェアは、各画像のすべての顔と、かなりの数の誤検知を記録します。良い結果を得るには、人はすべての結果を調べ、ソフトウェアが人のために取った不要な顔やすべてを取り除く必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
学習は簡単にセットアップでき、人間の関与はほとんど必要ありません。</font><font style="vertical-align: inherit;">ただし、良好な結果を得るには、数日または数週間のコンピューター時間がかかる場合があります。</font><font style="vertical-align: inherit;">12月7日に最終モデルのトレーニングを開始し、12月13日まで機能しました。</font><font style="vertical-align: inherit;">さらに1週間の作業の後で、私の二目盛りの品質が向上する可能性があります。</font><font style="vertical-align: inherit;">また、クラウドモンスターと4つの高度なグラフィックカードを使用しました。</font><font style="vertical-align: inherit;">電力が少ない単一のGPUを使用してコンピューターで作業している場合、優れたモデルをトレーニングするには数週間かかる場合があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後のステップである変換は、人とコンピュータの両方にとって迅速です。</font><font style="vertical-align: inherit;">適切にトレーニングされたモデルを受け取ることで、1分未満でdipfakeビデオを作成できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">二相性はどのように機能するか</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswap学習プロセスを説明する前に、その基盤となるテクノロジーがどのように機能するかを説明する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswapの中心にあるのは-と二相性を作成するための他の主要なソフトウェアパッケージ-オートエンコーダーです。これは、入力画像を受信して​​同一の画像を生成するようにトレーニングされたニューラルネットワークです。このスキル自体はそれほど有用ではないかもしれませんが、後で説明するように、これは、ディプフェイクを作成するプロセスの主要なビルディングブロックです。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/63f/e44/76b/63fe4476bd395c863cd0c9b71bf4cfbf.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自動エンコーダは、狭い端で接続された2つの漏斗の原理に従って構成されています。ネットワークの片側には、画像を受け取り、それを少数の変数に圧縮するエンコーダーがあります。 Faceswapで使用したモデルでは、これらは1024の32ビット浮動小数点数です。ニューラルネットワークの反対側にはデコーダがあります。彼は「潜伏空間」として知られているこのコンパクトな表現を受け取り、それを拡張しようとし、初期イメージを受け取りました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
エンコーダーからデコーダーに送信されるデータの量を人工的に制限することで、これら2つのネットワークは人間の顔のコンパクトな表現を開発します。エンコーダーは、ストレージの量を制限しながら、顔に関する情報をできるだけ多く保存しようとする不可逆圧縮アルゴリズムのようなものです。潜在空間は、たとえば、対象が見ている方向、目が開いているか閉じている、笑顔または眉をひそめているなど、重要な詳細を何らかの方法で抽出する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
自動エンコーダは、時間とともに変化する顔の機能のみを保存する必要があることが重要です。目の色や鼻の形など、変化のないものを保存する必要はありません。ザッカーバーグのすべての写真に青い目がある場合、ネットワークデコーダーは青い目で顔を自動的に描くことを学習します。あるイメージから別のイメージに移動しても変化しない狭い潜在スペースに情報を詰め込む必要はありません。後で見るように、オートエンコーダーが絶え間なく変化する顔の特徴に対して異なる態度を持っているという事実は、ジフフェイクを発行する能力にとって非常に重要です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークをトレーニングするための各アルゴリズムには、ネットワークの品質を評価して改善するための何らかの方法が必要です。多くの場合、これは、教師がトレーニングデータのセットから各要素に対して正しい答えを提供するときに、教師とのトレーニングを通じて行われます。自動エンコーダーの動作は異なります。彼らは単に自分の入力データを再現しようとしているだけなので、トレーニングソフトウェアは自分の仕事の質を自動的に判断できます。機械学習の専門用語では、これは教師なしの学習と呼ばれます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
他のニューラルネットワークと同様に、Faceswapオートエンコーダは、バックプロパゲーションを使用してトレーニングされます。トレーニングアルゴリズムは、特定の画像をニューラルネットワークに送り、出力のどのピクセルが入力と一致しないかを調べます。次に、最後のレイヤーのどのニューロンがエラーに最も大きく寄与したかを計算し、各ニューロンのパラメーターを少し修正して、より良い結果が得られるようにします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、これらのエラーは前のレイヤーに伝播し、各ニューロンのパラメーターが再度修正されます。エラーは、ニューラルネットワークの各パラメーター（エンコーダーとデコーダーの両方）が修正されるまで、この方法でさらに伝播します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、トレーニングアルゴリズムがネットワークの別の画像をフィードし、プロセス全体が再び繰り返されます。独自の入力を適切に再現する自動エンコーダを作成するには、数十万回のこのような繰り返しが必要になる場合があります。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/335/661/bb1/335661bb13300b80164987a1aa1dd420.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dipfakeソフトウェアは、2つの自動エンコーダを同時にトレーニングすることで機能します。1つは元の顔用、もう1つは新しい顔用です。トレーニングプロセス中、各オートエンコーダーには1人の画像のみが与えられ、オリジナルと非常に似た画像を生成するようにトレーニングされます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、落とし穴があります。両方のネットワークが同じエンコーダを使用しています。デコーダー-ネットワークの右側にあるニューロン-は分離したままで、それぞれが異なる面を与えるように訓練されています。しかし、ネットワークの左側のニューロンには、オートエンコーダーがトレーニングされるたびに変化する共通のパラメーターがあります。 ZuckerbergネットワークがZuckerbergの面でトレーニングされると、エンコーダーに属するネットワークの半分とデータ用のネットワークが変更されます。 DataのネットワークがDataの顔でトレーニングされるたびに、Zuckerbergエンコーダーはこれらの変更を継承します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その結果、2つの自動エンコーダーには、Zuckerbergの顔またはデータの顔のいずれかを「読み取る」ことができる1つの共通のエンコーダーがあります。エンコーダーの目的は、入力でZuckerbergの写真またはDataの写真を受け取ったかどうかに関係なく、頭の角度や眉の位置などの同じ表現を使用することです。そして、これは、エンコーダーで顔を圧迫したときに、任意のデコーダーを使用して開梱できることを意味します。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/ce8/0b6/670/ce80b6670b49be4b905f9ce520810931.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、この方法でいくつかの自動エンコーダーをトレーニングした後は、ダイフェークを作成する簡単なステップが残ります。デコーダーを交換します。 Zuckerbergの写真をエンコードしていますが、デコードのステップでデータデコーダーを使用しています。結果はデー​​タの再構成された写真ですが、Zuckerbergの元の写真と同じ頭の位置と表情を持っています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
覚えておきますが、潜在空間は人のさまざまな顔の特徴（表情、視線の方向、眉の位置）をキャプチャし、目の色や口の形などの一定のものがデコーダに与えられることを思い出しました。つまり、Zuckerberg画像をエンコードし、Dataデコーダーを使用してデコードすると、元のZuckerbergの顔の表情と向きを備えた、顔の形状などの永続的なデータ機能を持つ顔が得られます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このテクニックをZuckerbergのビデオの連続するフレームに適用すると、Dataの顔がZuckerbergが元のビデオで行ったのと同じ動き-笑顔、点滅、頭を回す-を実行する新しいビデオが得られます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この状況は対称的です。</font><font style="vertical-align: inherit;">ニューラルネットワークをトレーニングして、Zuckerbergの写真を受け取り、Dataの写真を発行するとき、同時に、Dataの写真を受け取り、Zuckerbergの写真を発行するようにトレーニングします。</font><font style="vertical-align: inherit;">Faceswapのビデオ変換ツール-dipfakeを作成するプロセスの最後のステップ-には、ユーザーがデコーダーを交換できる便利なチェックボックス「スワップモデル」が含まれています。</font><font style="vertical-align: inherit;">その結果、プログラムはザッカーバーグの顔の代わりにデータの顔を代用する代わりに、反対のことを行い、次のような非常に面白いビデオを作成します。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Fi7sj7SU1Vg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニングデータ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際には、diffakeを作成するときに良い結果を得るのは簡単ではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
前述のとおり、Dataには7分のビデオ、Zuckerbergには9分のビデオがありました。次に、Faceswap画像抽出ツールを使用してビデオをカットし、両方の男性の顔のトリミングされた画像を取得しました。ビデオには毎秒約30フレームが含まれていますが、6秒ごとにしか抽出していません。この方法はFaceswapのドキュメントで推奨されています。これは、さまざまな画像は数だけではなく、各フレームを保存すると非常に類似した画像が大量に作成されるためです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswap抽出ツールは、多くの誤検知を生成しました。彼はまた、いくつかのショットの背景に本当の顔を見つけました。数時間、私は2つの実験対象のいずれにも属さない抽出されたすべての写真を手動で削除しました。その結果、データの顔の画像は2598枚、ザッカーバーグの顔の画像は2224枚ありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そしてその瞬間、ついに、実際のモデルトレーニングに移る時がきました。現在、Faceswapには、異なる画像サイズをサポートし、異なるコンピューティングパワーを必要とする10の異なるdipfakeアルゴリズムが付属しています。最も気取らないものの中には、サイズが64ピクセル以下の顔画像で機能する「軽量」モデルがあります。ビデオメモリが2 GB以下のマシンで実行できます。他のモデルは、サイズが128、256、または512ピクセルの画像でも機能しますが、より多くのビデオメモリとより多くのトレーニング時間が必要です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
DeepFaceLabのアルゴリズムから派生したDFL-SAEモデルのトレーニングを始めました。ただし、Faceswapのドキュメントには、このモデルが「アイデンティティリーク」の影響を受け、1つの顔の一部の機能が別の顔に浸透する可能性があるという警告がありました。最初のテスト動画のペアで似たようなものを見たように思えたので、翌日、128ピクセルの画像で機能する悪役モデルに切り替えました。 Faceswapマニュアルでは、VRAMの負荷が非常に高く、「パラメータを調整せずに高解像度のモデルを取得したい場合に適した選択肢」と説明されています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それから私は待った。そして彼は待った。私の締め切りが金曜日に来たとき、学習プロセスはまだ終わっていませんでした-そしてこれは6日間のトレーニングの後です。その時、私のモデルはかなり良いディプフェイクを作り出しました。進行速度は遅くなりましたが、さらに1週間のコンピューター時間があると、より良い結果が得られる可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswapは、長時間のコンピューティング作業に適しています。</font><font style="vertical-align: inherit;">グラフィカルインターフェイスからトレーニングチームを開始すると、プログラムインターフェイスが定期的にプレビュー画面を更新し、ソフトウェアがDataとZuckerbergのポートレートを作成する方法の例を確認できます。</font><font style="vertical-align: inherit;">コマンドラインからトレーニングを実施したい場合は、これも可能です。</font><font style="vertical-align: inherit;">Faceswapインターフェースには、インターフェースで行われた現在の設定でモデルをトレーニングするために実行する必要がある正確なコマンドを提供する便利な「生成」ボタンがあります。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ディプフェイクはどれほど良かったですか？</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
学習プロセスでは、Faceswapは2つの自動エンコーダーそれぞれの「損失」の数値推定を常に表示します。これらの推定値は、ZuckerbergのオートエンコーダーがZuckerbergの写真をどれだけうまく再現できるか、およびDataのオートエンコーダーがDataの写真をどれだけうまく再現できるかを示しています。そして、金曜日に学習をやめたとき、これらの数はまだ減少していましたが、進行速度は大幅に低下しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、実際には、DataのデコーダーがZuckerbergの顔をDataの顔にどれだけうまく変換できるかが私たちにとって重要です。 「最終結果」がどのようになるかわからないため、正確な数値で作業の品質を測定することは不可能です。私たちにできる最善のことは、ビデオをレビューして、それが現実的に見えるかどうかを決定することです。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/zZEi1lHTdpY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上のビデオは、学習プロセスの4つの段階でのdipfakeの品質を示しています。 12月10日と12日のビデオは、部分的に訓練された悪役モデルを示しています。左上の12月6日のビデオは、別のモデルでの初期テストです。右下が最終結果です。訓練の過程で、彼の顔の細部はより明確になり、より信頼できるようになりました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
12月9日、3日間のトレーニングの後、私はSlackの編集部の内部チャンネルで予備ビデオを公開しました。ビデオは左上隅にあるものに似ていました。私たちの設計の第一人者であるAurich Lawsonは、皮肉なことに彼に反応しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「一般的に、それは見た目が悪い」と彼は書き、「それは説得力がないように見えます。偽物に見えない動画の1つを待っています。」</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼の批判には合理的な核があると思う。 FaceswapがZuckerbergよりもブレントスピナーに非常によく似た顔の画像をすばやく作成できたことに驚きました。ただし、よく見ると、デジタル詐欺の特徴的な兆候が見られます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一部のフレームでは、Dataの偽の顔とZuckerbergの頭の境界が完全に正しく表示されません。時々、ザッカーバーグの眉がデータの顔の下から覗きます。他の場所では、偽の顔の端がザッカーバーグの耳の数ピクセルで覆われています。人が手動で後処理するときに、コンポジションに関するこれらの問題を修正できる場合がありますが、誰かがビデオをフレームごとにスクロールして、それぞれのマスクを修正する必要があります。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/d8XknbnMs4c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、より根本的な問題は、dipfakeアルゴリズムではまだ人間の顔の細部を十分に再現できないことです。これは、開始ビデオと終了ビデオを並行して見るとかなり明白です。 Faceswapは、意外にもデータの顔の全体的な構造をよく伝えていました。しかし、1週間のトレーニングの後でも、顔はぼやけて見え、そこには十分な重要な詳細がありません。たとえば、dipheykasのソフトウェアは、人間の歯の描画にほとんど対応できません。ときどき歯がはっきり見えるようになり、次のフレームで歯が消えて黒くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これの主な理由の1つは、Faceswapタスクが高解像度で指数関数的に複雑になるためです。自動エンコーダーは、64x64ピクセルの画像に適しています。しかし、128x128ピクセルの画像（256ピクセル以上の画像は言うまでもありません）の細部を再現することは、すでにはるかに困難です。おそらくこれが、最も印象的なジフが、顔をクローズアップせずにかなり広い視野角を持っている理由の1つです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、これはdiphakeテクノロジの基本的な制限とは見なされません。今後数年間で、研究者はこれらの制限を克服できる技術を開発するでしょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多くの場合、dipheykaのソフトウェアの基礎は、生成競争ネットワーク（GSS）、またはソフトウェアが「表現」できるようにするそのようなニューラルネットワークとして誤って記述されています</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">存在しない人</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、物、風景。</font><font style="vertical-align: inherit;">実際、dipfeykiはオートエンコーダを使用して動作します。</font><font style="vertical-align: inherit;">ただし、GSSテクノロジーの最新の進歩は、ディファイクにはまだ改善の余地があることを示唆しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2014年に最初に登場したGSSは、粗い低解像度画像しか生成できませんでした。</font><font style="vertical-align: inherit;">しかし最近、研究者たちは、</font><font style="vertical-align: inherit;">最大1024ピクセルのサイズの写実的な画像を生成するGSSを作成する方法を</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">見つけまし</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">た。</font><font style="vertical-align: inherit;">これらの科学研究で使用されている特定の手法は、二相性の作成には適用できない場合がありますが、オートエンコーダ用の同様のテクノロジー、またはおそらく顔を置き換えるために設計されたまったく新しいニューラルネットワークアーキテクチャを開発する方法を想像するのは簡単です。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfakeパースペクティブ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
dipfakesの人気の高まりは明らかに憂慮すべきです。最近まで、人々は額面どおりの人物と簡単にビデオを撮ることができました。 dipheykaソフトウェアやその他のデジタルツールの登場により、動画に対する懐疑的な見方が高まっています。ある人がスキャンダラスなことを主張しているビデオを見つけた場合、またはそのストリップを行った場合、その人の信用を落とすために誰かがこのビデオを偽造した可能性を検討する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、私の実験では、dipfakeテクノロジーの制限を強調しています。少なくとも現在の形ではそうです。完全に説得力のある仮想顔を作成するには、広範な知識と努力が必要です。私は成功しなかったし、誰かが実際のビデオと実際に区別がつかないdipfakeビデオをすでに作成できたかどうかはわかりません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さらに、Faceswapのような今日のツールは、顔の変更のみを扱います。彼らは額、髪、腕、脚を変えません。そして、顔が完璧であっても、正しく見えない要素に基づいて、二目盛りのビデオを定義することは可能かもしれません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、dipfakeテクノロジのこれらの制限はなくなる可能性があります。数年後には、ソフトウェアは実際のビデオと区別できないビデオを生成することを学ぶかもしれません。それで？</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この場合、他のタイプのメディアは長い間偽造が容易であったことを覚えておくと役に立ちます。</font><font style="vertical-align: inherit;">簡単なタスクは、誰かが実際には書いていない何かを書いているメールのスクリーンショットを撮ることです。</font><font style="vertical-align: inherit;">そして、これは詐欺的な電子メールのために不規則な採石場の数の増加につながらず、公の議論で使用される証拠としての手紙のスクリーンショットの信用を失いませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、人々は電子メールが偽造される可能性があることを知っており、そのような場合には追加の確認を求めています。</font><font style="vertical-align: inherit;">どんな出来事の連鎖が手紙に注目を集めましたか？</font><font style="vertical-align: inherit;">書かれるはずだったときに、他の人がこの電子メールのコピーを受け取っていますか？</font><font style="vertical-align: inherit;">手紙の作者とされる人物は、彼の著作を認めたか、偽造を主張しましたか？</font><font style="vertical-align: inherit;">このような質問に対する回答は、公開された手紙をどれだけ真剣に受け取ることができるかを人々が判断するのに役立ちます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あなたは一度騙されることができます</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
だからそれはビデオです。</font><font style="vertical-align: inherit;">おそらく、詐欺師が彼の発言やとんでもないことをする動画を投稿して、その人のキャリアを破壊することができる短い期間があるでしょう。</font><font style="vertical-align: inherit;">しかし、ビデオクリップにドキュメンタリーの証拠、証人、またはその他の裏付けとなる要素がない限り、まもなく社会はビデオを懐疑的に扱うことを学びます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これは、difffaceテクノロジーの最も法外な乱用の場合でも機能すると思います。ポルノビデオに人物の顔を挿入することです。</font><font style="vertical-align: inherit;">これは明らかに失礼で許容できないものです。</font><font style="vertical-align: inherit;">しかし、人々はそのようなビデオが彼らの評判とキャリアを破壊するかもしれないと心配しています。</font><font style="vertical-align: inherit;">これはそうではないと思います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際、インターネット上で、Photoshopの助けを借りてポルノスターの体に頭が取り付けられている有名人（主に女性）の完全な画像を見つけることができます。女性の苦しみは理解できます。しかし、これらの女性が裸であると公衆が自動的に結論付けたわけではありません-私たちは、Photoshopの存在と、偽の写真を作成する可能性について知っています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
深いポルノにも同じことが言えます。もちろん、あなたが参加して偽のポルノを作るのは良くありません。しかし、ある種の人との二人称ビデオのリリースは、セックスの本当のビデオほど壊滅的な影響を与えません。ビデオの信憑性の証拠がない場合、国民はそれが偽物であると結論するでしょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Faceswapの作者であるMatt Torahは、この考慮事項は、パッケージを作成する動機のコンポーネントの1つであったと私に語っています。彼は、人々を変えるためのソフトウェアが必然的に開発されると信じています。彼は、オープンソースの人々を置き換えるためのユーザーフレンドリーなツールを作成することにより、このテクノロジーで秘密のベールを取り除き、その機能と制限について公衆に伝えることを望んでいます。そしてこれは、偽の動画となる可能性のある動画について、一般の人々が懐疑的になるようになるのに役立ちます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
長い目で見れば、PRの振り子が逆に大きく振れすぎてリスクを負うことになるので、ディファイクを作成する可能性は、ビデオの証拠力に対する信念を破壊します。</font><font style="vertical-align: inherit;">一部の政治家は、メディアの批判を拒否するという習慣をすでに「偽りのニュース」と見なしている。</font><font style="vertical-align: inherit;">この戦術は、ニジマスの技術に対する社会の意識の高まりとともに、より効果的になります。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja482674/index.html">「休暇の直後」：ITMO大学でのセミナー、マスタークラス、技術コンテスト</a></li>
<li><a href="../ja482676/index.html">Structタイプのデータの効果的なソート</a></li>
<li><a href="../ja482678/index.html">iOSのテキストクエストを行うことに決めた方法とその理由</a></li>
<li><a href="../ja482680/index.html">暗号化、XOR、暗号化されていないZIPおよびPRSPのハッキング。r0ot-mi Cryptoによる問題解決。パート2</a></li>
<li><a href="../ja482682/index.html">Qtツールの自動化</a></li>
<li><a href="../ja482686/index.html">科学者は動物の行動研究を自動化して脳機能を解読する</a></li>
<li><a href="../ja482690/index.html">Combineでパブリッシャーを作成する</a></li>
<li><a href="../ja482696/index.html">Windows Linuxインストール済みシステムの完全ディスク暗号化。暗号化されたマルチブート</a></li>
<li><a href="../ja482698/index.html">[エッセイ]オフィスプランクトン専用。私は自分の仕事に触発されていません</a></li>
<li><a href="../ja482700/index.html">GoogleとYandexを「ファック」する方法：サイトの白黒のSEO宣伝。シェスタコフ| People PRO＃74</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
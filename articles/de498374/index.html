<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üà∏ üö∂ ‚úÖ GPU Computing - Warum, wann und wie. Plus einige Tests üßñüèæ üß• üëºüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jeder wei√ü seit langem, dass man auf Grafikkarten nicht nur Spielzeug spielen, sondern auch Dinge ausf√ºhren kann, die nicht mit Spielen zusammenh√§ngen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>GPU Computing - Warum, wann und wie. Plus einige Tests</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dbtc/blog/498374/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jeder wei√ü seit langem, dass man auf Grafikkarten nicht nur Spielzeug spielen, sondern auch Dinge ausf√ºhren kann, die nicht mit Spielen zusammenh√§ngen, z. B. ein neuronales Netzwerk trainieren, sich an Kryptow√§hrung erinnern oder wissenschaftliche Berechnungen durchf√ºhren. Wie es passiert ist </font><font style="vertical-align: inherit;">, man kann es lesen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , aber ich wollte das Thema ber√ºhren , </font></font><i><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">warum die GPU auf die interessant sein k√∂nnen</font></font></strong></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> durchschnittliche Programmierer (nicht zu GameDev bezogen) , </font></font><i><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wie zu n√§hern</font></font></strong></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Entwicklung auf der GPU , </font><font style="vertical-align: inherit;">ohne viel Zeit damit zu verbringen, </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entscheiden</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , ob Schauen Sie in diese Richtung und "finden Sie </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">an Ihren Fingern heraus", welchen Gewinn Sie erzielen k√∂nnen.</font></font></strong>&nbsp;<br>
<br>
<div style="text-align:center;"><img width="800" src="https://habrastorage.org/getpro/habr/post_images/3ee/2ac/893/3ee2ac8936a685e6993966cfa40f53fd.jpg"></div><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Artikel wurde basierend auf meiner </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pr√§sentation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in HighLoad ++ geschrieben. </font><font style="vertical-align: inherit;">Es werden haupts√§chlich die von NVIDIA angebotenen Technologien er√∂rtert. </font><font style="vertical-align: inherit;">Ich habe keinen Zweck, f√ºr Produkte zu werben, ich gebe sie nur als Beispiel, und wahrscheinlich findet sich etwas √Ñhnliches bei konkurrierenden Herstellern.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Warum auf die GPU z√§hlen?</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zwei Prozessoren k√∂nnen nach unterschiedlichen Kriterien verglichen werden. Die wahrscheinlich beliebtesten sind die H√§ufigkeit und Anzahl der Kerne, die Gr√∂√üe der Caches usw. Letztendlich sind wir jedoch daran interessiert, wie viele Operationen ein Prozessor pro Zeiteinheit ausf√ºhren kann, welche Art von Operation dies ist, aber eine separate Frage Eine √ºbliche Metrik ist die Anzahl der Gleitkommaoperationen pro Sekunde - Flops. Und wenn wir warm mit weich und in unserem Fall GPU mit CPU vergleichen m√∂chten, ist diese Metrik n√ºtzlich. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die folgende Grafik zeigt das Wachstum dieser Flops im Laufe der Zeit f√ºr Prozessoren und Grafikkarten.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5e2/048/3f5/5e20483f59e87b0a395b0fae0e6495c5.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Daten werden aus offenen Quellen gesammelt, es gibt keine Daten f√ºr 2019-20 Jahre, weil dort nicht alles so sch√∂n ist, aber die GPUs trotzdem gewinnen.)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Nun, es ist verlockend, nicht </font><i><font style="vertical-align: inherit;">wahr</font></i><font style="vertical-align: inherit;"> ? </font><font style="vertical-align: inherit;">Wir verlagern alle Berechnungen von der CPU auf die GPU und erzielen die achtfache beste Leistung! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber nat√ºrlich ist nicht alles so einfach. </font><font style="vertical-align: inherit;">Sie k√∂nnen nicht einfach alles auf die GPU √ºbertragen. Wir werden weiter dar√ºber sprechen.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPU-Architektur und ihr Vergleich mit der CPU</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich bringe vielen ein vertrautes Bild mit der Architektur der CPU und den Grundelementen:</font></font><br>
<br>
<div style="text-align:center;"><img width="400" src="https://habrastorage.org/getpro/habr/post_images/df0/8c2/4c3/df08c24c3fe92cd97356670729c318cd.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CPU Core</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Was ist das Besondere? </font><font style="vertical-align: inherit;">Ein Kern und eine Reihe von Hilfsbl√∂cken. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schauen wir uns nun die GPU-Architektur an:</font></font><br>
<br>
<div style="text-align:center;"><img width="400" src="https://habrastorage.org/getpro/habr/post_images/0fe/138/0cc/0fe1380ccbb321b289d16e39a499009a.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPU-Kern</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Eine Grafikkarte verf√ºgt √ºber viele Prozessorkerne, normalerweise mehrere Tausend, aber sie sind zu Bl√∂cken zusammengefasst. Bei NVIDIA-Grafikkarten sind es normalerweise jeweils 32, und sie haben gemeinsame Elemente, einschlie√ülich und Register. Die Architektur des GPU-Kerns und der logischen Elemente ist viel einfacher als auf der CPU, dh es gibt keine Prefetcher, Brunch-Pr√§diktoren und vieles mehr. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, dies sind die Hauptunterschiede in der Architektur der CPU und der GPU, und tats√§chlich legen sie Einschr√§nkungen fest oder er√∂ffnen umgekehrt die M√∂glichkeiten f√ºr das, was wir effektiv auf der GPU lesen k√∂nnen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich habe einen weiteren wichtigen Punkt nicht erw√§hnt. Normalerweise ‚Äûst√∂bern‚Äú die Grafikkarte und der Prozessor nicht untereinander und schreiben Daten auf die Grafikkarte und lesen das Ergebnis zur√ºck. Dies sind separate Vorg√§nge, die sich als ‚ÄûEngpass‚Äú in Ihrem System herausstellen k√∂nnen, ein Diagramm der Pumpzeit im Verh√§ltnis zur Gr√∂√üe Daten werden sp√§ter in dem Artikel angegeben.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPU-Einschr√§nkungen und -Funktionen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Welche Einschr√§nkungen bringt diese Architektur ausf√ºhrbaren Algorithmen auf:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn wir auf einer GPU rechnen, k√∂nnen wir nicht nur einen Kern ausw√§hlen, sondern es wird ein ganzer Block von Kernen zugewiesen (32 f√ºr NVIDIA).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alle Kerne f√ºhren die gleichen Anweisungen aus, aber mit unterschiedlichen Daten (wir werden sp√§ter darauf eingehen) werden solche Berechnungen als Single-Instruction-Multiple-Data oder SIMD bezeichnet (obwohl NVIDIA seine Verfeinerung einf√ºhrt).&nbsp;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aufgrund des relativ einfachen Satzes von Logikbl√∂cken und allgemeinen Registern mag die GPU die Verzweigung und die komplexe Logik in den Algorithmen wirklich nicht.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Welche M√∂glichkeiten er√∂ffnet es:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eigentlich ist die Beschleunigung der gleichen SIMD-Berechnungen. </font><font style="vertical-align: inherit;">Das einfachste Beispiel ist das elementweise Hinzuf√ºgen von Matrizen, und wir analysieren es.</font></font></li>
</ul><br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reduktion klassischer Algorithmen auf SIMD-Darstellung</font></font></h1><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben zwei Arrays, A und B, und wir m√∂chten jedem Element von Array A ein Element aus Array B hinzuf√ºgen. Nachfolgend finden Sie ein Beispiel in C, obwohl ich hoffe, dass es f√ºr diejenigen klar ist, die diese Sprache nicht sprechen:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *A, <span class="hljs-keyword">float</span> *B, size)</span>
</span>{ 
   <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; size; i++) <font></font>
   { <font></font>
       A[i] += B[i]<font></font>
   } <font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Klassischer Loopback von Elementen in einer Schleife und linearer Laufzeit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun wollen wir sehen, wie ein solcher Code f√ºr die GPU aussehen wird:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func</span><span class="hljs-params">(<span class="hljs-keyword">float</span> *A, <span class="hljs-keyword">float</span> *B, size)</span> 
</span>{ 
   <span class="hljs-keyword">int</span> i = threadIdx.x; 
   <span class="hljs-keyword">if</span> (i &lt; size) <font></font>
      A[i] += B[i] <font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und hier ist es schon interessant, dass die Variable threadIdx aufgetaucht ist, die wir anscheinend nirgendwo deklariert haben. Ja, sein System bietet uns. Stellen Sie sich vor, dass das Array im vorherigen Beispiel aus drei Elementen besteht und Sie es in drei parallelen Threads ausf√ºhren m√∂chten. Dazu m√ºssten Sie einen weiteren Parameter hinzuf√ºgen - den Index oder die Stream-Nummer. Dies ist, was die Grafikkarte f√ºr uns tut, obwohl sie den Index als statische Variable √ºbergibt und mit mehreren Dimensionen gleichzeitig arbeiten kann - x, y, z. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine weitere Nuance: Wenn Sie eine gro√üe Anzahl paralleler Streams gleichzeitig starten m√∂chten, m√ºssen die Streams in Bl√∂cke unterteilt werden (ein architektonisches Merkmal von Grafikkarten). Die maximale Blockgr√∂√üe h√§ngt von der Grafikkarte ab, und der Index des Elements, f√ºr das wir Berechnungen durchf√ºhren, muss wie folgt ermittelt werden:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x; <span class="hljs-comment">// blockIdx ‚Äì  , blockDim ‚Äì  , threadIdx ‚Äì    </span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis haben wir: viele parallel laufende Threads, die denselben Code ausf√ºhren, jedoch unterschiedliche Indizes aufweisen, und dementsprechend Daten, d. H. </font><font style="vertical-align: inherit;">das gleiche SIMD. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies ist das einfachste Beispiel. Wenn Sie jedoch mit der GPU arbeiten m√∂chten, m√ºssen Sie Ihre Aufgabe in dieselbe Form bringen. </font><font style="vertical-align: inherit;">Leider ist dies nicht immer m√∂glich und kann in einigen F√§llen Gegenstand einer Dissertation werden, dennoch k√∂nnen klassische Algorithmen in diese Form gebracht werden.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anh√§ufung</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns nun sehen, wie die in die SIMD-Darstellung √ºbertragene Aggregation aussehen wird:</font></font><br>
&nbsp;<br>
<div style="text-align:center;"><img width="400" src="https://habrastorage.org/getpro/habr/post_images/ecd/78a/bba/ecd78abbaff0c1be8799c1337f7652f8.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben ein Array von n Elementen. </font><font style="vertical-align: inherit;">In der ersten Stufe starten wir n / 2 Threads und jeder Thread f√ºgt zwei Elemente hinzu, d. H. </font><font style="vertical-align: inherit;">In einer Iteration addieren wir die H√§lfte der Elemente im Array. </font><font style="vertical-align: inherit;">Und dann wiederholen wir in der Schleife dasselbe f√ºr das neu erstellte Array, bis wir die letzten beiden Elemente aggregieren. </font><font style="vertical-align: inherit;">Wie Sie sehen k√∂nnen, k√∂nnen wir umso weniger parallele Threads starten, je kleiner das Array ist, d. H. </font><font style="vertical-align: inherit;">Auf einer GPU ist es sinnvoll, Arrays mit einer ausreichend gro√üen Gr√∂√üe zusammenzufassen. </font><font style="vertical-align: inherit;">Ein solcher Algorithmus kann verwendet werden, um die Summe der Elemente zu berechnen (vergessen Sie √ºbrigens nicht den m√∂glichen √úberlauf des Datentyps, mit dem Sie arbeiten) und nach einem Maximum, Minimum oder nur einer Suche zu suchen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sortierung</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Sortieren sieht aber schon viel komplizierter aus. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die zwei beliebtesten Sortieralgorithmen auf der GPU sind:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bitonische Sorte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Radix-Sortierung</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Radix-Sort wird jedoch immer noch h√§ufiger verwendet, und in einigen Bibliotheken ist eine produktionsbereite Implementierung zu finden. </font><font style="vertical-align: inherit;">Ich werde nicht im Detail analysieren, wie diese Algorithmen funktionieren. Interessierte finden eine Beschreibung der Radix-Sortierung unter </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.codeproject.com/Articles/543451/Parallel-Radix-Sort-on-the-GPU-using-Cplusplus- AMP</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://stackoverflow.com/a/26229897</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Die Idee ist jedoch, dass selbst ein nichtlinearer Algorithmus wie das Sortieren auf eine SIMD-Ansicht reduziert werden kann. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und bevor wir uns die reellen Zahlen ansehen, die von der GPU erhalten werden k√∂nnen, wollen wir herausfinden, wie man f√ºr dieses Wunder der Technologie programmiert.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wo soll man anfangen</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die g√§ngigsten zwei Technologien, die f√ºr die Programmierung unter der GPU verwendet werden k√∂nnen:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Opencl</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuda</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
OpenCL ist ein Standard, der von den meisten Grafikkartenherstellern unterst√ºtzt wird, einschlie√ülich </font><font style="vertical-align: inherit;">Auf Mobilger√§ten kann auch in OpenCL geschriebener Code auf der CPU ausgef√ºhrt werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie k√∂nnen OpenCL aus C / C ++ verwenden, es gibt Ordner f√ºr andere Sprachen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
F√ºr OpenCL hat mir das Buch </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCL in Action am</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> besten gefallen </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Es werden auch verschiedene Algorithmen auf der GPU beschrieben, einschlie√ülich </font><font style="vertical-align: inherit;">Bitonische Sortierung und Radix-Sortierung. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
CUDA ist die propriet√§re Technologie und das SDK von NVIDIA. </font><font style="vertical-align: inherit;">Sie k√∂nnen in C / C ++ schreiben oder Bindungen zu anderen Sprachen verwenden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Vergleich von OpenCL und CUDA ist etwas falsch, weil </font><font style="vertical-align: inherit;">Einer ist der Standard, der andere ist das gesamte SDK. </font><font style="vertical-align: inherit;">Trotzdem w√§hlen viele Leute CUDA f√ºr die Entwicklung von Grafikkarten, obwohl die Technologie propriet√§r ist, obwohl sie kostenlos ist und nur auf NVIDIA-Karten funktioniert. </font><font style="vertical-align: inherit;">Daf√ºr gibt es mehrere Gr√ºnde:</font></font><br>
<br>
<ul>
<li>  API</li>
<li>    </li>
<li>,   GPU,      (host) </li>
<li> ,  ..  </li>
<li>   </li>
<li>  </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu den Besonderheiten geh√∂rt die Tatsache, dass CUDA √ºber einen eigenen Compiler verf√ºgt, der auch Standard-C / C ++ - Code kompilieren kann. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das umfassendste CUDA-Buch, auf das ich gesto√üen bin, war </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Professional CUDA C Programming</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , obwohl es bereits etwas veraltet ist, behandelt es dennoch viele technische Nuancen der Programmierung f√ºr NVIDIA-Karten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber was ist, wenn ich nicht ein paar Monate damit verbringen m√∂chte, diese B√ºcher zu lesen, mein eigenes Programm f√ºr eine Grafikkarte zu schreiben, zu testen und zu debuggen und dann herauszufinden, dass dies nichts f√ºr mich ist?&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie gesagt, es gibt eine gro√üe Anzahl von Bibliotheken , </font><font style="vertical-align: inherit;">die die Komplexit√§t der Entwicklung unter der GPU verstecken: XGBoost, cuBLAS, TensorFlow, PyTorch und andere, werden wir die betrachten </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Schub</font></a><font style="vertical-align: inherit;"> Bibliothek</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Da es weniger spezialisiert ist als die anderen oben genannten Bibliotheken, implementiert es gleichzeitig grundlegende Algorithmen, z. B. Sortieren, Suchen, Aggregieren, und kann mit hoher Wahrscheinlichkeit auf Ihre Aufgaben angewendet werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thrust ist eine C ++ - Bibliothek, die darauf abzielt, Standard-STL-Algorithmen durch GPU-basierte Algorithmen zu "ersetzen". </font><font style="vertical-align: inherit;">Das Sortieren eines Arrays von Zahlen mithilfe dieser Bibliothek auf einer Grafikkarte sieht beispielsweise folgenderma√üen aus:</font></font><br>
<br>
<pre><code class="cpp hljs"><span class="hljs-function">thrust::host_vector&lt;DataType&gt; <span class="hljs-title">h_vec</span><span class="hljs-params">(size)</span></span>; <span class="hljs-comment">//    </span>
<span class="hljs-built_in">std</span>::generate(h_vec.begin(), h_vec.end(), rand); <span class="hljs-comment">//   </span>
thrust::device_vector&lt;DataType&gt; d_vec = h_vec; <span class="hljs-comment">//        &nbsp;</span>
thrust::sort(d_vec.begin(), d_vec.end()); <span class="hljs-comment">//    </span>
thrust::copy(d_vec.begin(), d_vec.end(), h_vec.begin()); <span class="hljs-comment">//   ,     </span>
</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Vergessen Sie nicht, dass das Beispiel von einem Compiler von NVIDIA kompiliert werden muss.)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Sie sehen k√∂nnen, ist push :: sort einem √§hnlichen Algorithmus von STL sehr √§hnlich. Diese Bibliothek verbirgt viele Schwierigkeiten, insbesondere die Entwicklung eines Unterprogramms (genauer gesagt des Kernels), das auf der Grafikkarte ausgef√ºhrt wird, aber gleichzeitig die Flexibilit√§t verliert. Wenn wir beispielsweise mehrere Gigabyte Daten sortieren m√∂chten, ist es logisch, ein Datenelement an die Karte zu senden, um mit dem Sortieren zu beginnen, und w√§hrend der Sortierung weitere Daten an die Karte zu senden. Dieser Ansatz wird als Latenzverstecken bezeichnet und erm√∂glicht eine effizientere Nutzung der Serverzuordnungsressourcen. Wenn wir jedoch Bibliotheken auf hoher Ebene verwenden, bleiben diese M√∂glichkeiten leider verborgen. F√ºr das Prototyping und die Messung der Leistung sind sie jedoch gleich, insbesondere mit Schub k√∂nnen Sie messen, welchen Overhead die Daten√ºbertragung bietet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich habe einen kleinen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benchmark geschrieben</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wenn Sie diese Bibliothek verwenden, in der mehrere g√§ngige Algorithmen mit unterschiedlichen Datenmengen auf der GPU ausgef√ºhrt werden, sehen wir uns die Ergebnisse an.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ergebnisse des GPU-Algorithmus</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die GPU zu testen, habe ich eine Instanz in AWS mit einer Tesla k80-Grafikkarte erstellt. Dies ist nicht die bisher leistungsst√§rkste Serverkarte (die leistungsst√§rkste Tesla v100), aber die g√ºnstigste und hat Folgendes an Bord:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4992 CUDA-Kernel</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">24 GB Speicher</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">480 Gbit / s - Speicherbandbreite&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und f√ºr Tests auf der CPU habe ich eine Instanz mit einer Intel Xeon-Prozessor-CPU E5-2686 v4 bei 2,30 GHz genommen</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformation</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/930/6e1/687/9306e1687be5ee95c29c8aac7b2ae337.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ausf√ºhrungszeit der Transformation auf der GPU und der CPU in ms</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Wie Sie sehen k√∂nnen, ist die √ºbliche Transformation der Array-Elemente sowohl auf der GPU als auch auf der CPU zeitlich ungef√§hr gleich. </font><font style="vertical-align: inherit;">Und warum? </font><font style="vertical-align: inherit;">Da der Overhead f√ºr das Senden von Daten an die Karte und zur√ºck den gesamten Leistungsschub verschlingt (wir werden den Overhead separat behandeln) und es relativ wenige Berechnungen auf der Karte gibt. </font><font style="vertical-align: inherit;">Vergessen Sie auch nicht, dass Prozessoren auch SIMD-Anweisungen unterst√ºtzen und Compiler diese in einfachen F√§llen effektiv verwenden k√∂nnen.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns nun sehen, wie effizient die Aggregation auf der GPU erfolgt.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anh√§ufung</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c92/d0e/cb9/c92d0ecb96c32866000e6948f5da61f9.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ausf√ºhrungszeit der Aggregation auf GPU und CPU in ms</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Im Aggregationsbeispiel sehen wir bereits eine signifikante Leistungssteigerung mit zunehmendem Datenvolumen. </font><font style="vertical-align: inherit;">Es lohnt sich auch, darauf zu achten, dass wir eine gro√üe Datenmenge in den Speicher der Karte pumpen und nur ein aggregierter Wert zur√ºckgenommen wird, d. H. </font><font style="vertical-align: inherit;">Der Overhead f√ºr die √úbertragung von Daten von der Karte in den RAM ist minimal. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kommen wir zum interessantesten Beispiel - dem Sortieren.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sortierung</font></font></h2><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fde/504/8da/fde5048da5084d1f0902c9362b21d939.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sortierzeit f√ºr GPU und CPU in ms</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Trotz der Tatsache, dass wir das gesamte Datenarray an die Grafikkarte senden und umgekehrt, ist das Sortieren von 800 MB Daten an die GPU ungef√§hr 25-mal schneller als auf dem Prozessor.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daten√ºbertragungsaufwand</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie aus dem Transformationsbeispiel hervorgeht, ist es nicht immer offensichtlich, ob die GPU auch bei parallelen Aufgaben effektiv ist. </font><font style="vertical-align: inherit;">Der Grund daf√ºr ist ein Overhead f√ºr die √úbertragung von Daten aus dem RAM des Computers in den Speicher der Grafikkarte (in Spielekonsolen wird der Speicher √ºbrigens von der CPU und der GPU gemeinsam genutzt, und es besteht keine Notwendigkeit, Daten zu √ºbertragen). </font><font style="vertical-align: inherit;">Eine der Eigenschaften einer Grafikkarte ist die Speicherbandbreite oder Speicherbandbreite, die die theoretische Bandbreite der Karte bestimmt. </font><font style="vertical-align: inherit;">F√ºr Tesla k80 sind es 480 GB / s, f√ºr Tesla v100 sind es bereits 900 GB / s. </font><font style="vertical-align: inherit;">Die PCI Express-Version und die Implementierung der Daten√ºbertragung auf die Karte wirken sich auch auf den Durchsatz aus. Dies kann beispielsweise in mehreren parallelen Streams erfolgen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schauen wir uns die praktischen Ergebnisse an, die f√ºr die Tesla k80-Grafikkarte in der Amazon-Cloud erzielt wurden:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/798/fb5/613/798fb56139f6158566232bc6283b24e7.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zeit zum √úbertragen von Daten auf die GPU, Sortieren und </font></font></i><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zur√ºcksenden von Daten in den </font></font><br>
<br><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">RAM in ms </font></i><i><font style="vertical-align: inherit;">HtoD - √úbertragen von Daten auf die </font></i><i><font style="vertical-align: inherit;">
GPU </font></i><i><font style="vertical-align: inherit;">-Grafikkarte </font></i><i><font style="vertical-align: inherit;">Ausf√ºhrung - Sortieren auf der Grafikkarte </font></i><i><font style="vertical-align: inherit;">
DtoH - Kopieren von Daten von der Grafikkarte in den RAM</font></i></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Das erste, was zu beachten ist, ist, dass das Lesen von Daten von der Grafikkarte schneller ist als schreibe sie dort auf. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zweitens: Wenn Sie mit einer Grafikkarte arbeiten, k√∂nnen Sie eine Latenz von 350 Mikrosekunden erreichen. Dies reicht m√∂glicherweise bereits f√ºr einige Anwendungen mit geringer Latenz aus. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die folgende Tabelle zeigt einen Overhead f√ºr weitere Daten:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d18/653/b96/d18653b96af325f35fade713bdaa8dae.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zeit zum √úbertragen von Daten an die GPU, Sortieren und Zur√ºcksenden von Daten in den RAM in ms</font></font></i><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Servernutzung</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die h√§ufigste Frage ist, wie sich eine Spiel-Grafikkarte von einer Server-Grafikkarte unterscheidet. </font><font style="vertical-align: inherit;">Entsprechend den Merkmalen sind sie sehr √§hnlich, aber die Preise unterscheiden sich erheblich.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/203/01b/741/20301b7418ee616d9611f42d2b4a8f5d.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Hauptunterschiede zwischen dem Server (NVIDIA) und der Spielkarte:</font></font><br>
<br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Herstellergarantie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (die Spielkarte ist nicht f√ºr die Verwendung auf Servern vorgesehen)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M√∂gliche </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Virtualisierungsprobleme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr eine Consumer-Grafikkarte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verf√ºgbarkeit des Fehlerkorrekturmechanismus auf der Serverkarte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Anzahl der parallelen Threads (keine CUDA-Kerne) oder die Unterst√ºtzung f√ºr Hyper-Q, mit der Sie mit der Karte von mehreren Threads auf der CPU aus arbeiten k√∂nnen. Laden Sie beispielsweise Daten von einem Thread auf eine Karte hoch und starten Sie Berechnungen von einem anderen</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies sind vielleicht die wichtigsten Unterschiede, die ich gefunden habe.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Multithreading</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir herausgefunden haben, wie der einfachste Algorithmus auf der Grafikkarte ausgef√ºhrt wird und welche Ergebnisse zu erwarten sind, ist die n√§chste logische Frage, wie sich die Grafikkarte bei der Verarbeitung mehrerer paralleler Anforderungen verh√§lt. Als Antwort habe ich zwei Diagramme des Rechnens auf der GPU und einen Prozessor mit 4 und 32 Kernen:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a1/1f6/022/0a11f6022198a582929f384be357fe43.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Zeit, die ben√∂tigt wird, um mathematische Berechnungen auf der GPU und der CPU mit Matrizen von 1000 x 60 in ms durchzuf√ºhren</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
. Dieses Diagramm f√ºhrt Berechnungen mit Matrizen von 1000 x 60 Elementen durch. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Berechnungen werden</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus mehreren Programmstr√∂men </font><font style="vertical-align: inherit;">gestartet. </font><font style="vertical-align: inherit;">F√ºr jeden CPU-Stream wird ein separater Stream f√ºr die GPU erstellt (es wird genau das Hyper-Q verwendet).&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Sie sehen, kommt der Prozessor mit dieser Last sehr gut zurecht, w√§hrend die Latenz f√ºr eine Anforderung pro GPU mit zunehmender Anzahl paralleler Anforderungen erheblich zunimmt.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e09/22c/7fb/e0922c7fba0ef001cca97c7a99817c83.png"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Zeit f√ºr die Durchf√ºhrung mathematischer Berechnungen auf der GPU und der CPU mit Matrizen von 10.000 x 60 in ms.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In der zweiten Grafik sind dieselben Berechnungen, jedoch mit zehnmal l√§ngeren Matrizen, und die GPU verh√§lt sich unter einer solchen Last viel besser. Diese Grafiken sind sehr bezeichnend, und wir k√∂nnen daraus schlie√üen: Das Verhalten unter Last h√§ngt von der Art der Last selbst ab. Ein Prozessor kann Matrixberechnungen auch recht effizient durchf√ºhren, jedoch bis zu einem gewissen Grad. F√ºr eine Grafikkarte ist es charakteristisch, dass bei einer kleinen Rechenlast die Leistung ungef√§hr linear abf√§llt. Mit zunehmender Last und der Anzahl paralleler Threads kommt die Grafikkarte besser zurecht.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es ist schwierig zu vermuten, wie sich die GPU in verschiedenen Situationen verh√§lt. Wie Sie jedoch sehen k√∂nnen, kann eine Serverkarte unter bestimmten Bedingungen Anforderungen aus mehreren parallelen Streams recht effizient verarbeiten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir werden einige weitere Fragen besprechen, die Sie m√∂glicherweise haben, wenn Sie sich dennoch f√ºr die Verwendung der GPU in Ihren Projekten entscheiden.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ressourcenlimit</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie bereits erw√§hnt, sind die beiden Hauptressourcen einer Grafikkarte Rechenkerne und Speicher. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Beispiel haben wir mehrere Prozesse oder Container, die eine Grafikkarte verwenden, und wir m√∂chten die Grafikkarte zwischen ihnen teilen k√∂nnen. </font><font style="vertical-align: inherit;">Leider gibt es daf√ºr keine einfache API. </font><font style="vertical-align: inherit;">NVIDIA bietet </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vGPU-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Technologie an </font><font style="vertical-align: inherit;">, aber ich habe die Tesla k80-Karte nicht in der Liste der unterst√ºtzten Karten gefunden. Soweit ich aus der Beschreibung ersehen kann, konzentriert sich die Technologie mehr auf virtuelle Anzeigen als auf Berechnungen. </font><font style="vertical-align: inherit;">Vielleicht bietet AMD etwas passenderes an. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie die GPU in Ihren Projekten verwenden m√∂chten, sollten Sie sich daher darauf verlassen, dass die Anwendung ausschlie√ülich die Grafikkarte verwendet, oder Sie steuern programmgesteuert die Gr√∂√üe des zugewiesenen Speichers und die Anzahl der f√ºr Berechnungen verwendeten Kerne.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Container und GPU</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie das Ressourcenlimit herausgefunden haben, lautet die folgende logische Frage: Was ist, wenn sich mehrere Grafikkarten auf dem Server befinden? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auch hier k√∂nnen Sie auf Anwendungsebene entscheiden, welche GPU verwendet wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein weiterer bequemer Weg sind Docker-Container. </font><font style="vertical-align: inherit;">Sie k√∂nnen normale Container verwenden, aber NVIDIA bietet seine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NGC-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Container </font><font style="vertical-align: inherit;">mit optimierten Versionen verschiedener Software, Bibliotheken und Treibern an. </font><font style="vertical-align: inherit;">F√ºr einen Container k√∂nnen Sie die Anzahl der verwendeten GPUs und deren Sichtbarkeit f√ºr den Container begrenzen. </font><font style="vertical-align: inherit;">Der Overhead bei der Containernutzung betr√§gt ca. 3%.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Arbeiten Sie in einem Cluster</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine andere Frage: Was tun, wenn Sie eine Aufgabe auf mehreren GPUs innerhalb desselben Servers oder Clusters ausf√ºhren m√∂chten? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie eine Bibliothek gew√§hlt haben, die Schub √§hnelt, oder eine L√∂sung auf niedrigerer Ebene, muss die Aufgabe manuell gel√∂st werden. </font><font style="vertical-align: inherit;">Hochrangige Frameworks, beispielsweise f√ºr maschinelles Lernen oder neuronale Netze, unterst√ºtzen normalerweise die M√∂glichkeit, mehrere Karten sofort zu verwenden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dar√ºber hinaus m√∂chte ich darauf hinweisen, dass NVIDIA beispielsweise eine Schnittstelle f√ºr den direkten Datenaustausch zwischen Karten bietet - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVLINK</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die erheblich schneller als PCI Express ist. </font><font style="vertical-align: inherit;">Und es gibt eine Technologie f√ºr den direkten Zugriff auf den Speicher der Karte von anderen PCI Express-Ger√§ten - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPUDirect RDMA</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , inkl. </font><font style="vertical-align: inherit;">und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Netzwerk</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Empfehlungen</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie erw√§gen, die GPU in Ihren Projekten zu verwenden, ist die GPU h√∂chstwahrscheinlich f√ºr Sie geeignet, wenn:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ihre Aufgabe kann auf eine SIMD-Ansicht reduziert werden</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist m√∂glich, die meisten Daten vor den Berechnungen auf die Karte zu laden (Cache)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Herausforderung besteht in intensivem Computing</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie sollten auch im Voraus Fragen stellen:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie viele parallele Abfragen werden sein&nbsp;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Welche Latenz erwarten Sie?</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ben√∂tigen Sie eine Karte f√ºr Ihre Last? Ben√∂tigen Sie einen Server mit mehreren Karten oder einen Cluster von GPU-Servern?&nbsp;</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das ist alles, ich hoffe, dass das Material f√ºr Sie n√ºtzlich ist und Ihnen hilft, die richtige Entscheidung zu treffen!</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verweise</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Benchmark und Ergebnisse auf github - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://github.com/tishden/gpu_benchmark/tree/master/cuda</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Zus√§tzlich zum Thema eine Aufzeichnung des Berichts </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûGPU-Datenbanken - Architektur, Leistung und Nutzungsaussichten‚Äú</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
NVIDIA NGC Containers Webinar - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http : //bit.ly/2UmVIVt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://bit.ly/2x4vJKF</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de498362/index.html">Kingston ist weiterhin f√ºhrend bei SSD-Sendungen: Wie machen wir das?</a></li>
<li><a href="../de498366/index.html">Welche Algorithmen implementieren Yandex-Entwickler t√§glich?</a></li>
<li><a href="../de498368/index.html">Die Geschichte eines Schalters</a></li>
<li><a href="../de498370/index.html">SAP UI5 und Best√§tigungsfenster: Nochmals zum Kontext</a></li>
<li><a href="../de498372/index.html">Netzwerksimulator-Tutorial ns-3. Kapitel 5</a></li>
<li><a href="../de498378/index.html">Ank√ºndigung von Slurms Abendschule durch Agile</a></li>
<li><a href="../de498380/index.html">Overtons Fenster in Aktion: Wie eine Pandemie eingesetzt wird, um unsere Freiheit einzuschr√§nken</a></li>
<li><a href="../de498390/index.html">IAR + Clion = Freundschaft</a></li>
<li><a href="../de498392/index.html">18 GitLab-Funktionen werden Open Source</a></li>
<li><a href="../de498394/index.html">7 kostenlose Analoga von Screaming Frog und Netpeak Spider</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👌🏾 🙏🏾 🤙🏾 Comment créer rapidement une modélisation thématique d'un forum ou ce qui dérange les personnes atteintes de la maladie cœliaque 🤘🏼 👨🏾‍⚕️ ⛎</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je vais raconter et montrer un exemple de la façon dont une personne ayant une expérience minimale en science des données a pu colle...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Comment créer rapidement une modélisation thématique d'un forum ou ce qui dérange les personnes atteintes de la maladie cœliaque</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/503398/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cet article, je vais raconter et montrer un exemple de la façon dont une personne ayant une expérience minimale en science des données a pu collecter des données sur le forum et créer une modélisation thématique des publications en utilisant le modèle LDA, et a révélé des sujets douloureux pour les personnes souffrant d'intolérance cœliaque. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'année dernière, j'avais besoin d'améliorer d'urgence mes connaissances dans le domaine de l'apprentissage automatique. Je suis chef de produit pour la science des données, l'apprentissage automatique et l'IA, ou d'une autre manière chef de produit technique AI / ML. Les compétences en affaires et la capacité de développer des produits, comme c'est généralement le cas dans les projets destinés à des utilisateurs qui ne sont pas dans le domaine technique, ne suffisent pas. Vous devez comprendre les concepts techniques de base de l'industrie du ML et, si nécessaire, être capable d'écrire vous-même un exemple pour démontrer le produit.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depuis environ 5 ans, je développe des projets front-end, développant des applications web complexes sur JS et React, mais je n'ai jamais traité d'apprentissage automatique, d'ordinateurs portables et d'algorithmes. Par conséquent, quand j'ai vu la nouvelle d' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otus</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qu'ils avaient ouvert un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cours</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> expérimental de cinq mois </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">sur l'apprentissage automatique</font></a><font style="vertical-align: inherit;"> , sans hésitation, j'ai décidé de subir des tests d'essai et j'ai suivi le cours.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pendant cinq mois, chaque semaine, il y avait des conférences de deux heures et des devoirs pour eux. J'y ai appris les bases du ML: divers algorithmes de régression, classifications, ensembles de modèles, renforcement du gradient et même des technologies cloud légèrement affectées. En principe, si vous écoutez attentivement chaque conférence, il y a suffisamment d'exemples et d'explications pour les devoirs. Mais parfois, comme dans tout autre projet de codage, je devais me tourner vers la documentation. Étant donné mon emploi à temps plein, il était très pratique d'étudier, car je pouvais toujours réviser le dossier d'une conférence en ligne.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À la fin de la formation de ce cours, tout le monde devait prendre le projet final. </font><font style="vertical-align: inherit;">L'idée du projet est née tout à fait spontanément, à ce moment-là j'ai commencé une formation en entrepreneuriat à Stanford, où j'ai fait partie de l'équipe qui travaillait sur le projet pour les personnes souffrant d'intolérance cœliaque. </font><font style="vertical-align: inherit;">Au cours de l'étude de marché, j'étais intéressé de savoir de quels soucis, de quoi ils parlent, de quoi les personnes atteintes de cette fonctionnalité se plaignent. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au fil de l'étude, j'ai trouvé un forum sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">celiac.com</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">avec une énorme quantité de matériel sur la maladie cœliaque. </font><font style="vertical-align: inherit;">Il était évident que faire défiler manuellement et lire plus de 100 000 messages n'était pas pratique. </font><font style="vertical-align: inherit;">Alors l'idée m'est venue, d'appliquer les connaissances que j'ai reçues dans ce cours: rassembler toutes les questions et commentaires du forum à partir d'un certain sujet et faire de la modélisation thématique avec les mots les plus courants dans chacun d'eux.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Étape 1. Collecte de données sur le forum</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le forum se compose de nombreux sujets de différentes tailles. </font><font style="vertical-align: inherit;">Au total, ce forum compte environ 115 000 sujets et environ un million de messages, avec des commentaires à leur sujet. </font><font style="vertical-align: inherit;">Je m'intéressais au sous-thème spécifique </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«Faire face à la maladie cœliaque»</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui signifie littéralement </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">«Faire face à la maladie</font></a><font style="vertical-align: inherit;"> cœliaque», si en russe, cela signifie plus «continuer à vivre avec un diagnostic de maladie cœliaque et faire face aux difficultés». </font><font style="vertical-align: inherit;">Ce sous-sujet contient environ 175 000 commentaires. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le téléchargement des données s'est déroulé en deux étapes. </font><font style="vertical-align: inherit;">Pour commencer, j'ai dû parcourir toutes les pages du sujet et collecter tous les liens vers tous les articles, de sorte qu'à l'étape suivante, je pouvais déjà collecter un commentaire.</font></font><br>
<br>
<pre><code class="python hljs">url_coping = <span class="hljs-string">'https://www.celiac.com/forums/forum/5-coping-with-celiac-disease/'</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme le forum s'est avéré être assez ancien, j'ai eu beaucoup de chance et le site n'a eu aucun problème de sécurité, donc pour collecter les données, il suffisait d'utiliser la combinaison </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">User-Agent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fake_useragent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , la </font><font style="vertical-align: inherit;">bibliothèque </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beautiful Soup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour travailler avec le balisage html et connaître le nombre de pages:</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># Get total number of pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_pages_count</span>(<span class="hljs-params">url</span>):</span>
    response = requests.get(url, headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
    soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
    last_page_section = soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsPagination_last'</span>})
    <span class="hljs-keyword">if</span> (last_page_section):<font></font>
        count_link = last_page_section.find(<span class="hljs-string">'a'</span>)
        <span class="hljs-keyword">return</span> int(count_link[<span class="hljs-string">'data-page'</span>])
    <span class="hljs-keyword">else</span>: 
        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><font></font>
<font></font>
coping_pages_count = get_pages_count(url_coping)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, téléchargez le DOM HTML de chaque page pour en extraire facilement et facilement des données à l'aide de la bibliothèque </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BeautifulSoup</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Python </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">
<span class="hljs-comment"># collect pages</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">retrieve_pages</span>(<span class="hljs-params">pages_count, url</span>):</span><font></font>
    pages = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> range(pages_count):<font></font>
        response = requests.get(<span class="hljs-string">'{}page/{}'</span>.format(url, page), headers={<span class="hljs-string">'User-Agent'</span>: UserAgent().chrome})<font></font>
        soup = BeautifulSoup(response.content, <span class="hljs-string">'html.parser'</span>)<font></font>
        pages.append(soup)<font></font>
    <span class="hljs-keyword">return</span> pages<font></font>
<font></font>
coping_pages = retrieve_pages(coping_pages_count, url_coping)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour télécharger les données, j'avais besoin de déterminer les champs nécessaires à l'analyse: trouver les valeurs de ces champs dans le DOM et les enregistrer dans le dictionnaire. </font><font style="vertical-align: inherit;">Je venais moi-même de l'arrière-plan, donc travailler avec la maison et les objets était trivial pour moi.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_post_info</span>(<span class="hljs-params">pages</span>):</span><font></font>
    posts = []<font></font>
    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> pages:<font></font>
        posts_list_soup = page.find(<span class="hljs-string">'ol'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataList'</span>}).findAll(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>: <span class="hljs-string">'ipsDataItem'</span>})
        <span class="hljs-keyword">for</span> post_soup <span class="hljs-keyword">in</span> posts_list_soup:<font></font>
            post = {}<font></font>
            post[<span class="hljs-string">'id'</span>] = uuid.uuid4()
            <span class="hljs-comment"># collecting titles and urls</span>
            title_section = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_break ipsContained'</span>})
            <span class="hljs-keyword">if</span> (title_section):<font></font>
                title_section_a = title_section.find(<span class="hljs-string">'a'</span>)<font></font>
                post[<span class="hljs-string">'title'</span>] = title_section_a[<span class="hljs-string">'title'</span>]<font></font>
                post[<span class="hljs-string">'url'</span>] = title_section_a[<span class="hljs-string">'data-ipshover-target'</span>]
            <span class="hljs-comment"># collecting author &amp; last action</span>
            author_section = post_soup.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_meta'</span>})
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_a = post_soup.find(<span class="hljs-string">'a'</span>)<font></font>
                author_section_time = post_soup.find(<span class="hljs-string">'time'</span>)<font></font>
                post[<span class="hljs-string">'author'</span>] = author_section_a[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
                post[<span class="hljs-string">'last_action'</span>] = author_section_time[<span class="hljs-string">'datetime'</span>]
            <span class="hljs-comment"># collecting stats</span>
            stats_section = post_soup.find(<span class="hljs-string">'ul'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats'</span>})
            <span class="hljs-keyword">if</span> (stats_section):<font></font>
                stats_section_replies = post_soup.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>})
                <span class="hljs-keyword">if</span> (stats_section_replies):<font></font>
                    post[<span class="hljs-string">'replies'</span>] = stats_section_replies.getText()<font></font>
                stats_section_views = post_soup.find(<span class="hljs-string">'li'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsType_light'</span>})
                <span class="hljs-keyword">if</span> (stats_section_views):<font></font>
                    post[<span class="hljs-string">'views'</span>] = stats_section_views.find(<span class="hljs-string">'span'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsDataItem_stats_number'</span>}).getText()<font></font>
            posts.append(post)<font></font>
    <span class="hljs-keyword">return</span> posts
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au total, j'ai collecté environ 15 450 messages dans ce sujet.</font></font><br>
<br>
<pre><code class="python hljs">coping_posts_info = collect_post_info(coping_pages)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, ils pouvaient être transférés vers le DataFrame afin qu'ils se trouvent là magnifiquement, et en même temps les enregistrer dans un fichier csv afin que vous n'ayez pas à attendre à nouveau lorsque les données ont été collectées sur le site si le bloc-notes s'est accidentellement cassé ou j'ai accidentellement redéfini une variable où. </font></font><br>
<br>
<pre><code class="python hljs">df_coping = pd.DataFrame(coping_posts_info, <font></font>
               columns =[<span class="hljs-string">'title'</span>, <span class="hljs-string">'url'</span>, <span class="hljs-string">'author'</span>, <span class="hljs-string">'last_action'</span>, <span class="hljs-string">'replies'</span>, <span class="hljs-string">'views'</span>]) <font></font>
<font></font>
<span class="hljs-comment"># format data</span>
df_coping[<span class="hljs-string">'replies'</span>] = df_coping[<span class="hljs-string">'replies'</span>].astype(int)<font></font>
df_coping[<span class="hljs-string">'views'</span>] = df_coping[<span class="hljs-string">'views'</span>].apply(<span class="hljs-keyword">lambda</span> x: int(x.replace(<span class="hljs-string">','</span>,<span class="hljs-string">''</span>)))<font></font>
df_coping.to_csv(<span class="hljs-string">'celiac_forum_coping.csv'</span>, sep=<span class="hljs-string">','</span>)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après avoir collecté une collection de messages, j'ai procédé à la collecte des commentaires eux-mêmes.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collect_postpage_details</span>(<span class="hljs-params">pages, df</span>):</span><font></font>
    comments = []<font></font>
    <span class="hljs-keyword">for</span> i, page <span class="hljs-keyword">in</span> enumerate(pages):<font></font>
        articles = page.findAll(<span class="hljs-string">'article'</span>)
        <span class="hljs-keyword">for</span> k, article <span class="hljs-keyword">in</span> enumerate(articles):<font></font>
            comment = {<font></font>
                <span class="hljs-string">'url'</span>: df[<span class="hljs-string">'url'</span>][i]<font></font>
            }<font></font>
            <span class="hljs-keyword">if</span>(k == <span class="hljs-number">0</span>):<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">1</span>
            <span class="hljs-keyword">else</span>:<font></font>
                comment[<span class="hljs-string">'question'</span>] = <span class="hljs-number">0</span>
            <span class="hljs-comment"># collecting comments</span>
            comment_section = article.find(<span class="hljs-string">'div'</span>, attrs = {<span class="hljs-string">'class'</span>:<span class="hljs-string">'ipsComment_content'</span>})
            <span class="hljs-keyword">if</span> (comment_section):<font></font>
                comment_section_p = comment_section.find(<span class="hljs-string">'p'</span>)
                <span class="hljs-keyword">if</span>(comment_section_p):<font></font>
                    comment[<span class="hljs-string">'comment'</span>] = comment_section_p.getText()<font></font>
            comment[<span class="hljs-string">'date'</span>] = comment_section.find(<span class="hljs-string">'time'</span>)[<span class="hljs-string">'datetime'</span>]<font></font>
            author_section = article.find(<span class="hljs-string">'strong'</span>)
            <span class="hljs-keyword">if</span> (author_section):<font></font>
                author_section_url = author_section.find(<span class="hljs-string">'a'</span>)
                <span class="hljs-keyword">if</span> (author_section_url):<font></font>
                    comment[<span class="hljs-string">'author'</span>] = author_section_url[<span class="hljs-string">'data-ipshover-target'</span>]<font></font>
            comments.append(comment)<font></font>
    <span class="hljs-keyword">return</span> comments<font></font>
<font></font>
coping_data = collect_postpage_details(coping_comments_pages, df_coping)<font></font>
df_coping_comments.to_csv(<span class="hljs-string">'celiac_forum_coping_comments_1.csv'</span>, sep=<span class="hljs-string">','</span>)<font></font>
<font></font>
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ÉTAPE 2 Analyse des données et modélisation thématique</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À l'étape précédente, nous avons collecté des données sur le forum et reçu les données finales sous la forme de 153777 lignes de questions et commentaires. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais les données collectées ne sont pas intéressantes, donc la première chose que je voulais faire était une analyse très simple: j'ai dérivé des statistiques pour les 30 sujets les plus consultés et les 30 sujets les plus commentés. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9o/ai/dj/9oaidjzovi7va3alxg7vdwkts84.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les publications les plus vues ne coïncidaient pas avec les publications les plus commentées. Les titres des articles commentés, même à première vue, sont visibles. Leurs noms sont plus émotifs: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«Je déteste, je déteste, je déteste»</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou « </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Commentaires arrogants»</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">«Wow, j'ai des ennuis»</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Et les plus regardés ont un format de question: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Puis-je manger du soja?", "Pourquoi ne puis-je pas absorber correctement l'eau?"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">autre. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons fait une simple analyse de texte. </font><font style="vertical-align: inherit;">Pour passer directement à une analyse plus complexe, vous devez préparer les données elles-mêmes avant de les soumettre à l'entrée du modèle LDA pour une ventilation par sujet. </font><font style="vertical-align: inherit;">Pour ce faire, débarrassez-vous des commentaires contenant moins de 30 mots, afin de filtrer les spams et les courts commentaires sans signification. </font><font style="vertical-align: inherit;">Nous les amenons en minuscules.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># Let's get rid of text &lt; 30 words</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">filter_text_words</span>(<span class="hljs-params">text, min_words = <span class="hljs-number">30</span></span>):</span><font></font>
    text = str(text)<font></font>
    <span class="hljs-keyword">return</span> len(text.split()) &gt; <span class="hljs-number">30</span>
filtered_comments = filtered_comments[filtered_comments[<span class="hljs-string">'comment'</span>].apply(filter_text_words)]<font></font>
comments_only = filtered_comments[<span class="hljs-string">'comment'</span>]<font></font>
comments_only= comments_only.apply(<span class="hljs-keyword">lambda</span> x: x.lower())<font></font>
comments_only.head()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Supprimez les mots vides inutiles pour effacer notre sélection de texte</font></font><br>
<br>
<pre><code class="python hljs">stop_words = stopwords.words(<span class="hljs-string">'english'</span>)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">remove_stop_words</span>(<span class="hljs-params">tokens</span>):</span><font></font>
    new_tokens = []<font></font>
    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tokens:<font></font>
        token = []<font></font>
        <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> t:
            <span class="hljs-keyword">if</span> word <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stop_words:<font></font>
                token.append(word)<font></font>
        new_tokens.append(token)<font></font>
    <span class="hljs-keyword">return</span> new_tokens<font></font>
<font></font>
tokens = remove_stop_words(data_words)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous ajoutons également des bigrammes et formons un sac de mots pour mettre en évidence des expressions stables, par exemple, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">comme gluten_free, support_group</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et d'autres expressions qui, lorsqu'elles sont regroupées, ont une certaine signification.</font></font><br>
<br>
<pre><code class="python hljs">
bigram = gensim.models.Phrases(tokens, min_count=<span class="hljs-number">5</span>, threshold=<span class="hljs-number">100</span>)<font></font>
bigram_mod = gensim.models.phrases.Phraser(bigram)<font></font>
bigram_mod.save(<span class="hljs-string">'bigram_mod.pkl'</span>)<font></font>
bag_of_words = [bigram_mod[w] <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> tokens]
<span class="hljs-keyword">with</span> open(<span class="hljs-string">'bigrams.pkl'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:<font></font>
    pickle.dump(bag_of_words, f)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, nous sommes enfin prêts à former directement le modèle LDA lui-même.</font></font><br>
<br>
<pre><code class="python hljs"><font></font>
id2word = corpora.Dictionary(bag_of_words)<font></font>
id2word.save(<span class="hljs-string">'id2word.pkl'</span>)<font></font>
id2word.filter_extremes(no_below=<span class="hljs-number">3</span>, no_above=<span class="hljs-number">0.4</span>, keep_n=<span class="hljs-number">3</span>*<span class="hljs-number">10</span>**<span class="hljs-number">6</span>)<font></font>
corpus = [id2word.doc2bow(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> bag_of_words]<font></font>
<font></font>
lda_model = gensim.models.ldamodel.LdaModel(<font></font>
    corpus, <font></font>
    id2word=id2word, <font></font>
    eval_every=<span class="hljs-number">20</span>,<font></font>
    random_state=<span class="hljs-number">42</span>,<font></font>
    num_topics=<span class="hljs-number">30</span>, <font></font>
    passes=<span class="hljs-number">5</span><font></font>
    )<font></font>
lda_model.save(<span class="hljs-string">'lda_default_2.pkl'</span>)<font></font>
topics = lda_model.show_topics(num_topics=<span class="hljs-number">30</span>, num_words=<span class="hljs-number">100</span>, formatted=<span class="hljs-literal">False</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À la fin de la formation, nous obtenons finalement le résultat des sujets formés. Ce que j'ai joint à la fin de ce post.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(lda_model.num_topics):<font></font>
    plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">10</span>))<font></font>
    plt.imshow(WordCloud(background_color=<span class="hljs-string">"white"</span>, max_words=<span class="hljs-number">100</span>, width=<span class="hljs-number">900</span>, height=<span class="hljs-number">900</span>, collocations=<span class="hljs-literal">False</span>)<font></font>
               .fit_words(dict(topics[t][<span class="hljs-number">1</span>])))<font></font>
    plt.axis(<span class="hljs-string">"off"</span>)<font></font>
    plt.title(<span class="hljs-string">"Topic #"</span> + themes_headers[t])<font></font>
    plt.show()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme cela peut être perceptible, les sujets se sont avérés être très différents dans leur contenu les uns des autres. </font><font style="vertical-align: inherit;">Selon eux, il devient clair de quoi les gens parlent d'intolérance cœliaque. </font><font style="vertical-align: inherit;">Fondamentalement, sur la nourriture, aller au restaurant, les aliments contaminés avec du gluten, les douleurs terribles, le traitement, aller chez le médecin, la famille, les malentendus et d'autres choses que les gens doivent affronter chaque jour en relation avec leur problème. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'est tout. </font><font style="vertical-align: inherit;">Merci à tous pour votre attention. </font><font style="vertical-align: inherit;">J'espère que vous trouverez ce matériel intéressant et utile. </font><font style="vertical-align: inherit;">Et pourtant, comme je ne suis pas développeur DS, ne jugez pas strictement. </font><font style="vertical-align: inherit;">S'il y a quelque chose à ajouter ou à améliorer, j'accueille toujours les critiques constructives, écrivez. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour afficher 30 sujets</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Attention, beaucoup d'images</font></font></b>
                        <div class="spoiler_text"><img src="https://habrastorage.org/webt/cn/dy/tb/cndytbwrtz9ujkkh6xicy0mjyds.png"><br>
<br>
<img src="https://habrastorage.org/webt/no/n2/iq/non2iqgux8nvb5hnitr8n7yra_w.png"><br>
<br>
<img src="https://habrastorage.org/webt/dx/dh/nl/dxdhnlddgexrb_noeq8psjb7nps.png"><br>
<br>
<img src="https://habrastorage.org/webt/x1/_f/q6/x1_fq6omll0iigewzz0ba8tjvys.png"><br>
<br>
<img src="https://habrastorage.org/webt/7v/qy/fh/7vqyfh-uwk_bhypzdgisxxabzjs.png"><br>
<br>
<img src="https://habrastorage.org/webt/v7/1z/fn/v71zfn2kb0xj7rpsthrplgznzzw.png"><br>
<br>
<img src="https://habrastorage.org/webt/ab/tt/t7/abttt7c8aqydfc28gxyq9ai7a4q.png"><br>
<br>
<img src="https://habrastorage.org/webt/oz/hc/m7/ozhcm72ldjjenp5onkjydxgpvly.png"><br>
<br>
<img src="https://habrastorage.org/webt/fe/ex/lw/feexlw8tcrcwni5wmy8k8rv8k3e.png"><br>
<br>
<img src="https://habrastorage.org/webt/w0/hu/5j/w0hu5jix2zrewo2l9jnbkddd3tk.png"><br>
<br>
<img src="https://habrastorage.org/webt/zf/ye/kw/zfyekw6s6qfxuqwy-qxhv_dehrq.png"><br>
<br>
<img src="https://habrastorage.org/webt/l0/9s/vw/l09svwry19fhz1y-1-pooeo_vew.png"><br>
<br>
<img src="https://habrastorage.org/webt/pm/mt/bk/pmmtbkkybu50vhgttl-0kz4tcf4.png"><br>
<br>
<img src="https://habrastorage.org/webt/1h/hu/vr/1hhuvrmmfjxwfzh3fbhf9dbut38.png"><br>
<br>
<img src="https://habrastorage.org/webt/bw/is/ad/bwisadbn9a000lt6xp927szic2u.png"><br>
<br>
<img src="https://habrastorage.org/webt/iu/bf/4q/iubf4qt_juq9uip17rmngbr7wxe.png"><br>
<br>
<img src="https://habrastorage.org/webt/jk/of/sa/jkofsalh2hev8zx6jjlom0pnnxy.png"><br>
<br>
<img src="https://habrastorage.org/webt/js/bs/ls/jsbslsv_4ly4rwe7wir6xvcs6t4.png"><br>
<br>
<img src="https://habrastorage.org/webt/_e/ly/wr/_elywrkbtgk-4fvlnuzfr6zqq4o.png"><br>
<br>
<img src="https://habrastorage.org/webt/4j/x8/pa/4jx8paomlrca7t0syfunmtmlxk4.png"><br>
<br>
<img src="https://habrastorage.org/webt/y2/he/s1/y2hes1fvuepisygriea98m_yavw.png"><br>
<br>
<img src="https://habrastorage.org/webt/9k/xs/sr/9kxssr9rxlyeobjw12fwju0-xkq.png"><br>
<br>
<img src="https://habrastorage.org/webt/i-/sl/qd/i-slqdug6x9dkwybnfnxmdolho8.png"><br>
<br>
<img src="https://habrastorage.org/webt/nq/pk/x5/nqpkx5q6j8e_6mkpfak0ytkkvfc.png"><br>
<br>
<img src="https://habrastorage.org/webt/jv/3b/pa/jv3bpafludpki_2a-4pgajhreh0.png"><br>
<br>
<img src="https://habrastorage.org/webt/sw/-e/pn/sw-epnxhrwa4t7i6uksmggczs-8.png"><br>
<br>
<img src="https://habrastorage.org/webt/-y/qj/0t/-yqj0t-jkax-s09bivkgx8a3mqa.png"><br>
<br>
<img src="https://habrastorage.org/webt/ta/rp/4w/tarp4wr8bcui0zszwuzl7l9h8zo.png"><br>
<br>
<img src="https://habrastorage.org/webt/eo/xl/m2/eoxlm2i2z9weffxhgm-zzgszd3q.png"><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">    «Machine Learning»  OTUS</a>.<br>
<br>
<hr><br>
</div>
                    </div></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr503382/index.html">Rake marche dans un champ propre ou comment collecter les adresses MAC des appareils Wi-Fi à proximité</a></li>
<li><a href="../fr503386/index.html">Coach agile personne en bonne santé</a></li>
<li><a href="../fr503388/index.html">Numérisation de la panique: DIT de Moscou contre les Moscovites - une table ronde le 23 mai</a></li>
<li><a href="../fr503390/index.html">Pourquoi Intel parie-t-il sur le développement de puces pour le génie de Jim Keller?</a></li>
<li><a href="../fr503394/index.html">Expérience d'investissement en actions</a></li>
<li><a href="../fr503402/index.html">Comment se souvenir de tout le monde en personne ou une recherche efficace de visages dans une grande base de données</a></li>
<li><a href="../fr503404/index.html">Systèmes numériques sémantiques</a></li>
<li><a href="../fr503406/index.html">Sémantique et activité</a></li>
<li><a href="../fr503408/index.html">Boutique en ligne côté client Blazor: Partie 7 - Mise à jour pour publier la version 3.2.0 et affichage d'image ajouté</a></li>
<li><a href="../fr503410/index.html">Polygones Another World: Sega Genesis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👲 🖐🏻 💚 Sélection de l'importance des caractéristiques pour les k voisins les plus proches (puits ou autres hyperparamètres) par descente similaire au gradient ♊️ 👨‍👧‍👦 👉🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En expérimentant la tâche d'apprentissage automatique la plus simple, j'ai trouvé qu'il serait intéressant de sélectionner 18 hyperparamètres en même ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Sélection de l'importance des caractéristiques pour les k voisins les plus proches (puits ou autres hyperparamètres) par descente similaire au gradient</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/496484/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/eg/qm/x6/egqmx63h8mgrbxfytg9nmuaby-g.gif" alt="Un vrai non-sens peut non seulement accomplir l'impossible, mais aussi servir d'exemple d'avertissement"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En expérimentant la tâche d'apprentissage automatique la plus simple, j'ai trouvé qu'il serait intéressant de sélectionner 18 hyperparamètres en même temps sur une plage assez large. Dans mon cas, tout était si simple que la tâche pouvait être exécutée avec une puissance informatique brute. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque vous apprenez quelque chose, il peut être très intéressant d'inventer une sorte de vélo. Parfois, il s'avère vraiment trouver quelque chose de nouveau. Parfois, il s'avère que tout a été inventé avant moi. Mais même si je ne fais que répéter le chemin parcouru bien avant moi, en récompense, j'ai souvent une compréhension des mécanismes sous-jacents des algorithmes de leurs capacités et de leurs limites internes. Auquel je vous invite.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En Python et DS, pour faire simple, je suis un débutant et je fais beaucoup de choses qui peuvent être implémentées dans une seule équipe selon mon ancienne habitude de programmation, que Python punit en ralentissant, pas parfois, mais par ordre de grandeur. </font><font style="vertical-align: inherit;">Par conséquent, je télécharge tout mon code dans le référentiel. </font><font style="vertical-align: inherit;">Si vous savez comment l'implémenter beaucoup plus efficacement - ne soyez pas timide, modifiez-le ou écrivez dans les commentaires. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://github.com/kraidiky/GDforHyperparameters</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ceux qui sont déjà un cool datatanist et qui ont tout essayé dans cette vie seront intéressants, je crois, une visualisation du processus d'apprentissage, qui ne s'applique pas seulement à cette tâche.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Formulation du problème</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a un si bon cours DS de ODS.ai et il y a la troisième conférence </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification, arbres de décision et la méthode des voisins les plus proches</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Là, il est montré sur des données extrêmement simples et probablement synthétiques comment l'arbre de décision le plus simple donne une précision de 94,5%, et la même méthode extrêmement simple de k voisins les plus proches donne 89% sans aucun prétraitement</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Importer et charger des données</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> warnings<font></font>
warnings.filterwarnings(<span class="hljs-string">'ignore'</span>)<font></font>
<font></font>
df = pd.read_csv(<span class="hljs-string">'data/telecom_churn.csv'</span>)<font></font>
df[<span class="hljs-string">'Voice mail plan'</span>] = pd.factorize(df[<span class="hljs-string">'Voice mail plan'</span>])[<span class="hljs-number">0</span>]<font></font>
df[<span class="hljs-string">'International plan'</span>] = pd.factorize(df[<span class="hljs-string">'International plan'</span>])[<span class="hljs-number">0</span>]<font></font>
df[<span class="hljs-string">'Churn'</span>] = df[<span class="hljs-string">'Churn'</span>].astype(<span class="hljs-string">'int32'</span>)<font></font>
states = df[<span class="hljs-string">'State'</span>]<font></font>
y = df[<span class="hljs-string">'Churn'</span>]<font></font>
df.drop([<span class="hljs-string">'State'</span>,<span class="hljs-string">'Churn'</span>], axis = <span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<font></font>
df.head()<font></font>
</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comparer le bois avec le tricot</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split, StratifiedKFold
<span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV, cross_val_score
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<font></font>
<font></font>
X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=<span class="hljs-number">0.3</span>,<font></font>
random_state=<span class="hljs-number">17</span>)<font></font>
<font></font>
tree = DecisionTreeClassifier(random_state=<span class="hljs-number">17</span>, max_depth=<span class="hljs-number">5</span>)<font></font>
knn = KNeighborsClassifier(n_neighbors=<span class="hljs-number">10</span>)<font></font>
<font></font>
tree_params = {<span class="hljs-string">'max_depth'</span>: range(<span class="hljs-number">1</span>,<span class="hljs-number">11</span>), <span class="hljs-string">'max_features'</span>: range(<span class="hljs-number">4</span>,<span class="hljs-number">19</span>)}<font></font>
tree_grid = GridSearchCV(tree, tree_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
tree_grid.fit(X_train, y_train)<font></font>
tree_grid.best_params_, tree_grid.best_score_, accuracy_score(y_holdout, tree_grid.predict(X_holdout))<font></font>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'max_depth': 6, 'max_features': 16}, 0.944706386626661, 0.945)</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">idem pour knn</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
<font></font>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_jobs=<span class="hljs-number">-1</span>))])<font></font>
knn_params = {<span class="hljs-string">'knn__n_neighbors'</span>: range(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>)}<font></font>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))<font></font>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'knn__n_neighbors': 9}, 0.8868409772824689, 0.891) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À ce stade, je me suis senti désolé pour knn qui était évidemment malhonnête, car nous n'avions aucun travail avec la métrique. </font><font style="vertical-align: inherit;">Je ne pensais pas avec mon cerveau, j'ai pris feature_importances_ de l'arbre et normalisé l'entrée. </font><font style="vertical-align: inherit;">Ainsi, plus la caractéristique est importante, plus sa contribution est grande la distance entre les points.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous alimentons les données normalisées à l'importance des fonctionnalités</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
feature_importances = pd.DataFrame({<span class="hljs-string">'features'</span>: df.columns, <span class="hljs-string">'importance'</span>:tree_grid.best_estimator_.feature_importances_})<font></font>
print(feature_importances.sort_values(by=[<span class="hljs-string">'importance'</span>], inplace=<span class="hljs-literal">False</span>, ascending=<span class="hljs-literal">False</span>))<font></font>
<font></font>
scaler = StandardScaler().fit(X_train)<font></font>
X_train_transformed = scaler.transform(X_train)<font></font>
X_train_transformed = X_train_transformed * np.array(feature_importances[<span class="hljs-string">'importance'</span>])<font></font>
<font></font>
X_holdout_transformed = scaler.transform(X_holdout)<font></font>
X_holdout_transformed = X_holdout_transformed * np.array(feature_importances[<span class="hljs-string">'importance'</span>])<font></font>
<font></font>
knn_grid = GridSearchCV(KNeighborsClassifier(n_jobs=<span class="hljs-number">-1</span>), {<span class="hljs-string">'n_neighbors'</span>: range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">2</span>)}, cv=<span class="hljs-number">5</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
knn_grid.fit(X_train_transformed, y_train)<font></font>
<span class="hljs-keyword">print</span> (knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout_transformed)))
</code></pre></div></div><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nombre total de minutes par jour</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,270386</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">17</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Appels au service client</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,147185</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total des minutes de veille</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,135475</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Plan international</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,097249</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seize</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total charge internationale</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,091671</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quinze</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total appels internationaux</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">09.090008</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nombre de messages vmail</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,050646</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dix</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Charge totale la veille</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,038593</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Charge journalière totale</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,026422</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Plan de messagerie vocale</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,017068</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Onze</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total des minutes de nuit</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,014185</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">treize</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Charge de nuit totale</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,005742</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">12</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total des appels de nuit</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,005502</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total des appels la veille</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,003614</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nombre total d'appels d'une journée</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,002246</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Total des minutes internationales</font></font></td>
<td>0.002009</td>
</tr>
<tr>
<td>0</td>
<td>Account length</td>
<td>0.001998</td>
</tr>
<tr>
<td>1</td>
<td>Area code</td>
<td>0.000000</td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
{'n_neighbors': 5} 0,909129875696528 0,913 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'arbre vient de partager un peu de connaissances avec knn et maintenant nous en voyons 91%. Ce n'est pas si loin de 94,5% de la vanille. Et puis une idée m'est venue. Mais comment, en fait, devons-nous normaliser l'entrée pour que knn affiche le meilleur résultat? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Premièrement, nous allons estimer dans notre esprit combien cela sera désormais considéré comme «front». 18 paramètres, pour chacun nous faisons, disons, 10 étapes possibles des facteurs dans l'échelle logarithmique. Nous avons des options 10e18. Une option avec tout le nombre impair possible de voisins est inférieure à 10 et la validation croisée est également de 10, je pense environ 1,5 seconde. Il s'avère que 42 milliards d'années. Peut-être faudra-t-il abandonner l'idée de quitter le calcul pour la nuit. :) Et quelque part par ici, je me suis dit: «Hé! Je vais donc faire un vélo qui volera! "</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recherche par dégradé</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En fait, cette tâche n'a probablement qu'un seul maximum disponible. </font><font style="vertical-align: inherit;">Eh bien, ce n'est pas un bien sûr, tout un domaine de bons résultats, mais ils se ressemblent à peu près. </font><font style="vertical-align: inherit;">Par conséquent, nous pouvons simplement marcher le long du gradient et trouver le point le plus approprié. </font><font style="vertical-align: inherit;">La première pensée a été de généraliser l'algorithme génétique, mais ici le terrain adaptatif ne semble pas très traversé, et ce serait un peu exagéré.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je vais essayer de le faire manuellement pour commencer. </font><font style="vertical-align: inherit;">Pour pousser des facteurs en tant qu'hyperparamètres, je dois faire face à des détartreurs. </font><font style="vertical-align: inherit;">Dans l'exemple précédent, comme dans la leçon, j'ai utilisé StandartScaler, qui a centré l'échantillon d'apprentissage en moyenne et a fait sigma = 1. Afin de bien le mettre à l'échelle à l'intérieur du pipeline, l'hyperparamètre doit être rendu un peu plus délicat. </font><font style="vertical-align: inherit;">J'ai commencé à rechercher parmi les convertisseurs se trouvant dans sklearn.preprocessing quelque chose qui convenait à mon cas, mais je n'ai rien trouvé. </font><font style="vertical-align: inherit;">Par conséquent, j'ai essayé d'hériter de StandartScaler en y suspendant un ensemble supplémentaire de facteurs.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classe de nominalisation puis de multiplication par échelle légèrement compatible avec le pipeline sklearn</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.base <span class="hljs-keyword">import</span> TransformerMixin
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StandardAndPoorScaler</span>(<span class="hljs-params">StandardScaler, TransformerMixin</span>):</span>
    <span class="hljs-comment">#normalization = None</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, copy=True, with_mean=True, with_std=True, normalization = None</span>):</span>
        <span class="hljs-comment">#print("new StandardAndPoorScaler(normalization=", normalization.shape if normalization is not None else normalization, ") // ", type(self))</span><font></font>
        self.normalization = normalization<font></font>
        super().__init__(copy, with_mean, with_std)<font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, X, y=None</span>):</span>
        <span class="hljs-comment">#print(type(self),".fit(",X.shape, ",", y.shape if y is not None else "&lt;null&gt;",")")</span><font></font>
        super().fit(X, y)<font></font>
        <span class="hljs-keyword">return</span> self
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">partial_fit</span>(<span class="hljs-params">self, X, y=None</span>):</span>
        <span class="hljs-comment">#print(type(self),".partial_fit(",X.shape, ",", y.shape if y is not None else "&lt;null&gt;)")</span><font></font>
        super().partial_fit(X, y)<font></font>
        <span class="hljs-keyword">if</span> self.normalization <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
            self.normalization = np.ones((X.shape[<span class="hljs-number">1</span>]))
        <span class="hljs-keyword">elif</span> type(self.normalization) != np.ndarray:<font></font>
            self.normalization = np.array(self.normalization)<font></font>
        <span class="hljs-keyword">if</span> X.shape[<span class="hljs-number">1</span>] != self.normalization.shape[<span class="hljs-number">0</span>]:
            <span class="hljs-keyword">raise</span> <span class="hljs-string">"X.shape[1]="</span>+X.shape[<span class="hljs-number">1</span>]+<span class="hljs-string">" in equal self.scale.shape[0]="</span>+self.normalization.shape[<span class="hljs-number">0</span>]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transform</span>(<span class="hljs-params">self, X, copy=None</span>):</span>
        <span class="hljs-comment">#print(type(self),".transform(",X.shape,",",copy,").self.normalization", self.normalization)</span><font></font>
        Xresult = super().transform(X, copy)<font></font>
        Xresult *= self.normalization<font></font>
        <span class="hljs-keyword">return</span> Xresult
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_reset</span>(<span class="hljs-params">self</span>):</span>
        <span class="hljs-comment">#print(type(self),"._reset()")</span><font></font>
        super()._reset()<font></font>
    <font></font>
scaler = StandardAndPoorScaler(normalization = feature_importances[<span class="hljs-string">'importance'</span>])<font></font>
scaler.fit(X = X_train, y = <span class="hljs-literal">None</span>)<font></font>
print(scaler.normalization)<font></font>
</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Essayer d'appliquer cette classe</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_jobs=<span class="hljs-number">-1</span>))])<font></font>
<font></font>
knn_params = {<span class="hljs-string">'knn__n_neighbors'</span>: range(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">4</span>), <span class="hljs-string">'scaler__normalization'</span>: [feature_importances[<span class="hljs-string">'importance'</span>]]}<font></font>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">5</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))<font></font>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'knn__n_neighbors': 5, 'scaler__normalization': Name: importance, dtype: float64}, 0.909558508358337, 0.913) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le résultat est légèrement différent de mes attentes. Eh bien, en principe, tout fonctionne. Juste pour comprendre cela, j'ai dû reproduire cette classe avec toutes les tripes à partir de zéro en trois heures, et seulement alors j'ai réalisé que l'impression n'imprimait pas non pas parce que sklearn était mal fait, mais parce que GridSearchCV crée des clones dans le flux principal , mais les configure et les entraîne dans d'autres threads. Et tout ce que vous imprimez dans d'autres flux disparaît dans l'oubli. Mais si vous mettez n_jobs = 1, tous les appels aux fonctions remplacées sont affichés comme mignons. Les connaissances sont sorties très chères, maintenant vous les avez aussi, et vous les avez payées en lisant un article fastidieux.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bon, passons. </font><font style="vertical-align: inherit;">Maintenant, je veux donner une certaine variance pour chacun de leurs paramètres, puis le donner un peu moins autour de la meilleure valeur, et ainsi de suite jusqu'à ce que j'obtienne un résultat similaire à la réalité. </font><font style="vertical-align: inherit;">Ce sera la première ligne de base grossière de ce qui devrait finalement obtenir l'algorithme de mes rêves.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je formerai plusieurs options de repondération, différant par plusieurs paramètres</font></font></b><div class="spoiler_text"><pre><code class="python hljs">feature_base = feature_importances[<span class="hljs-string">'importance'</span>]<font></font>
searchArea = np.array([feature_base - <span class="hljs-number">.05</span>, feature_base, feature_base + <span class="hljs-number">.05</span>])<font></font>
searchArea[searchArea &lt; <span class="hljs-number">0</span>] = <span class="hljs-number">0</span>
searchArea[searchArea &gt; <span class="hljs-number">1</span>] = <span class="hljs-number">1</span>
print(searchArea[<span class="hljs-number">2</span>,:] - searchArea[<span class="hljs-number">0</span>,:])<font></font>
<font></font>
<span class="hljs-keyword">import</span> itertools<font></font>
<font></font>
affected_props = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<font></font>
parametrs_ranges = np.concatenate([<font></font>
    np.linspace(searchArea[<span class="hljs-number">0</span>,affected_props], searchArea[<span class="hljs-number">1</span>,affected_props], <span class="hljs-number">2</span>, endpoint=<span class="hljs-literal">False</span>),<font></font>
    np.linspace(searchArea[<span class="hljs-number">1</span>,affected_props], searchArea[<span class="hljs-number">2</span>,affected_props], <span class="hljs-number">3</span>, endpoint=<span class="hljs-literal">True</span>)]).transpose()<font></font>
<font></font>
print(parametrs_ranges) <span class="hljs-comment">#      .  125 </span>
recombinations = itertools.product(parametrs_ranges[<span class="hljs-number">0</span>],parametrs_ranges[<span class="hljs-number">1</span>],parametrs_ranges[<span class="hljs-number">1</span>])<font></font>
<font></font>
variances = []<font></font>
<span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> recombinations: <span class="hljs-comment">#          ,       Python .</span><font></font>
    varince = feature_base.copy()<font></font>
    varince[affected_props] = item<font></font>
    variances.append(varince)<font></font>
print(variances[<span class="hljs-number">0</span>])<font></font>
print(len(variances))<font></font>
<span class="hljs-comment">#  knn   ,               .</span>
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, l'ensemble de données pour la première expérience est prêt. </font><font style="vertical-align: inherit;">Maintenant, je vais essayer d'expérimenter avec les données, pour commencer par une recherche exhaustive des 15 options résultantes.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous faisons une sélection d'essai des paramètres comme dans l'article</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-comment">#scale = np.ones([18])</span>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>))])<font></font>
<font></font>
knn_params = {<span class="hljs-string">'scaler__normalization'</span>: variances} <span class="hljs-comment"># 'knn__n_neighbors': range(3, 9, 2), </span>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, tout va mal, du temps a été consacré à une percée et le résultat est très instable. </font><font style="vertical-align: inherit;">Cela se voit également à partir de la vérification X_holdout, le résultat danse comme dans un kaléidoscope avec des modifications mineures des données d'entrée. </font><font style="vertical-align: inherit;">Je vais essayer une approche différente. </font><font style="vertical-align: inherit;">Je ne changerai qu'un paramètre à la fois, mais avec une discrétisation beaucoup plus importante.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je change une 4ème propriété</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
affected_property = <span class="hljs-number">4</span><font></font>
parametrs_range = np.concatenate([<font></font>
    np.linspace(searchArea[<span class="hljs-number">0</span>,affected_property], searchArea[<span class="hljs-number">1</span>,affected_property], <span class="hljs-number">29</span>, endpoint=<span class="hljs-literal">False</span>),<font></font>
    np.linspace(searchArea[<span class="hljs-number">1</span>,affected_property], searchArea[<span class="hljs-number">2</span>,affected_property], <span class="hljs-number">30</span>, endpoint=<span class="hljs-literal">True</span>)]).transpose()<font></font>
<font></font>
print(searchArea[<span class="hljs-number">1</span>,affected_property])<font></font>
print(parametrs_range) <span class="hljs-comment"># C   ,  .</span><font></font>
<font></font>
<font></font>
variances = []<font></font>
<span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> parametrs_range: <span class="hljs-comment">#          ,       Python .</span><font></font>
    varince = feature_base.copy()<font></font>
    varince[affected_property] = item<font></font>
    variances.append(varince)<font></font>
print(variances[<span class="hljs-number">0</span>])<font></font>
print(len(variances))<font></font>
<span class="hljs-comment">#  knn   ,               .</span><font></font>
<font></font>
knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>))])<font></font>
<font></font>
knn_params = {<span class="hljs-string">'scaler__normalization'</span>: variances} <span class="hljs-comment"># 'knn__n_neighbors': range(3, 9, 2), </span>
knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
knn_grid.fit(X_train, y_train)<font></font>
knn_grid.best_params_, knn_grid.best_score_, accuracy_score(y_holdout, knn_grid.predict(X_holdout))</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
({'scaler__normalization': 4 0.079957 Nom: importance, dtype: float64}, 0.9099871410201458, 0.913) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, </font><font style="vertical-align: inherit;">qu'avons </font><font style="vertical-align: inherit;">-nous avec une oie? </font><font style="vertical-align: inherit;">Décalages d'un à deux dixièmes de pour cent sur la validation croisée, et un demi-pour cent sur X_holdout si vous regardez les propriétés affectées différentes. </font><font style="vertical-align: inherit;">Apparemment, il est essentiel et bon marché d'améliorer la situation si vous commencez avec le fait que l'arbre nous donne, c'est impossible sur de telles données. </font><font style="vertical-align: inherit;">Mais supposons que nous n'ayons pas de distribution de poids initiale connue, et essayons de faire la même chose à un moment arbitraire du cycle avec de petites étapes. </font><font style="vertical-align: inherit;">Il est très intéressant de savoir à quoi nous en viendrons.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Remplissage initial</font></font></b><div class="spoiler_text"><pre><code class="python hljs">searchArea = np.array([np.zeros((<span class="hljs-number">18</span>,)), np.ones((<span class="hljs-number">18</span>,)) /<span class="hljs-number">18</span>, np.ones((<span class="hljs-number">18</span>,))])<font></font>
print(searchArea[:,<span class="hljs-number">0</span>])<font></font>
<font></font>
history_parametrs = [searchArea[<span class="hljs-number">1</span>,:].copy()]<font></font>
scaler = StandardAndPoorScaler(normalization=searchArea[<span class="hljs-number">1</span>,:])<font></font>
scaler.fit(X_train)<font></font>
knn = KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>)<font></font>
knn.fit(scaler.transform(X_train), y_train)<font></font>
history_holdout_score = [accuracy_score(y_holdout, knn.predict(scaler.transform(X_holdout)))]</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fonction modifiant légèrement un paramètre (avec les journaux de débogage)</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">changePropertyNormalization</span>(<span class="hljs-params">affected_property, points_count = <span class="hljs-number">15</span></span>):</span><font></font>
    test_range = np.concatenate([<font></font>
        np.linspace(searchArea[<span class="hljs-number">0</span>,affected_property], searchArea[<span class="hljs-number">1</span>,affected_property], points_count//<span class="hljs-number">2</span>, endpoint=<span class="hljs-literal">False</span>),<font></font>
        np.linspace(searchArea[<span class="hljs-number">1</span>,affected_property], searchArea[<span class="hljs-number">2</span>,affected_property], points_count//<span class="hljs-number">2</span> + <span class="hljs-number">1</span>, endpoint=<span class="hljs-literal">True</span>)]).transpose()<font></font>
    variances = [searchArea[<span class="hljs-number">1</span>,:].copy() <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(test_range.shape[<span class="hljs-number">0</span>])]
    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> range(len(variances)):<font></font>
        variances[row][affected_property] = test_range[row]<font></font>
    <font></font>
    knn_pipe = Pipeline([(<span class="hljs-string">'scaler'</span>, StandardAndPoorScaler()), (<span class="hljs-string">'knn'</span>, KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>))])<font></font>
    knn_params = {<span class="hljs-string">'scaler__normalization'</span>: variances} <span class="hljs-comment"># 'knn__n_neighbors': range(3, 9, 2), </span>
    knn_grid = GridSearchCV(knn_pipe, knn_params, cv=<span class="hljs-number">10</span>, n_jobs=<span class="hljs-number">-1</span>, verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    knn_grid.fit(X_train, y_train)<font></font>
    holdout_score = accuracy_score(y_holdout, knn_grid.predict(X_holdout))<font></font>
    best_param = knn_grid.best_params_[<span class="hljs-string">'scaler__normalization'</span>][affected_property]<font></font>
    print(affected_property,<font></font>
          <span class="hljs-string">'property:'</span>, searchArea[<span class="hljs-number">1</span>, affected_property], <span class="hljs-string">"=&gt;"</span>, best_param,
          <span class="hljs-string">'holdout:'</span>, history_holdout_score[<span class="hljs-number">-1</span>], <span class="hljs-string">"=&gt;"</span>, holdout_score, <span class="hljs-string">'('</span>, knn_grid.best_score_, <span class="hljs-string">')'</span>)
    <span class="hljs-comment">#             .</span><font></font>
    before = searchArea[:, affected_property]<font></font>
    propertySearchArea = searchArea[:, affected_property].copy()<font></font>
    <span class="hljs-keyword">if</span> best_param == propertySearchArea[<span class="hljs-number">0</span>]:<font></font>
        print(<span class="hljs-string">'|&lt;&lt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = best_param/<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> best_param &gt; <span class="hljs-number">0.01</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
        searchArea[<span class="hljs-number">2</span>, affected_property] = (best_param + searchArea[<span class="hljs-number">2</span>, affected_property])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param == propertySearchArea[<span class="hljs-number">2</span>]:<font></font>
        print(<span class="hljs-string">'&gt;&gt;|'</span>)<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = (best_param + <span class="hljs-number">1</span>)/<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> best_param &lt; <span class="hljs-number">0.99</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>
        searchArea[<span class="hljs-number">0</span>, affected_property] = (best_param + searchArea[<span class="hljs-number">0</span>, affected_property])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &lt; (propertySearchArea[<span class="hljs-number">0</span>] + propertySearchArea[<span class="hljs-number">1</span>])/<span class="hljs-number">2</span>:<font></font>
        print(<span class="hljs-string">'&lt;&lt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = max(propertySearchArea[<span class="hljs-number">0</span>]*<span class="hljs-number">1.1</span> - <span class="hljs-number">.1</span>*propertySearchArea[<span class="hljs-number">1</span>], <span class="hljs-number">0</span>)<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = (best_param + propertySearchArea[<span class="hljs-number">2</span>])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &gt; (propertySearchArea[<span class="hljs-number">1</span>] + propertySearchArea[<span class="hljs-number">2</span>])/<span class="hljs-number">2</span>:<font></font>
        print(<span class="hljs-string">'&gt;&gt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = (best_param + propertySearchArea[<span class="hljs-number">0</span>])/<span class="hljs-number">2</span>
        searchArea[<span class="hljs-number">2</span>, affected_property] = min(propertySearchArea[<span class="hljs-number">2</span>]*<span class="hljs-number">1.1</span> - <span class="hljs-number">.1</span>*propertySearchArea[<span class="hljs-number">1</span>], <span class="hljs-number">1</span>)<font></font>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &lt; propertySearchArea[<span class="hljs-number">1</span>]:<font></font>
        print(<span class="hljs-string">'&lt;'</span>)<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">2</span>, affected_property]<font></font>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">elif</span> best_param &gt; propertySearchArea[<span class="hljs-number">1</span>]:<font></font>
        print(<span class="hljs-string">'&gt;'</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">0</span>, affected_property]<font></font>
        searchArea[<span class="hljs-number">1</span>, affected_property] = best_param
    <span class="hljs-keyword">else</span>:<font></font>
        print(<span class="hljs-string">'='</span>)<font></font>
        searchArea[<span class="hljs-number">0</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">0</span>, affected_property]<font></font>
        searchArea[<span class="hljs-number">2</span>, affected_property] = searchArea[<span class="hljs-number">1</span>, affected_property]*<span class="hljs-number">.25</span> + <span class="hljs-number">.75</span>*searchArea[<span class="hljs-number">2</span>, affected_property]<font></font>
    normalization = searchArea[<span class="hljs-number">1</span>,:].sum() <span class="hljs-comment">#,      .</span><font></font>
    searchArea[:,:] /= normalization<font></font>
    print(before, <span class="hljs-string">"=&gt;"</span>,searchArea[:, affected_property])<font></font>
    history_parametrs.append(searchArea[<span class="hljs-number">1</span>,:].copy())<font></font>
    history_holdout_score.append(holdout_score)<font></font>
    <font></font>
changePropertyNormalization(<span class="hljs-number">1</span>, <span class="hljs-number">9</span>)<font></font>
changePropertyNormalization(<span class="hljs-number">1</span>, <span class="hljs-number">9</span>)
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je n’ai rien optimisé nulle part et, par conséquent, j’ai franchi la prochaine étape décisive pendant près d’une demi-heure:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Texte masqué</font></font></b><div class="spoiler_text">       40 .<pre><code class="python hljs">%%time
<span class="hljs-comment">#   </span>
searchArea = np.array([np.zeros((<span class="hljs-number">18</span>,)), np.ones((<span class="hljs-number">18</span>,)) /<span class="hljs-number">18</span>, np.ones((<span class="hljs-number">18</span>,))])<font></font>
print(searchArea[:,<span class="hljs-number">0</span>])<font></font>
<font></font>
history_parametrs = [searchArea[<span class="hljs-number">1</span>,:].copy()]<font></font>
scaler = StandardAndPoorScaler(normalization=searchArea[<span class="hljs-number">1</span>,:])<font></font>
scaler.fit(X_train)<font></font>
knn = KNeighborsClassifier(n_neighbors = <span class="hljs-number">7</span> , n_jobs=<span class="hljs-number">-1</span>)<font></font>
knn.fit(scaler.transform(X_train), y_train)<font></font>
history_holdout_score = [accuracy_score(y_holdout, knn.predict(scaler.transform(X_holdout)))]<font></font>
<font></font>
<span class="hljs-keyword">for</span> tick <span class="hljs-keyword">in</span> range(<span class="hljs-number">40</span>):
    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> range(searchArea.shape[<span class="hljs-number">1</span>]):<font></font>
        changePropertyNormalization(p, <span class="hljs-number">7</span>)<font></font>
    <font></font>
print(searchArea[<span class="hljs-number">1</span>,:])<font></font>
print(history_holdout_score)</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La précision résultante de knn: 91,9% meilleure que lorsque nous déchirons les données de l'arbre. </font><font style="vertical-align: inherit;">Et beaucoup, beaucoup mieux que dans la version originale. </font><font style="vertical-align: inherit;">Comparez ce que nous avons avec l'importance des fonctionnalités selon l'arbre de décision:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualisation de l'importance des fonctionnalités selon knn</font></font></b><div class="spoiler_text"><pre><code class="python hljs">feature_importances[<span class="hljs-string">'knn_importance'</span>] = history_parametrs[<span class="hljs-number">-1</span>]<font></font>
diagramma = feature_importances.copy()<font></font>
indexes = diagramma.index<font></font>
diagramma.index = diagramma[<span class="hljs-string">'features'</span>]<font></font>
diagramma.drop(<span class="hljs-string">'features'</span>, <span class="hljs-number">1</span>, inplace = <span class="hljs-literal">True</span>)<font></font>
diagramma.plot(kind=<span class="hljs-string">'bar'</span>);<font></font>
plt.savefig(<span class="hljs-string">"images/pic1.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()<font></font>
feature_importances</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/kk/pe/nf/kkpenftrnyfl6dpu4p1qh2dnwqq.gif"><br>
<br>
<img src="https://habrastorage.org/webt/ui/o2/rp/uio2rplq9j2p5cxppq7jb7h_mpk.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Semble être? </font><font style="vertical-align: inherit;">Oui, semble-t-il. </font><font style="vertical-align: inherit;">Mais loin d'être identique. </font><font style="vertical-align: inherit;">Observation intéressante. </font><font style="vertical-align: inherit;">Il existe plusieurs fonctionnalités dans l'ensemble de données qui se dupliquent complètement, par exemple, «Total des minutes de nuit» et «Total de nuit de charge». </font><font style="vertical-align: inherit;">Alors faites attention, knn a lui-même scié une partie importante de ces caractéristiques répétées.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous enregistrerons les résultats dans un fichier, sinon il est quelque peu gênant de retourner au travail ...</font></font></b><div class="spoiler_text"><pre><code class="python hljs">parametrs_df = pd.DataFrame(history_parametrs)<font></font>
parametrs_df[<span class="hljs-string">'scores'</span>] = history_holdout_score<font></font>
parametrs_df.index.name = <span class="hljs-string">'index'</span>
parametrs_df.to_csv(<span class="hljs-string">'parametrs_and_scores.csv'</span>)
</code></pre></div></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">résultats</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, le résultat .919 en soi n'est pas mauvais pour knn, il y a 1,5 fois moins d'erreurs que dans la version vanille et 7% de moins que lorsque nous avons pris l'arborescence feature_importance pour conduire. </font><font style="vertical-align: inherit;">Mais la chose la plus intéressante est que nous avons maintenant feature_importance selon knn lui-même. </font><font style="vertical-align: inherit;">C'est quelque peu différent de ce que l'arbre nous a dit. </font><font style="vertical-align: inherit;">Par exemple, tree et knn ont des opinions différentes sur lesquels des signes ne sont pas importants du tout pour nous. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Enfin, finalement. </font><font style="vertical-align: inherit;">Nous avons obtenu quelque chose de relativement nouveau et inhabituel, ayant une réserve de connaissances de trois conférences mlcourse.ai </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ods et Google pour répondre à des questions simples sur python. </font><font style="vertical-align: inherit;">À mon avis, pas mal.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant diapositives</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un sous-produit du travail de l'algorithme est le chemin qu'il a parcouru. Certes, le chemin est à 18 dimensions, ce qui entrave un peu sa conscience, eh bien, pour suivre en temps réel ce que fait l'algorithme là-bas, apprendre ou utiliser des ordures n'est pas si pratique. Selon le calendrier des erreurs, cela n'est en fait pas toujours visible. L'erreur peut ne pas changer sensiblement pendant longtemps, mais l'algorithme est très occupé, rampant le long d'une longue vallée étroite dans l'espace adaptatif. Par conséquent, j'appliquerai, pour commencer, la première approche la plus simple mais la plus informative - je projette au hasard un espace à 18 dimensions sur un espace à deux dimensions afin que les contributions de tous les paramètres, quelle que soit leur signification, soient uniques. En fait, le chemin à 18 dimensions est très petit, dans notre article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Peeping Over the Throws of a Neural Network</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> J'ai également admiré l'espace des échelles de toutes les synapses que possédait le réseau neuronal et c'était agréable et instructif.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'ai lu les données du fichier, si je retourne au travail, après avoir passé la formation elle-même</font></font></b><div class="spoiler_text"><pre><code class="python hljs">parametrs_df = pd.read_csv(<span class="hljs-string">'parametrs_and_scores.csv'</span>, index_col = <span class="hljs-string">'index'</span>)<font></font>
history_holdout_score = np.array(parametrs_df[<span class="hljs-string">'scores'</span>])<font></font>
parametrs_df.drop(<span class="hljs-string">'scores'</span>,axis=<span class="hljs-number">1</span>)<font></font>
history_parametrs = np.array(parametrs_df.drop(<span class="hljs-string">'scores'</span>,axis=<span class="hljs-number">1</span>))</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'erreur sur la validation cesse de changer à partir d'un certain point. </font><font style="vertical-align: inherit;">Ici, il serait possible de visser un arrêt automatique d'apprentissage et d'utiliser la fonction reçue pour le reste de ma vie, mais j'ai déjà un peu de temps. </font><font style="vertical-align: inherit;">:(</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous déterminons combien étudier.</font></font></b><div class="spoiler_text"><pre><code class="python hljs">last = history_holdout_score[<span class="hljs-number">-1</span>]<font></font>
steps = np.arange(<span class="hljs-number">0</span>, history_holdout_score.shape[<span class="hljs-number">0</span>])[history_holdout_score != last].max()<font></font>
print(steps/<span class="hljs-number">18</span>)</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
35.5555555555555556 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons changé un paramètre à la fois, donc un cycle d'optimisation se </font><font style="vertical-align: inherit;">compose de </font><font style="vertical-align: inherit;">18 étapes. </font><font style="vertical-align: inherit;">Il s'avère que nous avons eu 36 étapes significatives, ou quelque chose comme ça. </font><font style="vertical-align: inherit;">Essayons maintenant de visualiser la trajectoire le long de laquelle la méthode a été formée.</font></font><br>
<br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Texte masqué</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-comment">#    :</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> math<font></font>
random.seed(<span class="hljs-number">17</span>)<font></font>
property_projection = np.array([[math.sin(a), math.cos(a)] <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> [random.uniform(-math.pi, math.pi) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(history_parametrs[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>])]]).transpose()<font></font>
history = np.array(history_parametrs[::<span class="hljs-number">18</span>]) <span class="hljs-comment">#   - 18 .</span>
<span class="hljs-comment">#           . :(</span>
points = np.array([(history[i] * property_projection).sum(axis=<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(history.shape[<span class="hljs-number">0</span>])])<font></font>
plt.plot(points[:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">0</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.savefig(<span class="hljs-string">"images/pic2.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/jt/zs/rc/jtzsrcgk60i_aeqhcvxjq9atvee.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On peut voir qu'une partie importante du voyage a été réalisée au cours des quatre premières étapes. </font><font style="vertical-align: inherit;">Regardons le reste du chemin avec l'augmentation</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sans les 4 premiers points</font></font></b><div class="spoiler_text"><pre><code class="python hljs">plt.plot(points[<span class="hljs-number">4</span>:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">4</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.savefig(<span class="hljs-string">"images/pic3.png"</span>, format = <span class="hljs-string">'png'</span>)</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/gq/xh/wa/gqxhwawt9nnsmypgk3tkry9vbpw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Examinons de plus près la dernière partie du chemin et voyons ce que l'enseignant a fait après avoir atteint sa destination.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">se rapprocher</font></font></b><div class="spoiler_text"><pre><code class="python hljs">plt.plot(points[<span class="hljs-number">14</span>:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">14</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.savefig(<span class="hljs-string">"images/pic4.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()<font></font>
plt.plot(points[<span class="hljs-number">24</span>:<span class="hljs-number">36</span>,<span class="hljs-number">0</span>],points[<span class="hljs-number">24</span>:<span class="hljs-number">36</span>,<span class="hljs-number">1</span>]);<font></font>
plt.plot(points[<span class="hljs-number">35</span>:,<span class="hljs-number">0</span>],points[<span class="hljs-number">35</span>:,<span class="hljs-number">1</span>], color = <span class="hljs-string">'red'</span>);<font></font>
plt.savefig(<span class="hljs-string">"images/pic5.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show()</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/a5/kq/6m/a5kq6mq5yxl3roojyjfzdw8wq8a.png"><br>
<br>
<img src="https://habrastorage.org/webt/g5/lo/gs/g5logsa_jmna5lveoc-w0679koy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On peut voir que l'algorithme est entraîné intensément. Jusqu'à ce qu'il trouve sa destination. Le point spécifique, bien sûr, dépend de la randomisation dans la validation croisée. Mais quel que soit le point spécifique, l'image générale de ce qui se passe est compréhensible. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Soit dit en passant, j'avais l'habitude d'utiliser un tel calendrier pour démontrer le processus d'apprentissage. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Non pas la trajectoire entière est affichée, mais les dernières étapes avec un lissage glissant de l'échelle. Un exemple peut être trouvé dans mon autre article, «Nous espions sur les lancers d'un réseau neuronal». Et oui, bien sûr, tous ceux qui rencontrent une telle visualisation demandent immédiatement pourquoi tous les facteurs ont le même poids, la même importance, alors ils ont différents. La dernière fois dans l'article, j'ai essayé de repenser l'importance des synapses et cela s'est avéré moins instructif.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cette fois, armée de nouvelles connaissances, je vais essayer d'utiliser t-SNE pour déployer un espace multidimensionnel dans une projection où tout peut être mieux.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t-SNE</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">import</span> sklearn.manifold <span class="hljs-keyword">as</span> manifold<font></font>
tsne = manifold.TSNE(random_state=<span class="hljs-number">19</span>)<font></font>
tsne_representation = tsne.fit_transform(history)<font></font>
plt.plot(tsne_representation[:, <span class="hljs-number">0</span>], tsne_representation[:, <span class="hljs-number">1</span>])<font></font>
plt.savefig(<span class="hljs-string">"images/pic6.png"</span>, format = <span class="hljs-string">'png'</span>)<font></font>
plt.show();</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/qe/bp/nn/qebpnnz71ywbxgqvhzj3fpv8vzc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
t-Sne semble avoir déplié l'espace de sorte qu'il a complètement mangé l'échelle des changements pour les fonctionnalités qui ont rapidement cessé de changer, ce qui a rendu l'image complètement non informative. </font><font style="vertical-align: inherit;">Conclusion - n'essayez pas de glisser les algorithmes dans des endroits qui ne leur sont pas destinés: \</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous ne pouvez pas lire plus loin</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'ai également essayé d'injecter tsne à l'intérieur pour visualiser les états d'optimisation intermédiaires, dans l'espoir que la beauté se révèle. mais il s'est avéré que ce n'était pas de la beauté, des ordures. Si vous êtes intéressé, voyez comment le faire. Internet est parsemé d'exemples de ce type de code d'injection, mais en copiant simplement, ils ne pa </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">botent</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pas car le substitut contenu dans </font><b><font style="vertical-align: inherit;">sklearn.manifold.t_sne</font></b><font style="vertical-align: inherit;"> fonction interne </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">_gradient_descent</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et selon la version peut être très différent à la fois dans la signature et sur le traitement des variables internes. Il vous suffit donc de trouver les sources en vous-même, de sélectionner votre version de la fonction à partir de là et d'y insérer une seule ligne qui ajoute des vidages intermédiaires à votre variable: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
positions.append (p.copy ()) # Nous enregistrons la position actuelle.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et puis, comme, nous visualisons magnifiquement ce que nous obtenons en conséquence:</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code d'injection</font></font></b><div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> linalg
<span class="hljs-comment"># This list will contain the positions of the map points at every iteration.</span><font></font>
positions = []<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_gradient_descent</span>(<span class="hljs-params">objective, p0, it, n_iter,
                      n_iter_check=<span class="hljs-number">1</span>, n_iter_without_progress=<span class="hljs-number">300</span>,
                      momentum=<span class="hljs-number">0.8</span>, learning_rate=<span class="hljs-number">200.0</span>, min_gain=<span class="hljs-number">0.01</span>,
                      min_grad_norm=<span class="hljs-number">1e-7</span>, verbose=<span class="hljs-number">0</span>, args=None, kwargs=None</span>):</span>
    <span class="hljs-comment"># The documentation of this function can be found in scikit-learn's code.</span>
    <span class="hljs-keyword">if</span> args <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
        args = []<font></font>
    <span class="hljs-keyword">if</span> kwargs <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
        kwargs = {}<font></font>
<font></font>
    p = p0.copy().ravel()<font></font>
    update = np.zeros_like(p)<font></font>
    gains = np.ones_like(p)<font></font>
    error = np.finfo(np.float).max<font></font>
    best_error = np.finfo(np.float).max<font></font>
    best_iter = i = it<font></font>
<font></font>
    tic = time()<font></font>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(it, n_iter):<font></font>
        positions.append(p.copy()) <span class="hljs-comment"># We save the current position.</span><font></font>
        <font></font>
        check_convergence = (i + <span class="hljs-number">1</span>) % n_iter_check == <span class="hljs-number">0</span>
        <span class="hljs-comment"># only compute the error when needed</span>
        kwargs[<span class="hljs-string">'compute_error'</span>] = check_convergence <span class="hljs-keyword">or</span> i == n_iter - <span class="hljs-number">1</span><font></font>
<font></font>
        error, grad = objective(p, *args, **kwargs)<font></font>
        grad_norm = linalg.norm(grad)<font></font>
<font></font>
        inc = update * grad &lt; <span class="hljs-number">0.0</span><font></font>
        dec = np.invert(inc)<font></font>
        gains[inc] += <span class="hljs-number">0.2</span>
        gains[dec] *= <span class="hljs-number">0.8</span><font></font>
        np.clip(gains, min_gain, np.inf, out=gains)<font></font>
        grad *= gains<font></font>
        update = momentum * update - learning_rate * grad<font></font>
        p += update<font></font>
<font></font>
        <span class="hljs-keyword">if</span> check_convergence:<font></font>
            toc = time()<font></font>
            duration = toc - tic<font></font>
            tic = toc<font></font>
<font></font>
            <span class="hljs-keyword">if</span> verbose &gt;= <span class="hljs-number">2</span>:<font></font>
                print(<span class="hljs-string">"[t-SNE] Iteration %d: error = %.7f,"</span>
                      <span class="hljs-string">" gradient norm = %.7f"</span>
                      <span class="hljs-string">" (%s iterations in %0.3fs)"</span>
                      % (i + <span class="hljs-number">1</span>, error, grad_norm, n_iter_check, duration))<font></font>
<font></font>
            <span class="hljs-keyword">if</span> error &lt; best_error:<font></font>
                best_error = error<font></font>
                best_iter = i<font></font>
            <span class="hljs-keyword">elif</span> i - best_iter &gt; n_iter_without_progress:
                <span class="hljs-keyword">if</span> verbose &gt;= <span class="hljs-number">2</span>:<font></font>
                    print(<span class="hljs-string">"[t-SNE] Iteration %d: did not make any progress "</span>
                          <span class="hljs-string">"during the last %d episodes. Finished."</span>
                          % (i + <span class="hljs-number">1</span>, n_iter_without_progress))
                <span class="hljs-keyword">break</span>
            <span class="hljs-keyword">if</span> grad_norm &lt;= min_grad_norm:
                <span class="hljs-keyword">if</span> verbose &gt;= <span class="hljs-number">2</span>:<font></font>
                    print(<span class="hljs-string">"[t-SNE] Iteration %d: gradient norm %f. Finished."</span>
                          % (i + <span class="hljs-number">1</span>, grad_norm))
                <span class="hljs-keyword">break</span><font></font>
<font></font>
    <span class="hljs-keyword">return</span> p, error, i<font></font>
<font></font>
manifold.t_sne._gradient_descent = _gradient_descent</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Appliquer le t-SNE `` fixe ''</font></font></b><div class="spoiler_text"><pre><code class="python hljs">tsne_representation = manifold.TSNE(random_state=<span class="hljs-number">17</span>).fit_transform(history)<font></font>
X_iter = np.dstack(position.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> position <span class="hljs-keyword">in</span> positions)<font></font>
position_reshape = [position.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> position <span class="hljs-keyword">in</span> positions]<font></font>
print(position_reshape[<span class="hljs-number">0</span>].shape)<font></font>
print(<span class="hljs-string">'[0] min'</span>, position_reshape[<span class="hljs-number">0</span>][:,<span class="hljs-number">0</span>].min(),<span class="hljs-string">'max'</span>, position_reshape[<span class="hljs-number">0</span>][:,<span class="hljs-number">0</span>].max())<font></font>
print(<span class="hljs-string">'[1] min'</span>, position_reshape[<span class="hljs-number">1</span>][:,<span class="hljs-number">0</span>].min(),<span class="hljs-string">'max'</span>, position_reshape[<span class="hljs-number">1</span>][:,<span class="hljs-number">0</span>].max())<font></font>
print(<span class="hljs-string">'[2] min'</span>, position_reshape[<span class="hljs-number">2</span>][:,<span class="hljs-number">0</span>].min(),<span class="hljs-string">'max'</span>, position_reshape[<span class="hljs-number">2</span>][:,<span class="hljs-number">0</span>].max())
</code></pre></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(41, 2) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[0] min -0,00018188123 max 0,00027207955 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[1] min -0,05136269 max 0,032607622 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[2] min -4,392309 max 7,9074526 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les valeurs dansent dans une très large plage, je vais donc les mettre à l'échelle avant de les dessiner. </font><font style="vertical-align: inherit;">Sur les cycles, tout cela se fait kapets lentement. </font><font style="vertical-align: inherit;">:(</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je l'échelle</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler<font></font>
minMaxScaler = MinMaxScaler()<font></font>
minMaxScaler.fit_transform(position_reshape[<span class="hljs-number">0</span>])<font></font>
position_reshape = [minMaxScaler.fit_transform(frame) <span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> position_reshape]<font></font>
position_reshape[<span class="hljs-number">0</span>].min(), position_reshape[<span class="hljs-number">0</span>].max()</code></pre></div></div><br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Animer</font></font></b><div class="spoiler_text"><pre><code class="python hljs">%%time<font></font>
<font></font>
<span class="hljs-keyword">from</span> matplotlib.animation <span class="hljs-keyword">import</span> FuncAnimation, PillowWriter
<span class="hljs-comment">#plt.style.use('seaborn-pastel')</span><font></font>
<font></font>
fig = plt.figure()<font></font>
<font></font>
ax = plt.axes(xlim=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), ylim=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<font></font>
line, = ax.plot([], [], lw=<span class="hljs-number">3</span>)<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init</span>():</span><font></font>
    line.set_data([], [])<font></font>
    <span class="hljs-keyword">return</span> line,
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">animate</span>(<span class="hljs-params">i</span>):</span>
    x = position_reshape[i][:,<span class="hljs-number">0</span>]<font></font>
    y = position_reshape[i][:,<span class="hljs-number">1</span>]<font></font>
    line.set_data(x, y)<font></font>
    <span class="hljs-keyword">return</span> line,<font></font>
<font></font>
anim = FuncAnimation(fig, animate, init_func=init, frames=<span class="hljs-number">36</span>, interval=<span class="hljs-number">20</span>, blit=<span class="hljs-literal">True</span>, repeat_delay = <span class="hljs-number">1000</span>)<font></font>
anim.save(<span class="hljs-string">'images/animate_tsne_learning.gif'</span>, writer=PillowWriter(fps=<span class="hljs-number">5</span>))
</code></pre></div></div><br>
<img src="https://habrastorage.org/webt/lh/dq/g6/lhdqg6khzhplw6jtkei6y0s3pdu.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
C'est instructif en termes de compétences, mais absolument inutile dans cette tâche et moche. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur ce, je vous dis au revoir. </font><font style="vertical-align: inherit;">J'espère que l'idée que même de knn vous pouvez obtenir quelque chose de nouveau et d'intéressant, ainsi que des morceaux de code, vous aidera et vous amusera avec les données de cette fête intellectuelle pendant la peste.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr496466/index.html">Toute source de lumière assez rapide a un décalage Doppler rouge</a></li>
<li><a href="../fr496472/index.html">10 référentiels intéressants sur GitHub, utiles à tout développeur</a></li>
<li><a href="../fr496476/index.html">Poussez Windows Server sur un VPS de faible puissance à l'aide de Windows Server Core</a></li>
<li><a href="../fr496480/index.html">Le son du futur silence</a></li>
<li><a href="../fr496482/index.html">Le développement d'un leadership informé pour la gestion d'équipe</a></li>
<li><a href="../fr496486/index.html">Opinion: Spamhaus - censure en ligne ou combattants du web propres?</a></li>
<li><a href="../fr496488/index.html">Les fournisseurs IaaS luttent contre les attaques contre le protocole BGP</a></li>
<li><a href="../fr496490/index.html">Nous étudions le moteur VoIP Mediastreamer2. Partie 7</a></li>
<li><a href="../fr496492/index.html">Fonctions de base de LXD - Systèmes de conteneurs Linux</a></li>
<li><a href="../fr496494/index.html">Nous jouons de la musique de Mario sur le haut-parleur du système</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
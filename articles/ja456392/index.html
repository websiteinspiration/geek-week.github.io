<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤟 📪 🚝 AWKおよびRを備えたParsim 25TB 🙂 📕 🚆</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="この記事の読み方：テキストが長くて無秩序になってしまったことをお詫びします。時間を節約するために、各章の冒頭で「私が学んだこと」を紹介し、その章の本質を1〜2文で説明します。
 
 「解決策を示すだけです！」私がこれまでに得たものを見たいだけの場合は、「より独創的になる」の章に進んでください。しかし...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>AWKおよびRを備えたParsim 25TB</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/456392/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/9d/3y/lc/9d3ylcjuqiv6r7vrv6p52apvmne.jpeg"></div><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">この記事の読み方</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：テキストが長くて無秩序になってしまったことをお詫びします。時間を節約するために、各章の冒頭で「私が学んだこと」を紹介し、その章の本質を1〜2文で説明します。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「解決策を示すだけです！」</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私がこれまでに得たものを見たいだけの場合は、「より独創的になる」の章に進んでください。しかし、失敗について読むことは、より興味深く、役に立つと思います。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最近、大量の元のDNA配列を処理するプロセスをセットアップするように指示されました（技術的には、これはSNPチップです）。</font><font style="vertical-align: inherit;">後続のモデリングやその他のタスクのために、特定の遺伝的位置（SNPと呼ばれる）に関するデータをすばやく取得する必要がありました。</font><font style="vertical-align: inherit;">RとAWKの助けを借りて、自然な方法でデータを整理して整理でき、リクエストの処理を大幅に高速化できました。</font><font style="vertical-align: inherit;">これは私にとっては簡単ではなく、何度も繰り返す必要がありました。</font><font style="vertical-align: inherit;">この記事は、私の間違いのいくつかを回避し、最後に私が何をしたかを示すのに役立ちます。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初に、いくつかの紹介的な説明。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
大学の遺伝子情報処理センターは、25 TBのTSVデータを提供してくれました。</font><font style="vertical-align: inherit;">私はそれらをGzipで圧縮された5つのパッケージに分割しました。各パッケージには約240の4ギガバイトのファイルが含まれていました。</font><font style="vertical-align: inherit;">各行には、1人の1つのSNPのデータが含まれていました。</font><font style="vertical-align: inherit;">合計で、約250万のSNPと約6万人のデータが送信されました。</font><font style="vertical-align: inherit;">SNP情報に加えて、ファイルには、読み取り強度、異なる対立遺伝子の頻度など、さまざまな特性を反映する番号を含む列が多数ありました。</font><font style="vertical-align: inherit;">一意の値を持つ約30列がありました。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">目的</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
他のデータ管理プロジェクトと同様に、最も重要なことは、データの使用方法を決定することでした。</font><font style="vertical-align: inherit;">この場合、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ほとんどの</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">場合、</font><b><font style="vertical-align: inherit;">SNPに基づいてSNPのモデルとワークフローを選択します</font></b><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">つまり、同時に必要なSNPは1つだけです。</font><font style="vertical-align: inherit;">250万のSNPの1つに関連するすべてのレコードをできるだけ簡単、迅速かつ安価に抽出する方法を学ぶ必要がありました。</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">それをしない方法</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
適切な決まり文句を引用します。</font></font><br>
<br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私は何千回も失敗しませんでした。クエリに便利な形式で大量のデータを解析しない1000の方法を発見しました。</font></font></blockquote><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">初挑戦</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：一度に25 TBを解析する安価な方法はありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ヴァンダービルト大学で主題「高度なビッグデータ処理方法」を聞いた後、それは帽子であると確信しました。おそらく、すべてのデータを実行して結果を報告するようにHiveサーバーをセットアップするのに1〜2時間かかります。データはAWS S3に保存されているため、</font><font style="vertical-align: inherit;">S3データにHive SQLクエリを適用できる</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Athena</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">サービスを使用しました</font><font style="vertical-align: inherit;">。 Hiveクラスターを構成/生成する必要はなく、探しているデータに対してのみ支払います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
データとそのフォーマットをAthenaに示した後、同様のクエリを使用していくつかのテストを実行しました。</font></font><br>
<br>
<pre><code class="sql hljs"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> intensityData <span class="hljs-keyword">limit</span> <span class="hljs-number">10</span>;</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、すぐに構造化された結果が得られました。</font><font style="vertical-align: inherit;">できました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
仕事でデータを使おうとするまでは… </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SNPのモデルをテストするために、SNPに関するすべての情報を引き出すよう求められました。</font><font style="vertical-align: inherit;">私はクエリを実行しました：</font></font><br>
<br>
<pre><code class="sql hljs">
<span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> intensityData 
<span class="hljs-keyword">where</span> snp = <span class="hljs-string">'rs123456'</span>;</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
...そして待った。</font><font style="vertical-align: inherit;">8分後に要求されたデータが4 TBを超えると、結果が得られました。</font><font style="vertical-align: inherit;">Athenaは、テラバイトあたり5ドルで、見つかったデータの量に料金を請求します。</font><font style="vertical-align: inherit;">したがって、この1つの要求のコストは20ドルで、待機時間は8分です。</font><font style="vertical-align: inherit;">すべてのデータに従ってモデルを実行するには、38年待つ必要があり、5,000万ドルを支払う必要がありましたが、明らかにこれは私たちに適していませんでした。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parquetを使用する必要がありました...</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：Parquetファイルのサイズとその構成に注意してください。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初に、すべてのTSVを</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parquetファイルに</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">変換して状況を修正しようとしました</font><font style="vertical-align: inherit;">。行内に各列の要素が含まれているテキストファイルとは異なり、それらの情報は列形式で格納されるため、大きなデータセットの操作に便利です。各列は独自のメモリ/ディスクセグメントにあります。そして、何かを見つける必要がある場合は、必要な列を読んでください。さらに、値の範囲は列の各ファイルに保存されるため、目的の値が列の範囲にない場合でも、Sparkはファイル全体のスキャンに時間を浪費しません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
簡単な</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">AWS Glue</font></a><font style="vertical-align: inherit;">タスクを実行しました</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TSVをParquetに変換し、Athenaの新しいファイルを破棄します。</font><font style="vertical-align: inherit;">約5時間かかりました。</font><font style="vertical-align: inherit;">しかし、リクエストを開始したとき、それを完了するのにほぼ同じ時間と少し少ないお金がかかりました。</font><font style="vertical-align: inherit;">事実は、タスクを最適化しようとするSparkが、1つのTSVチャンクをアンパックし、それを独自のParquetチャンクに配置することです。</font><font style="vertical-align: inherit;">また、各チャンクは十分に大きく、多くの人々の完全な記録が含まれていたため、すべてのSNPが各ファイルに保存されたため、Sparkはすべてのファイルを開いて必要な情報を抽出する必要がありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
奇妙なことに、Parquetのデフォルト（および推奨）圧縮タイプ-snappy-は分割できません。</font><font style="vertical-align: inherit;">したがって、各エグゼキューターは、3.5 GBの完全なデータセットをアンパックしてダウンロードするタスクにこだわりました。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/f42/584/fb3/f42584fb3e65319eef46f117c11525f3.png"><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私たちは問題を理解しています</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：特にデータが分散されている場合、ソートするのは難しいです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
問題の本質を理解したように思えました。</font><font style="vertical-align: inherit;">私がしなければならなかったのは、人ではなくSNP列でデータをソートすることだけでした。</font><font style="vertical-align: inherit;">次に、いくつかのSNPが個別のデータチャンクに格納され、Parquetスマート関数が「値が範囲内にある場合にのみ開く」ことで、すべての栄光を示します。</font><font style="vertical-align: inherit;">残念ながら、クラスター全体に散在する数十億行を整理することは困難な作業であることが証明されています。</font></font><br>
<br>
<div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-0" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1105127759318319105"></twitter-widget>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「私はぼんやりした学生です」ので、AWSは確かに返金を望んでいません。</font><font style="vertical-align: inherit;">Amazon Glueで並べ替えを開始した後、2日間機能し、失敗しました。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パーティション化についてはどうですか？</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：Sparkのパーティションはバランスが取れている必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、染色体上のデータを分割するというアイデアが浮かびました。</font><font style="vertical-align: inherit;">それらは23個あります（ミトコンドリアDNAとマップされていない領域を考えると、さらにいくつかあります）。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これにより、データをより小さな部分に分割できます。</font><font style="vertical-align: inherit;">GlueスクリプトのSparkエクスポート関数に1行のみを追加する場合</font></font><code>partition_by = "chr"</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、データはバケットにソートされる必要があります。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/652/f42/3dc/652f423dc8806401b6638a3cf8c1480b.png"> <br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ゲノムは、染色体と呼ばれる多数の断片で構成されています。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
残念ながら、これは機能しませんでした。</font><font style="vertical-align: inherit;">染色体はサイズが異なるため、情報量も異なります。</font><font style="vertical-align: inherit;">これは、一部のノードが以前に終了してアイドル状態だったため、Sparkがワーカーに送信したタスクのバランスが取れておらず、実行速度が遅いことを意味しています。</font><font style="vertical-align: inherit;">ただし、タスクは完了しました。</font><font style="vertical-align: inherit;">しかし、1つのSNPを要求すると、不均衡が再び問題を引き起こしました。</font><font style="vertical-align: inherit;">より大きな染色体（つまり、データを取得する場所）でSNPを処理するコストは、約10分の1に減少しました。</font><font style="vertical-align: inherit;">たくさんありますが、十分ではありません。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">そして、さらに小さなパーティションに分割するとしたら？</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：250万のパーティションを作成しようとしないでください。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私は散歩に行くことにし、すべてのSNPを分割しました。</font><font style="vertical-align: inherit;">これにより、同じサイズのパーティションが保証されました。</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">悪いアイデアだった</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">私は接着剤を利用して、罪のないひもを追加しました</font></font><code>partition_by = 'snp'</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">タスクが開始され、実行が開始されました。</font><font style="vertical-align: inherit;">1日後、チェックしたところ、これまでのところS3には何も書き込まれていないことがわかり、タスクを強制終了しました。</font><font style="vertical-align: inherit;">グルーが中間ファイルをS3の隠された場所に書き込んでいたようで、多くのファイル、おそらく数百万のファイルが書き込まれています。</font><font style="vertical-align: inherit;">その結果、私の間違いは千ドル以上かかり、私のメンターを満足させませんでした。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パーティショニング+ソート</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：Sparkをセットアップするのと同じように、ソートはまだ難しいです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
パーティション分割の最後の試みは、染色体をパーティション分割して、各パーティションをソートすることでした。理論的には、必要なSNPデータは特定の範囲内の複数のParquetチャンク内にある必要があるため、これにより各要求が高速化されます。悲しいかな、分割されたデータでさえソートすることは難しい作業であることが証明されています。その結果、カスタムクラスターをEMRに切り替え、8つの強力なインスタンス（C5.4xl）とSparklyrを使用して、より柔軟なワークフローを作成しました...</font></font><br>
<br>
<pre><code class="scala hljs"># <span class="hljs-type">Sparklyr</span> snippet to partition by chr and sort w/in partition<font></font>
# <span class="hljs-type">Join</span> the raw data <span class="hljs-keyword">with</span> the snp bins<font></font>
raw_data<font></font>
  group_by(chr) %&gt;%<font></font>
  arrange(<span class="hljs-type">Position</span>) %&gt;% 
  <span class="hljs-type">Spark_write_Parquet</span>(<font></font>
    path = <span class="hljs-type">DUMP_LOC</span>,<font></font>
    mode = <span class="hljs-symbol">'overwrit</span>e',<font></font>
    partition_by = c(<span class="hljs-symbol">'ch</span>r')<font></font>
  )</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
...しかし、タスクはまだ完了していません。</font><font style="vertical-align: inherit;">私はあらゆる方法で調整しました：各クエリエグゼキューターのメモリ割り当てを増やし、大量のメモリを使用するノードを使用し、ブロードキャスト変数を使用しましたが、毎回それが半分の測定値であることが判明し、すべてが停止するまでパフォーマーは徐々に失敗し始めました。</font></font><br>
<br>
<div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-1" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1128703858610450434"></twitter-widget>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div><br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私はもっ​​と独創的になっています</font></font></h1><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：時々特別なデータは特別なソリューションを必要とします。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各SNPには位置の値があります。これは、その染色体に沿って存在する塩基の数に対応する数です。これは、データを整理するための適切で自然な方法です。最初は、各染色体の領域ごとに分割したいと思っていました。たとえば、位置1-2000、2001-4000など。しかし問題は、SNPが染色体全体に均一に分布していないことです。そのため、グループのサイズは大きく異なります。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/f46/a8e/17b/f46a8e17b9af8d2ae9777c47017764c6.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その結果、カテゴリー（ランク）のポジションに分かれるようになりました。既にダウンロードしたデータによると、私はユニークなSNP、それらの位置、染色体のリストのリクエストを実行しました。次に、各染色体内のデータを並べ替え、SNPを特定のサイズのグループ（ビン）に収集しました。それぞれ1000 SNPと言います。これにより、染色体グループとのSNP関係が得られました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結局、75 SNPでグループ（ビン）を作りましたが、その理由を以下に説明します。</font></font><br>
<br>
<pre><code class="bash hljs">snp_to_bin &lt;- unique_snps %&gt;% <font></font>
  group_by(chr) %&gt;% <font></font>
  arrange(position) %&gt;% <font></font>
  mutate(<font></font>
    rank = 1:n()<font></font>
    bin = floor(rank/snps_per_bin)<font></font>
  ) %&gt;% <font></font>
  ungroup()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最初にSparkを試す</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：Sparkの統合は高速ですが、パーティショニングは依然として高価です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この小さな（250万行）データフレームをSparkで読み取り、生データと組み合わせて、新しく追加した列でパーティション分割したいと考えていました</font></font><code>bin</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<pre><code class="sql hljs">
<span class="hljs-comment"># Join the raw data with the snp bins</span><font></font>
data_w_bin &lt;- raw_data %&gt;%<font></font>
  left_join(sdf_broadcast(snp_to_bin), by ='snp_name') %&gt;%<font></font>
  group_by(chr_bin) %&gt;%<font></font>
  arrange(Position) %&gt;% <font></font>
  Spark_write_Parquet(<font></font>
    path = DUMP_LOC,<font></font>
    mode = 'overwrite',<font></font>
    partition_by = c('chr_bin')<font></font>
  )</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私はを使用</font></font><code>sdf_broadcast()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">したので、Sparkはすべてのノードにデータフレームを送信する必要があることを検出しました。</font><font style="vertical-align: inherit;">これは、データが小さく、すべてのタスクに必要な場合に役立ちます。</font><font style="vertical-align: inherit;">そうでない場合、Sparkはスマートになり、必要に応じてデータを配信するため、ブレーキがかかる可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
繰り返しになりますが、私の考えはうまくいきませんでした。タスクはしばらくの間機能し、合併が完了し、その後、パーティション分割によって起動されたエグゼキュータのように、失敗し始めました。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AWKを追加</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：基本があなたを教えるとき、眠らないでください。きっと誰かがあなたの問題を1980年代にすでに解決してくれたことでしょう。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この時点まで、Sparkでのすべての失敗の理由は、クラスター内のデータの混乱でした。おそらく、前処理によって状況を改善できます。生のテキストデータを染色体の列に分割することを決定したので、Sparkに「事前に分割された」データを提供したいと考えていました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
列の値を分解する方法についてStackOverflowを検索し、そのよう</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">な素晴らしい答え</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を見つけました</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">。</font></a><font style="vertical-align: inherit;"> AWKを使用すると、結果をに送信するのではなくスクリプトに書き込むことで、テキストファイルを列の値に分割できます</font></font><code>stdout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テストのために、Bashスクリプトを作成しました。パックされたTSVの1つをダウンロードし、それを使用して解凍しました</font></font><code>gzip</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に送信されました</font></font><code>awk</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<pre><code class="bash hljs">gzip -dc path/to/chunk/file.gz |<font></font>
awk -F <span class="hljs-string">'\t'</span> \
<span class="hljs-string">'{print $1",..."$30"&gt;"chunked/"$chr"_chr"$15".csv"}'</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
動いた！</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コア充填</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：</font></font><code>gnu parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">魔法のことです、誰もがそれを使うべきです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
分離はかなり遅く、</font></font><code>htop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">強力な（そして高価な）EC2インスタンスの使用をテストし</font><font style="vertical-align: inherit;">始め</font><font style="vertical-align: inherit;">た</font><font style="vertical-align: inherit;">とき</font><font style="vertical-align: inherit;">、1つのコアと約200 MBのメモリしか使用していないことがわかりました。</font><font style="vertical-align: inherit;">問題を解決し、多くのお金を失うことのないように、作業を並列化する方法を理解する必要がありました。</font><font style="vertical-align: inherit;">幸い、</font><font style="vertical-align: inherit;">Jeron Janssensの</font><font style="vertical-align: inherit;">驚異的な</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コマンドサイエンスのデータサイエンスの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">本で、並列化に関する章を見つけました。</font><font style="vertical-align: inherit;">それから</font></font><code>gnu parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、Unixにマルチスレッドを実装するための非常に柔軟な方法</font><font style="vertical-align: inherit;">について学びました</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/835/7c0/e45/8357c0e45f4162d53ca1c3da0c78444a.png" width="300"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
新しいプロセスを使用してパーティションを開始したとき、すべては問題ありませんでしたが、ボトルネックがありました-S3オブジェクトをディスクにダウンロードするのが速すぎず、完全に並列化されていませんでした。</font><font style="vertical-align: inherit;">これを修正するために、私はこれを行いました：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S3ダウンロード手順をパイプラインに直接実装して、ディスク上の中間ストレージを完全に排除できることがわかりました。</font><font style="vertical-align: inherit;">これは、生データをディスクに書き込むことを避け、AWSでさらに小さく、したがって安価なストレージを使用できることを意味します。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">チーム</font></font><code>aws configure set default.s3.max_concurrent_requests 50 </code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">はAWS CLIが使用するスレッドの数を大幅に増やしました（デフォルトでは10です）。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">名前に文字nを使用して、ネットワーク速度に最適化されたEC2インスタンスに切り替えました。</font><font style="vertical-align: inherit;">nインスタンスを使用した場合の処理​​能力の損失は、ダウンロード速度の増加による相殺以上のものであることがわかりました。</font><font style="vertical-align: inherit;">ほとんどのタスクでは、c5n.4xlを使用しました。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に変更さ</font></font><code>gzip</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">れ</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><code>pigz</code></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">たgzipツールで、最初は比類のないファイルの解凍タスクを並列化することができます（これが最も役に立ちました）。</font></font><br>
</li>
</ol><br>
<pre><code class="bash hljs"><span class="hljs-comment"># Let S3 use as many threads as it wants</span>
aws configure <span class="hljs-built_in">set</span> default.s3.max_concurrent_requests 50<font></font>
<font></font>
<span class="hljs-keyword">for</span> chunk_file <span class="hljs-keyword">in</span> $(aws s3 ls <span class="hljs-variable">$DATA_LOC</span> | awk <span class="hljs-string">'{print $4}'</span> | grep <span class="hljs-string">'chr'</span><span class="hljs-variable">$DESIRED_CHR</span><span class="hljs-string">'.csv'</span>) ; <span class="hljs-keyword">do</span><font></font>
<font></font>
        aws s3 cp s3://<span class="hljs-variable">$batch_loc</span><span class="hljs-variable">$chunk_file</span> - |<font></font>
        pigz -dc |<font></font>
        parallel --block 100M --pipe  \<font></font>
        <span class="hljs-string">"awk -F '\t' '{print \$1\",...\"<span class="hljs-variable">$30</span>\"&gt;\"chunked/{#}_chr\"\$15\".csv\"}'"</span><font></font>
<font></font>
       <span class="hljs-comment"># Combine all the parallel process chunks to single files</span><font></font>
        ls chunked/ |<font></font>
        cut -d <span class="hljs-string">'_'</span> -f 2 |<font></font>
        sort -u |<font></font>
        parallel <span class="hljs-string">'cat chunked/*_{} | sort -k5 -n -S 80% -t, | aws s3 cp - '</span><span class="hljs-variable">$s3_dest</span><span class="hljs-string">'/batch_'</span><span class="hljs-variable">$batch_num</span><span class="hljs-string">'_{}'</span><font></font>
        <font></font>
         <span class="hljs-comment"># Clean up intermediate data</span><font></font>
       rm chunked/*<font></font>
<span class="hljs-keyword">done</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらの手順は互いに組み合わされているため、すべてが非常に迅速に機能します。</font><font style="vertical-align: inherit;">ダウンロード速度の向上とディスクへの書き込みの拒否のおかげで、5テラバイトのパッケージを数時間で処理できるようになりました。</font></font><br>
<br>
<div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-2" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1129416944233226240"></twitter-widget>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このつぶやきは「TSV」に言及することになっていた。</font><font style="vertical-align: inherit;">ああ。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">再解析されたデータの使用</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：Sparkは非圧縮データが大好きで、パーティションを組み合わせるのが好きではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで、データはアンパック（読み取り、共有）および半順序形式でS3になり、再びSparkに戻ることができました。驚きは私を待っていました：私は再び希望を達成するのに失敗しました！データがどのようにパーティション分割されているかをSparkに正確に伝えることは非常に困難でした。そして、これを行ったとしても、パーティションが多すぎる（95千）</font></font><code>coalesce</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ことがわかりました。パーティションの数を適切な制限</font><font style="vertical-align: inherit;">に</font><font style="vertical-align: inherit;">減らしたところ、パーティションが破壊されました。これは修正できると思いますが、数日探しても解決策は見つかりませんでした。少し時間がかかりましたが、最終的にはすべてのタスクをSparkで完了しました。また、分割したParquetファイルはそれほど小さくありませんでした（約200 KB）。ただし、データは必要な場所にありました。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/ae5/43b/236/ae543b236b8d37d4a6794aa63d9ada94.png"> <br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">小さすぎて違う、素晴らしい！</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ローカルSparkリクエストのテスト</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：Sparkは単純な問題を解決するのにオーバーヘッドが多すぎます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スマートなフォーマットでデータをダウンロードすることにより、速度をテストすることができました。</font><font style="vertical-align: inherit;">ローカルのSparkサーバーを起動するようにRでスクリプトを設定してから、Parquetグループ（bin）の指定されたリポジトリーからSparkデータフレームをロードしました。</font><font style="vertical-align: inherit;">すべてのデータをロードしようとしましたが、Sparklyrにパーティション分割を認識させることができませんでした。</font></font><br>
<br>
<pre><code class="scala hljs">sc &lt;- <span class="hljs-type">Spark_connect</span>(master = <span class="hljs-string">"local"</span>)<font></font>
<font></font>
desired_snp &lt;- <span class="hljs-symbol">'rs3477173</span>9'<font></font>
<font></font>
# <span class="hljs-type">Start</span> a timer<font></font>
start_time &lt;- <span class="hljs-type">Sys</span>.time()<font></font>
<font></font>
# <span class="hljs-type">Load</span> the desired bin into <span class="hljs-type">Spark</span><font></font>
intensity_data &lt;- sc %&gt;% <font></font>
  <span class="hljs-type">Spark_read_Parquet</span>(<font></font>
    name = <span class="hljs-symbol">'intensity_dat</span>a', <font></font>
    path = get_snp_location(desired_snp),<font></font>
    memory = <span class="hljs-type">FALSE</span> )<font></font>
<font></font>
# <span class="hljs-type">Subset</span> bin to snp and then collect to local<font></font>
test_subset &lt;- intensity_data %&gt;% <font></font>
  filter(<span class="hljs-type">SNP_Name</span> == desired_snp) %&gt;% <font></font>
  collect()<font></font>
<font></font>
print(<span class="hljs-type">Sys</span>.time() - start_time)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実行には29.415秒かかりました。</font><font style="vertical-align: inherit;">はるかに良いですが、何かを大量にテストするにはあまり良いとは言えません。</font><font style="vertical-align: inherit;">さらに、データフレームをメモリにキャッシュしようとすると、15未満のデータセットに50 GBを超えるメモリを割り当てた場合でも、Sparkが常にクラッシュしたため、キャッシュを使用して作業を高速化できませんでした。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AWKに戻る</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：AWK連想配列は非常に効率的です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
より高速にできることがわかりました。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bruce Barnett</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の優れたAWKガイドで、「</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">連想配列</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">」</font><font style="vertical-align: inherit;">と呼ばれるクールな機能について読んだ</font><font style="vertical-align: inherit;">ことを思い出しました</font><font style="vertical-align: inherit;">。実際、これらはキーと値のペアであり、何らかの理由でAWKでは異なる方法で呼び出されていたため、どういうわけか特にそれらについては触れませんでした。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Roman Cheplyaka</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、「連想配列」という用語は「キーと値のペア」という用語よりはるかに古いことを思い出しました。</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">Google NgramでKey-Value</font></a><font style="vertical-align: inherit;">を</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">検索して</font></a><font style="vertical-align: inherit;">も</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、この用語は表示されませんが、連想配列が見つかります！さらに、キーと値のペアはデータベースに関連付けられることが最も多いため、ハッシュマップと比較するとはるかに論理的です。 Sparkを使用せずに、これらの連想配列を使用してSNPをビンテーブルと生データにリンクできることに気付きました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このため、AWKスクリプトではブロックを使用しました</font></font><code>BEGIN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。これは、データの最初の行がスクリプトの本体に転送される前に実行されるコードです。</font></font><br>
<br>
<pre><code class="cpp hljs">join_data.awk<font></font>
BEGIN {<font></font>
  FS=<span class="hljs-string">","</span>;<font></font>
  batch_num=substr(chunk,<span class="hljs-number">7</span>,<span class="hljs-number">1</span>);<font></font>
  chunk_id=substr(chunk,<span class="hljs-number">15</span>,<span class="hljs-number">2</span>);
  <span class="hljs-keyword">while</span>(getline &lt; <span class="hljs-string">"snp_to_bin.csv"</span>) {bin[$<span class="hljs-number">1</span>] = $<span class="hljs-number">2</span>}<font></font>
}<font></font>
{<font></font>
  print $<span class="hljs-number">0</span> &gt; <span class="hljs-string">"chunked/chr_"</span>chr<span class="hljs-string">"_bin_"</span>bin[$<span class="hljs-number">1</span>]<span class="hljs-string">"_"</span>batch_num<span class="hljs-string">"_"</span>chunk_id<span class="hljs-string">".csv"</span>
}</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
コマンド</font></font><code>while(getline...)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、CSVグループ（bin）からすべての行をロードし、最初の列（SNP名）を連想配列のキーとして設定し</font></font><code>bin</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、2番目の値（グループ）を値として設定します。次に、</font></font><code>{</code> <code>}</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">メインファイルのすべての行に対して実行される</font><font style="vertical-align: inherit;">ブロック</font><font style="vertical-align: inherit;">で、各行が出力ファイルに送信され、グループ（binディレクトリ）に応じて一意の名前が付けられます</font></font><code>..._bin_"bin[$1]"_...</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
変数</font><font style="vertical-align: inherit;">は、コンベヤーによって提供されるデータ</font></font><code>batch_num</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font></font><code>chunk_id</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">反映し、競合状態を回避し、実行の各スレッドが実行され、</font></font><code>parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">独自のファイルに書き込みます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AWKを使用した前回の実験の後に残った染色体上のフォルダーにすべての生データを分散させたので、今度は別のBashスクリプトを作成して染色体を同時に処理し、より深いパーティションデータをS3に与えることができます。</font></font><br>
<br>
<pre><code class="bash hljs">DESIRED_CHR=<span class="hljs-string">'13'</span><font></font>
<font></font>
<span class="hljs-comment"># Download chromosome data from s3 and split into bins</span>
aws s3 ls <span class="hljs-variable">$DATA_LOC</span> |<font></font>
awk <span class="hljs-string">'{print $4}'</span> |<font></font>
grep <span class="hljs-string">'chr'</span><span class="hljs-variable">$DESIRED_CHR</span><span class="hljs-string">'.csv'</span> |<font></font>
parallel <span class="hljs-string">"echo 'reading {}'; aws s3 cp "</span><span class="hljs-variable">$DATA_LOC</span><span class="hljs-string">"{} - | awk -v chr=\""</span><span class="hljs-variable">$DESIRED_CHR</span><span class="hljs-string">"\" -v chunk=\"{}\" -f split_on_chr_bin.awk"</span><font></font>
<font></font>
<span class="hljs-comment"># Combine all the parallel process chunks to single files and upload to rds using R</span><font></font>
ls chunked/ |<font></font>
cut -d <span class="hljs-string">'_'</span> -f 4 |<font></font>
sort -u |<font></font>
parallel <span class="hljs-string">"echo 'zipping bin {}'; cat chunked/*_bin_{}_*.csv | ./upload_as_rds.R '<span class="hljs-variable">$S3_DEST</span>'/chr_'<span class="hljs-variable">$DESIRED_CHR</span>'_bin_{}.rds"</span>
rm chunked/*</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクリプトには2つのセクションがあります</font></font><code>parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初のセクションは、目的の染色体に関する情報を含むすべてのファイルからデータを読み取り、次にこのデータは、ファイルを対応するグループ（bin）に分散するストリーム全体に分散されます。</font><font style="vertical-align: inherit;">複数のストリームが単一のファイルに記録されるときの競合状態を回避するために、AWKはファイル名を渡して、たとえば、異なる場所にデータを記録します</font></font><code>chr_10_bin_52_batch_2_aa.csv</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">その結果、ディスク上に多数の小さなファイルが作成されます（このため、テラバイトのEBSボリュームを使用しました）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2番目のセクションのコンベヤは、</font></font><code>parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">グループ（bin）を通過し、個々のファイルを共通のCSV c </font></font><code>cat</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に</font><font style="vertical-align: inherit;">結合し</font><font style="vertical-align: inherit;">てから、エクスポートのために送信します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rにブロードキャストしますか？</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：あなたがアクセスすることができます</font></font><code>stdin</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">し、</font></font><code>stdout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R-スクリプトから、そのためのパイプラインでそれを使用しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bashスクリプト内には、次のような行があります</font></font><code>...cat chunked/*_bin_{}_*.csv | ./upload_as_rds.R...</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。すべての連結されたグループファイル（bin）を以下のRスクリプトに変換します。</font><font style="vertical-align: inherit;">送信されたデータを指定されたストリームに直接コマンド自体に挿入</font></font><code>{}</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">する特別な手法</font></font><code>parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。このオプション</font></font><code>{#}</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、一意のスレッドIDを提供し</font></font><code>{%}</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、ジョブスロット番号</font><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">表し</font><font style="vertical-align: inherit;">ます</font><font style="vertical-align: inherit;">（繰り返されますが、同時には行われません）。すべてのオプションのリストは</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ドキュメント</font></a><font style="vertical-align: inherit;">にあり</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font></font></a><br>
<br>
<pre><code class="lisp hljs"><span class="hljs-meta">#!/usr/bin/env Rscript</span>
library(<span class="hljs-name">readr</span>)<font></font>
library(<span class="hljs-name">aws</span>.s3)<font></font>
<font></font>
# Read first command line argument<font></font>
data_destination &lt;- commandArgs(<span class="hljs-name">trailingOnly</span> = TRUE)[<span class="hljs-number">1</span>]<font></font>
<font></font>
data_cols &lt;- list(<span class="hljs-name">SNP_Name</span> = 'c', ...)<font></font>
<font></font>
s3saveRDS(<font></font>
  <span class="hljs-name">read_csv</span>(
        <span class="hljs-name">file</span>(<span class="hljs-string">"stdin"</span>), <font></font>
        col_names = names(<span class="hljs-name">data_cols</span>),<font></font>
        col_types = data_cols <font></font>
    ),<font></font>
  object = data_destination<font></font>
)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
変数がに</font></font><code>file("stdin")</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">転送さ</font></font><code>readr::read_csv</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">れると、Rスクリプトに変換されたデータがフレームに読み込まれ、</font><font style="vertical-align: inherit;">Sを直接</font></font><code>.rds</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用し</font><font style="vertical-align: inherit;">て</font><font style="vertical-align: inherit;">ファイル</font><font style="vertical-align: inherit;">の形式で</font></font><code>aws.s3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">書き込ま</font><font style="vertical-align: inherit;">れ</font><font style="vertical-align: inherit;">ます</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
RDSは、列ストレージのフリルがない、Parquetの新しいバージョンに少し似ています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bashスクリプトを完成させた後</font></font><code>.rds</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、S3にある多数のファイル</font><font style="vertical-align: inherit;">を受け取りました</font><font style="vertical-align: inherit;">。これにより、効率的な圧縮と組み込み型を使用できるようになりました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ブレーキRを使用しているにもかかわらず、すべてが非常に速く機能しました。</font><font style="vertical-align: inherit;">データの読み取りと書き込みを担当するRのフラグメントが適切に最適化されていることは当然のことです。</font><font style="vertical-align: inherit;">1つの中型の染色体でテストした後、タスクはC5n.4xlインスタンスで約2時間で完了しました。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S3の制限</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：パスのスマートな実装のおかげで、S3は多くのファイルを処理できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
S3に転送された多くのファイルを処理できるかどうか心配でした。ファイル名を意味のあるものにすることはできますが、S3はそれらをどのように探しますか？</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/841/0dc/c34/8410dcc34a563c683dd7602dc66d884a.png"> <br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S3のフォルダーは単に美しさのためのものであり、実際、システムはシンボルに関心がありません</font></font><code>/</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S3 FAQページから。</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
S3は、特定のファイルへのパスを、一種のハッシュテーブルまたはドキュメントベースのデータベースの単純なキーとして表しているようです。バケットはテーブルと考えることができ、ファイルはこのテーブルのエントリと考えることができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Amazonで利益を上げるには速度と効率が重要であるため、このキーからファイルへのファイルシステムが驚くほど最適化されていることは驚くに値しません。</font><font style="vertical-align: inherit;">私はバランスを見つけようとしました。これにより、多くのget要求を行う必要がなくなり、要求が迅速に実行されるようになりました。</font><font style="vertical-align: inherit;">約2万個のbinファイルを実行するのが最適であることがわかりました。</font><font style="vertical-align: inherit;">最適化を続ければ、速度を上げることができると思います（たとえば、データ専用の特別なバケットを作成して、検索テーブルのサイズを小さくします）。</font><font style="vertical-align: inherit;">しかし、さらなる実験のための時間とお金はもはやありませんでした。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">相互互換性についてはどうですか？</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私が学んだこと：時間を失う主な理由は、保存方法の時期尚早の最適化です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この時点で、「なぜ独自のファイル形式を使用するのか」と自問することが非常に重要です。</font><font style="vertical-align: inherit;">その理由は、ダウンロード速度（パックされたgzip CSVファイルが7倍長く読み込まれた）と私たちの作業プロセスとの互換性です。</font><font style="vertical-align: inherit;">RがSparkの形式でロードせずにParquet（またはArrow）ファイルを簡単にロードできるかどうか、私の決定を再考できます。</font><font style="vertical-align: inherit;">私たちの研究室では、誰もがRを使用しており、データを別の形式に変換する必要がある場合でも、元のテキストデータが残っているので、パイプラインを再び開始できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ワークシェアリング</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：手動でタスクを最適化しようとせず、コンピューターに任せてください。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1つの染色体でワークフローをデバッグしましたが、他のすべてのデータを処理する必要があります。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
変換のためにいくつかのEC2インスタンスを上げたかったのですが、同時に、さまざまな処理タスクで非常に不均衡な負荷がかかることを恐れていました（Sparkが不均衡なパーティションに悩まされていたように）。さらに、AWSアカウントのデフォルトの制限は10インスタンスであるため、染色体ごとに1つのインスタンスを発生させたくありませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、Rでスクリプトを作成して、処理タスクを最適化することにしました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、S3に各染色体が占めるストレージ容量を計算するように依頼しました。</font></font><br>
<br>
<pre><code class="bash hljs">library(aws.s3)<font></font>
library(tidyverse)<font></font>
<font></font>
chr_sizes &lt;- get_bucket_df(<font></font>
  bucket = <span class="hljs-string">'...'</span>, prefix = <span class="hljs-string">'...'</span>, max = Inf<font></font>
) %&gt;% <font></font>
  mutate(Size = as.numeric(Size)) %&gt;% <font></font>
  filter(Size != 0) %&gt;% <font></font>
  mutate(<font></font>
    <span class="hljs-comment"># Extract chromosome from the file name </span>
    chr = str_extract(Key, <span class="hljs-string">'chr.{1,4}\\.csv'</span>) %&gt;%<font></font>
             str_remove_all(<span class="hljs-string">'chr|\\.csv'</span>)<font></font>
  ) %&gt;% <font></font>
  group_by(chr) %&gt;% <font></font>
  summarise(total_size = sum(Size)/1e+9) <span class="hljs-comment"># Divide to get value in GB</span><font></font>
<font></font>
<font></font>
<font></font>
<span class="hljs-comment"># A tibble: 27 x 2</span><font></font>
   chr   total_size<font></font>
   &lt;chr&gt;      &lt;dbl&gt;<font></font>
 1 0           163.<font></font>
 2 1           967.<font></font>
 3 10          541.<font></font>
 4 11          611.<font></font>
 5 12          542.<font></font>
 6 13          364.<font></font>
 7 14          375.<font></font>
 8 15          372.<font></font>
 9 16          434.<font></font>
10 17          443.<font></font>
<span class="hljs-comment"># … with 17 more rows</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、合計サイズを取得し、染色体の順序を入れ替えてグループに分け</font></font><code>num_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、すべての処理ジョブのサイズがどの程度異なるかを報告</font><font style="vertical-align: inherit;">する関数を</font><font style="vertical-align: inherit;">作成</font><font style="vertical-align: inherit;">しました</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<pre><code class="bash hljs">num_jobs &lt;- 7
<span class="hljs-comment"># How big would each job be if perfectly split?</span>
job_size &lt;- sum(chr_sizes<span class="hljs-variable">$total_size</span>)/7<font></font>
<font></font>
shuffle_job &lt;- <span class="hljs-keyword">function</span>(i){<font></font>
  chr_sizes %&gt;%<font></font>
    sample_frac() %&gt;% <font></font>
    mutate(<font></font>
      cum_size = cumsum(total_size),<font></font>
      job_num = ceiling(cum_size/job_size)<font></font>
    ) %&gt;% <font></font>
    group_by(job_num) %&gt;% <font></font>
    summarise(<font></font>
      job_chrs = paste(chr, collapse = <span class="hljs-string">','</span>),<font></font>
      total_job_size = sum(total_size)<font></font>
    ) %&gt;% <font></font>
    mutate(sd = sd(total_job_size)) %&gt;% <font></font>
    nest(-sd)<font></font>
}<font></font>
<font></font>
shuffle_job(1)<font></font>
<font></font>
<font></font>
<font></font>
<span class="hljs-comment"># A tibble: 1 x 2</span><font></font>
     sd data            <font></font>
  &lt;dbl&gt; &lt;list&gt;          <font></font>
1  153. &lt;tibble [7 × 3]&gt;</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それから私はゴロゴロと千回の攪拌を実行し、最高のものを選びました。</font></font><br>
<br>
<pre><code class="bash hljs">1:1000 %&gt;% <font></font>
  map_df(shuffle_job) %&gt;% <font></font>
  filter(sd == min(sd)) %&gt;% <font></font>
  pull(data) %&gt;% <font></font>
  pluck(1)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そのため、サイズが非常に似ている一連のタスクを取得しました。</font><font style="vertical-align: inherit;">次に、以前のBashスクリプトを大きなループでラップするだけでした</font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">この最適化を記述するのに約10分かかりました。</font><font style="vertical-align: inherit;">そして、これは、不均衡の場合に手動でタスクを作成するのに費やしたであろうものよりもはるかに少ないです。</font><font style="vertical-align: inherit;">したがって、私はこの予備的な最適化で私が失うことはなかったと信じています。</font></font><br>
<br>
<pre><code class="bash hljs"><span class="hljs-keyword">for</span> DESIRED_CHR <span class="hljs-keyword">in</span> <span class="hljs-string">"16"</span> <span class="hljs-string">"9"</span> <span class="hljs-string">"7"</span> <span class="hljs-string">"21"</span> <span class="hljs-string">"MT"</span>
<span class="hljs-keyword">do</span>
<span class="hljs-comment"># Code for processing a single chromosome</span>
<span class="hljs-keyword">fi</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後に、シャットダウンコマンドを追加します。</font></font><br>
<br>
<pre><code class="bash hljs">sudo shutdown -h now</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
...そしてそれはすべてうまくいきました！</font><font style="vertical-align: inherit;">AWS CLIを使用してインスタンスを生成し、オプションを通じて、</font></font><code>user_data</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">それらに処理​​タスクのBashスクリプトを渡しました。</font><font style="vertical-align: inherit;">それらは実行されて自動的にオフにされたので、私は過度の処理能力にお金を払うことはありませんでした。</font></font><br>
<br>
<pre><code class="bash hljs">aws ec2 run-instances ...\<font></font>
--tag-specifications <span class="hljs-string">"ResourceType=instance,Tags=[{Key=Name,Value=&lt;&lt;job_name&gt;&gt;}]"</span> \<font></font>
--user-data file://&lt;&lt;job_script_loc&gt;&gt;</code></pre><br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">梱包中です！</font></font></h1><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：使用の単純さと柔軟性のために、APIは単純であるべきです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後に、適切な場所と形式でデータを取得しました。</font><font style="vertical-align: inherit;">データを使用するプロセスを可能な限り簡略化して、同僚がより簡単になるようにした。</font><font style="vertical-align: inherit;">クエリを作成するためのシンプルなAPIを作りたかったのです。</font><font style="vertical-align: inherit;">将来</font></font><code>.rds</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、Parquetファイル</font><font style="vertical-align: inherit;">に切り替えることにした場合、</font><font style="vertical-align: inherit;">これは私にとって問題であり、同僚にとっては問題ではありません。</font><font style="vertical-align: inherit;">このため、内部Rパッケージを作成することにしました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
関数の周りに収集されたデータにアクセスするためのいくつかの関数を含む非常に単純なパッケージをコンパイルして文書化しました</font></font><code>get_snp</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">また、同僚</font><font style="vertical-align: inherit;">が簡単に例やドキュメントを確認できるよう</font><font style="vertical-align: inherit;">に、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pkgdownを</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">同僚用</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">の</font></a><font style="vertical-align: inherit;">サイトにしました</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/a75/afb/f3a/a75afbf3a2c7c8ef5fa2a873f8ba50b9.png"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">インテリジェントキャッシング</font></font></h2><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：データが適切に準備されていれば、キャッシングは簡単です！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
メインワークフローの1つが同じ分析モデルをSNPパッケージに適用したため、ビニングを使用することにしました。 SNPを介してデータを送信する場合、グループ（bin）からのすべての情報は返されたオブジェクトに添付されます。つまり、古いクエリは（理論的には）新しいクエリの処理を高速化できます。</font></font><br>
<br>
<pre><code class="bash hljs"><span class="hljs-comment"># Part of get_snp()</span><font></font>
...<font></font>
  <span class="hljs-comment"># Test if our current snp data has the desired snp.</span>
  already_have_snp &lt;- desired_snp %<span class="hljs-keyword">in</span>% prev_snp_results<span class="hljs-variable">$snps_in_bin</span><font></font>
<font></font>
  <span class="hljs-keyword">if</span>(!already_have_snp){
    <span class="hljs-comment"># Grab info on the bin of the desired snp</span><font></font>
    snp_results &lt;- get_snp_bin(desired_snp)<font></font>
<font></font>
    <span class="hljs-comment"># Download the snp's bin data</span>
    snp_results<span class="hljs-variable">$bin_data</span> &lt;- aws.s3::s3readRDS(object = snp_results<span class="hljs-variable">$data_loc</span>)<font></font>
  } <span class="hljs-keyword">else</span> {
    <span class="hljs-comment"># The previous snp data contained the right bin so just use it</span><font></font>
    snp_results &lt;- prev_snp_results<font></font>
  }<font></font>
...</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
パッケージをビルドするとき、さまざまな方法を使用した場合の速度を比較するために、多くのベンチマークを実行しました。</font><font style="vertical-align: inherit;">予期しない結果になることもあるので、これを無視しないことをお勧めします。</font><font style="vertical-align: inherit;">たとえば、</font></font><code>dplyr::filter</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">インデックスベースのフィルタリングを使用して行をキャプチャするよりもはるかに高速</font><font style="vertical-align: inherit;">であること</font><font style="vertical-align: inherit;">が判明し、フィルタリングされたデータフレームから1つの列を取得することは、インデックス構文を使用するよりもはるかに高速に機能しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
オブジェクト</font></font><code>prev_snp_results</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">にはキーが含まれ</font><font style="vertical-align: inherit;">ていること</font><font style="vertical-align: inherit;">に</font><font style="vertical-align: inherit;">注意してください</font></font><code>snps_in_bin</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">これは、グループ（bin）内のすべての一意のSNPの配列であり、これにより、前の要求からのデータがすでにあるかどうかをすばやく確認できます。</font><font style="vertical-align: inherit;">また、次のコードを使用すると、グループ（bin）内のすべてのSNPを簡単にループできます。</font></font><br>
<br>
<pre><code class="bash hljs"><span class="hljs-comment"># Get bin-mates</span>
snps_in_bin &lt;- my_snp_results<span class="hljs-variable">$snps_in_bin</span><font></font>
<font></font>
<span class="hljs-keyword">for</span>(current_snp <span class="hljs-keyword">in</span> snps_in_bin){<font></font>
  my_snp_results &lt;- get_snp(current_snp, my_snp_results)<font></font>
  <span class="hljs-comment"># Do something with results </span>
}</code></pre><br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結果</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで、以前はアクセスできなかったモデルやシナリオを実行できます（真剣に始めました）。一番良いのは、私の研究室の同僚が困難について考える必要がないことです。彼らはただ働く機能を持っています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、パッケージは細部からそれらを保存しますが、私がデータ形式を十分にシンプルにして、私が明日突然消えた場合にそれを理解できるようにしようとしました... </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
速度は著しく増加しました。通常、機能的に重要なゲノムの断片をスキャンします。以前はこれを行うことができませんでしたが（高すぎることがわかりました）、今はグループ（bin）構造とキャッシュのおかげで、単一のSNPをクエリするのに平均で0.1秒未満かかり、データ使用量が非常に少ないため、S3のコストは安価です。</font></font><br>
<br>
<div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-3" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1134151057385369600"></twitter-widget>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div><br>
<h2></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事はガイドではありません。ソリューションは個別のものであり、ほぼ間違いなく最適ではありませんでした。むしろ、それは旅行物語です。そのような解決策は頭の中で完全に形成されていないように見えることを他の人に理解してもらいたい。これは試行錯誤の結果である。さらに、データ分析の専門家を探している場合は、これらのツールを効果的に使用するには経験が必要であり、経験にはお金が必要であることを覚えておいてください。お金が出せてよかったのですが、自分より上手にできる人は、お金が足りないので、そんな機会はありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ビッグデータツールは普遍的です。</font><font style="vertical-align: inherit;">時間があれば、スマートデータクレンジング、ストレージ、および抽出技術を使用して、より高速なソリューションをほぼ確実に作成できます。</font><font style="vertical-align: inherit;">最終的には、それはコストと利益の分析に帰着します。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私が学んだこと：</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一度に25 TBを解析する安価な方法はありません。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parquetファイルのサイズとその構成に注意してください。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sparkのパーティションはバランスをとる必要があります。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">決して250万のパーティションを作成しようとしないでください。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sparkのセットアップと同様に、並べ替えは依然として困難です。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">特別なデータには特別なソリューションが必要な場合があります。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sparkの統合は高速ですが、パーティショニングは依然として高価です。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">基本を教えられたら眠らないでください。確かに1980年代に誰かがすでに問題を解決しています。</font></font><br>
</li>
<li><code>gnu parallel</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -これは魔法のことです、誰もがそれを使うべきです。</font></font><br>
</li>
<li>Spark        ;<br>
</li>
<li> Spark        ;<br>
</li>
<li>   AWK  ;<br>
</li>
<li>   <code>stdin</code>  <code>stdout</code>  R-,       ;<br>
</li>
<li>    S3    ;<br>
</li>
<li>    —     ;<br>
</li>
<li>    ,    ;<br>
</li>
<li>API        ;<br>
</li>
<li>    ,   !<br>
</li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja456376/index.html">1つの春のブーツではない：代替案の概要</a></li>
<li><a href="../ja456380/index.html">ネットロジーのプログラミング学部のオープンデー</a></li>
<li><a href="../ja456382/index.html">フロントエンドでのコラボレーションと自動化。13校から学んだこと</a></li>
<li><a href="../ja456386/index.html">オーディオコンテンツの視覚化のためのオープンライブラリ</a></li>
<li><a href="../ja456388/index.html">PVS-Studioの診断開発チャート</a></li>
<li><a href="../ja456394/index.html">iOSでユビキタススプラッシュスクリーンを作成する</a></li>
<li><a href="../ja456398/index.html">Vue-cliプラグイン、複雑なデータとプロパティベースのテストでの作業-Panda-Meetupフロントエンドの発表</a></li>
<li><a href="../ja456400/index.html">なぜ競争は詰め込みよりも優れている：私たちの学習ゲーミフィケーションの経験</a></li>
<li><a href="../ja456402/index.html">知恵の歯：プルプル</a></li>
<li><a href="../ja456404/index.html">ルーパー-スケッチプラグイン</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
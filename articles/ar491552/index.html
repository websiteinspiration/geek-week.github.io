<!doctype html>
<html class="no-js" lang="ar">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>âš–ï¸ ğŸ–ï¸ ğŸˆ Python Anomaly Detection Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Autoencoders ÙÙŠ Python ğŸŒ‰ ğŸ™ğŸ» ğŸ‘©ğŸ¾â€ğŸ¤â€ğŸ‘¨ğŸ¿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ÙŠØ¹Ø¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø°ÙˆØ° Ù…Ù‡Ù…Ø© Ù…Ù‡Ù…Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ. Ù„Ø§ ØªÙˆØ¬Ø¯ Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø¯Ø¯Ø© Ù„Ø­Ù„Ù‡Ø§ ØŒ Ù„Ø£Ù† ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‡Ø§ Ø®ØµØ§Ø¦ØµÙ‡Ø§ Ø§Ù„Ø®Ø§ØµØ©. ÙˆÙ„ÙƒÙ† ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª ØŒ Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø³...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Python Anomaly Detection Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Autoencoders ÙÙŠ Python</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/491552/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ÙŠØ¹Ø¯ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø´Ø°ÙˆØ° Ù…Ù‡Ù…Ø© Ù…Ù‡Ù…Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ. </font><font style="vertical-align: inherit;">Ù„Ø§ ØªÙˆØ¬Ø¯ Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ø¯Ø¯Ø© Ù„Ø­Ù„Ù‡Ø§ ØŒ Ù„Ø£Ù† ÙƒÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‡Ø§ Ø®ØµØ§Ø¦ØµÙ‡Ø§ Ø§Ù„Ø®Ø§ØµØ©. </font><font style="vertical-align: inherit;">ÙˆÙ„ÙƒÙ† ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª ØŒ Ù‡Ù†Ø§Ùƒ Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„ØªÙŠ ØªØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­. </font><font style="vertical-align: inherit;">Ø£Ø±ÙŠØ¯ Ø£Ù† Ø£ØªØ­Ø¯Ø« Ø¹Ù† Ø£Ø­Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ - ØªØ±Ù…ÙŠØ² Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª.</font></font></p><a name="habracut"></a><br>
<h2 id="kakoy-dataset-vybrat"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ø£ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ®ØªØ§Ø±ØŸ</font></font></h2><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± Ø¥Ù„Ø­Ø§Ø­Ù‹Ø§ ÙÙŠ Ø­ÙŠØ§Ø© Ø£ÙŠ Ø¹Ø§Ù„Ù… Ø¨ÙŠØ§Ù†Ø§Øª. </font><font style="vertical-align: inherit;">Ù„ØªØ¨Ø³ÙŠØ· Ø§Ù„Ù‚ØµØ© ØŒ Ø³Ø£Ø³ØªØ®Ø¯Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³ÙŠØ·Ø© ÙÙŠ Ø§Ù„Ù‡ÙŠÙƒÙ„ ØŒ ÙˆØ§Ù„ØªÙŠ Ø³Ù†Ù†Ø´Ø¦Ù‡Ø§ Ù‡Ù†Ø§.</font></font></p><br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> matplotlib.colors <span class="hljs-keyword">import</span> Normalize</code></pre><br>
<pre><code class="python hljs"><span class="hljs-comment">#        </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_normal_distribution</span>(<span class="hljs-params">mu, sigma, size, range=(<span class="hljs-params"><span class="hljs-number">0</span>, <span class="hljs-number">1</span></span>), max_val=<span class="hljs-number">1</span></span>):</span><font></font>
  bins = np.linspace(*range, size)<font></font>
  result = <span class="hljs-number">1</span> / (sigma * np.sqrt(<span class="hljs-number">2</span>*np.pi)) * np.exp(-(bins - mu)**<span class="hljs-number">2</span> / (<span class="hljs-number">2</span>*sigma**<span class="hljs-number">2</span>))<font></font>
<font></font>
  cur_max_val = result.max()<font></font>
  k = max_val / cur_max_val<font></font>
<font></font>
  result *= k<font></font>
<font></font>
  <span class="hljs-keyword">return</span> result</code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ø®Ø° Ø¨Ø¹ÙŠÙ† Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ù…Ø«Ø§Ù„ Ø¯Ø§Ù„Ø©. </font><font style="vertical-align: inherit;">Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØ²ÙŠØ¹ Ø¹Ø§Ø¯ÙŠ Ù…Ø¹ Î¼ = 0.3 Ùˆ Ïƒ = 0.05:</font></font></p><br>
<pre><code class="python hljs">dist = gen_normal_distribution(<span class="hljs-number">0.3</span>, <span class="hljs-number">0.05</span>, <span class="hljs-number">256</span>, max_val=<span class="hljs-number">1</span>)<font></font>
print(dist.max())<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">1.0</span>
plt.plot(np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">256</span>), dist)</code></pre><br>
<p><img src="https://habrastorage.org/webt/g_/yf/dk/g_yfdkkwd3z97n9kpek3k-6mjwk.png"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ø£Ø¹Ù„Ù† Ù…Ø¹Ù„Ù…Ø§Øª Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¯ÙŠÙ†Ø§:</font></font></p><br>
<pre><code class="python hljs">in_distribution_size = <span class="hljs-number">2000</span>
out_distribution_size = <span class="hljs-number">200</span>
val_size = <span class="hljs-number">100</span>
sample_size = <span class="hljs-number">256</span><font></font>
<font></font>
random_generator = np.random.RandomState(seed=<span class="hljs-number">42</span>) <span class="hljs-comment">#    seed</span></code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ÙˆÙˆØ¸Ø§Ø¦Ù ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ©. </font><font style="vertical-align: inherit;">ØªØ¹ØªØ¨Ø± Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ø¹Ø§Ø¯ÙŠ ÙˆØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ - Ø¨Ø§Ø«Ù†ÙŠÙ†:</font></font></p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_in_samples</span>(<span class="hljs-params">size, sample_size</span>):</span>
  <span class="hljs-keyword">global</span> random_generator<font></font>
<font></font>
  in_samples = np.zeros((size, sample_size))<font></font>
<font></font>
  in_mus = random_generator.uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.9</span>, size)<font></font>
  in_sigmas = random_generator.uniform(<span class="hljs-number">0.05</span>, <span class="hljs-number">0.5</span>, size)<font></font>
<font></font>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(size):<font></font>
    in_samples[i] = gen_normal_distribution(in_mus[i], in_sigmas[i], sample_size, max_val=<span class="hljs-number">1</span>)<font></font>
<font></font>
  <span class="hljs-keyword">return</span> in_samples<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_out_samples</span>(<span class="hljs-params">size, sample_size</span>):</span>
  <span class="hljs-keyword">global</span> random_generator<font></font>
<font></font>
  <span class="hljs-comment">#     </span><font></font>
  out_samples = generate_in_samples(size, sample_size)<font></font>
<font></font>
  <span class="hljs-comment">#        </span>
  out_additional_mus = random_generator.uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.9</span>, size)<font></font>
  out_additional_sigmas = random_generator.uniform(<span class="hljs-number">0.01</span>, <span class="hljs-number">0.05</span>, size)<font></font>
<font></font>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(size):<font></font>
    anomaly = gen_normal_distribution(out_additional_mus[i], out_additional_sigmas[i], sample_size, max_val=<span class="hljs-number">0.12</span>)<font></font>
    out_samples[i] += anomaly<font></font>
<font></font>
  <span class="hljs-keyword">return</span> out_samples</code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ¨Ø¯Ùˆ Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„Ø¹Ø§Ø¯ÙŠ:</font></font></p><br>
<pre><code class="python hljs">in_samples = generate_in_samples(in_distribution_size, sample_size)<font></font>
plt.plot(np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, sample_size), in_samples[<span class="hljs-number">42</span>])</code></pre><br>
<p><img src="https://habrastorage.org/webt/f2/zs/zo/f2zszowdiozndeblbr9y174adgi.png"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ÙˆØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ - Ù…Ø«Ù„ Ù‡Ø°Ø§:</font></font></p><br>
<pre><code class="python hljs">out_samples = generate_out_samples(out_distribution_size, sample_size)<font></font>
plt.plot(np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, sample_size), out_samples[<span class="hljs-number">42</span>])</code></pre><br>
<p><img src="https://habrastorage.org/webt/em/bd/7b/embd7b623honrwk-7ofxbvk6_yg.png"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ø¥Ù†Ø´Ø§Ø¡ ØµÙØ§Ø¦Ù Ù…Ø¹ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª:</font></font></p><br>
<pre><code class="python hljs">x = np.concatenate((in_samples, out_samples))
<span class="hljs-comment">#     0,  -- 1</span><font></font>
y = np.concatenate((np.zeros(in_distribution_size), np.ones(out_distribution_size)))<font></font>
<font></font>
<span class="hljs-comment">#   / </span>
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.2</span>, shuffle=<span class="hljs-literal">True</span>, random_state=<span class="hljs-number">42</span>)</code></pre><br>
<p>    .  ,    ,  2    1  ().             ,      (  ),      :</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#     100   100  </span><font></font>
x_val_out = generate_out_samples(val_size, sample_size)<font></font>
x_val_in = generate_in_samples(val_size, sample_size)<font></font>
<font></font>
x_val = np.concatenate((x_val_out, x_val_in))<font></font>
y_val = np.concatenate((np.ones(val_size), np.zeros(val_size)))</code></pre><br>
<h2 id="modeli"></h2><br>
<p> ,     ,       Sklearn:  SVM   .     ,        ,     .</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#     </span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score</code></pre><br>
<h3 id="one-class-svm">One class SVM</h3><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> OneClassSVM</code></pre><br>
<p>OneClassSVM    <code>nu</code> â€”     .</p><br>
<pre><code class="python hljs">out_dist_part = out_distribution_size / (out_distribution_size + in_distribution_size)<font></font>
svm = OneClassSVM(nu=out_dist_part)<font></font>
svm.fit(x_train, y_train)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>OneClassSVM(cache_size=<span class="hljs-number">200</span>, coef0=<span class="hljs-number">0.0</span>, degree=<span class="hljs-number">3</span>, gamma=<span class="hljs-string">'scale'</span>, kernel=<span class="hljs-string">'rbf'</span>,<font></font>
            max_iter=<span class="hljs-number">-1</span>, nu=<span class="hljs-number">0.09090909090909091</span>, shrinking=<span class="hljs-literal">True</span>, tol=<span class="hljs-number">0.001</span>,<font></font>
            verbose=<span class="hljs-literal">False</span>)</code></pre><br>
<p>    :</p><br>
<pre><code class="python hljs">svm_prediction = svm.predict(x_val)<font></font>
svm_prediction[svm_prediction == <span class="hljs-number">1</span>] = <span class="hljs-number">0</span>
svm_prediction[svm_prediction == <span class="hljs-number">-1</span>] = <span class="hljs-number">1</span></code></pre><br>
<p> sklearn     â€” <code>classification_report</code>,       Anomaly detection ,  precision  recall,    :</p><br>
<pre><code class="python hljs">print(classification_report(y_val, svm_prediction))<font></font>
<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>          precision    recall  f1-score   support<font></font>
<font></font>
         <span class="hljs-number">0.0</span>       <span class="hljs-number">0.57</span>      <span class="hljs-number">0.93</span>      <span class="hljs-number">0.70</span>       <span class="hljs-number">100</span>
         <span class="hljs-number">1.0</span>       <span class="hljs-number">0.81</span>      <span class="hljs-number">0.29</span>      <span class="hljs-number">0.43</span>       <span class="hljs-number">100</span><font></font>
<font></font>
    accuracy                           <span class="hljs-number">0.61</span>       <span class="hljs-number">200</span>
   macro avg       <span class="hljs-number">0.69</span>      <span class="hljs-number">0.61</span>      <span class="hljs-number">0.57</span>       <span class="hljs-number">200</span>
weighted avg       <span class="hljs-number">0.69</span>      <span class="hljs-number">0.61</span>      <span class="hljs-number">0.57</span>       <span class="hljs-number">200</span>
</code></pre><br>
<p>, .   f1-score   ,      .</p><br>
<h3 id="isolation-forest">Isolation forest</h3><br>
<p>,  , -       ?</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> IsolationForest</code></pre><br>
<p>     ,       .  :</p><br>
<pre><code class="python hljs">out_dist_part = out_distribution_size / (out_distribution_size + in_distribution_size)<font></font>
<font></font>
iso_forest = IsolationForest(n_estimators=<span class="hljs-number">100</span>, contamination=out_dist_part, max_features=<span class="hljs-number">100</span>, n_jobs=<span class="hljs-number">-1</span>)<font></font>
iso_forest.fit(x_train)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>IsolationForest(behaviour=<span class="hljs-string">'deprecated'</span>, bootstrap=<span class="hljs-literal">False</span>,<font></font>
                contamination=<span class="hljs-number">0.09090909090909091</span>, max_features=<span class="hljs-number">100</span>,<font></font>
                max_samples=<span class="hljs-string">'auto'</span>, n_estimators=<span class="hljs-number">100</span>, n_jobs=<span class="hljs-number">-1</span>,<font></font>
                random_state=<span class="hljs-literal">None</span>, verbose=<span class="hljs-number">0</span>, warm_start=<span class="hljs-literal">False</span>)</code></pre><br>
<p>Classification report? â€” Classification report!</p><br>
<pre><code class="python hljs">iso_forest_prediction = iso_forest.predict(x_val)<font></font>
iso_forest_prediction[iso_forest_prediction == <span class="hljs-number">1</span>] = <span class="hljs-number">0</span>
iso_forest_prediction[iso_forest_prediction == <span class="hljs-number">-1</span>] = <span class="hljs-number">1</span><font></font>
<font></font>
print(classification_report(y_val, iso_forest_prediction))<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>           precision    recall  f1-score   support<font></font>
<font></font>
         <span class="hljs-number">0.0</span>       <span class="hljs-number">0.50</span>      <span class="hljs-number">0.91</span>      <span class="hljs-number">0.65</span>       <span class="hljs-number">100</span>
         <span class="hljs-number">1.0</span>       <span class="hljs-number">0.53</span>      <span class="hljs-number">0.10</span>      <span class="hljs-number">0.17</span>       <span class="hljs-number">100</span><font></font>
<font></font>
    accuracy                           <span class="hljs-number">0.51</span>       <span class="hljs-number">200</span>
   macro avg       <span class="hljs-number">0.51</span>      <span class="hljs-number">0.51</span>      <span class="hljs-number">0.41</span>       <span class="hljs-number">200</span>
weighted avg       <span class="hljs-number">0.51</span>      <span class="hljs-number">0.51</span>      <span class="hljs-number">0.41</span>       <span class="hljs-number">200</span></code></pre><br>
<h3 id="randomforestclassifier">RandomForestClassifier</h3><br>
<p>,    -    "        ?"  , :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<font></font>
<font></font>
random_forest = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>, max_features=<span class="hljs-number">100</span>, n_jobs=<span class="hljs-number">-1</span>)<font></font>
random_forest.fit(x_train, y_train)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>RandomForestClassifier(bootstrap=<span class="hljs-literal">True</span>, ccp_alpha=<span class="hljs-number">0.0</span>, class_weight=<span class="hljs-literal">None</span>,<font></font>
                       criterion=<span class="hljs-string">'gini'</span>, max_depth=<span class="hljs-literal">None</span>, max_features=<span class="hljs-number">100</span>,<font></font>
                       max_leaf_nodes=<span class="hljs-literal">None</span>, max_samples=<span class="hljs-literal">None</span>,<font></font>
                       min_impurity_decrease=<span class="hljs-number">0.0</span>, min_impurity_split=<span class="hljs-literal">None</span>,<font></font>
                       min_samples_leaf=<span class="hljs-number">1</span>, min_samples_split=<span class="hljs-number">2</span>,<font></font>
                       min_weight_fraction_leaf=<span class="hljs-number">0.0</span>, n_estimators=<span class="hljs-number">100</span>,<font></font>
                       n_jobs=<span class="hljs-number">-1</span>, oob_score=<span class="hljs-literal">False</span>, random_state=<span class="hljs-literal">None</span>, verbose=<span class="hljs-number">0</span>,<font></font>
                       warm_start=<span class="hljs-literal">False</span>)</code></pre><br>
<pre><code class="python hljs">random_forest_prediction = random_forest.predict(x_val)<font></font>
print(classification_report(y_val, random_forest_prediction))<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>           precision    recall  f1-score   support<font></font>
<font></font>
         <span class="hljs-number">0.0</span>       <span class="hljs-number">0.57</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.72</span>       <span class="hljs-number">100</span>
         <span class="hljs-number">1.0</span>       <span class="hljs-number">0.96</span>      <span class="hljs-number">0.25</span>      <span class="hljs-number">0.40</span>       <span class="hljs-number">100</span><font></font>
<font></font>
    accuracy                           <span class="hljs-number">0.62</span>       <span class="hljs-number">200</span>
   macro avg       <span class="hljs-number">0.77</span>      <span class="hljs-number">0.62</span>      <span class="hljs-number">0.56</span>       <span class="hljs-number">200</span>
weighted avg       <span class="hljs-number">0.77</span>      <span class="hljs-number">0.62</span>      <span class="hljs-number">0.56</span>       <span class="hljs-number">200</span></code></pre><br>
<h3 id="autoencoder">Autoencoder</h3><br>
<p> ,       :   .   .</p><br>
<p>     ,     "" ,    .    2 : Encoder'  Decoder',      .</p><br>
<p><img src="https://habrastorage.org/webt/kv/bx/mt/kvbxmtkqeauexgdruqi52u6dhs8.png"><br>
<em>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" rel="nofollow"></a></em></p><br>
<p>   "" ,    ,         .</p><br>
<p>    ?     ,     ,     ,    . ,      9%   91%  .          ,    .  ,       ,       <strong></strong>  :         .</p><br>
<p>     <em></em>   .</p><br>
<p>   PyTorch,    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset, DataLoader
<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> Adam</code></pre><br>
<p>  :</p><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">32</span>
lr = <span class="hljs-number">1e-3</span></code></pre><br>
<p>  .        ,      ,    ""               . ,    (    , learning rate,  )  ,    ,   .</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#      x_train,    </span>
train_in_distribution = x_train[y_train == <span class="hljs-number">0</span>]<font></font>
train_in_distribution = torch.tensor(train_in_distribution.astype(np.float32))<font></font>
<font></font>
train_in_dataset = TensorDataset(train_in_distribution)<font></font>
train_in_loader = DataLoader(train_in_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<font></font>
<font></font>
<span class="hljs-comment">#       ,           </span><font></font>
test_dataset = TensorDataset(<font></font>
    torch.tensor(x_test.astype(np.float32)),<font></font>
    torch.tensor(y_test.astype(np.long))<font></font>
)<font></font>
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>)<font></font>
<font></font>
val_dataset = TensorDataset(torch.tensor(x_val.astype(np.float32)))<font></font>
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>)</code></pre><br>
<p>.      4 ,      (     2 :    Î¼,  â€”  Ïƒ,     ;   4       ,     ).</p><br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Autoencoder</span>(<span class="hljs-params">nn.Module</span>):</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, input_size</span>):</span><font></font>
    super(Autoencoder, self).__init__()<font></font>
    self.encoder = nn.Sequential(<font></font>
      nn.Linear(input_size, <span class="hljs-number">128</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
      nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
      nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">16</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
      nn.Linear(<span class="hljs-number">16</span>, <span class="hljs-number">4</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
    )<font></font>
    self.decoder = nn.Sequential(<font></font>
      nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">16</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
      nn.Linear(<span class="hljs-number">16</span>, <span class="hljs-number">64</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
      nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
      nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>),<font></font>
      nn.LeakyReLU(<span class="hljs-number">0.2</span>),<font></font>
    )<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><font></font>
    x = self.encoder(x)<font></font>
    x = self.decoder(x)<font></font>
    <span class="hljs-keyword">return</span> x</code></pre><br>
<pre><code class="python hljs">model = Autoencoder(sample_size).cuda()<font></font>
criterion = nn.MSELoss()<font></font>
per_sample_criterion = nn.MSELoss(reduction=<span class="hljs-string">"none"</span>) <span class="hljs-comment"># loss   ,   </span>
<span class="hljs-comment">#   reduction="none" pytorch  loss'   </span>
optimizer = Adam(model.parameters(), lr=lr, weight_decay=<span class="hljs-number">1e-5</span>)</code></pre><br>
<p> -  loss'     ,  ,  boxplot' :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_score_distribution</span>(<span class="hljs-params">model, data_loader, criterion, save_to, figsize=(<span class="hljs-params"><span class="hljs-number">8</span>, <span class="hljs-number">6</span></span>)</span>):</span>
  losses = [] <span class="hljs-comment">#    loss    </span>
  labels = [] <span class="hljs-comment">#  --  </span>
  <span class="hljs-keyword">for</span> (x_batch, y_batch) <span class="hljs-keyword">in</span> data_loader:<font></font>
    x_batch = x_batch.cuda()<font></font>
<font></font>
    output = model(x_batch)<font></font>
    loss = criterion(output, x_batch)<font></font>
<font></font>
    loss = torch.mean(loss, dim=<span class="hljs-number">1</span>) <span class="hljs-comment">#  loss    (        )</span><font></font>
    loss = loss.detach().cpu().numpy().flatten()<font></font>
    losses.append(loss)<font></font>
<font></font>
    labels.append(y_batch.detach().cpu().numpy().flatten())<font></font>
<font></font>
  losses = np.concatenate(losses)<font></font>
  labels = np.concatenate(labels)<font></font>
<font></font>
  losses_0 = losses[labels == <span class="hljs-number">0</span>] <span class="hljs-comment">#  </span>
  losses_1 = losses[labels == <span class="hljs-number">1</span>] <span class="hljs-comment">#  </span><font></font>
<font></font>
  fig, ax = plt.subplots(<span class="hljs-number">1</span>, figsize=figsize)<font></font>
<font></font>
  ax.boxplot([losses_0, losses_1])<font></font>
  ax.set_xticklabels([<span class="hljs-string">'normal'</span>, <span class="hljs-string">'anomaly'</span>])<font></font>
<font></font>
  plt.savefig(save_to)<font></font>
  plt.close(fig)</code></pre><br>
<p>      :</p><br>
<p><img src="https://habrastorage.org/webt/zd/bk/vd/zdbkvdiaq0ogs63d8w2wvrzkgey.jpeg"></p><br>
<p>:</p><br>
<pre><code class="python hljs">experiment_path = <span class="hljs-string">"ood_detection"</span> <span class="hljs-comment">#    </span><font></font>
!rm -rf $experiment_path<font></font>
os.makedirs(experiment_path, exist_ok=<span class="hljs-literal">True</span>)</code></pre><br>
<pre><code class="python hljs">epochs = <span class="hljs-number">100</span><font></font>
<font></font>
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(epochs):<font></font>
  running_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> (x_batch, ) <span class="hljs-keyword">in</span> train_in_loader:<font></font>
    x_batch = x_batch.cuda()<font></font>
<font></font>
    output = model(x_batch)<font></font>
    loss = criterion(output, x_batch)<font></font>
<font></font>
    optimizer.zero_grad()<font></font>
    loss.backward()<font></font>
    optimizer.step()<font></font>
<font></font>
    running_loss += loss.item()<font></font>
<font></font>
  print(<span class="hljs-string">"epoch [{}/{}], train loss:{:.4f}"</span>.format(epoch+<span class="hljs-number">1</span>, epochs, running_loss))<font></font>
<font></font>
  <span class="hljs-comment">#   </span>
  plot_path = os.path.join(experiment_path, <span class="hljs-string">"{}.jpg"</span>.format(epoch+<span class="hljs-number">1</span>))<font></font>
  save_score_distribution(model, test_loader, per_sample_criterion, plot_path)<font></font>
<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>
epoch [<span class="hljs-number">1</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">8.5728</span>
epoch [<span class="hljs-number">2</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">4.2405</span>
epoch [<span class="hljs-number">3</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">4.0852</span>
epoch [<span class="hljs-number">4</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">1.7578</span>
epoch [<span class="hljs-number">5</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">0.8543</span><font></font>
...<font></font>
epoch [<span class="hljs-number">96</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">0.0147</span>
epoch [<span class="hljs-number">97</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">0.0154</span>
epoch [<span class="hljs-number">98</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">0.0117</span>
epoch [<span class="hljs-number">99</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">0.0105</span>
epoch [<span class="hljs-number">100</span>/<span class="hljs-number">100</span>], train loss:<span class="hljs-number">0.0097</span></code></pre><br>
<p><img src="https://habrastorage.org/webt/b2/j_/p3/b2j_p34rxntvfl1zjcuq4kpomkw.jpeg"><br>
<em> 50</em></p><br>
<p><img src="https://habrastorage.org/webt/do/za/bo/dozabo7dq8ffd-5ahaoe4h29tka.jpeg"><br>
<em> 100</em></p><br>
<p>,          . ,      :</p><br>
<pre><code class="python hljs"><span class="hljs-comment"># ,    </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_prediction</span>(<span class="hljs-params">model, x</span>):</span>
  <span class="hljs-keyword">global</span> batch_size<font></font>
<font></font>
  dataset = TensorDataset(torch.tensor(x.astype(np.float32)))<font></font>
  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>)<font></font>
<font></font>
  predictions = []<font></font>
  <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> data_loader:<font></font>
    x_batch = batch[<span class="hljs-number">0</span>].cuda()<font></font>
    pred = model(x_batch) <span class="hljs-comment"># x -&gt; encoder -&gt; decoder -&gt; x_pred</span><font></font>
    predictions.append(pred.detach().cpu().numpy())<font></font>
<font></font>
  predictions = np.concatenate(predictions)<font></font>
  <span class="hljs-keyword">return</span> predictions<font></font>
<font></font>
<span class="hljs-comment">#      (  )</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compare_data</span>(<span class="hljs-params">xs, sample_num, data_range=(<span class="hljs-params"><span class="hljs-number">0</span>, <span class="hljs-number">1</span></span>), labels=None</span>):</span><font></font>
  fig, axes = plt.subplots(len(xs))<font></font>
  sample_size = len(xs[<span class="hljs-number">0</span>][sample_num])<font></font>
<font></font>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(xs)):<font></font>
    axes[i].plot(np.linspace(*data_range, sample_size), xs[i][sample_num])<font></font>
<font></font>
  <span class="hljs-keyword">if</span> labels:
    <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> enumerate(labels):<font></font>
      axes[i].set_ylabel(label)</code></pre><br>
<p>     :</p><br>
<pre><code class="python hljs">x_test_pred = get_prediction(model, x_test)<font></font>
compare_data([x_test[y_test == <span class="hljs-number">0</span>], x_test_pred[y_test == <span class="hljs-number">0</span>]], <span class="hljs-number">10</span>, labels=[<span class="hljs-string">"real"</span>, <span class="hljs-string">"encoded"</span>])</code></pre><br>
<p><img src="https://habrastorage.org/webt/__/pk/l2/__pkl2tmqin1hyvfz6oafuskooa.png"></p><br>
<p>  :</p><br>
<p><img src="https://habrastorage.org/webt/mo/jn/js/mojnjsp5pbw8up0gifbnerzgrbu.png"></p><br>
<p>     <code>X</code>?   .</p><br>
<h4 id="difference-score">Difference score</h4><br>
<p>  â€”     .    ,    ,  ,  .      .</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_difference_score</span>(<span class="hljs-params">model, x</span>):</span>
  <span class="hljs-keyword">global</span> batch_size<font></font>
<font></font>
  dataset = TensorDataset(torch.tensor(x.astype(np.float32)))<font></font>
  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>)<font></font>
<font></font>
  predictions = []<font></font>
  <span class="hljs-keyword">for</span> (x_batch, ) <span class="hljs-keyword">in</span> data_loader:<font></font>
    x_batch = x_batch.cuda()<font></font>
    preds = model(x_batch)<font></font>
    predictions.append(preds.detach().cpu().numpy())<font></font>
<font></font>
  predictions = np.concatenate(predictions)<font></font>
<font></font>
  <span class="hljs-comment">#     </span>
  <span class="hljs-keyword">return</span> (x - predictions)</code></pre><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<font></font>
<font></font>
test_score = get_difference_score(model, x_test)<font></font>
<font></font>
score_forest = RandomForestClassifier(max_features=<span class="hljs-number">100</span>)<font></font>
score_forest.fit(test_score, y_test)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>RandomForestClassifier(bootstrap=<span class="hljs-literal">True</span>, ccp_alpha=<span class="hljs-number">0.0</span>, class_weight=<span class="hljs-literal">None</span>,<font></font>
                       criterion=<span class="hljs-string">'gini'</span>, max_depth=<span class="hljs-literal">None</span>, max_features=<span class="hljs-number">100</span>,<font></font>
                       max_leaf_nodes=<span class="hljs-literal">None</span>, max_samples=<span class="hljs-literal">None</span>,<font></font>
                       min_impurity_decrease=<span class="hljs-number">0.0</span>, min_impurity_split=<span class="hljs-literal">None</span>,<font></font>
                       min_samples_leaf=<span class="hljs-number">1</span>, min_samples_split=<span class="hljs-number">2</span>,<font></font>
                       min_weight_fraction_leaf=<span class="hljs-number">0.0</span>, n_estimators=<span class="hljs-number">100</span>,<font></font>
                       n_jobs=<span class="hljs-literal">None</span>, oob_score=<span class="hljs-literal">False</span>, random_state=<span class="hljs-literal">None</span>,<font></font>
                       verbose=<span class="hljs-number">0</span>, warm_start=<span class="hljs-literal">False</span>)</code></pre><br>
<p>,     :      2  â€”   .  ,     2 :     ,  â€”   <code>difference_score</code>,   â€”   .        ,        ,   <em></em>     .</p><br>
<p>  ?        <strong></strong> .  <code>difference_score</code>     ,    ( )  ,      ,   .       ,  ,    <code>difference_score</code>    ,    (        ).        .</p><br>
<p>    :</p><br>
<pre><code class="python hljs">val_score = get_difference_score(model, x_val)<font></font>
prediction = score_forest.predict(val_score)<font></font>
print(classification_report(y_val, prediction))<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>           precision    recall  f1-score   support<font></font>
<font></font>
         <span class="hljs-number">0.0</span>       <span class="hljs-number">0.76</span>      <span class="hljs-number">1.00</span>      <span class="hljs-number">0.87</span>       <span class="hljs-number">100</span>
         <span class="hljs-number">1.0</span>       <span class="hljs-number">1.00</span>      <span class="hljs-number">0.69</span>      <span class="hljs-number">0.82</span>       <span class="hljs-number">100</span><font></font>
<font></font>
    accuracy                           <span class="hljs-number">0.84</span>       <span class="hljs-number">200</span>
   macro avg       <span class="hljs-number">0.88</span>      <span class="hljs-number">0.84</span>      <span class="hljs-number">0.84</span>       <span class="hljs-number">200</span>
weighted avg       <span class="hljs-number">0.88</span>      <span class="hljs-number">0.84</span>      <span class="hljs-number">0.84</span>       <span class="hljs-number">200</span></code></pre><br>
<p> .    :</p><br>
<pre><code class="python hljs">indices = np.arange(len(prediction))
<span class="hljs-comment">#       ,     </span>
wrong_indices = indices[(prediction == <span class="hljs-number">0</span>) &amp; (y_val == <span class="hljs-number">1</span>)]<font></font>
<font></font>
x_val_pred = get_prediction(model, x_val)<font></font>
compare_data([x_val, x_val_pred], wrong_indices[<span class="hljs-number">0</span>])</code></pre><br>
<p><img src="https://habrastorage.org/webt/ia/23/md/ia23mdeirk0yph9z4daawza1axw.png"></p><br>
<p>     ?  :</p><br>
<pre><code class="python hljs">plt.imshow(val_score[wrong_indices], norm=Normalize(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, clip=<span class="hljs-literal">True</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/cg/oy/eq/cgoyeqykuf6bpows4sd8tlky-gg.png"></p><br>
<p> :</p><br>
<pre><code class="python hljs">plt.imshow(val_score[(prediction == <span class="hljs-number">1</span>) &amp; (y_val == <span class="hljs-number">1</span>)], norm=Normalize(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, clip=<span class="hljs-literal">True</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/nk/hw/th/nkhwthlp5-_pvq_6xbcy2cqn20c.png"></p><br>
<p>     :</p><br>
<pre><code class="python hljs">plt.imshow(val_score[(prediction == <span class="hljs-number">0</span>) &amp; (y_val == <span class="hljs-number">0</span>)], norm=Normalize(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, clip=<span class="hljs-literal">True</span>))</code></pre><br>
<p><img src="https://habrastorage.org/webt/cu/xw/od/cuxwod1ophr8rs43agecaz_sawm.png"></p><br>
<p>,     :          .</p><br>
<h4 id="difference-histograms">Difference histograms</h4><br>
<p>         .            .    â€”   ,   "",        .</p><br>
<p>,     <code>difference score</code></p><br>
<pre><code class="python hljs">print(<span class="hljs-string">"test score: [{}; {}]"</span>.format(test_score.min(), test_score.max()))
<span class="hljs-meta">&gt;&gt;&gt; </span>test score: [<span class="hljs-number">-0.2260764424351479</span>; <span class="hljs-number">0.26339245919832344</span>]</code></pre><br>
<p>     ,       :</p><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score_to_histograms</span>(<span class="hljs-params">scores, bins=<span class="hljs-number">10</span>, data_range=(<span class="hljs-params"><span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span></span>)</span>):</span><font></font>
  result_histograms = np.zeros((len(scores), bins))<font></font>
<font></font>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(scores)):<font></font>
    hist, bins = np.histogram(scores[i], bins=bins, range=data_range)<font></font>
    result_histograms[i] = hist<font></font>
<font></font>
  <span class="hljs-keyword">return</span> result_histograms</code></pre><br>
<pre><code class="python hljs">test_histogram = score_to_histograms(test_score, bins=<span class="hljs-number">10</span>, data_range=(<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>))<font></font>
val_histogram = score_to_histograms(val_score, bins=<span class="hljs-number">10</span>, data_range=(<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>))</code></pre><br>
<pre><code class="python hljs">plt.title(<span class="hljs-string">"normal histogram"</span>)<font></font>
plt.bar(np.linspace(<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">10</span>), test_histogram[y_test == <span class="hljs-number">0</span>][<span class="hljs-number">0</span>])</code></pre><br>
<p><img src="https://habrastorage.org/webt/3v/vg/y0/3vvgy00sui4mr7xamlvdnfmxzos.png"></p><br>
<pre><code class="python hljs">plt.title(<span class="hljs-string">"anomaly histogram"</span>)<font></font>
plt.bar(np.linspace(<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">10</span>), test_histogram[y_test == <span class="hljs-number">1</span>][<span class="hljs-number">0</span>])</code></pre><br>
<p><img src="https://habrastorage.org/webt/b4/lh/r-/b4lhr-eiytahuwak954gzmstkbq.png"></p><br>
<p>,   "",    .</p><br>
<pre><code class="python hljs">histogram_forest = RandomForestClassifier(n_estimators=<span class="hljs-number">10</span>)<font></font>
histogram_forest.fit(test_histogram, y_test)<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>RandomForestClassifier(bootstrap=<span class="hljs-literal">True</span>, ccp_alpha=<span class="hljs-number">0.0</span>, class_weight=<span class="hljs-literal">None</span>,<font></font>
                       criterion=<span class="hljs-string">'gini'</span>, max_depth=<span class="hljs-literal">None</span>, max_features=<span class="hljs-string">'auto'</span>,<font></font>
                       max_leaf_nodes=<span class="hljs-literal">None</span>, max_samples=<span class="hljs-literal">None</span>,<font></font>
                       min_impurity_decrease=<span class="hljs-number">0.0</span>, min_impurity_split=<span class="hljs-literal">None</span>,<font></font>
                       min_samples_leaf=<span class="hljs-number">1</span>, min_samples_split=<span class="hljs-number">2</span>,<font></font>
                       min_weight_fraction_leaf=<span class="hljs-number">0.0</span>, n_estimators=<span class="hljs-number">10</span>,<font></font>
                       n_jobs=<span class="hljs-literal">None</span>, oob_score=<span class="hljs-literal">False</span>, random_state=<span class="hljs-literal">None</span>,<font></font>
                       verbose=<span class="hljs-number">0</span>, warm_start=<span class="hljs-literal">False</span>)</code></pre><br>
<pre><code class="python hljs">val_prediction = histogram_forest.predict(val_histogram)<font></font>
print(classification_report(y_val, val_prediction))<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span>           precision    recall  f1-score   support<font></font>
<font></font>
         <span class="hljs-number">0.0</span>       <span class="hljs-number">0.83</span>      <span class="hljs-number">0.99</span>      <span class="hljs-number">0.90</span>       <span class="hljs-number">100</span>
         <span class="hljs-number">1.0</span>       <span class="hljs-number">0.99</span>      <span class="hljs-number">0.80</span>      <span class="hljs-number">0.88</span>       <span class="hljs-number">100</span><font></font>
<font></font>
    accuracy                           <span class="hljs-number">0.90</span>       <span class="hljs-number">200</span>
   macro avg       <span class="hljs-number">0.91</span>      <span class="hljs-number">0.90</span>      <span class="hljs-number">0.89</span>       <span class="hljs-number">200</span>
weighted avg       <span class="hljs-number">0.91</span>      <span class="hljs-number">0.90</span>      <span class="hljs-number">0.89</span>       <span class="hljs-number">200</span></code></pre><br>
<h2 id="vyvody"></h2><br>
<p>  â€”    .  ,      ,     ,    , .        ()    .</p><br>
<p> â€”      .      ?    VAE,     (  4 )   .       .   CVAE,   -        . ,     ,  ,      ..</p><br>
<p>     GAN',     (),       .         (   ).</p><br>
<p>       ,     ,   .</p><br>
<div class="spoiler"><b class="spoiler_title">    </b><div class="spoiler_text"><h4 id="statistical-parametric">Statistical parametric</h4><br>
<ul>
<li>GMM â€” Gaussian mixture modelling + Akaike or Bayesian Information Criterion</li>
<li>HMM â€” Hidden Markov models</li>
<li>MRF â€” Markov random fields</li>
<li>CRF â€” conditional random fields</li>
</ul><br>
<h4 id="robust-statistic">Robust statistic</h4><br>
<ul>
<li>minimum volume estimation</li>
<li>PCA</li>
<li>estimation maximisation (EM) + deterministic annealing</li>
<li>K-means</li>
</ul><br>
<h4 id="non-parametric-statistics">Non-parametric statistics</h4><br>
<ul>
<li>histogram analysis with density estimation on KNN</li>
<li>local kernel models (Parzen windowing)</li>
<li>vector of feature matching with similarity distance (between train and test)</li>
<li>wavelets + MMRF</li>
<li>histogram-based measures features</li>
<li>texture features</li>
<li>shape features</li>
<li>features from VGG-16</li>
<li>HOG</li>
</ul><br>
<h4 id="neural-networks">Neural networks</h4><br>
<ul>
<li>self organisation maps (SOM) or Kohonen's</li>
<li>Radial Basis Functions (RBF) (Minhas, 2005)</li>
<li>LearningVector Quantisation (LVQ)</li>
<li>ProbabilisticNeural Networks (PNN)</li>
<li>Hopfieldnetworks</li>
<li>SupportVector Machines (SVM)</li>
<li>AdaptiveResonance Theory (ART)</li>
<li>Relevance vector machine (RVM)</li>
</ul></div></div><br>
<h4 id="nemnogo-obo-mne">  </h4><br>
<p>  , Data science'     .       Computer vision,    . (      â€”  !)       â€” FARADAY Lab.  â€”         ,   .</p><br>
<p> c:</p><br>
<p><img src="https://habrastorage.org/webt/ms/1u/a8/ms1ua8wsr4u5h1opv3ylaonfq2k.png"></p><br>
<h3 id="poleznye-ssylki"> </h3><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" rel="nofollow">  </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø·Ø¨ÙŠØ©</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø¹Ù† Ø§Ù„Ø¯Ù…Ù‰</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ø·Ø±Ù‚ Ø§Ù„ÙƒØ´Ù Ø§Ù„Ø´Ø§Ø°Ø©</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒØ´Ù Ø¹Ù† OOD</font></font></a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar491542/index.html">ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù„ÙˆÙ†: Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ®ÙÙŠÙ</a></li>
<li><a href="../ar491544/index.html">Ù…Ø§Ø°Ø§ ØªÙ‚Ø±Ø£ ÙÙŠ Ø¹Ø·Ù„Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© - ÙƒØªØ¨ Ø¹Ù† Ø§Ù„ÙÙŠØ±ÙˆØ³Ø§Øª ÙˆØ§Ù„Ù…ØªØ³Ù„Ù„ÙŠÙ† ÙˆØªØ§Ø±ÙŠØ® ÙƒØ§Ø±ØªÙ„ "Ø±Ù‚Ù…ÙŠ"</a></li>
<li><a href="../ar491546/index.html">Java 14 Ù‚Ø§Ø¯Ù…</a></li>
<li><a href="../ar491548/index.html">Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ± ReactJS - NodeJS</a></li>
<li><a href="../ar491550/index.html">Ù†Ù†ØªØ¬ ÙƒÙ„Ù…Ø§Øª Ù…Ø¹ Ø³Ù„Ø§Ø³Ù„ Ù…Ø§Ø±ÙƒÙˆÙ</a></li>
<li><a href="../ar491554/index.html">Ù†ØªØ¬Ø§ÙˆØ² Ø­Ø¸Ø± Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ API ÙÙƒÙˆÙ†ØªØ§ÙƒØªÙŠ Ù…Ù† Ø®Ù„Ø§Ù„ Python</a></li>
<li><a href="../ar491556/index.html">Java Microservices: Ø¯Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ</a></li>
<li><a href="../ar491558/index.html">Ø§Ø¹Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø¨ÙŠØ¶ Ø¹ÙŠØ¯ Ø§Ù„ÙØµØ­: Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ØºØ§Ù…Ø¶Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ù„ØºØ³Ù„ ÙŠØ¯ÙŠÙƒ ÙˆØ§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø£Ø¯Ø§Ø¡ ÙˆØ§Ø¬Ø¨Ùƒ</a></li>
<li><a href="../ar491560/index.html">ÙƒÙŠÙ ØªØ¬Ø¹Ù„ Ø§Ù„Ù…Ø­Ø·Ø© Ù…Ø³Ø§Ø¹Ø¯Ùƒ ÙˆÙ„ÙŠØ³ Ø¹Ø¯ÙˆØ§ØŸ</a></li>
<li><a href="../ar491562/index.html">FOSS News No. 6 - Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± Ù…Ù† 2 Ø¥Ù„Ù‰ 8 Ù…Ø§Ø±Ø³ 2020</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï¥üèø ü§¥ üßõüèª Configurando a fun√ß√£o de perda para uma rede neural baseada em dados s√≠smicos üíÜüèø ‚úçüèª ü§∂üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em um artigo anterior, descrevemos um experimento para determinar a quantidade m√≠nima de se√ß√µes rotuladas manualmente para treinar uma rede neural usa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Configurando a fun√ß√£o de perda para uma rede neural baseada em dados s√≠smicos</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/488852/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artigo anterior,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> descrevemos um experimento para determinar a quantidade m√≠nima de se√ß√µes rotuladas manualmente para treinar uma rede neural usando dados s√≠smicos. </font><font style="vertical-align: inherit;">Hoje, continuamos esse t√≥pico escolhendo a fun√ß√£o de perda mais apropriada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Duas classes b√°sicas de fun√ß√µes s√£o consideradas - entropia cruzada bin√°ria e interse√ß√£o sobre uni√£o - em 6 variantes com sele√ß√£o de par√¢metros, bem como combina√ß√µes de fun√ß√µes de diferentes classes. </font><font style="vertical-align: inherit;">Al√©m disso, a regulariza√ß√£o da fun√ß√£o de perda √© considerada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Spoiler: conseguiu melhorar significativamente a qualidade da previs√£o da rede.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/nq/rn/qt/nqrnqtl1xaabhj0vtklokcrbtpc.jpeg"><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Objetivos de pesquisa de neg√≥cios</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
N√£o repetiremos a descri√ß√£o das especificidades da pesquisa s√≠smica, os dados obtidos e as tarefas de sua interpreta√ß√£o. Tudo isso √© descrito em </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nosso artigo anterior</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A ideia deste estudo foi motivada pelos resultados da </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">competi√ß√£o pela busca de dep√≥sitos de sal em fatias 2D</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Segundo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">os participantes da competi√ß√£o</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , para resolver esse problema, um zool√≥gico inteiro de v√°rias fun√ß√µes de perda foi usado, al√©m disso, com sucessos diferentes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Portanto, nos perguntamos: √© realmente poss√≠vel que esses problemas nesses dados selecionem a fun√ß√£o de perda que pode proporcionar um ganho significativo de qualidade? Ou essa caracter√≠stica √© apenas para as condi√ß√µes da competi√ß√£o, quando h√° uma luta pela quarta ou quinta casa decimal por uma m√©trica predefinida pelos organizadores?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Normalmente, em tarefas resolvidas com a ajuda de redes neurais, o ajuste do processo de aprendizagem √© baseado principalmente na experi√™ncia do pesquisador e em algumas heur√≠sticas. Por exemplo, para os problemas de segmenta√ß√£o de imagens, as fun√ß√µes de perda s√£o usadas com mais frequ√™ncia, com base na avalia√ß√£o da coincid√™ncia das formas das zonas reconhecidas, a chamada Intersec√ß√£o sobre Uni√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Intuitivamente, com base no entendimento do comportamento e dos resultados da pesquisa, esses tipos de fun√ß√µes fornecer√£o um resultado melhor do que aqueles que n√£o s√£o agu√ßados por imagens, como as de entropia cruzada. No entanto, experimentos em busca da melhor op√ß√£o para esse tipo de tarefa como um todo e cada tarefa individualmente continuam.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os dados s√≠smicos preparados para interpreta√ß√£o t√™m v√°rios recursos que podem ter um impacto significativo no comportamento da fun√ß√£o de perda. </font><font style="vertical-align: inherit;">Por exemplo, os horizontes que separam as camadas geol√≥gicas s√£o suaves, mudando mais acentuadamente apenas nos locais de falhas. </font><font style="vertical-align: inherit;">Al√©m disso, as zonas distintas t√™m uma √°rea suficientemente grande em rela√ß√£o √† imagem, isto √©, </font><font style="vertical-align: inherit;">pequenas manchas nos resultados da interpreta√ß√£o s√£o frequentemente consideradas um erro de reconhecimento. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como parte desse experimento, tentamos encontrar respostas para as seguintes perguntas locais:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A fun√ß√£o de perda da classe Intersec√ß√£o sobre Uni√£o √© realmente o melhor resultado para o problema considerado abaixo? </font><font style="vertical-align: inherit;">Parece que a resposta √© √≥bvia, mas qual? </font><font style="vertical-align: inherit;">E qual √© o melhor do ponto de vista comercial?</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â poss√≠vel melhorar os resultados combinando fun√ß√µes de diferentes classes? </font><font style="vertical-align: inherit;">Por exemplo, interse√ß√£o sobre uni√£o e entropia cruzada com pesos diferentes.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â poss√≠vel melhorar os resultados adicionando √† fun√ß√£o de perda v√°rias adi√ß√µes projetadas especificamente para dados s√≠smicos?</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E para uma pergunta mais global: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
vale a pena se preocupar com a sele√ß√£o da fun√ß√£o de perda para as tarefas de interpreta√ß√£o de dados s√≠smicos, ou o ganho de qualidade n√£o √© compar√°vel com a perda de tempo para a realiza√ß√£o de tais estudos? </font><font style="vertical-align: inherit;">Talvez valha a pena escolher intuitivamente qualquer fun√ß√£o e gastar energia na sele√ß√£o de par√¢metros de treinamento mais significativos?</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descri√ß√£o geral do experimento e os dados utilizados</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para o experimento, realizamos a mesma tarefa de isolar camadas geol√≥gicas em fatias 2D de um cubo s√≠smico (veja a Figura 1). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w6/j3/gn/w6j3gnflms5vqyxc3mbjdnzsaam.png"> <br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 1. Um exemplo de uma fatia 2D (esquerda) e o resultado da marca√ß√£o das camadas geol√≥gicas correspondentes (direita) ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">origem</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
E o mesmo conjunto de dados completamente rotulados do setor holand√™s do Mar do Norte. Os dados s√≠smicos de origem est√£o dispon√≠veis no site do </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Open Seismic Repository: Project Netherlands Offshore F3 Block</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Uma breve descri√ß√£o pode ser encontrada em </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Silva et al. "Conjunto de dados da Holanda: um novo conjunto de dados p√∫blico para aprendizado de m√°quina na interpreta√ß√£o s√≠smica</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">"</font></a></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Como estamos falando de fatias 2D, no nosso caso, n√£o usamos o cubo 3D original, mas a ‚Äúfatia‚Äù j√° feita, dispon√≠vel aqui:</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conjunto de Dados de Interpreta√ß√£o F3 da Holanda</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante o experimento, resolvemos os seguintes problemas:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analisamos os dados de origem e selecionamos as fatias, com qualidade mais pr√≥xima da marca√ß√£o manual (semelhante √† experi√™ncia anterior).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Registramos a arquitetura da rede neural, a metodologia e os par√¢metros do treinamento e o princ√≠pio de selecionar fatias para treinamento e valida√ß√£o (semelhante ao experimento anterior).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Escolhemos as fun√ß√µes de perda estudadas.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Selecionamos os melhores par√¢metros para as fun√ß√µes de perda parametrizadas.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Treinamos redes neurais com fun√ß√µes diferentes no mesmo volume de dados e escolhemos a melhor fun√ß√£o.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Treinamos redes neurais com diferentes combina√ß√µes da fun√ß√£o selecionada com fun√ß√µes de outra classe na mesma quantidade de dados.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Treinamos redes neurais com regulariza√ß√£o da fun√ß√£o selecionada na mesma quantidade de dados.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para compara√ß√£o, usamos os resultados de um experimento anterior, no qual a fun√ß√£o de perda foi escolhida exclusivamente intuitivamente e era uma combina√ß√£o de fun√ß√µes de diferentes classes com coeficientes tamb√©m escolhidos ‚Äúa olho‚Äù. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os resultados desse experimento na forma de m√©tricas estimadas e previstas pelas redes de m√°scaras de fatia s√£o apresentados abaixo.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 1. Sele√ß√£o de dados</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como dados iniciais, usamos linhas e linhas cruzadas prontas de um cubo s√≠smico do setor holand√™s do Mar do Norte. </font><font style="vertical-align: inherit;">Como no experimento anterior, simulando o trabalho do int√©rprete, para treinar a rede, escolhemos apenas m√°scaras limpas, tendo analisado todas as fatias. </font><font style="vertical-align: inherit;">Como resultado, foram selecionadas 700 linhas cruzadas e 400 linhas entre ~ 1600 imagens de origem.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 2. Corrigindo os par√¢metros do experimento</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta e as se√ß√µes a seguir s√£o de interesse, em primeiro lugar, para especialistas em Data Science, portanto, terminologia apropriada ser√° usada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para o treinamento, escolhemos 5% do n√∫mero total de fatias, al√©m disso, linhas e linhas cruzadas em partes iguais, ou seja, 40 + 40. As fatias foram selecionadas uniformemente em todo o cubo. Para valida√ß√£o, foi utilizada 1 fatia entre as imagens adjacentes da amostra de treinamento. Assim, a amostra de valida√ß√£o consistiu em 39 linhas e 39 linhas cruzadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
321 inline e 621 crossline ca√≠ram na amostra atrasada, na qual os resultados foram comparados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Semelhante ao experimento anterior, o pr√©-processamento de imagem n√£o foi realizado e a mesma arquitetura UNet com os mesmos par√¢metros de treinamento foi usada.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As m√°scaras de fatia de destino foram representadas como cubos bin√°rios de dimens√£o HxWx10, onde a √∫ltima dimens√£o corresponde ao n√∫mero de classes e cada valor do cubo √© 0 ou 1, dependendo se esse pixel na imagem pertence ou n√£o √† classe da camada correspondente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada previs√£o de rede era um cubo semelhante, cada valor relacionado √† probabilidade de um determinado pixel de imagem pertencer √† classe da camada correspondente. Na maioria dos casos, esse valor foi convertido na pr√≥pria probabilidade usando um sigm√≥ide. No entanto, isso n√£o deve ser feito para todas as fun√ß√µes de perda; portanto, a ativa√ß√£o n√£o foi usada para a √∫ltima camada da rede. Em vez disso, as convers√µes correspondentes foram realizadas nas pr√≥prias fun√ß√µes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para reduzir a influ√™ncia da aleatoriedade da escolha dos pesos iniciais nos resultados, a rede foi treinada por 1 era com entropia cruzada bin√°ria em fun√ß√£o de perdas. </font><font style="vertical-align: inherit;">Todos os outros treinamentos come√ßaram com esses pesos recebidos.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 3. A escolha das fun√ß√µes de perda</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para o experimento, duas classes b√°sicas de fun√ß√µes foram selecionadas em 6 variantes: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia cruzada bin√°ria</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entropia cruzada bin√°ria;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entropia cruzada bin√°ria ponderada;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entropia cruzada bin√°ria equilibrada.</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interse√ß√£o sobre Uni√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Jaccard;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Tversky;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Lov√°sz.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma breve descri√ß√£o das fun√ß√µes listadas com c√≥digo para Keras √© fornecida no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artigo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Aqui, apresentamos os links mais importantes (sempre que poss√≠vel) para uma descri√ß√£o detalhada de cada fun√ß√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para nosso experimento, a consist√™ncia da fun√ß√£o usada durante o treinamento √© importante com a m√©trica pela qual avaliamos o resultado da previs√£o de rede na amostra atrasada. </font><font style="vertical-align: inherit;">Portanto, usamos nosso c√≥digo implementado no TensorFlow e Numpy, escrito diretamente usando as f√≥rmulas abaixo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A seguinte nota√ß√£o √© usada nas f√≥rmulas:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pt - para a m√°scara de alvo bin√°rio (Ground Truth);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pp - para m√°scara de previs√£o de rede.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para todas as fun√ß√µes, a menos que especificado de outra forma, sup√µe-se que a m√°scara de previs√£o da rede contenha probabilidades para cada pixel da imagem, ou seja, </font><font style="vertical-align: inherit;">valores no intervalo (0, 1).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia cruzada bin√°ria</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Descri√ß√£o: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fc/-1/ep/fc-1epf3rdg8gfdq0ycdtywgxee.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essa fun√ß√£o procura aproximar a distribui√ß√£o de previs√£o da rede do alvo, penalizando n√£o apenas previs√µes erradas, mas tamb√©m incertas.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia cruzada bin√°ria ponderada</font></font></h3><br>
<img src="https://habrastorage.org/webt/gm/ud/n3/gmudn3reniryckosw6v_myxzyh0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta fun√ß√£o coincide com a entropia cruzada bin√°ria com um valor beta de 1. √â recomendado para desequil√≠brios de classe fortes. </font><font style="vertical-align: inherit;">Para beta&gt; 1, o n√∫mero de previs√µes de falso negativo (falso negativo) diminui e a integridade (Rechamada) aumenta; para beta &lt;1, o n√∫mero de previs√µes de falso positivo (falso positivo) diminui e a precis√£o aumenta (Precis√£o).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia cruzada bin√°ria equilibrada</font></font></h3><br>
<img src="https://habrastorage.org/webt/pd/pn/sd/pdpnsd3ah6jwiofykm1ftkggfec.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essa fun√ß√£o √© semelhante √† entropia cruzada ponderada, mas corrige a contribui√ß√£o n√£o apenas dos valores √∫nicos, mas tamb√©m de zero da m√°scara de destino. </font><font style="vertical-align: inherit;">Coinc√≠dios (at√© uma constante) com entropia cruzada bin√°ria no valor do coeficiente beta = 0,5.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Jaccard </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O coeficiente de Jacquard (tamb√©m conhecido como Intersec√ß√£o sobre Uni√£o, IoU) determina a medida da ‚Äúsimilaridade‚Äù das duas √°reas. </font><font style="vertical-align: inherit;">O √≠ndice de dados faz a mesma coisa: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ej/ak/to/ejakto7j-ghcfffxulq6o6i7kz0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
n√£o faz sentido considerar essas duas fun√ß√µes. </font><font style="vertical-align: inherit;">N√≥s escolhemos Jacquard. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No caso em que ambas as √°reas s√£o especificadas usando m√°scaras bin√°rias, a f√≥rmula acima pode ser facilmente reescrita em termos dos valores das m√°scaras: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/n-/6w/zh/n-6wzhefudinbxqnol6vaibdbaw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para previs√µes n√£o bin√°rias, a otimiza√ß√£o do coeficiente Jacquard √© uma tarefa n√£o trivial. </font><font style="vertical-align: inherit;">Usaremos a mesma f√≥rmula para probabilidades na m√°scara de previs√£o como uma certa imita√ß√£o do coeficiente inicial e, consequentemente, a seguinte fun√ß√£o de perda:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/eq/yi/8f/eqyi8fefrizsnxxu909mlx9wmgm.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Tversky</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Descri√ß√£o: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://arxiv.org/pdf/1706.05721.pdf</font></font></a><br>
<br>
<img src="https://habrastorage.org/webt/hr/3k/cc/hr3kccuxmb3qfogjzaotqbz1ewa.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Esta fun√ß√£o √© uma vers√£o parametrizada da otimiza√ß√£o do coeficiente Jacquard que coincide com ele em alfa = beta = 1 e com o √≠ndice de dados em alfa = beta = 0,5. </font><font style="vertical-align: inherit;">Para outros valores diferentes de zero e n√£o coincidentes, podemos mudar a √™nfase em dire√ß√£o √† precis√£o ou completude da mesma maneira que nas fun√ß√µes de entropia cruzada ponderada e equilibrada. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O problema da mudan√ßa de √™nfase pode ser reescrito usando um √∫nico coeficiente no intervalo (0, 1). </font><font style="vertical-align: inherit;">A fun√ß√£o de perda resultante ter√° a seguinte apar√™ncia:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fd/re/og/fdreog2gzjmosed7ggczhjwj9oo.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Lov√°sz</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√â dif√≠cil fornecer uma f√≥rmula para essa fun√ß√£o, pois √© uma op√ß√£o para otimizar o coeficiente de Jacquard por um algoritmo baseado em erros classificados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ pode ver a descri√ß√£o da fun√ß√£o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqui</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , uma das op√ß√µes de c√≥digo est√° </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqui</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Explica√ß√£o importante! </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para simplificar a compara√ß√£o de valores e gr√°ficos a seguir, sob o termo "coeficiente de Jacquard", entenderemos melhor a unidade menos o pr√≥prio coeficiente. </font><font style="vertical-align: inherit;">A perda de Jaccard √© uma maneira de otimizar esse √≠ndice, juntamente com a perda de Tversky e Lov√°sz.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 4. Escolhendo os melhores par√¢metros para fun√ß√µes de perda parametrizadas</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para selecionar a melhor fun√ß√£o de perda no mesmo conjunto de dados, √© necess√°rio um crit√©rio de avalia√ß√£o. Em sua qualidade, escolhemos o n√∫mero m√©dio / mediano de componentes conectados nas m√°scaras resultantes. Al√©m disso, usamos o coeficiente Jacquard para m√°scaras preditivas convertidas em argmax de camada √∫nica e novamente divididas em camadas binarizadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O n√∫mero de componentes conectados (ou seja, pontos s√≥lidos da mesma cor) em cada previs√£o obtida √© um crit√©rio indireto para avaliar o volume de seu refinamento subsequente pelo int√©rprete. Se esse valor for 10, as camadas ser√£o selecionadas corretamente e estamos falando de um m√°ximo de corre√ß√£o menor do horizonte. Se n√£o houver muito mais, ser√° necess√°rio "limpar" pequenas √°reas da imagem. Se houver substancialmente mais deles, tudo est√° ruim e pode at√© precisar de um re-layout completo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O coeficiente de Jacquard, por sua vez, caracteriza a coincid√™ncia de zonas de imagem atribu√≠das a uma classe e seus limites.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia cruzada bin√°ria ponderada</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De acordo com os resultados das experi√™ncias, o valor do par√¢metro beta = 2 foi selecionado: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/iu/uo/hs/iuuohsoebw2mam6axgianwbi_se.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 2. Compara√ß√£o da qualidade da previs√£o de rede para a principal fun√ß√£o de perda e os crit√©rios selecionados </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/dm/-c/3t/dm-c3teowwucpbfd2cckbspwbi0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 3. Estat√≠sticas para o n√∫mero de componentes conectados em termos dos valores do par√¢metro beta</font></font><br>
</i><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia cruzada bin√°ria equilibrada</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De acordo com os resultados dos experimentos, foi escolhido o valor do par√¢metro beta = 0,7: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ae/cl/p8/aeclp8omibpajaurlwmrg9sttai.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 4. Compara√ß√£o da qualidade da rede prevista pela principal fun√ß√£o de perda e os crit√©rios selecionados </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/lj/r0/fm/ljr0fmrrxbyarastm-wudodn0w0.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 5. Estat√≠sticas para o n√∫mero de componentes conectados</font></font><br>
</i><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perda de Tversky</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De acordo com os resultados dos experimentos, foi escolhido o valor do par√¢metro beta = 0,7: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/3a/rk/vt/3arkvtetkqy6i9k3ih8zyo8is78.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 6. Compara√ß√£o da qualidade da rede prevista pela principal fun√ß√£o de perda e os crit√©rios selecionados </font></font><br>
</i><br>
<img src="https://habrastorage.org/webt/ct/qx/bh/ctqxbh-6f4hy2ek2k-phurk4zmg.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 7. Compara√ß√£o da qualidade da rede prevista pela principal fun√ß√£o de perda e os crit√©rios selecionados</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Duas conclus√µes podem ser tiradas das figuras acima. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Primeiro, os crit√©rios selecionados se correlacionam bastante bem entre si, ou seja, </font><font style="vertical-align: inherit;">o coeficiente de Jacquard √© consistente com uma estimativa do volume de refinamento necess√°rio. </font><font style="vertical-align: inherit;">Em segundo lugar, o comportamento das fun√ß√µes de perda de entropia cruzada √© bastante logicamente diferente do comportamento dos crit√©rios, ou seja, </font><font style="vertical-align: inherit;">usar o treinamento apenas nesta categoria de fun√ß√µes sem avalia√ß√£o adicional dos resultados ainda n√£o vale a pena.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 5. Escolhendo a melhor fun√ß√£o de perda.</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora compare os resultados que mostraram as 6 fun√ß√µes de perda selecionadas no mesmo conjunto de dados. </font><font style="vertical-align: inherit;">Para completar, adicionamos as previs√µes da rede obtidas no experimento anterior. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/wc/xr/my/wcxrmy--zexfjmduml37g4smpvc.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 8. redes projec√ß√µes Compara√ß√£o formados com diferentes fun√ß√µes de perda para os crit√©rios seleccionados</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Tabela 1. Os valores m√©dios de crit√©rios </font></font><br>
<br>
<img src="https://habrastorage.org/webt/kx/89/87/kx8987wn5narwnkfza5k2nemhbm.png"><br>
<br>
<img src="https://habrastorage.org/webt/6s/f4/_k/6sf4_kelwapket3g27sjs2eukyw.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 9. Compara√ß√£o redes projec√ß√µes sobre o n√∫mero de previs√µes do n√∫mero indicado de componentes ligados entre si</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
a partir dos diagramas apresentados e tabelas, as seguintes conclus√µes em rela√ß√£o ao uso de "solo" fun√ß√µes de perda:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No nosso caso, as fun√ß√µes "Jacquard" da classe Intersection over Union mostram realmente melhores valores que os da entropia cruzada. </font><font style="vertical-align: inherit;">Al√©m disso, significativamente melhor.</font></font></li>
<li>              Lovazh loss.</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos comparar visualmente as previs√µes para as fatias com um dos melhores e um dos piores valores de perda do Lovazh e o n√∫mero de componentes conectados. A m√°scara de destino √© exibido no canto superior direito, a previs√£o obtida no experimento anterior no canto inferior direito: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xp/xi/ra/xpxirarzwu1-6gfacc2c1cjh5yy.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">previs√µes Figura 10. Rede de para uma das melhores fatias </font></font><br>
 </i><br>
<img src="https://habrastorage.org/webt/xq/13/dr/xq13drinuno-gjldxvuknxurm-m.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">previs√µes Figura 11. Rede de para um dos piores fatias</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pode ser visto que todas as redes funcionam igualmente bem em facilmente reconhec√≠vel fatias. Mas mesmo em uma fatia pouco reconhec√≠vel em que todas as redes est√£o erradas, a previs√£o para a perda de Lovazh √© visualmente melhor do que as previs√µes de outras redes. Embora seja uma das piores perdas para essa fun√ß√£o. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Portanto, nesta etapa, decidimos um l√≠der claro - a perda de Lovazh, cujos resultados podem ser descritos da seguinte forma:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cerca de 60% das previs√µes est√£o pr√≥ximas do ideal, ou seja, </font><font style="vertical-align: inherit;">n√£o requerem mais do que ajustes em se√ß√µes individuais dos horizontes;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aproximadamente 30% das previs√µes n√£o cont√™m mais de 2 pontos extras, ou seja, </font><font style="vertical-align: inherit;">requer pequenas melhorias;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aproximadamente 1% das previs√µes cont√©m de 10 a 25 pontos extras, ou seja, </font><font style="vertical-align: inherit;">requer melhorias substanciais.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nesta etapa, substituindo apenas a fun√ß√£o de perda, obtivemos uma melhora significativa nos resultados em compara√ß√£o com o experimento anterior. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainda pode ser melhorado por uma combina√ß√£o de fun√ß√µes diferentes? </font><font style="vertical-align: inherit;">Confira.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 6. Escolhendo a melhor combina√ß√£o de fun√ß√£o de perda</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A combina√ß√£o de fun√ß√µes de perda de v√°rias naturezas √© usada com bastante frequ√™ncia. No entanto, encontrar a melhor combina√ß√£o n√£o √© f√°cil. Um bom exemplo √© o resultado de um experimento anterior, que acabou sendo ainda pior do que a fun√ß√£o "solo". O objetivo de tais combina√ß√µes √© melhorar o resultado otimizando de acordo com diferentes princ√≠pios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos tentar classificar as diferentes op√ß√µes da fun√ß√£o selecionada na etapa anterior com outras pessoas, mas n√£o com todas seguidas. Nos limitamos a combina√ß√µes de fun√ß√µes de diferentes tipos, neste caso, com entropia cruzada. N√£o faz sentido considerar combina√ß√µes de fun√ß√µes do mesmo tipo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No total, verificamos 3 pares com 9 poss√≠veis coeficientes cada (de 0,1 \ 0,9 a 0,9 \ 0,1). Nas figuras abaixo, o eixo x mostra o coeficiente antes da perda de Lovazh. O coeficiente antes da segunda fun√ß√£o √© igual a um menos o coeficiente antes da primeira. O valor esquerdo √© apenas uma fun√ß√£o de entropia cruzada, o valor correto √© apenas a perda de Lovazh. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/gq/rq/-d/gqrq-d_mwnnwg5dgvyzysvlxzqw.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 12. Avalia√ß√£o dos resultados previstos das redes treinadas em BCE + Lovazh </font></font><br>
 </i><br>
<img src="https://habrastorage.org/webt/1p/as/9p/1pas9pcxuskc8hnyj2igbzjibkc.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 13. Avalia√ß√£o dos resultados previstos das redes treinadas em BCE + Lovazh </font></font></i><br>
 <br>
<img src="https://habrastorage.org/webt/dy/22/8z/dy228z6wlagamlmywmivsvbvzmg.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 14. Avalia√ß√£o dos resultados previstos das redes treinadas em BCE + Lovazh</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pode-se observar que a fun√ß√£o ‚Äúsolo‚Äù selecionada n√£o foi aprimorada com a adi√ß√£o de entropia cruzada. Reduzir alguns valores do coeficiente Jacquard em 1-2 mil√©simos pode ser importante em um ambiente competitivo, mas n√£o compensa a deteriora√ß√£o dos neg√≥cios no crit√©rio para o n√∫mero de componentes conectados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para verificar o comportamento t√≠pico de uma combina√ß√£o de fun√ß√µes de diferentes tipos, realizamos uma s√©rie semelhante de treinamento para perda de Jaccard. Para apenas um par, foi poss√≠vel melhorar ligeiramente os valores de ambos os crit√©rios simultaneamente: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
0,8 * JaccardLoss + 0,2 * BBCE </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
M√©dia de componentes conectados: 11,5695 -&gt; 11,2895 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
M√©dia de Jaccard: 0,0307 -&gt; 0,0283 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mas mesmo esses valores s√£o piores que a perda "solo" do Lovazh.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Assim, faz sentido investigar combina√ß√µes de fun√ß√µes de natureza diferente em nossos dados apenas em condi√ß√µes de competi√ß√£o ou na presen√ßa de tempo e recursos livres. </font><font style="vertical-align: inherit;">√â pouco prov√°vel que alcan√ßar um aumento significativo na qualidade.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tarefa 7. Regulariza√ß√£o da melhor fun√ß√£o de perda.</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nesta etapa, tentamos melhorar a fun√ß√£o de perda selecionada anteriormente com uma adi√ß√£o projetada especificamente para dados s√≠smicos. Esta √© a regulariza√ß√£o descrita no artigo: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Redes neurais para geof√≠sicos e sua aplica√ß√£o √† interpreta√ß√£o de dados s√≠smicos"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O artigo menciona que regulariza√ß√µes padr√£o como pesos se deterioram em dados s√≠smicos n√£o funcionam bem. Em vez disso, √© proposta uma abordagem baseada na norma da matriz de gradiente, que visa suavizar os limites das classes. A abordagem √© l√≥gica se lembrarmos que os limites das camadas geol√≥gicas devem ser suaves.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No entanto, ao usar essa regulariza√ß√£o, deve-se esperar alguma deteriora√ß√£o nos resultados pelo crit√©rio Jacquard, uma vez que limites de classe suavizados provavelmente coincidir√£o com poss√≠veis transi√ß√µes abruptas obtidas com a marca√ß√£o manual. Mas temos mais um crit√©rio para verifica√ß√£o - pelo n√∫mero de componentes conectados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Treinamos 13 redes com a regulariza√ß√£o descrita no artigo e o coeficiente √† sua frente, assumindo valores de 0,1 a 0,0001. As figuras abaixo mostram algumas das classifica√ß√µes para ambos os crit√©rios. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/hz/ud/no/hzudnopqafa6t6chsygeikxsvwy.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 15. Compara√ß√£o da qualidade da previs√£o de rede pelos crit√©rios selecionados </font></font><br>
 </i><br>
<img src="https://habrastorage.org/webt/rq/v7/2h/rqv72hpfiaplc9m3_nfurrxk3xq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 16. Estat√≠sticas para o n√∫mero de componentes conectados em termos dos valores do coeficiente antes da regulariza√ß√£o</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Observa-se que a regulariza√ß√£o com um coeficiente de 0,025 reduziu significativamente as estat√≠sticas do crit√©rio para o n√∫mero de componentes conectados. No entanto, o crit√©rio Jacquard nesse caso aumentou para 0,0357. No entanto, este √© um pequeno aumento em compara√ß√£o com uma redu√ß√£o no refinamento manual. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/oa/-1/ow/oa-1owbvsfhyuzxqsugvjmlk1ro.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 17. Compara√ß√£o de previs√µes de rede pelo n√∫mero de previs√µes com o n√∫mero especificado de componentes conectados.Finalmente</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
, comparamos os limites de classe no destino e nas m√°scaras previstas para o pior corte selecionado anteriormente. </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/gh/sp/1o/ghsp1oiatktuohroonfpakr3teq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 18. A previs√£o da rede para uma das piores fatias </font></font></i><br>
 <br>
<img src="https://habrastorage.org/webt/ge/0b/zg/ge0bzgqe3gpsuktjwgmxannuxca.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figura 19. Sobreposi√ß√£o de parte do horizonte da m√°scara de destino e previs√£o</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como pode ser visto nas figuras, a m√°scara de previs√£o, √© claro, √© equivocada em alguns lugares, mas ao mesmo tempo suaviza as oscila√ß√µes dos horizontes alvo, ou seja, </font><font style="vertical-align: inherit;">corrige pequenos erros na marca√ß√£o inicial. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Resumo das caracter√≠sticas da fun√ß√£o de perda selecionada com regulariza√ß√£o:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cerca de 87% das previs√µes est√£o pr√≥ximas do ideal, ou seja, </font><font style="vertical-align: inherit;">n√£o requerem mais do que ajustes em se√ß√µes individuais dos horizontes;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aproximadamente 10% das previs√µes cont√™m 1 ponto extra, ou seja, </font><font style="vertical-align: inherit;">requer pequenas melhorias;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cerca de 3% das previs√µes cont√™m de 2 a 5 pontos extras, ou seja, </font><font style="vertical-align: inherit;">requer um refinamento um pouco mais substancial.</font></font></li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">achados</font></font></h2><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Somente ajustando um par√¢metro de aprendizado - a fun√ß√£o de perda - conseguimos melhorar significativamente a qualidade da previs√£o da rede e reduzir a quantidade de refinamento necess√°rio em cerca de tr√™s vezes. </font></font></li>
<li>             Intersection over Union (     Lovazh loss)      .            -,       .</li>
<li>    -,      .         , ..     .</li>
</ul><br>
<h2>  :</h2><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reinaldo Mozart Silva, Lais Baroni, Rodrigo S. Ferreira, Daniel Civitarese, Daniela Szwarcman, Emilio Vital Brazil. Netherlands Dataset: A New Public Dataset for Machine Learning in Seismic Interpretation</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lars Nieradzik. Losses for Image Segmentation</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Daniel Godoy. Understanding binary cross-entropy / log loss: a visual explanation</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali Gholipour. Tversky loss function for image segmentation using 3D fully convolutional deep networks</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Maxim Berman, Amal Rannen Triki, Matthew B. Blaschko. The Lovasz-Softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bas Peters, Eldad Haber, and Justin Granek. Neural-networks for geophysicists and their application to seismic data interpretation</a></li>
</ol></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt488842/index.html">Pegar um el√©tron: observar um processo que leva um quintilion√©simo de segundo</a></li>
<li><a href="../pt488844/index.html">Fronteiras para guardas de fronteira: tribunal dos EUA estabeleceu regras para dispositivos de verifica√ß√£o - discuta a situa√ß√£o</a></li>
<li><a href="../pt488846/index.html">Postgresso 19</a></li>
<li><a href="../pt488848/index.html">CTO toda inicializa√ß√£o</a></li>
<li><a href="../pt488850/index.html">Usando RabbitMQ com MonsterMQ Parte 1</a></li>
<li><a href="../pt488854/index.html">10. Introdu√ß√£o ao Fortinet v6.0. Escolta</a></li>
<li><a href="../pt488856/index.html">Bem, CRM e CRM. Tudo √© mais f√°cil do que voc√™ pensa.</a></li>
<li><a href="../pt488860/index.html">Substitui√ß√£o de importa√ß√£o e constru√ß√£o naval</a></li>
<li><a href="../pt488866/index.html">Validando imagens com o Gitlab CI / CD</a></li>
<li><a href="../pt488868/index.html">An√∫ncio do Mobius 2020 Piter: o que excita os desenvolvedores de dispositivos m√≥veis?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
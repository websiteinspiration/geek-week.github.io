<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨 🧘🏼 🏂🏻 本「ビジネスとマーケティングのための機械学習」 🤞🏼 🎈 🌂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="データサイエンスはあらゆるマーケティング活動の不可欠な部分になりつつあり、この本は、マーケティングにおけるデジタル変革の生きた肖像画です。データ分析とスマートアルゴリズムは、時間のかかるマーケティングタスクを自動化します。意思決定プロセスはより完全になるだけでなく、より速くなり、それは絶えず加速する...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>本「ビジネスとマーケティングのための機械学習」</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/460375/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><img src="https://habrastorage.org/webt/gq/td/mc/gqtdmc8joactk6gu7xrzcdr0f4i.jpeg" align="left" alt="画像"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データサイエンスはあらゆるマーケティング活動の不可欠な部分になりつつあり、この本は、マーケティングにおけるデジタル変革の生きた肖像画です。データ分析とスマートアルゴリズムは、時間のかかるマーケティングタスクを自動化します。意思決定プロセスはより完全になるだけでなく、より速くなり、それは絶えず加速する競争環境において非常に重要です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「この本は、マーケティングにおけるデジタル変革の生きた肖像画です。</font><font style="vertical-align: inherit;">これは、データサイエンスがどのようにあらゆるマーケティング活動の不可欠な部分になりつつあるかを示しています。</font><font style="vertical-align: inherit;">データ分析とインテリジェントアルゴリズムに基づくアプローチが、従来労働集約型のマーケティングタスクの深い自動化にどのように貢献しているかを詳しく説明しています。</font><font style="vertical-align: inherit;">意思決定プロセスは、より完璧になるだけでなく、より速くなりつつあります。これは、絶えず加速する競争環境において重要です。</font><font style="vertical-align: inherit;">この本は、データ処理の専門家とマーケティングの専門家が読む必要があり、一緒に読んだ方がよいでしょう。」</font><font style="vertical-align: inherit;">Yandexの戦略的マーケティング担当ディレクター、Andrey Sebrant氏。</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">抜粋。</font><font style="vertical-align: inherit;">5.8.3。</font><font style="vertical-align: inherit;">隠れた因子モデル</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これまでに説明したジョイントフィルタリングアルゴリズムでは、ほとんどの計算は評価マトリックスの個々の要素に基づいています。近接メソッドは、評価マトリックスの既知の値から直接、欠落している評価を測定します。モデルベースのメソッドは、評価マトリックスの上に抽象化レイヤーを追加し、ユーザーと要素間の関係の特定のパターンをキャプチャする予測モデルを作成しますが、モデルのトレーニングは依然として評価マトリックスのプロパティに大きく依存しています。結果として、これらの協調フィルタリング方法は通常、次の問題に直面します</font></font><br>
  <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
。評価マトリックスには数百万のユーザー、数百万の要素、数十億の既知の評価が含まれる可能性があり、計算の複雑さとスケーラビリティの深刻な問題を引き起こします。</font></font><br>
  <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
評価マトリックスは通常非常に疎です（実際には、評価の約99％が欠落している可能性があります）。これは、推奨アルゴリズムの計算の安定性に影響を与え、ユーザーまたは要素に本当に類似した近傍がない場合、信頼性の低い推定につながります。この問題は、ほとんどの基本的なアルゴリズムがユーザー指向または要素指向のどちらかであり、評価マトリックスで利用可能なすべてのタイプの類似性と関係を記録する能力を制限するという事実によって、しばしば悪化します。</font></font><br>
  <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
評価マトリックスのデータは、ユーザーと要素の類似性のため、通常は強く相関しています。これは、評価マトリックスで利用可能な信号がまばらであるだけでなく冗長であることを意味し、スケーラビリティ問題の悪化の一因となります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上記の考慮事項は、元の評価行列が信号の最適な表現ではない可能性があることを示しており、ジョイントフィルタリングにより適した他の代替表現を検討する必要があります。</font><font style="vertical-align: inherit;">このアイデアを探求するために、出発点に戻って、レコメンデーションサービスの性質について少し考えてみましょう。</font><font style="vertical-align: inherit;">実際、レコメンデーションサービスは、ユーザーと要素間の類似性の測定に基づいて評価を予測するアルゴリズムと見なすことができます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/at/bc/6n/atbc6no-aj2vssp1mrgyctgu_oy.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この類似性の尺度を決定する1つの方法は、隠れ因子アプローチを使用して、ユーザーと要素をいくつかのk次元空間内のポイントにマッピングし、各ユーザーと各要素がk次元ベクトルで表されるようにすることです。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/9e/ck/no/9eckno4ntrf2yl0hw1q2tr2irbk.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
対応する次元pとqが互いに比較できるように、ベクトルを構築する必要があります。つまり、各次元は記号または概念と見なすことができます。つまり、pujはユーザーuと概念jの近接度の尺度であり、qijはそれぞれ要素iと概念jの尺度です。実際には、これらの寸法は、ユーザーと要素に同時に適用されるジャンル、スタイル、およびその他の属性として解釈されることがよくあります。ユーザーと要素の間の類似性、したがって評価は、対応するベクトルの積として定義できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k3/1w/9w/k31w9wqmwas5pfvhr8_mopo7ibg.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各評価は、元の評価行列では直接観察されない概念空間に属する2つのベクトルの積に分解できるため、pとqは隠れ因子と呼ばれます。</font><font style="vertical-align: inherit;">もちろん、この抽象的なアプローチが成功するかどうかは、潜在的な要因がどのように定義され構築されるかに完全に依存します。</font><font style="vertical-align: inherit;">この質問に答えるために、式5.92は行列形式で次のように書き直すことができます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/2i/bp/j9/2ibpj9pmptpun2amylvxf41okjw.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、Pはpベクトルから組み立てられたn×k行列であり、Qは図1に示すようにqベクトルから組み立てられたm×k行列です。</font><font style="vertical-align: inherit;">5.13。</font><font style="vertical-align: inherit;">ジョイントフィルタリングシステムの主な目的は、通常、評価の予測誤差を最小限に抑えることです。これにより、隠れた因子の行列に関する最適化問題を直接決定できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/9h/nm/mx/9hnmmxregnvn9snp9empxqf91qk.png" alt="画像"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/z-/vl/nu/z-vlnuz-v9git5dmm0nj79etl5g.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
隠れた次元の数kが固定され、k≤nおよびk≤mであると仮定すると、最適化問題5.94は、第2章で検討した低ランク付け近似問題に減少します。解決策へのアプローチを示すために、評価行列が完全であると仮定します。</font><font style="vertical-align: inherit;">この場合、最適化問題には、評価行列の特異値分解（SVD）に関する分析的解があります。</font><font style="vertical-align: inherit;">特に、標準のSVDアルゴリズムを使用して、マトリックスを3つのマトリックスの積に分解できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/7z/ic/x0/7zicx0iwp156hctp6t7axd5bzu4.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、Uは列によって正規化されたn×n行列、Σはn×m対角行列、Vは列によって正規化されたm×m行列です。</font><font style="vertical-align: inherit;">問題5.94の最適な解決策は、kの最上位の次元に切り捨てられたこれらの要素に関して取得できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mw/i-/os/mwi-oskhgcs-ehf_bhepytyo_os.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その結果、以下に示すように、予測精度の点で最適な隠れた要素を特異分解によって取得できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uc/ih/yl/ucihyltxuqye29vkocknsbzyguw.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このSVDベースの隠し因子モデルは、このセクションの冒頭で説明した協調フィルタリングの問題の解決に役立ちます。まず、n×mの大きな評価行列をn×kおよびm×kの因子行列に置き換えます。実際には、隠れた次元の最適な数kが小さいことが多いため、通常ははるかに小さくなります。たとえば、500,000人のユーザーと17,000個の要素を持つ評価マトリックスは、40の測定値を使用してかなりよく近似できた場合があります[Funk、2016]。さらに、SVDは評価行列の相関を排除します。5.97で定義された潜在因子行列は列で正規直交です。つまり、非表示の次元は相関されません。実際には通常そうである場合、元の評価行列に信号が存在するため、SVDはスパース性の問題も解決します。効果的に集中し（信号エネルギーが最も高いk次元を選択することを思い出してください）、隠れた因子の行列はスパースではありません。図5.14は、このプロパティを示しています。ユーザーベースの近接アルゴリズム（5.14、a）は、特定の要素と特定のユーザーのスパース評価ベクトルを縮小して、評価スコアを取得します。逆に、隠れた因子モデル（5.14、b）は、次元が小さく、エネルギー密度が高い2つのベクトルのたたみ込みによって、評価を推定します。逆に、隠れた因子モデル（5.14、b）は、次元が小さく、エネルギー密度が高い2つのベクトルのたたみ込みによって、評価を推定します。逆に、隠れた因子モデル（5.14、b）は、次元が小さく、エネルギー密度が高い2つのベクトルのたたみ込みによって、評価を推定します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/v3/te/fm/v3tefmto-k2yf54og0xn4rpbxlq.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今説明したアプローチは、隠れた要因の問題に対する首尾一貫した解決策のように見えますが、実際には、評価マトリックスが完全であるという仮定のために、重大な欠点があります。評価行列がスパースである場合、これはほとんどの場合に当てはまりますが、標準のSVDアルゴリズムは欠落している（未定義の）要素を処理できないため、直接適用できません。この場合の最も簡単な解決策は、欠落している評価をデフォルト値で埋めることですが、これは予測に深刻なバイアスをもたらす可能性があります。さらに、そのようなソリューションの計算の複雑さは、完全なn×m行列のSVDの複雑さに等しいため、計算効率がよくありませんが、既知の評価の数に比例する複雑さのメソッドを持つことが望ましいです。これらの問題は、次のセクションで説明する別の分解方法を使用して解決できます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.8.3.1。</font><font style="vertical-align: inherit;">無制限の分解</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
標準のSVDアルゴリズムは、低ランクの近似問題に対する分析的ソリューションです。</font><font style="vertical-align: inherit;">ただし、この問題は最適化問題と見なすことができ、普遍的な最適化手法も適用できます。</font><font style="vertical-align: inherit;">最も単純なアプローチの1つは、勾配降下法を使用して、隠れた因子の値を繰り返し改良することです。</font><font style="vertical-align: inherit;">開始点は、残存予測誤差としてのコスト関数Jの定義です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/g8/d_/gk/g8d_gkpksz8-d3wyg0xs9ca60a8.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今回は、隠れた因子の行列に直交性などの制限を課さないことに注意してください。</font><font style="vertical-align: inherit;">隠れた因子に関するコスト関数の勾配を計算すると、次の結果が得られます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jn/_l/cu/jn_lcurj48vk0kuluh8mojadgcy.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、Eは残差誤差行列です。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/6z/wt/at/6zwtat7l4h9qoo0fq7ejzatlobi.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
勾配降下アルゴリズムは、各ステップで勾配の負の方向に移動することにより、コスト関数を最小化します。したがって、次の式に従って、行列PとQを繰り返し変更して収束させることにより、評価を予測する際の二乗誤差を最小限に抑える隠れた要因を見つけることができます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/f9/uw/gu/f9uwguspa118fw__nuchwxu1ycy.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、αは学習速度です。勾配降下法の欠点は、残留誤差の行列全体を計算し、各反復で隠れた因子のすべての値を同時に変更する必要があることです。大きな行列に適している代替アプローチは、確率的勾配降下法です[Funk、2016]。確率的勾配降下アルゴリズムは、予測誤差の合計Jが評価行列の個々の要素の誤差の合計であるという事実を利用しているため、一般的な勾配Jは、1つのデータポイントの勾配で近似でき、隠れた要素は要素ごとに変更できます。このアイデアの完全な実装は、アルゴリズム5.1に示されています。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/le/c5/ct/lec5ctumggjq0twtb30wnamvj0g.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アルゴリズムの最初の段階は、隠れた因子の行列の初期化です。これらの初期値の選択はそれほど重要ではありませんが、この場合、ランダムに生成された隠し要素間での既知の評価のエネルギーの均一な分布が選択されます。次に、アルゴリズムはコンセプトの次元を順次最適化します。各測定について、彼はトレーニングセットのすべての評価を繰り返しトラバースし、隠れた因子の現在の値を使用して各評価を予測し、誤差を推定し、式5.101に従って因子の値を修正します。収束条件が満たされると、測定の最適化が完了し、その後、アルゴリズムは次の測定に進みます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アルゴリズム5.1は、標準のSVDメソッドの制限を克服するのに役立ちます。</font><font style="vertical-align: inherit;">個々のデータポイントをループすることで隠れた要素を最適化し、欠落した評価や巨大行列を使った代数演算の問題を回避します。</font><font style="vertical-align: inherit;">また、反復アプローチにより、確率的勾配降下法は、5.11式を使用して行列全体を変更する勾配降下法よりも実用的なアプリケーションにとって便利になります。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">例5.6</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実際、隠れた要素に基づくアプローチは、評価マトリックスで暗黙的なパターンを識別し、それらを概念の形で明示的に表現できる表現を教える方法のグループ全体です。すべての概念が常に意味のある意味を持つわけではありませんが、概念には完全に意味のある解釈、特に高エネルギーの解釈がある場合があります。たとえば、マトリックス分解アルゴリズムを映画の評価データベースに適用すると、メロドラマ、コメディ、ホラーなど、心理的な次元にほぼ対応する要素を作成できます。この現象を、表の評価マトリックスを使用する小さな数値例で示します。 5.3：</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xw/6a/vu/xw6avuizjd2x8aku8k-0r89ieem.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初に、すべての要素からグローバル平均μ= 2.82を差し引き、行列を中央に配置します。次に、k = 3の隠れた測定値と学習速度α= 0.01でアルゴリズム5.1を実行し、次の2つの因子行列を取得します。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k-/rr/vd/k-rrvde1sezar3qo0e2vqfb7jh8.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらの行列の各行はユーザーまたはフィルムに対応し、12の行ベクトルすべてが図1に示されています。 5.15。最初の列（概念の最初のベクトル）の要素は最大値を持ち、後続の列の値は徐々に減少していることに注意してください。これは、最初の概念ベクトルが1つの測定を使用してキャプチャできる限りの信号エネルギーをキャプチャし、2番目の概念ベクトルが残留エネルギーの一部のみをキャプチャするという事実によって説明されます。さらに、最初のコンセプトは意味的にドラマ軸として解釈できることに注意してください。 -正の方向がアクション映画のジャンルに対応し、負の方向がドラマのジャンルに対応するアクション映画。この例の評価は非常に相関しているため、はっきりと見ることができます最初の3人のユーザーと最初の3本の映画は、最初のベクトル概念（ドラマ映画とそのような映画が好きなユーザー）で大きな負の値を持ち、最後の3人のユーザーと最後の3本の映画は、同じ列で大きな正の値を持っています（アクション映画とこのジャンルを好むユーザー）。この特定のケースの2番目の次元は、主にユーザーまたは要素のバイアスに対応します。これは、サイコグラフィック属性（ユーザーの判断の重要性？映画の人気？）として解釈できます。他の概念はノイズと見なすことができます。このジャンルを好む人）。この特定のケースの2番目の次元は、主にユーザーまたは要素のバイアスに対応します。これは、サイコグラフィック属性（ユーザーの判断の重要性？映画の人気？）として解釈できます。他の概念はノイズと見なすことができます。このジャンルを好む人）。この特定のケースの2番目の次元は、主にユーザーまたは要素のバイアスに対応します。これは、サイコグラフィック属性（ユーザーの判断の重要性？映画の人気？）として解釈できます。他の概念はノイズと見なすことができます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/z0/s6/t9/z0s6t9vbnwdtgonx0p6rswo_ufe.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果の因子の行列は列で完全に直交ではありませんが、これは直交する傾向があります。これは、これがSVDソリューションの最適性から生じるためです。</font><font style="vertical-align: inherit;">これは、対角行列に近いPTPとQTQの積を見るとわかります。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/pb/zr/sf/pbzrsfbqm0hjvmoqgh1xlurslnm.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
行列5.103は、本質的に、既知の評価と欠落している評価の両方を評価するために使用できる予測モデルです。</font><font style="vertical-align: inherit;">推定値は、2つの因子を掛けてグローバル平均を加算することで取得できます。</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qg/du/d2/qgdud2i8fqm_ut6doi-8jnpllq8.png" alt="画像"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果は、よく知られているものを正確に再現し、直感的な期待に従って欠落している評価を予測します。</font><font style="vertical-align: inherit;">推定値の精度は、測定数を変更することで増減できます。最適な測定数は、実際にクロスチェックして、計算の複雑さと精度の間の妥当な妥協点を選択することで決定できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
»本の詳細については</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、出版社のWebサイトを参照してください</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
» </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">目次</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
» </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">抜粋</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
ハブロジテリーの25％割引クーポン- </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">機械学習</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
本の紙のバージョンの支払い時に、電子書籍が電子メールで送信されます。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja460361/index.html">医療情報システムのサイバーセキュリティに関する素晴らしいFAQ</a></li>
<li><a href="../ja460363/index.html">アプローチに欠けている7つの要素12 Factor App</a></li>
<li><a href="../ja460365/index.html">分散トレース：すべてが間違っていました</a></li>
<li><a href="../ja460367/index.html">カオスエンジニアリング：意図的な破壊の芸術。パート1</a></li>
<li><a href="../ja460373/index.html">フードターボページの下で：ウェブページの高速ダウンロード技術のアーキテクチャ</a></li>
<li><a href="../ja460377/index.html">Liquibaseを使用してSpring Bootアプリケーションでデータベース構造を管理する。パート1</a></li>
<li><a href="../ja460381/index.html">主張性とは何か、なぜ必要なのか</a></li>
<li><a href="../ja460383/index.html">Legend of Zeldaの画面遷移は文書化されていないNESの機能を使用します</a></li>
<li><a href="../ja460387/index.html">SELinux初心者向けガイド</a></li>
<li><a href="../ja460393/index.html">背景：Fedora Silverblueに期待すること</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
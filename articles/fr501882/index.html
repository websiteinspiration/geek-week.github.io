<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💆🏽 👨🏻‍🚒 👈🏽 Comment nous utilisons les algorithmes de vision par ordinateur: traitement vidéo dans un navigateur mobile utilisant OpenCV.js 👩🏽‍🚒 🕝 🤮</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il existe déjà toutes les possibilités d'identifier une personne en ligne, mais jusqu'à présent, elles sont rarement utilisées. Nous avons peut-être é...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Comment nous utilisons les algorithmes de vision par ordinateur: traitement vidéo dans un navigateur mobile utilisant OpenCV.js</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/simbirsoft/blog/501882/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il existe déjà toutes les possibilités d'identifier une personne en ligne, mais jusqu'à présent, elles sont rarement utilisées. </font><font style="vertical-align: inherit;">Nous avons peut-être été l'un des premiers à mettre en œuvre le scénario optimal pour l'utilisateur - connectez-vous au site à partir d'un smartphone, prenez une photo de votre permis de conduire ou de votre passeport et envoyez des données au système. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voyons comment les algorithmes de vision par ordinateur aident à reconnaître les documents dans un flux vidéo directement dans les navigateurs mobiles. </font><font style="vertical-align: inherit;">Dans cet article, nous partageons notre expérience de la façon dont nous avons utilisé OpenCV.js pour cela chez SimbirSoft, quelles difficultés sont possibles, comment garantir la vitesse et obtenir une UX «fluide» sans ralentir.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jx/y7/u7/jxy7u7brc2ixo10gyheuhr19zcu.png"><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle était la tâche</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le scénario commercial de l'algorithme en cours de développement est le suivant. Un utilisateur accédant au site à partir d'un téléphone portable doit pouvoir photographier ses documents et les envoyer au système pour un traitement ultérieur. Cela peut faire partie du processus d'identité lors de la demande d'utilisation de tout service. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans ce scénario, une application Web est préférable à une application mobile en raison de sa disponibilité et du temps réduit pour terminer l'opération. La page Web n'a pas besoin d'installation et est prête à fonctionner immédiatement après le chargement. L'utilisateur peut procéder aux actions dont il a besoin - soumettre une demande - immédiatement après avoir reçu le lien, sans se laisser distraire par des actions supplémentaires. D'un point de vue commercial, ces facteurs augmentent la conversion et l'efficacité commerciale du processus.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D'un point de vue architectural, l'algorithme est nécessaire pour détecter directement les limites du document et recadrer le fond en excès dans l'image. </font><font style="vertical-align: inherit;">La vérification de l'identité, l'authentification et les contrôles de fraude seront mis en œuvre par d'autres composants. </font><font style="vertical-align: inherit;">Cependant, il est conseillé d'effectuer au moins des vérifications minimales pour exclure l'envoi de cartes de visite, de rectangles de papier vides et d'autres images manifestement non pertinentes pour le traitement des images.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exigences</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le cadre de notre projet, il y avait les exigences supplémentaires suivantes pour l'algorithme:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la possibilité de travailler en temps réel: le flux vidéo de la caméra ne doit pas "ralentir" pendant le fonctionnement de l'algorithme;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la capacité de travailler dans un large éventail de contrastes et de textures de fond: contraste et contraste faibles, fond homogène et hétérogène;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prise en charge d'une large gamme de modèles de smartphones, y compris les modèles économiques publiés il y a plusieurs années.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Enfin, il n'y avait aucun ensemble de données pour la formation d'algorithmes d'apprentissage automatique dans le projet, et il n'y avait aucun moyen de le collecter et de le baliser. </font><font style="vertical-align: inherit;">Nous n'avons eu que quelques échantillons de test dans les résultats de recherche de Google. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Compte tenu de cet énoncé du problème, nous avons décidé de développer sur la base des algorithmes classiques de vision par ordinateur de la bibliothèque opencv. </font><font style="vertical-align: inherit;">Une autre possibilité était l'utilisation d'algorithmes d'apprentissage automatique et de réseaux de neurones, mais elle a déjà été écartée au début des travaux en raison d'exigences de performances: une fois appliqués, il ne serait pas possible de fournir un traitement de trame en temps réel sur tous les appareils cibles.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Approche générale et structure de l'algorithme</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'idée principale de l'algorithme est un cadre de référence, le long duquel il est nécessaire d'aligner le document. </font><font style="vertical-align: inherit;">Son utilisation poursuit plusieurs objectifs à la fois. </font><font style="vertical-align: inherit;">Premièrement, il fournira une taille d'image appropriée, suffisante pour un traitement ultérieur des documents. </font><font style="vertical-align: inherit;">Deuxièmement, comme nous le verrons plus loin, il peut être utilisé comme l'un des filtres candidats lors de la recherche de bordures de document. </font><font style="vertical-align: inherit;">Troisièmement, il peut être utilisé pour capturer et recadrer l'image si les bordures du document sont introuvables. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ru/et/bq/ruetbqsseuefny01b_anvvaa834.png"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure. </font><font style="vertical-align: inherit;">1. La structure générale de l'algorithme</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La structure générale de l'algorithme est représentée sur la Fig. </font><font style="vertical-align: inherit;">1. Les images du flux vidéo sont traitées dans un cycle, entre les itérations dont un délai est défini pour se conformer au FPS souhaité - nous nous sommes arrêtés à 30 images par seconde. </font><font style="vertical-align: inherit;">Cela vous permet d'éviter les «ralentissements» et de réduire la charge sur le processeur et la consommation d'énergie de l'appareil.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Chaque trame traitée subit un prétraitement, au cours duquel deux opérations principales sont effectuées. Tout d'abord, une copie d'une trame d'une taille fixe de 640x480 est créée, avec laquelle les autres étapes de l'algorithme fonctionnent. L'image d'origine reste également, le document détecté sera découpé. Cela permettra d'économiser la qualité de l'image finale. Deuxièmement, la copie créée est traduite en nuances de gris. La couleur du document en cours de traitement est ignorée par l'algorithme, car elle peut varier d'un pays à l'autre et même dans différentes régions du pays - un exemple est un permis de conduire aux États-Unis.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La première étape de la détection d'un document consiste à rechercher le visage dans l'image. L'utilisation de cette heuristique élimine la capture de cartes de visite et d'autres images manifestement non pertinentes. La recherche est effectuée en utilisant le standard opencv'shash </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CascadeClassifier.detectMultiScale ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et la cascade pré- </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">formée haarcascade_frontalface_default</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Les tailles minimales et maximales des visages détectés sont limitées, ce qui permet de réduire les coûts de calcul, et limite encore davantage l'échelle du document dans l'image. Un visage est considéré comme détecté dans l'image lorsqu'il se trouve dans la partie gauche - ou inférieure gauche, pour les passeports - de la zone à l'intérieur du cadre de référence (Fig. 2). Il s'agit d'une mesure supplémentaire pour assurer l'alignement correct du document dans l'image.</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les exemples de cet article ne contiennent pas de données personnelles. </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/ws/mz/7w/wsmz7wghvpoyfdslngrf59jofms.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure. 2. La zone de la position attendue du visage dans l'image. Le cadre de support est affiché en rouge, les bordures de la zone de l'emplacement attendu du visage sont affichées en vert.</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Après la détection des visages, nous procédons à la détection des bordures. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FindContours ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est souvent utilisé ici </font><font style="vertical-align: inherit;">. Cependant, cette approche ne fonctionne bien que dans des cas contrastés, par exemple pour une feuille de papier posée sur un bureau sombre. Si le contraste est plus faible, ou l'éclairage est pire, ou si quelqu'un tient une feuille dans ses mains, couvrant une partie de la bordure avec ses doigts, les contours détectés se décomposent en composants séparés, «perdent» des sections importantes ou ne sont pas détectés du tout.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par conséquent, nous avons adopté une approche différente. Après la binarisation, nous passons d'abord l'image à travers le filtre de bordure en utilisant </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Canny ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , puis regardons l'image résultante pour la ligne en utilisant la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HoughLines de</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> transformation Huff </font><i><font style="vertical-align: inherit;">()</font></i><font style="vertical-align: inherit;"> . Le paramètre de seuil est immédiatement réglé suffisamment grand, égal à 30 - pour filtrer les segments courts et autres non pertinents détectés.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'ensemble de lignes résultant est en outre filtré, ne laissant que des lignes proches du cadre de référence. Pour ce faire, nous traduisons d'abord les équations des lignes de trame en points dans le système de coordonnées polaires (rho, thêta) - thêta sera toujours 0 ou pi / 2, et rho sera unique pour chaque ligne. Après cela, nous sélectionnons dans les lignes obtenues à partir de la transformation de Huff uniquement celles qui se trouvent au voisinage des points de contrôle - selon la métrique euclidienne, en tenant compte de la différence dans l'échelle des valeurs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous répartissons l'ensemble des lignes obtenues après filtrage en quatre groupes correspondant aux quatre lignes du référentiel, trouvons les intersections des lignes par paires entre les groupes, calculons la moyenne et obtenons les coordonnées des quatre points - les coins du document détecté (Fig.3).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zr/7g/lz/zr7glzo5dwn-mofan9fhnthwu8k.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure. 3. Filtrer les lignes et définir les coins du document. Des lignes vertes - résultat du filtrage, des points jaunes - ont détecté les coins du document.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ensuite, vous devez vous assurer de la qualité du cadre. Pour ce faire, nous vérifions que le cadre est resté immobile pour la dernière fois. Pour ce faire, soustrayez la trame au début de la période de la trame actuelle à l'aide de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">absdiff ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et comparez-la avec le seuil. Avant la soustraction, nous lissons en outre les images avec un filtre </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gaussien GaussianBlur ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pour réduire l'influence du bruit et d'autres facteurs aléatoires. Nous évaluons également la focalisation du cadre en calculant son laplacien </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplacien ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , en estimant sa variance et en comparant la valeur obtenue avec un seuil.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si toutes les vérifications réussissent, vous pouvez passer à la dernière partie. </font><font style="vertical-align: inherit;">Nous recalculons les coordonnées détectées des angles dans le système de coordonnées de l'image originale sous-exposée et découpons la région résultante à l'aide de la méthode </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">roi ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Le document a été détecté avec succès.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caractéristiques d'implémentation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au cours du développement de l'algorithme, ses principaux composants ont été assemblés dans un script python. Après cela, l'algorithme a été porté sur opencv.js et javascript, puis sur wasm. Cette approche est dictée par des considérations de commodité à toutes les étapes. Sur python, il était plus pratique pour notre équipe d'expérimenter différentes variantes de l'algorithme et d'effectuer des réglages de paramètres approximatifs. Le portage en javascript a permis de tester le fonctionnement de l'algorithme sur la plateforme cible, notamment sur différents appareils et navigateurs. Sur la base des résultats de ces vérifications, un réglage fin des paramètres de l'algorithme a été effectué. Enfin, la réécriture de sections critiques de code sur wasm nous a permis d'obtenir une amélioration supplémentaire des performances.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Au cours de la migration, un certain nombre de différences ont été découvertes dans l'API OpenCV, ce qui a entraîné des changements mineurs dans l'implémentation. Par exemple, la variance d'un Laplacien en python est simplement considérée comme </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplacian (). Var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Avec OpenCV.js, il n'y a aucun moyen d'utiliser NumPy, mais aucune implémentation alternative de la méthode </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> n'a </font><font style="vertical-align: inherit;">été fournie. Solution: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">comptez la</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fonction </font><i><font style="vertical-align: inherit;">meanStdDev ()</font></i><font style="vertical-align: inherit;"> comme l' </font><font style="vertical-align: inherit;">écart type (Listing 1).</font></font><br>
<br>
<pre><code class="javascript hljs">private isImageBlurry(image: cv.Mat): boolean {
		<span class="hljs-keyword">const</span> laplacian = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.Laplacian(image, laplacian, cv.CV_64F);<font></font>
		<span class="hljs-keyword">const</span> s_mat = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.meanStdDev(laplacian, <span class="hljs-keyword">new</span> cv.Mat(), s_mat);
		<span class="hljs-keyword">const</span> s = s_mat.data64F[<span class="hljs-number">0</span>];
		<span class="hljs-keyword">const</span> v = <span class="hljs-built_in">Math</span>.pow(s, <span class="hljs-number">2</span>);
		<span class="hljs-keyword">return</span> (v &lt; <span class="hljs-keyword">this</span>.laplacianVarianceThreshold);<font></font>
	}</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Liste 1. Évaluation de la concentration sur l'image à travers la variance du laplacien dans opencv.js (TypeScript)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Une autre caractéristique était la nécessité de réduire la taille de la bibliothèque. Dans sa forme originale, OpenCV.js a une capacité de 7,9 Mo. Son téléchargement via Internet ralentit l'initialisation de l'algorithme. La solution à ce problème est de «rogner» les modules inutilisés pendant le processus d'assemblage de la bibliothèque, ce qui peut réduire considérablement la taille du fichier de sortie: nous avons réussi à atteindre une taille de 1,8 Mo. La liste des composants inclus dans l'assemblage peut être configurée dans le fichier de configuration </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plates-formes / js / opencv_js.config.py</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Listing 2).</font></font><br>
<br>
<pre><code class="javascript hljs">white_list = makeWhiteList([core, imgproc, objdetect, video, dnn, features2d, photo, aruco, calib3d])</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listing 2. La liste blanche d'origine des modules opencv inclus dans l'assembly pour javascript</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Enfin, une contribution importante pour garantir les performances requises de l'algorithme a été apportée en le déplaçant vers Web Worker. </font><font style="vertical-align: inherit;">Cette étape, associée à la restriction du FPS, nous a permis de nous débarrasser des «ralentissements» du flux vidéo lors du fonctionnement de l'algorithme, ce qui a eu un effet positif sur l'UX.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">résultats</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Des exemples de capture et de recadrage d'images sont présentés sur la Fig. </font><font style="vertical-align: inherit;">4. On peut voir que le recadrage de la plus haute qualité est obtenu sur un fond uniforme sombre et la qualité la plus basse est obtenue avec un fond inhomogène clair. </font><font style="vertical-align: inherit;">Il s'agit de l'effet attendu associé aux dégradés obtenus sur différents arrière-plans et utilisé pour détecter les bordures d'un document. </font><font style="vertical-align: inherit;">Sur un fond sombre, les dégradés sont plus grands que sur un fond clair, un fond uniforme conduit à moins de variabilité des valeurs de gradient. </font><font style="vertical-align: inherit;">Cela conduit à une détection fiable des limites et, par conséquent, à un meilleur recadrage. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/es/my/90/esmy90lihywocpj3-7p5bgttqkg.jpeg"><br>
<img src="https://habrastorage.org/webt/w4/uz/2l/w4uz2lnqlaajyd6eyplijsg72hc.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure. </font><font style="vertical-align: inherit;">4. Exemples de recadrage de documents à l'aide d'un algorithme</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'article présente un algorithme pour détecter des documents sur des images à partir d'un flux vidéo adapté à une utilisation dans les navigateurs mobiles, et examine également les caractéristiques de sa mise en œuvre à l'aide de la bibliothèque opencv.js. </font><font style="vertical-align: inherit;">L'algorithme vous permet d'obtenir l'image de sortie des documents dans une qualité suffisante pour une utilisation ultérieure par des algorithmes d'authentification, de vérification d'identité, etc. </font><font style="vertical-align: inherit;">La vitesse de l'implémentation résultante vous permet d'obtenir une UX «fluide» sans «ralentissements» et perte de trame. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Merci pour l'attention! </font><font style="vertical-align: inherit;">Nous espérons que cet article vous sera utile.</font></font></b></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr501868/index.html">Comment ne pas laisser le comptable se jeter ou On transfère 1C vers le cloud. Instruction étape par étape</a></li>
<li><a href="../fr501870/index.html">Nombre maximal de valeurs dans la partie II de l'énumération</a></li>
<li><a href="../fr501872/index.html">Lieu d'étude dans les systèmes cybernétiques</a></li>
<li><a href="../fr501874/index.html">Architectures frontales modernes (partie 2)</a></li>
<li><a href="../fr501880/index.html">À propos de la traduction de "débuts" et "débuts" sans début, début et premier</a></li>
<li><a href="../fr501884/index.html">Comment les archives électroniques d'informations médicales aideront à diagnostiquer plus efficacement les maladies</a></li>
<li><a href="../fr501886/index.html">L'espace n'est pas aussi simple qu'il y paraît.</a></li>
<li><a href="../fr501888/index.html">Comment réduire les risques associés aux ransomwares ransomwares</a></li>
<li><a href="../fr501890/index.html">React Native - enregistrez des photos et des vidéos dans la galerie d'appareils</a></li>
<li><a href="../fr501892/index.html">Pas ma jambe gauche: une analyse de la structure cérébrale des personnes atteintes de xénomélie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåÑ üëæ üé¨ C√≥mo reconocemos el equipo de protecci√≥n personal üçâ üë®üèª‚Äç‚úàÔ∏è üíû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬°Probablemente, te has estado preguntando toda tu vida c√≥mo entrenar una red neuronal para reconocer a las personas con cascos y chalecos naranjas! ¬øN...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>C√≥mo reconocemos el equipo de protecci√≥n personal</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/499248/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬°Probablemente, te has estado preguntando toda tu vida c√≥mo entrenar una red neuronal para reconocer a las personas con cascos y chalecos naranjas! ¬øNo? Pero te lo diremos de todos modos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nuestro nombre es Tatyana Voronova y Elvira Dyaminova. Nos dedicamos al an√°lisis de datos en la empresa Center 2M, trabajamos mucho con las f√°bricas y empresas m√°s reales. Debido a violaciones de seguridad, sufren p√©rdidas multimillonarias, los empleados resultan heridos, por lo que ser√≠a bueno poder detectar tales violaciones sistem√°ticamente y lo antes posible. Lo mejor de todo: autom√°ticamente. Por lo tanto, tenemos problemas asociados con el reconocimiento de equipos de protecci√≥n personal (EPP) en video y la identificaci√≥n de personas o equipos en la zona de peligro.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/2u/-q/gv2u-qjuorn0awf-hlwjbuu3dc4.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En su mayor parte, nos llegan √≥rdenes para determinar los cascos (m√°s precisamente, su ausencia) y la ropa de trabajo. </font><font style="vertical-align: inherit;">Ya hemos adquirido experiencia en la realizaci√≥n de tales tareas y ahora podemos describir los problemas que hemos encontrado y c√≥mo resolverlos.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dado que, seg√∫n los t√©rminos de cooperaci√≥n, no tenemos derecho a publicar im√°genes de los objetos del cliente, ilustraremos el art√≠culo con im√°genes de Internet, en las que las personas con casco a menudo sonr√≠en y se ven geniales. </font><font style="vertical-align: inherit;">Desafortunadamente, en el dominio p√∫blico no por todas las caracter√≠sticas de las tareas que enfrentamos en la realidad, puede encontrar buenos ejemplos. </font><font style="vertical-align: inherit;">En particular, en la vida es menos probable que las personas con casco sonr√≠an, y el problema de los trabajadores calvos (hablaremos un poco m√°s adelante) en Internet no se ha revelado realmente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imagen de Internet (tama√±o 1920x1280):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/f9/9q/nb/f99qnblemmbik0caykgir0zfiag.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El reconocimiento del EPP puede reducirse a uno de los dos problemas cl√°sicos de la visi√≥n por computadora: clasificaci√≥n de im√°genes y detecci√≥n de objetos. En la pr√°ctica, result√≥ que era mejor no utilizar uno de estos enfoques, sino elegir el m√°s adecuado para cada caso en particular, as√≠ como combinarlos de manera flexible. Por ejemplo, primero podemos determinar d√≥nde est√°n las personas en la imagen, luego clasificar las im√°genes cortadas por silueta en clases "en ropa de trabajo" y "sin", y detectar la presencia de un casco en el segundo pase. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En las figuras precortadas de personas, la clasificaci√≥n de la presencia de cascos y ropa de trabajo se ve as√≠ (vista de la imagen original): </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
el resultado del trabajo de los modelos para la clasificaci√≥n de ropa de trabajo y cascos</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/su/ad/lg/suadlgvrpviurbpxflbg6y3bm8s.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En las mismas figuras humanas previamente seleccionadas, la aplicaci√≥n del enfoque esta vez con detecci√≥n de cascos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El resultado del modelo para la clasificaci√≥n de ropa de trabajo y un modelo para detectar cascos:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/jb/8l/qjjb8lebwt3t-6xttueihk2gaqw.jpeg" alt="imagen"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Etapa uno: detecci√≥n humana</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La calidad de la definici√≥n de objetos peque√±os (cascos / anteojos / guantes) en marcos grandes es regular. Es mucho m√°s f√°cil para una computadora, como una persona, entender primero d√≥nde est√°n las personas, y solo entonces descubrir qu√© llevan puesta. Entonces, todo comienza con la identificaci√≥n de las personas en el marco. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado de los experimentos, descubrimos que la red neuronal Faster R-CNN con Inception v2 como extracci√≥n de caracter√≠sticas es muy adecuada para detectar personas. TensorFlow ya tiene </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">redes neuronales pre-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> entrenadas </font><font style="vertical-align: inherit;">para detectar objetos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para nosotros, Faster R-CNN Inception v2 (entrenado en el conjunto de datos COCO) es el m√©todo b√°sico que intentamos primero al resolver tales problemas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inicialmente, detectamos personas en el marco (y luego en las personas encontradas encontramos PPE):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/xp/gy/ukxpgyllgs-olfg9xgbpmzkuwly.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tenga en cuenta que hemos aumentado el cuadro delimitador "con una persona" a lo largo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">del eje y</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/8x/dp/ad8xdpfnx8f1fke9afg9u5q-9xs.jpeg" alt="imagen"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En esta fotograf√≠a, el trabajador recibi√≥ un disparo con buena luz y contra un fondo contrastante (con im√°genes encontradas en Internet, esto sucede todo el tiempo). </font><font style="vertical-align: inherit;">Por lo tanto, el cuadro delimitador con la persona estaba bien construido. </font><font style="vertical-align: inherit;">Sin embargo, en nuestra pr√°ctica hay casos frecuentes (especialmente en condiciones de visibilidad insuficiente) cuando el modelo de detecci√≥n corta un casco en una persona, despu√©s de lo cual es in√∫til buscarlo en una imagen recortada. </font><font style="vertical-align: inherit;">En este sentido, a lo largo del eje y, aumentamos el cuadro delimitador predicho en un 15% antes de pasar a la segunda etapa.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al detectar personas, nos encontramos con peque√±os problemas desagradables. En primer lugar, cuando dos personas caminan o se paran una detr√°s de otra, a menudo comienzan a ser detectadas como una sola persona. En segundo lugar, sucede que un objeto est√°tico ingresa al campo de visi√≥n de la c√°mara, en el cual el modelo puede reconocer a una persona, como un hidrante. Estos problemas pueden resolverse de varias maneras. Por ejemplo, c√≥mo lo hicimos: reconciliarlos y aceptarlos, ya que, en general, el modelo es adecuado para nosotros en t√©rminos de productividad y calidad. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un problema m√°s fundamental es que las instalaciones industriales en las que hay una "zona de peligro" a menudo son enormes y, en consecuencia, las personas en los marcos son muy peque√±as. Nuestro m√©todo b√°sico basado en Faster R-CNN Inception v2 mostr√≥ malos resultados en tales casos, y al final lo intentamos</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R-CNN m√°s r√°pido Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Los resultados fueron impresionantes, las personas fueron bien reconocidas incluso en la distancia, pero la velocidad fue mucho menor que el modelo base. </font><font style="vertical-align: inherit;">Con suficientes recursos y la necesidad de una alta precisi√≥n, puede usar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster R-CNN Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Segunda etapa: determinaci√≥n de infractores maliciosos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dependiendo de la tarea, a menudo se utilizan los siguientes:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelo de clasificaci√≥n de imagen: inicio v3</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelo de detecci√≥n de objetos: inicio m√°s r√°pido de R-CNN v2</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Clasificaci√≥n de ropa de trabajo y cascos.</font></font></h3> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Probamos diferentes arquitecturas de redes neuronales para clasificar im√°genes, y finalmente nos decidimos por Inception v3, decidiendo aprovechar el hecho de que est√° dise√±ado para trabajar con tama√±os de imagen variables. Ya ten√≠amos muchas fotos recortadas con personas, y no fue dif√≠cil calcular los valores medios para la altura y el ancho. Entonces llegamos a la conclusi√≥n de que para la capacitaci√≥n de clasificadores comenzaron a llevar im√°genes a un tama√±o de 150x400.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para capacitar a la red para que reconozca el PPE, en primer lugar, es necesario recopilar un conjunto de datos a partir de ejemplos etiquetados. </font><font style="vertical-align: inherit;">En este proceso, hay sutilezas, cuya realizaci√≥n viene con la experiencia. </font><font style="vertical-align: inherit;">Por ejemplo, es mejor eliminar del conjunto de datos a las personas que est√°n cortadas por encima de las caderas. </font><font style="vertical-align: inherit;">Esto acercar√° el conjunto de datos a las condiciones reales, ya que la mayor√≠a de las veces se ve a la gente a plena altura en video de c√°maras de vigilancia. </font><font style="vertical-align: inherit;">Los casos de superposici√≥n, por supuesto, tambi√©n ocurren, pero las siluetas completas para la muestra objetivo son mucho m√°s caracter√≠sticas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ejemplos de nuestro conjunto de datos de ropa de trabajo:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k8/22/sh/k822shy7m4ddtteqqjp1mfs09b8.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No hemos inventado nada espec√≠fico como m√©trica; utilizamos memoria y precisi√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelo para clasificar la presencia / ausencia de ropa de trabajo: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultados en una muestra de validaci√≥n</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/lw/ql/hu/lwqlhu_7-efmfxzrxug-d64pafq.jpeg" alt="imagen"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Detecci√≥n de EPP</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El modelo de clasificaci√≥n funciona m√°s r√°pido que el modelo para detectar objetos, pero debido al hecho de que las gafas y guantes de seguridad son peque√±os en la imagen, es dif√≠cil crear un buen clasificador para dicho PPE. </font><font style="vertical-align: inherit;">Por lo tanto, capacitamos a la red neuronal Faster R-CNN en un conjunto de datos con seis clases:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">anteojos / no anteojos</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">guantes / not_gloves</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">casco / no_casco</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/pw/iy/i_/pwiyi_nep5v7k8wlrz6yxvz8ug4.jpeg" alt="imagen"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recopilaci√≥n de datos y marcado</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los principales problemas estaban relacionados con el conjunto de datos de cascos. Fue una forma fascinante: pasamos por personas calvas, personas con cascos en sus manos e incluso por personas calvas con cascos en sus manos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como al comienzo del viaje no ten√≠amos muchos cuadros de condiciones reales, recopilamos el conjunto de datos lo mejor que pudimos: filmarnos, tomar im√°genes de Internet o de sitios de construcci√≥n. Un poco m√°s tarde, comenzamos a recibir muchos videos de varias empresas, por lo que comenzamos a enriquecer el conjunto de datos solo con marcos de condiciones reales. En alg√∫n momento, el n√∫mero de im√°genes etiquetadas excedi√≥ los 5k, y la calidad de agregar nuevos ejemplos dej√≥ de mejorar, en este sentido, revisamos el enfoque del marcado.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Describiremos las etapas para mejorar el conjunto de datos del casco utilizando el ejemplo de im√°genes de Internet, por lo que el √°ngulo y la calidad no coinciden con lo que ten√≠amos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s de la imagen de arriba, recortada por encima de las caderas, eliminamos las im√°genes en las que los cascos se recortan m√°s de la mitad para evitar confusiones con las gorras.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/zh/eu/dlzheusrhwz0grtyrxdxalkkupq.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tambi√©n nos enfrentamos al hecho de que si una persona tiene un casco en sus manos, a menudo la modelo no vio ninguna violaci√≥n: ¬øhay un casco? Ahi esta. Por lo tanto, eliminamos del conjunto de datos de entrenamiento todos los marcos en los que una persona sostiene un casco con la mano, incluso si el casco est√° sobre su cabeza en ese momento. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En general, tratamos de eliminar im√°genes con un fondo iluminado o en habitaciones oscuras, y luego minimizamos la cantidad de fotos tomadas por nosotros, dejando principalmente im√°genes de la producci√≥n. Como resultado, redujimos el conjunto de datos a la mitad. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s, enriquecimos el conjunto de datos con personas calvas, de lo contrario siempre estar√°n en cascos, incluso si esto no es as√≠, y con rubias con cuadrados, para los cuales, con un cierto √°ngulo, el detector tambi√©n determina el casco.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de eliminar im√°genes inadecuadas, pasamos directamente al marcado (para detectar objetos). Result√≥ no ser tan simple. Resulta que la calidad del detector final depende en gran medida del √°rea exacta de la imagen marcada como "casco" o "guantes". Inicialmente, asignamos cascos y gafas sin agarrar caras y guantes con manos agarradoras. Sin embargo, con la experiencia, mejoramos gradualmente nuestro enfoque al observar los errores del primer y segundo tipo, donde las personas sostienen los cascos en sus manos, y algo redondo en algo largo resulta ser un "guante". Ahora, al marcar cascos y anteojos, tratamos de agarrar la cara hasta la punta de la nariz, y al marcar guantes, por el contrario, nos limitamos a un cepillo.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/us/re/kausredcadkqks_cn012broh2qq.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado de nuestras manipulaciones en el conjunto de datos, obtuvimos los siguientes resultados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelo para detectar la presencia / ausencia de EPP utilizando cascos como ejemplo: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultados de una muestra de validaci√≥n antes del inicio del "trabajo global" en el conjunto de datos</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/oo/rx/k-/oorxk-v05lijjyljtrp5lvtbsq4.jpeg" alt="imagen"></div><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados finales en la muestra de validaci√≥n</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/y1/nn/0u/y1nn0uy66v5qmwji-zk2rwotnle.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La integridad del reconocimiento de los cascos disminuy√≥ ligeramente, pero al mismo tiempo, las m√©tricas para detectar violaciones mejoraron, y esto es lo que quer√≠amos lograr. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelo para clasificar la presencia / ausencia de cascos: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultados en una muestra de validaci√≥n antes del inicio del "trabajo global" en el conjunto de datos</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wi/eu/fp/wieufpwnxltfvgf1kvkvisr3fk4.jpeg" alt="imagen"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resultados finales en la muestra de validaci√≥n</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ct/d1/etctd1ymh_9jmjvc3lgaz_mw47o.jpeg" alt="imagen"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cabe se√±alar que no tenemos una divisi√≥n en gafas y anteojos para la visi√≥n, van bajo la misma etiqueta "anteojos", y los guantes de tonos claros se pueden percibir como un cepillo desnudo. </font><font style="vertical-align: inherit;">Intentamos maximizar la gama de colores de los cascos y la ropa de trabajo en nuestros conjuntos de datos, pero para mayor confiabilidad agregamos la t√©cnica m√°s simple y confiable: si es necesario, para detectar guantes, les decimos a los clientes que los colores brillantes ayudan a aumentar la precisi√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por el momento, tenemos modelos universales que utilizamos para la presentaci√≥n inicial al cliente. </font><font style="vertical-align: inherit;">Sin embargo, debe entenderse que es imposible crear un modelo universal para todos, es necesario adaptarse a cada cliente, identificar y tener en cuenta nuevos matices, enriquecer conjuntos de datos o crearlos de nuevo para cumplir requisitos espec√≠ficos.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kl/-l/9t/kl-l9tfsjdr528i4xgl5flmtqjk.jpeg" alt="imagen"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prima</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo general, los clientes desean procesar tantas c√°maras como sea posible, utilizando la menor cantidad de recursos posible. </font><font style="vertical-align: inherit;">Butch, por supuesto, es algo bueno, pero no se proh√≠ben trucos adicionales para optimizar el proceso. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por ejemplo, mis colegas y yo del centro de clientes de IBM en Mosc√∫ ten√≠amos la hip√≥tesis de que reunir a varias personas para detectar m√°s cascos aumentar√≠a la cantidad de c√°maras por servidor con una p√©rdida de precisi√≥n sin principios. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como base, decidimos tomar el tama√±o de 1000x600 para el lienzo en el que las personas ser√°n "aplicadas". </font><font style="vertical-align: inherit;">Inicialmente se consideraron dos opciones de dise√±o:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ancho y alto fijos (200x600), con este enfoque, hay 5 personas en el marco.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ancho y alto fijos (125x600), 8 personas.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta decisi√≥n se debi√≥ al hecho de que con datos fijos, sabemos exactamente el n√∫mero de personas en la foto, lo que nos da un pron√≥stico de la carga. </font><font style="vertical-align: inherit;">Sin embargo, durante el desarrollo, consideramos esa opci√≥n:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Altura fija y ancho proporcional (*** x600), diferente n√∫mero de personas.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se asumi√≥ que al aumentar el tama√±o y mantener las proporciones, los resultados ser√°n mejores en comparaci√≥n con otras opciones de dise√±o. </font><font style="vertical-align: inherit;">El n√∫mero de personas vari√≥ de 3 a 5 (+/‚Äì). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, obtuvimos que la opci√≥n con un ancho y una altura fijos (200x600) es la mejor entre las consideradas. </font><font style="vertical-align: inherit;">Por supuesto, este m√©todo no es adecuado para detectar gafas y guantes, porque los objetos son peque√±os, pero para detectar cascos / falta de cascos, este m√©todo mostr√≥ buenos resultados. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por ejemplo, en una muestra de validaci√≥n:</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/wg/zy/arwgzypgxzuk6ykdrj57p851-co.jpeg" alt="imagen"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lw/y5/iilwy5ihzrc57ezgdnjp3gs646s.jpeg" alt="imagen"></div><br>
<i> :   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">tvoronova</a>),  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">elviraa</a>)</i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es499238/index.html">Soldar en casa: grabaci√≥n de flujo</a></li>
<li><a href="../es499240/index.html">A trav√©s de espinas a las estrellas, o an√°lisis de datos en los asuntos del cielo</a></li>
<li><a href="../es499242/index.html">Los investigadores transmitieron datos desde una PC de escritorio a trav√©s de vibraciones a trav√©s de una mesa</a></li>
<li><a href="../es499244/index.html">Organizaciones sinerg√©ticas. Parte II</a></li>
<li><a href="../es499246/index.html">Investigaci√≥n de la funci√≥n log√≠stica como ley de desarrollo industrial.</a></li>
<li><a href="../es499252/index.html">Crear un juego de carreras pseudo-tridimensional</a></li>
<li><a href="../es499254/index.html">El miembro del comit√© del programa PyConRu 2020 responde preguntas sobre Python: una apariencia actualizada y un poco de an√°lisis</a></li>
<li><a href="../es499262/index.html">Hackathon final en l√≠nea para SMZhack aut√≥nomo: proyectos que afectar√°n a la gente</a></li>
<li><a href="../es499268/index.html">Conciencia espacial: ¬øqu√© pueden hacer las gafas Hololens?</a></li>
<li><a href="../es499272/index.html">Componentes de soldadura 0201. Nervioso, al√©jese de las pantallas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
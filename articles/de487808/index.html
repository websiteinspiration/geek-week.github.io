<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí≥ üíó üéÖ Wiederkehrende neuronale Netze (RNN) mit Keras üôÜüèº üí¨ üòê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√úbersetzung des Leitfadens f√ºr rekursive neuronale Netze von Tensorflow.org. Das Material beschreibt sowohl die integrierten Funktionen von Keras / Te...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Wiederkehrende neuronale Netze (RNN) mit Keras</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487808/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√úbersetzung des Leitfadens f√ºr rekursive neuronale Netze von Tensorflow.org. </font><font style="vertical-align: inherit;">Das Material beschreibt sowohl die integrierten Funktionen von Keras / Tensorflow 2.0 f√ºr eine schnelle Vernetzung als auch die M√∂glichkeit, Ebenen und Zellen anzupassen. </font><font style="vertical-align: inherit;">F√§lle und Einschr√§nkungen der Verwendung des CuDNN-Kerns werden ebenfalls ber√ºcksichtigt, wodurch der Lernprozess des neuronalen Netzwerks beschleunigt werden kann.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/xt/_q/nj/xt_qnjgfjengqoqd4gizkq4j_wk.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Rekursive neuronale Netze (RNNs) sind eine Klasse von neuronalen Netzen, die sich gut zur Modellierung serieller Daten wie Zeitreihen oder nat√ºrlicher Sprache eignen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn schematisch, verwendet die RNN-Schicht eine Schleife </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, um √ºber eine zeitlich geordnete Sequenz zu iterieren, w√§hrend sie in einem internen Zustand codierte Informationen √ºber die Schritte speichert, die er bereits gesehen hat. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras RNN API ist mit einem Fokus entwickelt , um </font><font style="vertical-align: inherit;">auf: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Einfache Bedienung</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Einbau-Schichten </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k√∂nnen Sie schnell ein rekursive Modell bauen , </font><font style="vertical-align: inherit;">ohne komplexe Konfigurationseinstellungen vornehmen zu </font><font style="vertical-align: inherit;">m√ºssen. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Einfache Anpassung</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Sie k√∂nnen auch Ihre eigene Schicht von RNN-Zellen (innerer Teil der Schleife) definieren</font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) mit benutzerdefiniertem Verhalten und verwenden Sie es mit einer gemeinsamen Ebene von `tf.keras.layers.RNN` (die` for`-Schleife selbst). </font><font style="vertical-align: inherit;">Auf diese Weise k√∂nnen Sie schnell und flexibel verschiedene Forschungsideen mit einem Minimum an Code prototypisieren.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation</font></font></h2><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> collections
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein einfaches Modell bauen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras verf√ºgt √ºber drei integrierte RNN-Schichten:</font></font><br>
<br>
<ol>
<li><code>tf.keras.layers.SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">eine vollst√§ndig verbundene RNN, in der die Ausgabe des vorherigen Zeitschritts an den n√§chsten Schritt √ºbergeben werden soll.</font></font></li>
<li><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, zuerst vorgeschlagen im Artikel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Studieren von Phrasen mit RNN-Codec f√ºr statistische maschinelle √úbersetzung</font></font></a></li>
<li><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, zuerst vorgeschlagen im Artikel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Langzeit-Kurzzeitged√§chtnis</font></font></a></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anfang 2015 f√ºhrte Keras die ersten wiederverwendbaren Open-Source-Python-LSTM- und GRU-Implementierungen in Python ein. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Folgende ist ein Beispiel eines </font></font><code>Sequential</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modells, das Folgen von ganzen Zahlen verarbeitet, indem jede ganze Zahl in einem 64-dimensionalen Vektor verschachtelt wird und dann Folgen von Vektoren unter Verwendung einer Schicht verarbeitet werden </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()
<span class="hljs-comment">#   Embedding      1000, </span>
<span class="hljs-comment">#     64.</span>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#   LSTM  128  .</span>
model.add(layers.LSTM(<span class="hljs-number">128</span>))<font></font>
<font></font>
<span class="hljs-comment">#   Dense  10    softmax.</span>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ausg√§nge und Status</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Standardm√§√üig enth√§lt die Ausgabe der RNN-Schicht einen Vektor pro Element. Dieser Vektor ist die Ausgabe der letzten RNN-Zelle, die Informationen √ºber die gesamte Eingabesequenz enth√§lt. Die Dimension dieser Ausgabe </font></font><code>(batch_size, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, wobei </font><font style="vertical-align: inherit;">das an den Layer-Konstruktor √ºbergebene </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Argument entspricht </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die RNN-Schicht kann auch die gesamte Ausgabesequenz f√ºr jedes Element zur√ºckgeben (ein Vektor f√ºr jeden Schritt), wenn Sie dies angeben </font></font><code>return_sequences=True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Die Dimension dieser Ausgabe ist </font></font><code>(batch_size, timesteps, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#  GRU  3D   (batch_size, timesteps, 256)</span>
model.add(layers.GRU(<span class="hljs-number">256</span>, return_sequences=<span class="hljs-literal">True</span>))<font></font>
<font></font>
<span class="hljs-comment">#  SimpleRNN  2D   (batch_size, 128)</span>
model.add(layers.SimpleRNN(<span class="hljs-number">128</span>))<font></font>
<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dar√ºber hinaus kann die RNN-Schicht ihre endg√ºltigen internen Zust√§nde zur√ºckgeben. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die zur√ºckgegebenen Zust√§nde k√∂nnen sp√§ter verwendet werden, um die Ausf√ºhrung des RNN fortzusetzen oder ein </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">anderes RNN zu initialisieren</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Diese Einstellung wird normalerweise im Codierer-Decodierer-Modell von Sequenz zu Sequenz verwendet, wobei der Endzustand des Codierers f√ºr den Anfangszustand des Decodierers verwendet wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Damit der RNN-Layer seinen internen Status zur√ºckgibt, setzen Sie den Parameter </font><font style="vertical-align: inherit;">beim Erstellen des Layers </font></font><code>return_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auf value </font></font><code>True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Beachten Sie, dass es </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 Zustandstensoren und </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nur einen gibt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um den Anfangszustand einer Ebene anzupassen, rufen Sie die Ebene einfach mit einem zus√§tzlichen Argument auf </font></font><code>initial_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beachten Sie, dass die Bema√üung mit der Bema√üung des Ebenenelements √ºbereinstimmen muss, wie im folgenden Beispiel.</font></font><br>
<br>
<pre><code class="python hljs">encoder_vocab = <span class="hljs-number">1000</span>
decoder_vocab = <span class="hljs-number">2000</span><font></font>
<font></font>
encoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=<span class="hljs-number">64</span>)(encoder_input)<font></font>
<font></font>
<span class="hljs-comment">#       </span><font></font>
output, state_h, state_c = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, return_state=<span class="hljs-literal">True</span>, name=<span class="hljs-string">'encoder'</span>)(encoder_embedded)<font></font>
encoder_state = [state_h, state_c]<font></font>
<font></font>
decoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=<span class="hljs-number">64</span>)(decoder_input)<font></font>
<font></font>
<span class="hljs-comment">#  2     LSTM    </span><font></font>
decoder_output = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, name=<span class="hljs-string">'decoder'</span>)(decoder_embedded, initial_state=encoder_state)<font></font>
output = layers.Dense(<span class="hljs-number">10</span>)(decoder_output)<font></font>
<font></font>
model = tf.keras.Model([encoder_input, decoder_input], output)<font></font>
model.summary()<font></font>
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN-Schichten und RNN-Zellen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die RNN-API bietet zus√§tzlich zu den integrierten RNN-Schichten auch APIs auf Zellebene. </font><font style="vertical-align: inherit;">Im Gegensatz zu RNN-Schichten, die ganze Pakete von Eingabesequenzen verarbeiten, verarbeitet eine RNN-Zelle nur einen Zeitschritt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Zelle befindet sich innerhalb des Zyklus der </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN-Schicht. </font><font style="vertical-align: inherit;">Wenn Sie eine Zelle mit einer Schicht </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">umwickeln, erhalten Sie eine Schicht, die Sequenzpakete verarbeiten kann, z. </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mathematisch </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ergibt es das gleiche Ergebnis wie </font></font><code>LSTM(10)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Tats√§chlich bestand die Implementierung dieser Schicht in TF v1.x nur darin, die entsprechende RNN-Zelle zu erstellen und sie in die RNN-Schicht einzubinden. </font><font style="vertical-align: inherit;">Allerdings ist die Verwendung von eingebetteten Schichten </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">erm√∂glicht die Verwendung von CuDNN , </font><font style="vertical-align: inherit;">die Ihnen eine </font><font style="vertical-align: inherit;">bessere Leistung geben kann.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt drei eingebaute RNN-Zellen, von denen jede ihrer eigenen RNN-Schicht entspricht.</font></font><br>
<br>
<ul>
<li><code>tf.keras.layers.SimpleRNNCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passt zur Ebene </font></font><code>SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.GRUCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passt zur Ebene </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.LSTMCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passt zur Ebene </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Abstraktion einer Zelle zusammen mit einer gemeinsamen Klasse </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">macht es sehr einfach, benutzerdefinierte RNN-Architekturen f√ºr Ihre Forschung zu implementieren.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stapel√ºbergreifender Speicherstatus</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei der Verarbeitung langer Sequenzen (m√∂glicherweise endlos) m√∂chten Sie m√∂glicherweise das </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">stapel√ºbergreifende Statefulness-</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Muster verwenden </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Normalerweise wird der interne Zustand der RNN-Schicht mit jedem neuen Datenpaket zur√ºckgesetzt (d. H. Jedes Beispiel, das die Schicht sieht, wird als unabh√§ngig von der Vergangenheit angenommen). Die Ebene beh√§lt den Status nur f√ºr die Dauer der Verarbeitung dieses Elements bei. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie jedoch sehr lange Sequenzen haben, ist es hilfreich, diese in k√ºrzere zu zerlegen und nacheinander auf die RNN-Schicht zu √ºbertragen, ohne den Schichtstatus zur√ºckzusetzen. Somit kann eine Schicht Informationen √ºber die gesamte Sequenz speichern, obwohl jeweils nur eine Teilsequenz angezeigt wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie k√∂nnen dies tun, indem Sie im Konstruktor `stateful = True` setzen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie die Sequenz `s = [t0, t1, ... t1546, t1547]` haben, k√∂nnen Sie sie beispielsweise aufteilen in:</font></font><br>
<br>
<pre><code class="python hljs">s1 = [t0, t1, ... t100]<font></font>
s2 = [t101, ... t201]<font></font>
...<font></font>
s16 = [t1501, ... t1547]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann k√∂nnen Sie es verarbeiten mit:</font></font><br>
<br>
<pre><code class="python hljs">lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> sub_sequences:<font></font>
  output = lstm_layer(s)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie den Zustand reinigen m√∂chten, verwenden Sie </font></font><code>layer.reset_states()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<blockquote><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hinweis:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In diesem Fall wird davon ausgegangen, dass das Beispiel </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in diesem Paket eine Fortsetzung des Beispiels des </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vorherigen Pakets ist. </font><font style="vertical-align: inherit;">Dies bedeutet, dass alle Pakete die gleiche Anzahl von Elementen enthalten (Paketgr√∂√üe). </font><font style="vertical-align: inherit;">Wenn das Paket beispielsweise enth√§lt </font></font><code>[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, sollte das n√§chste Paket enthalten </font></font><code>[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein vollst√§ndiges Beispiel:</font></font><br>
<br>
<pre><code class="python hljs">paragraph1 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph2 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph3 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
<font></font>
lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)<font></font>
output = lstm_layer(paragraph1)<font></font>
output = lstm_layer(paragraph2)<font></font>
output = lstm_layer(paragraph3)<font></font>
<font></font>
<span class="hljs-comment"># reset_states()      initial_state.</span>
<span class="hljs-comment">#  initial_state   ,      .</span>
lstm_layer.reset_states()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bidirektionale RNN</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei anderen Sequenzen als Zeitreihen (z. B. Texten) funktioniert das RNN-Modell h√§ufig besser, wenn es die Sequenz nicht nur von Anfang bis Ende verarbeitet, sondern auch umgekehrt. Um beispielsweise das n√§chste Wort in einem Satz vorherzusagen, ist es oft n√ºtzlich, den Kontext um das Wort herum zu kennen und nicht nur die W√∂rter davor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras bietet eine einfache API zum Erstellen solcher bidirektionaler RNNs: einen Wrapper </font></font><code>tf.keras.layers.Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">64</span>, return_sequences=<span class="hljs-literal">True</span>), <font></font>
                               input_shape=(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)))<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">32</span>)))<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unter der Haube wird die </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√ºbertragene RNN-Schicht </font></font><code>go_backwards</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kopiert </font><font style="vertical-align: inherit;">und das Feld der </font><font style="vertical-align: inherit;">neu kopierten Schicht wird </font><font style="vertical-align: inherit;">umgedreht </font><font style="vertical-align: inherit;">, und somit werden die Eingabedaten in umgekehrter Reihenfolge verarbeitet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Ausgabe von ` </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN ist standardm√§√üig die Summe der Ausgabe der Vorw√§rtsschicht und der Ausgabe der R√ºckw√§rtsschicht. </font><font style="vertical-align: inherit;">Wenn Sie ein anderes Zusammenf√ºhrungsverhalten ben√∂tigen, z. </font><font style="vertical-align: inherit;">Verkettung, √§ndern Sie den Parameter `merge_mode` im Wrapper-Konstruktor` Bidirectional`.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Leistungsoptimierung und CuDNN-Kern in TensorFlow 2.0</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In TensorFlow 2.0 k√∂nnen die integrierten LSTM- und GRU-Schichten standardm√§√üig CuDNN-Kerne verwenden, wenn ein Grafikprozessor verf√ºgbar ist. </font><font style="vertical-align: inherit;">Mit dieser √Ñnderung sind die vorherigen Ebenen </font></font><code>keras.layers.CuDNNLSTM/CuDNNGRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">veraltet, und Sie k√∂nnen Ihr Modell erstellen, ohne sich Gedanken √ºber die Ausr√ºstung machen zu m√ºssen, auf der es funktionieren wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da der CuDNN-Kernel mit einigen Annahmen erstellt wird, bedeutet dies, dass der Layer </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">den CuDNN-Kernel-Layer nicht verwenden kann, wenn Sie die Standardeinstellungen der integrierten LSTM- oder GRU-Layer √§ndern</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Z.B.</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ñndern einer Funktion </font></font><code>activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von </font></font><code>tanh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zu etwas anderem.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ñndern einer Funktion </font></font><code>recurrent_activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von </font></font><code>sigmoid</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zu etwas anderem.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verwendung </font></font><code>recurrent_dropout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&gt; 0.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setzen Sie es </font></font><code>unroll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auf True, wodurch LSTM / GRU das Interne </font></font><code>tf.while_loop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in eine bereitgestellte Schleife </font><font style="vertical-align: inherit;">zerlegt </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf </font></font><code>use_bias</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">False setzen.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verwenden von Masken, wenn die Eingabedaten nicht richtig ausgerichtet sind (wenn die Maske mit den genau ausgerichteten Daten √ºbereinstimmt, kann CuDNN weiterhin verwendet werden. Dies ist der h√§ufigste Fall).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verwenden Sie nach M√∂glichkeit CuDNN-Kernel</font></font></h3><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">64</span>
<span class="hljs-comment">#    MNIST    (batch_size, 28, 28).</span>
<span class="hljs-comment">#     (28, 28) (   ).</span>
input_dim = <span class="hljs-number">28</span><font></font>
<font></font>
units = <span class="hljs-number">64</span>
output_size = <span class="hljs-number">10</span>  <span class="hljs-comment">#   0  9</span><font></font>
<font></font>
<span class="hljs-comment">#  RNN </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_model</span>(<span class="hljs-params">allow_cudnn_kernel=True</span>):</span>
  <span class="hljs-comment"># CuDNN     ,     .</span>
  <span class="hljs-comment">#   `LSTM(units)`    CuDNN,</span>
  <span class="hljs-comment">#   RNN(LSTMCell(units))   non-CuDNN .</span>
  <span class="hljs-keyword">if</span> allow_cudnn_kernel:
    <span class="hljs-comment">#  LSTM      CuDNN.</span>
    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(<span class="hljs-literal">None</span>, input_dim))
  <span class="hljs-keyword">else</span>:
    <span class="hljs-comment">#  LSTMCell  RNN    CuDNN.</span><font></font>
    lstm_layer = tf.keras.layers.RNN(<font></font>
        tf.keras.layers.LSTMCell(units),<font></font>
        input_shape=(<span class="hljs-literal">None</span>, input_dim))<font></font>
  model = tf.keras.models.Sequential([<font></font>
      lstm_layer,<font></font>
      tf.keras.layers.BatchNormalization(),<font></font>
      tf.keras.layers.Dense(output_size)]<font></font>
  )<font></font>
  <span class="hljs-keyword">return</span> model
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laden des MNIST-Datasets</font></font></h3><br>
<pre><code class="python hljs">mnist = tf.keras.datasets.mnist<font></font>
<font></font>
(x_train, y_train), (x_test, y_test) = mnist.load_data()<font></font>
x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span>
sample, sample_label = x_train[<span class="hljs-number">0</span>], y_train[<span class="hljs-number">0</span>]</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie eine Instanz des Modells und kompilieren Sie es</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir haben </font></font><code>sparse_categorical_crossentropy</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">als Funktion der Verluste gew√§hlt. </font><font style="vertical-align: inherit;">Die Ausgabe des Modells hat eine Dimension </font></font><code>[batch_size, 10]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Die Antwort des Modells ist ein ganzzahliger Vektor, jede der Zahlen liegt im Bereich von 0 bis 9.</font></font><br>
<br>
<pre><code class="python hljs">model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
<font></font>
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
              optimizer=<span class="hljs-string">'sgd'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<pre><code class="python hljs">model.fit(x_train, y_train,<font></font>
          validation_data=(x_test, y_test),<font></font>
          batch_size=batch_size,<font></font>
          epochs=<span class="hljs-number">5</span>)</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie ein neues Modell ohne CuDNN-Kern</font></font></h3><br>
<pre><code class="python hljs">slow_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">False</span>)<font></font>
slow_model.set_weights(model.get_weights())<font></font>
slow_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
                   optimizer=<span class="hljs-string">'sgd'</span>, <font></font>
                   metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
slow_model.fit(x_train, y_train, <font></font>
               validation_data=(x_test, y_test), <font></font>
               batch_size=batch_size,<font></font>
               epochs=<span class="hljs-number">1</span>)  <span class="hljs-comment">#         .</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Sie sehen k√∂nnen, ist das mit CuDNN erstellte Modell f√ºr das Training viel schneller als das Modell mit dem √ºblichen TensorFlow-Kern. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das gleiche Modell mit CuDNN-Unterst√ºtzung kann f√ºr die Ausgabe in einer Einzelprozessorumgebung verwendet werden. </font><font style="vertical-align: inherit;">Die Anmerkung gibt </font></font><code>tf.device</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lediglich das verwendete Ger√§t an. </font><font style="vertical-align: inherit;">Das Modell wird standardm√§√üig auf der CPU ausgef√ºhrt, wenn die GPU nicht verf√ºgbar ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie m√ºssen sich nur keine Gedanken √ºber die Hardware machen, an der Sie arbeiten. </font><font style="vertical-align: inherit;">Ist das nicht cool?</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">'CPU:0'</span>):<font></font>
  cpu_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
  cpu_model.set_weights(model.get_weights())<font></font>
  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, <span class="hljs-number">0</span>)), axis=<span class="hljs-number">1</span>)<font></font>
  print(<span class="hljs-string">'Predicted result is: %s, target result is: %s'</span> % (result.numpy(), sample_label))<font></font>
  plt.imshow(sample, cmap=plt.get_cmap(<span class="hljs-string">'gray'</span>))
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN mit Listen- / W√∂rterbucheingabe oder verschachtelter Eingabe</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit verschachtelten Strukturen k√∂nnen Sie mehr Informationen in einem Zeitschritt einf√ºgen. </font><font style="vertical-align: inherit;">Beispielsweise kann ein Videorahmen gleichzeitig Audio- und Videoeingang enthalten. </font><font style="vertical-align: inherit;">Die Dimension der Daten kann in diesem Fall sein:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einem anderen Beispiel k√∂nnen handgeschriebene Daten sowohl x- als auch y-Koordinaten f√ºr die aktuelle Stiftposition sowie Druckinformationen enthalten. </font><font style="vertical-align: inherit;">Die Daten k√∂nnen also wie folgt dargestellt werden:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der folgende Code erstellt ein Beispiel f√ºr eine benutzerdefinierte RNN-Zelle, die mit einer solchen strukturierten Eingabe arbeitet.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Definieren Sie eine Benutzerzelle, die verschachtelte Ein- / Ausgabe unterst√ºtzt</font></font></h3><br>
<pre><code class="python hljs">NestedInput = collections.namedtuple(<span class="hljs-string">'NestedInput'</span>, [<span class="hljs-string">'feature1'</span>, <span class="hljs-string">'feature2'</span>])<font></font>
NestedState = collections.namedtuple(<span class="hljs-string">'NestedState'</span>, [<span class="hljs-string">'state1'</span>, <span class="hljs-string">'state2'</span>])<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NestedCell</span>(<span class="hljs-params">tf.keras.layers.Layer</span>):</span><font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, unit_1, unit_2, unit_3, **kwargs</span>):</span><font></font>
    self.unit_1 = unit_1<font></font>
    self.unit_2 = unit_2<font></font>
    self.unit_3 = unit_3<font></font>
    self.state_size = NestedState(state1=unit_1, <font></font>
                                  state2=tf.TensorShape([unit_2, unit_3]))<font></font>
    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))<font></font>
    super(NestedCell, self).__init__(**kwargs)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build</span>(<span class="hljs-params">self, input_shapes</span>):</span>
    <span class="hljs-comment"># #  input_shape  2 , [(batch, i1), (batch, i2, i3)]</span>
    input_1 = input_shapes.feature1[<span class="hljs-number">1</span>]<font></font>
    input_2, input_3 = input_shapes.feature2[<span class="hljs-number">1</span>:]<font></font>
<font></font>
    self.kernel_1 = self.add_weight(<font></font>
        shape=(input_1, self.unit_1), initializer=<span class="hljs-string">'uniform'</span>, name=<span class="hljs-string">'kernel_1'</span>)<font></font>
    self.kernel_2_3 = self.add_weight(<font></font>
        shape=(input_2, input_3, self.unit_2, self.unit_3),<font></font>
        initializer=<span class="hljs-string">'uniform'</span>,<font></font>
        name=<span class="hljs-string">'kernel_2_3'</span>)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span>(<span class="hljs-params">self, inputs, states</span>):</span>
    <span class="hljs-comment">#     [(batch, input_1), (batch, input_2, input_3)]</span>
    <span class="hljs-comment">#     [(batch, unit_1), (batch, unit_2, unit_3)]</span><font></font>
    input_1, input_2 = tf.nest.flatten(inputs)<font></font>
    s1, s2 = states<font></font>
<font></font>
    output_1 = tf.matmul(input_1, self.kernel_1)<font></font>
    output_2_3 = tf.einsum(<span class="hljs-string">'bij,ijkl-&gt;bkl'</span>, input_2, self.kernel_2_3)<font></font>
    state_1 = s1 + output_1<font></font>
    state_2_3 = s2 + output_2_3<font></font>
<font></font>
    output = [output_1, output_2_3]<font></font>
    new_states = NestedState(state1=state_1, state2=state_2_3)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> output, new_states
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie ein RNN-Modell mit verschachtelter Eingabe / Ausgabe</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Erstellen wir ein Keras-Modell, das eine Ebene </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und eine benutzerdefinierte Zelle verwendet, die wir gerade definiert haben.</font></font><br>
<br>
<pre><code class="python hljs">unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trainieren Sie das Modell anhand zuf√§llig generierter Daten</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da wir f√ºr dieses Modell keinen guten Datensatz haben, verwenden wir zur Demonstration zuf√§llige Daten, die von der Numpy-Bibliothek generiert wurden.</font></font><br>
<br>
<pre><code class="python hljs">input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))<font></font>
input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))<font></font>
target_1_data = np.random.random((batch_size * num_batch, unit_1))<font></font>
target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))<font></font>
input_data = [input_1_data, input_2_data]<font></font>
target_data = [target_1_data, target_2_data]<font></font>
<font></font>
model.fit(input_data, target_data, batch_size=batch_size)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei einer Ebene m√ºssen </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie nur die mathematische Logik eines einzelnen Schritts innerhalb der Sequenz bestimmen, und die Ebene </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√ºbernimmt f√ºr Sie die Iteration der Sequenz. </font><font style="vertical-align: inherit;">Dies ist eine unglaublich leistungsstarke Methode, um schnell neue Arten von RNNs (z. B. die LSTM-Variante) zu prototypisieren. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nach der √úberpr√ºfung wird die √úbersetzung auch auf Tensorflow.org angezeigt. </font><font style="vertical-align: inherit;">Wenn Sie an der √úbersetzung der Dokumentation der Website Tensorflow.org ins Russische teilnehmen m√∂chten, wenden Sie sich bitte pers√∂nlich oder in einem Kommentar an. </font><font style="vertical-align: inherit;">Korrekturen und Kommentare sind willkommen.</font></font></i></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de487798/index.html">Wie wir von Oracle JDK und Java Web Start zu AdoptOpenJDK und OpenWebStart migriert sind</a></li>
<li><a href="../de487800/index.html">Warum ist es wichtig, dem Bewerber mitzuteilen, was w√§hrend des Interviews schief gelaufen ist (und wie man es richtig macht)?</a></li>
<li><a href="../de487802/index.html">Unterbrechungsfreie APC Smart UPS und wie man sie kocht</a></li>
<li><a href="../de487804/index.html">Wachstumsteams-Treffen bei der Raiffeisenbank</a></li>
<li><a href="../de487806/index.html">Erstellen einer kleinen Deno-API</a></li>
<li><a href="../de487812/index.html">Testen der polnischen LED-Spektrum-LED E27</a></li>
<li><a href="../de487814/index.html">Geschwindigkeit und Zuverl√§ssigkeit sind h√∂her und der Preis ist niedriger. Neue Kingston KC2000 Solid State Drives</a></li>
<li><a href="../de487822/index.html">AvitoTech On Tour: Android-Treffen in Nischni Nowgorod</a></li>
<li><a href="../de487824/index.html">√úbersicht der LED-Lampen Spectrum Led GU10 aus Europa</a></li>
<li><a href="../de487826/index.html">√úbersicht der LED-Lampen von Poland Spectrum Led E14</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí∂ üåº ‚õëÔ∏è YOLOv4: la red neuronal en tiempo real m√°s precisa en el conjunto de datos COCO de Microsoft üïï üöπ üî§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Darknet YOLOv4 es m√°s r√°pido / m√°s preciso que Google TensorFlow EfficientDet y FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. 
 
 El mismo art√≠cu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>YOLOv4: la red neuronal en tiempo real m√°s precisa en el conjunto de datos COCO de Microsoft</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/503200/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Darknet YOLOv4 es m√°s r√°pido / m√°s preciso que Google TensorFlow EfficientDet y FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El mismo art√≠culo en medio</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medio </font></font></a><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C√≥digo</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet </font></font></a><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Art√≠culo</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/3h/nc/sr/3hncsroz9wt8u3ycqskubgu1xk8.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mostraremos algunos matices de comparaci√≥n y uso de redes neuronales para detectar objetos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nuestro objetivo era desarrollar un algoritmo de detecci√≥n de objetos para usar en productos reales, y no solo hacer avanzar la ciencia. </font><font style="vertical-align: inherit;">La precisi√≥n de la red neuronal YOLOv4 (608x608) es 43.5% AP / 65.7% AP50 Microsoft-COCO-testdev. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">62 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (608x608 lote = 1) en Tesla V100 - usando Darknet-framework </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (416x416 lote = 4) en RTX 2080 Ti - usando TensorRT + tkDNN </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (416x416 lote = 1) en Jetson AGX Xavier - mediante el uso de TensorRT + tkDNN</font></font><br>
<br>
<img src="https://habrastorage.org/webt/p_/ep/cl/p_epcl_aaw_trgeltekatagtqkg.jpeg"> <br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1_SiUOYUoOI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Primero, algunos enlaces √∫tiles.</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Puede leer una descripci√≥n detallada de las funciones utilizadas en YOLOv4 en este art√≠culo: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium.com/@jonathan_hui/yolov4-c9901eaa8e61</font></font></a></li>
<li>  YOLOv4: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://lutzroeder.github.io/netron/%3Furl%3D" rel="nofollow">lutzroeder.github.io/netron/?url=https%3A%2F%2Fraw.githubusercontent.com%2FAlexeyAB%2Fdarknet%2Fmaster%2Fcfg%2Fyolov4.cfg</a></li>
<li>     YOLOv4  GPU   Google-cloud  Jupyter Notebook ‚Äì      ,   - ¬´Open in Playground¬ª,         [ ] ‚Äì    ,  ,  ,    5    : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE</a>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">www.youtube.com/watch?v=mKAEGSxwOAY</a></li>
<li>  Darknet   : <br>
 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 </li>
</ul><br>
<h3>   </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nuestra red neuronal YOLOv4 y nuestro propio marco Darknet DL (C / C ++ / CUDA) son mejores en velocidad FPS y precisi√≥n AP50: 95 y AP50 en los conjuntos de datos Microsoft COCO que los marcos DL y las redes neuronales: Google TensorFlow EfficientDet, FaceBook Detectron RetinaNet / MaskRCNN, PyTorch Yolov3-ASFF y muchos otros ... YOLOv4 logra una precisi√≥n de 43.5% AP / 65.7% AP50 en la prueba de Microsoft COCO a una velocidad de 62 FPS TitanV o 34 FPS RTX 2070. A diferencia de otros detectores modernos, YOLOv4 puede entrenar a cualquiera con quien tenga la tarjeta gr√°fica de juegos nVidia con 8-16 GB de VRAM. Ahora, no solo las grandes empresas pueden entrenar una red neuronal en cientos de GPU / TPU para usar grandes tama√±os de mini lotes para lograr una mayor precisi√≥n, por lo que estamos devolviendo el control de la inteligencia artificial a los usuarios comunes, porque para YOLOv4 no se requiere un gran mini lote,puede limitarse a un tama√±o de 2 a 8.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLOV4 es √≥ptimo para usar en tiempo real, porque la red se encuentra </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en la curva de optimizaci√≥n de Pareto</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> en el gr√°fico AP (precisi√≥n) / FPS (velocidad). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2k/77/as/2k77aszzprngk0qmtistcehkz8c.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gr√°ficos de precisi√≥n (AP) y velocidad (FPS) de muchas redes neuronales para detectar objetos medidos en GPU TitanV / TeslaV100, TitanXP / TeslaP100, TitanX / TeslaM40 para los dos indicadores principales de precisi√≥n AP50: 95 y AP50</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para una comparaci√≥n justa, tomamos datos de art√≠culos y compare solo en la GPU con la misma arquitectura. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La mayor√≠a de las tareas pr√°cticas tienen los requisitos m√≠nimos necesarios para los detectores: estos son la precisi√≥n y velocidad m√≠nimas aceptables. Por lo general, la velocidad m√≠nima permitida de 30 FPS (fotogramas por segundo) y superior para sistemas en tiempo real. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como se puede ver en los gr√°ficos, en sistemas en tiempo real con FPS 30 o m√°s:</font></font><br>
<br>
<ul>
<li> YOLOv4-608   RTX 2070  <b>450$</b> (34 FPS)   <b>43.5% AP / 65.7% AP50</b></li>
<li> EfficientDet-D2   TitanV  <b>2250$</b> (42 FPS)   <b>43.0% AP / 62.3% AP50</b></li>
<li> EfficientDet-D0   RTX 2070  <b>450$</b> (34 FPS)   <b>33.8% AP / 52.2% AP50</b></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aquellos. YOLOv4 requiere </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un equipo 5 veces m√°s barato</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y m√°s preciso que EfficientDet-D2 (Google-TensorFlow). Puede usar EfficientDet-D0 (Google-TensorFlow), entonces el costo del equipo ser√° el mismo, pero la precisi√≥n ser√° 10% AP m√°s baja. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s, algunos sistemas industriales tienen limitaciones en la disipaci√≥n de calor o en el uso de un sistema de enfriamiento pasivo; en este caso, no puede usar TitanV incluso con dinero. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cuando usamos YOLOv4 (416x416) en una GPU RTX 2080 Ti usando TensorRT + tkDNN, alcanzamos una velocidad 2 veces m√°s r√°pida, y cuando usamos batch = 4 es 3x-4x veces m√°s r√°pido, para una comparaci√≥n honesta, no presentamos estos resultados en un art√≠culo sobre arxiv. org:</font></font><br>
<img src="https://habrastorage.org/webt/ci/j7/uq/cij7uqas0ypsjcpsfkhvdxuyxzs.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Red neuronal YOLOv4 (416x416) FP16 (n√∫cleos tensoriales) lote = </font><font style="vertical-align: inherit;">1 alcanza a 32 calculadora FPS nVidia Jetson AGX Xavier usando bibliotecas + tkDNN TensorRT: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
velocidad ligeramente m√°s lenta da una biblioteca OpenCV-dnn compilada con CUDA: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documentos .opencv.org / master / da / d9d / tutorial_dnn_yolo.html</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A veces, la velocidad (FPS) de algunas redes neuronales en los art√≠culos se indica cuando se usa un tama√±o de lote alto o cuando se prueba con un software especializado (TensorRT), que optimiza la red y muestra un mayor valor de FPS. La comparaci√≥n de algunas redes en TRT con otras redes sin TRT no es justa. El uso de un tama√±o de lote alto aumenta el FPS, pero tambi√©n aumenta la latencia (en lugar de disminuirlo) en comparaci√≥n con el lote = 1. Si la red con lote = 1 muestra 40 FPS, y con lote = 32 muestra 60 FPS, el retraso ser√° de 25 ms para lote = 1 y ~ 500 ms para lote = 32, porque solo se procesar√°n ~ 2 paquetes (32 im√°genes cada uno) por segundo, por lo que el uso de lote = 32 no es aceptable en muchos sistemas industriales. Por lo tanto, comparamos los resultados en los gr√°ficos solo con lote = 1 y sin usar TensorRT.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cualquier proceso puede ser controlado por personas o por computadoras. Cuando un sistema inform√°tico act√∫a con un gran retraso debido a la baja velocidad y comete demasiados errores, no se le puede confiar el control completo de las acciones, en este caso la persona controla el proceso, y el sistema inform√°tico solo da pistas (este es un sistema de recomendaci√≥n), la persona trabaja y solo el sistema dice d√≥nde se cometieron los errores. Cuando el sistema funciona r√°pidamente y con alta precisi√≥n, dicho sistema puede controlar el proceso de forma independiente, y una persona solo lo cuida. Por lo tanto, la precisi√≥n y la velocidad del sistema son siempre importantes. Si le parece que 120 FPS para YOLOv4 416x416 es demasiado para su tarea, y es mejor tomar el algoritmo de manera m√°s lenta y precisa, entonces lo m√°s probable es que en tareas reales use algo m√°s d√©bil que el Tesla V100 de 250 vatios,por ejemplo, RTX 2060 / Jetson-Xavier 30-80 Watt, en este caso obtendr√° 30 FPS en YOLOv4 416x416 y otras redes neuronales a 1-15 FPS o no comenzar√° en absoluto.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caracter√≠sticas del entrenamiento de varias redes neuronales.</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debe entrenar EfficientDet con tama√±o mini-lote = 128 en varias GPU Tesla V100 de 32 GB, mientras que YOLOv4 recibi√≥ capacitaci√≥n en una sola GPU Tesla V100 de 32 GB con mini lote = 8 = lote / subdivisiones, y puede entrenarse en un juego regular Tarjeta gr√°fica GPU-VRAM de 8-16GB. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El siguiente matiz es la dificultad de entrenar una red neuronal para detectar sus propios objetos. </font><font style="vertical-align: inherit;">No importa cu√°nto tiempo entrene otras redes en la misma GPU 1080 Ti, no obtendr√° la precisi√≥n indicada en el gr√°fico anterior. </font><font style="vertical-align: inherit;">La mayor√≠a de las redes (EfficientDet, ASFF, ...) necesitan capacitaci√≥n en 4 a 128 GPU (con un tama√±o de mini lote grande usando syncBN) y es necesario entrenar cada vez de nuevo para cada resoluci√≥n de red, sin cumplir ambas condiciones es imposible lograr la precisi√≥n AP o AP50 declarada por ellos.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/p4/sx/p3/p4sxp3ewxd9owskis23n6dyrv58.jpeg"><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Puede ver la dependencia de la precisi√≥n de detecci√≥n de objetos en el tama√±o del minibatch en otros detectores, es decir. </font><font style="vertical-align: inherit;">usando 128 tarjetas de video en lugar de 8 tarjetas de video y la velocidad de aprendizaje es 10 veces m√°s alta y la precisi√≥n final es 1.5 AP m√°s alta - MegDet: un detector de objetos de mini lotes grandes </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1711.07240</font></font></a></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Yolo ASFF: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09516</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Siguiendo [43], presentamos una bolsa de trucos en el proceso de entrenamiento, como el algoritmo de mezcla [12], el programa de tasa de aprendizaje de coseno [26] y la t√©cnica de normalizaci√≥n por lotes sincronizada [30].</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
EfficientDet: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09070</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La normalizaci√≥n de lote sincronizada se agrega despu√©s de cada convoluci√≥n con la descomposici√≥n de la norma de lote 0.99 y epsilon 1e-3. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada modelo est√° entrenado 300 √©pocas con un tama√±o total de lote 128 en 32 n√∫cleos TPUv3.</font></font></blockquote><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">cloud.google.com/tpu/docs/types-zones#europe</a><br>
<blockquote>v3-32 TPU type (v3) ‚Äì 32 TPU v3 cores ‚Äì 512 GiB Total TPU memory</blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debe usar 512 GB de TPU / GPU-RAM para entrenar el modelo EfficientDet con normalizaci√≥n de lote sincronizada en lote = 128, mientras que mini-lote = 8 y solo 32 GB de GPU-RAM se usaron para entrenar YOLOv4. A pesar de esto, YOLOv4 es m√°s r√°pido / m√°s preciso que las redes p√∫blicas, aunque se entrena solo 1 vez con una resoluci√≥n de 512x512 por 1 GPU (Tesla V100 32GB / 16GB). Al mismo tiempo, usar el tama√±o de mini lote m√°s peque√±o y GPU-VRAM no conduce a una p√©rdida de precisi√≥n tan dram√°tica como en otras redes neuronales: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xi/ol/rs/xiolrsvx4vzpjvahb6kvambdvgq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fuente: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para que pueda entrenar inteligencia artificial localmente en su PC, en lugar de descargar Conjunto de datos en la nube: esto garantiza la protecci√≥n de sus datos personales y hace que la capacitaci√≥n en inteligencia artificial est√© disponible para todos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es suficiente entrenar nuestra red una vez con una resoluci√≥n de red 512x512, y luego se puede usar con diferentes resoluciones de red en el rango: [416x416 - 512x512 - 608x608]. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La mayor√≠a de los otros modelos necesitan ser entrenados cada vez por separado para cada resoluci√≥n de red, debido a esto, el entrenamiento lleva muchas m√°s horas.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caracter√≠sticas de la precisi√≥n de medici√≥n de algoritmos de detecci√≥n de objetos</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Siempre puede encontrar una imagen en la que un algoritmo funcionar√° mal, y otro algoritmo funcionar√° bien, y viceversa. Por lo tanto, para probar los algoritmos de detecci√≥n, se utiliza un gran conjunto de ~ 20,000 im√°genes y 80 tipos diferentes de objetos: el conjunto de datos MSCOCO test-dev. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para que el algoritmo no solo intente recordar el hash de cada imagen y las coordenadas que contiene (sobreajuste), la precisi√≥n de la detecci√≥n de objetos siempre se verifica en las im√°genes y etiquetas que el algoritmo no vio durante el entrenamiento; esto garantiza que el algoritmo pueda detectar objetos en im√°genes / videos que Nunca lo vi.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para que nadie pueda cometer un error al calcular la precisi√≥n, en el dominio p√∫blico solo hay im√°genes de prueba test-dev en las que detecta y env√≠a los resultados al servidor de evaluaci√≥n CodaLab, en el que el programa compara sus resultados con anotaciones de prueba que no son accesibles para nadie . </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El conjunto de datos MSCOCO consta de 3 partes</font></font></a><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tutorial: 120,000 im√°genes y un archivo json con las coordenadas de cada objeto</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conjunto de validaci√≥n: 5,000 im√°genes y un archivo json con las coordenadas de cada objeto</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conjunto de pruebas: 41,000 im√°genes jpg sin las coordenadas de los objetos (algunas de estas im√°genes se utilizan para determinar la precisi√≥n en las tareas: detecci√≥n de objetos, segmentaci√≥n de instancias, puntos clave, ...)</font></font></li>
</ol><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caracter√≠sticas del desarrollo de YOLOv4</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al desarrollar YOLOv4, tuve que desarrollar tanto la red neuronal YOLOv4 como el marco Darknet en C / C ++ / CUDA. </font><font style="vertical-align: inherit;">Porque </font><font style="vertical-align: inherit;">en Darknet no hay diferenciaci√≥n autom√°tica y ejecuci√≥n autom√°tica de reglas de cadena, entonces todos los gradientes deben implementarse manualmente. </font><font style="vertical-align: inherit;">Por otro lado, podemos apartarnos de la estricta adherencia a la regla de la cadena, cambiar la propagaci√≥n hacia atr√°s e intentar cosas muy poco triviales para aumentar la estabilidad y precisi√≥n del aprendizaje.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallazgos adicionales al crear redes neuronales</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No siempre la mejor red para clasificar objetos ser√° la mejor como red troncal para la red utilizada para detectar objetos</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El uso de pesas entrenadas con caracter√≠sticas que tienen mayor precisi√≥n en la clasificaci√≥n puede afectar negativamente la precisi√≥n del detector (en algunas redes)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No todas las caracter√≠sticas indicadas en varios estudios mejoran la precisi√≥n de la red.</font></font></li>
<li>                .</li>
<li>      BFLOPS  ,   BFLOPS    </li>
<li>                  ,     receptive field     ,       stride=2 / conv3x3,    weights (filters)      . </li>
</ul><br>
<h3>   YOLOv4</h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La detecci√≥n de objetos utilizando modelos entrenados de YOLOv4 est√° integrada en la biblioteca OpenCV-dnn </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/issues/17148</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para que pueda usar YOLOv4 directamente desde OpenCV sin usar el marco Darknet. </font><font style="vertical-align: inherit;">La biblioteca OpenCV admite la implementaci√≥n de redes neuronales en la CPU, GPU (GPU nVidia), VPU (Intel Myriad X). </font><font style="vertical-align: inherit;">M√°s detalles: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs.opencv.org/master/da/d9d/tutorial_dnn_yolo.html Marco </font></font></a><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dnn):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ejemplo de C ++: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ejemplo de Python: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.py</font></font></a></li>
</ul><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Marco </font><b><font style="vertical-align: inherit;">Darknet</font></b><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instrucciones para usar YOLOv4 para detectar objetos: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-use-on-the-command-line</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instrucciones para entrenar una red neuronal para detectar sus propios objetos: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instrucciones para entrenar al clasificador CSPDarknet53 en el conjunto de datos ILSVRC2012 (ImageNet): </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Classifier-on-ImageNet-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (ILSVRC2012)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instrucciones para entrenar a YOLOv4 en el conjunto de datos MS COCO: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Detector-on-MS-COCO-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (trainvalno5k-2014) -dataset</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tkDNN + TensorRT</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Velocidad m√°xima de detecci√≥n de objetos usando YOLOv4: TensorRT + tkDNN </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS - YOLOv4 (416x416 lote = 4) en RTX 2080 Ti</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS - YOLOv4 (416x416 lote = 1) en Jetson AGX Xavier</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El uso de YOLOv4 se puede ampliar para detectar Bboxes rotados en 3D o puntos clave / puntos de referencia faciales, por ejemplo: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ouyanghuiyu/darknet_face_with_landmark</font></font></a><br>
<br>
<img src="https://habrastorage.org/webt/z7/vs/dv/z7vsdvhcpfbrgmdv1byhbpzd1cu.jpeg"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es503182/index.html">"Soy el primer desarrollador ciego de mi empresa". Parte 1</a></li>
<li><a href="../es503184/index.html">Te invitamos a la reuni√≥n en l√≠nea Zabbix</a></li>
<li><a href="../es503192/index.html">oVirt en 2 horas. Parte 4. Operaciones b√°sicas</a></li>
<li><a href="../es503194/index.html">ISA no perdona errores</a></li>
<li><a href="../es503196/index.html">450 cursos gratuitos de la Ivy League</a></li>
<li><a href="../es503204/index.html">C√≥mo flashear Xiaomi Redmi 4 Prime / Pro / Premium en Android 10</a></li>
<li><a href="../es503208/index.html">¬øCu√°ndo es el mejor momento para invertir?</a></li>
<li><a href="../es503210/index.html">¬øSe pueden erradicar los sitios de phishing?</a></li>
<li><a href="../es503212/index.html">30 trucos para completar el curso en l√≠nea</a></li>
<li><a href="../es503214/index.html">Optimizaci√≥n de carga en un proyecto Highload con ElasticSearch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîô üë©üèæ‚Äç‚úàÔ∏è üõë Researchers are developing an approach to reducing bias in computer vision datasets ‚ÜòÔ∏è ü•Å üßñüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A translation of the article was prepared specifically for students of the Computer Vision course . 
 
 February 14, 2020 
 Princeton University, Depa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Researchers are developing an approach to reducing bias in computer vision datasets</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/498046/"><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A translation of the article was prepared specifically for students of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the Computer Vision</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> course </font><font style="vertical-align: inherit;">. </font></font></i></b><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">February 14, 2020 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton University, Department of Engineering.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/7l/rc/oe/7lrcoe52n2bvvynvhjwhmhhprx4.png"><br>
<hr><br>
<blockquote><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Summary:</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
To solve the problems of bias in artificial intelligence, computer scientists have developed methods for obtaining more reliable data sets containing images of people. Researchers are offering enhancements to ImageNet, a database of more than 14 million images that has played a key role in the development of computer vision over the past decade.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ImageNet, which includes images of objects, landscapes and, in particular, people, serves as a source of training data for researchers creating machine learning algorithms that classify images or recognize individual elements on them. ImageNet's unprecedented scale required automated image collection and annotation using crowdsourcing. While the category of images of people from the database was rarely used by the research community, the ImageNet team worked to eliminate the bias and a number of other problems associated with images of people that are unintended consequences of the ImageNet design.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄúToday, computer vision works well enough to be implemented everywhere in a variety of contexts,‚Äù said co-author Olga Russakovskaya, associate professor of computer science at Princeton. ‚ÄúThis means that now is the time to talk about how it affects the world and think about the issues of credibility.‚Äù</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In a new article, the ImageNet team systematically identified non-visual concepts and offensive categories, such as racial and sexual characteristics, for ImageNet's human image categories and suggested removing them from the database. Researchers have also developed a tool that allows users to identify and obtain sets of images of people that are balanced by age, gender and skin color, in order to facilitate appropriate algorithms to more reliably classify people's faces and their actions on images. Researchers presented their work on January 30 at a conference on the veracity, reliability, and transparency of the Computing Technology Association in Barcelona, ‚Äã‚ÄãSpain.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄúIt is very important to bring to the discussion the attention of laboratories and researchers with fundamental technical experience,‚Äù continues Russakovskaya. ‚ÄúGiven the fact that we need to collect data on a colossal scale, and the fact that this will be realized through crowdsourcing (because it is the most efficient and well-proven pipeline), the question arises - how do we do this in order to ensure the greatest reliability without stepping on a familiar rake? This article primarily focuses on design solutions. ‚Äù</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A group of computer scientists at Princeton and Stanford launched ImageNet in 2009 as a resource for researchers and educators. Princeton graduate and teacher Fay-Fay Lee, now a professor of computer science at Stanford, led the initiative. To encourage researchers to create better computer vision algorithms using ImageNet, the team also launched the ImageNet Large Scale Visual Recognition Challenge. The competition was mainly focused on the recognition of objects using 1000 categories of images, only three of which featured people.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Some of the reliability issues in ImageNet stem from the pipeline used to create the database. Its image categories are taken from WordNet, an old database of English words used for natural language processing research. The creators of ImageNet borrowed nouns from WordNet - some of which, although they are well-defined verbal terms, are poorly translated into a visual dictionary. For example, the terms that describe a person‚Äôs religion or geographical origin can only extract the most prominent image search results, which can result in algorithms that reinforce stereotypes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A recent art project called ImageNet Roulette has drawn attention to these issues. The project, released in September 2019 as part of an art exhibition dedicated to image recognition systems, used the images of people from ImageNet to train an artificial intelligence model that categorized people with words based on the presented image. Users could upload their image and get a tag based on this model. Many of the classifications were offensive or simply unfounded.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main innovation that allowed ImageNet creators to accumulate such a large database of tagged images was the use of crowdsourcing, in particular the Amazon Mechanical Turk (MTurk) platform, in which employees were paid to verify candidate images. This approach, although it was revolutionary, was still imperfect, which led to some biased and inappropriate categories. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄúWhen you ask people to check images by selecting from a wide range of candidates, people feel the pressure to choose something, and these images tend to have distinctive or stereotyped features,‚Äù says lead author Kayu Young, a computer science graduate .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the course of the study, Jan and his colleagues first filtered out potentially abusive or sensitive categories of people from ImageNet. They considered offensive the categories containing profanity or racial or gender insults; sensitive categories included, for example, classification of people based on sexual orientation or religion. To annotate the categories, they recruited 12 graduate students from different walks of life, instructing them to mark the category as sensitive if they are unsure. So they excluded 1593 categories - about 54% of the 2932 categories of people on ImageNet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Then, the researchers turned to MTurk employees for help, so that they rated the ‚Äúimagery‚Äù of the remaining acceptable categories on a scale of 1 to 5. Selecting categories with a rating of imagery of 4 or higher led to the fact that only 158 categories were classified as acceptable and sufficiently figurative. Even this carefully filtered set of categories contained more than 133,000 images - a huge number of examples for teaching computer vision algorithms.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Within these 158 categories, researchers studied the demographic representation of people in images to assess the level of bias in ImageNet and to develop an approach to create more appropriate data sets. ImageNet content comes primarily from image-targeted search engines such as Flickr. Search engines, on the whole, tend to return results that represent significantly more men, fair-skinned people, and adults between the ages of 18 and 40. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄúPeople have found that image search results are highly biased in terms of demographic distribution, so ImageNet also has a biased distribution,‚Äù says Young. "In this article, we tried to assess the level of bias, and also propose a method that would balance the distribution."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Researchers have identified and reviewed three attributes that are protected under U.S. anti-discrimination laws: skin color, gender, and age. MTurk workers were asked to annotate each attribute of each person in the image. They classified skin color as light, medium or dark; and by age as children (under 18), adults 18‚Äì40 years old, adults 40‚Äì65 years old or adults over 65 years old. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gender classification included men, women and indefinite gender - a way to include people with different gender expressions, as well as annotate images in which gender cannot be perceived by visual signs (such as images of many children or scuba divers).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An analysis of the annotations showed that, as in the search results, ImageNet content reflects a significant bias. People marked as black, women, and adults over 40 were underrepresented in most categories.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Although the annotation process included quality control and required that annotators reach consensus, because of concerns about the potential harm of incorrect annotations, researchers chose not to issue demographic annotations for individual images. Instead, they developed a web-based tool that allows users to retrieve a set of images that are demographically balanced in the manner specified by the user. For example, a complete collection of images in the programmer category may include about 90% of men and 10% of women, while in the United States about 20% of programmers are women. The researcher can use the new tool to obtain a set of images of programmers representing 80% of men and 20% of women - or even individually, depending on the goals of the researcher.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄúWe don‚Äôt want to talk about how to balance demographics, because it‚Äôs not a very simple problem,‚Äù says Young. ‚ÄúThe distribution may be different in different parts of the world - for example, the distribution of skin colors in the US is different from the distribution in Asian countries. Therefore, we leave this question to our user and simply provide a tool for extracting a balanced subset of images. " </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The ImageNet team is currently working on technical updates of its equipment and the database itself, in addition to implementing face filtering and the rebalancing tool developed in this study. ImageNet will soon be reissued with these updates and a request for feedback from the computer vision researchers community.</font></font><br>
 <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Princeton Ph.D. Clint Kinami and associate professor of computer science, Jia Dang, co-authored with Young, Lee, and Russakovskaya. </font><font style="vertical-align: inherit;">The study was supported by the National Science Foundation. </font></font><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font></b><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Materials</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> provided by </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the Department of Engineering, Princeton University</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Original written by Molly Charlach. </font><font style="vertical-align: inherit;">P </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Note: The content may be modified by style and length. </font></font></i><br>
 <br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Link:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Kaiyu Yang, Klint Qinami, Li Fei-Fei, Jia Deng, Olga Russakovsky. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Towards fairer datasets: filtering and balancing the distribution of the people subtree in the ImageNet hierarchy. </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 2020 DOI: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10.1145 / 3351095.3375709</font></font></a><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Learn more about the course</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en498032/index.html">Quick calculation of formulas from Excel in C #</a></li>
<li><a href="../en498034/index.html">The modern by design aircraft is protected against biological threats (COVID-19) better than you think</a></li>
<li><a href="../en498036/index.html">Mark Andriessen: It's time to create for ourselves (It's Time to Build)</a></li>
<li><a href="../en498038/index.html">The digest of fresh materials from the world of the front-end for the last week No. 411 (April 13-19, 2020)</a></li>
<li><a href="../en498042/index.html">Parse, not validate</a></li>
<li><a href="../en498050/index.html">Culture as the basis for scaling the x2 team every year. About hiring mistakes and culture fit</a></li>
<li><a href="../en498052/index.html">Zabbix 5.0, or What's New With Template Server by IPMI</a></li>
<li><a href="../en498054/index.html">Defeat the Dragon News Feed: Making Sure You Live a Good Life</a></li>
<li><a href="../en498056/index.html">Digital events in Moscow from April 20 to 26</a></li>
<li><a href="../en498060/index.html">PostgreSQL Industrial Tuning Approach: Database Experiments. Nikolay Samokhvalov</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèø üêü ‚ö´Ô∏è YOLOv4 - a rede neural em tempo real mais precisa no conjunto de dados Microsoft COCO üôè ü§Ωüèæ ‚úäüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O Darknet YOLOv4 √© mais r√°pido / preciso do que o Google TensorFlow EfficientDet e o FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. 
 
 O mesmo ar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>YOLOv4 - a rede neural em tempo real mais precisa no conjunto de dados Microsoft COCO</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/503200/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Darknet YOLOv4 √© mais r√°pido / preciso do que o Google TensorFlow EfficientDet e o FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O mesmo artigo em medium</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium </font></font></a><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C√≥digo</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet </font></font></a><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artigo</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/3h/nc/sr/3hncsroz9wt8u3ycqskubgu1xk8.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mostraremos algumas nuances de compara√ß√£o e uso de redes neurais para detectar objetos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nosso objetivo era desenvolver um algoritmo de detec√ß√£o de objetos para uso em produtos reais, e n√£o apenas avan√ßar a ci√™ncia. </font><font style="vertical-align: inherit;">A precis√£o da rede neural YOLOv4 (608x608) √© de 43,5% AP / 65,7% AP50 Microsoft-COCO-testdev. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">62 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (lote 608x608 = 1) no Tesla V100 - usando o framework Darknet </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (lote 416x416 = 4) no RTX 2080 Ti - usando TensorRT + tkDNN </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (lote 416x416 = 1) no Jetson AGX Xavier - usando TensorRT + tkDNN</font></font><br>
<br>
<img src="https://habrastorage.org/webt/p_/ep/cl/p_epcl_aaw_trgeltekatagtqkg.jpeg"> <br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1_SiUOYUoOI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Primeiro, alguns links √∫teis.</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ pode ler uma descri√ß√£o detalhada dos recursos usados ‚Äã‚Äãno YOLOv4 neste artigo: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium.com/@jonathan_hui/yolov4-c9901eaa8e61</font></font></a></li>
<li>  YOLOv4: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://lutzroeder.github.io/netron/%3Furl%3D" rel="nofollow">lutzroeder.github.io/netron/?url=https%3A%2F%2Fraw.githubusercontent.com%2FAlexeyAB%2Fdarknet%2Fmaster%2Fcfg%2Fyolov4.cfg</a></li>
<li>     YOLOv4  GPU   Google-cloud  Jupyter Notebook ‚Äì      ,   - ¬´Open in Playground¬ª,         [ ] ‚Äì    ,  ,  ,    5    : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE</a>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">www.youtube.com/watch?v=mKAEGSxwOAY</a></li>
<li>  Darknet   : <br>
 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 </li>
</ul><br>
<h3>   </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nossa rede neural YOLOv4 e nossa pr√≥pria estrutura Darknet DL (C / C ++ / CUDA) s√£o melhores em velocidade de FPS e precis√£o AP50: 95 e AP50 em conjuntos de dados Microsoft COCO do que estruturas DL e redes neurais: Google TensorFlow EfficientDet, FaceBook Detectron RetinaNet / MaskRCNN, PyTorch Yolov3-ASFF e muitos outros ... O YOLOv4 alcan√ßa precis√£o de 43,5% AP / 65,7% AP50 no teste Microsoft COCO a uma velocidade de 62 FPS TitanV ou 34 FPS RTX 2070. Ao contr√°rio de outros detectores modernos, o YOLOv4 pode treinar qualquer pessoa com quem tiver a placa gr√°fica da nVidia para jogos com VRAM de 8 a 16 GB. Agora, n√£o apenas as grandes empresas podem treinar uma rede neural em centenas de GPU / TPUs para usar tamanhos grandes de mini lotes para obter maior precis√£o, por isso estamos devolvendo o controle da intelig√™ncia artificial aos usu√°rios comuns, porque para o YOLOv4 n√£o √© necess√°rio um mini lote grande,pode ser limitado a um tamanho de 2 a 8.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLOV4 √© ideal para usar em tempo real, porque a rede est√° </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">na curva de otimiza√ß√£o de Pareto</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> no gr√°fico AP (precis√£o) / FPS (velocidade). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2k/77/as/2k77aszzprngk0qmtistcehkz8c.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gr√°ficos de precis√£o (AP) e velocidade (FPS) de muitas redes neurais para a detec√ß√£o de objetos medidos nas GPUs TitanV / TeslaV100, TitanXP / TeslaP100, TitanX / TeslaM40 para os dois principais indicadores de precis√£o AP50: 95 e AP50</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para uma compara√ß√£o justa </font><b><font style="vertical-align: inherit;">, coletamos</font></b><font style="vertical-align: inherit;"> dados de artigos e compare apenas na GPU com a mesma arquitetura. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As tarefas mais pr√°ticas t√™m os requisitos m√≠nimos necess√°rios para os detectores - s√£o a precis√£o e velocidade aceit√°veis ‚Äã‚Äãm√≠nimas. Geralmente, a velocidade m√≠nima permitida de 30 FPS (quadros por segundo) e superior para sistemas em tempo real. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como pode ser visto nos gr√°ficos, em sistemas em tempo real com FPS 30 ou mais:</font></font><br>
<br>
<ul>
<li> YOLOv4-608   RTX 2070  <b>450$</b> (34 FPS)   <b>43.5% AP / 65.7% AP50</b></li>
<li> EfficientDet-D2   TitanV  <b>2250$</b> (42 FPS)   <b>43.0% AP / 62.3% AP50</b></li>
<li> EfficientDet-D0   RTX 2070  <b>450$</b> (34 FPS)   <b>33.8% AP / 52.2% AP50</b></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essa. O YOLOv4 requer </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">equipamentos 5 vezes mais baratos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e com mais precis√£o do que o EfficientDet-D2 (Google-TensorFlow). Voc√™ pode usar o EfficientDet-D0 (Google-TensorFlow), pois o custo do equipamento ser√° o mesmo, mas a precis√£o ser√° 10% mais baixa. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m disso, alguns sistemas industriais t√™m limita√ß√µes na dissipa√ß√£o de calor ou no uso de um sistema de resfriamento passivo - nesse caso, voc√™ n√£o pode usar o TitanV mesmo com dinheiro. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ao usar o YOLOv4 (416x416) em uma GPU RTX 2080 Ti usando TensorRT + tkDNN, atingimos uma velocidade duas vezes mais r√°pida e, ao usar batch = 4, √© 3x-4x vezes mais r√°pido - para uma compara√ß√£o honesta, n√£o apresentamos esses resultados em um artigo sobre arxiv. org:</font></font><br>
<img src="https://habrastorage.org/webt/ci/j7/uq/cij7uqas0ypsjcpsfkhvdxuyxzs.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLOv4 rede neural (416x416) FP16 (Tensor n√∫cleos) do lote = </font><font style="vertical-align: inherit;">1 atinge a 32 FPS calculadora nVidia Jetson AGX Xavier utilizando bibliotecas + tkDNN TensorRT: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
velocidade ligeiramente mais lenta d√° biblioteca OpenCV-dnn compilado com CUDA: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs .opencv.org / master / da / d9d / tutorial_dnn_yolo.html</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√Äs vezes, a velocidade (FPS) de algumas redes neurais nos artigos √© indicada ao usar um tamanho de lote alto ou ao testar com software especializado (TensorRT), que otimiza a rede e mostra um valor aumentado de FPS. A compara√ß√£o de algumas redes no TRT com outras redes sem o TRT n√£o √© justa. O uso de um tamanho de lote alto aumenta o FPS, mas tamb√©m aumenta a lat√™ncia (em vez de diminu√≠-lo) em compara√ß√£o com o lote = 1. Se a rede com lote = 1 mostrar 40 FPS e com lote = 32 mostrar 60 FPS, o atraso ser√° de 25 ms para o lote = 1 e ~ 500 ms para o lote = 32, porque apenas ~ 2 pacotes (32 imagens cada) ser√£o processados ‚Äã‚Äãpor segundo, e √© por isso que usar batch = 32 n√£o √© aceit√°vel em muitos sistemas industriais. Portanto, comparamos os resultados nos gr√°ficos apenas com o lote = 1 e sem o uso do TensorRT.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qualquer processo pode ser controlado por pessoas ou por computadores. Quando um sistema de computador age com um grande atraso devido √† baixa velocidade e comete muitos erros, n√£o pode ser confiado a ele um controle completo das a√ß√µes; nesse caso, a pessoa controla o processo, e o sistema de computador apenas fornece dicas - este √© um sistema de recomenda√ß√£o - a pessoa trabalha e apenas o sistema informa onde foram cometidos erros. Quando o sistema trabalha rapidamente e com alta precis√£o, esse sistema pode controlar o processo de forma independente, e uma pessoa s√≥ cuida dele. Portanto, a precis√£o e a velocidade do sistema s√£o sempre importantes. Se voc√™ acha que 120 FPS para YOLOv4 416x416 √© demais para sua tarefa, e √© melhor usar o algoritmo com mais lentid√£o e precis√£o, ent√£o provavelmente em tarefas reais voc√™ usar√° algo mais fraco que o Tesla V100 250 Watt,por exemplo, RTX 2060 / Jetson-Xavier 30-80 Watt, nesse caso, voc√™ obter√° 30 FPS no YOLOv4 416x416 e outras redes neurais a 1-15 FPS ou nem iniciar√°.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caracter√≠sticas do treinamento de v√°rias redes neurais</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ precisa treinar o EfficientDet com mini-lote = tamanho 128 em v√°rias GPUs Tesla V100 de 32GB, enquanto o YOLOv4 foi treinado em apenas uma GPU Tesla V100 32GB com mini-lote = 8 = lote / subdivis√µes e pode ser treinado em jogos regulares placa gr√°fica 8-16GB GPU-VRAM. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A pr√≥xima nuance √© a dificuldade de treinar uma rede neural para detectar seus pr√≥prios objetos. </font><font style="vertical-align: inherit;">N√£o importa quanto tempo voc√™ treine outras redes na mesma GPU 1080 Ti, voc√™ n√£o obter√° a precis√£o declarada mostrada no gr√°fico acima. </font><font style="vertical-align: inherit;">A maioria das redes (EfficientDet, ASFF, ...) precisa ser treinada em 4 a 128 GPUs (com um tamanho grande de minicatch usando syncBN) e √© necess√°rio treinar novamente a cada resolu√ß√£o de rede, sem atender a ambas as condi√ß√µes, √© imposs√≠vel obter a precis√£o de AP ou AP50 declarada por eles.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/p4/sx/p3/p4sxp3ewxd9owskis23n6dyrv58.jpeg"><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voc√™ pode ver a depend√™ncia da precis√£o da detec√ß√£o de objetos no tamanho do minibatch em outros detectores, ou seja, </font><font style="vertical-align: inherit;">usando 128 placas de v√≠deo em vez de 8 placas de v√≠deo e a velocidade de aprendizado √© 10 vezes maior e a precis√£o final √© 1,5 AP maior - MegDet: um detector grande de objetos em lotes</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"></font></a></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
pequenos </font><b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">arxiv.org/abs/1711.07240</font></a></b><font style="vertical-align: inherit;"> Yolo ASFF: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09516</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A seguir [43], introduzimos uma s√©rie de truques no processo de treinamento, como o algoritmo de mixagem [12], o cronograma da taxa de aprendizado do cosseno [26] e a t√©cnica de normaliza√ß√£o de lote sincronizada [30].</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
EfficientDet: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09070</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A normaliza√ß√£o de lote sincronizada √© adicionada ap√≥s cada convolu√ß√£o com decaimento da norma de lote 0,99 e epsilon 1e-3. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada modelo √© treinado 300 √©pocas com tamanho total de lote 128 em 32 n√∫cleos TPUv3.</font></font></blockquote><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">cloud.google.com/tpu/docs/types-zones#europe</a><br>
<blockquote>v3-32 TPU type (v3) ‚Äì 32 TPU v3 cores ‚Äì 512 GiB Total TPU memory</blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ deve usar TPU / GPU-RAM de 512 GB para treinar o modelo EfficientDet com normaliza√ß√£o de lote sincronizado no lote = 128, enquanto mini-lote = 8 e apenas GPU-RAM de 32 GB foram usados ‚Äã‚Äãpara treinar o YOLOv4. Apesar disso, o YOLOv4 √© mais r√°pido / preciso do que as redes p√∫blicas, embora seja treinado apenas uma vez com uma resolu√ß√£o de 512x512 por 1 GPU (Tesla V100 32GB / 16GB). Ao mesmo tempo, o uso de um tamanho menor de minilote e o GPU-VRAM n√£o leva a uma perda de precis√£o t√£o dram√°tica como em outras redes neurais: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xi/ol/rs/xiolrsvx4vzpjvahb6kvambdvgq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fonte: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para que voc√™ possa treinar intelig√™ncia artificial localmente no seu PC, em vez de baixar Conjunto de dados na nuvem - isso garante a prote√ß√£o de seus dados pessoais e disponibiliza treinamento de intelig√™ncia artificial para todos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Basta treinar nossa rede uma vez com uma resolu√ß√£o de rede de 512x512 e, em seguida, pode ser usada com diferentes resolu√ß√µes de rede no intervalo: [416x416 - 512x512 - 608x608]. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A maioria dos outros modelos precisa ser treinada cada vez separadamente para cada resolu√ß√£o de rede, por isso, o treinamento leva muitas vezes mais tempo.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recursos para medir a precis√£o dos algoritmos de detec√ß√£o de objetos</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ sempre pode encontrar uma imagem na qual um algoritmo funcione mal e outro funcione bem e vice-versa. Portanto, para testar algoritmos de detec√ß√£o, √© usado um grande conjunto de ~ 20.000 imagens e 80 tipos diferentes de objetos - conjunto de dados MSCOCO test-dev. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para que o algoritmo n√£o tente simplesmente se lembrar do hash de cada imagem e das coordenadas nela (ajuste excessivo), a precis√£o da detec√ß√£o de objetos √© sempre verificada nas imagens e nos r√≥tulos que o algoritmo n√£o viu durante o treinamento - isso garante que o algoritmo possa detectar objetos nas imagens / v√≠deos que ele nunca vi.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para que ningu√©m cometa um erro no c√°lculo da precis√£o, no dom√≠nio p√∫blico existem apenas imagens de teste test-dev nas quais voc√™ detecta e envia os resultados ao servidor de avalia√ß√£o CodaLab, no qual o pr√≥prio programa compara seus resultados com anota√ß√µes de teste que n√£o s√£o acess√≠veis a ningu√©m . </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O conjunto de dados MSCOCO consiste em 3 partes</font></font></a><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tutorial: 120.000 imagens e um arquivo json com as coordenadas de cada objeto</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conjunto de valida√ß√£o: 5.000 imagens e um arquivo json com as coordenadas de cada objeto</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conjunto de testes: 41.000 imagens jpg sem as coordenadas dos objetos (algumas dessas imagens s√£o usadas para determinar a precis√£o nas tarefas: detec√ß√£o de objetos, segmenta√ß√£o de inst√¢ncia, pontos-chave, ...)</font></font></li>
</ol><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caracter√≠sticas do desenvolvimento do YOLOv4</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ao desenvolver o YOLOv4, tive que desenvolver a rede neural do YOLOv4 e a estrutura Darknet no C / C ++ / CUDA. </font><font style="vertical-align: inherit;">Porque </font><font style="vertical-align: inherit;">no Darknet n√£o h√° diferencia√ß√£o autom√°tica e execu√ß√£o autom√°tica de regra de cadeia; todos os gradientes precisam ser implementados manualmente. </font><font style="vertical-align: inherit;">Por outro lado, podemos nos afastar da estrita ades√£o √† regra da cadeia, alterar a retropropaga√ß√£o e tentar coisas muito n√£o triviais para aumentar a estabilidade e a precis√£o do aprendizado.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descobertas adicionais ao criar redes neurais</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nem sempre a melhor rede para classificar objetos ser√° a melhor como espinha dorsal da rede usada para detectar objetos</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O uso de pesos treinados com recursos que aumentaram a precis√£o na classifica√ß√£o pode afetar adversamente a precis√£o do detector (em algumas redes)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nem todos os recursos declarados em v√°rios estudos melhoram a precis√£o da rede.</font></font></li>
<li>                .</li>
<li>      BFLOPS  ,   BFLOPS    </li>
<li>                  ,     receptive field     ,       stride=2 / conv3x3,    weights (filters)      . </li>
</ul><br>
<h3>   YOLOv4</h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A detec√ß√£o de objetos usando modelos YOLOv4 treinados √© incorporada √† biblioteca OpenCV-dnn </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/issues/17148,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para que voc√™ possa usar o YOLOv4 diretamente do OpenCV sem usar a estrutura Darknet. </font><font style="vertical-align: inherit;">A biblioteca OpenCV suporta a implementa√ß√£o de redes neurais na CPU, GPU (nVidia GPU), VPU (Intel Myriad X). </font><font style="vertical-align: inherit;">Mais detalhes: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs.opencv.org/master/da/d9d/tutorial_dnn_yolo.html Estrutura do </font></font></a><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dnn):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemplo de C ++: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemplo de Python: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.py</font></font></a></li>
</ul><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quadro </font><b><font style="vertical-align: inherit;">Darknet</font></b><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instru√ß√µes para usar o YOLOv4 para detectar objetos: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-use-on-the-command-line</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instru√ß√µes para treinar uma rede neural para detectar seus pr√≥prios objetos: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instru√ß√µes para treinar o classificador CSPDarknet53 no conjunto de dados ILSVRC2012 (ImageNet): </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Classifier-on-ImageNet-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (ILSVRC2012)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instru√ß√µes para o treinamento do YOLOv4 no conjunto de dados do MS COCO: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Detector-on-MS-COCO-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (trainvalno5k-2014) -dataset</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tkDNN + TensorRT</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Velocidade m√°xima de detec√ß√£o de objeto usando o YOLOv4: TensorRT + tkDNN </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS - YOLOv4 (lote de 416x416 = 4) no RTX 2080 Ti</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS - YOLOv4 (lote de 416x416 = 1) no Jetson AGX Xavier</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O uso do YOLOv4 pode ser expandido para detectar caixas-rotativas em 3D ou pontos-chave / pontos faciais, por exemplo: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ouyanghuiyu/darknet_face_with_landmark</font></font></a><br>
<br>
<img src="https://habrastorage.org/webt/z7/vs/dv/z7vsdvhcpfbrgmdv1byhbpzd1cu.jpeg"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt503182/index.html">"Sou o primeiro desenvolvedor cego da minha empresa." Parte 1</a></li>
<li><a href="../pt503184/index.html">Convidamos voc√™ para a reuni√£o on-line do Zabbix</a></li>
<li><a href="../pt503192/index.html">oVirt em 2 horas. Parte 4. Opera√ß√µes B√°sicas</a></li>
<li><a href="../pt503194/index.html">ISA n√£o perdoa erros</a></li>
<li><a href="../pt503196/index.html">450 cursos gratuitos da Ivy League</a></li>
<li><a href="../pt503204/index.html">Como flash Xiaomi Redmi 4 Prime / Pro / Premium no Android 10</a></li>
<li><a href="../pt503208/index.html">Quando √© o melhor momento para investir?</a></li>
<li><a href="../pt503210/index.html">Os sites de phishing podem ser erradicados?</a></li>
<li><a href="../pt503212/index.html">30 hacks para completar o curso on-line</a></li>
<li><a href="../pt503214/index.html">Otimiza√ß√£o de carga em um projeto Highload com ElasticSearch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
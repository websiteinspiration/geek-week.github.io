<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗞️ 🥖 🐨 1ピクセル攻撃。またはニューラルネットワークをだます方法 ☹️ 🧑🏽‍🤝‍🧑🏽 ⚡️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ニューラルネットワークへの攻撃の1つを理解しましょう。これは、外部の影響を最小限に抑えて分類エラーを引き起こします。しばらくの間、ニューラルネットワークがあなたであると想像してください。そして現在、香り豊かなコーヒーを飲みながら、「1ピクセルの攻撃」がすべての「猫」をトラックに変えたことを疑うことな...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>1ピクセル攻撃。またはニューラルネットワークをだます方法</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498114/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラルネットワークへの攻撃の1つを理解しましょう。これは、外部の影響を最小限に抑えて分類エラーを引き起こします。しばらくの間、ニューラルネットワークがあなたであると想像してください。そして現在、香り豊かなコーヒーを飲みながら、「1ピクセルの攻撃」がすべての「猫」をトラックに変えたことを疑うことなく、猫の画像を90％を超える精度で分類しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、一時停止し、コーヒーを脇に置き、必要なすべてのライブラリをインポートし、このような1ピクセルの攻撃がどのように機能するかを分析します。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この攻撃の目的は、アルゴリズム（ニューラルネットワーク）に不正解を与えることです。</font><font style="vertical-align: inherit;">以下では、畳み込みニューラルネットワークのいくつかの異なるモデルでこれを確認します。</font><font style="vertical-align: inherit;">多次元数学的最適化の方法の1つである差分進化を使用して、ニューラルネットワークがこの画像を誤って分類し始めるように画像を変更できる特別なピクセルを見つけます（以前のアルゴリズムが同じ画像を正しく高精度で「認識」したという事実にもかかわらず）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ライブラリをインポートします。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># Python Libraries</span><font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> pickle
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> matplotlib
<span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> cifar10
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> backend <span class="hljs-keyword">as</span> K<font></font>
<font></font>
<span class="hljs-comment"># Custom Networks</span>
<span class="hljs-keyword">from</span> networks.lenet <span class="hljs-keyword">import</span> LeNet
<span class="hljs-keyword">from</span> networks.pure_cnn <span class="hljs-keyword">import</span> PureCnn
<span class="hljs-keyword">from</span> networks.network_in_network <span class="hljs-keyword">import</span> NetworkInNetwork
<span class="hljs-keyword">from</span> networks.resnet <span class="hljs-keyword">import</span> ResNet
<span class="hljs-keyword">from</span> networks.densenet <span class="hljs-keyword">import</span> DenseNet
<span class="hljs-keyword">from</span> networks.wide_resnet <span class="hljs-keyword">import</span> WideResNet
<span class="hljs-keyword">from</span> networks.capsnet <span class="hljs-keyword">import</span> CapsNet<font></font>
<font></font>
<span class="hljs-comment"># Helper functions</span>
<span class="hljs-keyword">from</span> differential_evolution <span class="hljs-keyword">import</span> differential_evolution
<span class="hljs-keyword">import</span> helper<font></font>
<font></font>
matplotlib.style.use(<span class="hljs-string">'ggplot'</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この実験では、10個のクラスに分割された実際の画像を含むCIFAR-10データセットをロードします。</font></font><br>
<br>
<pre><code class="python hljs">(x_train, y_train), (x_test, y_test) = cifar10.load_data()<font></font>
<font></font>
class_names = [<span class="hljs-string">'airplane'</span>, <span class="hljs-string">'automobile'</span>, <span class="hljs-string">'bird'</span>, <span class="hljs-string">'cat'</span>, <span class="hljs-string">'deer'</span>, <span class="hljs-string">'dog'</span>, <span class="hljs-string">'frog'</span>, <span class="hljs-string">'horse'</span>, <span class="hljs-string">'ship'</span>, <span class="hljs-string">'truck'</span>]
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
インデックスで画像を見てみましょう。</font><font style="vertical-align: inherit;">たとえば、この馬について。</font></font><br>
<br>
<pre><code class="python hljs">image_id = <span class="hljs-number">99</span> <span class="hljs-comment"># Image index in the test set</span><font></font>
helper.plot_image(x_test[image_id])<font></font>
</code></pre><br>
<img src="https://habrastorage.org/webt/gp/k9/gw/gpk9gwtmh-_e8e5jcni2vhcej70.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークの応答を変更できる非常に強力なピクセルを探す必要があります。つまり、画像の1つ以上のピクセルを変更する関数を作成する時が来ました。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">perturb_image</span>(<span class="hljs-params">xs, img</span>):</span>
    <span class="hljs-comment"># If this function is passed just one perturbation vector,</span>
    <span class="hljs-comment"># pack it in a list to keep the computation the same</span>
    <span class="hljs-keyword">if</span> xs.ndim &lt; <span class="hljs-number">2</span>:<font></font>
        xs = np.array([xs])<font></font>
    <font></font>
    <span class="hljs-comment"># Copy the image n == len(xs) times so that we can </span>
    <span class="hljs-comment"># create n new perturbed images</span>
    tile = [len(xs)] + [<span class="hljs-number">1</span>]*(xs.ndim+<span class="hljs-number">1</span>)<font></font>
    imgs = np.tile(img, tile)<font></font>
    <font></font>
    <span class="hljs-comment"># Make sure to floor the members of xs as int types</span><font></font>
    xs = xs.astype(int)<font></font>
    <font></font>
    <span class="hljs-keyword">for</span> x,img <span class="hljs-keyword">in</span> zip(xs, imgs):
        <span class="hljs-comment"># Split x into an array of 5-tuples (perturbation pixels)</span>
        <span class="hljs-comment"># i.e., [[x,y,r,g,b], ...]</span>
        pixels = np.split(x, len(x) // <span class="hljs-number">5</span>)
        <span class="hljs-keyword">for</span> pixel <span class="hljs-keyword">in</span> pixels:
            <span class="hljs-comment"># At each pixel's x,y position, assign its rgb value</span><font></font>
            x_pos, y_pos, *rgb = pixel<font></font>
            img[x_pos, y_pos] = rgb<font></font>
    <font></font>
    <span class="hljs-keyword">return</span> imgs
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
見てみな ？！</font><font style="vertical-align: inherit;">座標（16、16）の馬の1ピクセルを黄色に変更します。</font></font><br>
<br>
<pre><code class="python hljs">image_id = <span class="hljs-number">99</span> <span class="hljs-comment"># Image index in the test set</span>
pixel = np.array([<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>]) <span class="hljs-comment"># pixel = x,y,r,g,b</span>
image_perturbed = perturb_image(pixel, x_test[image_id])[<span class="hljs-number">0</span>]<font></font>
<font></font>
helper.plot_image(image_perturbed)<font></font>
</code></pre><br>
<img src="https://habrastorage.org/webt/qj/sf/li/qjsflidtymruwiuotebu0r7siby.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
攻撃を実証するには、CIFAR-10データセットにニューラルネットワークの事前トレーニング済みモデルをダウンロードする必要があります。</font><font style="vertical-align: inherit;">ここでは、lenetとresnetの2つのモデルを使用しますが、対応するコード行のコメントを外すことで、他のモデルを実験に使用できます。</font></font><br>
<br>
<pre><code class="python hljs">lenet = LeNet()<font></font>
resnet = ResNet()<font></font>
<font></font>
models = [lenet, resnet]<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 モデルを読み込んだ後、各モデルのテスト画像を評価して、正しく分類された画像のみが攻撃されることを確認する必要があります。</font><font style="vertical-align: inherit;">以下のコードは、各モデルの精度とパラメーターの数を表示します。</font></font><br>
<br>
<pre><code class="python hljs">network_stats, correct_imgs = helper.evaluate_models(models, x_test, y_test)<font></font>
<font></font>
correct_imgs = pd.DataFrame(correct_imgs, columns=[<span class="hljs-string">'name'</span>, <span class="hljs-string">'img'</span>, <span class="hljs-string">'label'</span>, <span class="hljs-string">'confidence'</span>, <span class="hljs-string">'pred'</span>])<font></font>
<font></font>
network_stats = pd.DataFrame(network_stats, columns=[<span class="hljs-string">'name'</span>, <span class="hljs-string">'accuracy'</span>, <span class="hljs-string">'param_count'</span>])<font></font>
<font></font>
network_stats<font></font>
Evaluating lenet<font></font>
Evaluating resnet<font></font>
<font></font>
Out[<span class="hljs-number">11</span>]:<font></font>
<font></font>
<font></font>
	name        accuracy    param_count<font></font>
<span class="hljs-number">0</span>      lenet        <span class="hljs-number">0.748</span>       <span class="hljs-number">62006</span>
<span class="hljs-number">1</span>      resnet       <span class="hljs-number">0.9231</span>      <span class="hljs-number">470218</span><font></font>
<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 このような攻撃はすべて、WhiteBoxとBlackBoxの2つのクラスに分類できます。それらの違いは、最初のケースでは、私たち全員がアルゴリズム、つまり私たちが扱っているモデルについて確実に知っているということです。 BlackBoxの場合、必要なのは入力（画像）と出力（クラスの1つに割り当てられる確率）だけです。 1つのピクセル攻撃はBlackBoxを指します。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事では、単一のピクセルを攻撃するための2つのオプション、非ターゲットとターゲットを検討します。最初のケースでは、猫のニューラルネットワークがどのクラスに属するかは絶対に問題になりません。最も重要なのは、猫のクラスに属さないことです。標的型攻撃は、猫をトラックにしてトラックだけにしたいときに適用できます。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、その変化が画像のクラスの変化につながる非常にピクセルを見つける方法は？どの1つのピクセルの攻撃が可能で成功するかを変更することによってピクセルを見つける方法は？この問題を最適化の問題として定式化してみましょう。非常に単純な言葉で言えば、非標的型攻撃では、目的のクラスへの信頼を最小限に抑え、標的型ではターゲットクラスへの信頼を最大限にする必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このような攻撃を行う場合、勾配を使用して関数を最適化することは困難です。関数の滑らかさに依存しない最適化アルゴリズムを使用する必要があります。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今回の実験では、CIFAR-10データセットを使用することを思い出してください。CIFAR-10データセットには、サイズが32 x 32ピクセルで、10個のクラスに分割された実世界の画像が含まれています。</font><font style="vertical-align: inherit;">そして、これは、0から31までの整数の離散値と0から255までの色の強度があり、関数が滑らかであるとは予想されないが、以下に示すようにギザギザしていることを意味します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vs/0k/mv/vs0kmvtq35lowxplx0rsq2-kppw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そのため、微分進化アルゴリズムを使用します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、コードに戻り、モデルの信頼性の確率を返す関数を記述します。</font><font style="vertical-align: inherit;">ターゲットクラスが正しい場合、この関数を最小化して、モデルが別のクラスであると確信できるようにします（これは正しくありません）。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_classes</span>(<span class="hljs-params">xs, img, target_class, model, minimize=True</span>):</span>
    <span class="hljs-comment"># Perturb the image with the given pixel(s) x and get the prediction of the model</span><font></font>
    imgs_perturbed = perturb_image(xs, img)<font></font>
    predictions = model.predict(imgs_perturbed)[:,target_class]<font></font>
    <span class="hljs-comment"># This function should always be minimized, so return its complement if needed</span>
    <span class="hljs-keyword">return</span> predictions <span class="hljs-keyword">if</span> minimize <span class="hljs-keyword">else</span> <span class="hljs-number">1</span> - predictions<font></font>
<font></font>
image_id = <span class="hljs-number">384</span>
pixel = np.array([<span class="hljs-number">16</span>, <span class="hljs-number">13</span>,  <span class="hljs-number">25</span>, <span class="hljs-number">48</span>, <span class="hljs-number">156</span>])<font></font>
model = resnet<font></font>
<font></font>
true_class = y_test[image_id, <span class="hljs-number">0</span>]<font></font>
prior_confidence = model.predict_one(x_test[image_id])[true_class]<font></font>
confidence = predict_classes(pixel, x_test[image_id], true_class, model)[<span class="hljs-number">0</span>]<font></font>
<font></font>
print(<span class="hljs-string">'Confidence in true class'</span>, class_names[true_class], <span class="hljs-string">'is'</span>, confidence)<font></font>
print(<span class="hljs-string">'Prior confidence was'</span>, prior_confidence)<font></font>
helper.plot_image(perturb_image(pixel, x_test[image_id])[<span class="hljs-number">0</span>])<font></font>
<font></font>
Confidence <span class="hljs-keyword">in</span> true <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">bird</span> <span class="hljs-title">is</span> 0.00018887444
<span class="hljs-title">Prior</span> <span class="hljs-title">confidence</span> <span class="hljs-title">was</span> 0.70661753
</span></code></pre><br>
<img src="https://habrastorage.org/webt/re/g3/yn/reg3ync4qxac0hxb5wrr0jus_je.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
攻撃が成功したかどうかの基準を確認するには、次の関数が必要です。変更がモデルをだますのに十分である場合、関数はTrueを返します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">attack_success</span>(<span class="hljs-params">x, img, target_class, model, targeted_attack=False, verbose=False</span>):</span>
    <span class="hljs-comment"># Perturb the image with the given pixel(s) and get the prediction of the model</span><font></font>
    attack_image = perturb_image(x, img)<font></font>
    confidence = model.predict(attack_image)[<span class="hljs-number">0</span>]<font></font>
    predicted_class = np.argmax(confidence)<font></font>
    <font></font>
    <span class="hljs-comment"># If the prediction is what we want (misclassification or </span>
    <span class="hljs-comment"># targeted classification), return True</span>
    <span class="hljs-keyword">if</span> verbose:<font></font>
        print(<span class="hljs-string">'Confidence:'</span>, confidence[target_class])
    <span class="hljs-keyword">if</span> ((targeted_attack <span class="hljs-keyword">and</span> predicted_class == target_class) <span class="hljs-keyword">or</span>
        (<span class="hljs-keyword">not</span> targeted_attack <span class="hljs-keyword">and</span> predicted_class != target_class)):
        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span>
    <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> return None otherwise (not False), due to how Scipy handles its callback function</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
成功基準関数の働きを見てみましょう。</font><font style="vertical-align: inherit;">実証するために、非標的攻撃を想定します。</font></font><br>
<br>
<pre><code class="python hljs">image_id = <span class="hljs-number">541</span>
pixel = np.array([<span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">185</span>, <span class="hljs-number">36</span>, <span class="hljs-number">215</span>])<font></font>
model = resnet<font></font>
<font></font>
true_class = y_test[image_id, <span class="hljs-number">0</span>]<font></font>
prior_confidence = model.predict_one(x_test[image_id])[true_class]<font></font>
success = attack_success(pixel, x_test[image_id], true_class, model, verbose=<span class="hljs-literal">True</span>)<font></font>
<font></font>
print(<span class="hljs-string">'Prior confidence'</span>, prior_confidence)<font></font>
print(<span class="hljs-string">'Attack success:'</span>, success == <span class="hljs-literal">True</span>)<font></font>
helper.plot_image(perturb_image(pixel, x_test[image_id])[<span class="hljs-number">0</span>])<font></font>
Confidence: <span class="hljs-number">0.07460087</span>
Prior confidence <span class="hljs-number">0.50054216</span>
Attack success: <span class="hljs-literal">True</span>
</code></pre><br>
<img src="https://habrastorage.org/webt/vh/qb/vp/vhqbvpxy3blhf-krbwmmtezadbu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すべてのパズルを1つの画像にまとめます。</font><font style="vertical-align: inherit;">Scipyでの差分進化の実装の小さな変更を使用します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">attack</span>(<span class="hljs-params">img_id, model, target=None, pixel_count=<span class="hljs-number">1</span>, 
           maxiter=<span class="hljs-number">75</span>, popsize=<span class="hljs-number">400</span>, verbose=False</span>):</span>
    <span class="hljs-comment"># Change the target class based on whether this is a targeted attack or not</span>
    targeted_attack = target <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
    target_class = target <span class="hljs-keyword">if</span> targeted_attack <span class="hljs-keyword">else</span> y_test[img_id, <span class="hljs-number">0</span>]<font></font>
    <font></font>
    <span class="hljs-comment"># Define bounds for a flat vector of x,y,r,g,b values</span>
    <span class="hljs-comment"># For more pixels, repeat this layout</span>
    bounds = [(<span class="hljs-number">0</span>,<span class="hljs-number">32</span>), (<span class="hljs-number">0</span>,<span class="hljs-number">32</span>), (<span class="hljs-number">0</span>,<span class="hljs-number">256</span>), (<span class="hljs-number">0</span>,<span class="hljs-number">256</span>), (<span class="hljs-number">0</span>,<span class="hljs-number">256</span>)] * pixel_count<font></font>
    <font></font>
    <span class="hljs-comment"># Population multiplier, in terms of the size of the perturbation vector x</span>
    popmul = max(<span class="hljs-number">1</span>, popsize // len(bounds))<font></font>
    <font></font>
    <span class="hljs-comment"># Format the predict/callback functions for the differential evolution algorithm</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_fn</span>(<span class="hljs-params">xs</span>):</span>
        <span class="hljs-keyword">return</span> predict_classes(xs, x_test[img_id], target_class, <font></font>
                               model, target <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>)<font></font>
    <font></font>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">callback_fn</span>(<span class="hljs-params">x, convergence</span>):</span>
        <span class="hljs-keyword">return</span> attack_success(x, x_test[img_id], target_class, <font></font>
                              model, targeted_attack, verbose)<font></font>
    <font></font>
    <span class="hljs-comment"># Call Scipy's Implementation of Differential Evolution</span><font></font>
    attack_result = differential_evolution(<font></font>
        predict_fn, bounds, maxiter=maxiter, popsize=popmul,<font></font>
        recombination=<span class="hljs-number">1</span>, atol=<span class="hljs-number">-1</span>, callback=callback_fn, polish=<span class="hljs-literal">False</span>)<font></font>
<font></font>
    <span class="hljs-comment"># Calculate some useful statistics to return from this function</span>
    attack_image = perturb_image(attack_result.x, x_test[img_id])[<span class="hljs-number">0</span>]<font></font>
    prior_probs = model.predict_one(x_test[img_id])<font></font>
    predicted_probs = model.predict_one(attack_image)<font></font>
    predicted_class = np.argmax(predicted_probs)<font></font>
    actual_class = y_test[img_id, <span class="hljs-number">0</span>]<font></font>
    success = predicted_class != actual_class<font></font>
    cdiff = prior_probs[actual_class] - predicted_probs[actual_class]<font></font>
<font></font>
    <span class="hljs-comment"># Show the best attempt at a solution (successful or not)</span><font></font>
    helper.plot_image(attack_image, actual_class, class_names, predicted_class)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> [model.name, pixel_count, img_id, actual_class, predicted_class, success, cdiff, prior_probs, predicted_probs, attack_result.x]
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
調査（攻撃）の結果を共有し、1つのピクセルのみを変更すると、カエルが犬に、猫がカエルに、車が飛行機に変わる方法を確認します。</font><font style="vertical-align: inherit;">ただし、変更できるイメージポイントが多いほど、任意のイメージに対する攻撃が成功する可能性が高くなります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ga/mc/r2/gamcr2jr7fgitczf7wevptkafwa.png"><img src="https://habrastorage.org/webt/hc/df/xg/hcdfxgdnndfgcug3bb4hn9ij6xk.png"><img src="https://habrastorage.org/webt/qn/l_/zj/qnl_zjqfyz67jemvl5fewdbvvii.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
resnetモデルを使用して、カエルのイメージに対する攻撃が成功したことを示します。</font><font style="vertical-align: inherit;">何回か繰り返した後、クラスの真の減少に自信が出るはずです。</font></font><br>
<br>
<pre><code class="python hljs">image_id = <span class="hljs-number">102</span>
pixels = <span class="hljs-number">1</span> <span class="hljs-comment"># Number of pixels to attack</span><font></font>
model = resnet<font></font>
<font></font>
_ = attack(image_id, model, pixel_count=pixels, verbose=<span class="hljs-literal">True</span>)<font></font>
<font></font>
Confidence: <span class="hljs-number">0.9938618</span>
Confidence: <span class="hljs-number">0.77454716</span>
Confidence: <span class="hljs-number">0.77454716</span>
Confidence: <span class="hljs-number">0.77454716</span>
Confidence: <span class="hljs-number">0.77454716</span>
Confidence: <span class="hljs-number">0.77454716</span>
Confidence: <span class="hljs-number">0.53226393</span>
Confidence: <span class="hljs-number">0.53226393</span>
Confidence: <span class="hljs-number">0.53226393</span>
Confidence: <span class="hljs-number">0.53226393</span>
Confidence: <span class="hljs-number">0.4211318</span>
</code></pre><br>
<img src="https://habrastorage.org/webt/a2/bw/rh/a2bwrhij-hnpjshjqcpmigtisyi.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらは対象を絞った攻撃の例でした。次に、対象を絞った攻撃を行い、モデルに画像を分類させたいクラスを選択します。</font><font style="vertical-align: inherit;">ニューラルネットワークで船の画像を車に、馬の画像を猫に分類するため、前のタスクよりもはるかに複雑です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yr/n5/sw/yrn5swb3-4bqoyfujgxz6dfdome.png"><img src="https://habrastorage.org/webt/li/cp/iy/licpiypraj8dcsuxolvh2etbdde.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以下では、船の画像を車として分類するために、lenetを取得しようとします。</font></font><br>
<br>
<pre><code class="python hljs">image_id = <span class="hljs-number">108</span>
target_class = <span class="hljs-number">1</span> <span class="hljs-comment"># Integer in range 0-9</span>
pixels = <span class="hljs-number">3</span><font></font>
model = lenet<font></font>
<font></font>
print(<span class="hljs-string">'Attacking with target'</span>, class_names[target_class])<font></font>
_ = attack(image_id, model, target_class, pixel_count=pixels, verbose=<span class="hljs-literal">True</span>)<font></font>
Attacking <span class="hljs-keyword">with</span> target automobile<font></font>
Confidence: <span class="hljs-number">0.044409167</span>
Confidence: <span class="hljs-number">0.044409167</span>
Confidence: <span class="hljs-number">0.044409167</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.054611664</span>
Confidence: <span class="hljs-number">0.081972085</span>
Confidence: <span class="hljs-number">0.081972085</span>
Confidence: <span class="hljs-number">0.081972085</span>
Confidence: <span class="hljs-number">0.081972085</span>
Confidence: <span class="hljs-number">0.1537778</span>
Confidence: <span class="hljs-number">0.1537778</span>
Confidence: <span class="hljs-number">0.1537778</span>
Confidence: <span class="hljs-number">0.22246778</span>
Confidence: <span class="hljs-number">0.23916133</span>
Confidence: <span class="hljs-number">0.25238588</span>
Confidence: <span class="hljs-number">0.25238588</span>
Confidence: <span class="hljs-number">0.25238588</span>
Confidence: <span class="hljs-number">0.44560355</span>
Confidence: <span class="hljs-number">0.44560355</span>
Confidence: <span class="hljs-number">0.44560355</span>
Confidence: <span class="hljs-number">0.5711696</span>
</code></pre><br>
<img src="https://habrastorage.org/webt/xi/ym/pn/xiympn3dd-xburofpy5tl34yybu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
単一の攻撃のケースに対処した後、畳み込みニューラルネットワークResNetのアーキテクチャを使用して統計を収集し、各モデルを通過して、各画像の1、3、または5ピクセルを変更します。</font><font style="vertical-align: inherit;">この記事では、多くの時間と計算リソースを必要とするため、読者が各反復に慣れるまで煩わされることなく、最終的な結論を示します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">attack_all</span>(<span class="hljs-params">models, samples=<span class="hljs-number">500</span>, pixels=(<span class="hljs-params"><span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span></span>), targeted=False, 
               maxiter=<span class="hljs-number">75</span>, popsize=<span class="hljs-number">400</span>, verbose=False</span>):</span><font></font>
    results = []<font></font>
    <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> models:<font></font>
        model_results = []<font></font>
        valid_imgs = correct_imgs[correct_imgs.name == model.name].img<font></font>
        img_samples = np.random.choice(valid_imgs, samples, replace=<span class="hljs-literal">False</span>)<font></font>
        <font></font>
        <span class="hljs-keyword">for</span> pixel_count <span class="hljs-keyword">in</span> pixels:
            <span class="hljs-keyword">for</span> i, img_id <span class="hljs-keyword">in</span> enumerate(img_samples):<font></font>
                print(<span class="hljs-string">'\n'</span>, model.name, <span class="hljs-string">'- image'</span>, img_id, <span class="hljs-string">'-'</span>, i+<span class="hljs-number">1</span>, <span class="hljs-string">'/'</span>, len(img_samples))<font></font>
                targets = [<span class="hljs-literal">None</span>] <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> targeted <span class="hljs-keyword">else</span> range(<span class="hljs-number">10</span>)<font></font>
                <font></font>
                <span class="hljs-keyword">for</span> target <span class="hljs-keyword">in</span> targets:
                    <span class="hljs-keyword">if</span> targeted:<font></font>
                        print(<span class="hljs-string">'Attacking with target'</span>, class_names[target])
                        <span class="hljs-keyword">if</span> target == y_test[img, <span class="hljs-number">0</span>]:
                            <span class="hljs-keyword">continue</span><font></font>
                    result = attack(img_id, model, target, pixel_count, <font></font>
                                    maxiter=maxiter, popsize=popsize, <font></font>
                                    verbose=verbose)<font></font>
                    model_results.append(result)<font></font>
                    <font></font>
        results += model_results<font></font>
        helper.checkpoint(results, targeted)<font></font>
    <span class="hljs-keyword">return</span> results<font></font>
<font></font>
untargeted = attack_all(models, samples=<span class="hljs-number">100</span>, targeted=<span class="hljs-literal">False</span>)<font></font>
<font></font>
targeted = attack_all(models, samples=<span class="hljs-number">10</span>, targeted=<span class="hljs-literal">False</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ネットワーク不信の可能性をテストするために、アルゴリズムが開発され、パターン認識ソリューションの予測品質への影響が測定されました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最終結果を見てみましょう。</font></font><br>
<br>
<pre><code class="python hljs">untargeted, targeted = helper.load_results()<font></font>
<font></font>
columns = [<span class="hljs-string">'model'</span>, <span class="hljs-string">'pixels'</span>, <span class="hljs-string">'image'</span>, <span class="hljs-string">'true'</span>, <span class="hljs-string">'predicted'</span>, <span class="hljs-string">'success'</span>, <span class="hljs-string">'cdiff'</span>, <span class="hljs-string">'prior_probs'</span>, <span class="hljs-string">'predicted_probs'</span>, <span class="hljs-string">'perturbation'</span>]<font></font>
<font></font>
untargeted_results = pd.DataFrame(untargeted, columns=columns)<font></font>
targeted_results = pd.DataFrame(targeted, columns=columns)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
以下の表は、0.9231の精度でResNetニューラルネットワークを使用して、画像のいくつかのピクセルを変更することで、攻撃に成功した画像（attack_success_rate）の非常に高い割合を取得したことを示しています。</font></font><br>
<br>
<pre><code class="python hljs">helper.attack_stats(targeted_results, models, network_stats)<font></font>
Out[<span class="hljs-number">26</span>]:<font></font>
	model	accuracy   pixels	attack_success_rate<font></font>
<span class="hljs-number">0</span>	resnet	<span class="hljs-number">0.9231</span>	    <span class="hljs-number">1</span>	        <span class="hljs-number">0.144444</span>
<span class="hljs-number">1</span>	resnet	<span class="hljs-number">0.9231</span>	    <span class="hljs-number">3</span>	        <span class="hljs-number">0.211111</span>
<span class="hljs-number">2</span>	resnet	<span class="hljs-number">0.9231</span>	    <span class="hljs-number">5</span>	        <span class="hljs-number">0.222222</span><font></font>
<font></font>
helper.attack_stats(untargeted_results, models, network_stats)<font></font>
Out[<span class="hljs-number">27</span>]:<font></font>
	model	accuracy   pixels	attack_success_rate<font></font>
<span class="hljs-number">0</span>	resnet	<span class="hljs-number">0.9231</span>	   <span class="hljs-number">1</span>	        <span class="hljs-number">0.34</span>
<span class="hljs-number">1</span>	resnet	<span class="hljs-number">0.9231</span>	   <span class="hljs-number">3</span>	        <span class="hljs-number">0.79</span>
<span class="hljs-number">2</span>	resnet	<span class="hljs-number">0.9231</span>	   <span class="hljs-number">5</span>	        <span class="hljs-number">0.79</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
現在、非常に多くの人工ニューラルネットワークが存在するため、実験では人工ニューラルネットワークの他のアーキテクチャを自由に使用できます。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ta/lw/tv/talwtvpnwkzp2od0p-8q9o28eli.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークは、現代の世界を目に見えないスレッドで覆っています。長い間、AI（人工知能）を使用して、ユーザーが優れたアーティストの作品に似たスタイルで処理された写真を受け取るサービスが発明されてきました。現在、アルゴリズム自体が絵を描き、音楽の傑作を作成し、本を書き、映画の脚本さえ作成することができます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
コンピュータービジョン、顔認識、無人車両、病気の診断などの分野は、重要な決定を行い、間違いを犯す権利はありません。アルゴリズムの操作を妨害すると、悲惨な結果を招きます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1ピクセル攻撃は、攻撃を偽装する1つの方法です。</font><font style="vertical-align: inherit;">ネットワーク不信の可能性をテストするために、アルゴリズムが開発され、パターン認識ソリューションの予測品質への影響が測定されました。</font><font style="vertical-align: inherit;">その結果、ニューラルネットワークの適用された畳み込みアーキテクチャは、認識アルゴリズムの信用を傷つけるために、1ピクセルを置き換える特別にトレーニングされた1ピクセル攻撃アルゴリズムに対して脆弱であることが示されました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
記事をすることにより調製した</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アレクサンダーAndronic</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adrey Cherny-Tkach</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">でのインターンシップの一環として</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DATA4</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja498094/index.html">社内のすべての通信をオンラインに転送した方法</a></li>
<li><a href="../ja498096/index.html">メモリーズデモが256バイトに収まる方法</a></li>
<li><a href="../ja498100/index.html">Kubernetesクラスタの設計：いくつあるべきですか？</a></li>
<li><a href="../ja498104/index.html">100,000ドルからサイトを開発する方法</a></li>
<li><a href="../ja498110/index.html">「プロセスの劇的な変化がチームをやる気にさせたときに何をすべきか」チームリーダーになったバックエンドエンジニアの体験</a></li>
<li><a href="../ja498118/index.html">リモートでの会議：JUG Ruグループのオンライン変換</a></li>
<li><a href="../ja498120/index.html">ビルド時間の最適化-パート1</a></li>
<li><a href="../ja498122/index.html">製品とあなたの人生を台無しにしないようにリモートサイトでテストする方法</a></li>
<li><a href="../ja498124/index.html">テクニカルサポートのための電報：ツールと落とし穴</a></li>
<li><a href="../ja498126/index.html">アマゾンが人々に購入してもらう方法...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëéüèº ü§¶üèø ü§∞üèæ The semantic web myth üë∞üèø ‚óΩÔ∏è ü§Æ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the field of semantic modeling, a rather strange situation has developed: a set of standards and specifications from W3C used for the ‚Äúsemantic web...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>The semantic web myth</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/502628/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the field of semantic modeling, a rather strange situation has developed: a set of standards and specifications from W3C used for the ‚Äúsemantic web‚Äù project (RDF / OWL, SPARQL, etc.) is used as the basic ones, although the project itself is not only not implemented at the moment, but and, apparently, will never be embodied due to the doubtfulness of the original hypotheses.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The semantic web was thought by its author Tim Berners Lee as the next stage in the development of the Internet. The idea was quite rational: you need to connect all the network resources not with meaningless links that send the user from one page to another, but with meaningful (semantic) connections. For this, it was proposed to assign each online and even offline entity (object, property) a unique identifier and combine these entities into a single graph. After that, users could quickly and accurately find the information they need, and most importantly, computers would gain access to the semantic content of the network. That is, the goal was to create a distributed knowledge graph that connects semantically defined data in a single network space, with the possibility of machine processing and logical inference of new facts.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The idea of ‚Äã‚Äãa semantic network described above looks not only relevant, relevant, but also quite feasible using modern technologies - such as peer-to-peer networks with attack-resistant consensus algorithms, cryptographic user identification and cryptographic data protection. But the founders of the project initially made dubious architectural and ideological decisions that left the semantic web in the status of a beautiful dream.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since the main goal of creating a semantic web was the sharing of information on the Internet, this Internet was chosen as the technological platform of the project, that is, a chaotic dump of sites whose content is controlled not by authors, but by domain owners. Orientation to a modern network has necessarily determined the basic principles of the project: (1) using an Internet address as a basis for resource identifiers (URIs), (2) the ability of anyone to make an assertion about any resource, (3) the assumption of an open world, that is, incompleteness information. These principles were the main problems.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First of all, it is obvious that Internet addresses are not something that can serve as the basis for identifying entities. A domain can change its owner, it can be abandoned, and it‚Äôs just not technically available. The structure of names within a domain can be arbitrarily changed. Not to mention that many diverse technologies and engines, on the basis of which the sites are built, do not adhere to any standards for the formation of addresses.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But the main formal reason for the failure of the semantic web project should be recognized as the second basic principle, that is, the hope that the owners of the sites will build a single network semantic graph. Although even at the inception of the project idea, it was obvious that website owners would go to any forgery to deceive search robots (even writing invisible text on pages and manipulating keywords). Among those who honestly would like to perform semantic markup of pages, only a few would cope with the task. But even in the ideal case, if a semantic network had been competently thrown on all existing sites, the project would still not have worked. After all, then the obvious would have been revealed: we are dealing with hundreds and thousands of duplicates of the same resource (text, image,video) with different identifiers (addresses). And besides, most instances of one entity would not have the same properties, because "anyone has the right to make a statement about any resource." Well, it‚Äôs clear that it‚Äôs not possible to find the author‚Äôs original among these copies.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And of course, big problems arose with the third principle, proclaiming the presumption of the open world, that is, implying the possibility of free addition of facts to the general network. Let us dwell on it in more detail.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, the idea of ‚Äã‚Äãan open world is inherited from the standard Internet, where everyone is free to add any domains, pages, entities and link to any other entities. But the semantic graph differs from the link network in that it must establish logical, ideally formally verifiable, relationships between statements about entities, and therefore, in order to be consistent, it must be closed. The compiler of the semantic graph, modeling a certain fragment of the subject area, should proceed from a strict conceptual scheme in which the ambiguity of terminology, the uniqueness of identifiers, and, moreover, the arbitrary addition of statements by any actors are fundamentally unacceptable. That is, if we talk about the openness of the logical world,then this openness should imply the free addition of new closed models to the graph, rather than arbitrary facts. The network should be composed of independent subject and level ontologies, the interaction between which is ensured by the use of common dictionaries. It is necessary to strictly separate two tasks: (1) constructing the ontology of the subject area and (2) solving the problem of interaction / correlation of different ontologies, that is, matching identifiers of entities, naming types and logical constraints to coordinate data exchange.(1) constructing the ontology of the subject domain; and (2) solving the problem of interaction / correlation of different ontologies, i.e., matching identifiers of entities, naming types, and logical constraints to coordinate data exchange.(1) constructing the ontology of the subject area; and (2) solving the problem of the interaction / correlation of different ontologies, i.e., matching identifiers of entities, naming types, and logical constraints to coordinate data exchange.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It should also be recognized as an erroneous decision and the orientation of the semantic web project towards creating the only true, consistent graph constructed according to the canons of formal (monotonic) logic. One can still agree with this approach when building a fixed knowledge base in some practically completed subject areas (geography, engineering standards, etc.). However, an ontology modeling tool is needed not to describe static structures, but to support the functioning of real complex systems in which the monotonicity and consistency of the description are unattainable not only during their formation, but also in the final state. It is worth recognizing that the occurrence of an error in building a system is a fact that changes its state, and ignoring this fact can lead to disastrous consequences.That is, the logic of the semantic graph should not be monotonic. And here it should be remembered that the authors of the idea of ‚Äã‚Äãthe semantic web were not the only ones who stepped on the rake of a single ontology - after many years of trying to build a single consistent semantic space, the well-known CYC project abandoned this idea and switched to working with microtheories - locally closed ontologies of individual subject areas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In fact, the mistake in designing the semantic web tools was that the difference between the two tasks was not identified and taken into account. The first is the creation of a local ontology of the domain: adding statements validated by local (offline and online) means into it, the logical derivation of new statements according to the rules built into the local ontology. The second is the connection of local ontologies into a single network graph and an attempt to obtain conclusions from a variety of independent data. Obviously, even if all network data sources use the same dictionaries and each of them is logically flawless in itself, the answers received for queries to the aggregate graph (if at all possible) will have a fundamentally different reliability status compared to the results obtained in each local ontology.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The described difference in working with local ontologies and a common semantic graph can be formally expressed in terms of the openness of the world: a request to the network should be based on the presumption of the openness of the world, and the logic of working with local ontologies will most often be based on the closed-world hypothesis. </font><font style="vertical-align: inherit;">We can say that the world should be open, but not for individual statements, but for holistic ontologies. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So it turns out that the W3C standards continue to be developed for the mythical semantic web, and everyone who tries to use them in real projects, that is, to create ontologies of subject areas, are forced to constantly come up with crutches to get a working product. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(Continued </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">myths of semantic technology</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en502608/index.html">How we started the marketplace of applications in the SaaS service</a></li>
<li><a href="../en502614/index.html">Kubernetes best practices. Setting Queries and Resource Limits</a></li>
<li><a href="../en502620/index.html">Money accounting</a></li>
<li><a href="../en502624/index.html">How do they work on Facebook? Values ‚Äã‚Äãand hiring in a company</a></li>
<li><a href="../en502626/index.html">Automatic iOS screenshots using XCTestplan and Xcode 11</a></li>
<li><a href="../en502630/index.html">Mail that you deleted a couple of years ago can still be stored on your smartphone</a></li>
<li><a href="../en502634/index.html">Telemedicine. Three technology startups. The product is one, but different fates</a></li>
<li><a href="../en502636/index.html">Business and cyberpunk: mix, sustain, use</a></li>
<li><a href="../en502638/index.html">How to develop a blog on Instagram in 2020: analysis of the case of Sasha Mitroshina</a></li>
<li><a href="../en502642/index.html">Putting the game "Snake" on the breadboard. Part 2: ‚Äúvector‚Äù display</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
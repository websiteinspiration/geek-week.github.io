<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐉 😁 🥥 Comment nous reconnaissons les équipements de protection individuelle 👩🏼‍🚒 👨‍🎤 🌯</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vous vous êtes probablement demandé toute votre vie comment former un réseau de neurones pour reconnaître les gens dans les casques et les gilets oran...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Comment nous reconnaissons les équipements de protection individuelle</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/499248/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous vous êtes probablement demandé toute votre vie comment former un réseau de neurones pour reconnaître les gens dans les casques et les gilets orange! Non? Mais nous vous le dirons quand même. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notre nom est Tatyana Voronova et Elvira Dyaminova. Nous sommes engagés dans l'analyse des données dans la société Center 2M, nous travaillons beaucoup avec les usines et les entreprises les plus réelles. En raison de violations de la sécurité, ils subissent des pertes de plusieurs millions de dollars, les employés sont blessés, il serait donc agréable de pouvoir détecter de telles violations de manière systématique et le plus tôt possible. Le meilleur de tous - automatiquement. Nous avons donc des problèmes liés à la reconnaissance des équipements de protection individuelle (EPI) sur vidéo et à l'identification des personnes ou des équipements dans la zone de danger.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/2u/-q/gv2u-qjuorn0awf-hlwjbuu3dc4.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour la plupart, des commandes nous parviennent pour déterminer les casques (plus précisément leur absence) et les vêtements de travail. </font><font style="vertical-align: inherit;">Nous avons déjà acquis de l'expérience dans l'exécution de ces tâches et nous pouvons maintenant décrire les problèmes que nous avons rencontrés et comment les résoudre.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Étant donné que, selon les termes de la coopération, nous n'avons pas le droit de publier des images des objets du client, nous illustrerons l'article avec des images d'Internet, sur lesquelles les casques sourient souvent et ont fière allure. </font><font style="vertical-align: inherit;">Malheureusement, dans le domaine public pas pour toutes les caractéristiques des tâches auxquelles nous sommes confrontés en réalité, vous pouvez trouver de bons exemples. </font><font style="vertical-align: inherit;">En particulier, dans la vie, les casques sont moins susceptibles de sourire et le problème des chauves (nous en reparlerons un peu plus tard) sur Internet n'est pas vraiment révélé! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Image provenant d'Internet (taille 1920x1280):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/f9/9q/nb/f99qnblemmbik0caykgir0zfiag.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La reconnaissance des EPI peut être réduite à l'un des deux problèmes classiques de la vision par ordinateur: la classification des images et la détection des objets. Dans la pratique, il s'est avéré préférable de ne pas utiliser l'une de ces approches, mais de choisir la plus adaptée à chaque cas particulier, ainsi que de les combiner de manière flexible. Par exemple, on peut d'abord déterminer où se trouvent les personnes sur l'image, puis classer les images découpées par silhouette en classes «en tenue de travail» et «sans», et détecter la présence d'un casque lors du deuxième passage. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur des figures de personnes prédécoupées, la classification de la présence de casques et de vêtements de travail ressemble à ceci (vue de la photo originale): </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le résultat du travail des modèles pour la classification des vêtements de travail et des casques</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/su/ad/lg/suadlgvrpviurbpxflbg6y3bm8s.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur les mêmes figures humaines préalablement sélectionnées, l'application de l'approche cette fois avec détection pour casques. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le résultat du modèle de classification des vêtements de travail et d'un modèle de détection des casques:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/jb/8l/qjjb8lebwt3t-6xttueihk2gaqw.jpeg" alt="image"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Première étape: détection humaine</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La qualité de définition des petits objets (casques / lunettes / gants) sur les grands cadres est telle. Il est beaucoup plus facile pour un ordinateur, comme une personne, de comprendre d’abord où se trouvent les gens, puis de comprendre ce qu’ils portent. Donc, tout commence par l'identification des personnes dans le cadre. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À la suite des expériences, nous avons découvert que le réseau de neurones F-R plus rapide avec Inception v2 comme extraction de caractéristiques est bien adapté à la détection de personnes. TensorFlow dispose déjà de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réseaux de neurones pré-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> formés </font><font style="vertical-align: inherit;">pour détecter des objets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour nous, Faster R-CNN Inception v2 (formé sur le jeu de données COCO) est la méthode de base que nous essayons en premier pour résoudre de tels problèmes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans un premier temps, nous détectons des personnes sur le cadre (puis sur les personnes trouvées, nous trouvons des EPI):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/xp/gy/ukxpgyllgs-olfg9xgbpmzkuwly.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notez que nous avons augmenté la boîte englobante «avec une personne» le long de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'axe y</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/8x/dp/ad8xdpfnx8f1fke9afg9u5q-9xs.jpeg" alt="image"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sur cette photo, le travailleur a été photographié sous un bon éclairage et sur un fond contrasté (avec des images trouvées sur Internet, cela se produit tout le temps). </font><font style="vertical-align: inherit;">Par conséquent, la boîte englobante avec la personne était bien construite. </font><font style="vertical-align: inherit;">Cependant, dans notre pratique, il y a des cas fréquents (surtout dans des conditions de visibilité insuffisante) où le modèle de détection coupe un casque chez une personne, après quoi il est inutile de le chercher sur une image recadrée. </font><font style="vertical-align: inherit;">À cet égard, le long de l'axe y, nous augmentons le cadre de délimitation prévu de 15% avant de passer à la deuxième étape.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors de la détection de personnes, nous rencontrons de petits problèmes désagréables. Premièrement, lorsque deux personnes marchent ou se tiennent l'une derrière l'autre, elles commencent souvent à être détectées comme une seule personne. Deuxièmement, il arrive qu'un objet statique entre dans le champ de vision de la caméra, dans lequel le modèle peut reconnaître une personne, comme une bouche d'incendie. Ces problèmes peuvent être résolus de différentes manières. Par exemple, comment nous l'avons fait: conciliez-les et acceptez-les, car en général, le modèle nous convient en termes de productivité et de qualité. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un problème plus fondamental est que les locaux industriels dans lesquels il y a une «zone de danger» sont souvent énormes et, par conséquent, les personnes dans les cadres sont très petites. Notre méthode de base basée sur Faster R-CNN Inception v2 a montré de mauvais résultats dans de tels cas, et à la fin nous avons essayé</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R-CNN Nas plus rapide</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Les résultats étaient impressionnants, les gens étaient bien reconnus même à distance, mais la vitesse était bien inférieure à celle du modèle de base. </font><font style="vertical-align: inherit;">Avec des ressources suffisantes et le besoin d'une grande précision, vous pouvez utiliser </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faster R-CNN Nas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deuxième étape: détermination des contrevenants malveillants</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selon la tâche, les éléments suivants sont souvent utilisés:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modèle de classification d'images - Inception v3</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modèle de détection d'objets - Création plus rapide de R-CNN v2</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification des vêtements de travail et des casques</font></font></h3> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons testé différentes architectures de réseaux de neurones pour classer les images, et nous nous sommes finalement tournés vers Inception v3, décidant de tirer parti du fait qu'il est conçu pour fonctionner avec des tailles d'images variables. Nous avions déjà beaucoup de photos découpées avec des gens, et il n'était pas difficile de calculer les valeurs médianes pour la hauteur et la largeur. Nous sommes donc arrivés à la conclusion que pour la formation des classificateurs, nous avons commencé à apporter des images à une taille de 150x400.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Afin de former le réseau à reconnaître les EPI, tout d'abord, il est nécessaire de collecter un ensemble de données à partir d'exemples étiquetés. </font><font style="vertical-align: inherit;">Dans ce processus, il y a des subtilités, dont la réalisation vient avec l'expérience. </font><font style="vertical-align: inherit;">Par exemple, il est préférable de supprimer les personnes coupées au-dessus des hanches de l'ensemble de données. </font><font style="vertical-align: inherit;">Cela rapprochera l'ensemble de données des conditions réelles, car la plupart du temps, les gens sont vus à pleine hauteur sur la vidéo des caméras de surveillance. </font><font style="vertical-align: inherit;">Bien entendu, des cas de chevauchement se produisent également, mais les silhouettes complètes de l'échantillon cible sont beaucoup plus caractéristiques. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Exemples de notre ensemble de données de vêtements de travail:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/k8/22/sh/k822shy7m4ddtteqqjp1mfs09b8.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous n'avons rien inventé de spécifique en tant que métrique, nous utilisons le rappel et la précision. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modèle de classification de la présence / absence de vêtements de travail: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">résultats sur un échantillon de validation</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/lw/ql/hu/lwqlhu_7-efmfxzrxug-d64pafq.jpeg" alt="image"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Détection d'EPI</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le modèle de classification fonctionne plus rapidement que le modèle de détection d'objets, mais étant donné que les lunettes de sécurité et les gants sont petits dans l'image, il est difficile de créer un bon classificateur pour un tel EPI. </font><font style="vertical-align: inherit;">Par conséquent, nous avons formé le réseau neuronal Faster R-CNN sur un ensemble de données avec six classes:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lunettes / pas_lunettes</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gants / pas_gants</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">casque / not_helmet</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/pw/iy/i_/pwiyi_nep5v7k8wlrz6yxvz8ug4.jpeg" alt="image"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Collecte et balisage des données</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les principaux problèmes étaient liés à l'ensemble de données des casques. C'était une manière fascinante: nous sommes passés par des gens chauves, des gens avec des casques à la main, et même par des gens chauves avec des casques à la main. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Puisqu'au tout début du voyage, nous n'avions pas beaucoup d'images dans des conditions réelles, nous avons collecté le jeu de données du mieux que nous pouvions: nous filmer, prendre des images sur Internet ou sur des chantiers. Un peu plus tard, nous avons commencé à recevoir beaucoup de vidéos de diverses entreprises, nous avons donc commencé à enrichir l'ensemble de données uniquement avec des images de conditions réelles. À un moment donné, le nombre d'images marquées a dépassé 5k, et la qualité de l'ajout de nouveaux exemples a cessé de s'améliorer, à cet égard, nous avons révisé l'approche du balisage.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous décrirons les étapes de l'amélioration de l'ensemble de données du casque en utilisant l'exemple d'images provenant d'Internet, donc l'angle et la qualité ne correspondent pas tout à fait à ce que nous avions. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En plus de l'image ci-dessus, recadrée au-dessus des hanches, nous avons supprimé les images dans lesquelles les casques sont recadrés plus de la moitié pour éviter toute confusion avec les casquettes.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/zh/eu/dlzheusrhwz0grtyrxdxalkkupq.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons également été confrontés au fait que si une personne a un casque dans les mains, le modèle ne voit souvent aucune violation: y a-t-il un casque? Il y a. Par conséquent, nous avons supprimé de l'ensemble de données d'entraînement toutes les images dans lesquelles une personne tient un casque avec sa main, même si le casque est sur sa tête à ce moment. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En général, nous avons essayé de supprimer les images avec un fond éclairé ou dans des pièces sombres, puis nous avons minimisé le nombre de photos prises par nous, en laissant principalement des images de la production. En conséquence, nous avons réduit de moitié l'ensemble de données. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, nous avons enrichi l'ensemble de données avec des personnes chauves, sinon elles seront toujours dans des casques, même si ce n'est pas le cas, et avec des blondes avec des carrés, pour lesquelles, avec un certain angle, le détecteur détermine également le casque.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Après avoir supprimé les images inappropriées, nous avons procédé directement au balisage (pour détecter les objets). Il s'est avéré que ce n'était pas si simple. Il s'avère que la qualité du détecteur final dépend en grande partie de ce que exactement la zone dans l'image est marquée comme "casque" ou "gants". Au départ, nous avons attribué des casques et des lunettes sans saisir les visages et des gants avec les mains saisissantes. Cependant, avec l'expérience, nous avons progressivement amélioré notre approche en examinant les erreurs du premier et du deuxième type, où les gens tiennent un casque dans leurs mains, et quelque chose de rond sur quelque chose de long se révèle être un «gant». Maintenant, lors du marquage des casques et des lunettes, nous essayons de saisir le visage jusqu'au bout du nez, et lors du marquage des gants, au contraire, nous nous sommes limités à une brosse.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/us/re/kausredcadkqks_cn012broh2qq.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À la suite de nos manipulations sur l'ensemble de données, nous avons obtenu les résultats suivants. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modèle de détection de la présence / absence d'EPI en utilisant des casques à titre d'exemple: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">résultats sur un échantillon de validation avant le début du «travail global» sur l'ensemble de données</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/oo/rx/k-/oorxk-v05lijjyljtrp5lvtbsq4.jpeg" alt="image"></div><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Résultats finaux sur l'échantillon de validation</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/y1/nn/0u/y1nn0uy66v5qmwji-zk2rwotnle.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'intégralité de la reconnaissance des casques s'est légèrement affaiblie, mais en même temps, les mesures de détection des violations se sont améliorées, et c'est ce que nous voulions atteindre. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modèle de classification de la présence / absence de casques: </font></font><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">résultats sur un échantillon de validation avant le début du «travail global» sur l'ensemble de données</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wi/eu/fp/wieufpwnxltfvgf1kvkvisr3fk4.jpeg" alt="image"></div><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Résultats finaux sur l'échantillon de validation</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ct/d1/etctd1ymh_9jmjvc3lgaz_mw47o.jpeg" alt="image"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il est à noter que nous n'avons pas de division en lunettes et lunettes pour la vision, elles passent sous le même tag «lunettes», et les gants de teintes claires peuvent être perçus comme une brosse nue. </font><font style="vertical-align: inherit;">Nous avons essayé de maximiser la gamme de couleurs des casques et des vêtements de travail dans nos jeux de données, mais pour plus de fiabilité, nous y avons ajouté la technique la plus simple et la plus fiable: si nécessaire, pour détecter les gants, nous disons aux clients que les couleurs vives aident à augmenter la précision. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À l'heure actuelle, nous avons des modèles universels que nous utilisons pour le salon initial pour le client. </font><font style="vertical-align: inherit;">Cependant, il faut comprendre qu'il est impossible de créer un modèle universel pour tout le monde, il faut s'adapter à chaque client, identifier et prendre en compte de nouvelles nuances, enrichir les jeux de données ou les recréer pour répondre à des besoins spécifiques.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/kl/-l/9t/kl-l9tfsjdr528i4xgl5flmtqjk.jpeg" alt="image"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prime</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En règle générale, les clients souhaitent traiter autant de caméras que possible, en utilisant le moins de ressources possible. </font><font style="vertical-align: inherit;">Le butch, bien sûr, est une bonne chose, mais des astuces supplémentaires pour optimiser le processus ne sont pas interdites. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par exemple, mes collègues et moi du centre client IBM de Moscou avions l'hypothèse que le regroupement de plusieurs personnes pour détecter davantage les casques augmenterait le nombre de caméras par serveur avec une perte de précision sans principe. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme base, nous avons décidé de prendre la taille de 1000x600 pour la toile sur laquelle les gens seront "appliqués". </font><font style="vertical-align: inherit;">Deux options de mise en page ont été initialement envisagées:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Largeur et hauteur fixes (200x600), avec cette approche, il y a 5 personnes sur le cadre.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Largeur et hauteur fixes (125x600), 8 personnes.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cette décision est due au fait qu'avec des données fixes, nous connaissons exactement le nombre de personnes sur la photo, ce qui nous donne une prévision de la charge. </font><font style="vertical-align: inherit;">Cependant, au cours du développement, nous avons envisagé une telle option:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hauteur fixe et largeur proportionnelle (*** x600), nombre de personnes différent.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On a supposé qu'avec l'augmentation des tailles et le maintien des proportions, les résultats seraient meilleurs par rapport à d'autres options de mise en page. </font><font style="vertical-align: inherit;">Le nombre de personnes variait de 3 à 5 (+/–). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En conséquence, nous avons obtenu que l'option avec une largeur et une hauteur fixes (200x600) soit la meilleure parmi celles considérées. </font><font style="vertical-align: inherit;">Bien sûr, cette méthode ne convient pas pour détecter des lunettes et des gants, car les objets sont petits, mais pour détecter des casques / manque de casques, cette méthode a donné de bons résultats. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par exemple, dans un échantillon de validation:</font></font></i><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/wg/zy/arwgzypgxzuk6ykdrj57p851-co.jpeg" alt="image"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lw/y5/iilwy5ihzrc57ezgdnjp3gs646s.jpeg" alt="image"></div><br>
<i> :   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">tvoronova</a>),  (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">elviraa</a>)</i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr499238/index.html">Soudure à domicile: enregistrement de flux</a></li>
<li><a href="../fr499240/index.html">À travers les épines jusqu'aux étoiles ou l'analyse des données dans les affaires du ciel</a></li>
<li><a href="../fr499242/index.html">Les chercheurs ont transmis des données à partir d'un ordinateur de bureau via des vibrations sur une table</a></li>
<li><a href="../fr499244/index.html">Organisations synergiques. Partie II</a></li>
<li><a href="../fr499246/index.html">Enquête sur la fonction logistique en tant que loi de développement de l'industrie</a></li>
<li><a href="../fr499252/index.html">Création d'un jeu de course pseudo-tridimensionnel</a></li>
<li><a href="../fr499254/index.html">Un membre du comité du programme PyConRu 2020 répond aux questions sur Python: un look à jour et un peu de fourchelang</a></li>
<li><a href="../fr499262/index.html">Dernier hackathon en ligne pour les indépendants SMZhack: des projets qui toucheront les gens</a></li>
<li><a href="../fr499268/index.html">Conscience spatiale: que peuvent faire les lunettes Hololens?</a></li>
<li><a href="../fr499272/index.html">Composants de soudure 0201. Nerveux, veuillez vous éloigner des écrans</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
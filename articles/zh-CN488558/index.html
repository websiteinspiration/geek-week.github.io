<!doctype html>
<html class="no-js" lang="zh-CN">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥑 🧚🏼 👩🏼 使用Kafka Streams确保应用程序的高可用性 🏣 🏆 👩🏽‍🚀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kafka Streams是一个Java库，用于分析和处理存储在Apache Kafka中的数据。与任何其他流处理平台一样，它能够实时执行带有和/或不带有状态保存的数据处理。在这篇文章中，我将尝试描述为何在Kafka Streams中实现高可用性（99.99％）是有问题的，以及我们可以做些什么。
 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>使用Kafka Streams确保应用程序的高可用性</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488558/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams是一个Java库，用于分析和处理存储在Apache Kafka中的数据。</font><font style="vertical-align: inherit;">与任何其他流处理平台一样，它能够实时执行带有和/或不带有状态保存的数据处理。</font><font style="vertical-align: inherit;">在这篇文章中，我将尝试描述为何在Kafka Streams中实现高可用性（99.99％）是有问题的，以及我们可以做些什么。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们需要知道什么</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在描述问题和可能的解决方案之前，让我们看一下Kafka Streams的基本概念。</font><font style="vertical-align: inherit;">如果您使用过面向消费者/生产者的Kafka API，那么您对这些范例中的大多数都是熟悉的。</font><font style="vertical-align: inherit;">在以下各节中，我将尝试用几个词来描述分区中的数据存储，消费者组的重新平衡以及Kafka客户端的基本概念如何适合Kafka Streams库。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka：分区数据</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在Kafka世界中，生产者应用程序将数据作为键值对发送到特定主题。</font><font style="vertical-align: inherit;">该主题本身在Kafka经纪人中分为一个或多个分区。</font><font style="vertical-align: inherit;">Kafka使用消息键指示应将数据写入哪个分区。</font><font style="vertical-align: inherit;">因此，具有相同密钥的消息始终以同一分区结尾。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
消费者应用程序分为多个消费者组，每个组可以有一个或多个消费者实例。 </font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">消费者组中消费者的每个实例负责处理来自输入主题的唯一分区集合的数据。</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
使用者实例本质上是在一组使用者中扩大处理量的一种方法。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">卡夫卡：重新平衡消费群体</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
如前所述，使用者组的每个实例都接收一组唯一的分区，并从中消费数据。</font><font style="vertical-align: inherit;">每当新的消费者加入一个小组时，都必须进行重新平衡，以便获得一个分区。</font><font style="vertical-align: inherit;">当使用者死亡时，会发生同样的事情，其余的使用者应使用其分区以确保所有分区都得到处理。</font></font><br>
<cut></cut><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams：流</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在本文的开头，我们熟悉了一个事实，即Kafka Streams库是基于生产者和消费者的API构建的，并且数据处理的组织方式与Kafka上的标准解决方案相同。在Kafka Streams配置中，</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">字段</font><font style="vertical-align: inherit;">等效于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">group.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在使用者API中。 Kafka Streams会预先创建一定数量的线程，并且每个线程都会从一个或多个输入主题分区中执行数据处理。用消费者API的术语来说，流实质上与来自同一组的消费者实例重合。线程是扩展Kafka Streams中数据处理的主要方法，可以通过增加一台计算机上每个Kafka Streams应用程序的线程数来垂直完成此操作，或者通过添加具有相同application.id的另一台计算机来水平执行此操作。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bb7/bd3/8ed/bb7bd38edd33f26a146c12a1dea385b5.jpg" alt="图片"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
资料来源：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kafka.apache.org/21/documentation/streams/architecture</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kafka Streams中还有许多其他元素，例如任务，处理拓扑，线程模型等，我们将不在本文中讨论。</font><font style="vertical-align: inherit;">可以在</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">此处</font></a><font style="vertical-align: inherit;">找到更多信息</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams：状态存储</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在流处理中，存在带有或不带有状态保存的操作。</font><font style="vertical-align: inherit;">状态使应用程序能够记住超出当前正在处理的记录范围之外的必要信息。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
状态操作（例如计数，任何类型的聚合，联接等）要复杂得多。这是由于只有一条记录，您无法确定给定键的最后状态（例如，计数），因此您需要将流的状态存储在应用程序中。如前所述，每个线程处理一组唯一的分区；因此，一个线程仅处理整个数据集的一个子集。这意味着每个具有相同application.id的Kafka Streams应用程序线程都保持其自己的隔离状态。我们不会详细介绍状态在Kafka Streams中的形成方式，但重要的是要了解使用状态更改主题（更改日志主题）来还原状态，不仅将状态保存在本地磁盘上，而且还保存在Kafka Broker中。将状态更改日志保存在Kafka Broker中作为一个单独的主题不仅是为了容错，而且还可以使您轻松地使用相同的application.id部署Kafka Streams的新实例。由于状态在代理方面存储为更改日志主题，因此新实例可以从该主题加载其自己的状态。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
有关状态存储的更多信息，请参见</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">此处</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">为什么高可用性对Kafka Streams有问题？</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我们回顾了使用Kafka Streams进行数据处理的基本概念和原理。</font><font style="vertical-align: inherit;">现在，让我们尝试将所有部分组合在一起，并分析为什么实现高可用性可能会带来问题。</font><font style="vertical-align: inherit;">在前面的部分中，我们必须记住：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kafka主题中的数据分为多个分区，这些分区分布在Kafka Streams流之间。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 实际上，具有相同application.id的Kafka Streams应用程序是一组使用者，并且其每个线程都是使用者的独立隔离实例。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 对于状态操作，线程维护其自己的状态，该状态由Kafka主题以更改日志的形式“保留”。</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br>
<h2>TransferWise SPaaS (Stream Processing as a Service)</h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在强调这篇文章的本质之前，让我首先告诉您我们在TransferWise中创建的内容以及为什么高可用性对我们非常重要。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在TransferWise中，我们有多个用于流处理的节点，每个节点包含每个产品团队的多个Kafka Streams实例。专为特定开发团队设计的Kafka Streams实例具有特殊的application.id，通常具有5个以上的线程。通常，团队在整个集群中通常具有10-20个线程（相当于使用者的实例数）。部署在节点上的应用程序侦听输入主题，并在输入数据有状态和无状态的情况下执行几种类型的操作，并为后续的下游微服务提供实时数据更新。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
产品团队需要实时更新汇总数据。</font><font style="vertical-align: inherit;">为了使我们的客户能够立即转账，这是必要的。</font><font style="vertical-align: inherit;">我们通常的SLA：</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在任何给定的一天中，应在不到10秒的时间内获得99.99％的汇总数据。</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
为了给您一个想法，在压力测试期间，Kafka Streams每秒能够处理和聚合20,085条输入消息。</font><font style="vertical-align: inherit;">因此，在正常负载下10秒的SLA听起来是可以实现的。</font><font style="vertical-align: inherit;">不幸的是，在滚动部署应用程序的节点的更新过程中未达到我们的SLA，下面我将描述发生这种情况的原因。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">滑动节点更新</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在TransferWise，我们坚信软件的持续交付，并且通常每天发布两次新版本的服务。</font><font style="vertical-align: inherit;">让我们看一个简单的连续服务更新的示例，看看发布过程中发生了什么。</font><font style="vertical-align: inherit;">同样，我们必须记住：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka主题中的数据分为多个分区，这些分区分布在Kafka Streams流之间。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">实际上，具有相同application.id的Kafka Streams应用程序是一组使用者，并且其每个线程都是使用者的独立隔离实例。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">对于状态操作，线程维护其自己的状态，该状态由Kafka主题以更改日志的形式“保留”。</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在单个节点上的释放过程通常需要八到九秒钟。</font><font style="vertical-align: inherit;">在发行期间，节点上的Kafka Streams实例会“缓慢重启”。</font><font style="vertical-align: inherit;">因此，对于单个节点，正确重新启动服务所需的时间大约为8到9秒。</font><font style="vertical-align: inherit;">显然，关闭节点上的Kafka Streams实例会导致使用者组重新平衡。</font><font style="vertical-align: inherit;">由于数据已分区，因此属于可启动实例的所有分区必须在具有相同application.id的活动Kafka Streams应用程序之间分配。</font><font style="vertical-align: inherit;">这也适用于已保存到磁盘的聚合数据。</font><font style="vertical-align: inherit;">在此过程完成之前，将不会处理数据。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">备用副本</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
为了减少Kafka Streams应用程序的重新平衡时间，有一个备份副本的概念，该副本在配置中定义为num.standby.replicas。备份副本是本地状态存储的副本。这种机制可以将状态存储从一个Kafka Streams实例复制到另一个实例。当Kafka Streams线程由于任何原因终止时，状态恢复过程的持续时间可以最小化。不幸的是，由于我将在下面解释的原因，即使备份副本也无法帮助滚动服务更新。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
假设我们在两台不同的机器上有两个Kafka Streams实例：node-a和node-b。</font><font style="vertical-align: inherit;">对于每个Kafka Streams实例，在这2个节点上指示num.standby.replicas = 1.通过这种配置，每个Kafka Streams实例在另一个节点上维护自己的存储库副本。</font><font style="vertical-align: inherit;">在滚动更新中，我们遇到以下情况：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">新版本的服务已部署到节点a。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">节点a上的Kafka Streams实例已禁用。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">重新平衡已经开始。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">由于我们指定配置num.standby.replicas = 1，因此已将节点a的存储库复制到节点b。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">节点b已经具有节点a的卷影副本，因此重新平衡过程几乎立即发生。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">节点-a重新启动。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 节点-a加入了一组消费者。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka经纪人看到Kafka Streams的新实例并开始重新平衡。</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
如我们所见，num.standby.replicas仅在完全关闭节点的情况下才有用。</font><font style="vertical-align: inherit;">这意味着，如果节点a崩溃，那么节点b几乎可以立即继续正常工作。</font><font style="vertical-align: inherit;">但是在滚动更新的情况下，断开连接后，节点a将再次加入该组，而这最后一步将导致重新平衡。</font><font style="vertical-align: inherit;">当节点a重新引导后加入使用者组时，它将被视为使用者的新实例。</font><font style="vertical-align: inherit;">同样，我们必须记住，实时数据处理将停止，直到新实例从更改日志主题恢复其状态为止。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
请注意，将新实例加入组时重新平衡分区不适用于Kafka Streams API，因为这是Apache Kafka使用者组协议的工作方式。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">成就：Kafka Streams的高可用性</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
尽管Kafka客户端库没有为上述问题提供内置功能，但是在滚动更新过程中，可以使用一些技巧来实现高群集可用性。</font><font style="vertical-align: inherit;">备份副本背后的想法仍然有效，并且在适当的时候拥有备份计算机是一个很好的解决方案，我们可以用来确保在实例发生故障时实现高可用性。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
初始设置的问题是我们在所有节点上的所有团队都有一组消费者。</font><font style="vertical-align: inherit;">现在，我们不再有一组消费者，而是两个，而第二个充当“热”集群。</font><font style="vertical-align: inherit;">在prod中，节点具有特殊的变量CLUSTER_ID，该变量已添加到Kafka Streams实例的application.id中。</font><font style="vertical-align: inherit;">这是一个示例Spring Boot application.yml配置：</font></font><div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.yml</font></font></b><div class="spoiler_text"><code>spring.profiles: production<br>
streaming-pipelines:<br>
 team-a-stream-app-id: "${CLUSTER_ID}-team-a-stream-app"<br>
 team-b-stream-app-id: "${CLUSTER_ID}-team-b-stream-app"</code><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在某个时间点，分别只有一个集群处于活动模式，备用集群不会实时向下游微服务发送消息。在发行版的发行期间，备份群集将变为活动状态，从而可以在第一个群集上进行滚动更新。由于这是一个完全不同的消费者组，因此我们的客户甚至没有注意到处理中的任何违规行为，并且后续服务继续从最近活动的群集中接收消息。使用后备使用者组的明显缺点之一是额外的开销和资源消耗，但是，尽管如此，此体系结构仍为我们的流处理系统提供了额外的保证，控制和容错能力。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
除了添加其他群集外，还有一些技巧可以缓解频繁重新平衡的问题。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">增加group.initial.rebalance.delay.ms</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
从Kafka 0.11.0.0开始，添加了配置组.initial.rebalance.delay.ms。</font><font style="vertical-align: inherit;">根据文档，此设置负责：</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GroupCoordinator将延迟该组消费者的初始重新平衡的时间（以毫秒为单位）。</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
例如，如果我们在此设置中设置了60,000毫秒，则通过滚动更新，我们可能会有一个分钟的发布窗口。</font><font style="vertical-align: inherit;">如果Kafka Streams实例在此时间窗口内成功重新启动，则不会调用任何重新平衡。</font><font style="vertical-align: inherit;">请注意，重启的Kafka Streams实例负责的数据将继续不可用，直到该节点返回联机模式为止。</font><font style="vertical-align: inherit;">例如，如果实例重启大约需要八秒钟，那么该实例所负责的数据将有八秒钟的停机时间。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
应该注意的是，此概念的主要缺点是，在节点发生故障的情况下，考虑到当前配置，还原期间还会收到一分钟的额外延迟。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">变更日志主题中的段大小缩小</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
重新平衡Kafka Stream的最大延迟是由于从更改日志主题恢复了状态存储。更改日志主题是压缩的主题，它使您可以存储主题中特定键的最新记录。我将在下面简要描述这个概念。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kafka Broker中的主题按段进行组织。当段达到配置的阈值大小时，将创建一个新段并压缩前一个段。默认情况下，此阈值设置为1 GB。您可能知道，Kafka主题及其分区基础的主要数据结构是具有前向写入功能的日志结构，即，将消息发送到该主题时，它们总是添加到最后一个“活动”段中，而压缩不继续。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
因此，变更日志中大多数已存储的存储状态始终位于“活动段”文件中，并且从未压缩，从而导致数百万条未压缩的变更日志消息。</font><font style="vertical-align: inherit;">对于Kafka Streams，这意味着在重新平衡期间，当Kafka Streams实例从changelog主题恢复其状态时，它需要从changelog主题读取很多冗余条目。</font><font style="vertical-align: inherit;">假定状态存储仅关心最后一个状态，而不关心历史，则浪费了该处理时间。</font><font style="vertical-align: inherit;">减小段的大小将导致更积极的数据压缩，因此Kafka Streams应用程序的新实例可以更快地恢复。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">结论</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
即使Kafka Streams没有提供在滚动服务更新过程中提供高可用性的内置功能，仍然可以在基础结构级别上完成。</font><font style="vertical-align: inherit;">我们必须记住，与Apache Flink或Apache Spark不同，Kafka Streams不是一个“集群框架”。</font><font style="vertical-align: inherit;">它是一个轻量级的Java库，允许开发人员创建可伸缩的应用程序以流式传输数据。</font><font style="vertical-align: inherit;">尽管如此，它还是提供了实现“ 99.99％”可用性这样宏伟的流媒体目标所必需的构建块。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN488544/index.html">从已经运行的Node.JS应用程序中删除代码覆盖率</a></li>
<li><a href="../zh-CN488546/index.html">砍箱子。JSON演练。通过SeImpersonatePrivilege的Json.Net和LPE中的漏洞</a></li>
<li><a href="../zh-CN488548/index.html">实验：如何学习创建流行的英语文本（以及为什么说英语的哈伯族人读得这么少）</a></li>
<li><a href="../zh-CN488550/index.html">谁想要使合作伙伴脱离IT巨头</a></li>
<li><a href="../zh-CN488552/index.html">Apple FAS和家长控制开发人员</a></li>
<li><a href="../zh-CN488560/index.html">在Google Cloud Platform上托管的免费Telegram机器人</a></li>
<li><a href="../zh-CN488564/index.html">您在图形处理单元（GPU）上的第一个神经网络。初学者指南</a></li>
<li><a href="../zh-CN488566/index.html">质量检查工程师如何通过链接Visual Studio中的自动测试和测试IT来节省一整天</a></li>
<li><a href="../zh-CN488568/index.html">神经网络是否梦想着用电钱？</a></li>
<li><a href="../zh-CN488570/index.html">美国特勤局如何将网络朋克RPG与黑客教科书混淆</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤾🏽 🕜 👨🏽‍🤝‍👨🏻 BERT, ELMO und Co. in Bildern (wie das Transfer-Training zu NLP kam) 🐶 👨🏾‍🤝‍👨🏻 👜</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="2018 war ein Wendepunkt für die Entwicklung von Modellen für maschinelles Lernen zur Lösung von Problemen der Textverarbeitung (oder genauer gesagt de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>BERT, ELMO und Co. in Bildern (wie das Transfer-Training zu NLP kam)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487358/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2018 war ein Wendepunkt für die Entwicklung von Modellen für maschinelles Lernen zur Lösung von Problemen der Textverarbeitung (oder genauer gesagt der Verarbeitung natürlicher Sprache (NLP)). </font><font style="vertical-align: inherit;">Das konzeptionelle Verständnis, wie Wörter und Sätze dargestellt werden können, um ihre semantischen Bedeutungen und Beziehungen zwischen ihnen am genauesten zu extrahieren, wächst rasant. </font><font style="vertical-align: inherit;">Darüber hinaus fördert die NLP-Community unglaublich leistungsstarke Tools, die heruntergeladen und kostenlos in ihren Modellen und Pipelines verwendet werden können. </font><font style="vertical-align: inherit;">Dieser Wendepunkt wird auch als </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ImageNet-Moment von NLP bezeichnet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und bezieht sich auf den Moment vor einigen Jahren, als ähnliche Entwicklungen die Entwicklung des maschinellen Lernens im Bereich der Computer-Vision-Probleme erheblich beschleunigten.</font></font></p><br>
<p><img src="https://habrastorage.org/webt/uh/cd/qv/uhcdqv--w2t4i8srv9rtzjgk9ac.png" alt="transformator-ber-ulmfit-elmo"></p><br>
<p><em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(ULM-FiT hat nichts mit Korzhik zu tun, aber etwas Besseres ist nicht eingetreten)</font></font></em></p><a name="habracut"></a><br>
<p>        –  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">BERT'</a>, ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"> </a>    NLP. BERT –  ,        NLP-.    ,  ,                BERT',        .                    ,   ,   ,        .</p><br>
<p><img src="https://habrastorage.org/webt/pz/zk/xy/pzzkxyzmqf21r5rik00228zntwm.png" alt="Bert-Transfer-Lernen"></p><br>
<p><em> BERT'.  1:   (   );  2:   .</em></p><br>
<p>BERT      ,  NLP-, ,   : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Semi-supervised Sequence learning</a> ( – <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Andrew Dai</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Quoc Le</a>), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">ELMo</a> ( – <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Matthew Peters</a>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">AI2</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">UW CSE</a>), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">ULMFiT</a> ( –  fast.ai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Jeremy Howard</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Sebastian Ruder</a>), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">OpenAI Transformer</a> ( –  OpenAI <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Radford</a>, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Narasimhan</a>, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Salimans</a>,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Sutskever</a>)   (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Vaswani et al</a>).</p><br>
<p>  ,     ,     BERT'.   ,     ,       .</p><br>
<h1 id="primer-klassifikaciya-predlozheniy">:  </h1><br>
<p>    BERT –    .      :</p><br>
<p><img src="https://habrastorage.org/webt/mx/eo/u_/mxeou__qytr_9_2m6pxjo2icemc.png" alt="Bert-Klassifizierungs-Spam"></p><br>
<p>   ,   ,    (classifier)       BERT'    .       (fine-tuning),      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Semi-supervised Sequence Learning</a>   ULMFiT.</p><br>
<p> ,    :   ,         .        .               («»  « »).</p><br>
<p><img src="https://habrastorage.org/webt/hy/qr/pa/hyqrpadlqytj81eqk3xtkyr3fcu.png" alt="Spam-beschrifteter Datensatz"></p><br>
<p>   BERT':</p><br>
<ul>
<li><strong>  (sentiment analysis)</strong><br>
<ul>
<li>:   /. : / </li>
<li>  : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">SST</a></li>
</ul></li>
<li><strong>  (fact-checking)</strong>:<br>
<ul>
<li>: . : «» (Claim)  « » (Not Claim)</li>
<li> / :<br>
<ul>
<li>:    (Claim sentence). : «»  «»</li>
</ul></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Full Fact</a> – ,      .     ,        ,      ( , , ,    )</li>
<li>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">     </a></li>
</ul></li>
</ul><br>
<h1 id="arhitektura-modeli"> </h1><br>
<p>,         BERT', ,   .</p><br>
<p><img src="https://habrastorage.org/webt/i3/u4/fq/i3u4fq9cclcq0-zeqfk56b5y78i.png" alt="Bert-Base-Bert-Large"></p><br>
<p>     BERT'  :</p><br>
<ul>
<li>BERT BASE () –       OpenAI Transformer; </li>
<li>BERT LARGE () –   ,     (state of the art),   .</li>
</ul><br>
<p> , BERT –     . . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>,      –   BERT’   ,      .</p><br>
<p><img src="https://habrastorage.org/webt/6k/ce/se/6kcesezyar2zqppjc31sfkcsxak.png" alt="Bert-Base-Bert-Large-Encoder"></p><br>
<p>   BERT'      (    « » (Transformer Blocks)): 12     24  .          (768  1024   )   «»  (attention heads)(12  16 ),     ,     (6  , 512  , 8 «» ).</p><br>
<h3 id="vhody-modeli"> </h3><br>
<p><img src="https://habrastorage.org/webt/ed/7k/go/ed7kgoai63syz-koc-_tlqs0gwk.png" alt="Bert-Input-Output"></p><br>
<p>        [CLS]  ,     . CLS     .</p><br>
<p>  ,     , BERT     ,       .       (self-attention)       ,      .</p><br>
<p><img src="https://habrastorage.org/webt/jp/kd/qs/jpkdqszmo06ogw7xbfk1tqmz0kw.png" alt="Bert-Encoder-Eingang"></p><br>
<p>   ,         (   ,    ).        .</p><br>
<h3 id="vyhody-modeli"> </h3><br>
<p>        hidden_size (768    BERT').    ,    ,       (      [CLS]).</p><br>
<p><img src="https://habrastorage.org/webt/at/9b/xe/at9bxefqh-vnkxlc-xkuxlgi13s.png" alt="Bert-Output-Vektor"></p><br>
<p>           .      ,          .</p><br>
<p><img src="https://habrastorage.org/webt/ee/lg/99/eelg99xutp6h7oztqyyz3hv-5e4.png" alt="Bert-Klassifikator"></p><br>
<p>       (,       «», « », « », «»  .),               .</p><br>
<h1 id="paralleli-so-svertochnymi-setyami">   </h1><br>
<p> ,     ,      ,        VGGNet     .</p><br>
<p><img src="https://habrastorage.org/webt/sl/37/yf/sl37yfo6xriqw24ule31ukksi8q.png" alt="vgg-net-klassifikator"></p><br>
<h1 id="novaya-era-embeddingov">  </h1><br>
<p>         .   ,    NLP-     ,   :        Word2Vec  GloVe.    ,    ,     ,  .</p><br>
<h3 id="kratkiy-obzor-mehanizma-embeddingov-slov">    </h3><br>
<p>              ,        . Word2Vec ,      ( ),     ,         (..                ,  «» – «»  «» – «»),       (, ,    «»  «»  ,   «»  «»).</p><br>
<p>  ,     ,     ,            .        ,      Word2Vec  GloVe.      GloVe   «stick» (   – 200):</p><br>
<p><img src="https://habrastorage.org/webt/l1/u-/ad/l1u-admk5irbjkb__sq90albkx0.png" alt="Einbettung von Handschuhen"></p><br>
<p><em>  «stick»   GloVe –   200     (  2   ).</em></p><br>
<p>                .</p><br>
<p><img src="https://habrastorage.org/webt/gz/ji/ee/gzjieex8v-pmouar89ocbbzan-e.png" alt="Vektorkästen"></p><br>
<h3 id="elmo-kontekst-imeet-znachenie">ELMo:   </h3><br>
<p>    GloVe,   «stick»        . « », –   NLP- (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Peters et. al., 2017</a>, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">McCann et. al., 2017</a>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Peters et. al., 2018    ELMo</a>). – « «stick»       ,   .         ,     –  ,      ,    ?».     (contextualized word-embeddings).</p><br>
<p><img src="https://habrastorage.org/webt/jr/rt/hb/jrrthbwj9xdzd4vgs5ckjgayv0m.png" alt="Elmo-Embedding-Robin-Williams"></p><br>
<p><em>            .</em></p><br>
<p> ,     , ELMo    ,       .        (bi-directional LSTM),       .</p><br>
<p><img src="https://habrastorage.org/webt/bf/yw/qq/bfywqqcnnk6cw6hr3l3fbl-xq-i.png" alt="Elmo-Wort-Einbettung"></p><br>
<p>ELMo         NLP.  ELMo LSTM          ,        ,     .</p><br>
<p>   ELMo?</p><br>
<p>   ELMo          – ,    (language modeling).  ,        ,         .</p><br>
<p><img src="https://habrastorage.org/webt/mq/j1/bo/mqj1bozk08fff_cglqbdcatcuao.png" alt="Bert-Sprachmodellierung"></p><br>
<p><em>    ELMo:     «Let's stick to»,        –   .            . ,         .  ,    , , , «hang»,       «out» (   «hang out»),   «camera».</em></p><br>
<p>  ,      LSTM  -  ELMo.       ,       .</p><br>
<p>  , ELMo        LSTM – ,    «»    ,    .</p><br>
<p><img src="https://habrastorage.org/webt/0w/re/y4/0wrey4vtsshgd7wcgvi_k_cguzk.png" alt="Einbettung von elmo-forward-backward-language-model"></p><br>
<p><em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"> </a>  ELMo</em></p><br>
<p>ELMo        (  )   (    ).</p><br>
<p><img src="https://habrastorage.org/webt/d8/dq/ch/d8dqchc0wxmoxmg2e79fnahk3ru.png" alt="Elmo-Einbettung"></p><br>
<h1 id="ulm-fit-vnedryaya-transfernoe-obuchenie-v-nlp">ULM-FiT:     NLP</h1><br>
<p>ULM-FiT      ,        –       . ULM-FiT              .</p><br>
<p>NLP      , ,   ,       .</p><br>
<h1 id="transformer-vyhodya-za-predely-lstm-setey">:    LSTM </h1><br>
<p>   ,    ,   ,        ,     NLP-    LSTM.          .</p><br>
<p> -       .         ?         ,        (..     ,     )?</p><br>
<h1 id="openai-transformer-predvaritelnoe-obuchenie-dekodera-transformera-dlya-yazykovogo-modelirovaniya">OpenAI Transformer:       </h1><br>
<p> ,     ,          NLP-.        .    :    ,        (  ).</p><br>
<p><img src="https://habrastorage.org/webt/3p/-d/q3/3p-dq3wsky9bqnz6mdfv6-y-r2o.png" alt="openai-transformator-1"></p><br>
<p><em>OpenAI Transformer     </em></p><br>
<p>   12  .          -  ,     . ,         (   ).</p><br>
<p>                :   ,     .    7       .       , ..          ,         – ,   ,        .</p><br>
<p><img src="https://habrastorage.org/webt/8d/l0/4k/8dl04ko7gbfw9kiq_jlg5ve281w.png" alt="Openai-Transformator-Sprachmodellierung"></p><br>
<p><em>OpenAI Transformer             7000 </em></p><br>
<h1 id="transfernoe-obuchenie-v-prikladnyh-zadachah">    </h1><br>
<p>,  OpenAI Transformer           ,         .      (    «»   « »):</p><br>
<p><img src="https://habrastorage.org/webt/-l/fo/hr/-lfohrojznururmmrni-ykoqnog.png" alt="Openai-Transformator-Satz-Klassifikation"></p><br>
<p>  OpenAI    ,        .               :</p><br>
<p><img src="https://habrastorage.org/webt/mb/aw/na/mbawnanchccikwp7z4hhe1n0tbi.png" alt="Openai-Input-Transformationen"></p><br>
<p>,   ?</p><br>
<h1 id="bert-ot-dekoderov-k-enkoderam">BERT:    </h1><br>
<p>OpenAI Transformer      ,    .  -       LSTM  .   ELMo  ,  OpenAI Transformer    .         ,      ,    ( – «   ,    »)?</p><br>
<blockquote>«  », –      .</blockquote><br>
<h3 id="maskirovannaya-yazykovaya-model-masked-language-model">   (masked language model)</h3><br>
<blockquote>«    », –  .<br>
« !» –  . – « ,            .»<br>
«   », –   .</blockquote><p><img src="https://habrastorage.org/webt/z7/m-/qm/z7m-qmmtz724m8viviqejgzsmjs.png" alt="BERT-Sprachmodellierung-maskiert-lm"></p><br>
<p><em>    BERT  «»   15%          .</em></p><br>
<p>        –   ,  BERT ,    «  » (masked language model)     (   «-»).</p><br>
<p>  15%  , BERT      ,      .             .</p><br>
<h3 id="zadachi-dvuh-predlozheniy">  </h3><br>
<p>     OpenAI Transformer,   ,        -      (,       ?                ,       ?).</p><br>
<p> ,  BERT         ,     :    (  );  ,      ?</p><br>
<p><img src="https://habrastorage.org/webt/rz/hr/jf/rzhrjfq5iyequzyykq9tp0urdic.png" alt="Bert-Next-Satz-Vorhersage"></p><br>
<p><em> ,   BERT    –     .     , .. BERT  WordPieces,       –        .</em></p><br>
<h3 id="modeli-dlya-konkretnyh-zadach">   </h3><br>
<p>   BERT'        .</p><br>
<p><img src="https://habrastorage.org/webt/03/8i/a7/038ia7qjndp3qhcz8pdkcd_14nw.png" alt="Bert-Aufgaben"></p><br>
<p><em>a)    : MNLI, QQP, QNLI, STS-B, MRPC, RTE, SWAG; b)    : SST-2, CoLA; c) - : SQuAD v1.1; d)    : CoNLL-2003 NER.</em></p><br>
<h3 id="bert-dlya-izvlecheniya-priznakov">BERT   </h3><br>
<p>   –     BERT.      ELMo,     BERT'    .         – ,          , , ,    (named-entity recognition).</p><br>
<p><img src="https://habrastorage.org/webt/ob/pa/a6/obpaa6snqryacqb9vbyaahue7zc.png" alt="Bert-Contexualized-Einbettungen"></p><br>
<p>       ?    .    6  (    ,   96,4):</p><br>
<p><img src="https://habrastorage.org/webt/ir/vr/sv/irvrsv9mefroz7io6ilnjng3fo4.png" alt="Bert-Feature-Extraktion-Kontextualisierte-Einbettungen"></p><br>
<h1 id="test-drayv-berta">- BERT'</h1><br>
<p>   BERT   –   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">BERT FineTuning with Cloud TPUs</a>,   Google Colab.       Cloud TPU,    , ..  BERT'     TPU,    CPU  GPU.</p><br>
<p>  –     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"> BERT'</a>:</p><br>
<ul>
<li>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">modeling.py</a> (class BertModel)      .</li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">run_classifier.py</a> –    .         .       , .  create_model()   .</li>
<li>     ,     BERT'     ,    ,      102 .</li>
<li>BERT     .      WordPieces. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">tokenization.py</a> – ,     WordPieces,   BERT'.</li>
</ul><br>
<p>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">PyTorch- BERT'</a>.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">AllenNLP</a>      BERT'a   .</p><br>
<h1 id="avtory"></h1><br>
<ul>
<li><strong> </strong> — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Jay Alammar</a></li>
<li><strong></strong> — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a></li>
<li><strong>  </strong> — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a></li>
</ul></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de487340/index.html">Da haben wir den nächsten Designer von Chat Bots gemacht. Teil 1</a></li>
<li><a href="../de487342/index.html">Lektion 2 - Tagungen und Veranstaltungen</a></li>
<li><a href="../de487346/index.html">Fälle für die Verwendung von Tools zur Analyse von Netzwerkanomalien: Lecksuche</a></li>
<li><a href="../de487348/index.html">Priority Task Ranking - IL TEMPO App</a></li>
<li><a href="../de487356/index.html">Wirst du dich ändern? Denk nochmal</a></li>
<li><a href="../de487360/index.html">Die Anonymisierung von Daten garantiert nicht Ihre vollständige Anonymität</a></li>
<li><a href="../de487362/index.html">Angular 9 ist jetzt verfügbar - Ivy ist angekommen</a></li>
<li><a href="../de487366/index.html">Zustandspanik: Ein nicht offensichtlicher Blick auf die 2019-nCoV-Coronovirus-Epidemie</a></li>
<li><a href="../de487368/index.html">Hybrides Verkaufsteam. Menschen + KI arbeiten im selben Team</a></li>
<li><a href="../de487370/index.html">Immobilienmarktanalyse basierend auf Daten von msgr.ru.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💵 👨‍⚖️ 🏼 ロシア語のNLU：ELMo対BERT 👩🏿‍💼 ☝🏽 👩🏼‍🤝‍👨🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="この記事では、人工知能の一部として機械学習に焦点を当てます。コミュニケーションは私たちを人間にするものなので、AIは主に会話コンポーネントを意味します。したがって、私たちを理解し、言葉に応えられるシステムを構築すれば、人工知能の発達にある程度近づくことになります。しかし、これはすべて哲学の瀬戸際にあ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ロシア語のNLU：ELMo対BERT</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mipt/blog/478358/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">この記事では、人工知能の一部として機械学習に焦点を当てます。</font><font style="vertical-align: inherit;">コミュニケーションは私たちを人間にするものなので、AIは主に会話コンポーネントを意味します。</font><font style="vertical-align: inherit;">したがって、私たちを理解し、言葉に応えられるシステムを構築すれば、人工知能の発達にある程度近づくことになります。</font><font style="vertical-align: inherit;">しかし、これはすべて哲学の瀬戸際にある理論です。</font><font style="vertical-align: inherit;">練習しましょう。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7f/eu/uq/7feuuqurale8_vfloxhkt_im640.jpeg"><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">自然言語処理について話す</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、自然言語でのテキストの分析、つまり自然言語処理は、3つの部分に分けることができるタスクの幅広い計画です。自然言語理解-理解、自然言語生成-生成、これはすべてテキストに関連しています。そして最後に、話し言葉-認識と合成。記事では、テキストの理解について詳しく説明します。自然言語理解は、テキストコンテンツを自動的に分析し、関心のある組織、製品、および人々に関する事実を抽出するシステムを作成する場合、独立した価値があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキストを理解するには、まず、セマンティクスを強調する必要があります。何が書かれているか、シグネチャのクラス、ユーザーの意図、イントネーション、調性、そして最後に、テキストの内容、実世界のオブジェクト、人、組織、場所、データを特定する必要があります。 。オブジェクトを区別するタスクは、名前付きエンティティの認識（Natural Entity Recognition）と呼ばれ、ユーザーが何を望んでいるか、ユーザーの意図の分類、または分類の意図を決定します。そして最後に、トーン認識は感情分析です。タスクはかなりよく知られており、それらのソリューションへのアプローチは長い間存在しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
認識された名前付きエンティティ。名前付きエンティティを選択する必要があるクライアントによって生成されたテキストがいくつかあります。まず、これらは人の名前、組織の名前、地理位置情報です。社会的エンティティもあります：より詳細な住所、電話、地政学的エンティティ。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
チャットボットと話すとき、彼が私たちに何を望んでいるかを知ることが重要です。ユーザーの意図を理解することは、対話の列の場所とチャットボットの最も適切な応答を決定するのに役立ちます。意図（ユーザーの意図）はさまざまな方法で表現できます。ボットクライアントとの実際のチャットの一部を以下に示します。「Simka、私は言う、ブロックします！」または「しばらく電話番号を切断できますか？」意図の分類はキーワードで行えるように思えます。しかし、ご覧のとおり、同じ意図に関連するこれら2つの単純な例（SIMカードのブロック）でさえ、交差する単語はまったく含まれていません。したがって、テキスト自体を分類し、チャットボットを操作する場所に応じて、意図の新しいクラスのセット用にチャットボットを構築および構成する機械学習ベースのシステムを作成するのが最善です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして最後に、調性を分析する古典的なタスク。ある意味では、意図の分類よりもすべてが簡単です。通信プロバイダーと通信するか、ピザを注文するか、銀行の問題を解決するかに応じて、各チャットボットの意図が異なる場合、調性分析の分野では、調性クラスのセットは標準です：3（中立感情）またはクラス2（否定的または肯定的） ）ただし、調性自体を強調する作業はより複雑です。なぜなら、人々は皮肉的または暗黙的に感情を表現することが多いからです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべてのタスクについて、教師とトレーニングを受けたモデルを構築することが最も効果的です。</font><font style="vertical-align: inherit;">人間は自分のものの奴隷ではありません。</font><font style="vertical-align: inherit;">したがって、データセットをマークアップするために人を使用する場合、彼はテキストで述べられている感情、これらのクラスまたは他のユーザーテキストを含むクラス、およびコールセンターオペレーターへの要求である調性を強調できます。</font><font style="vertical-align: inherit;">その後、特徴的な説明を考え出し、それに基づいてベクターテキストまたは単語テキストを受け取り、システムをさらにトレーニングできます。</font><font style="vertical-align: inherit;">テーマは定評のあるクラシックです。</font><font style="vertical-align: inherit;">うまく機能しますが、問題がないわけではありません。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データを準備する方法</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さまざまなテキストコーパスの準備のために、多くのツールがあります。下の画像では、最も人気のあるツールの1つであるブラットの表記ツールのスクリーンショットを示しました。これに一連のテキストをロードし、教師自身がマウスを使用してテキストから単語を選択します。たとえば、クラスorgの名前付きエンティティの組織の名前、クラスmoneyの名前付きエンティティの名前。インターフェースは非常に便利で直感的ですが、ここで大量のテキストを区別するには非常に長くて面倒です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/hi/-a/lz/hi-alzd6i_qocijvkdhnzfoqmyk.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
何をすべきか？通常、チャットボットを設計するときやコンテンツ分析システムを作成するときの実際のタスクでは、さまざまな大きなケースを使用することはできません。軍団の量は100、200、おそらく1000、2000のテキストであり、それ以上ではありません。しかし、あなたは学ぶ必要があります。同時に、教師による指導の問題に関する古典的な声明には、非常に多くのテキスト（数万）が含まれています。トレーニング能力の高いシステムを構築して問題を解決することはできますが、ここでは不可能です。機械学習への最新のアプローチは、大規模ニューラルネットワークのトレーニングである転移学習と呼ばれる救済策です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その多層構造により、ニューラルネットワークは機能の分類子でありイラストレーターでもあります。若いレイヤーは、ダッシュ、グラフィックプリミティブなど、画像の基本的な特徴を抽出します。そして、ニューラルネットワークの出口に近いほど、より高レベルで抽象的なイメージ要素が抽出されます。 ImageNetを使用して画像認識ネットワークをトレーニングする場合（非常にクールなディープニューラルネットワークを構築できる、1400万を超えるさまざまな画像があるサイト）、最後のいくつかのレイヤーを削除し、頭を「カットオフ」して「ボディ」だけを残します-初期レイヤー、次に、初期層の形で蓄積された知識により、基本応答画像を取得することがすでに可能になっています。また、どのレイヤーも基本レイヤーで構成されているため、ニューラルネットワークをゼロからトレーニングする問題を解決します。同じ分野のあらゆるタスクに通常の「体」を使用します。たとえば、コンピュータービジョンでは、新しい「頭」を縫い合わせて、その構造全体を一緒にトレーニングします。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMoの革命</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、問題が発生します。テキスト分析についてはどうでしょうか。</font><font style="vertical-align: inherit;">結局のところ、テキストは言語ごとに異なり、そのような巨大なラベル付きコレクションを作成することは問題があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2017年から、コンピューター言語学とテキスト分析の分野で一種の革命が起こり始めました。</font><font style="vertical-align: inherit;">効果的な転移学習法がここに来ています。</font><font style="vertical-align: inherit;">ELMo（言語モデルからの埋め込み）とBERT（トランスフォーマーからの双方向エンコーダー表現）の2つのモデルを使用する言語学の分野でのTransferLearningは、まったく新しいレベルに到達しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
それが具体的に起こったかどうかは不明ですが、これらの略語は、セサミストリートシリーズのキャラクターの名前と一致しています。 ELMoは歴史的に最初のモデルになりました。これにより、テキストの詳細なセマンティクスを考慮することができます。名前付きエンティティの認識、テキストの分類、調性の分析—これらのタスクはすべて、テキストのセマンティクスと意味の抽出に基づいています。したがって、私たちはディープニューラルネットワーク言語モデリング、テキスト内の依存関係の検索を教えます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
たとえば、次の図は、照応を解決する方法を示しています。「プログラマーVasyaはビールが大好きです。</font><font style="vertical-align: inherit;">仕事の後の毎晩、彼はジョナサンに行き、グラスを1つか2つ逃します。</font><font style="vertical-align: inherit;">プログラマーVasyaはビールが大好きな人です。</font><font style="vertical-align: inherit;">仕事の後の毎晩、彼はジョナサンに行き、グラスを1つか2つ逃します。</font><font style="vertical-align: inherit;">彼は誰？</font><font style="vertical-align: inherit;">彼は今夜ですか、ビールですか。</font><font style="vertical-align: inherit;">ビールです。</font><font style="vertical-align: inherit;">彼はプログラマーVasyaですか？</font><font style="vertical-align: inherit;">おそらく、プログラマーVasya。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/i3/u6/bz/i3u6bzmqdayeq_3jnjsermyfs1m.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
フィードバックのおかげで、再帰型ニューラルネットワークにはメモリがあり、依存関係を何度でも考慮に入れることができます。</font><font style="vertical-align: inherit;">これらのパターンに基づいて、言語モデリングの問題を解決することができます。</font><font style="vertical-align: inherit;">テキストがどれほど長くても、ニューラルネットワークに段落全体で、たとえば2、3、4語の次の単語を予測させようとしています。</font><font style="vertical-align: inherit;">これらのタイプの言語モデルはより効果的です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
長い間、各言語のマークアップを作成する必要がないことがわかります。コンピューターを使用して、任意の言語の言語モデルを非常に簡単に生成できます。操作モードでモデルをトレーニングした後、テキストが入力され、モデルはテキスト内の各単語を処理するときに、次の単語を予測しようとします。潜在状態は、再帰型ニューラルネットワークの逆であるニューラルネットワークのすべてのレベルで取得されるため、テキスト内の単語のベクトル表現が取得されます。これがELMoの仕組みです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
順方向言語モデルと逆方向言語モデルでは、一連の単語が提供され、モデルがトレーニングされ、埋め込みを取得する必要がある場合（たとえば、このテキストの単語スティックが「先に固定」である場合）、最初の単語、2番目の時点、および現時点でのリカレントニューラルネットワークの状態が取得されます。逆モデルは最初に、2番目にあり、大きなベクトル表現が得られます。このようなモデルの利点は、単語のベクトル表現を生成するときにコンテキストが考慮されることです。埋め込みは、他の単語の環境を考慮して生成されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ELM®は深い意味論を考慮に入れ、同音異義の問題を解決しますが、このモデルには欠点がないわけではありません。</font><font style="vertical-align: inherit;">再帰的なニューラルネットワークは、一方では軽い依存関係を考慮に入れることができ、他方では非常に一生懸命に学習し、長いシーケンスを常にうまく分析できるとは限りません。とにかく、忘却に問題があります。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">バート</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
リカレントニューラルネットワークを使用し、別のアーキテクチャ（BERT）を使用する決定的な「いいえ」としましょう。</font><font style="vertical-align: inherit;">リカレントニューラルネットワークの代わりに、フィードバックではなく、いわゆる注意メカニズムに基づいたTransformerモデルを使用します。</font><font style="vertical-align: inherit;">テキストを読むとき、意味的な負荷が最も大きいキーワードが思わず強調されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像またはテキスト内の一部のオブジェクトをローカライズできます。注意メカニズムはニューラルネットワークに存在し、ほぼ同じ原理に基づいています。特定のレイヤーがシーケンスの各要素を重み付けし、次に各瞬間の各シーケンスを重み付けします。このステップでシーケンスのどの要素が最も重要であるか最も重要でないかを確認できることがわかります。トランスフォーマーは特別なバージョンの注意を使用します-マルチヘッド注意。さらに、Transformerは完全かつ完全に単語全体を使用するのではなく、準同型性（BPE）を使用しています。ポイントは何ですか？テキスト内の最も安定した文字の組み合わせが強調表示され、文字から単語が作成されます。辞書の問題は、ロシア語などの多くの単語形式がある言語では非常に深刻です：「母」、「母」、「母」、「母」-ケース、小形など</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すべての単語の形の辞書を保持していると、数百万という結果になりますが、もちろん非常に不便なため、妥協案が見つかりました。単語内の最も安定したサブワードは、統計的に最も頻度の高いバイグラム（文字の繰り返し）で区別され、特殊文字BPEに置き換えられます。結果はBPE辞書です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
イワン・パブロフの伝記が書かれたテキストであるBPEの例を考えてみましょう。「1890年の春、ワルシャワとトムスクの大学が彼を教授に選出しました。」</font><font style="vertical-align: inherit;">一般的に、単語は「春」、「1890」、「ワルシャワ」ですが、「##ナチュラル」の単語の断片を強調表示しています。</font><font style="vertical-align: inherit;">「## ar ## sha ## vsky」などです。</font><font style="vertical-align: inherit;">したがって、辞書のサイズを数万のBPEに効果的に縮小することが可能であり、さらに、複数の言語で同時に動作するシステムを作成できます。</font><font style="vertical-align: inherit;">将来を見据えて、オプションの1つは105の言語でトレーニングされ、BERT辞書は10万BPEに達したと言います。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私たちはBERTに何を教えますか？ </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
「このスキットでは即興に固執しましょう」というテキストがあるとします。 quasitoken、つまり始まりを意味し、各テキストの10〜15％の単語がランダムにマスク（特殊文字）に置き換えられます。これは入力信号です。つまり、私たちはBERTに、マスクとして偽装された欠落している単語を回復するように学習させています。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/r0/rd/5y/r0rd5y6ropbv8b3swubizzldo8i.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このデータセットの場合、マークアップは不要です。この場合、テキスト自体がマークアップであり、BERTはテキスト内のセマンティクスをモデル化することを学習します。 2番目のタスクは、2番目の文が最初のマルチタスク学習の論理的発展であるかどうかを判断するようにBERTを教えることです。 「毎晩、バシャはバーに行きます。彼はビールが大好きです。「2番目の文は最初の文の論理的な発展です。この場合、BERTはこのタスクの単位を設定する必要があります。リスは冬に毛皮を変えます」-2番目の文はまったく関係がなく、最初の文から続かず、BERTはゼロを示すはずです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BERTとELMoの両方の場合の最初の結果は英語で得られ、それらは本当に印象的でした。しかし、ロシア語を分析したい場合はどうでしょうか？最初のオプションは、ウィキペディアのテキストでトレーニングされた、Googleの専門家によって準備された多言語BERTです。ウィキペディアは単なる百科事典ではなく、多くの言語のテキストのソースでもあります。その結果、1億1千万のパラメーターを持つ多言語BERTが実現します。より詳細な説明は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こちら</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。事前トレーニング済みのモデルは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tfhubにあり</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。機能の使用と生成は非常に簡単です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多言語BERTは良いですが、BERTとローカライズされたものがあります。</font><font style="vertical-align: inherit;">特に、ロシア語の場合は、多言語BERTを使用して、特にロシア語のテキストに適合させることができます。</font><font style="vertical-align: inherit;">IPavlovは現在そのような作業を行っており、最初の結果はすでに得られています。</font><font style="vertical-align: inherit;">BERTはロシア語のニューステキストに採用され、私たちの言語にさらに適合していることが判明しました。</font><font style="vertical-align: inherit;">iPavlovプロジェクトのフレームワーク内</font><font style="vertical-align: inherit;">の</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">リンク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">からダウンロードして、</font><font style="vertical-align: inherit;">さまざまな問題を解決するために使用できます。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">深いナー</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一連の実験を行った後、研究目的に使用できるだけでなく、名前付きエンティティの認識に関する特定の問題を解決するために実践できるオブジェクトを作成することにしました。</font><font style="vertical-align: inherit;">私は</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deep NER</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を作成し</font><font style="vertical-align: inherit;">ました。これは、転移学習に基づいてトレーニングされるディープニューラルネットワークです。ELMoまたはBERTクラスのオブジェクトをベースとして指定できます。</font><font style="vertical-align: inherit;">Deep NERは、非常にシンプルなインターフェースを持つ一種のリポジトリです。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最後に転移学習について</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、トレーニングを転送することで、特に大きな分析センターを作成する方法がない場合に、さまざまな問題を効果的に解決できることは言うまでもありません。</font><font style="vertical-align: inherit;">2番目のポイント：テキストの細かい意味論では、複雑なモデルが、マージンの広い単純なモデルと比較してリードします。</font><font style="vertical-align: inherit;">そして、最後に、NERとロシア語のテキストの分類が容易になりました。これは、タスクに使用でき、効果的で実用的で有用なソリューションを取得できるモデルと十分に開発されたデータベースがあるためです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
投稿者：</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ivan Bondarenko</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、NTI Competence Center for Artificial Intelligence MIPTに基づくビジネスソリューション研究所の主任科学開発者。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja478346/index.html">2020年にMacBook Pro 2011を購入するとどうなりますか？</a></li>
<li><a href="../ja478350/index.html">12月5日、ManyChatバックエンドMeetUp</a></li>
<li><a href="../ja478352/index.html">WxWidgetsサイザー</a></li>
<li><a href="../ja478354/index.html">実用的な関数型プログラミング</a></li>
<li><a href="../ja478356/index.html">PeopleBlending：認知サービスと少しの創造性でサイエンスアートを作成する</a></li>
<li><a href="../ja478364/index.html">プライバシーとセキュリティを確保する方法と方法。2019ツールの概要</a></li>
<li><a href="../ja478366/index.html">Microsoft SQL Server 2019およびDell EMC Unity XTフラッシュアレイ</a></li>
<li><a href="../ja478368/index.html">オフィスは私たちが俳優である劇場です</a></li>
<li><a href="../ja478370/index.html">オブジェクトビデオ分析の最新システムのアーキテクチャ。時間の経過とともに欠陥になる、または根付くプロセス？</a></li>
<li><a href="../ja478372/index.html">耐え難いほど苦痛にならないようにWAFと共存する方法</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
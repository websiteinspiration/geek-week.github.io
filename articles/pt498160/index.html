<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤲🏼 🎤 🎚️ GlusterFS como armazenamento externo para o Kubernetes 👨🏿‍🔧 👨‍👧‍👦 ⤴️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Encontrar o armazenamento ideal é um processo bastante complicado, tudo tem seus prós e contras. Obviamente, o líder nesta categoria é o CEPH, mas é u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>GlusterFS como armazenamento externo para o Kubernetes</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498160/"><img src="https://portworx.com/wp-content/uploads/2018/10/Twitter-Social-Graphic-68.png" alt="imagem"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Encontrar o armazenamento ideal é um processo bastante complicado, tudo tem seus prós e contras. </font><font style="vertical-align: inherit;">Obviamente, o líder nesta categoria é o CEPH, mas é um sistema bastante complexo, embora com uma funcionalidade muito rica. </font><font style="vertical-align: inherit;">Para nós, esse sistema é redundante, uma vez que precisávamos de um armazenamento replicado simples no modo mestre-mestre por alguns terabytes. </font><font style="vertical-align: inherit;">Tendo estudado muito material, decidiu-se testar o produto mais moderno do mercado para o circuito em que estamos interessados. </font><font style="vertical-align: inherit;">Devido ao fato de não ter sido encontrada uma solução pronta para esse plano, gostaria de compartilhar minhas práticas recomendadas sobre este tópico e descrever os problemas que encontramos no processo de implantação.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Metas</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O que esperávamos do novo repositório:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Capacidade de trabalhar com um número par de nós para replicação.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fácil instalação, configuração, suporte</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O sistema deve ser adulto, testado pelo tempo e usuários</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Capacidade de expandir o espaço de armazenamento sem tempo de inatividade</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O armazenamento deve ser compatível com o Kubernetes</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Deve haver um failover automático quando um dos nós falha</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
É no último ponto que temos muitas perguntas.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desdobramento, desenvolvimento</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para implantação, duas máquinas virtuais foram criadas no CentOs 8. Cada uma delas é conectada através de um disco adicional com armazenamento.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparação preliminar</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para o GlusterFS, você precisa alocar um disco separado com o XFS para que ele não afete o sistema de nenhuma maneira. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selecione a partição:</font></font><br>
<br>
<pre><code class="bash hljs">$ fdisk /dev/sdb<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): n<font></font>
Partition <span class="hljs-built_in">type</span><font></font>
   p   primary (0 primary, 0 extended, 4 free)<font></font>
   e   extended (container <span class="hljs-keyword">for</span> logical partitions)<font></font>
Select (default p): p<font></font>
Partition number (1-4, default 1):  1<font></font>
First sector (2048-16777215, default 2048): <font></font>
Last sector, +sectors or +size{K,M,G,T,P} (2048-16777215, default 16777215): <font></font>
&nbsp;<font></font>
Created a new partition 1 of <span class="hljs-built_in">type</span> ‘Linux’ and of size 8 GiB.<font></font>
Command (m <span class="hljs-keyword">for</span> <span class="hljs-built_in">help</span>): w <font></font>
<font></font>
The partition table has been altered.<font></font>
Calling ioctl() to re-read partition table. Syncing disks.<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Formate no XFS e monte:</font></font><br>
<br>
<pre><code class="bash hljs">$ mkfs.xfs /dev/sdb1<font></font>
$ mkdir /gluster<font></font>
$ mount /dev/sdb1 /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E ainda por cima, solte a entrada em / etc / fstab para montar automaticamente o diretório na inicialização do sistema:</font></font><br>
<br>
<pre><code class="bash hljs">/dev/sdb1       /gluster        xfs     defaults        0       0</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instalação</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em relação à instalação, muitos artigos foram escritos; nesse contexto, não iremos aprofundar o processo, apenas consideraremos o que vale a pena prestar atenção. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nos dois nós, instale e execute a versão mais recente glusterfs:</font></font><br>
<br>
<pre><code class="bash hljs">$ wget -P /etc/yum.repos.d  https://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-rhel8.repo<font></font>
$ yum -y install yum-utils<font></font>
$ yum-config-manager --<span class="hljs-built_in">enable</span> PowerTools<font></font>
$ yum install -y glusterfs-server<font></font>
$ systemctl start glusterd<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em seguida, você precisa informar ao glaster onde está o nó vizinho. </font><font style="vertical-align: inherit;">Isso é feito com apenas um nó. </font><font style="vertical-align: inherit;">Um ponto importante: se você possui uma rede de domínio, deve especificar o nome do servidor com o domínio; caso contrário, no futuro, precisará refazer tudo.</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer probe gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se foi bem-sucedido, verificamos a conexão com o comando de ambos os servidores:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster peer status<font></font>
Number of Peers: 1<font></font>
<font></font>
Hostname: gluster-02.example.com<font></font>
Uuid: a6de3b23-ee31-4394-8bff-0bd97bd54f46<font></font>
State: Peer <span class="hljs-keyword">in</span> Cluster (Connected)<font></font>
Other names:<font></font>
10.10.6.72<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora você pode criar um volume no qual iremos escrever.</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume create main replica 2 gluster-01.example.com:/gluster/main gluster-02.example.com:/gluster/main force</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Onde:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">main - nome Volume </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réplica - tipo Volume (mais detalhes podem ser encontrados na </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documentação oficial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 - número de réplicas </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Execute o Volume e verifique seu desempenho:</font></font><br>
<br>
<pre><code class="bash hljs">gluster volume start main<font></font>
gluster volume status main</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para o volume replicado, é recomendável que você defina os seguintes parâmetros:</font></font><br>
<br>
<pre><code class="bash hljs">$ gluster volume <span class="hljs-built_in">set</span> main network.ping-timeout 5<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-type fixed<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main cluster.quorum-count 1<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main performance.quick-read on</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com essas etapas simples, criamos um cluster GlusterFS. </font><font style="vertical-align: inherit;">Resta conectar-se a ele e verificar o desempenho. </font><font style="vertical-align: inherit;">O Ubuntu está instalado na máquina cliente, para a montagem você precisa instalar o cliente:</font></font><br>
<br>
<pre><code class="bash hljs">$ add-apt-repository ppa:gluster/glusterfs-7<font></font>
$ apt install glusterfs-client<font></font>
$ mkdir /gluster<font></font>
$ mount.glusterfs gluster-01.example.com:/main /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O Gluster, quando conectado a um dos nós, fornece os endereços de todos os nós e se conecta automaticamente a todos. </font><font style="vertical-align: inherit;">Se o cliente já estiver conectado, a falha de um dos nós não levará a uma parada. </font><font style="vertical-align: inherit;">Mas se o primeiro nó estiver indisponível, não será possível conectar-se no caso de uma interrupção da sessão. </font><font style="vertical-align: inherit;">Para fazer isso, ao montar, você pode passar o parâmetro backupvolfile indicando o segundo nó.</font></font><br>
<pre><code class="bash hljs">mount.glusterfs gluster-01.example.com:/main /gluster -o backupvolfile-server=gluster-02.example.com</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um ponto importante: o gluster sincroniza os arquivos entre os nós apenas se as alterações ocorrerem no volume montado. </font><font style="vertical-align: inherit;">Se você fizer alterações diretamente nos nós, o arquivo ficará fora de sincronia.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conecte-se ao Kubernetes</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nesse estágio, começaram as perguntas: “Como conectá-lo?”. </font><font style="vertical-align: inherit;">E há várias opções. </font><font style="vertical-align: inherit;">Considere-os.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Heketi</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O mais popular e recomendado é usar um serviço externo: heketi. </font><font style="vertical-align: inherit;">O heketi é uma camada entre o kubernetes e o gluster, que permite gerenciar e trabalhar com armazenamento por meio de http. </font><font style="vertical-align: inherit;">Mas heketi será esse único ponto de falha, porque </font><font style="vertical-align: inherit;">serviço não está em cluster. </font><font style="vertical-align: inherit;">A segunda instância deste serviço não poderá funcionar independentemente, porque </font><font style="vertical-align: inherit;">quaisquer alterações são armazenadas no banco de dados local. </font><font style="vertical-align: inherit;">A execução deste serviço no kubernetes também não é adequada, porque </font><font style="vertical-align: inherit;">ele precisa de um disco estático no qual seu banco de dados será armazenado. </font><font style="vertical-align: inherit;">Nesse sentido, essa opção acabou sendo a mais inadequada.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Endpoint na Kubernetes</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se você possui o Kubernetes em sistemas com gerenciadores de pacotes, essa é uma opção muito conveniente. </font><font style="vertical-align: inherit;">O ponto é que, para todos os servidores GlusteFS no Kubernetes, um Endpoint comum é criado. </font><font style="vertical-align: inherit;">Um serviço está suspenso neste nó de extremidade e já estaremos montados nesse serviço. </font><font style="vertical-align: inherit;">Para que essa opção funcione, é necessário instalar o glusterfs-client em cada nó do Kubernetes e garantir que ele possa ser montado. </font><font style="vertical-align: inherit;">No Kubernetes, implante a seguinte configuração:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: v1<font></font>
kind: Endpoints<font></font>
metadata: <font></font>
  name: glusterfs-cluster<font></font>
subsets:<font></font>
  - addresses:<font></font>
      <span class="hljs-comment">#  ip  </span>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.71</span><font></font>
    ports:<font></font>
      <span class="hljs-comment">#    1,    </span>
      - port: <span class="hljs-number">1</span><font></font>
  - addresses:<font></font>
      - ip: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.72</span><font></font>
    ports:<font></font>
      - port: <span class="hljs-number">1</span><font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: Service<font></font>
metadata:<font></font>
  name: glusterfs-cluster<font></font>
spec:<font></font>
  ports:<font></font>
  - port: <span class="hljs-number">1</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora podemos criar uma implantação de teste simples e verificar como a montagem funciona. </font><font style="vertical-align: inherit;">Abaixo está um exemplo de uma implantação de teste simples:</font></font><br>
<br>
<pre><code class="python hljs">apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        glusterfs:<font></font>
          endpoints: glusterfs-cluster<font></font>
          path: main<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta opção não nos convinha, porque temos container-linux em todos os nós do Kubernetes. </font><font style="vertical-align: inherit;">O gerenciador de pacotes não está lá, portanto, não foi possível instalar o gluster-client para montagem. </font><font style="vertical-align: inherit;">Nesse sentido, foi encontrada a terceira opção, que foi decidida a sua utilização.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GlusterFS + NFS + keepalived</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Até recentemente, o GlusterFS oferecia seu próprio servidor NFS, mas agora o serviço externo nfs-ganesha é usado para NFS. </font><font style="vertical-align: inherit;">Muito já foi escrito sobre isso, em conexão com isso, vamos descobrir como configurá-lo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O repositório deve ser registrado manualmente. </font><font style="vertical-align: inherit;">Para fazer isso, no arquivo /etc/yum.repos.d/nfs-ganesha.repo, adicionamos:</font></font><br>
<br>
<pre><code class="bash hljs">[nfs-ganesha]<font></font>
name=nfs-ganesha<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/<span class="hljs-variable">$basearch</span>/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
[nfs-ganesha-noarch]<font></font>
name=nfs-ganesha-noarch<font></font>
baseurl=https://download.nfs-ganesha.org/2.8/2.8.0/RHEL/el-8/noarch/<font></font>
enabled=1<font></font>
gpgcheck=1<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E instale:</font></font><br>
<br>
<pre><code class="bash hljs">yum -y install nfs-ganesha-gluster --nogpgcheck
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Após a instalação, realizamos a configuração básica no arquivo /etc/ganesha/ganesha.conf.</font></font><br>
<br>
<pre><code class="json hljs"># create new<font></font>
NFS_CORE_PARAM {<font></font>
    # possible to mount with NFSv3 to NFSv4 Pseudo path<font></font>
    mount_path_pseudo = true;<font></font>
    # NFS protocol<font></font>
    Protocols = 3,4;<font></font>
}<font></font>
EXPORT_DEFAULTS {<font></font>
    # default access mode<font></font>
    Access_Type = RW;<font></font>
}<font></font>
EXPORT {<font></font>
    # uniq ID<font></font>
    Export_Id = 101;<font></font>
    # mount path of Gluster Volume<font></font>
    Path = <span class="hljs-attr">"/gluster/main"</span>;<font></font>
    FSAL {<font></font>
        # any name<font></font>
        name = GLUSTER;<font></font>
        # hostname or IP address of this Node<font></font>
        hostname=<span class="hljs-attr">"gluster-01.example.com"</span>;<font></font>
        # Gluster volume name<font></font>
        volume=<span class="hljs-attr">"main"</span>;<font></font>
    }<font></font>
    # config for root Squash<font></font>
    Squash=<span class="hljs-string">"No_root_squash"</span>;<font></font>
    # NFSv4 Pseudo path<font></font>
    Pseudo=<span class="hljs-string">"/main"</span>;<font></font>
    # allowed security options<font></font>
    SecType = <span class="hljs-string">"sys"</span>;<font></font>
}<font></font>
LOG {<font></font>
    # default log level<font></font>
    Default_Log_Level = WARN;<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Precisamos iniciar o serviço, ativar nfs para o nosso volume e verificar se ele está ativado.</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start nfs-ganesha<font></font>
$ systemctl <span class="hljs-built_in">enable</span> nfs-ganesha<font></font>
$ gluster volume <span class="hljs-built_in">set</span> main nfs.disable off<font></font>
$ gluster volume status main<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, o status deve indicar que o servidor nfs foi iniciado para o nosso volume. </font><font style="vertical-align: inherit;">Você precisa montar e verificar.</font></font><br>
<br>
<pre><code class="bash hljs">mkdir /gluster-nfs<font></font>
mount.nfs gluster-01.example.com:/main /gluster-nfs</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mas essa opção não é tolerante a falhas, portanto, você precisa criar um endereço VIP que viaje entre nossos dois nós e ajude a mudar o tráfego se um dos nós cair. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A instalação de keepalived no CentOs é feita imediatamente através do gerenciador de pacotes.</font></font><br>
<br>
<pre><code class="bash hljs">$ yum install -y keepalived</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Configuramos o serviço no arquivo /etc/keepalived/keepalived.conf:</font></font><br>
<br>
<pre><code class="json hljs">global_defs {<font></font>
    notification_email {<font></font>
        admin@example.com<font></font>
    }<font></font>
    notification_email_from alarm@example.com<font></font>
    smtp_server mail.example.com<font></font>
    smtp_connect_timeout <span class="hljs-number">30</span><font></font>
<font></font>
    vrrp_garp_interval <span class="hljs-number">10</span>
    vrrp_garp_master_refresh <span class="hljs-number">30</span><font></font>
}<font></font>
<font></font>
#C   ,   .    , VIP .<font></font>
vrrp_script chk_gluster {<font></font>
    script <span class="hljs-attr">"pgrep glusterd"</span><font></font>
    interval 2<font></font>
}<font></font>
<font></font>
vrrp_instance gluster {<font></font>
    interface ens192<font></font>
    state MASTER #     BACKUP<font></font>
    priority 200 #      ,  100<font></font>
    virtual_router_id 1<font></font>
    virtual_ipaddress {<font></font>
        10.10.6.70/24<font></font>
    }<font></font>
<font></font>
    unicast_peer {<font></font>
        10.10.6.72 #        <font></font>
    }<font></font>
<font></font>
    track_script {<font></font>
        chk_gluster<font></font>
    }<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora podemos iniciar o serviço e verificar se o VIP no nó aparece:</font></font><br>
<br>
<pre><code class="bash hljs">$ systemctl start keepalived<font></font>
$ systemctl <span class="hljs-built_in">enable</span> keepalived<font></font>
$ ip addr<font></font>
1: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000<font></font>
    link/ether 00:50:56:97:55:eb brd ff:ff:ff:ff:ff:ff<font></font>
    inet 10.10.6.72/24 brd 10.10.6.255 scope global noprefixroute ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
    inet 10.10.6.70/24 scope global secondary ens192<font></font>
       valid_lft forever preferred_lft forever<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se tudo funcionou para nós, resta adicionar o PersistentVolume ao Kubernetes e criar um serviço de teste para verificar a operação.</font></font><br>
<br>
<pre><code class="python hljs">---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolume<font></font>
metadata:<font></font>
  name: gluster-nfs<font></font>
spec:<font></font>
  capacity:<font></font>
    storage: <span class="hljs-number">10</span>Gi<font></font>
  accessModes:<font></font>
    - ReadWriteMany<font></font>
  persistentVolumeReclaimPolicy: Retain<font></font>
  nfs:<font></font>
    server: <span class="hljs-number">10.10</span><span class="hljs-number">.6</span><span class="hljs-number">.70</span><font></font>
    path: /main<font></font>
<font></font>
---<font></font>
apiVersion: v1<font></font>
kind: PersistentVolumeClaim<font></font>
metadata:<font></font>
 name: gluster-nfs<font></font>
spec:<font></font>
 accessModes:<font></font>
 - ReadWriteMany<font></font>
 resources:<font></font>
   requests:<font></font>
     storage: <span class="hljs-number">10</span>Gi<font></font>
 volumeName: <span class="hljs-string">"gluster-nfs"</span><font></font>
<font></font>
---<font></font>
apiVersion: apps/v1<font></font>
kind: Deployment<font></font>
metadata:<font></font>
  name: gluster-test<font></font>
  labels:<font></font>
    app: gluster-test<font></font>
spec:<font></font>
  replicas: <span class="hljs-number">1</span><font></font>
  selector:<font></font>
    matchLabels:<font></font>
      app: gluster-test<font></font>
  template:<font></font>
    metadata:<font></font>
      labels:<font></font>
        app: gluster-test<font></font>
    spec:<font></font>
      volumes:<font></font>
      - name: gluster<font></font>
        persistentVolumeClaim:<font></font>
          claimName: gluster-nfs<font></font>
      containers:<font></font>
      - name: gluster-test<font></font>
        image: nginx<font></font>
        volumeMounts:<font></font>
        - name: gluster<font></font>
          mountPath: /gluster</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com essa configuração, no caso de uma queda do nó principal, ele fica ocioso por cerca de um minuto até que a montagem caia no tempo limite e nos comutadores. </font><font style="vertical-align: inherit;">Simples por um minuto para esse armazenamento, digamos que essa não seja uma situação regular e raramente a encontraremos, mas nesse caso o sistema alternará automaticamente e continuará funcionando, e seremos capazes de resolver o problema e realizar a recuperação sem se preocupar com o simples.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sumário</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Neste artigo, examinamos três opções possíveis para conectar o GlusterFS ao Kubernetes. Em nossa versão, é possível adicionar um provisionador ao Kubernetes, mas ainda não precisamos dele. </font><font style="vertical-align: inherit;">Resta adicionar os resultados dos testes de desempenho entre o NFS e o Gluster nos mesmos nós. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arquivos em 1Mb:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1M count=1024; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 2.63496 s, 407 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 5.4527 s, 197 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arquivos em 1Kb:</font></font><br>
<br>
<pre><code class="bash hljs">sync; dd <span class="hljs-keyword">if</span>=/dev/zero of=tempfile bs=1K count=1048576; sync<font></font>
Gluster: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 70.0508 s, 15.3 MB/s<font></font>
NFS: 1073741824 bytes (1.1 GB, 1.0 GiB) copied, 6.95208 s, 154 MB/s<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O NFS funciona da mesma forma para qualquer tamanho de arquivo, a diferença de velocidade não é particularmente perceptível, ao contrário do GlusterFS, que é muito degradado com arquivos pequenos. </font><font style="vertical-align: inherit;">Mas, ao mesmo tempo, com tamanhos de arquivo grandes, o NFS mostra desempenho 2-3 vezes menor que o Gluster.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt498144/index.html">Seu primeiro BERT: um guia ilustrado</a></li>
<li><a href="../pt498146/index.html">Seis tendências de segurança inteligentes a serem observadas</a></li>
<li><a href="../pt498150/index.html">Programadores de encanador, ou a história de um vazamento e as dificuldades de lidar com ele</a></li>
<li><a href="../pt498154/index.html">Calendário de eventos gratuitos de TI on-line de 20 a 26 de abril</a></li>
<li><a href="../pt498158/index.html">Semana 1 da Maratona Remota: Local de Trabalho</a></li>
<li><a href="../pt498162/index.html">Convidamos você para um estágio de TI no Alfa Bank</a></li>
<li><a href="../pt498164/index.html">Estratégias de produto para custos de transição</a></li>
<li><a href="../pt498168/index.html">Novas arquiteturas de redes neurais</a></li>
<li><a href="../pt498172/index.html">Java Digest para 21 de abril</a></li>
<li><a href="../pt498174/index.html">Como parar de se preocupar e começar a acreditar nos testes A / B</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
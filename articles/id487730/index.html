<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🅾️ 🤶 😷 Pemrosesan Bahasa Alami. Hasil 2019 dan tren untuk 2020 🍷 🚆 🤞🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya. Dengan beberapa penundaan, saya memutuskan untuk menerbitkan artikel ini. Setiap tahun saya mencoba merangkum apa yang terjadi di bidan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pemrosesan Bahasa Alami. Hasil 2019 dan tren untuk 2020</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/huawei/blog/487730/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Halo semuanya. </font><font style="vertical-align: inherit;">Dengan beberapa penundaan, saya memutuskan untuk menerbitkan artikel ini. </font><font style="vertical-align: inherit;">Setiap tahun saya mencoba merangkum apa yang terjadi di bidang pemrosesan bahasa alami. </font><font style="vertical-align: inherit;">Tahun ini tidak terkecuali.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERTs, BERTs ada di mana-mana</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mari kita mulai. </font><font style="vertical-align: inherit;">Jika Anda belum pergi ke taiga Siberia terpencil atau liburan di Goa selama satu setengah tahun terakhir, maka Anda pasti telah mendengar kata BERT. </font><font style="vertical-align: inherit;">Muncul pada akhir 2018, selama masa lalu, model ini telah mendapatkan popularitas sedemikian rupa sehingga gambaran seperti itu akan tepat:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/cu/vm/_i/cuvm_irxzrscw8rctmtyoqywxss.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BERT benar-benar memikat semua yang bisa diisi NLP. </font><font style="vertical-align: inherit;">Mereka mulai digunakan untuk klasifikasi, pengakuan entitas bernama, dan bahkan untuk terjemahan mesin. </font><font style="vertical-align: inherit;">Sederhananya, Anda tidak dapat melewati mereka dan Anda masih harus mengatakan apa itu. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5j/mo/sq/5jmosqk9vhjts6ai88v8hcrdhci.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gambar menunjukkan perbandingan pahlawan acara (kiri) dengan dua model yang juga terdengar. </font><font style="vertical-align: inherit;">Di sebelah kanan adalah pendahulu langsung dari </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT -</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> model </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">ELMo</font></a><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penyimpangan liris.</font></font></b><div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/8a1/bb1/e07/8a1bb1e076e3b3b1b2637343e28359d4.jpg" alt="image"><br>
         « »:           ,        ,   Elmo,  Bert —   ;    ,   ,   , —    .         .  ,    ,   .<br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Model </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Allen AI</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ELMo </font><font style="vertical-align: inherit;">adalah semacam penerus seluruh pengembangan wilayah pada tahun-tahun sebelumnya - yaitu, jaringan saraf berulang dua arah, ditambah beberapa trik baru untuk boot. Rekan-rekan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> telah </font><font style="vertical-align: inherit;">memutuskan apa yang bisa dilakukan dengan lebih baik. Dan untuk ini, Anda hanya perlu menerapkan arsitektur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformer yang</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> disajikan setahun sebelum Google </font><font style="vertical-align: inherit;">untuk tugas ini. Saya percaya bahwa selama 2,5 tahun terakhir, semua orang telah berhasil berkenalan dengan arsitektur ini, jadi saya tidak akan membahasnya secara rinci. Bagi mereka yang ingin menerima komuni, saya merujuk </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ulasan</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> saya </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">dari tahun 2017</font></a><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mereka (karyawan OpenAI) menyebut model </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2 mereka</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dan kemudian, pada model ini, mereka </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">telah melakukan pekerjaan yang cukup bagus</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Tapi mari kita tinggalkan di hati nurani mereka, dan kembalilah kepada domba-domba kita, yaitu para model. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Salah satu trik ELMo yang paling penting adalah pra-pelatihan untuk kasus besar dan tidak terisi. Ternyata sangat baik, dan kolega dari Google memutuskan bahwa kami bisa melakukan yang lebih baik lagi. Selain menerapkan arsitektur Transformer (yang sudah ada di GPT-2), BERT, yang merupakan singkatan dari Bidirectional Encoder Representations from Transformers, yaitu representasi vektor dari bidirectional encoder berdasarkan arsitektur Transformer, berisi beberapa hal yang lebih penting. Secara khusus, yang paling penting adalah cara untuk melatih kasus besar.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lb/hw/yw/lbhwywgm70j3shvnrtzrnx6clyy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gambar menunjukkan metode untuk menandai data yang tidak terisi. Dua metode tata letak secara khusus ditampilkan sekaligus. Pertama, urutan token (kata) diambil, misalnya, kalimat, dan dalam urutan ini satu token sewenang-wenang ([MASK]) bertopeng. Dan model dalam proses pembelajaran harus menebak token seperti apa yang disamarkan. Cara kedua - dua kalimat diambil secara berurutan atau dari tempat sewenang-wenang dalam teks. Dan model harus menebak apakah kalimat ini berurutan ([CLS] dan [SEP]). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ide pelatihan seperti itu sangat efektif. Jawaban dari teman sumpah dari Facebook adalah model </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RoBERTa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , sebuah artikel tentang model ini disebut "Pelatihan BERT Dioptimalkan Secara Berkelanjutan". Lebih jauh lagi.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saya tidak akan mencantumkan semua cara untuk meningkatkan pelatihan model bahasa besar berdasarkan arsitektur Transfomer karena fakta bahwa itu hanya membosankan. </font><font style="vertical-align: inherit;">Saya menyebutkan, mungkin, hanya karya rekan-rekan saya dari Hong Kong - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ERNIE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Dalam pekerjaan mereka, rekan kerja memperkaya pelatihan melalui penggunaan grafik pengetahuan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sebelum melanjutkan, berikut adalah beberapa tautan bermanfaat: artikel tentang </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Serta </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seperangkat</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> model BERT dan ELMo yang terlatih untuk bahasa Rusia.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model kecil</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tapi cukup tentang BERT. Ada beberapa tren yang lebih penting. Pertama-tama, ini adalah tren untuk mengurangi ukuran model. BERT yang sama sangat menuntut sumber daya, dan banyak yang mulai berpikir tentang cara mempertahankan (atau tidak benar-benar kehilangan) kualitas, mengurangi sumber daya yang diperlukan agar model dapat bekerja. Rekan Google muncul dengan BERT kecil, saya tidak bercanda - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ALBERT: BERT kecil</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Anda dapat melihat bahwa BERT kecil bahkan melampaui kakaknya dalam sebagian besar tugas, sambil memiliki urutan parameter yang lebih kecil. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/y5/su/h3/y5suh3uzlmgy16l8stcoahmio4w.png"> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pendekatan lain untuk bar yang sama dilakukan lagi oleh rekan-rekan saya dari Hong Kong. Mereka datang dengan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">TinyBERT kecil</font></a><font style="vertical-align: inherit;"> . (Jika pada titik ini Anda berpikir bahwa nama-nama itu mulai diulang, saya cenderung setuju dengan Anda.)</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7_/bb/el/7_bbelco1m2dewd3gj6cjqq2upw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Perbedaan mendasar antara kedua model di atas adalah bahwa jika ALBERT menggunakan trik-trik rumit untuk mengurangi model BERT asli, misalnya, berbagi parameter dan mengurangi dimensi representasi vektor internal melalui penguraian matriks, maka TinyBERT menggunakan pendekatan yang berbeda secara mendasar, yaitu distilasi pengetahuan, yaitu, ada distilasi pengetahuan, yaitu, ada model kecil yang belajar mengulang setelah kakak perempuannya dalam proses pembelajaran.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kasing kecil</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam beberapa tahun terakhir (sejak sekitar 1990, ketika Internet muncul), telah ada peningkatan bangunan yang tersedia. Kemudian muncul algoritma yang menjadi mampu memproses lampiran besar seperti itu (ini adalah apa yang kita sebut "revolusi pembelajaran yang mendalam", ini sudah tahun sejak 2013). Dan, sebagai hasilnya, mulai dirasakan secara normal bahwa untuk mendapatkan kualitas yang baik dalam beberapa tugas, diperlukan sejumlah besar data mark-up - kumpulan teks dalam kasus kami. Misalnya, kasus-kasus umum untuk tugas penerjemahan mesin pembelajaran saat ini diukur dalam jutaan pasang kalimat. Sudah lama jelas bahwa untuk banyak tugas tidak mungkin untuk mengumpulkan kasus-kasus seperti itu dalam jumlah waktu yang wajar dan untuk jumlah uang yang masuk akal. Untuk waktu yang lama tidak begitu jelas apa yang harus dilakukan. Tapi tahun lalu (siapa yang akan Anda pikirkan?) BERT datang ke tempat kejadian.Model ini dapat melakukan pra-pelatihan pada volume besar teks yang tidak terisi, dan model yang sudah selesai mudah untuk beradaptasi dengan tugas dengan case kecil.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7_/bb/el/7_bbelco1m2dewd3gj6cjqq2upw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Semua tugas yang tercantum dalam tabel ini memiliki korps pelatihan dalam ukuran beberapa </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ribu</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> unit. </font><font style="vertical-align: inherit;">Artinya, dua hingga tiga kali lipat lebih kecil. </font><font style="vertical-align: inherit;">Dan ini adalah alasan lain mengapa BERT (dan keturunan serta kerabatnya) menjadi sangat populer.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tren baru</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nah, pada akhirnya, beberapa tren baru, seperti yang saya lihat. Pertama-tama, ini adalah perubahan mendasar dalam sikap terhadap teks. Jika semua waktu sebelumnya dalam sebagian besar tugas teks hanya dirasakan sebagai bahan input, dan hasilnya adalah sesuatu yang bermanfaat, misalnya, label kelas. Sekarang masyarakat memiliki kesempatan untuk mengingat bahwa teks tersebut terutama merupakan alat komunikasi, yaitu, Anda dapat "berbicara" dengan model - mengajukan pertanyaan dan menerima jawaban dalam bentuk teks yang dapat dibaca manusia. Inilah yang dikatakan oleh artikel baru dari Google </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T5</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (namanya dapat diterjemahkan sebagai "transformator lima kali").</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ba/vz/mj/bavzmjwryypmza-ywo18njxfbjy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tren penting lainnya adalah bahwa wilayah tersebut belajar kembali untuk bekerja dengan teks yang panjang. Sejak tahun 70-an, komunitas memiliki cara untuk bekerja dengan teks yang panjangnya sewenang-wenang - ambil TF-IDF yang sama. Tetapi model ini memiliki batas kualitas sendiri. Tetapi model pembelajaran mendalam yang baru tidak dapat bekerja dengan teks yang panjang (BERT yang sama memiliki batas 512 token dari panjang teks input). Namun akhir-akhir ini, setidaknya dua karya muncul bahwa dari sisi yang berbeda mendekati masalah teks panjang. Karya pertama dari kelompok Ruslan Salakhutdinov disebut Transformer-XL. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ci/op/gj/ciopgjs1htbc2gmucz7dwkiwqtk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam karya ini, idenya dihidupkan kembali yang menjadikan jaringan rekursif begitu populer - Anda dapat menyimpan status sebelumnya dan menggunakannya untuk membangun yang berikutnya, bahkan jika Anda tidak memutar gradien mundur dalam waktu (BPTT). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kedua</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">karya ini</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bekerja dengan polinomial Legendre dan dengan bantuan mereka memungkinkan untuk memproses urutan puluhan ribu token dengan jaringan saraf berulang. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mengenai hal ini, saya ingin menyelesaikan tinjauan perubahan yang telah terjadi dan tren yang muncul. </font><font style="vertical-align: inherit;">Mari kita lihat apa yang akan terjadi tahun ini, saya yakin banyak hal yang menarik. </font><font style="vertical-align: inherit;">Video pidato saya tentang topik yang sama di Pohon Data:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cdlAUcaOCDY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS Kami akan segera memiliki beberapa pengumuman yang lebih menarik, jangan beralih!</font></font></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id487706/index.html">Service Discovery dalam sistem terdistribusi menggunakan contoh Konsul. Alexander Sigachev</a></li>
<li><a href="../id487716/index.html">SAST sempurna. Parser</a></li>
<li><a href="../id487720/index.html">Tentang persaingan ketat (menggunakan pemrograman reaktif sebagai contoh)</a></li>
<li><a href="../id487724/index.html">BlazingPizza: Aplikasi Blazor dari awal hingga akhir. Bagian 2. Tambahkan komponen</a></li>
<li><a href="../id487728/index.html">@Pythonetc kompilasi, Januari 2020</a></li>
<li><a href="../id487734/index.html">Mempercepat Inti Kerangka Entitas</a></li>
<li><a href="../id487738/index.html">Animasi skema di SCADA</a></li>
<li><a href="../id487740/index.html">Merakit magnetometer portabel</a></li>
<li><a href="../id487742/index.html">Perdagangan Arbitrage (Algoritma Bellman-Ford)</a></li>
<li><a href="../id487744/index.html">FARO Memperkenalkan FOCUS S 70 Laser 3D Scanner</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
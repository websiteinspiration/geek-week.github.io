<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥙 📅 🌿 Verarbeitung natürlicher Sprache. Ergebnisse 2019 und Trends für 2020 🚣🏾 🐆 👨🏻‍🔬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo alle zusammen. Mit einiger Verzögerung habe ich beschlossen, diesen Artikel zu veröffentlichen. Jedes Jahr versuche ich zusammenzufassen, was au...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Verarbeitung natürlicher Sprache. Ergebnisse 2019 und Trends für 2020</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/huawei/blog/487730/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo alle zusammen. </font><font style="vertical-align: inherit;">Mit einiger Verzögerung habe ich beschlossen, diesen Artikel zu veröffentlichen. </font><font style="vertical-align: inherit;">Jedes Jahr versuche ich zusammenzufassen, was auf dem Gebiet der Verarbeitung natürlicher Sprache passiert ist. </font><font style="vertical-align: inherit;">Dieses Jahr war keine Ausnahme.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BERTs, BERTs sind überall</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fangen wir in der richtigen Reihenfolge an. </font><font style="vertical-align: inherit;">Wenn Sie in den letzten anderthalb Jahren nicht in die abgelegene sibirische Taiga oder in den Urlaub nach Goa gereist sind, müssen Sie das Wort BERT gehört haben. </font><font style="vertical-align: inherit;">Dieses Modell, das Ende 2018 in der Vergangenheit erschien, hat eine solche Popularität erlangt, dass genau ein solches Bild genau richtig sein wird:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/cu/vm/_i/cuvm_irxzrscw8rctmtyoqywxss.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BERTs faszinierten wirklich alles, was in NLP gefüllt werden konnte. </font><font style="vertical-align: inherit;">Sie wurden zur Klassifizierung, Erkennung benannter Entitäten und sogar zur maschinellen Übersetzung verwendet. </font><font style="vertical-align: inherit;">Einfach ausgedrückt, Sie können sie nicht umgehen und müssen immer noch sagen, was es ist. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5j/mo/sq/5jmosqk9vhjts6ai88v8hcrdhci.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Bild zeigt einen Vergleich des Helden des Anlasses (links) mit zwei Modellen, die ebenfalls klangen. </font><font style="vertical-align: inherit;">Rechts ist der unmittelbare Vorgänger von BERT - das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ELMo-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modell </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lyrischer Exkurs.</font></font></b><div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/8a1/bb1/e07/8a1bb1e076e3b3b1b2637343e28359d4.jpg" alt="image"><br>
         « »:           ,        ,   Elmo,  Bert —   ;    ,   ,   , —    .         .  ,    ,   .<br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Allen AI</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ELMo-Modell </font><font style="vertical-align: inherit;">ist eine Art Nachfolger der gesamten Entwicklung der Region in den vergangenen Jahren - nämlich ein bidirektionales wiederkehrendes neuronales Netzwerk sowie mehrere neue Tricks. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kollegen haben </font><font style="vertical-align: inherit;">entschieden, was besser gemacht werden kann. Dazu müssen Sie lediglich die im Jahr vor Google vorgestellte </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformer-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Architektur </font><font style="vertical-align: inherit;">auf diese Aufgabe </font><font style="vertical-align: inherit;">anwenden </font><font style="vertical-align: inherit;">. Ich glaube, dass es in den letzten 2,5 Jahren bereits allen gelungen ist, sich mit dieser Architektur vertraut zu machen, daher werde ich nicht näher darauf eingehen. Für diejenigen, die Kommunion erhalten möchten, verweise ich auf meine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bewertung aus dem 2017. Jahr</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie (OpenAI-Mitarbeiter) nannten ihr </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modell </font><font style="vertical-align: inherit;">. Und dann haben sie bei diesem Modell </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ziemlich gute Arbeit geleistet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Aber lassen wir es auf ihrem Gewissen und kehren zu unseren Schafen zurück, das heißt zu den Modellen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einer der wichtigsten ELMo-Tricks war das Pre-Training für einen großen, nicht zugewiesenen Fall. Es ist sehr gut gelaufen, und Kollegen von Google haben entschieden, dass wir es noch besser machen können. Neben der Anwendung der Transformer-Architektur (die bereits in GPT-2 enthalten war) enthielt BERT, das für bidirektionale Encoder-Darstellungen von Transformatoren steht, dh Vektordarstellungen von einem bidirektionalen Encoder, der auf der Transformer-Architektur basiert, einige weitere wichtige Dinge. Das Wichtigste war insbesondere die Art und Weise, in einem großen Fall zu trainieren.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lb/hw/yw/lbhwywgm70j3shvnrtzrnx6clyy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Bild zeigt eine Methode zum Markieren nicht zugeordneter Daten. Es werden speziell zwei Layoutmethoden gleichzeitig gezeigt. Zuerst wird eine Folge von Token (Wörtern) genommen, beispielsweise ein Satz, und in dieser Folge wird ein beliebiges Token ([MASK]) maskiert. Und das Modell im Lernprozess sollte erraten, welche Art von Token getarnt wurde. Der zweite Weg - zwei Sätze werden nacheinander oder an beliebigen Stellen im Text genommen. Und das Modell muss raten, ob diese Sätze sequentiell waren ([CLS] und [SEP]). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Idee eines solchen Trainings war äußerst effektiv. Die Antwort von vereidigten Freunden von Facebook war das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RoBERTa-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modell </font><font style="vertical-align: inherit;">. Ein Artikel über dieses Modell heißt „Nachhaltig optimiertes BERT-Training“. Außerdem.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich werde nicht alle Möglichkeiten auflisten, um das Training eines großen Sprachmodells basierend auf der Transfomer-Architektur zu verbessern, da es einfach langweilig ist. </font><font style="vertical-align: inherit;">Ich erwähne vielleicht nur die Arbeit meiner Kollegen aus Hongkong - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ERNIE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">In ihrer Arbeit bereichern Kollegen die Ausbildung durch die Verwendung von Wissensgraphen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bevor Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fortfahren</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , finden Sie hier einige nützliche Links: einen Artikel über </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">BERT</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Sowie eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reihe von</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> geschulten BERT- und ELMo-Modellen für die russische Sprache.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kleine Modelle</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber genug über BERTs. Es gibt mehrere wichtige Trends. Dies ist vor allem ein Trend, die Größe des Modells zu reduzieren. Das gleiche BERT stellt hohe Anforderungen an die Ressourcen, und viele begannen darüber nachzudenken, wie die Qualität erhalten (oder nicht wirklich verloren) und die erforderlichen Ressourcen für das Funktionieren der Modelle reduziert werden können. Google-Kollegen haben sich ein kleines BERT ausgedacht, ich scherze nicht - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ALBERT: Ein kleines BERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Sie können sehen, dass der kleine BERT bei den meisten Aufgaben sogar seinen älteren Bruder übertrifft, während er um eine Größenordnung weniger Parameter hat. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/y5/su/h3/y5suh3uzlmgy16l8stcoahmio4w.png"> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein anderer Ansatz für dieselbe Bar wurde erneut von meinen Kollegen aus Hongkong gemacht. Sie kamen mit einem winzigen BERT - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TinyBERT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . (Wenn Sie zu diesem Zeitpunkt dachten, dass sich die Namen wiederholen, bin ich geneigt, Ihnen zuzustimmen.)</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7_/bb/el/7_bbelco1m2dewd3gj6cjqq2upw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der grundlegende Unterschied zwischen den beiden oben genannten Modellen besteht darin, dass, wenn ALBERT knifflige Tricks verwendet, um das ursprüngliche BERT-Modell zu reduzieren, z. B. die gemeinsame Nutzung von Parametern und die Reduzierung der Dimension interner Vektordarstellungen durch Matrixzerlegung, TinyBERT einen grundlegend anderen Ansatz verwendet, nämlich die Destillation von Wissen ein kleines Modell, das lernt, sich nach ihrer älteren Schwester im Lernprozess zu wiederholen.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kleine Fälle</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den letzten Jahren (seit etwa 1990, als das Internet erschien) haben die verfügbaren Gebäude zugenommen. Dann kamen die Algorithmen, die in der Lage waren, so große Gehäuse zu verarbeiten (dies ist die „Revolution des tiefen Lernens“, dies ist bereits das Jahr seit 2013). Infolgedessen wurde normal wahrgenommen, dass große Arrays markierter Daten erforderlich sind, um bei einer bestimmten Aufgabe eine gute Qualität zu erzielen - in unserem Fall ein Korpus von Texten. Beispielsweise werden typische Fälle für das Erlernen von maschinellen Übersetzungsaufgaben heutzutage in Millionen von Satzpaaren gemessen. Es ist seit langem offensichtlich, dass es für viele Aufgaben unmöglich ist, solche Fälle in angemessener Zeit und für einen angemessenen Geldbetrag zusammenzustellen. Lange war nicht klar, was man dagegen tun sollte. Aber letztes Jahr (wer denkst du?) Kam BERT auf die Bühne.Dieses Modell war in der Lage, große Mengen nicht zugeordneter Texte vorab zu trainieren, und das fertige Modell war mit einem kleinen Fall leicht an die Aufgabe anzupassen.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7_/bb/el/7_bbelco1m2dewd3gj6cjqq2upw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alle in dieser Tabelle aufgeführten Aufgaben haben ein Ausbildungskorps in der Größe von mehreren </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tausend</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Einheiten. </font><font style="vertical-align: inherit;">Das heißt, zwei bis drei Größenordnungen weniger. </font><font style="vertical-align: inherit;">Und dies ist ein weiterer Grund, warum BERT (und seine Nachkommen und Verwandten) so beliebt geworden sind.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neue Trends</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, am Ende ein paar neue Trends, wie ich sie gesehen habe. Dies ist vor allem eine grundlegende Änderung der Einstellung zum Text. Wenn in den meisten Aufgaben die gesamte vorherige Zeit der Text nur als Eingabematerial wahrgenommen wurde und die Ausgabe etwas Nützliches war, beispielsweise eine Klassenbezeichnung. Jetzt hat die Community die Möglichkeit, sich daran zu erinnern, dass der Text in erster Linie ein Kommunikationsmittel ist, dh Sie können mit dem Modell „sprechen“ - Fragen stellen und Antworten in Form eines für Menschen lesbaren Textes erhalten. Dies ist, was der neue Artikel von Google </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T5</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sagt </font><font style="vertical-align: inherit;">(der Name kann als "fünfmal Transformator" übersetzt werden).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ba/vz/mj/bavzmjwryypmza-ywo18njxfbjy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein weiterer wichtiger Trend ist, dass die Region wieder lernt, mit langen Texten zu arbeiten. Seit den 70er Jahren hat die Community Möglichkeiten, mit Text beliebiger Länge zu arbeiten - nehmen Sie dieselbe TF-IDF. Diese Modelle haben jedoch ihre eigene Qualitätsgrenze. Die neuen Deep-Learning-Modelle konnten jedoch nicht mit langen Texten arbeiten (derselbe BERT hat eine Begrenzung auf 512 Token für die Länge des Eingabetextes). In letzter Zeit sind jedoch mindestens zwei Werke erschienen, die sich von verschiedenen Seiten dem Problem des Langtextes nähern. Die erste Arbeit aus der Gruppe von Ruslan Salakhutdinov namens Transformer-XL. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ci/op/gj/ciopgjs1htbc2gmucz7dwkiwqtk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In dieser Arbeit wird die Idee wiederbelebt, die wiederkehrende Netzwerke so beliebt gemacht hat. Sie können den vorherigen Status speichern und zum Erstellen des nächsten verwenden, auch wenn Sie den Gradienten nicht in der Zeit zurückwerfen (BPTT). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der zweite</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Arbeit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> arbeitet mit Legendre-Polynomen und ermöglicht mit ihrer Hilfe die Verarbeitung von Sequenzen von Zehntausenden von Token mit wiederkehrenden neuronalen Netzen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Zusammenhang möchte ich die Überprüfung der eingetretenen Änderungen und der aufkommenden Trends abschließen. </font><font style="vertical-align: inherit;">Mal sehen, was dieses Jahr passieren wird, ich bin mir sicher, dass es viele interessante Dinge gibt. </font><font style="vertical-align: inherit;">Video meiner Rede zum gleichen Thema im Datenbaum:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/cdlAUcaOCDY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS Wir werden bald weitere interessante Ankündigungen haben, nicht wechseln!</font></font></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de487706/index.html">Service Discovery in verteilten Systemen anhand des Consul-Beispiels. Alexander Sigachev</a></li>
<li><a href="../de487716/index.html">Perfekt SAST. Parser</a></li>
<li><a href="../de487720/index.html">Zum Wettbewerbskorutinismus (am Beispiel der reaktiven Programmierung)</a></li>
<li><a href="../de487724/index.html">BlazingPizza: Blazor App von Anfang bis Ende. Teil 2. Fügen Sie eine Komponente hinzu</a></li>
<li><a href="../de487728/index.html">@ Pythonetc-Zusammenstellung, Januar 2020</a></li>
<li><a href="../de487734/index.html">Beschleunigung des Entity Framework-Kerns</a></li>
<li><a href="../de487738/index.html">Schemaanimation in SCADA</a></li>
<li><a href="../de487740/index.html">Zusammenbau eines tragbaren Magnetometers</a></li>
<li><a href="../de487742/index.html">Arbitrage-Handel (Bellman-Ford-Algorithmus)</a></li>
<li><a href="../de487744/index.html">FARO stellt den FOCUS S 70 Laser 3D Scanner vor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüë¶‚Äçüë¶ üåæ üëÇüèª Entropia: como as √Årvores de Decis√£o tomam decis√µes üòá ‚û°Ô∏è üë®üèø‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Uma tradu√ß√£o do artigo foi preparada antes do in√≠cio do curso Machine Learning .
 
 
 
 Voc√™ √© um especialista em ci√™ncia de dados que est√° atualmente...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Entropia: como as √Årvores de Decis√£o tomam decis√µes</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/502200/"><i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uma tradu√ß√£o do artigo foi preparada antes do in√≠cio do curso </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Machine Learning</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></b></i><br>
<br>
<img src="https://habrastorage.org/webt/az/2h/3e/az2h3eq1jejcxtd0g4wi4gmamki.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ √© um especialista em ci√™ncia de dados que est√° atualmente seguindo um caminho de aprendizado. E voc√™ percorreu um longo caminho desde que escreveu sua primeira linha de c√≥digo em Python ou R. Voc√™ conhece o Scikit-Learn como a palma da sua m√£o. Agora voc√™ est√° mais sentado no Kaggle do que no Facebook. Voc√™ n√£o √© novo na cria√ß√£o de florestas aleat√≥rias impressionantes e outros modelos de conjunto de √°rvores de decis√£o que fazem um excelente trabalho. No entanto, voc√™ sabe que n√£o conseguir√° nada se n√£o se desenvolver de forma abrangente. Voc√™ deseja aprofundar e entender os meandros e os conceitos subjacentes aos modelos populares de aprendizado de m√°quina. Bem, eu tamb√©m.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hoje vou falar sobre o conceito de entropia - um dos t√≥picos mais importantes da estat√≠stica, e mais tarde falaremos sobre o conceito de ganho de informa√ß√£o (ganho de informa√ß√£o) e descobriremos por que esses conceitos fundamentais formam a base de como as √°rvores de decis√£o s√£o constru√≠das a partir dos dados obtidos.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Boa. Agora vamos transgredir. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O que √© entropia? Em termos simples, a entropia n√£o passa de uma medida de desordem. (Tamb√©m pode ser considerada uma medida de pureza, e logo voc√™ ver√° o porqu√™. Mas eu gosto mais da bagun√ßa porque parece mais legal.) A </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
f√≥rmula matem√°tica da entropia √© a seguinte: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ey/wa/u-/eywau-ntm5stedcuyrelbhhoipu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropia. √Äs vezes, √© escrito como H.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Aqui p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √© a probabilidade de frequ√™ncia de um elemento / classe i de nossos dados. Por simplicidade, suponha que tenhamos apenas duas classes: positiva e negativa. Ent√£o pegarei o valor de "+" ou "-". Se tiv√©ssemos um total de 100 pontos em nosso conjunto de dados, 30 dos quais pertenciam √† classe positiva e 70 √† negativa, ent√£o p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> seria 3/10 ep</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ser√° 7/10. Tudo √© simples aqui. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se eu calcular a entropia das classes neste exemplo, √© isso que recebo usando a f√≥rmula acima: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5_/hh/20/5_hh20bihmp119n_5vzmlq_vuyw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Entropia √© de cerca de 0,88. Esse valor √© considerado bastante alto, ou seja, temos um alto n√≠vel de entropia ou desordem (ou seja, um baixo valor de pureza). A entropia √© medida no intervalo de 0 a 1. Dependendo do n√∫mero de classes no seu conjunto de dados, o valor da entropia pode ser maior que 1, mas significa o mesmo que o n√≠vel de desordem √© extremamente alto. Para simplificar a explica√ß√£o, no artigo de hoje, teremos entropia variando de 0 a 1. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D√™ uma olhada no gr√°fico abaixo.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jt/sx/zs/jtsxzsfwwbstp10fqo-rd0ndddw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No eixo X, o n√∫mero de pontos da classe positiva em cada c√≠rculo √© refletido e, no eixo Y, as entropias correspondentes. Voc√™ pode notar imediatamente a forma de U invertida do gr√°fico. A entropia ser√° a menor em extremos quando n√£o houver elementos positivos no c√≠rculo, em princ√≠pio, ou quando houver apenas elementos positivos. Ou seja, quando os elementos s√£o id√™nticos em um c√≠rculo, o dist√∫rbio ser√° 0. A entropia ser√° mais alta no meio do gr√°fico, onde os elementos positivos e negativos ser√£o distribu√≠dos igualmente dentro do c√≠rculo. Aqui a maior entropia ou desordem ser√° alcan√ßada, uma vez que n√£o haver√° elementos predominantes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Existe alguma raz√£o para a entropia ser medida usando o logaritmo de base 2, ou por que a entropia √© medida entre 0 e 1, e n√£o em um intervalo diferente? N√£o, n√£o h√° raz√£o. Esta √© apenas uma m√©trica. N√£o √© t√£o importante entender por que isso est√° acontecendo. √â importante saber como o que chegamos acima √© calculado e como funciona. A entropia √© uma medida de confus√£o ou incerteza, e o objetivo dos modelos de aprendizado de m√°quina e dos especialistas em ci√™ncia de dados em geral √© reduzir essa incerteza. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora sabemos como a bagun√ßa √© medida. Em seguida, precisamos de um valor para medir a redu√ß√£o desse dist√∫rbio nas informa√ß√µes adicionais (atributos / vari√°veis ‚Äã‚Äãindependentes) da vari√°vel / classe alvo. √â aqui que o ganho de informa√ß√£o ou o ganho de informa√ß√£o entra em jogo. Do ponto de vista da matem√°tica, pode ser escrito da seguinte maneira:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bn/el/t4/bnelt40yxay8hkbanig088mpk6a.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Simplesmente subtra√≠mos a entropia Y de X da entropia Y para calcular a diminui√ß√£o na incerteza sobre Y, desde que X sobre Y esteja dispon√≠vel. Quanto mais forte a incerteza diminuir, mais informa√ß√µes poder√£o ser obtidas de Y sobre X. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vejamos um exemplo simples da tabela de conting√™ncia para que Aproxime-se da quest√£o de como as √°rvores de decis√£o usam a entropia e o ganho de informa√ß√µes para decidir em que base os n√≥s do processo de aprendizado de dados s√£o quebrados. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemplo: tabela de conjuga√ß√£o</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/s4/ea/e5/s4eae57mpuehp3mk_mjpmikuan0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Aqui, nossa vari√°vel de destino ser√° </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Responsabilidade</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que pode assumir apenas dois valores: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Normal"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Alto"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Tamb√©m temos apenas um sinal, chamado Rating de Cr√©dito, que distribui os valores em tr√™s categorias: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Excelente"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Bom"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Ruim"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Foram feitas 14 observa√ß√µes. 7 deles pertencem √† classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilidade normal</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e 7 outros √† classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">alta responsabilidade</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Esta √© uma divis√£o em si. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se observarmos a soma total dos valores na primeira linha, veremos que temos 4 observa√ß√µes com Valor </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">excelente</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> com </font><font style="vertical-align: inherit;">base no </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Al√©m disso, posso at√© dizer que minha vari√°vel de destino √© quebrada pelo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de cr√©dito ‚ÄúExcelente‚Äù</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Entre as observa√ß√µes com o valor </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúExcelente‚Äù</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> por atributo</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classifica√ß√£o de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , existem 3 que pertencem √† classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilidade normal</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e 1 que pertence √† </font><font style="vertical-align: inherit;">classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">alta responsabilidade</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Da mesma forma, posso calcular resultados semelhantes para outros valores de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> da tabela de conting√™ncia. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por exemplo, eu uso a tabela de conting√™ncia acima para calcular independentemente a entropia de nossa vari√°vel de destino e depois calcular sua entropia, levando em considera√ß√£o informa√ß√µes adicionais do atributo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de Cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Assim, posso calcular a quantidade de informa√ß√µes adicionais que o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fornecer√° </font><font style="vertical-align: inherit;">para a vari√°vel de meta de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilidade</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Ent√£o vamos come√ßar.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2v/2y/lg/2v2ylghvtk-f-e0eom6aeocsb1q.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 A entropia da nossa vari√°vel alvo √© 1, o que significa desorganiza√ß√£o m√°xima devido √† distribui√ß√£o uniforme de elementos entre </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Normal"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Alto"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . O pr√≥ximo passo √© calcular a entropia da vari√°vel de destino do </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Passivo</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , levando em considera√ß√£o informa√ß√µes adicionais do </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de Cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Para fazer isso, calculamos a entropia de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilidade</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para cada valor do </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e os adicionamos usando a taxa de observa√ß√£o ponderada m√©dia para cada valor. O motivo pelo qual usamos a m√©dia ponderada ficar√° mais claro quando falamos sobre √°rvores de decis√£o. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rt/_5/fh/rt_5fhldx4dfjcioh7d_uiori6e.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Obtivemos a entropia da nossa vari√°vel alvo com o atributo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classifica√ß√£o de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Agora podemos calcular o ganho de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">responsabilidade</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> informacional </font><font style="vertical-align: inherit;">do </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rating de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para entender o qu√£o informativo esse recurso √©. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 O conhecimento </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">do rating de cr√©dito</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nos ajudou a reduzir a incerteza de nossa vari√°vel de meta de </font><i><font style="vertical-align: inherit;">responsabilidade</font></i><font style="vertical-align: inherit;"> .</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. N√£o √© um bom sinal de que deve funcionar? D√™-nos informa√ß√µes sobre a vari√°vel de destino? Bem, por essa mesma raz√£o, as √°rvores de decis√£o usam entropia e ganho informacional. Eles determinam por qual crit√©rio dividir os n√≥s em ramifica√ß√µes, para abordar a vari√°vel de destino com cada parti√ß√£o subseq√ºente e tamb√©m para entender quando a constru√ß√£o da √°rvore precisa ser conclu√≠da! (al√©m de hiperpar√¢metros, como profundidade m√°xima, √© claro). Vamos ver como tudo isso funciona no exemplo a seguir, usando √°rvores de decis√£o. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemplo: √°rvore de decis√£o</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Vejamos um exemplo de constru√ß√£o de uma √°rvore de decis√£o, com o objetivo de prever se o cr√©dito de uma pessoa ser√° baixado ou n√£o. A popula√ß√£o ser√° de 30 c√≥pias. 16 pertencer√£o √† classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baixa </font><font style="vertical-align: inherit;">e os outros 14</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"N√£o amortizado"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Teremos dois sinais, a saber, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Equil√≠brio"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que pode assumir dois valores: "&lt;50K" ou "&gt; 50K" e </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Resid√™ncia"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que aceita tr√™s valores: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"PR√ìPRIO"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"ALUGAR"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OUTROS"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Demonstrarei como o algoritmo da √°rvore de decis√£o decidir√° qual atributo ser√° quebrado primeiro e qual ser√° o mais informativo, ou seja, elimina melhor a incerteza da vari√°vel de destino usando o conceito de entropia e ganho de informa√ß√£o. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sintoma 1: Equil√≠brio</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Aqui, os c√≠rculos pertencem √† </font><font style="vertical-align: inherit;">classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"write-off"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e as estrelas correspondem √† classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"non-write-off"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Particionando uma raiz pai por atributo</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O saldo</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nos dar√° 2 n√≥s de herdeiro. No n√≥ esquerdo, haver√° 13 observa√ß√µes, sendo 12/13 (probabilidade 0,92) de observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"write-off"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e apenas 1/13 (probabilidade 0,08) de observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"non-write-off"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . No n√≥ direito, haver√° 17 das 30 observa√ß√µes, sendo 13/17 (probabilidade 0,76) das observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"write-off"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e 4/17 (probabilidade 0,24) das observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"non-write-off"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vamos calcular a entropia da raiz e ver o quanto a √°rvore pode reduzir a incerteza usando uma parti√ß√£o baseada em </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yq/ke/do/yqkedojc2s80__h-vqqcptzewai.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Uma divis√£o com base no </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Saldo</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fornecer√° um ganho informacional de 0,37. Vamos contar o mesmo para o sinal de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resid√™ncia</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e compare os resultados. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sintoma 2: Resid√™ncia Ao</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/mx/tm/sd/mxtmsdt2hm0mamxkdxzqnb9v7mg.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 dividir uma √°rvore com base no </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , voc√™ ter√° tr√™s n√≥s de herdeiro. O n√≥ descendente esquerdo receber√° 8 observa√ß√µes, onde 7/8 (probabilidade 0,88) de observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baixa </font><font style="vertical-align: inherit;">e apenas 1/8 (probabilidade 0,12) de observa√ß√µes da classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n√£o</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baixa </font><font style="vertical-align: inherit;">. O n√≥ m√©dio sucessor receber√° 10 observa√ß√µes, onde 4/10 (probabilidade 0,4) de observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baixa </font><font style="vertical-align: inherit;">e 6/10 (probabilidade 0,6) de observa√ß√µes da classe de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n√£o</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baixa </font><font style="vertical-align: inherit;">. O herdeiro certo receber√° 12 observa√ß√µes, sendo 5/12 (probabilidade 0,42) de observa√ß√µes da classe </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> baixa </font><font style="vertical-align: inherit;">e 7/12 (probabilidade 0,58) de observa√ß√µes da classe de </font><i><font style="vertical-align: inherit;">n√£o</font></i><font style="vertical-align: inherit;"> baixa</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. J√° conhecemos a entropia do n√≥ pai, portanto, simplesmente calculamos a entropia ap√≥s a parti√ß√£o para entender o ganho informacional do atributo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/cb/zt/zf/cbztzffw12-wkj6cjfayt_jzlcq.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 O ganho informativo do atributo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √© </font><font style="vertical-align: inherit;">quase tr√™s vezes maior que o da </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! Se voc√™ olhar os gr√°ficos novamente, ver√° que a parti√ß√£o de acordo com o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fornecer√° n√≥s descendentes mais limpos do que de acordo com a </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . No entanto, o n√≥ mais √† esquerda no </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tamb√©m </font><i><font style="vertical-align: inherit;">√©</font></i><font style="vertical-align: inherit;"> bastante limpo, mas √© aqui que a m√©dia ponderada entra em jogo. Apesar de o n√≥ estar limpo, possui o menor n√∫mero de observa√ß√µes e seu resultado √© perdido no rec√°lculo geral e no c√°lculo da entropia total de acordo com </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Isso √© importante porque procuramos o conte√∫do informativo geral do atributo e n√£o queremos que o resultado final seja distorcido pelo valor raro do atributo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O pr√≥prio atributo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fornece mais informa√ß√µes sobre a vari√°vel de destino do que </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Assim, a entropia da nossa vari√°vel alvo √© reduzida. O algoritmo da √°rvore de decis√£o usa esse resultado para fazer a primeira divis√£o de acordo com </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para decidir posteriormente em que base quebrar os seguintes n√≥s. No mundo real, quando existem mais de dois recursos, o primeiro detalhamento ocorre de acordo com o recurso mais informativo e, a cada detalhamento subsequente, o ganho de informa√ß√µes ser√° recontado para cada recurso adicional, pois n√£o ser√° o mesmo que o ganho de informa√ß√µes de cada recurso individualmente. Entropia e ganho informacional devem ser calculados ap√≥s uma ou v√°rias parti√ß√µes, o que afetar√° o resultado final. A √°rvore de decis√£o repetir√° esse processo √† medida que cresce em profundidade, at√© atingir uma certa profundidade ou algum tipo de divis√£o levar a um ganho informacional mais alto al√©m de um determinado limite, que tamb√©m pode ser especificado como um hiperpar√¢metro!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Isso √© tudo! </font><font style="vertical-align: inherit;">Agora voc√™ sabe qual entropia, ganho de informa√ß√£o e como eles s√£o calculados. </font><font style="vertical-align: inherit;">Agora voc√™ entende como a √°rvore de decis√£o, sozinha ou como parte de um conjunto, toma decis√µes sobre a melhor ordem de particionamento por atributos e decide quando parar ao aprender os dados dispon√≠veis. </font><font style="vertical-align: inherit;">Bem, se voc√™ precisar explicar a algu√©m como as √°rvores de decis√£o funcionam, espero que voc√™ lide adequadamente com essa tarefa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Espero que voc√™ tenha aprendido algo √∫til para si mesmo neste artigo. </font><font style="vertical-align: inherit;">Se eu perdi alguma coisa ou me expressei incorretamente, escreva-me sobre isso. </font><font style="vertical-align: inherit;">Ficarei muito grato a voc√™! </font><font style="vertical-align: inherit;">Obrigado.</font></font><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Saiba mais sobre o curso.</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt502178/index.html">oVirt em 2 horas. Parte 3. Configura√ß√µes avan√ßadas</a></li>
<li><a href="../pt502180/index.html">O dia em que o per√≠metro desapareceu. Solu√ß√µes de seguran√ßa da Microsoft e parceiros</a></li>
<li><a href="../pt502182/index.html">Novamente sobre o MikroTik ou o t√£o esperado SOCKS5</a></li>
<li><a href="../pt502186/index.html">Webinar. Seguran√ßa da informa√ß√£o: SOC em quarentena</a></li>
<li><a href="../pt502196/index.html">–í –ø–æ–¥—Ö–æ–¥–µ –∫ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ —Å—Ç–æ–ª–µ—Ç–Ω–µ–π –¥–∞–≤–Ω–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω—ã –Ω–æ–≤—ã–µ –∫–ª—é—á–∏ –∫ —Ä–∞–∑–≥–∞–¥–∫–µ –ø—Ä–∏—Ä–æ–¥—ã –≤—Ä–µ–º–µ–Ω–∏</a></li>
<li><a href="../pt502202/index.html">O desenvolvimento de tecnologia n√£o tripulada no transporte ferrovi√°rio</a></li>
<li><a href="../pt502204/index.html">Gravando testes @SpringBootTest ao usar o Spring Shell em um aplicativo</a></li>
<li><a href="../pt502206/index.html">Yandex registrou os sons dos retrocomputadores</a></li>
<li><a href="../pt502208/index.html">Extens√£o do Chrome para ocultar recomenda√ß√µes perturbadoras no YouTube</a></li>
<li><a href="../pt502234/index.html">–ò–Ω—Å–∞–π–¥—ã –æ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ Facebook: –∫–∞–∫ –ø–æ–ø–∞—Å—Ç—å –Ω–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É, –ø–æ–ª—É—á–∏—Ç—å –æ—Ñ—Ñ–µ—Ä –∏ –≤—Å–µ –æ —Ä–∞–±–æ—Ç–µ –≤ –∫–æ–º–ø–∞–Ω–∏–∏</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóÉÔ∏è üèáüèΩ üé∑ OpenVINO Hackathon: Erkennen von Stimme und Emotion auf dem Raspberry Pi üßïüèª üì™ üåÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="30. November - 1. Dezember in Nischni Nowgorod OpenVINO Hackathon wurde abgehalten . Die Teilnehmer wurden gebeten, mit dem Intel OpenVINO-Toolkit ein...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>OpenVINO Hackathon: Erkennen von Stimme und Emotion auf dem Raspberry Pi</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/486672/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">30. November - 1. Dezember in Nischni Nowgorod </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenVINO Hackathon</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wurde abgehalten </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Die Teilnehmer wurden gebeten, mit dem Intel OpenVINO-Toolkit einen Prototyp einer Produktl√∂sung zu erstellen. </font><font style="vertical-align: inherit;">Die Organisatoren schlugen eine Liste von Beispielthemen vor, an denen sich die Auswahl einer Aufgabe orientieren konnte. Die endg√ºltige Entscheidung blieb jedoch bei den Teams. </font><font style="vertical-align: inherit;">Dar√ºber hinaus wurde die Verwendung von Modellen empfohlen, die nicht im Produkt enthalten sind.</font></font></p><br>
<p><img src="https://habrastorage.org/webt/o6/wy/ig/o6wyigv73bagr9kgojjthtu4mz0.jpeg"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In dem Artikel werden wir dar√ºber sprechen, wie wir unseren Prototyp des Produkts erstellt haben, mit dem wir schlie√ülich den ersten Platz gewonnen haben.</font></font></p><a name="habracut"></a><br>
<p>    10 . ,        .       ‚Äú  ‚Äù,        , ! (,        Intel     ).      26 ,       .     -,  ,     ,      . , , ,   !</p><br>
<p> ,  Intel    , Raspberry PI, Neural Compute Stick 2.</p><br>
<h3 id="vybor-zadachi"> </h3><br>
<p>             .    -,     ,      ,    .</p><br>
<p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>,       ,   ,         .         ,      OpenVINO,      ,        .        ‚Äî      .        .  ,   OpenVINO   ,     , :</p><br>
<ul>
<li> ,    ,      ,    ,      .</li>
<li>     ,    ,    ,     .</li>
</ul><br>
<p> :      retail .       .  -         ‚Äî      .<br>
        ,        ,     .    ,       ,    ,  !</p><br>
<p>    :</p><br>
<ul>
<li>   </li>
<li>   </li>
<li> </li>
<li> </li>
</ul><br>
<p>       Raspberry Pi 3 c <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Intel NCS 2</a>. </p><br>
<p>      NCS ‚Äî       CNN ,          ,   Ã∂Ã∂Ã∂Ã∂Ã∂Ã∂Ã∂ Ã∂Ã∂ Ã∂Ã∂Ã∂Ã∂Ã∂Ã∂Ã∂  . </p><br>
<p>  :   .    USB-,         RPI.      ‚Äú  ‚Äù.       Voice Bonnet   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google AIY Voice Kit</a>,      . </p><br>
<p> Raspbian  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> AIY projects</a>    , ,        (     5     ):</p><br>
<pre><code class="bash hljs">arecord -d 5 -r 16000 test.wav</code></pre><br>
<p> ,        .   ,   alsamixer,  Capture devices       50-60%.</p><br>
<p><img src="https://habrastorage.org/webt/le/_o/4j/le_o4jzwn9ai2n0-sqyhjk9eq8w.jpeg"><br>
<em>     ,    </em></p><br>
<h3 id="dobavlyaem-knopku-indikator"> -</h3><br>
<p>   AIY Voice Kit   ,    RGB-,     .  ‚ÄúGoogle AIY Led‚Äù   : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://aiyprojects.readthedocs.io/en/latest/aiy.leds.html</a><br>
         ,    7 ,    8 ,   !</p><br>
<p>   GPIO  Voice Bonnet,    (      AIY projects)</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> aiy.leds <span class="hljs-keyword">import</span> Leds, Color
<span class="hljs-keyword">from</span> aiy.leds <span class="hljs-keyword">import</span> RgbLeds</code></pre><br>
<p>C dict,          RGB Tuple    aiy.leds.Leds,     :</p><br>
<pre><code class="python hljs">led_dict = {<span class="hljs-string">'neutral'</span>: (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>), <span class="hljs-string">'happy'</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>), <span class="hljs-string">'sad'</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>), <span class="hljs-string">'angry'</span>: (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-string">'fearful'</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-string">'disgusted'</span>:  (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>), <span class="hljs-string">'surprised'</span>:  (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">0</span>)} <font></font>
leds = Leds()<font></font>
</code></pre><br>
<p>, ,              ( ).</p><br>
<pre><code class="python hljs">leds.update(Leds.rgb_on(led_dict.get(classes[prediction])))</code></pre><br>
<p><img src="https://habrastorage.org/webt/kq/t7/74/kqt77404yyxluyd5uwdiodu-uf4.jpeg"><br>
<em>, !</em></p><br>
<h3 id="rabotaem-s-golosom">  </h3><br>
<p>  pyaudio       webrtcvad      .  ,  ,          .</p><br>
<p>   webrtcvad       ‚Äî     10/20/30,       (   )    48,     48000√ó20/1000√ó1()=960 . Webrtcvad   True/False     ,        .</p><br>
<p>  : </p><br>
<ul>
<li>   list  ,   ,   ,     .</li>
<li>    &gt;=30 (600 ),       ,   &gt;250,    ,   , ,    ,        .</li>
<li>       &lt; 30,       300,         . (     )</li>
</ul><br>
<pre><code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">to_queue</span>(<span class="hljs-params">frames</span>):</span>
    d = np.frombuffer(<span class="hljs-string">b''</span>.join(frames), dtype=np.int16)
    <span class="hljs-keyword">return</span> d<font></font>
<font></font>
framesQueue = queue.Queue()<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">framesThreadBody</span>():</span>
    CHUNK = <span class="hljs-number">960</span><font></font>
    FORMAT = pyaudio.paInt16<font></font>
    CHANNELS = <span class="hljs-number">1</span>
    RATE = <span class="hljs-number">48000</span><font></font>
<font></font>
    p = pyaudio.PyAudio()<font></font>
    vad = webrtcvad.Vad()<font></font>
    vad.set_mode(<span class="hljs-number">2</span>)<font></font>
    stream = p.open(format=FORMAT,<font></font>
                channels=CHANNELS,<font></font>
                rate=RATE,<font></font>
                input=<span class="hljs-literal">True</span>,<font></font>
                frames_per_buffer=CHUNK)<font></font>
    false_counter = <span class="hljs-number">0</span><font></font>
    audio_frame = []<font></font>
    <span class="hljs-keyword">while</span> process:<font></font>
        data = stream.read(CHUNK)<font></font>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> vad.is_speech(data, RATE):<font></font>
            false_counter += <span class="hljs-number">1</span>
            <span class="hljs-keyword">if</span> false_counter &gt;= <span class="hljs-number">30</span>:
                <span class="hljs-keyword">if</span> len(audio_frame) &gt; <span class="hljs-number">250</span>:              <font></font>
                    framesQueue.put(to_queue(audio_frame,timestamp_start))<font></font>
                    audio_frame = []<font></font>
                    false_counter = <span class="hljs-number">0</span><font></font>
<font></font>
        <span class="hljs-keyword">if</span> vad.is_speech(data, RATE):<font></font>
            false_counter = <span class="hljs-number">0</span><font></font>
            audio_frame.append(data)<font></font>
            <span class="hljs-keyword">if</span> len(audio_frame) &gt; <span class="hljs-number">300</span>:                <font></font>
                    framesQueue.put(to_queue(audio_frame,timestamp_start))<font></font>
                    audio_frame = []</code></pre><br>
<p>       ,   github, ,  ,        .    ,         ,   ,     OpenVINO ‚Äî IR (Intermediate Representation).    5-7    github,        ,          ‚Äî     .</p><br>
<p>  :</p><br>
<ul>
<li>   ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/alexmuhr/Voice_Emotion</a><br>
    :      ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MFCC</a>        CNN</li>
<li>   ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/linhdvu14/vggvox-speaker-identification</a><br>
  MFCC   ,  FFT    CNN,       .</li>
</ul><br>
<p>     ,   . OpenVINO     :</p><br>
<ul>
<li>Open Model Zoo,           </li>
<li>Model Optimzer,          (Tensorflow, ONNX e.t.c)   Intermediate Representation,       </li>
<li>Inference Engine     IR    Intel,  Myriad   Neural Compute Stick</li>
<li>   OpenCV (  Inference Engine)<br>
    IR   : .xml  .bin.<br>
    IR  Model Optimizer  :<br>
<pre><code class="bash hljs">python /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --input_model speaker.hdf5.pb --data_type=FP16 --input_shape [1,512,1000,1]</code></pre><br>
<p><code>--data_type</code>    ,     .  FP32, FP16, INT8.          .<br>
<code>--input_shape</code>     .         C++ API,               .<br>
       IR   DNN   OpenCV   forward  . <br>
</p><pre><code class="python hljs"><span class="hljs-keyword">import</span> cv2 <span class="hljs-keyword">as</span> cv<font></font>
emotionsNet = cv.dnn.readNet(<span class="hljs-string">'emotions_model.bin'</span>,
                          <span class="hljs-string">'emotions_model.xml'</span>)<font></font>
emotionsNet.setPreferableTarget(cv.dnn.DNN_TARGET_MYRIAD)</code></pre><br>
<p>         Neural Compute Stick,     ,     Raspberry Pi   ,  .</p><br>
<br>
<p>  :        (   0.4),       MFCC,     :</p><br>
<pre><code class="python hljs">emotionsNet.setInput(MFCC_from_window)<font></font>
result = emotionsNet.forward()</code></pre><br>
<p>        .  ,        -  ,    .     ,    ‚Äî     .    ,        .     ,     .</p><br>
<p> ,       (   ,   ,           ).</p><br>
<p>.: </p><br>
<pre><code class="plaintext hljs">python3 voice_db/record_voice.py test.wav</code></pre><br>
<p>    (     )<br>
      fast fourier transform,       numpy array (.npy):</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> glob.glob(<span class="hljs-string">"voice_db/*.wav"</span>):<font></font>
        spec = get_fft_spectrum(file)<font></font>
        np.save(file[:<span class="hljs-number">-4</span>] + <span class="hljs-string">'.npy'</span>, spec)</code></pre><br>
<p>   <code>create_base.py</code><br>
              :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> glob.glob(<span class="hljs-string">"voice_db/*.npy"</span>):<font></font>
    spec = np.load(file)<font></font>
    spec = spec.astype(<span class="hljs-string">'float32'</span>)<font></font>
    spec_reshaped = spec.reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, spec.shape[<span class="hljs-number">0</span>], spec.shape[<span class="hljs-number">1</span>])<font></font>
    srNet.setInput(spec_reshaped)<font></font>
    pred = srNet.forward()<font></font>
    emb = np.squeeze(pred)</code></pre><br>
<p>       ,   ,  cosine distance        ( ,  ) ‚Äî      0.3):</p><br>
<pre><code class="python hljs">        dist_list = cdist(emb, enroll_embs, metric=<span class="hljs-string">"cosine"</span>)<font></font>
        distances = pd.DataFrame(dist_list, columns = df.speaker)</code></pre><br>
<p>   ,          1-2  (   7     2.5).             -.</p><br>
<h3 id="veb-prilozhenie">-</h3><br>
<p> :          ,       .</p><br>
<p>          Raspberry Pi,    websocket (http over tcp protocol).</p><br>
<p>       ,     json ,         ,           .      ,         .       golang,     ,       ,     .<br>
         ,     .  ,      hub,       (  ),      (  ),    ,     hub.</p><br>
<p><img src="https://habrastorage.org/webt/n4/4s/su/n44ssutnvuywhhuad4joml7gcw4.jpeg"><br>
<em>   </em></p><br>
<p>Front-end   web-,   JavaScript    React      .      ,    ,   back-end    Raspberry Pi.      ,    react-router,      ,              WebSocket. Raspberry Pi  ,            probability .     ,   ,       ,   ,     .</p><br>
<p><img src="https://habrastorage.org/webt/qj/hp/mh/qjhpmh2y60yn0mhplrc_qfaghq4.jpeg"><br>
<em>    </em></p><br>
<h3 id="zaklyuchenie"></h3><br>
<p>     ,   ,      ,  ,   .     ,   ,   ,    .     ‚Äî            ,     .    ,     ,    ,    ,   . </p><br>
<p>,       150$:</p><br>
<ul>
<li>Raspberry Pi 3 ~ 35$</li>
<li>Google AIY Voice Bonnet (   respeaker) ~ 15$</li>
<li>Intel NCS 2 ~ 100$</li>
</ul><br>
<p> :</p><br>
<ul>
<li>    ‚Äî   ,   </li>
<li>   :       </li>
<li>    ()</li>
</ul><br>
<p>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/vladimirwest/OpenEMO</a></p><br>
<p><img src="https://habrastorage.org/webt/ls/1a/3e/ls1a3ellukefpgk4mky9flhdj88.jpeg"><br>
<em>,   </em></p><br>
<p>       .             .            . ,         ,      AI .</p></li>
</ul></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de486672/">https://habr.com/ru/post/de486672/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de486660/index.html">Ideen vom Tisch: Metro Raumanzug</a></li>
<li><a href="../de486664/index.html">Hack The Box. Passage RE. Metasploit, Laden in Office-Dokument, Zip-Slip-Angriff, ein bisschen √ºber PowerSploit und Token</a></li>
<li><a href="../de486666/index.html">Schneemobile, Bier und Wetterderivate</a></li>
<li><a href="../de486668/index.html">Embedded World 2020. Russen kommen</a></li>
<li><a href="../de486670/index.html">–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –ø–∞—Å–ø–æ—Ä—Ç –†–§, 2020-–∞—è —á–∞—Å—Ç—å –º–∞—Ä–ª–µ–∑–æ–Ω—Å–∫–æ–≥–æ –±–∞–ª–µ—Ç–∞</a></li>
<li><a href="../de486674/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 400 (27. Januar - 2. Februar 2020)</a></li>
<li><a href="../de486676/index.html">Unvermeidlichkeit der FPGA-Penetration in Rechenzentren</a></li>
<li><a href="../de486678/index.html">Quarz in ASP.NET Core</a></li>
<li><a href="../de486680/index.html">ML, VR & Robots (und ein bisschen Cloud)</a></li>
<li><a href="../de486682/index.html">Docker Compose: Mit Makefile vereinfachen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
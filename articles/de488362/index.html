<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöî üë®üèª‚Äçüè´ üë∑üèº Klassifizierung mit mehreren Tags üå°Ô∏è üî™ üë®üèΩ‚Äç‚öïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo habrozhiteli! Wir haben beschlossen, einen Auszug aus dem Buch von Andrei Burkov , Maschinelles Lernen ohne zus√§tzliche W√∂rter , zu zitieren , d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Klassifizierung mit mehreren Tags</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/488362/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/hm/vf/c_/hmvfc_yyxepplv1mj0crw1vu7pw.jpeg" align="left" alt="Bild"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo habrozhiteli! </font><font style="vertical-align: inherit;">Wir haben beschlossen, einen Auszug aus dem Buch von Andrei Burkov </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, Maschinelles Lernen ohne zus√§tzliche W√∂rter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">zu zitieren </font><font style="vertical-align: inherit;">, das der Klassifizierung gewidmet ist.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zur Beschreibung des Bildes in der Abbildung k√∂nnen mehrere Bezeichnungen gleichzeitig verwendet werden: ‚ÄûNadelwald‚Äú, ‚ÄûBerge‚Äú, ‚ÄûStra√üe‚Äú. Wenn die Anzahl der m√∂glichen Werte f√ºr Beschriftungen gro√ü ist, sie jedoch alle dieselbe Natur wie Tags haben, kann jedes markierte Beispiel in mehrere markierte Daten konvertiert werden, eines f√ºr jedes Tag. Alle diese neuen Daten haben dieselben Merkmalsvektoren und nur eine Bezeichnung. Infolgedessen wird die Aufgabe zu einem Klassifizierungsproblem f√ºr mehrere Klassen. Es kann mit der Strategie ‚ÄûEins gegen alle‚Äú gel√∂st werden. Der einzige Unterschied zum √ºblichen Problem der Klassifizierung mehrerer Klassen besteht im Auftreten eines neuen Hyperparameters: der Schwelle. Wenn die √Ñhnlichkeitsbewertung f√ºr ein Etikett √ºber einem Schwellenwert liegt, wird dieses Etikett dem Eingabe-Feature-Vektor zugewiesen. In diesem Szenario k√∂nnen einem charakteristischen Vektor mehrere Beschriftungen zugewiesen werden.Der Schwellenwert wird mit dem Regelsatz ausgew√§hlt.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um das Klassifizierungsproblem mit vielen Bezeichnungen zu l√∂sen, kann man auf √§hnliche Weise Algorithmen anwenden, die nat√ºrlich in mehrere Klassen konvertiert werden (Entscheidungsb√§ume, logistische Regression, neuronale Netze usw.). Sie geben eine Sch√§tzung f√ºr jede Klasse zur√ºck, sodass wir einen Schwellenwert definieren und dann einem Merkmalsvektor mehrere Bezeichnungen zuweisen k√∂nnen, f√ºr die der Proximity-Score diesen Schwellenwert √ºberschreitet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Neuronale Netze k√∂nnen nat√ºrlich in Multi-Label-Klassifikationen unter Verwendung der bin√§ren Kreuzentropie als Kostenfunktion trainiert werden. Die Ausgabeschicht des neuronalen Netzwerks hat in diesem Fall einen Knoten pro Etikett. Jeder Knoten in der Ausgabeschicht verf√ºgt √ºber eine Sigmoid-Aktivierungsfunktion. Dementsprechend ist jedes Etikett l bin√§r</font></font><img src="https://habrastorage.org/webt/2n/_n/mg/2n_nmgvuciuadryomnq3urrg1xw.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wobei l = 1, ..., L und i = 1, ..., N. Die bin√§re Kreuzentropie der Wahrscheinlichkeit, </font></font><img src="https://habrastorage.org/webt/lb/le/cf/lblecfgyuy23k8zvlasuajncsds.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dass die Probe xi mit l bezeichnet wird, definiert als das </font></font><img src="https://habrastorage.org/webt/qd/1e/fx/qd1efxpmi6mmuhv_fhmsqpjgpi4.jpeg" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kriterium der Minimierung - der einfache Durchschnitt aller Mitglieder der bin√§ren Kreuzentropie in allen Trainingsproben und alle ihre Tags. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In F√§llen, in denen die Anzahl der m√∂glichen Etikettenwerte gering ist, k√∂nnen Sie versuchen, das Klassifizierungsproblem mit vielen Etiketten in ein Klassifizierungsproblem f√ºr mehrere Klassen umzuwandeln. </font><font style="vertical-align: inherit;">Stellen Sie sich das folgende Problem vor. </font><font style="vertical-align: inherit;">Sie m√ºssen Bildern zwei Arten von Beschriftungen zuweisen. </font><font style="vertical-align: inherit;">Etiketten des ersten Typs k√∂nnen zwei m√∂gliche Bedeutungen haben: { </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Foto, Malerei</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> }; </font><font style="vertical-align: inherit;">Markierungen des zweiten Typs k√∂nnen drei m√∂gliche Bedeutungen haben: { </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portr√§t, Landschaft, andere</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">}. </font><font style="vertical-align: inherit;">F√ºr jede Kombination von zwei Quellklassen k√∂nnen Sie eine neue Dummy-Klasse erstellen, zum Beispiel:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/mz/px/zn/mzpxzn0rlrumwoql7gkk3no7ihk.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt haben wir die gleichen markierten Daten, aber wir haben den Satz der echten Beschriftungen durch eine Dummy-Beschriftung mit Werten von 1 bis 6 ersetzt. In der Praxis liefert dieser Ansatz gute Ergebnisse, wenn nicht zu viele m√∂gliche Kombinationen von Klassen vorhanden sind. Andernfalls m√ºssen viel mehr Trainingsdaten verwendet werden, um die Zunahme der Klassen zu kompensieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Hauptvorteil dieses letzteren Ansatzes besteht darin, dass die Markierungen im Gegensatz zu den oben beschriebenen Methoden, die jede Markierung unabh√§ngig voneinander vorhersagen, korreliert bleiben. Bei vielen Aufgaben kann die Korrelation zwischen Etiketten ein wesentlicher Faktor sein. Stellen Sie sich beispielsweise vor, Sie m√∂chten E-Mails als </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spam</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font><i><font style="vertical-align: inherit;">Nicht- </font></i><i><font style="vertical-align: inherit;">Spam</font></i><font style="vertical-align: inherit;"> klassifizieren</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und gleichzeitig wie gew√∂hnlich und wichtig. </font><font style="vertical-align: inherit;">Sie m√∂chten wahrscheinlich Prognosen wie [ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spam, wichtig</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ] ausschlie√üen.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5. </font><font style="vertical-align: inherit;">Ensemble-Training</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die grundlegenden Algorithmen, die wir in Kapitel 3 behandelt haben, haben ihre Grenzen. Aufgrund seiner Einfachheit k√∂nnen sie manchmal kein Modell erstellen, das f√ºr Ihre Aufgabe effektiv genug ist. In solchen F√§llen k√∂nnen Sie versuchen, tiefe neuronale Netze zu verwenden. In der Praxis erfordern tiefe neuronale Netze jedoch eine erhebliche Menge an beschrifteten Daten, √ºber die Sie m√∂glicherweise nicht verf√ºgen. Eine andere M√∂glichkeit, die Effektivit√§t einfacher Lernalgorithmen zu erh√∂hen, ist das </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ensemble-Training</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensemble-Training ist ein Trainingsparadigma, das darauf basiert, nicht nur ein superkorrektes Modell, sondern eine gro√üe Anzahl von Modellen mit geringer Genauigkeit zu trainieren und die Prognosen dieser </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">schwachen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelle zu kombinieren, um ein korrekteres </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Metamodell zu erhalten</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modelle mit geringer Genauigkeit werden normalerweise durch </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">schwache Lernalgorithmen</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> trainiert </font><font style="vertical-align: inherit;">, die keine komplexen Modelle trainieren k√∂nnen und daher in der Trainings- und Prognosephase eine hohe Geschwindigkeit aufweisen. Am h√§ufigsten wird der Entscheidungsbaum-Lernalgorithmus als schwacher Algorithmus verwendet, der normalerweise nach mehreren Iterationen aufh√∂rt, den Trainingssatz zu unterbrechen. Das Ergebnis sind kleine und nicht sehr regelm√§√üige B√§ume, aber wie die Idee, das Ensemble zu lernen, besagt, k√∂nnen wir durch die Kombination einer gro√üen Anzahl solcher B√§ume eine hohe Genauigkeit erzielen, wenn die B√§ume nicht identisch sind und jeder Baum zumindest geringf√ºgig besser als zuf√§llige Vermutungen ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die endg√ºltige Prognose f√ºr Eintrag </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x zu erhalten</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prognosen aller schwachen Modelle werden mit einer gewichteten Abstimmungsmethode kombiniert. </font><font style="vertical-align: inherit;">Die spezifische Form der Gewichtung der Stimmen h√§ngt vom Algorithmus ab, aber das Wesentliche h√§ngt nicht davon ab: Wenn insgesamt schwache Modelle vorhersagen, dass es sich bei der E-Mail um Spam handelt, weisen wir Probe </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> das </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spam-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Label </font><font style="vertical-align: inherit;">zu </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die beiden Hauptmethoden f√ºr das Training von Ensembles sind </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Boosten</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Absacken</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Aggregation). </font><font style="vertical-align: inherit;">√úbersetzungen der Begriffe Boosten und Absacken sind ungenau und nicht gewohnt.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.1. </font><font style="vertical-align: inherit;">Boosten und Absacken</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Boosting-Methode besteht darin, die anf√§nglichen Trainingsdaten zu verwenden und iterativ mehrere Modelle unter Verwendung eines schwachen Algorithmus zu erstellen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jedes neue Modell unterscheidet sich von den vorherigen darin, dass ein schwacher Algorithmus bei seiner Konstruktion versucht, die von fr√ºheren Modellen gemachten Fehler zu ‚Äûbeheben‚Äú. </font><font style="vertical-align: inherit;">Das endg√ºltige Ensemblemodell ist eine Kombination dieser vielen schwachen iterativ konstruierten Modelle. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Wesentliche beim Absacken besteht darin, viele ‚ÄûKopien‚Äú von Trainingsdaten zu erstellen (jede Kopie unterscheidet sich geringf√ºgig von den anderen) und dann auf jede Kopie einen schwachen Algorithmus anzuwenden, um mehrere schwache Modelle zu erhalten, und diese dann zu kombinieren. </font><font style="vertical-align: inherit;">Ein weit verbreiteter und effizienter Algorithmus f√ºr maschinelles Lernen, der auf der Idee des Absackens basiert, ist eine </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zuf√§llige Gesamtstruktur</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.2. </font><font style="vertical-align: inherit;">Zuf√§lliger Wald</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der "klassische" Absackalgorithmus funktioniert wie folgt. </font><font style="vertical-align: inherit;">B Stichproben aus dem bestehenden Trainingssatz erzeugt </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(f√ºr jeden b = 1, ..., B) und ein </font><font style="vertical-align: inherit;">Entscheidungsbaum - </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modell ist aufgebaut </font><font style="vertical-align: inherit;">auf der Basis von jeder Probe </font></font><img src="https://habrastorage.org/webt/nd/ew/4z/ndew4zvx7r0jpeilfknakojmrbs.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Um eine Probe </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f√ºr einige b zu erhalten, wird eine </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Probe mit Ersatz erstellt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Das hei√üt, zuerst wird eine leere Stichprobe erstellt, und dann wird eine zuf√§llige Stichprobe aus dem Trainingssatz ausgew√§hlt und ihre genaue Kopie wird abgelegt </font></font><img src="https://habrastorage.org/webt/-d/6r/gn/-d6rgnsn5wk-yzl3dbk0i7x2ole.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, w√§hrend die Stichprobe selbst im urspr√ºnglichen Trainingssatz verbleibt. </font><font style="vertical-align: inherit;">Die Auswahl der Daten wird fortgesetzt, bis die Bedingung erf√ºllt ist. </font></font><img src="https://habrastorage.org/webt/se/au/-5/seau-5gwous1c1cshmrx8rwubig.jpeg" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als Ergebnis des Trainings werden </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Entscheidungsb√§ume </font><font style="vertical-align: inherit;">erhalten </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Die Prognose f√ºr die neue Stichprobe </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> im Falle einer Regression wird als Durchschnitt von </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B bestimmt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Prognosen</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/re/zp/mj/rezpmjqa9lo7w4dxvqd6njwwqcm.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
oder mit Stimmenmehrheit bei Einstufung.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zuf√§lliger Wald hat nur einen Unterschied zum klassischen Absacken. Es wird ein modifizierter Baumlernalgorithmus verwendet, der bei jeder Aufteilung im Lernprozess eine zuf√§llige Teilmenge von Merkmalen √ºberpr√ºft. Dies geschieht, um die Korrelation zwischen B√§umen zu beseitigen: Wenn ein oder mehrere Features eine gro√üe Vorhersagef√§higkeit aufweisen, werden sie von vielen B√§umen zum Aufteilen von Daten ausgew√§hlt. Dies wird dazu f√ºhren, dass im "Wald" eine gro√üe Anzahl korrelierter B√§ume erscheint. Die Vorzeichenkorrelation mit hoher Vorhersagef√§higkeit verhindert, dass die Vorhersagegenauigkeit zunimmt. Die hohe Effizienz des Modellensembles erkl√§rt sich aus der Tatsache, dass gute Modelle h√∂chstwahrscheinlich mit derselben Prognose √ºbereinstimmen und schlechte Modelle wahrscheinlich nicht √ºbereinstimmen und unterschiedliche Prognosen liefern. Durch die Korrelation werden schlechte Modelle eher zustimmen.Dies verzerrt das Abstimmungsmuster oder beeinflusst den Durchschnitt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die wichtigsten Hyperparameter f√ºr die Optimierung sind die Anzahl der B√§ume B und die Gr√∂√üe einer zuf√§lligen Teilmenge von Merkmalen, die bei jeder Aufteilung ber√ºcksichtigt werden m√ºssen. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Random Forest ist einer der am h√§ufigsten verwendeten Ensemble-Lernalgorithmen. Was bestimmt seine Wirksamkeit? Der Grund daf√ºr ist, dass wir durch die Verwendung mehrerer Stichproben aus dem Originaldatensatz die </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Varianz des</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> endg√ºltigen Modells </font><font style="vertical-align: inherit;">reduzieren </font><font style="vertical-align: inherit;">. Denken Sie daran, dass eine geringe Varianz eine schwache Veranlagung zur </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Umschulung bedeutet</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Eine Umschulung erfolgt, wenn das Modell versucht, kleine Abweichungen im Datensatz zu erkl√§ren, da der Datensatz nur eine kleine Auswahl aller m√∂glichen Beispiele f√ºr das Ph√§nomen ist, das wir simulieren m√∂chten. </font><font style="vertical-align: inherit;">Im Falle eines erfolglosen Ansatzes zur Bildung des Trainingssatzes k√∂nnen einige unerw√ºnschte (aber unvermeidliche) Artefakte in den Satz fallen: Rauschen, abnormale und √ºberm√§√üig oder unzureichend repr√§sentative Daten. </font><font style="vertical-align: inherit;">Indem wir mit dem Ersetzen des Trainingssatzes mehrere Zufallsstichproben erstellen, reduzieren wir den Einfluss dieser Artefakte.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.5.3. </font><font style="vertical-align: inherit;">Gradientenverst√§rkung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein weiterer effektiver Ensemble-Trainingsalgorithmus, der auf der Idee des Boostings basiert, ist das Gradienten-Boosting. </font><font style="vertical-align: inherit;">Betrachten Sie zun√§chst die Verwendung der Gradientenverst√§rkung bei der Regression. </font><font style="vertical-align: inherit;">Wir werden mit dem Aufbau eines effektiven Regressionsmodells mit einem konstanten Modell beginnen </font></font><img src="https://habrastorage.org/webt/7u/7x/jd/7u7xjdufljpsjwwu45j9_gkc3r0.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(wie wir es in ID3 getan haben):</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/em/vj/bv/emvjbvtmptxl_d3bihzev4wbh7o.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√Ñndern Sie dann die Beschriftungen in allen Proben i = 1, ..., N im Trainingssatz:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/va/wc/ah/vawcahk0zsdpgnumh_bfjuozw_e.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
wo </font></font><img src="https://habrastorage.org/webt/rf/1x/pk/rf1xpkgfxmcivy-1tqpwv2vgroi.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die aufgerufen wird , </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rest</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und ist das neue Label der Probe </font></font><img src="https://habrastorage.org/webt/dk/ey/2r/dkey2rj3yf-zkei2029wfa2ujso.jpeg" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
verwenden wir nun das modifizierte Trainingssatz mit den anstelle der Originaletiketten bleibt ein neues Modell des Entscheidungsbaums zu bauen. </font></font><img src="https://habrastorage.org/webt/mx/fw/um/mxfwumzpc5tq1wjpdate2rxra48.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Verst√§rkungs Modell jetzt ist definiert als </font></font><img src="https://habrastorage.org/webt/cy/c2/vz/cyc2vz0tmrrihcm6kta_7rnwmui.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wobei Œ± die Lerngeschwindigkeit (Hyper). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann berechnen wir die Residuen unter Verwendung von Gleichung 7.2 neu, ersetzen die Beschriftungen in den Trainingsdaten erneut, lehren ein neues Modell des Entscheidungsbaums, </font></font><img src="https://habrastorage.org/webt/p4/wk/nl/p4wknlhlvwiqtr7zz7lx_y5oq3s.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">definieren das Boost-Modell neu, w√§hrend </font></font><img src="https://habrastorage.org/webt/n-/mn/ht/n-mnhtck0rar7pz4anzlbdc-bmo.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wir den Prozess wiederholen, bis wir die vorbestimmte maximale Anzahl </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M von</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> B√§umen </font><font style="vertical-align: inherit;">kombinieren </font><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns intuitiv verstehen, was hier passiert. Durch Berechnung der Residuen bestimmen wir, wie gut (oder schlecht) das Ziel jeder Trainingsstichprobe vom aktuellen Modell f vorhergesagt wird. Dann trainieren wir einen anderen Baum, um die Fehler des aktuellen Modells zu korrigieren (weshalb wir Reste anstelle der tats√§chlichen Beschriftungen verwenden) und f√ºgen dem vorhandenen Modell einen neuen Baum mit einem gewissen Gewicht Œ± hinzu. Infolgedessen korrigiert jeder neue Baum, der dem Modell hinzugef√ºgt wird, teilweise die Fehler, die von vorherigen B√§umen gemacht wurden. Der Prozess wird fortgesetzt, bis die maximale Anzahl M (ein weiterer Hyperparameter) der B√§ume kombiniert ist.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Versuchen wir nun, die Frage zu beantworten, warum dieser Algorithmus als Gradientenverst√§rkung bezeichnet wird. Bei der Gradientenverst√§rkung berechnen wir den Gradienten nicht, anders als in Kapitel 4, um das Problem der linearen Regression zu l√∂sen. Um die √Ñhnlichkeiten zwischen Gradientenverst√§rkung und Gradientenabstieg zu erkennen, denken Sie daran, warum wir den Gradienten in linearer Regression berechnet haben: Um die Richtung der Parameterwerte herauszufinden, um die MSE-Kostenfunktion zu minimieren. Der Gradient zeigt die Richtung an, zeigt jedoch nicht, wie weit in diese Richtung zu gehen ist. Daher haben wir in jeder Iteration einen kleinen Schritt gemacht und dann erneut die Richtung bestimmt. Dasselbe passiert bei der Gradientenverst√§rkung, aber anstatt den Gradienten direkt zu berechnen, verwenden wir seine Sch√§tzung in Form von Residuen: Sie zeigen, wie das Modell angepasst werden sollte, um den Fehler (Residuum) zu reduzieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei der Gradientenverst√§rkung stehen drei Haupthyperparameter zur Abstimmung zur Verf√ºgung: die Anzahl der B√§ume, die Lerngeschwindigkeit und die Tiefe der B√§ume. Alle drei beeinflussen die Genauigkeit des Modells. Die Tiefe der B√§ume beeinflusst auch die Lern- und Prognosegeschwindigkeit: Je kleiner die Tiefe, desto schneller. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es kann gezeigt werden, dass das Lernen durch Residuen das Gesamtmodell f f√ºr den Standardfehlerstandard optimiert. Hier sehen Sie den Unterschied zum Absacken: Durch das Boosten werden Verzerrungen (oder mangelnde Bildung) anstelle von Varianz verringert. Infolgedessen muss das Boosten umgeschult werden. Durch Anpassen der Tiefe und Anzahl der B√§ume kann jedoch eine Umschulung weitgehend vermieden werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Gradientenverst√§rkung ist f√ºr Bewertungsaufgaben √§hnlich, die Schritte unterscheiden sich jedoch geringf√ºgig. Betrachten Sie den Fall der bin√§ren Klassifizierung. Angenommen, es gibt M Regressionsentscheidungsb√§ume. In Analogie zur logistischen Regression wird die Vorhersage des Ensembles von Entscheidungsb√§umen mithilfe der Sigmoid-Funktion modelliert:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wy/pd/gw/wypdgwjjgpzuojrelehnadtdggc.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wo </font></font><img src="https://habrastorage.org/webt/w6/3d/kb/w63dkbj3f9j-ik9hrhqbexyxtem.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ist der Regressionsbaum? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und wieder wird, wie bei der logistischen Regression, beim Versuch, ein Modell f√ºr die Maximierung zu finden </font></font><img src="https://habrastorage.org/webt/c4/lv/tt/c4lvttexfzr8disbsv1ph_drzka.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, das Prinzip der maximalen Wahrscheinlichkeit angewendet. Um einen numerischen √úberlauf zu vermeiden, maximieren wir in √§hnlicher Weise die Summe der Wahrscheinlichkeitslogarithmen und nicht das Produkt der Wahrscheinlichkeit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Algorithmus beginnt mit dem anf√§nglichen konstanten Modell, </font></font><img src="https://habrastorage.org/webt/hn/7j/ep/hn7jepdxhudnxvjjgbulvfwtpyw.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wobei </font></font><img src="https://habrastorage.org/webt/gj/6s/f6/gj6sf6i874m3gq3_fbbxbkrudae.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Es kann gezeigt werden, dass eine solche Initialisierung f√ºr die Sigmoidfunktion optimal ist.) Dann wird bei jeder Iteration m ein neuer Baum fm zum Modell hinzugef√ºgt. Um den besten Baum </font></font><img src="https://habrastorage.org/webt/b0/5w/rv/b05wrvcuk5hzvnrmkpebdnk_kxu.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zu finden </font><font style="vertical-align: inherit;">Um den besten Baum </font><font style="vertical-align: inherit;">zu finden </font></font><img src="https://habrastorage.org/webt/xm/u4/dp/xmu4dpm1hi3-podtuiayxggydti.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, wird zuerst die partielle Ableitung des </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aktuellen Modells f√ºr jedes i = 1, ..., N </font><font style="vertical-align: inherit;">berechnet </font><font style="vertical-align: inherit;">:</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/wg/v_/oo/wgv_oogvmupu4q5j6g3rq7dphvk.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dabei ist f das Modell des Ensemble-Klassifikators, der auf der vorherigen Iteration m - 1 basiert. Um zu berechnen </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, m√ºssen wir die Ableitungen von in </font></font><img src="https://habrastorage.org/webt/pv/pe/lb/pvpelb2jplsmq_jmkbdfyl-pzom.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bezug auf f f√ºr alle i finden. </font><font style="vertical-align: inherit;">Es ist zu beachten, dass die </font></font><img src="https://habrastorage.org/webt/nk/zn/0l/nkzn0lh0l0brnzl_vh0xxlmttrq.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ableitung in Bezug auf f des richtigen Terms in der vorherigen Gleichung ist</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/xx/en/iu/xxeniu2qr35ln17asbfk2fqb3sc.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dann wird der Trainingssatz transformiert, indem das urspr√ºngliche Etikett der </font></font><img src="https://habrastorage.org/webt/a1/fv/cu/a1fvcukqqvsu5wpv3x8i1zj5smc.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entsprechenden partiellen Ableitung ersetzt wird </font></font><img src="https://habrastorage.org/webt/ep/hx/gu/ephxgusen4ou8pc8atm4ksqathq.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, und ein neuer Baum wird auf der Basis des konvertierten Trainingssatzes erstellt. </font></font><img src="https://habrastorage.org/webt/w1/8f/41/w18f41gto37doyvyakgs4np_fyy.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Als n√§chstes wird der optimale Aktualisierungsschritt wie folgt bestimmt </font></font><img src="https://habrastorage.org/webt/1n/cf/sj/1ncfsjxfe-tao3ep_csuw-s-arw.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/co/qc/hw/coqchwpctxgy2ukbdwaybkouxx0.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Am Ende von Iteration m aktualisieren wir das Ensemble-Modell, </font></font><img src="https://habrastorage.org/webt/r7/ox/vy/r7oxvyc5mesbifpwfjtkcrtdr2q.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indem </font><font style="vertical-align: inherit;">wir </font><font style="vertical-align: inherit;">einen neuen Baum hinzuf√ºgen</font></font><img src="https://habrastorage.org/webt/s2/vp/u0/s2vpu0-7pmzuzv0n55f1z1fgktu.jpeg" alt="Bild"><br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/vg/ar/qn/vgarqnddik0vjhxxfsesr1t5qs8.jpeg" alt="Bild"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Iterationen werden fortgesetzt, bis die Bedingung m = M erf√ºllt ist. Danach stoppt das Training und das Ensemblemodell f wird erhalten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gradient Boosting ist einer der leistungsst√§rksten Algorithmen f√ºr maschinelles Lernen. </font><font style="vertical-align: inherit;">Nicht nur, weil es sehr genaue Modelle erstellt, sondern auch, weil es in der Lage ist, gro√üe Datenmengen mit Millionen von Daten und Funktionen zu verarbeiten. </font><font style="vertical-align: inherit;">In der Regel ist es einem zuf√§lligen Wald in seiner Genauigkeit √ºberlegen, aber aufgrund der konsistenten Natur kann es viel langsamer lernen.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de488346/index.html">Installieren von or-tools mit SCIP und GLPK in einer virtuellen Python 3.7-Umgebung unter Linux</a></li>
<li><a href="../de488348/index.html">Webinar ‚ÄûZehn agilste Herausforderungen und M√∂glichkeiten, sie in einer Stunde zu √ºberwinden‚Äú 17. Februar um 20:00 Uhr Moskauer Zeit</a></li>
<li><a href="../de488352/index.html">VDI-Kostenvergleich: On-Premise versus Public Cloud</a></li>
<li><a href="../de488356/index.html">Schulung f√ºr Dassault Syst√®mes-Produkte an der Staatlichen Marine Technischen Universit√§t St. Petersburg</a></li>
<li><a href="../de488360/index.html">Big Data Mythen und digitale Kultur</a></li>
<li><a href="../de488366/index.html">Und noch einmal zu "Falsche Zeitzoneninformationen f√ºr russische Zeitzonen" [.Net-Fehler, ID: 693286]</a></li>
<li><a href="../de488368/index.html">Was ich bei der Arbeit an meinem ersten Gro√üprojekt gelernt habe</a></li>
<li><a href="../de488370/index.html">TDD f√ºr Mikrocontroller. Teil 2: Wie Spione Abh√§ngigkeiten loswerden</a></li>
<li><a href="../de488374/index.html">Telegramm + 1C + Webhooks + Apache + Selbstsigniertes Zertifikat</a></li>
<li><a href="../de488376/index.html">Wenn das Prinzip "zur H√∂lle mit allem, nimm es und mach es!" funktioniert nicht: Zaudernotizen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏇🏿 👨🏾‍🏭 🚌 Méthodes de Monte Carlo pour les chaînes de Markov (MCMC). introduction 👲🏾 🤳🏽 🙇🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! 
 
 Nous vous rappelons que nous avons annoncé plus tôt le livre " Machine Learning Without Extra Words " - et maintenant il est déjà e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Méthodes de Monte Carlo pour les chaînes de Markov (MCMC). introduction</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/491268/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonjour, Habr! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous vous rappelons que nous avons annoncé plus tôt le livre " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Machine Learning Without Extra Words</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " - et maintenant il est déjà </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en vente</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Malgré le fait que pour les débutants en MO, le livre puisse en effet devenir un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ordinateur de bureau</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , certains sujets n'y étaient toujours pas abordés. Par conséquent, nous proposons à toutes les personnes intéressées une traduction d'un article de Simon Kerstens sur l'essence des algorithmes </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MCMC</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> avec la mise en œuvre d'un tel algorithme en Python.</font></font><br>
<a name="habracut"></a> <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les méthodes de Monte Carlo pour les chaînes de Markov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (MCMC) sont une classe puissante de méthodes d'échantillonnage à partir de distributions de probabilités connues uniquement jusqu'à une certaine constante de normalisation (inconnue). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, avant de plonger dans le MCMC, voyons pourquoi vous pourriez même avoir besoin de faire une telle sélection. La réponse est: vous pouvez être intéressé soit par les échantillons eux-mêmes de l'échantillon (par exemple, pour déterminer des paramètres inconnus en utilisant la méthode de dérivation bayésienne), soit pour approximer les valeurs attendues des fonctions par rapport à la distribution de probabilité (par exemple, pour calculer les quantités thermodynamiques à partir de la distribution des états en physique statistique). Parfois, nous ne nous intéressons qu'au mode de distribution des probabilités. Dans ce cas, nous l'obtenons par la méthode d'optimisation numérique, il n'est donc pas nécessaire de faire une sélection complète.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il s'avère que l'échantillonnage de toutes les distributions de probabilités, à l'exception des plus primitives, est une tâche difficile. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La méthode de transformation inverse</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est une technique élémentaire d'échantillonnage à partir de distributions de probabilités, qui nécessite cependant l'utilisation d'une fonction de distribution cumulative, et pour l'utiliser, à son tour, vous devez connaître la constante de normalisation, qui est généralement inconnue. En principe, une constante de normalisation peut être obtenue par intégration numérique, mais cette méthode devient rapidement impraticable avec une augmentation du nombre de dimensions. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Échantillonnage par déviation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il ne nécessite pas une distribution normalisée, mais pour le mettre en œuvre efficacement, il faut beaucoup de choses sur la distribution qui nous intéresse. De plus, cette méthode souffre gravement de la malédiction des dimensions - cela signifie que son efficacité diminue rapidement avec une augmentation du nombre de variables. C'est pourquoi vous devez organiser intelligemment la réception d'échantillons représentatifs de votre distribution - sans avoir besoin de connaître la constante de normalisation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les algorithmes MCMC sont une classe de méthodes conçues spécifiquement pour cela. Ils reviennent à l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">article historique de Metropolis et d'autres</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ; Metropolis a développé le premier algorithme MCMC nommé d' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">après lui</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et conçu pour calculer l'état d'équilibre d'un système bidimensionnel de sphères dures. En fait, les chercheurs recherchaient une méthode universelle qui nous permettrait de calculer les valeurs attendues en physique statistique. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cet article couvrira les bases de l'échantillonnage MCMC. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CHAÎNES DE MARKOV</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant que nous comprenons pourquoi nous devons échantillonner, passons au cœur de MCMC: les chaînes de Markov. Qu'est-ce qu'une chaîne Markov? Sans entrer dans les détails techniques, nous pouvons dire qu'une chaîne de Markov est une séquence aléatoire d'états dans un certain espace d'état, où la probabilité de choisir un certain état dépend uniquement de l'état actuel de la chaîne, mais pas de son histoire passée: cette chaîne est dépourvue de mémoire. Dans certaines conditions, une chaîne de Markov a une distribution stationnaire unique d'états, vers laquelle elle converge, surmontant un certain nombre d'états. Après un tel nombre d'états dans une chaîne de Markov, une distribution invariante est obtenue. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour échantillonner à partir d'une distribution, </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'algorithme MCMC crée et simule une chaîne de Markov dont la distribution stationnaire est</font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">; cela signifie qu'après la période initiale de «graine», les états d'une telle chaîne de Markov sont distribués selon le principe </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Par conséquent, nous n'aurons qu'à enregistrer l'état afin d'en obtenir des échantillons </font></font><img src="https://habrastorage.org/webt/wb/sl/yf/wbslyf0r1hu5bjl1gbu7pyr3u48.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À des fins éducatives, considérons à la fois un espace d'état discret et un «temps» discret. La quantité clé caractérisant une chaîne de Markov est un opérateur de transition </font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indiquant la probabilité d'être dans un état </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">à un moment </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, à condition que la chaîne soit dans un état </font></font><img src="https://habrastorage.org/webt/cj/ut/o7/cjuto7hmum9a2ki6gyy23a86jb0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">au moment </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant juste pour le plaisir (et comme démonstration) tissons rapidement une chaîne Markov avec une distribution stationnaire unique. Commençons par quelques importations et paramètres pour les graphiques:</font></font><br>
<br>
<pre><code class="python hljs">%matplotlib notebook<font></font>
%matplotlib inline<font></font>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
plt.rcParams[<span class="hljs-string">'figure.figsize'</span>] = [<span class="hljs-number">10</span>, <span class="hljs-number">6</span>]<font></font>
np.random.seed(<span class="hljs-number">42</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La chaîne de Markov fera le tour de l'espace d'état discret formé par trois conditions météorologiques: </font></font><br>
<br>
<pre><code class="python hljs">state_space = (<span class="hljs-string">"sunny"</span>, <span class="hljs-string">"cloudy"</span>, <span class="hljs-string">"rainy"</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans un espace d'états discret, l'opérateur de transition n'est qu'une matrice. </font><font style="vertical-align: inherit;">Dans notre cas, les colonnes et les lignes correspondent à un temps ensoleillé, nuageux et pluvieux. </font><font style="vertical-align: inherit;">Choisissons des valeurs relativement raisonnables pour les probabilités de toutes les transitions:</font></font><br>
<br>
<pre><code class="python hljs">transition_matrix = np.array(((<span class="hljs-number">0.6</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.1</span>),<font></font>
                              (<span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>, <span class="hljs-number">0.3</span>),<font></font>
                              (<span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.5</span>)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les lignes indiquent les états dans lesquels le circuit peut actuellement être situé, et les colonnes indiquent les états dans lesquels le circuit peut aller. </font><font style="vertical-align: inherit;">Si nous prenons le pas de «temps» de la chaîne de Markov dans une heure, alors, à condition qu'il soit ensoleillé maintenant, il y a 60% de chances que le temps ensoleillé continue pendant l'heure suivante. </font><font style="vertical-align: inherit;">Il y a également 30% de chances que le temps soit nuageux au cours de la prochaine heure et 10% de chances qu'il pleuve immédiatement après un temps ensoleillé. </font><font style="vertical-align: inherit;">Cela signifie également que les valeurs de chaque ligne totalisent un. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conduisons un peu notre chaîne Markov:</font></font><br>
<br>
<pre><code class="python hljs">n_steps = <span class="hljs-number">20000</span>
states = [<span class="hljs-number">0</span>]
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n_steps):<font></font>
    states.append(np.random.choice((<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), p=transition_matrix[states[<span class="hljs-number">-1</span>]]))<font></font>
states = np.array(states)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous pouvons observer comment la chaîne de Markov converge vers une distribution stationnaire, calculant la probabilité empirique de chacun des états en fonction de la longueur de la chaîne:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">despine</span>(<span class="hljs-params">ax, spines=(<span class="hljs-params"><span class="hljs-string">'top'</span>, <span class="hljs-string">'left'</span>, <span class="hljs-string">'right'</span></span>)</span>):</span>
    <span class="hljs-keyword">for</span> spine <span class="hljs-keyword">in</span> spines:<font></font>
        ax.spines[spine].set_visible(<span class="hljs-literal">False</span>)<font></font>
<font></font>
fig, ax = plt.subplots()<font></font>
width = <span class="hljs-number">1000</span>
offsets = range(<span class="hljs-number">1</span>, n_steps, <span class="hljs-number">5</span>)
<span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> enumerate(state_space):<font></font>
    ax.plot(offsets, [np.sum(states[:offset] == i) / offset <font></font>
            <span class="hljs-keyword">for</span> offset <span class="hljs-keyword">in</span> offsets], label=label)<font></font>
ax.set_xlabel(<span class="hljs-string">"number of steps"</span>)<font></font>
ax.set_ylabel(<span class="hljs-string">"likelihood"</span>)<font></font>
ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
despine(ax, (<span class="hljs-string">'top'</span>, <span class="hljs-string">'right'</span>))<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/vu/tg/xv/vutgxvc3lq1-sang725fmek1ibm.png"><br>
 <br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HONNEUR DE TOUS LES MCMC: ALGORITHME DE MÉTROPOLE-HASTINGS</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Bien sûr, tout cela est très intéressant, mais revenons au processus d'échantillonnage d'une distribution de probabilité arbitraire </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Elle peut être soit discrète, auquel cas nous continuerons à parler de la matrice de transition </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, soit continue, auquel cas ce </font></font><img src="https://habrastorage.org/webt/sz/nh/au/sznhau4xxghwlc7ma-eixqb9jok.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sera un noyau de transition. Nous parlerons ci-après de distributions continues, mais tous les concepts que nous considérons ici sont également applicables à des cas discrets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si nous pouvions concevoir le noyau de transition de manière à ce que l'état suivant soit déjà déduit </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, cela pourrait être limité, car notre chaîne de Markov ... serait directement échantillonnée </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Malheureusement, pour y parvenir, nous devons pouvoir échantillonner</font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ce que nous ne pouvons pas faire - sinon vous ne liriez pas cela, non? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La solution consiste à diviser le noyau de transition </font></font><img src="https://habrastorage.org/webt/7_/os/ja/7_osja2wwom8x6f29sp5ecxnrwc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en deux parties: l'étape de proposition et l'étape d'acceptation / rejet. Une distribution auxiliaire apparaît à l'étape d'échantillonnage</font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">parmi lesquels les prochains états possibles de la chaîne sont sélectionnés. Non seulement nous pouvons faire une sélection à partir de cette distribution, mais nous pouvons choisir arbitrairement la distribution elle-même. Cependant, lors de la conception, il faut s'efforcer de parvenir à une configuration dans laquelle les échantillons prélevés dans cette distribution seraient en corrélation minimale avec l'état actuel et auraient en même temps de bonnes chances de passer par la phase de réception. L'étape de réception / rejet ci-dessus est la deuxième partie du noyau de transition; à ce stade, les erreurs contenues dans les états d'essai sélectionnés sont corrigées </font></font><img src="https://habrastorage.org/webt/dq/wo/ba/dqwoba_pfa-ktifmo9zviggtesm.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ici, la probabilité de réception réussie est calculée </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et un échantillon est prélevé </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">avec une probabilité telle que l'état suivant dans la chaîne. Obtenir le prochain état </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de</font></font><img src="https://habrastorage.org/webt/5q/fu/fx/5qfufxlugigeusphytdet38q580.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">puis effectué comme suit: d'abord, l'état d'essai </font></font><img src="https://habrastorage.org/webt/gs/gz/hz/gsgzhzrwlbmvbexpmq21j8u1dbu.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est tiré de </font></font><img src="https://habrastorage.org/webt/qf/bl/m0/qfblm0cpxxgzun1zq6i9qv_zmfq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ensuite, il est considéré comme le prochain état avec probabilité </font></font><img src="https://habrastorage.org/webt/hz/f4/rv/hzf4rviqapfrbg3mphv1na6kao0.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ou rejeté avec probabilité </font></font><img src="https://habrastorage.org/webt/cr/_w/sd/cr_wsdxfgphyie2qbzl977pvfgq.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, et dans ce dernier cas, l'état actuel est copié et utilisé comme prochain. Par </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
conséquent, nous avons </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ty/vg/w-/tyvgw-g_ij7vgrpzoxtt7t3enmw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
condition suffisante pour la chaîne de </font><font style="vertical-align: inherit;">Markov a </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">une distribution stationnaire est la suivante: Le noyau de </font><font style="vertical-align: inherit;">transition doit présenter un </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">équilibre détaillé</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou écrire dans la littérature physique, la </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réversibilité microscopique</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hf/bg/oy/hfbgoyr944ikp5ce_menl-sg0da.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cela signifie que la probabilité d'être dans un état </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et de passer de là à</font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">doit être égal à la probabilité du processus inverse, c'est-à-dire pouvoir </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et entrer dans un état </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Les noyaux de transition de la plupart des algorithmes MCMC remplissent cette condition. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour que le noyau de transition en deux parties obéisse à l'équilibre détaillé, il est nécessaire de choisir correctement </font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, c'est-à-dire de s'assurer qu'il vous permet de corriger les asymétries dans le flux de probabilité de / vers </font></font><img src="https://habrastorage.org/webt/4t/py/hc/4tpyhcj70euwoys5id2rrqxa_ac.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ou </font></font><img src="https://habrastorage.org/webt/mt/2y/jr/mt2yjrl958wkwmuhsrpm3h-4uko.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Algorithme de </font><font style="vertical-align: inherit;">Metropolis-Hastings utilise critère de recevabilité Metropolis: </font></font><br>
 <br>
<img src="https://habrastorage.org/webt/mh/dm/z2/mhdmz27voos90zkz5_-zexopsdc.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et ici, la magie commence: </font></font><img src="https://habrastorage.org/webt/r2/lm/5b/r2lm5bcuhr-rdtxeg90gjnogcza.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nous ne connaissons qu'une constante, mais cela n'a pas d'importance, car cette constante inconnue annule l'expression de</font></font><img src="https://habrastorage.org/webt/oc/hr/x1/ochrx15_pe9awrsow_fygffjego.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! C'est cette propriété paccpacc qui assure le fonctionnement d'algorithmes basés sur l'algorithme Metropolis-Hastings sur des distributions non normalisées. Des distributions auxiliaires symétriques c sont souvent utilisées </font></font><img src="https://habrastorage.org/webt/b2/ss/pz/b2sspzujgmdn_uwizxwjjokkg5w.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, auquel cas l'algorithme Metropolis-Hastings est réduit à l'algorithme Metropolis original (moins général) développé en 1953. Dans l'algorithme d'origine </font></font><br>
<br>
<img src="https://habrastorage.org/webt/hd/3k/vq/hd3kvqg9l2jqltan97_gfmzutsi.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans ce cas, le noyau de transition complet de Metropolis-Hastings peut s'écrire </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NOUS METTONS EN ŒUVRE L'ALGORITHME METROPOLIS-HASTINGS À PYTHON</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, maintenant que nous avons compris comment fonctionne l'algorithme Metropolis-Hastings, passons à sa mise en œuvre. Premièrement, nous établissons la probabilité logarithmique de la distribution à partir de laquelle nous allons faire une sélection - sans constantes de normalisation; on suppose que nous ne les connaissons pas. Ensuite, nous travaillons avec la distribution normale standard:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">log_prob</span>(<span class="hljs-params">x</span>):</span>
     <span class="hljs-keyword">return</span> <span class="hljs-number">-0.5</span> * np.sum(x ** <span class="hljs-number">2</span>)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, nous choisissons une distribution auxiliaire symétrique. </font><font style="vertical-align: inherit;">En général, les performances de l'algorithme Metropolis-Hastings peuvent être améliorées si vous incluez des informations déjà connues de la distribution à partir de laquelle vous souhaitez effectuer une sélection dans la distribution auxiliaire. </font><font style="vertical-align: inherit;">Une approche simplifiée ressemble à ceci: nous prenons l'état actuel </font></font><code>x</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et sélectionnons un échantillon à partir de </font></font><img src="https://habrastorage.org/webt/tl/ic/rd/tlicrdfto9zvzlooid7cdt4ii-m.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, c'est-à-dire, définissons une certaine taille de pas </font></font><code>Δ</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et allons à gauche ou à droite de notre état actuel par pas plus de </font></font><img src="https://habrastorage.org/webt/q1/n2/d_/q1n2d_lbzpbqtvbmbgiha503cmo.png"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">proposal</span>(<span class="hljs-params">x, stepsize</span>):</span>
    <span class="hljs-keyword">return</span> np.random.uniform(low=x - <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             high=x + <span class="hljs-number">0.5</span> * stepsize, <font></font>
                             size=x.shape)</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Enfin, nous calculons la probabilité d'acceptation de la proposition:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">p_acc_MH</span>(<span class="hljs-params">x_new, x_old, log_prob</span>):</span>
    <span class="hljs-keyword">return</span> min(<span class="hljs-number">1</span>, np.exp(log_prob(x_new) - log_prob(x_old)))</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, nous mettons tout cela ensemble dans une mise en œuvre vraiment brève de la phase d'échantillonnage pour l'algorithme Metropolis-Hastings:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_MH</span>(<span class="hljs-params">x_old, log_prob, stepsize</span>):</span><font></font>
    x_new = proposal(x_old, stepsize)<font></font>
    <span class="hljs-comment">#   ,     :</span>
    <span class="hljs-comment">#       [0,1]  </span>
    <span class="hljs-comment">#     </span><font></font>
    accept = np.random.random() &lt; p_acc(x_new, x_old, log_prob)<font></font>
    <span class="hljs-keyword">if</span> accept:
        <span class="hljs-keyword">return</span> accept, x_new
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> accept, x_old</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En plus du prochain état de la chaîne de Markov, </font></font><code>x_new</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ou </font></font><code>x_old</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, nous renvoyons également des informations pour savoir si l'étape MCMC a été adoptée. </font><font style="vertical-align: inherit;">Cela nous permettra de suivre la dynamique de la collecte d'échantillons. </font><font style="vertical-align: inherit;">En conclusion de cette implémentation, nous écrivons une fonction qui appellera itérativement </font></font><code>sample_MH</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et donc construira une chaîne de Markov:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_MH_chain</span>(<span class="hljs-params">init, stepsize, n_total, log_prob</span>):</span><font></font>
<font></font>
    n_accepted = <span class="hljs-number">0</span><font></font>
    chain = [init]<font></font>
<font></font>
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(n_total):<font></font>
        accept, state = sample_MH(chain[<span class="hljs-number">-1</span>], log_prob, stepsize)<font></font>
        chain.append(state)<font></font>
        n_accepted += accept<font></font>
    <font></font>
    acceptance_rate = n_accepted / float(n_total)<font></font>
    <font></font>
    <span class="hljs-keyword">return</span> chain, acceptance_rate</code></pre><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TESTER NOTRE ALGORITHME METROPOLIS-HASTINGS ET RECHERCHER SON COMPORTEMENT</font></font></b> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Probablement, maintenant, vous avez hâte de voir tout cela en action. </font><font style="vertical-align: inherit;">Nous le ferons, nous prendrons des décisions éclairées sur les arguments </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">chain, acceptance_rate = build_MH_chain(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">3.0</span>, <span class="hljs-number">10000</span>, log_prob)<font></font>
chain = [state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain]<font></font>
print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
last_states = <span class="hljs-string">", "</span>.join(<span class="hljs-string">"{:.5f}"</span>.format(state) 
                        <span class="hljs-keyword">for</span> state <span class="hljs-keyword">in</span> chain[<span class="hljs-number">-10</span>:])<font></font>
print(<span class="hljs-string">"Last ten states of chain: "</span> + last_states)<font></font>
Acceptance rate: <span class="hljs-number">0.722</span>
Last ten states of chain: <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.84962</span>, <span class="hljs-number">-0.08692</span>, <span class="hljs-number">0.92728</span>, <span class="hljs-number">-0.46215</span>, <span class="hljs-number">0.08655</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span>, <span class="hljs-number">-0.33841</span></code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les choses sont bonnes. Alors ça a marché? Nous avons réussi à prélever des échantillons dans environ 71% des cas et nous avons une chaîne d'états. Les premiers États dans lesquels la chaîne n'a pas encore convergé vers sa distribution stationnaire doivent être écartés. Vérifions si les conditions que nous avons choisies ont bien une distribution normale:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_samples</span>(<span class="hljs-params">chain, log_prob, ax, orientation=<span class="hljs-string">'vertical'</span>, normalize=True,
                 xlims=(<span class="hljs-params"><span class="hljs-number">-5</span>, <span class="hljs-number">5</span></span>), legend=True</span>):</span>
    <span class="hljs-keyword">from</span> scipy.integrate <span class="hljs-keyword">import</span> quad<font></font>
    <font></font>
    ax.hist(chain, bins=<span class="hljs-number">50</span>, density=<span class="hljs-literal">True</span>, label=<span class="hljs-string">"MCMC samples"</span>,<font></font>
           orientation=orientation)<font></font>
    <span class="hljs-comment">#     PDF</span>
    <span class="hljs-keyword">if</span> normalize:<font></font>
        Z, _ = quad(<span class="hljs-keyword">lambda</span> x: np.exp(log_prob(x)), -np.inf, np.inf)
    <span class="hljs-keyword">else</span>:<font></font>
        Z = <span class="hljs-number">1.0</span>
    xses = np.linspace(xlims[<span class="hljs-number">0</span>], xlims[<span class="hljs-number">1</span>], <span class="hljs-number">1000</span>)<font></font>
    yses = [np.exp(log_prob(x)) / Z <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xses]
    <span class="hljs-keyword">if</span> orientation == <span class="hljs-string">'horizontal'</span>:<font></font>
        (yses, xses) = (xses, yses)<font></font>
    ax.plot(xses, yses, label=<span class="hljs-string">"true distribution"</span>)
    <span class="hljs-keyword">if</span> legend:<font></font>
        ax.legend(frameon=<span class="hljs-literal">False</span>)<font></font>
    <font></font>
fig, ax = plt.subplots()<font></font>
plot_samples(chain[<span class="hljs-number">500</span>:], log_prob, ax)<font></font>
despine(ax)<font></font>
ax.set_yticks(())<font></font>
plt.show()</code></pre><br>
<br>
<img src="https://habrastorage.org/webt/yo/rx/59/yorx59lirnkyju_dymptouaaokw.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cela semble très bien! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qu'en est-il des paramètres </font></font><code>stepsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">? Nous discutons d'abord de la taille de l'étape: elle détermine dans quelle mesure l'état d'essai peut être retiré de l'état actuel du circuit. Par conséquent, il s'agit d'un paramètre de distribution auxiliaire </font></font><code>q</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">qui contrôle la taille des pas aléatoires de la chaîne de Markov. Si la taille du pas est trop grande, les états d'essai se retrouvent souvent dans la queue de la distribution, où les valeurs de probabilité sont faibles. Le mécanisme d'échantillonnage de Metropolis-Hastings ignore la plupart de ces étapes, ce qui entraîne une réduction des taux de réception et un ralentissement significatif de la convergence. Voir par vous-même:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sample_and_display</span>(<span class="hljs-params">init_state, stepsize, n_total, n_burnin, log_prob</span>):</span><font></font>
    chain, acceptance_rate = build_MH_chain(init_state, stepsize, n_total, log_prob)<font></font>
    print(<span class="hljs-string">"Acceptance rate: {:.3f}"</span>.format(acceptance_rate))<font></font>
    fig, ax = plt.subplots()<font></font>
    plot_samples([state <span class="hljs-keyword">for</span> state, <span class="hljs-keyword">in</span> chain[n_burnin:]], log_prob, ax)<font></font>
    despine(ax)<font></font>
    ax.set_yticks(())<font></font>
    plt.show()<font></font>
    <font></font>
sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">30</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.116</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/0g/4-/-r/0g4--rezypxzaqta-pkugq3gi3w.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pas très cool, non? Il semble maintenant qu'il est préférable de définir une taille de pas minuscule. Il s'avère que ce n'est pas non plus une décision intelligente, car la chaîne de Markov étudiera la distribution de probabilité très lentement et ne convergera donc pas aussi rapidement qu'avec une taille de pas bien choisie:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">10000</span>, <span class="hljs-number">500</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.992</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/bf/qh/xi/bfqhxistqravnn7xug43ubowgmu.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quelle que soit la façon dont vous choisissez le paramètre de taille de pas, la chaîne de Markov converge finalement vers une distribution stationnaire. Mais cela peut prendre beaucoup de temps. Le temps pendant lequel nous simulerons la chaîne de Markov est </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">déterminé </font><font style="vertical-align: inherit;">par le paramètre </font><font style="vertical-align: inherit;">- il détermine simplement le nombre d'états de la chaîne de Markov (et, par conséquent, les échantillons sélectionnés) que nous aurons éventuellement. Si la chaîne converge lentement, alors elle doit être augmentée </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour que la chaîne de Markov ait le temps «d'oublier» l'état initial. Par conséquent, nous allons laisser la taille de l'étape minuscule et augmenter le nombre d'échantillons en augmentant le paramètre </font></font><code>n_total</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">sample_and_display(np.array([<span class="hljs-number">2.0</span>]), <span class="hljs-number">0.1</span>, <span class="hljs-number">500000</span>, <span class="hljs-number">25000</span>, log_prob)<font></font>
Acceptance rate: <span class="hljs-number">0.990</span></code></pre><br>
<br>
<img src="https://habrastorage.org/webt/fs/ba/27/fsba27vppyvfqnwdnnr0ifdp3w4.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous progressons plus lentement vers l'objectif ... </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CONCLUSIONS</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Compte tenu de tout ce qui précède, j'espère que vous avez maintenant compris intuitivement l'essence de l'algorithme Metropolis-Hastings, ses paramètres, et comprenez pourquoi il s'agit d'un outil extrêmement utile pour sélectionner des distributions de probabilités non standard que vous pouvez rencontrer dans la pratique. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je vous recommande fortement d'expérimenter avec le code donné </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ici.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- pour vous habituer au comportement de l'algorithme dans diverses circonstances et le comprendre plus profondément. </font><font style="vertical-align: inherit;">Essayez la distribution auxiliaire asymétrique! </font><font style="vertical-align: inherit;">Que se passera-t-il si vous ne définissez pas correctement les critères d'acceptation? </font><font style="vertical-align: inherit;">Que se passe-t-il si vous essayez d'échantillonner à partir d'une distribution bimodale? </font><font style="vertical-align: inherit;">Pouvez-vous trouver un moyen d'ajuster automatiquement la taille du pas? </font><font style="vertical-align: inherit;">Quels sont les pièges ici? </font><font style="vertical-align: inherit;">Répondez à ces questions vous-même!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr491258/index.html">IT girls, d'où venez-vous? Construisons une carte</a></li>
<li><a href="../fr491260/index.html">Normalisation du texte dans les tâches de reconnaissance vocale</a></li>
<li><a href="../fr491262/index.html">Oeil pour oeil. Problèmes de biométrie</a></li>
<li><a href="../fr491264/index.html">Introduction au SSD. Partie 4. Physique</a></li>
<li><a href="../fr491266/index.html">SurfingAttack: compromettre les smartphones avec des assistants sonores [+ vidéo]</a></li>
<li><a href="../fr491272/index.html">Développement de site web en pascal (backend)</a></li>
<li><a href="../fr491276/index.html">Comment j'ai contourné l'interdiction de l'API Messages via la documentation de Vkontakte</a></li>
<li><a href="../fr491278/index.html">CLRium # 7: Rapports, pratique, mentors</a></li>
<li><a href="../fr491280/index.html">L'histoire de la façon dont j'ai développé un langage de programmation</a></li>
<li><a href="../fr491282/index.html">Comment augmenter la productivité de l'équipe (et réduire les erreurs) à l'aide de rallyes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
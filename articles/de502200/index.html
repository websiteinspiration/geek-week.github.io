<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>▶️ 🍇 🅾️ Entropie: Wie Entscheidungsbäume Entscheidungen treffen 👩🏼‍🔧 👨🏼‍🎨 🦎</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine Übersetzung des Artikels wurde vor Beginn des Kurses für maschinelles Lernen vorbereitet .
 
 
 
 Sie sind ein Data Science-Spezialist, der derze...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Entropie: Wie Entscheidungsbäume Entscheidungen treffen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/502200/"><i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine Übersetzung des Artikels wurde vor Beginn des Kurses für </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">maschinelles Lernen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vorbereitet </font><font style="vertical-align: inherit;">.</font></font></b></i><br>
<br>
<img src="https://habrastorage.org/webt/az/2h/3e/az2h3eq1jejcxtd0g4wi4gmamki.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie sind ein Data Science-Spezialist, der derzeit einen Lernpfad verfolgt. Und Sie haben einen langen Weg zurückgelegt, seit Sie Ihre erste Codezeile in Python oder R geschrieben haben. Sie kennen Scikit-Learn wie Ihre Westentasche. Jetzt sitzt du mehr auf Kaggle als auf Facebook. Sie sind nicht neu darin, atemberaubende zufällige Wälder und andere Ensemblemodelle von Entscheidungsbäumen zu erstellen, die hervorragende Arbeit leisten. Trotzdem wissen Sie, dass Sie nichts erreichen werden, wenn Sie sich nicht umfassend entwickeln. Sie möchten tiefer gehen und die Feinheiten und Konzepte verstehen, die den beliebten Modellen des maschinellen Lernens zugrunde liegen. Nun, ich auch.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Heute werde ich über das Konzept der Entropie sprechen - eines der wichtigsten Themen in der Statistik. Später werden wir über das Konzept des Informationsgewinns (Informationsgewinn) sprechen und herausfinden, warum diese grundlegenden Konzepte die Grundlage dafür bilden, wie Entscheidungsbäume aus den erhaltenen Daten erstellt werden.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gut. Lassen Sie uns jetzt übertreten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was ist Entropie? In einfachen Worten ist Entropie nichts anderes als ein Maß für Unordnung. (Es kann auch als Maß für die Reinheit angesehen werden, und bald werden Sie sehen, warum. Aber ich mag das Durcheinander mehr, weil es cooler klingt.) Die </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
mathematische Formel der Entropie lautet wie folgt: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ey/wa/u-/eywau-ntm5stedcuyrelbhhoipu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropie. Es wird manchmal als H geschrieben.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Hier ist p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die Frequenzwahrscheinlichkeit eines Elements / einer Klasse i unserer Daten. Nehmen wir zur Vereinfachung an, wir haben nur zwei Klassen: positiv und negativ. Dann nehme ich entweder den Wert "+" oder "-". Wenn wir insgesamt 100 Punkte in unserem Datensatz hätten, von denen 30 zur positiven Klasse und 70 zur negativen Klasse gehörten, </font><font style="vertical-align: inherit;">wäre </font><font style="vertical-align: inherit;">p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 3/10 und p</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wird 7/10 sein. Hier ist alles einfach. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn ich die Entropie der Klassen aus diesem Beispiel berechne, erhalte ich dies mit der obigen Formel: Die </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5_/hh/20/5_hh20bihmp119n_5vzmlq_vuyw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Entropie beträgt ungefähr 0,88. Dieser Wert wird als ziemlich hoch angesehen, dh wir haben ein hohes Maß an Entropie oder Störung (dh einen niedrigen Reinheitsgrad). Die Entropie wird im Bereich von 0 bis 1 gemessen. Abhängig von der Anzahl der Klassen in Ihrem Datensatz kann der Wert der Entropie mehr als 1 betragen, dies bedeutet jedoch, dass der Grad der Störung extrem hoch ist. Der Einfachheit halber haben wir im heutigen Artikel eine Entropie im Bereich von 0 bis 1. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schauen Sie sich die folgende Tabelle an.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jt/sx/zs/jtsxzsfwwbstp10fqo-rd0ndddw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auf der X-Achse wird die Anzahl der Punkte aus der positiven Klasse in jedem Kreis und auf der Y-Achse die entsprechenden Entropien reflektiert. Sie können sofort die umgekehrte U-Form des Diagramms bemerken. Die Entropie ist im Extremfall am kleinsten, wenn der Kreis im Prinzip keine positiven Elemente enthält oder wenn nur positive Elemente darin sind. Das heißt, wenn die Elemente in einem Kreis identisch sind, ist die Störung 0. Die Entropie ist in der Mitte des Diagramms am höchsten, wobei positive und negative Elemente innerhalb des Kreises gleichmäßig verteilt sind. Hier wird die größte Entropie oder Störung erreicht, da es keine vorherrschenden Elemente gibt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gibt es einen Grund, warum die Entropie unter Verwendung des Logarithmus zur Basis 2 gemessen wird, oder warum wird die Entropie zwischen 0 und 1 gemessen und nicht in einem anderen Bereich? Nein, es gibt keinen Grund. Dies ist nur eine Metrik. Es ist nicht so wichtig zu verstehen, warum dies geschieht. Es ist wichtig zu wissen, wie das, was wir oben bekommen haben, berechnet wird und wie es funktioniert. Entropie ist ein Maß für Verwirrung oder Unsicherheit, und das Ziel von Modellen für maschinelles Lernen und Data Science-Spezialisten im Allgemeinen besteht darin, diese Unsicherheit zu verringern. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt wissen wir, wie das Chaos gemessen wird. Als nächstes benötigen wir einen Wert, um die Reduzierung dieser Störung in den zusätzlichen Informationen (Attribute / unabhängige Variablen) der Zielvariablen / -klasse zu messen. Hier kommt der Informationsgewinn oder Informationsgewinn ins Spiel. Aus mathematischer Sicht kann es wie folgt geschrieben werden:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bn/el/t4/bnelt40yxay8hkbanig088mpk6a.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Wir subtrahieren einfach die Entropie Y von X von der Entropie Y, um die Abnahme der Unsicherheit über Y zu berechnen, vorausgesetzt, es gibt Informationen über X über Y. Je stärker die Unsicherheit abnimmt, desto mehr Informationen können von Y über X </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
erhalten werden. Schauen wir uns ein einfaches Beispiel der Kontingenztabelle an Gehen Sie näher an die Frage heran, wie Entscheidungsbäume mithilfe von Entropie und Informationsgewinn entscheiden, auf welcher Grundlage Knoten im Lernprozess für Daten gebrochen werden sollen. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beispiel: Konjugationstabelle</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/s4/ea/e5/s4eae57mpuehp3mk_mjpmikuan0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Hier ist unsere Zielvariable </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Liability</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die nur zwei Werte annehmen kann: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Normal"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Hoch".</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir haben auch nur ein Zeichen, das als Bonität bezeichnet wird. Es verteilt die Werte in drei Kategorien: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Ausgezeichnet“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Gut“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Schlecht“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Insgesamt wurden 14 Beobachtungen gemacht. 7 von ihnen gehören zur Klasse der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">normalen Haftung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 7 weitere zur Klasse der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hohen Haftung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dies ist eine Teilung an sich. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir uns die Gesamtsumme der Werte in der ersten Zeile ansehen, werden wir sehen, dass wir 4 Beobachtungen mit einem </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ausgezeichneten</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wert </font><font style="vertical-align: inherit;">basierend auf der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität haben</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Darüber hinaus kann ich sogar sagen, dass meine Zielvariable durch die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität „Ausgezeichnet“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gebrochen wird </font><font style="vertical-align: inherit;">. Unter den Beobachtungen mit dem Wert </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Ausgezeichnet"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nach Attribut</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , es gibt 3, die zur Klasse der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">normalen Haftung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gehören, </font><font style="vertical-align: inherit;">und 1, die zur </font><font style="vertical-align: inherit;">Klasse </font><font style="vertical-align: inherit;">der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hohen Haftung gehören</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ebenso kann ich ähnliche Ergebnisse für andere </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonitätswerte</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus der Kontingenztabelle </font><font style="vertical-align: inherit;">berechnen </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Beispiel verwende ich die obige Kontingenztabelle, um die Entropie unserer Zielvariablen unabhängig zu berechnen und dann ihre Entropie unter Berücksichtigung zusätzlicher Informationen aus dem Attribut " </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität" zu</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> berechnen </font><font style="vertical-align: inherit;">. So kann ich berechnen, wie viele zusätzliche Informationen mir </font><font style="vertical-align: inherit;">die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> für die Zielvariable </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftung geben</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wird </font><font style="vertical-align: inherit;">. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Also lasst uns anfangen.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2v/2y/lg/2v2ylghvtk-f-e0eom6aeocsb1q.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Die Entropie unserer Zielvariablen ist 1, was maximale Unordnung aufgrund der gleichmäßigen Verteilung der Elemente zwischen </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Normal“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Hoch“ bedeutet</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der nächste Schritt besteht darin, die Entropie der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftungszielvariablen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> unter Berücksichtigung zusätzlicher Informationen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu berechnen </font><font style="vertical-align: inherit;">. Dazu berechnen wir die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftungsentropie</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> für jeden </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ratingwert</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und addieren sie anhand des durchschnittlichen gewichteten Beobachtungsverhältnisses für jeden Wert. Warum wir den gewichteten Durchschnitt verwenden, wird klarer, wenn wir über Entscheidungsbäume sprechen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rt/_5/fh/rt_5fhldx4dfjcioh7d_uiori6e.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Wir haben die Entropie unserer Zielvariablen mit dem Attribut </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität erhalten</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Jetzt können wir den informativen </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftungsgewinn</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> berechnen, um </font><font style="vertical-align: inherit;">zu verstehen, wie informativ diese Funktion ist. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Die Kenntnis der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonität hat</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> uns geholfen, die Unsicherheit unserer Zielvariablen für die </font><i><font style="vertical-align: inherit;">Haftung zu</font></i><font style="vertical-align: inherit;"> verringern.</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ist das nicht ein gutes Zeichen, das funktionieren sollte? Geben Sie uns Informationen über die Zielvariable? Genau aus diesem Grund verwenden Entscheidungsbäume Entropie und Informationsgewinn. Sie bestimmen, nach welchem ​​Kriterium die Knoten in Zweige unterteilt werden sollen, um sich der Zielvariablen bei jeder nachfolgenden Partition zu nähern und um zu verstehen, wann die Baumkonstruktion abgeschlossen sein muss! (zusätzlich zu Hyperparametern wie maximaler Tiefe natürlich). Lassen Sie uns im folgenden Beispiel anhand von Entscheidungsbäumen sehen, wie dies alles funktioniert. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beispiel: Entscheidungsbaum</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Schauen wir uns ein Beispiel für die Erstellung eines Entscheidungsbaums an, mit dem Ziel, vorherzusagen, ob das Guthaben einer Person abgeschrieben wird oder nicht. Die Bevölkerung wird 30 Exemplare sein. 16 werden zur </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gehören </font><font style="vertical-align: inherit;">, die anderen 14 werden</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Nicht abschreibbar"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Wir werden zwei Zeichen haben, nämlich </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Balance"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die zwei Werte annehmen können: "&lt;50K" oder "&gt; 50K" und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Residence"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die drei Werte </font><font style="vertical-align: inherit;">annehmen kann </font><font style="vertical-align: inherit;">: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OWN"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"RENT"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OTHER"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ich werde zeigen, wie der Entscheidungsbaumalgorithmus entscheidet, welches Attribut zuerst gebrochen werden soll und welches Attribut informativer ist, dh die Unsicherheit der Zielvariablen unter Verwendung des Konzepts der Entropie und des Informationsgewinns am besten beseitigt. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Symptom 1: Gleichgewicht</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Hier gehören die Kreise zur </font><font style="vertical-align: inherit;">Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Abschreibung“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , und die Sterne entsprechen der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Nicht-Abschreibung“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Partitionieren eines übergeordneten Stamms nach Attributen</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gibt uns 2 Erbenknoten. Im linken Knoten befinden sich 13 Beobachtungen, wobei 12/13 (Wahrscheinlichkeit 0,92) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Abschreibung"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und nur 1/13 (Wahrscheinlichkeit 0,08) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Nichtabschreibung"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Im rechten Knoten befinden sich 17 von 30 Beobachtungen, wobei 13/17 (Wahrscheinlichkeit 0,76) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Abschreibung“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 4/17 (Wahrscheinlichkeit 0,24) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">„Nicht-Abschreibung“</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns die Entropie der Wurzel berechnen und sehen, um wie viel der Baum die Unsicherheit verringern kann, indem er eine auf </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> basierende Partition verwendet </font><font style="vertical-align: inherit;">. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yq/ke/do/yqkedojc2s80__h-vqqcptzewai.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Ein auf </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> basierender Split </font><font style="vertical-align: inherit;">ergibt einen Informationsgewinn von 0,37. Zählen wir dasselbe für das </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenzzeichen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und vergleichen Sie die Ergebnisse. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Symptom 2: Residenz</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/mx/tm/sd/mxtmsdt2hm0mamxkdxzqnb9v7mg.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Wenn Sie einen Baum basierend auf der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> teilen, erhalten Sie 3 Erbenknoten. Der linke Nachkommenknoten erhält 8 Beobachtungen, wobei 7/8 (Wahrscheinlichkeit 0,88) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und nur 1/8 (Wahrscheinlichkeit 0,12) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nichtabschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der durchschnittliche Nachfolgeknoten erhält 10 Beobachtungen, wobei 4/10 (Wahrscheinlichkeit 0,4) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 6/10 (Wahrscheinlichkeit 0,6) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nichtabschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der rechte Erbe erhält 12 Beobachtungen, wobei 5/12 (Wahrscheinlichkeit 0,42) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 7/12 (Wahrscheinlichkeit 0,58) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nichtabschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir kennen die Entropie des übergeordneten Knotens bereits, daher berechnen wir einfach die Entropie nach der Partition, um den Informationsgewinn aus dem </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Attribut zu verstehen </font><font style="vertical-align: inherit;">. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/cb/zt/zf/cbztzffw12-wkj6cjfayt_jzlcq.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Der Informationsgewinn aus dem </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Attribut ist </font><font style="vertical-align: inherit;">fast dreimal höher als aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! Wenn Sie sich die Diagramme noch einmal ansehen, werden Sie feststellen, dass die Partitionierung nach </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sauberere Nachkommenknoten ergibt als nach </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der Knoten </font><font style="vertical-align: inherit;">ganz </font><font style="vertical-align: inherit;">links in der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz ist zwar</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auch ziemlich sauber, aber hier kommt der gewichtete Durchschnitt ins Spiel. Trotz der Tatsache, dass der Knoten sauber ist, weist er die geringste Anzahl von Beobachtungen auf, und sein Ergebnis geht bei der allgemeinen Neuberechnung und Berechnung der Gesamtentropie gemäß der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz verloren</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Dies ist wichtig, da wir nach dem allgemeinen Informationsgehalt des Attributs suchen und nicht möchten, dass das Endergebnis durch den seltenen Wert des Attributs verzerrt wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Attribut selbst </font><font style="vertical-align: inherit;">enthält mehr Informationen zur Zielvariablen als </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dadurch wird die Entropie unserer Zielvariablen reduziert. Der Entscheidungsbaumalgorithmus verwendet dieses Ergebnis, um die erste Aufteilung gemäß </font><i><font style="vertical-align: inherit;">Balance</font></i><font style="vertical-align: inherit;"> vorzunehmen</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">um später zu entscheiden, auf welcher Basis die folgenden Knoten zerstört werden sollen. In der realen Welt erfolgt bei mehr als zwei Merkmalen die erste Aufschlüsselung nach dem informativsten Merkmal, und dann wird bei jeder nachfolgenden Aufteilung der Informationsgewinn für jedes zusätzliche Merkmal nachgezählt, da er nicht mit dem Informationsgewinn von jedem Merkmal einzeln identisch ist. Entropie und Informationsgewinn sollten berechnet werden, nachdem eine oder mehrere Partitionen aufgetreten sind, was sich auf das Endergebnis auswirkt. Der Entscheidungsbaum wiederholt diesen Vorgang, wenn er in der Tiefe wächst, bis er entweder eine bestimmte Tiefe erreicht oder eine Art Aufteilung zu einem höheren Informationsgewinn über einen bestimmten Schwellenwert hinaus führt, der auch als Hyperparameter angegeben werden kann!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das ist alles! </font><font style="vertical-align: inherit;">Jetzt wissen Sie, welche Entropie, welcher Informationsgewinn und wie sie berechnet werden. </font><font style="vertical-align: inherit;">Jetzt verstehen Sie, wie der Entscheidungsbaum selbst oder als Teil eines Ensembles Entscheidungen über die beste Reihenfolge der Partitionierung nach Attributen trifft und entscheidet, wann beim Lernen der verfügbaren Daten aufgehört werden soll. </font><font style="vertical-align: inherit;">Wenn Sie jemandem erklären müssen, wie Entscheidungsbäume funktionieren, hoffe ich, dass Sie diese Aufgabe angemessen bewältigen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich hoffe, Sie haben aus diesem Artikel etwas Nützliches für sich gelernt. </font><font style="vertical-align: inherit;">Wenn ich etwas verpasst oder mich falsch ausgedrückt habe, schreibe mir darüber. </font><font style="vertical-align: inherit;">Ich werde dir sehr dankbar sein! </font><font style="vertical-align: inherit;">Danke.</font></font><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erfahren Sie mehr über den Kurs.</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de502176/index.html">Los: JSON-Deserialisierung mit falscher Eingabe oder Umgehen von API-Entwicklerfehlern</a></li>
<li><a href="../de502178/index.html">OVirt in 2 Stunden. Teil 3. Erweiterte Einstellungen</a></li>
<li><a href="../de502180/index.html">Der Tag, an dem der Umfang verschwand. Sicherheitslösungen von Microsoft und Partnern</a></li>
<li><a href="../de502182/index.html">Nochmals zu MikroTik oder dem lang erwarteten SOCKS5</a></li>
<li><a href="../de502186/index.html">Webinar. Informationssicherheit: SOC in Quarantäne</a></li>
<li><a href="../de502202/index.html">Die Entwicklung unbemannter Technologie im Schienenverkehr</a></li>
<li><a href="../de502204/index.html">Schreiben von @ SpringBootTest-Tests bei Verwendung von Spring Shell in einer Anwendung</a></li>
<li><a href="../de502206/index.html">Yandex zeichnete die Geräusche von Retrocomputern auf</a></li>
<li><a href="../de502208/index.html">Chrome-Erweiterung, um ablenkende Empfehlungen auf YouTube zu verbergen</a></li>
<li><a href="../de502234/index.html">Инсайды от сотрудника Facebook: как попасть на стажировку, получить оффер и все о работе в компании</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ñ∂Ô∏è üçá üÖæÔ∏è Entropie: Wie Entscheidungsb√§ume Entscheidungen treffen üë©üèº‚Äçüîß üë®üèº‚Äçüé® ü¶é</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine √úbersetzung des Artikels wurde vor Beginn des Kurses f√ºr maschinelles Lernen vorbereitet .
 
 
 
 Sie sind ein Data Science-Spezialist, der derze...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Entropie: Wie Entscheidungsb√§ume Entscheidungen treffen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/502200/"><i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine √úbersetzung des Artikels wurde vor Beginn des Kurses f√ºr </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">maschinelles Lernen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vorbereitet </font><font style="vertical-align: inherit;">.</font></font></b></i><br>
<br>
<img src="https://habrastorage.org/webt/az/2h/3e/az2h3eq1jejcxtd0g4wi4gmamki.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie sind ein Data Science-Spezialist, der derzeit einen Lernpfad verfolgt. Und Sie haben einen langen Weg zur√ºckgelegt, seit Sie Ihre erste Codezeile in Python oder R geschrieben haben. Sie kennen Scikit-Learn wie Ihre Westentasche. Jetzt sitzt du mehr auf Kaggle als auf Facebook. Sie sind nicht neu darin, atemberaubende zuf√§llige W√§lder und andere Ensemblemodelle von Entscheidungsb√§umen zu erstellen, die hervorragende Arbeit leisten. Trotzdem wissen Sie, dass Sie nichts erreichen werden, wenn Sie sich nicht umfassend entwickeln. Sie m√∂chten tiefer gehen und die Feinheiten und Konzepte verstehen, die den beliebten Modellen des maschinellen Lernens zugrunde liegen. Nun, ich auch.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Heute werde ich √ºber das Konzept der Entropie sprechen - eines der wichtigsten Themen in der Statistik. Sp√§ter werden wir √ºber das Konzept des Informationsgewinns (Informationsgewinn) sprechen und herausfinden, warum diese grundlegenden Konzepte die Grundlage daf√ºr bilden, wie Entscheidungsb√§ume aus den erhaltenen Daten erstellt werden.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gut. Lassen Sie uns jetzt √ºbertreten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was ist Entropie? In einfachen Worten ist Entropie nichts anderes als ein Ma√ü f√ºr Unordnung. (Es kann auch als Ma√ü f√ºr die Reinheit angesehen werden, und bald werden Sie sehen, warum. Aber ich mag das Durcheinander mehr, weil es cooler klingt.) Die </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
mathematische Formel der Entropie lautet wie folgt: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ey/wa/u-/eywau-ntm5stedcuyrelbhhoipu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entropie. Es wird manchmal als H geschrieben.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Hier ist p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die Frequenzwahrscheinlichkeit eines Elements / einer Klasse i unserer Daten. Nehmen wir zur Vereinfachung an, wir haben nur zwei Klassen: positiv und negativ. Dann nehme ich entweder den Wert "+" oder "-". Wenn wir insgesamt 100 Punkte in unserem Datensatz h√§tten, von denen 30 zur positiven Klasse und 70 zur negativen Klasse geh√∂rten, </font><font style="vertical-align: inherit;">w√§re </font><font style="vertical-align: inherit;">p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 3/10 und p</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wird 7/10 sein. Hier ist alles einfach. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn ich die Entropie der Klassen aus diesem Beispiel berechne, erhalte ich dies mit der obigen Formel: Die </font></font><br>
<br>
<img src="https://habrastorage.org/webt/5_/hh/20/5_hh20bihmp119n_5vzmlq_vuyw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Entropie betr√§gt ungef√§hr 0,88. Dieser Wert wird als ziemlich hoch angesehen, dh wir haben ein hohes Ma√ü an Entropie oder St√∂rung (dh einen niedrigen Reinheitsgrad). Die Entropie wird im Bereich von 0 bis 1 gemessen. Abh√§ngig von der Anzahl der Klassen in Ihrem Datensatz kann der Wert der Entropie mehr als 1 betragen, dies bedeutet jedoch, dass der Grad der St√∂rung extrem hoch ist. Der Einfachheit halber haben wir im heutigen Artikel eine Entropie im Bereich von 0 bis 1. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schauen Sie sich die folgende Tabelle an.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jt/sx/zs/jtsxzsfwwbstp10fqo-rd0ndddw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auf der X-Achse wird die Anzahl der Punkte aus der positiven Klasse in jedem Kreis und auf der Y-Achse die entsprechenden Entropien reflektiert. Sie k√∂nnen sofort die umgekehrte U-Form des Diagramms bemerken. Die Entropie ist im Extremfall am kleinsten, wenn der Kreis im Prinzip keine positiven Elemente enth√§lt oder wenn nur positive Elemente darin sind. Das hei√üt, wenn die Elemente in einem Kreis identisch sind, ist die St√∂rung 0. Die Entropie ist in der Mitte des Diagramms am h√∂chsten, wobei positive und negative Elemente innerhalb des Kreises gleichm√§√üig verteilt sind. Hier wird die gr√∂√üte Entropie oder St√∂rung erreicht, da es keine vorherrschenden Elemente gibt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gibt es einen Grund, warum die Entropie unter Verwendung des Logarithmus zur Basis 2 gemessen wird, oder warum wird die Entropie zwischen 0 und 1 gemessen und nicht in einem anderen Bereich? Nein, es gibt keinen Grund. Dies ist nur eine Metrik. Es ist nicht so wichtig zu verstehen, warum dies geschieht. Es ist wichtig zu wissen, wie das, was wir oben bekommen haben, berechnet wird und wie es funktioniert. Entropie ist ein Ma√ü f√ºr Verwirrung oder Unsicherheit, und das Ziel von Modellen f√ºr maschinelles Lernen und Data Science-Spezialisten im Allgemeinen besteht darin, diese Unsicherheit zu verringern. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt wissen wir, wie das Chaos gemessen wird. Als n√§chstes ben√∂tigen wir einen Wert, um die Reduzierung dieser St√∂rung in den zus√§tzlichen Informationen (Attribute / unabh√§ngige Variablen) der Zielvariablen / -klasse zu messen. Hier kommt der Informationsgewinn oder Informationsgewinn ins Spiel. Aus mathematischer Sicht kann es wie folgt geschrieben werden:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bn/el/t4/bnelt40yxay8hkbanig088mpk6a.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Wir subtrahieren einfach die Entropie Y von X von der Entropie Y, um die Abnahme der Unsicherheit √ºber Y zu berechnen, vorausgesetzt, es gibt Informationen √ºber X √ºber Y. Je st√§rker die Unsicherheit abnimmt, desto mehr Informationen k√∂nnen von Y √ºber X </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
erhalten werden. Schauen wir uns ein einfaches Beispiel der Kontingenztabelle an Gehen Sie n√§her an die Frage heran, wie Entscheidungsb√§ume mithilfe von Entropie und Informationsgewinn entscheiden, auf welcher Grundlage Knoten im Lernprozess f√ºr Daten gebrochen werden sollen. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beispiel: Konjugationstabelle</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/s4/ea/e5/s4eae57mpuehp3mk_mjpmikuan0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Hier ist unsere Zielvariable </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Liability</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die nur zwei Werte annehmen kann: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Normal"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Hoch".</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir haben auch nur ein Zeichen, das als Bonit√§t bezeichnet wird. Es verteilt die Werte in drei Kategorien: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûAusgezeichnet‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûGut‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûSchlecht‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Insgesamt wurden 14 Beobachtungen gemacht. 7 von ihnen geh√∂ren zur Klasse der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">normalen Haftung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 7 weitere zur Klasse der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hohen Haftung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dies ist eine Teilung an sich. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir uns die Gesamtsumme der Werte in der ersten Zeile ansehen, werden wir sehen, dass wir 4 Beobachtungen mit einem </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ausgezeichneten</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wert </font><font style="vertical-align: inherit;">basierend auf der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t haben</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dar√ºber hinaus kann ich sogar sagen, dass meine Zielvariable durch die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t ‚ÄûAusgezeichnet‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gebrochen wird </font><font style="vertical-align: inherit;">. Unter den Beobachtungen mit dem Wert </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Ausgezeichnet"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nach Attribut</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , es gibt 3, die zur Klasse der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">normalen Haftung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> geh√∂ren, </font><font style="vertical-align: inherit;">und 1, die zur </font><font style="vertical-align: inherit;">Klasse </font><font style="vertical-align: inherit;">der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hohen Haftung geh√∂ren</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ebenso kann ich √§hnliche Ergebnisse f√ºr andere </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§tswerte</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus der Kontingenztabelle </font><font style="vertical-align: inherit;">berechnen </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Beispiel verwende ich die obige Kontingenztabelle, um die Entropie unserer Zielvariablen unabh√§ngig zu berechnen und dann ihre Entropie unter Ber√ºcksichtigung zus√§tzlicher Informationen aus dem Attribut " </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t" zu</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> berechnen </font><font style="vertical-align: inherit;">. So kann ich berechnen, wie viele zus√§tzliche Informationen mir </font><font style="vertical-align: inherit;">die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr die Zielvariable </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftung geben</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> wird </font><font style="vertical-align: inherit;">. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Also lasst uns anfangen.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2v/2y/lg/2v2ylghvtk-f-e0eom6aeocsb1q.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Die Entropie unserer Zielvariablen ist 1, was maximale Unordnung aufgrund der gleichm√§√üigen Verteilung der Elemente zwischen </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûNormal‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûHoch‚Äú bedeutet</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der n√§chste Schritt besteht darin, die Entropie der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftungszielvariablen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> unter Ber√ºcksichtigung zus√§tzlicher Informationen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu berechnen </font><font style="vertical-align: inherit;">. Dazu berechnen wir die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftungsentropie</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr jeden </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ratingwert</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und addieren sie anhand des durchschnittlichen gewichteten Beobachtungsverh√§ltnisses f√ºr jeden Wert. Warum wir den gewichteten Durchschnitt verwenden, wird klarer, wenn wir √ºber Entscheidungsb√§ume sprechen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rt/_5/fh/rt_5fhldx4dfjcioh7d_uiori6e.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Wir haben die Entropie unserer Zielvariablen mit dem Attribut </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t erhalten</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Jetzt k√∂nnen wir den informativen </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Haftungsgewinn</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> berechnen, um </font><font style="vertical-align: inherit;">zu verstehen, wie informativ diese Funktion ist. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Die Kenntnis der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonit√§t hat</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> uns geholfen, die Unsicherheit unserer Zielvariablen f√ºr die </font><i><font style="vertical-align: inherit;">Haftung zu</font></i><font style="vertical-align: inherit;"> verringern.</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ist das nicht ein gutes Zeichen, das funktionieren sollte? Geben Sie uns Informationen √ºber die Zielvariable? Genau aus diesem Grund verwenden Entscheidungsb√§ume Entropie und Informationsgewinn. Sie bestimmen, nach welchem ‚Äã‚ÄãKriterium die Knoten in Zweige unterteilt werden sollen, um sich der Zielvariablen bei jeder nachfolgenden Partition zu n√§hern und um zu verstehen, wann die Baumkonstruktion abgeschlossen sein muss! (zus√§tzlich zu Hyperparametern wie maximaler Tiefe nat√ºrlich). Lassen Sie uns im folgenden Beispiel anhand von Entscheidungsb√§umen sehen, wie dies alles funktioniert. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beispiel: Entscheidungsbaum</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Schauen wir uns ein Beispiel f√ºr die Erstellung eines Entscheidungsbaums an, mit dem Ziel, vorherzusagen, ob das Guthaben einer Person abgeschrieben wird oder nicht. Die Bev√∂lkerung wird 30 Exemplare sein. 16 werden zur </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> geh√∂ren </font><font style="vertical-align: inherit;">, die anderen 14 werden</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Nicht abschreibbar"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Wir werden zwei Zeichen haben, n√§mlich </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Balance"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die zwei Werte annehmen k√∂nnen: "&lt;50K" oder "&gt; 50K" und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Residence"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die drei Werte </font><font style="vertical-align: inherit;">annehmen kann </font><font style="vertical-align: inherit;">: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OWN"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"RENT"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"OTHER"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ich werde zeigen, wie der Entscheidungsbaumalgorithmus entscheidet, welches Attribut zuerst gebrochen werden soll und welches Attribut informativer ist, dh die Unsicherheit der Zielvariablen unter Verwendung des Konzepts der Entropie und des Informationsgewinns am besten beseitigt. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Symptom 1: Gleichgewicht</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Hier geh√∂ren die Kreise zur </font><font style="vertical-align: inherit;">Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûAbschreibung‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , und die Sterne entsprechen der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûNicht-Abschreibung‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Partitionieren eines √ºbergeordneten Stamms nach Attributen</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gibt uns 2 Erbenknoten. Im linken Knoten befinden sich 13 Beobachtungen, wobei 12/13 (Wahrscheinlichkeit 0,92) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Abschreibung"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und nur 1/13 (Wahrscheinlichkeit 0,08) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Nichtabschreibung"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Im rechten Knoten befinden sich 17 von 30 Beobachtungen, wobei 13/17 (Wahrscheinlichkeit 0,76) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûAbschreibung‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 4/17 (Wahrscheinlichkeit 0,24) Beobachtungen aus der Klasse </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûNicht-Abschreibung‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lassen Sie uns die Entropie der Wurzel berechnen und sehen, um wie viel der Baum die Unsicherheit verringern kann, indem er eine auf </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> basierende Partition verwendet </font><font style="vertical-align: inherit;">. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yq/ke/do/yqkedojc2s80__h-vqqcptzewai.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Ein auf </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> basierender Split </font><font style="vertical-align: inherit;">ergibt einen Informationsgewinn von 0,37. Z√§hlen wir dasselbe f√ºr das </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenzzeichen</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und vergleichen Sie die Ergebnisse. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Symptom 2: Residenz</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/mx/tm/sd/mxtmsdt2hm0mamxkdxzqnb9v7mg.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 Wenn Sie einen Baum basierend auf der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> teilen, erhalten Sie 3 Erbenknoten. Der linke Nachkommenknoten erh√§lt 8 Beobachtungen, wobei 7/8 (Wahrscheinlichkeit 0,88) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und nur 1/8 (Wahrscheinlichkeit 0,12) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nichtabschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der durchschnittliche Nachfolgeknoten erh√§lt 10 Beobachtungen, wobei 4/10 (Wahrscheinlichkeit 0,4) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 6/10 (Wahrscheinlichkeit 0,6) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nichtabschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der rechte Erbe erh√§lt 12 Beobachtungen, wobei 5/12 (Wahrscheinlichkeit 0,42) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und 7/12 (Wahrscheinlichkeit 0,58) Beobachtungen aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nichtabschreibungsklasse</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir kennen die Entropie des √ºbergeordneten Knotens bereits, daher berechnen wir einfach die Entropie nach der Partition, um den Informationsgewinn aus dem </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Attribut zu verstehen </font><font style="vertical-align: inherit;">. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/cb/zt/zf/cbztzffw12-wkj6cjfayt_jzlcq.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Der Informationsgewinn aus dem </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Attribut ist </font><font style="vertical-align: inherit;">fast dreimal h√∂her als aus der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! Wenn Sie sich die Diagramme noch einmal ansehen, werden Sie feststellen, dass die Partitionierung nach </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sauberere Nachkommenknoten ergibt als nach </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der Knoten </font><font style="vertical-align: inherit;">ganz </font><font style="vertical-align: inherit;">links in der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz ist zwar</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auch ziemlich sauber, aber hier kommt der gewichtete Durchschnitt ins Spiel. Trotz der Tatsache, dass der Knoten sauber ist, weist er die geringste Anzahl von Beobachtungen auf, und sein Ergebnis geht bei der allgemeinen Neuberechnung und Berechnung der Gesamtentropie gem√§√ü der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residenz verloren</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Dies ist wichtig, da wir nach dem allgemeinen Informationsgehalt des Attributs suchen und nicht m√∂chten, dass das Endergebnis durch den seltenen Wert des Attributs verzerrt wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance-</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Attribut selbst </font><font style="vertical-align: inherit;">enth√§lt mehr Informationen zur Zielvariablen als </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Dadurch wird die Entropie unserer Zielvariablen reduziert. Der Entscheidungsbaumalgorithmus verwendet dieses Ergebnis, um die erste Aufteilung gem√§√ü </font><i><font style="vertical-align: inherit;">Balance</font></i><font style="vertical-align: inherit;"> vorzunehmen</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">um sp√§ter zu entscheiden, auf welcher Basis die folgenden Knoten zerst√∂rt werden sollen. In der realen Welt erfolgt bei mehr als zwei Merkmalen die erste Aufschl√ºsselung nach dem informativsten Merkmal, und dann wird bei jeder nachfolgenden Aufteilung der Informationsgewinn f√ºr jedes zus√§tzliche Merkmal nachgez√§hlt, da er nicht mit dem Informationsgewinn von jedem Merkmal einzeln identisch ist. Entropie und Informationsgewinn sollten berechnet werden, nachdem eine oder mehrere Partitionen aufgetreten sind, was sich auf das Endergebnis auswirkt. Der Entscheidungsbaum wiederholt diesen Vorgang, wenn er in der Tiefe w√§chst, bis er entweder eine bestimmte Tiefe erreicht oder eine Art Aufteilung zu einem h√∂heren Informationsgewinn √ºber einen bestimmten Schwellenwert hinaus f√ºhrt, der auch als Hyperparameter angegeben werden kann!</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das ist alles! </font><font style="vertical-align: inherit;">Jetzt wissen Sie, welche Entropie, welcher Informationsgewinn und wie sie berechnet werden. </font><font style="vertical-align: inherit;">Jetzt verstehen Sie, wie der Entscheidungsbaum selbst oder als Teil eines Ensembles Entscheidungen √ºber die beste Reihenfolge der Partitionierung nach Attributen trifft und entscheidet, wann beim Lernen der verf√ºgbaren Daten aufgeh√∂rt werden soll. </font><font style="vertical-align: inherit;">Wenn Sie jemandem erkl√§ren m√ºssen, wie Entscheidungsb√§ume funktionieren, hoffe ich, dass Sie diese Aufgabe angemessen bew√§ltigen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich hoffe, Sie haben aus diesem Artikel etwas N√ºtzliches f√ºr sich gelernt. </font><font style="vertical-align: inherit;">Wenn ich etwas verpasst oder mich falsch ausgedr√ºckt habe, schreibe mir dar√ºber. </font><font style="vertical-align: inherit;">Ich werde dir sehr dankbar sein! </font><font style="vertical-align: inherit;">Danke.</font></font><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erfahren Sie mehr √ºber den Kurs.</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de502176/index.html">Los: JSON-Deserialisierung mit falscher Eingabe oder Umgehen von API-Entwicklerfehlern</a></li>
<li><a href="../de502178/index.html">OVirt in 2 Stunden. Teil 3. Erweiterte Einstellungen</a></li>
<li><a href="../de502180/index.html">Der Tag, an dem der Umfang verschwand. Sicherheitsl√∂sungen von Microsoft und Partnern</a></li>
<li><a href="../de502182/index.html">Nochmals zu MikroTik oder dem lang erwarteten SOCKS5</a></li>
<li><a href="../de502186/index.html">Webinar. Informationssicherheit: SOC in Quarant√§ne</a></li>
<li><a href="../de502202/index.html">Die Entwicklung unbemannter Technologie im Schienenverkehr</a></li>
<li><a href="../de502204/index.html">Schreiben von @ SpringBootTest-Tests bei Verwendung von Spring Shell in einer Anwendung</a></li>
<li><a href="../de502206/index.html">Yandex zeichnete die Ger√§usche von Retrocomputern auf</a></li>
<li><a href="../de502208/index.html">Chrome-Erweiterung, um ablenkende Empfehlungen auf YouTube zu verbergen</a></li>
<li><a href="../de502234/index.html">–ò–Ω—Å–∞–π–¥—ã –æ—Ç —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ Facebook: –∫–∞–∫ –ø–æ–ø–∞—Å—Ç—å –Ω–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–∫—É, –ø–æ–ª—É—á–∏—Ç—å –æ—Ñ—Ñ–µ—Ä –∏ –≤—Å–µ –æ —Ä–∞–±–æ—Ç–µ –≤ –∫–æ–º–ø–∞–Ω–∏–∏</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ≥Ô∏è üë®üèø‚Äç‚öñÔ∏è üë∞üèª Resumen sobre m√©todos de clasificaci√≥n de datos ü•£ üò´ üëéüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Al estudiar Data Science, decid√≠ compilar para m√≠ un resumen de las t√©cnicas b√°sicas utilizadas en el an√°lisis de datos. Refleja los nombres de los m√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Resumen sobre m√©todos de clasificaci√≥n de datos</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/491326/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al estudiar Data Science, decid√≠ compilar para m√≠ un resumen de las t√©cnicas b√°sicas utilizadas en el an√°lisis de datos. </font><font style="vertical-align: inherit;">Refleja los nombres de los m√©todos, describe brevemente la esencia y proporciona el c√≥digo Python para una aplicaci√≥n r√°pida. </font><font style="vertical-align: inherit;">Estaba preparando un compendio para m√≠, pero pens√© que tambi√©n podr√≠a ser √∫til para alguien, por ejemplo, antes de una entrevista, en una competencia o al comenzar un nuevo proyecto. </font><font style="vertical-align: inherit;">Dise√±ado para una audiencia que generalmente est√° familiarizada con todos estos m√©todos, pero tiene la necesidad de actualizarlos en la memoria. </font><font style="vertical-align: inherit;">Art√≠culo debajo del corte.</font></font><br>
<a name="habracut"></a><br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Clasificador ingenuo de Bayes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">La f√≥rmula para calcular la probabilidad de clasificar una observaci√≥n como una u otra clase:</font></font></p><br>
  <p><img src="https://habrastorage.org/webt/xm/ks/pe/xmkspevmmrgf6mn_os_pvslb3qc.png"></p><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Por ejemplo, debe calcular la probabilidad de que se lleve a cabo un partido deportivo siempre que el clima sea soleado. </font><font style="vertical-align: inherit;">Los datos de origen y los c√°lculos se muestran en la tabla a continuaci√≥n:</font></font><br>
<br>
 <p><img src="https://habrastorage.org/webt/yd/gc/ik/ydgcik0buynftc9j_xo0bamb3s8.png"></p><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Puede calcular mediante la f√≥rmula (3/9) * (9/14) / (5/14) = 60%, o simplemente desde el sentido com√∫n 3 / (2 + 3) = 60%. </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortalezas</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : f√°cil de interpretar el resultado, adecuado para muestras grandes y clasificaci√≥n de varias clases. </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Debilidades</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : la suposici√≥n de que las caracter√≠sticas son independientes no siempre se cumple; las caracter√≠sticas deben formar un grupo completo de eventos.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
<span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = load_iris(return_X_y=<span class="hljs-literal">True</span>)<font></font>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.5</span>, random_state=<span class="hljs-number">0</span>)<font></font>
gnb = GaussianNB()<font></font>
y_pred = gnb.fit(X_train, y_train).predict(X_test)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
print(<span class="hljs-string">"Number of mislabeled points out of a total %d points : %d"</span>
            % (X_test.shape[<span class="hljs-number">0</span>], (y_test != y_pred).sum())) 
</code></pre> <br>
 <br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M√©todo de vecinos m√°s cercanos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Clasifica cada observaci√≥n de acuerdo con el grado de similitud con otras observaciones. </font><font style="vertical-align: inherit;">El algoritmo no es param√©trico (no hay restricciones en los datos, por ejemplo, la funci√≥n de distribuci√≥n) y utiliza entrenamiento diferido (no se utilizan modelos pre-entrenados, todos los datos disponibles se usan durante la clasificaci√≥n).</font></font></p><br>
  <p><img src="https://habrastorage.org/webt/l7/vw/1n/l7vw1nxyzyori9nkeminukor90q.png"></p><br>
  <br>
 <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortalezas</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : f√°cil de interpretar el resultado, muy adecuado para tareas con un peque√±o n√∫mero de variables explicativas. </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Debilidades</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : baja precisi√≥n en comparaci√≥n con otros m√©todos. </font><font style="vertical-align: inherit;">Requiere una potencia inform√°tica considerable con una gran cantidad de variables explicativas y muestras grandes.</font></font><br>
 <br>
  <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X = [[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>], [<span class="hljs-number">2</span>], [<span class="hljs-number">3</span>]]<font></font>
y = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<font></font>
neigh = KNeighborsClassifier(n_neighbors=<span class="hljs-number">3</span>)<font></font>
neigh.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
print(neigh.predict([[<span class="hljs-number">1.1</span>]]))<font></font>
print(neigh.predict_proba([[<span class="hljs-number">0.9</span>]]))
 </code></pre> <br>
 <br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M√©todo de vector de soporte (SVM)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Cada objeto de datos se representa como un vector (punto) en el espacio p-dimensional. </font><font style="vertical-align: inherit;">La tarea es separar los puntos con un hiperplano. </font><font style="vertical-align: inherit;">Es decir, ¬øes posible encontrar dicho hiperplano para que la distancia desde √©l hasta el punto m√°s cercano sea m√°xima? </font><font style="vertical-align: inherit;">Puede haber muchos hiperplanos buscados; por lo tanto, se cree que maximizar la brecha entre clases contribuye a una clasificaci√≥n m√°s segura.</font></font></p><br>
  <p><img src="https://habrastorage.org/getpro/habr/post_images/bcf/cdb/f99/bcfcdbf99544b1cd6ccb0f99ec519131.jpg"></p><br>
  <br>
 <p> <strong> </strong> ‚Äî     .   ,   ,   .      . <strong> </strong> ‚Äî  ,   ,   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"> </a>,    .        .<br>
 </p> <br>
  <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]<font></font>
y = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<font></font>
clf = svm.SVC()<font></font>
clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
clf.predict([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]])
 </code></pre> <br>
 <p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Årboles de decisi√≥n</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Divisi√≥n de datos en submuestras de acuerdo con una determinada condici√≥n en forma de estructura de √°rbol. </font><font style="vertical-align: inherit;">Matem√°ticamente, la divisi√≥n en clases ocurre hasta que se encuentran todas las condiciones que determinan la clase con la mayor precisi√≥n posible, es decir, cuando no hay representantes de otra clase en cada clase. </font><font style="vertical-align: inherit;">En la pr√°ctica, se utiliza un n√∫mero limitado de caracter√≠sticas y capas, y siempre hay dos ramas.</font></font></p><br>
  <p><img src="https://habrastorage.org/getpro/habr/post_images/b3c/162/1f1/b3c1621f19b930a48abce372977cadbb.png"></p><br>
 <br>
 <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortalezas</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : es posible simular procesos complejos e interpretarlos f√°cilmente. </font><font style="vertical-align: inherit;">La clasificaci√≥n multiclase es posible. </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Debilidades</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : es f√°cil volver a entrenar el modelo si crea muchas capas. </font><font style="vertical-align: inherit;">Las emisiones pueden afectar la precisi√≥n; la soluci√≥n a estos problemas es recortar los niveles inferiores.</font></font><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> tree<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = load_iris(return_X_y=<span class="hljs-literal">True</span>)<font></font>
clf = tree.DecisionTreeClassifier()<font></font>
clf = clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
tree.plot_tree(clf.fit(iris.data, iris.target)) </code></pre> <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"> / </a>.        .  ‚Äî     .       (random patching)             .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">oob-</a>.</p><br>
 <p><strong> </strong>:   ,     ,  ,    ,   ,       .     ,    . <strong> </strong> ‚Äî    ,      .  ,     ( 100 000),     ‚Äî .</p> <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_classification<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = make_classification(n_samples=<span class="hljs-number">1000</span>, n_features=<span class="hljs-number">4</span>,<font></font>
                           n_informative=<span class="hljs-number">2</span>, n_redundant=<span class="hljs-number">0</span>,<font></font>
                           random_state=<span class="hljs-number">0</span>, shuffle=<span class="hljs-literal">False</span>)<font></font>
                           <font></font>
clf = RandomForestClassifier(max_depth=<span class="hljs-number">2</span>, random_state=<span class="hljs-number">0</span>)<font></font>
clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span><font></font>
print(clf.feature_importances_)<font></font>
print(clf.predict([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]))</code></pre> <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">  </a>.      (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">hinge loss function</a>).      .<br>
  </p><p><img src="https://habrastorage.org/webt/d7/wk/si/d7wksizyut_vgl2idpts9-eythq.png"></p><br>
  <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Tambi√©n hay una versi√≥n de descenso de gradiente estoc√°stico, que se utiliza para muestras grandes. </font><font style="vertical-align: inherit;">Su esencia es que considera la derivada no para toda la muestra, sino para cada observaci√≥n (aprendizaje en l√≠nea) (o para el grupo de observaci√≥n de mini lotes) y cambia los pesos. </font><font style="vertical-align: inherit;">Como resultado, llega al mismo √≥ptimo que con un HS convencional. </font><font style="vertical-align: inherit;">Existen m√©todos para usar HS para OLS, logit, tobit y otros m√©todos ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">evidencia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
 <br>
 <p><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortalezas</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : alta precisi√≥n de clasificaci√≥n y pron√≥stico, adecuado para clasificaci√≥n de m√∫ltiples clases. </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Debilidades</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : sensibilidad a los par√°metros del modelo.</font></font></p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X = [[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>], [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]]<font></font>
y = [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<font></font>
clf = SGDClassifier(loss=<span class="hljs-string">"hinge"</span>, penalty=<span class="hljs-string">"l2"</span>, max_iter=<span class="hljs-number">5</span>)<font></font>
clf.fit(X, y)<font></font>
<font></font>
<span class="hljs-comment">#result</span>
clf.predict([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]])<font></font>
clf.coef_<font></font>
clf.intercept_</code></pre> <br>
 <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"> </a>.   .         ,    . ,     ,    . </p><br>
 <br>
 <p><strong> </strong>:     ,    ,    ,    . <strong> </strong> ‚Äî    .</p><br>
  <br>
 <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> ensemble
<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">from</span> sklearn.utils <span class="hljs-keyword">import</span> shuffle
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<font></font>
<font></font>
<span class="hljs-comment">#model fit</span><font></font>
boston = datasets.load_boston()<font></font>
X, y = shuffle(boston.data, boston.target, random_state=<span class="hljs-number">13</span>)<font></font>
X = X.astype(np.float32)<font></font>
offset = int(X.shape[<span class="hljs-number">0</span>] * <span class="hljs-number">0.9</span>)<font></font>
X_train, y_train = X[:offset], y[:offset]<font></font>
X_test, y_test = X[offset:], y[offset:]<font></font>
params = {<span class="hljs-string">'n_estimators'</span>: <span class="hljs-number">500</span>, <span class="hljs-string">'max_depth'</span>: <span class="hljs-number">4</span>, <span class="hljs-string">'min_samples_split'</span>: <span class="hljs-number">2</span>,
          <span class="hljs-string">'learning_rate'</span>: <span class="hljs-number">0.01</span>, <span class="hljs-string">'loss'</span>: <span class="hljs-string">'ls'</span>}<font></font>
clf = ensemble.GradientBoostingRegressor(**params)<font></font>
clf.fit(X_train, y_train)<font></font>
<font></font>
<span class="hljs-comment">#result</span><font></font>
mse = mean_squared_error(y_test, clf.predict(X_test))<font></font>
print(<span class="hljs-string">"MSE: %.4f"</span> % mse)</code></pre> <br>
 <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow"> /logit</a>.     0  1,     (<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">log likelihood</a>).  ‚Äî    Y       w.<br>
  </p><p><img src="https://habrastorage.org/getpro/habr/post_images/859/2c1/173/8592c1173d2ff17239fca69ec8b18cac.jpg"></p><br>
  <br>
  <p><img src="https://habrastorage.org/getpro/habr/post_images/cfe/2ca/c37/cfe2cac37843ae065a3ef157a02d389c.jpg"></p><br>
  <br>
 <br>
 <p><strong> </strong>:  ,      . <strong> </strong> ‚Äî    ,    .</p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<font></font>
<font></font>
<span class="hljs-comment">#model fit</span>
X, y = load_iris(return_X_y=<span class="hljs-literal">True</span>)<font></font>
clf = LogisticRegression(random_state=<span class="hljs-number">0</span>).fit(X, y)<font></font>
clf.predict(X[:<span class="hljs-number">2</span>, :])<font></font>
<font></font>
<span class="hljs-comment">#result</span>
clf.predict_proba(X[:<span class="hljs-number">2</span>, :])<font></font>
clf.score(X, y) </code></pre> <br>
 <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Probit</a>.     ,     ,   ,      .</p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">import</span> statsmodels<font></font>
<font></font>
<span class="hljs-comment">#model fit</span><font></font>
result_3 = statsmodels.discrete.<font></font>
    discrete_model.Probit(labf_part, ind_var_probit )<font></font>
<font></font>
<span class="hljs-comment">#result</span>
print(result_3.summary()) </code></pre> <br>
 <p>-<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="nofollow">Tobit</a>. ,      .</p><br>
  <pre><code class="python hljs"><span class="hljs-comment">#imports</span>
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> make_regression
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> tobit <span class="hljs-keyword">import</span> *<font></font>
<font></font>
<span class="hljs-comment">#model fit</span><font></font>
tr = TobitModel()<font></font>
<font></font>
<span class="hljs-comment">#result</span>
tr = tr.fit(x, y, cens, verbose=<span class="hljs-literal">False</span>)<font></font>
tr.coef_</code></pre> <br>
 <p>  -  , ,     .       ,  ,    ,    .   .</p><br>
 <br>
<br>
 <br></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es491302/index.html">Cliente OVPN en tel√©fonos Grandstream</a></li>
<li><a href="../es491304/index.html">Helsinki: una ciudad de felicidad y confort</a></li>
<li><a href="../es491308/index.html">ClickHouse: an√°lisis de datos visualmente r√°pido e intuitivo en Tabix. Igor Strykhar</a></li>
<li><a href="../es491310/index.html">C√≥mo descifrar un archivo de contrase√±a usted mismo</a></li>
<li><a href="../es491312/index.html">C√≥mo tomamos un tamiz de un hombre y ayudamos al molino</a></li>
<li><a href="../es491332/index.html">Planificaci√≥n horaria y otra optimizaci√≥n de eventos scrum</a></li>
<li><a href="../es491336/index.html">Juega como un dise√±ador de juegos</a></li>
<li><a href="../es491338/index.html">¬øPuede 5G reemplazar Wi-Fi?</a></li>
<li><a href="../es491342/index.html">C√≥mo perder a todos los usuarios de su bot de telegramas. Instrucciones breves</a></li>
<li><a href="../es491344/index.html">Nuevo participante en computaci√≥n cu√°ntica con tecnolog√≠a √∫nica</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
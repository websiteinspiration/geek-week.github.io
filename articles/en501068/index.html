<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍⚖️ 🚋 📬 Deepfakes and deep media: A new battleground for security 🤱🏿 👌🏿 👨🏽‍✈️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article is part of a special issue of VB. Read the full series here: AI and Security .
 
 The number of diphakes - media that take an existing ph...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Deepfakes and deep media: A new battleground for security</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/501068/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/je/nd/hrjendr1wj5jz4hjefypyqo2gqy.jpeg"></div></a><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This article is part of a special issue of VB. Read the full series here: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AI and Security</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
The number of diphakes - media that take an existing photo, audio or video and replace the person’s personality on it with someone else’s using AI - is growing rapidly. This is worrying, not only because such fakes can be used to influence people's opinions during elections or to entangle someone in crimes, but also because they have already been abused to create </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fake porn</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and to </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">deceive the director of a British energy company</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anticipating this kind of new reality, the union of academic institutions, technology firms and nonprofits is developing ways to identify misleading media generated by AI. </font><font style="vertical-align: inherit;">Their work shows that detection tools are only a short-term viable solution, while the diphtheic arms race is just beginning.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake text</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Previously, the best prose created by AI was more like texts from the game </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mad Libs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> than the novel “Bunches of Wrath”, but modern language models can now write texts that are close in presentation and persuasiveness to those written by a person. </font><font style="vertical-align: inherit;">For example, the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> model </font><font style="vertical-align: inherit;">, released by San Francisco's OpenAI research firm, creates fragments in the style </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">of New Yorker</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -style </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">articles</font></a><font style="vertical-align: inherit;"> or scripts for Brainstorming </font><font style="vertical-align: inherit;">in a matter of seconds </font><font style="vertical-align: inherit;">. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Researchers</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The Middlebury Institute's Center for Terrorism, Extremism and Counter-Terrorism suggested that the GPT-2 and other similar models could be set up to advocate the superiority of the white race, jihadist Islamism and other threatening ideologies - and this raises even more concerns.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/px/lx/fqpxlxj7iafxgiyvtrlle1pd254.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Above: Frontend GPT-2, a trained language model from research firm OpenAI. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Image courtesy: OpenAI</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In search of a system capable of detecting synthetic content, researchers at the Paul G. Allen School of Computer Science and Engineering at the University of Washington and the Allen Institute of Artificial Intelligence developed </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Grover</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , an algorithm that they claim was able to select 92% of the diphages in the test a set made up of Common Crawl Corpus open data. The team explains its success with a copywriting approach, which, according to them, helped to understand the features of the language created by AI. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A team of scientists from Harvard and MIT-IBM Watson AI Lab separately released </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Giant Language Model Test Room</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, a web environment that attempts to determine if text was written using an AI model. </font><font style="vertical-align: inherit;">Given the semantic context, she predicts which words are most likely to appear in a sentence, essentially writing her own text. </font><font style="vertical-align: inherit;">If the words in the sample being tested correspond to 10, 100 or 1000 most likely words, the indicator turns green, yellow or red, respectively. </font><font style="vertical-align: inherit;">In fact, she uses her own predictable text as a guideline for identifying artificially generated content.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake videos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Modern AI, generating video, is just as dangerous and has the same, if not great, capabilities as its natural counterpart. An </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">academic article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> published by Hong Kong-based startup SenseTime, Nanyang University of Technology, and the Institute of Automation of the Chinese Academy of Sciences details the framework that edits footage using audio to synthesize realistic video. And researchers from Hyperconnect in Seoul recently developed the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MarioNETte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tool </font><font style="vertical-align: inherit;">, which can manipulate the facial features of a historical figure, politician or CEO, synthesizing a face animated by another person’s movements.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
However, even the most realistic dipfakes contain artifacts that issue them. “Dipfakes created by generative systems study a set of real images in a video, to which you add new images, and then generate a new video with new images,” says Ishay Rosenberg, head of the deep training group at the cybersecurity company Deep Instinct. “The resulting video is slightly different as a result of changes in the distribution of artificially generated data and in the distribution of data in the original video. These so-called "glimpses in the matrix," are what the diphtheic detectors are capable of distinguishing. "</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jg/ba/nn/jgbanndfcnaymr8ggieay3n5vko.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Above: two fake videos created using the most advanced techniques. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Image courtesy of: SenseTime</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Last summer, a team from the University of California at Berkeley and the University of Southern California prepared a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">model</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to search for exact “units of facial action” - data on facial movements, ticks and expressions, including when lifting the upper lip and turning the head when people frown - to identify fake videos with an accuracy of more than 90%. Similarly, in August 2018, participants in the Media Forensics Program of the US Defense Advanced Research Projects Agency (DARPA) tested </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">systems</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">capable of detecting AI-generated video based on such signs as unnatural blinking, strange head movements, unusual eye color and much more. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Several startups are currently in the process of commercializing similar tools for detecting fake video images. The Amsterdam laboratory </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deeptrace Labs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> offers a set of monitoring tools aimed at classifying dipfakes that are uploaded to social networks, video hosting platforms and disinformation networks. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dessa has</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> proposed methods for improving fake detectors trained on fake video sets. And in July 2018, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Truepic raised $ 8 million.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to finance its service for the deep detection of fakes in video and photos. In December 2018, the company acquired the startup Fourandsix, whose counterfeit image detector received a DARPA license.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ys/o-/y6/yso-y6hqoqnnhtvgrmvwm4pmiio.png"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Above: Dipfake images edited by AI.</font></font><br>
</font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In addition to developing fully trained systems, a number of companies have published text corps in the hope that the research community will develop new methods for detecting fakes. To speed this process, Facebook, along with Amazon Web Services (AWS), Partnership on AI, and academics from several universities, led the Deepfake Detection Challenge. The program has a set of video samples with labels indicating that some of them were affected by artificial intelligence. In September 2019, Google released a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">collection of visual fakes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">as part of the FaceForensics test, which was created by the Technical University of Munich and the University of Naples Federico II. </font><font style="vertical-align: inherit;">And most recently, researchers from SenseTime, together with Nanyang University of Technology in Singapore, have developed </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeeperForensics-1.0</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , a data set for detecting fakes that they claim is the largest of its kind.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake Audio</font></font></h2><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AI and machine learning</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> are not only suitable for synthesizing video and text, they can also copy voices. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Countless </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">studies</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> have shown that a small data set is all that is required to recreate a person’s speech. Commercial systems such as </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resemble</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and Lyrebird require a few minutes of audio recordings, while sophisticated models, such as the latest Baidu Deep Voice implementation, can only copy voice from a 3.7-second sample. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are not so many tools for detecting audio diphakes, but solutions are starting to appear.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DWK_iYBl8cA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A few months ago, the Resemble team released an open-source tool called Resemblyzer, which uses AI and machine learning to detect dipfakes by acquiring high-level voice samples and predicting whether they are real or simulated. After receiving an audio file with speech, he creates a mathematical representation summarizing the characteristics of the recorded voice. This allows developers to compare the similarity of the two votes or find out who is talking at the moment.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In January 2019, as part of the Google News Initiative, Google released a speech corpus containing “thousands” of phrases spoken using text-to-speech models. </font><font style="vertical-align: inherit;">Samples were taken from English articles read by 68 different synthetic voices in different dialects. </font><font style="vertical-align: inherit;">The case is available to all participants of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ASVspoof 2019</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , a contest whose goal is to promote countermeasures against fake speech.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Much to lose</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
None of the detectors has achieved perfect accuracy, and researchers have not yet figured out how to identify fake authorship. Deep Instinct Rosenberg expects this to inspire bad actors to spread fakes. “Even if a dipfake created by an attacker is detected, only the dipfake risks being disclosed,” he said. “For an actor, the risk of being caught is minimal, so there are few constraints against creating fakes.” </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Rosenberg's theory is supported </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">by a Deeptrace report</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which found </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">14,698</font></a><font style="vertical-align: inherit;"> fake videos online during its most recent count in June and July 2019. Over a seven-month period, their number increased by 84%. The vast majority of them (96%) are pornographic videos featuring women.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Given these figures, Rosenberg argues that companies that “lose a lot” due to diphakes should develop and implement deep detection technology in their products, which, in his opinion, is similar to antivirus programs. And in this area shifts have appeared; </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facebook announced in early January</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that it would use a combination of automated and manual systems to detect fake content, and </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Twitter recently suggested</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> flagging diphakes and deleting those that could be harmful.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, the technologies underlying the generation of dipfakes are just tools, and they have great potential for good deeds. Michael Klozer, head of Data &amp; Trust at Access Partnership, a consulting company, said the technology is already being used to improve medical diagnostics and cancer detection, fill gaps in the mapping of the universe, and improve the training of unmanned vehicles. Therefore, he warns against the use of general campaigns to block generative AI. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
“Since leaders began to apply existing legal norms in cases of diplomatic affairs, it’s very important now not to get rid of </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">valuable technologies</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">getting rid of fakes, ”said Klozer. </font><font style="vertical-align: inherit;">“Ultimately, case law and social norms regarding the use of this new technology are not ripe enough to create bright red lines that delineate fair use and abuse.”</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en501056/index.html">Why, when and how to use multithreading and multiprocessing in Python</a></li>
<li><a href="../en501058/index.html">Teamcenter Rapid Start Solution Helps Industrial Equipment Manufacturers Cut Design Time By 25%</a></li>
<li><a href="../en501060/index.html">JetBrains .NET Days Online, May 13-14</a></li>
<li><a href="../en501062/index.html">All reports of the free online part of PHP Russia with foreign speakers can be viewed in translation</a></li>
<li><a href="../en501064/index.html">To the flight of the Chinese experimental ship. Infographics and collages.</a></li>
<li><a href="../en501072/index.html">So who invented the radio: Guglielmo Marconi or Alexander Popov?</a></li>
<li><a href="../en501076/index.html">Month removed. We summarize and share life hacks from the leaders of the working groups of the Jet Infosystems</a></li>
<li><a href="../en501084/index.html">Observable Services in Angular</a></li>
<li><a href="../en501086/index.html">Summ3r of h4ck 2020. Digital Security Summer Tutorial</a></li>
<li><a href="../en501088/index.html">Specify it. Yandex Report</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
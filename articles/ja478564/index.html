<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚡 🎊 🤰🏼 TsIANがテラバイトのログをどのように手入れしたか 🧑🏽‍🤝‍🧑🏻 🦆 😵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="皆さん、こんにちは。私の名前はアレクサンダーです。CIANのエンジニアとして、システム管理とインフラストラクチャプロセスの自動化に携わっています。以前の記事の1つに対するコメントで、1日あたり4 TBのログをどこで取得し、それらを使用して何を行うかを尋ねられました。はい、多くのログがあり、それらを処...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>TsIANがテラバイトのログをどのように手入れしたか</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/cian/blog/478564/"><img src="https://habrastorage.org/getpro/habr/post_images/f5a/f37/994/f5af37994ecad978b8cd3edd3dc7ae0a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
皆さん、こんにちは。私の名前はアレクサンダーです。CIANのエンジニアとして、システム管理とインフラストラクチャプロセスの自動化に携わっています。</font><font style="vertical-align: inherit;">以前の記事の1つに対するコメントで、1日あたり4 TBのログをどこで取得し、それらを使用して何を行うかを尋ねられました。</font><font style="vertical-align: inherit;">はい、多くのログがあり、それらを処理するための独立したインフラストラクチャクラスターが作成されているため、問題をすばやく解決できます。</font><font style="vertical-align: inherit;">この記事では、増え続けるデータの流れに対応するために、1年にわたってどのようにそれを適応させたかについて説明します。</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">どこから始めましたか</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/6d2/1eb/3da/6d21eb3da4aa0189ae44b9ca951b15a8.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
過去数年間で、cian.ruの負荷は非常に急速に増加し、2018年の第3四半期までに、リソーストラフィックは月間1,120万のユニークユーザーに達しました。当時、重大な瞬間にログの最大40％が失われたため、インシデントに迅速に対処できず、解決に多くの時間と労力を費やしました。問題の原因を見つけることができず、しばらくして再発しました。それはあなたが何かをしなければならなかった地獄でした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
当時は、ElasticSearchバージョン5.5.2の10個のデータノードのクラスターを使用して、ログを保存するために一般的なインデックス設定を使用していました。これは1年以上前に人気があり、手頃な価格のソリューションとして導入されました。その場合、ログストリームはそれほど大きくなく、非標準の構成を考えても意味がありませんでした。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
異なるポートのLogstashは、5つのElasticSearchコーディネーターで受信ログの処理を提供しました。</font><font style="vertical-align: inherit;">サイズに関係なく、1つのインデックスは5つのシャードで構成されていました。</font><font style="vertical-align: inherit;">毎時および毎日のローテーションが編成された結果、毎時間約100個の新しい断片がクラスターに出現しました。</font><font style="vertical-align: inherit;">ログはそれほど多くありませんでしたが、クラスターは管理しており、誰もその設定に注意を向けませんでした。&nbsp;</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">成長の問題</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2つのプロセスが互いにオーバーラップしたため、生成されたログの量は非常に急速に増加しました。一方で、サービスのユーザーはますます増えていました。一方で、私たちは積極的にマイクロサービスアーキテクチャに切り替え始め、古いモノリスをC＃とPythonに統合しました。モノリスの一部を置き換える数十の新しいマイクロサービスにより、インフラストラクチャクラスターのログが大幅に増加しました。&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
クラスタが事実上制御できなくなるという事実に私たちを導いたのはスケーリングでした。ログが毎秒2万メッセージの速度で到着し始めると、無用の頻繁なローテーションによりシャードの数が6千に増え、1つのノードが600を超えるシャードを占めていました。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これにより、RAMの割り当てに問題が発生し、ノードが落ちると、すべてのシャードの同時移動が始まり、トラフィックが増加し、残りのノードにロードされたため、クラスターにデータを書き込むことがほぼ不可能になりました。そしてこの期間中、私たちは丸太なしで残されました。また、サーバーの問題により、原則としてクラスターの1/10が失われました。小さなインデックスが多数あると、複雑さが増します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ログがなければ、インシデントの原因を理解できず、遅かれ早かれ同じレーキに再び踏み込むことができましたが、これまでのすべての動作メカニズムがまったく逆に研がれたため、これは私たちのチームのイデオロギーでは受け入れられません。同じ問題を繰り返さないでください。</font><font style="vertical-align: inherit;">これを行うには、全量のログとそれらのログをほぼリアルタイムで配信する必要がありました。担当エンジニアのチームがメトリックだけでなくログからもアラートを監視したためです。</font><font style="vertical-align: inherit;">問題の程度を理解するために-その時点でのログの総量は1日あたり約2 TBでした。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ログの損失を完全になくし、不可抗力中のELKクラスターへの配信時間を最大15分に削減するというタスクを設定しました（将来、この数値は内部KPIとして使用されました）。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">新しい回転メカニズムとホットウォームノード</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/363/96f/05e/36396f05e01c97e805388ff27d134e2a.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ElasticSearchのバージョンを5.5.2から6.4.3に更新することから、クラスター変換を開始しました。もう一度、バージョン5のクラスターを配置しました。それを返済して完全に更新することにしました。まだログはありません。したがって、この移行はわずか数時間で完了しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この段階で最も意欲的な変換は、中間バッファApache Kafkaとしてコーディネータを使用した3つのノードでの実装でした。メッセージブローカーにより、ElasticSearchで問題が発生したときにログを失うことがなくなりました。同時に、2つのノードをクラスターに追加し、3つの「ホット」ノードがデータセンターの異なるラックに配置されたホットウォームアーキテクチャに切り替えました。アプリケーションエラーログだけでなく、nginxも失われないようにログをリダイレクトしました。マイナーログ—デバッグ、警告などが他のノードに送られ、24時間後に「重要な」ログが「ホット」ノードから移動しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
小さなインデックスの数を増加させないために、時間ローテーションからロールオーバーメカニズムに切り替えました。</font><font style="vertical-align: inherit;">フォーラムには、インデックスサイズによるローテーションは非常に信頼できないという多くの情報があったため、インデックス内のドキュメント数によるローテーションを使用することにしました。</font><font style="vertical-align: inherit;">各インデックスを分析し、ローテーションが機能するまでのドキュメント数を記録しました。</font><font style="vertical-align: inherit;">したがって、シャードの最適サイズに達しました-50 GB以下。&nbsp;</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">クラスターの最適化</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/cf3/c46/45e/cf3c4645e6b74cf5491f9878dacfa185.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、問題を完全に取り除くことはできませんでした。</font><font style="vertical-align: inherit;">残念ながら、小さなインデックスはすべて同じように見えました。日付でローテーションを削除したため、設定されたボリュームに達せず、ローテーションせず、3日以上経過したインデックスのグローバルクリーニングによって削除されました。</font><font style="vertical-align: inherit;">これにより、クラスターからのインデックスが完全に消えたためにデータが失われ、存在しないインデックスに書き込もうとすると、制御に使用したキュレーターロジックが破損しました。</font><font style="vertical-align: inherit;">記録用のエイリアスがインデックスに変換され、ロールオーバーのロジックが壊れたため、一部のインデックスが600 GBまで制御不能に増加しました。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
たとえば、ローテーションを構成するには：</font></font><br>
<br>
<pre><code class="plaintext hljs">urator-elk-rollover.yaml<font></font>
<font></font>
---<font></font>
actions:<font></font>
&nbsp;&nbsp;1:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;action: rollover<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;options:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name: "nginx_write"<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;conditions:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_docs: 100000000<font></font>
&nbsp;&nbsp;2:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;action: rollover<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;options:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name: "python_error_write"<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;conditions:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;max_docs: 10000000<font></font>
</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ロールオーバーエイリアスがない場合、エラーが発生しました：</font></font><br>
<br>
<pre><code class="plaintext hljs">ERROR &nbsp; &nbsp; alias "nginx_write" not found.<font></font>
ERROR &nbsp; &nbsp; Failed to complete action: rollover.&nbsp; &lt;type 'exceptions.ValueError'&gt;: Unable to perform index rollover with alias "nginx_write".<font></font>
</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この問題の解決策を次の反復に残し、別の質問をしました。着信ログを処理するLogstashのロジックをプルするように切り替えました（不要な情報を削除して強化します）。これをdocker-composeを介して起動するdockerに配置し、同じ場所にlogstash-exporterを配置しました。これは、ログストリームの運用監視のためのメトリックをPrometheusに提供します。そこで、各タイプのログの処理を担当するlogstashインスタンスの数をスムーズに変更する機会を自分たちに与えました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
クラスタを改善している間、cian.ruトラフィックは1ヶ月あたり1280万のユニークユーザーに増加しました。</font><font style="vertical-align: inherit;">その結果、変換が本番環境での変更に少し遅れをとっていることがわかり、「ウォーム」ノードが負荷に対応できず、ログの配信全体が遅くなるという問題に直面しました。</font><font style="vertical-align: inherit;">「ホット」なデータは問題なく受信されましたが、インデックスを均等に分散するために、残りのデータの配信に介入し、手動でロールオーバーする必要がありました。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
同時に、クラスター内のlogstashインスタンスの設定のスケーリングと変更は、ローカルのdocker-composeであり、すべてのアクションが手動で実行されたために複雑でした（新しい目的を追加するには、すべてのサーバーを手で操作し、どこでもdocker-compose up -dを実行する必要がありました）。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ログの再配布</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今年の9月も引き続きモノリスが見られ、クラスターの負荷が増加し、ログストリームは1秒あたり3万メッセージに近づきました。&nbsp;</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/28c/ff7/c76/28cff7c7661c901102a69fe49beeccd0.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
アイアンのアップデートから次のイテレーションを始めました。</font><font style="vertical-align: inherit;">5つのコーディネーターから3つのコーディネーターに切り替え、データノードを交換し、金額とストレージ容量の点で勝ちました。</font><font style="vertical-align: inherit;">ノードの場合、2つの構成を使用します。&nbsp;</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ホットノードの場合：E3-1270 v6 / 960Gb SSD / 32 Gb x 3 x 2（Hot1には3つ、Hot2には3つ）。</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ウォームノードの場合：E3-1230 v6 / 4Tb SSD / 32 Gb x 4。</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この反復で、フロントエンドのnginxログと同じ容量を占めるマイクロサービスアクセスログを含むインデックスを、3つのホットノードの2番目のグループに取り出しました。 「ホット」ノードにデータを20時間保存し、「ウォーム」に転送して他のログに保存します。&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
回転を再構成することにより、小さなインデックスの消失の問題を解決しました。とにかく、データがほとんどない場合でも、インデックスは23時間ごとにローテーションされます。これにより、シャードの数がわずかに増加しました（シャードは約800になりました）が、クラスターのパフォーマンスの観点からは許容できます。&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その結果、6つの「ホット」ノードと4つの「ウォーム」ノードのみがクラスターで判明しました。これにより、長い時間間隔で要求にわずかな遅延が発生しますが、将来的にノード数を増やすと、この問題が解決します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この反復では、半自動スケーリングの欠如の問題も修正されました。</font><font style="vertical-align: inherit;">これを行うために、インフラストラクチャノマドクラスターを展開しました。</font><font style="vertical-align: inherit;">Logstashの数は、負荷に応じて自動的に変化するわけではありませんが、これについては後で説明します。</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/5c5/331/493/5c533149373a09c73e329e3bb43e0d81.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">今後の計画</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
実装された構成はスケーラブルで、現在13.3 TBのデータを保存しています。すべてのログは4日間で、アラートの緊急分析に必要です。ログの一部をメトリックに変換し、それをGraphiteに追加します。エンジニアの作業を容易にするために、インフラストラクチャクラスタのメトリックと、典型的な問題を半自動的に修正するためのスクリプトを用意しています。来年に予定されているデータノードの数を増やした後、データストレージに4日から7日に移行します。私たちは常にできるだけ早くインシデントを調査しようとし、テレメトリデータは長期調査に利用できるため、これは運用作業には十分です。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2019年10月、cian.ruトラフィックは1か月あたり1530万のユニークユーザーに増加しました。これは、ログを配信するためのアーキテクチャソリューションの真剣なテストでした。&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
現在、ElasticSearchをバージョン7にアップグレードする準備をしています。ただし、バージョン5.5から移動し、バージョン6で非推奨と宣言された（バージョン7では単に存在しない）ため、ElasticSearchの多くのインデックスのマッピングを更新する必要があります。そしてこれは、更新の過程で、当面の間ログなしで私たちを残す何らかの不可抗力が確かに存在することを意味します。 7つのバージョンの中で、インターフェースの改善と新しいフィルターを備えたKibanaを楽しみにしています。&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私たちは主な目標を達成しました。ログの損失を防ぎ、インフラストラクチャクラスターのダウンタイムを週あたり2〜3ドロップから月あたり数時間のサービス作業に削減しました。</font><font style="vertical-align: inherit;">この制作作業はほとんど見えません。</font><font style="vertical-align: inherit;">しかし、サービスで何が起こっているのかを正確に判断できるようになったので、落ち着いたモードですばやく行うことができ、ログが失われる心配はありません。</font><font style="vertical-align: inherit;">概して、私たちは満足し、幸せで、新しい偉業の準備をしています。これについては後で説明します。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja478546/index.html">WebSocket 開発と運用の経験。クライアントを変更します</a></li>
<li><a href="../ja478550/index.html">時計の管理方法は？第2回プログラミングチャンピオンシップのフロントエンドトラックの分析</a></li>
<li><a href="../ja478552/index.html">2番目のアプレット、Processing 3で閉じ、透明なボタン</a></li>
<li><a href="../ja478554/index.html">ウェビナー「SRE-誇大宣伝か未来か？」12月12日11:00</a></li>
<li><a href="../ja478560/index.html">無料のインスタントメッセンジャーは匿名ですか？</a></li>
<li><a href="../ja478566/index.html">iOS アプリケーションが実行されていないときのネットワーク</a></li>
<li><a href="../ja478572/index.html">ニューラルネットワーク上のボット：仮想アシスタントのしくみと学習方法</a></li>
<li><a href="../ja478574/index.html">鉄道ブレーキの真実：パート4-乗客用ブレーキ</a></li>
<li><a href="../ja478580/index.html">スーパーニンテンドーグラフィックチップのしくみ：スーパーPPUガイド</a></li>
<li><a href="../ja478582/index.html">2019年のモバイルデバイスに関するグローバルVPNレポート</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äç‚úàÔ∏è üëäüèø ü•É Machine translate. From the cold war to the present üëº üßî üë®üèº‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Machine translation has become very widespread in recent years. Surely, most of my readers have used Google.Translate or Yandex.Translation services a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Machine translate. From the cold war to the present</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/huawei/blog/492702/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Machine translation has become very widespread in recent years. Surely, most of my readers have used Google.Translate or Yandex.Translation services at least once. It is also likely that many people remember that not so long ago, about 5 years ago, using automatic translators was very difficult. It is not easy in the sense that they gave out a translation of very poor quality. Under the cut is a brief and incomplete history of machine translation, from which it will be visible in this task and some of its causes and consequences. First, a picture that shows an important concept regarding machine translation:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/qy/un/kd/qyunkdtrk_fjfnil56xfgfinck8.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This concept is called the ‚Äúnoisy channel‚Äù concept and came from radio engineering. In different versions, it is attributed to various scientists, Nyquist, Kupfm√ºller, Shannon, but in this dispute I am rooting for our compatriot - Vladimir Alexandrovich Kotelnikov, who in his 1933 work proved his famous theorem. By itself, this theorem is outside the scope of this article, so I am sending those interested </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in Wikipedia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For us, something else is important. The concept of a noisy channel has been applied to a new direction - automatic machine translation. After the end of World War II, our overseas partners decided that the Soviet Union, which had shown its strength by defeating the best army in Europe and the world, posed a serious threat. Various actions were taken to stop this threat, including work on the automatic translation from Russian into English. This was necessary because the Soviet Union produced extremely much information - television programs, radio talks, books and magazines. And if we take into account the negotiations of our allies on the organization of the Warsaw Pact, then the scale of the problem was already simply frightening: it was not possible to train, and even more so maintain such an army of professional translators.And here the idea was born - let's say that the text in Russian is just a distorted text in English, and we will try algorithmically to restore the "source" text. This is exactly what was proposed by Warren Weaver in 1949.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conceptually, it looks beautiful, but the question is how to implement it. Strongly running ahead in time, this was realized on the basis of the so-called phrase translation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But let's go in order. What is the easiest way to translate to mind? Dictionary translation - that is, a ready-made dictionary is taken, and all words in the sentence are replaced with their equivalents in another language. This approach was proposed by the notorious IBM company </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in 1989.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. This approach has an obvious drawback: the word order in different languages ‚Äã‚Äãcan differ, and sometimes very much. The next step in this model is to allow permutation of words. And how can these permutations be predicted? In the same work, another model was proposed (if the first is called Model 1, then the second is called very logically Model 2). In this system, in addition to the dictionary, there is a so-called alignment model - correlation of words in two sentences with each other. Alignment is learned based on body statistics. The obvious drawback of this model is that it takes a lot of effort to prepare the case in which the alignment is done, professional translators must not only translate the text, but also indicate which word is which translation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It is worth noting that in addition to the different order of words, there is, for example, the problem that some words will be completely without translation (for example, articles do not exist in Russian), and some words will require more than one translation word (e.g. preposition + noun). IBM colleagues called this the fertility rate and built models for it also based on statistics. This is Model 3 (pretty predictable, isn't it?). In the same work, several more models are described, they develop the described ideas by adding conditions for predicting the translation of a word - for example, to the previous word, since some words are better combined with each other and therefore are more common. This entire group of models gave rise to the so-called phrase-based translation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This direction existed and developed, in particular, an open framework for machine translation </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Moses</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was developed </font><font style="vertical-align: inherit;">(on the official website you can see that it has somewhat fallen into decay). At one time, this was the main means of machine translation, although machine translation was not so common at that time. But in 2014 a terrible thing happened - deep learning reached the field of machine translation. If you remember a year earlier it got to vector representations of words, I described this article about </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">embeddings</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . And in 2014, an article was published by Dmitry Bogdanov (and co-authors, one of whom was the famous Yoshua Bengio) entitled </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neural Machine Translation by Jointly Learning to Align and Translate</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(or - neural machine translation through joint training of alignment and translation). In this work, Dmitry proposed the use of the attention mechanism for recurrent neural networks and with his help he was able to beat the aforementioned Moses by a significant amount. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here you need to digress and talk about how to measure the quality of machine translation. In the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">work of Papineni</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In 2002, the BLEU metric was proposed (bilingual evaluation understudy - study of bilingual comparison). This metric basically compares how many words from machine translation matched words from the human version. Then the word combinations of two words, three, four are compared. All these figures are averaged and exactly one figure is obtained that describes the quality of the machine translation system on this building. This metric has its drawbacks, for example, there may be different human options for translating one text, but surprisingly for almost 20 years, nothing better has been proposed for assessing the quality of a translation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But back to the attention mechanism. It should be said that recurrent networks were proposed 15 years earlier, and then did not create any furor. A significant problem with these networks was that they quickly forgot what they ‚Äúread‚Äù. Partially solve this problem for machine translation and the attention mechanism helped. Here it is in the picture: </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/630/fa6/ce7/630fa6ce7d6c5261a63ad7cb87d2743f.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What is he doing? It weighs the words in the input to give one word vector for translation. This is what made it possible to automatically build alignment matrices based on raw text without markup. For example, such:</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/8e6/667/390/8e666739035c8ae6e138704e130d2b16.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After everyone saw that it was possible, great efforts were devoted to machine translation, which became the fastest growing field of natural language processing. Significant quality improvements have been achieved, including for distant language pairs, such as English and Chinese or English and Russian. Recurrent networks ruled the ball for quite some time by modern standards - almost 4 years. But at the end of 2017, trumpets sounded announcing the approach of a new king of the mountain. It was an article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">called Attention is all you need</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (attention is all you need; a paraphrase of the name of the famous The Beatles song ‚ÄúAll you need is love‚Äù). This article presented the architecture of the transformer, which a little less than completely consisted of attention mechanisms. I talked more about her in an article on</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2017 results</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , so I won‚Äôt repeat myself. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since then, quite a lot of water has flowed, but nevertheless, much more remains. For example, two years ago, at the beginning of 2018, Microsoft researchers </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">announced the achievement of equality</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in quality with a human translation translated from English into Chinese news documents. This article has been criticized a lot, primarily from the standpoint that the achievement of equal numbers by BLEU is an indicator of the incomplete adequacy of the BLEU metric. But hype was generated.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Another interesting direction in the development of machine translation is machine translation without parallel data. As you remember, the use of neural networks allowed us to abandon the alignment markup in translated texts for teaching the machine translation model. The authors of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unsupervised Machine Translation Using Monolingual Corpora Only</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (a machine translation using only monolingual data) presented a system that with some quality was able to translate from English to French (the quality was, of course, lower than the best achievements of that time, but only by 10%) . Interestingly, the same authors </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">improved their approach</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> using phrasal translation ideas later that year.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, the last thing I would like to highlight is the so-called non-self-regressive translation. What it is? All models, starting with IBM Model 3, rely on previous words already translated when translating. And the authors of the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">work</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which is called non-self-regressive machine translation, tried to get rid of this dependence. The quality also turned out to be slightly less, but the speed of such a translation can be tens of times faster than for autoregressive models. Considering that modern models can be very large and slow, this is a significant gain, especially under heavy load.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It goes without saying that the region does not stand still and new ideas are being proposed, for example, the so-called back-translation, when the monolingual data translated by the model itself is used for further training; the use of convolution networks, which is also faster than the standard transformer these days; the use of pre-trained large language models (I have a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">separate article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> about them </font><font style="vertical-align: inherit;">). All, unfortunately, cannot be listed. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Our company has one of the leading scientists in the field of machine translation - Professor Qun Liu. Professor Liu and I are leading a course in natural language processing, in which substantial attention is paid specifically to machine translation. If you are interested in this area, then you can still </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">join our course</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which began a month ago.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And if you feel the strength in yourself, then we will be glad to see you among the participants in our competition to translate from Chinese to Russian! </font><font style="vertical-align: inherit;">The competition will begin on April 14 and will last exactly a month. </font><font style="vertical-align: inherit;">We hope that our participants will achieve new results in this task and will be able to advance the entire field of machine translation. </font><font style="vertical-align: inherit;">The competition will be held on the MLBootCamp platform, and we are very grateful to the MLBootCamp team and personally Dmitry Sannikov for their help in organizing. </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Competition Link</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en492684/index.html">Free proxy server for enterprise with domain authentication</a></li>
<li><a href="../en492686/index.html">When Linux conntrack is no longer your friend</a></li>
<li><a href="../en492694/index.html">Recipes for ailing SQL queries</a></li>
<li><a href="../en492696/index.html">On what to test algorithms for the recognition and processing of identity documents?</a></li>
<li><a href="../en492700/index.html">Internet declarative shopping with Payment Request API and Angular</a></li>
<li><a href="../en492704/index.html">To increase the effectiveness of implant survival by 5-7 times - how is this possible?</a></li>
<li><a href="../en492706/index.html">Memory archives: how the brain encodes and reproduces memories</a></li>
<li><a href="../en492708/index.html">Global satellite Internet - is there any news from the fields?</a></li>
<li><a href="../en492710/index.html">Thorny path of candidate through various HRM systems</a></li>
<li><a href="../en492712/index.html">Mastering development through testing in Android using UI tests</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
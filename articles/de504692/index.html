<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÉüèº üê´ üñêüèΩ ZFS-Grundlagen: Speicher und Leistung üëÅÔ∏è ‚ö†Ô∏è üéº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In diesem Fr√ºhjahr haben wir bereits einige einf√ºhrende Themen besprochen, z. B. wie Sie die Geschwindigkeit Ihrer Laufwerke √ºberpr√ºfen und was RAID i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ZFS-Grundlagen: Speicher und Leistung</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/504692/"><img src="https://habrastorage.org/getpro/habr/post_images/abf/883/e96/abf883e96b01dbc78420e0dc1a158460.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Fr√ºhjahr haben wir bereits einige einf√ºhrende Themen besprochen, z. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">B. wie Sie die Geschwindigkeit Ihrer Laufwerke √ºberpr√ºfen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">was RAID ist</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">In der zweiten haben wir sogar versprochen, die Leistung verschiedener Multi-Disk-Topologien in ZFS weiter zu untersuchen. </font><font style="vertical-align: inherit;">Dies ist das Dateisystem der n√§chsten Generation, das √ºberall implementiert wird: von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apple</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bis </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ubuntu</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, heute ist der beste Tag, um ZFS kennenzulernen, neugierige Leser. </font><font style="vertical-align: inherit;">Beachten Sie jedoch, dass es nach einer konservativen Einsch√§tzung des OpenZFS-Entwicklers Matt Arens "sehr kompliziert" ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber bevor wir zu den Zahlen kommen - und ich verspreche es -, m√ºssen Sie f√ºr alle Varianten der vosmidiskovoy ZFS-Konfiguration dar√ºber sprechen, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wie</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ZFS Daten auf der Festplatte speichert.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zpool, vdev und Ger√§t</font></font></h1><br>
<img src="https://habrastorage.org/getpro/habr/post_images/674/1c6/ab3/6741c6ab310f4e0edf2adf7e2ca4c6bb.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses vollst√§ndige Pooldiagramm enth√§lt drei Hilfs-VDEVs, einen f√ºr jede Klasse und vier f√ºr RAIDz2. Normalerweise </font></font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/b9f/82c/887/b9f82c88748c44d1f86cc412a053bf94.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gibt es keinen Grund, einen Pool unangemessener </font></font></font></i><font style="vertical-align: inherit;"><i><font color="gray"><font style="vertical-align: inherit;">VDEV- </font></font></i><i><font color="gray"><font style="vertical-align: inherit;">Typen und -Gr√∂√üen zu erstellen. Wenn Sie m√∂chten, hindert Sie nichts daran</font></font></i></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
, das ZFS-Dateisystem wirklich zu verstehen m√ºssen Sie sich die tats√§chliche Struktur genau ansehen. </font><font style="vertical-align: inherit;">Erstens kombiniert ZFS traditionelle Ebenen der Datentr√§gerverwaltung und das Dateisystem. </font><font style="vertical-align: inherit;">Zweitens wird beim Schreiben ein Transaktionskopiermechanismus verwendet. </font><font style="vertical-align: inherit;">Diese Merkmale bedeuten, dass sich das System strukturell stark von normalen Dateisystemen und RAID-Arrays unterscheidet. </font><font style="vertical-align: inherit;">Die ersten grundlegenden Bausteine, die zu verstehen sind: ein Speicherpool (zpool), ein virtuelles Ger√§t (vdev) und ein reales Ger√§t (Ger√§t).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zpool</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der zpool-Speicherpool ist die oberste ZFS-Struktur. Jeder Pool enth√§lt ein oder mehrere virtuelle Ger√§te. Jedes von ihnen enth√§lt wiederum ein oder mehrere reale Ger√§te (Ger√§te). Virtuelle Pools sind autonome Bl√∂cke. Ein physischer Computer kann zwei oder mehr separate Pools enthalten, aber jeder ist v√∂llig unabh√§ngig von den anderen. Pools k√∂nnen keine virtuellen Ger√§te gemeinsam nutzen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Redundanz von ZFS erfolgt auf der Ebene der virtuellen Ger√§te, jedoch nicht auf der Ebene der Pools. Auf Poolebene gibt es absolut keine Redundanz. Wenn ein vdev-Laufwerk oder ein spezielles vdev verloren geht, geht der gesamte Pool verloren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Moderne Speicherpools k√∂nnen den Verlust eines Cache- oder virtuellen Ger√§teprotokolls √ºberleben - obwohl sie eine kleine Menge schmutziger Daten verlieren k√∂nnen, wenn sie das vdev-Protokoll w√§hrend eines Stromausfalls oder eines Systemabsturzes verlieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt ein weit verbreitetes Missverst√§ndnis, dass ‚ÄûDatenb√§nder‚Äú (Streifen) von ZFS √ºber den gesamten Pool aufgezeichnet werden. Das ist nicht wahr. Zpool ist √ºberhaupt kein lustiges RAID0, sondern ein lustiges </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">JBOD</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mit einem komplexen ver√§nderbaren Verteilungsmechanismus.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Datens√§tze werden gr√∂√ütenteils entsprechend dem verf√ºgbaren Speicherplatz auf die verf√ºgbaren virtuellen Ger√§te verteilt, sodass sie theoretisch alle gleichzeitig gef√ºllt werden. In sp√§teren Versionen von ZFS wird die aktuelle Verwendung (Auslastung) von vdev ber√ºcksichtigt. Wenn ein virtuelles Ger√§t erheblich st√§rker als das andere geladen ist (z. B. aufgrund der Leselast), wird es trotz des h√∂chsten freien Speicherplatzkoeffizienten vor√ºbergehend zum Schreiben √ºbersprungen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein in moderne ZFS-Datensatzverteilungsmethoden integrierter Mechanismus zur Erkennung von Recycling kann die Latenz verringern und den Durchsatz in Zeiten ungew√∂hnlich hoher Last erh√∂hen - dies ist jedoch kein </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Freibrief</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unwillk√ºrliches Mischen langsamer Festplatten und schneller SSDs in einem Pool. </font><font style="vertical-align: inherit;">Solch ein ungleicher Pool arbeitet immer noch mit der Geschwindigkeit des langsamsten Ger√§ts, das hei√üt, als ob es vollst√§ndig aus solchen Ger√§ten zusammengesetzt w√§re.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vdev</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Speicherpool besteht aus einem oder mehreren virtuellen Ger√§ten (virtuelles Ger√§t, vdev). </font><font style="vertical-align: inherit;">Jedes vdev enth√§lt wiederum ein oder mehrere reale Ger√§te. </font><font style="vertical-align: inherit;">Die meisten virtuellen Ger√§te werden zum einfachen Speichern von Daten verwendet, es gibt jedoch mehrere vdev-Hilfsklassen, darunter CACHE, LOG und SPECIAL. </font><font style="vertical-align: inherit;">Jeder dieser vdev-Typen kann eine von f√ºnf Topologien haben: Einzelger√§t, RAIDz1, RAIDz2, RAIDz3 oder Spiegel.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
RAIDz1, RAIDz2 und RAIDz3 sind spezielle Variationen der sogenannten RAID-Doppelparit√§t (Diagonale). 1, 2 und 3 beziehen sich darauf, wie viele Parit√§tsbl√∂cke f√ºr jedes Datenband zugewiesen sind. Anstelle separater Festplatten f√ºr die Parit√§t verteilen virtuelle RAIDz-Ger√§te diese Parit√§t gleichm√§√üig auf die Festplatten. Ein RAIDz-Array kann so viele Festplatten verlieren, wie es Parit√§tsbl√∂cke enth√§lt. Wenn er einen anderen verliert, wird er scheitern und den Speicherpool mitnehmen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In gespiegelten virtuellen Ger√§ten (Spiegel vdev) wird jeder Block auf jedem Ger√§t in vdev gespeichert. Obwohl es sich um die g√§ngigsten Spiegel mit zwei Breiten handelt, kann sich eine beliebige Anzahl von Ger√§ten im Spiegel befinden. In gro√üen Installationen werden h√§ufig dreifache Ger√§te verwendet, um die Leseleistung und die Fehlertoleranz zu erh√∂hen. Der vdev-Spiegel kann jeden Fehler √ºberstehen, w√§hrend mindestens ein Ger√§t in vdev weiterhin funktioniert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einzelne vdevs sind von Natur aus gef√§hrlich. Ein solches virtuelles Ger√§t √ºberlebt einen einzelnen Fehler nicht - und wenn es als Speicher oder als spezielles vdev verwendet wird, f√ºhrt sein Ausfall zur Zerst√∂rung des gesamten Pools. Sei hier sehr, sehr vorsichtig.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Virtuelle CACHE-, LOG- und SPECIAL-Appliances k√∂nnen mit einer der oben genannten Topologien erstellt werden. Beachten Sie jedoch, dass der Verlust einer virtuellen SPECIAL-Appliance den Verlust eines Pools bedeutet. Daher wird eine √ºberm√§√üige Topologie dringend empfohlen.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ger√§t</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies ist wahrscheinlich der am einfachsten zu verstehende Begriff in ZFS - es handelt sich buchst√§blich um ein Block-Direktzugriffsger√§t. Denken Sie daran, dass virtuelle Ger√§te aus einzelnen Ger√§ten bestehen und der Pool aus virtuellen Ger√§ten besteht. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Festplatten - magnetisch oder Festk√∂rper - sind die am h√§ufigsten verwendeten Blockger√§te, die als vdev-Bausteine ‚Äã‚Äãverwendet werden. Es ist jedoch jedes Ger√§t mit einem Handle in / dev geeignet, sodass Sie ganze Hardware-RAID-Arrays als separate Ger√§te verwenden k√∂nnen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine einfache Rohdatei ist eines der wichtigsten alternativen Blockger√§te, aus denen vdev erstellt werden kann. Testen Sie Pools aus </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dateien mit geringer Dichte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&nbsp;- Eine sehr bequeme M√∂glichkeit, Poolbefehle zu √ºberpr√ºfen und festzustellen, wie viel Speicherplatz im Pool oder auf dem virtuellen Ger√§t dieser Topologie verf√ºgbar ist. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/5cf/aa5/62c/5cfaa562cb208b654af113f7535b8f57.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie k√∂nnen in wenigen Sekunden einen Testpool aus Dateien mit geringer Dichte erstellen. Vergessen Sie jedoch nicht, den gesamten Pool und seine Komponenten sp√§ter zu l√∂schen.</font></font></font></i> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Angenommen, Sie m√∂chten einen Server auf acht Festplatten installieren und planen, 10-TB-Festplatten (~ 9300 GiB) zu verwenden. Sie sind sich jedoch nicht sicher, welche Die Topologie entspricht am besten Ihren Anforderungen. Im obigen Beispiel erstellen wir in Sekundenschnelle einen Testpool aus Dateien mit geringer Dichte - und jetzt wissen wir, dass RAIDz2 vdev von acht 10-TB-Laufwerken eine n√ºtzliche Kapazit√§t von 50 TiB bietet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine weitere spezielle Ger√§teklasse ist SPARE (Ersatz). Hot-Swap-f√§hige Ger√§te geh√∂ren im Gegensatz zu herk√∂mmlichen Ger√§ten zum gesamten Pool und nicht nur zu einem virtuellen Ger√§t. Wenn ein vdev im Pool ausf√§llt und das Ersatzger√§t mit dem Pool verbunden und verf√ºgbar ist, wird es automatisch dem betroffenen vdev beitreten. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nach dem Herstellen einer Verbindung zum betroffenen vdev empf√§ngt das Ersatzger√§t Kopien oder die Rekonstruktion von Daten, die sich auf dem fehlenden Ger√§t befinden sollten. In herk√∂mmlichem RAID wird dies als Neuerstellung bezeichnet, w√§hrend es in ZFS als "Resilvering" bezeichnet wird.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es ist wichtig zu beachten, dass Ersatzger√§te ausgefallene Ger√§te nicht dauerhaft ersetzen. </font><font style="vertical-align: inherit;">Dies ist nur ein vor√ºbergehender Ersatz, um die Zeit zu verk√ºrzen, in der eine vdev-Verschlechterung beobachtet wird. </font><font style="vertical-align: inherit;">Nachdem der Administrator das ausgefallene vdev-Ger√§t ersetzt hat, wird die Redundanz auf diesem permanenten Ger√§t wiederhergestellt, und SPARE trennt sich von vdev und kehrt als Ersatz f√ºr den gesamten Pool zur√ºck.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datens√§tze, Bl√∂cke und Sektoren</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die n√§chsten Bausteine, die Sie auf unserer Reise durch ZFS verstehen m√ºssen, sind nicht so sehr die Hardware, sondern die Organisation und Speicherung der Daten. </font><font style="vertical-align: inherit;">Wir √ºberspringen hier mehrere Ebenen - wie z. B. Metaslab -, um die Details nicht zu h√§ufen und gleichzeitig das Verst√§ndnis der Gesamtstruktur zu bewahren.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Datensatz</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/bd3/c48/d9d/bd3c48d9dff6e0f493a5d90d1dca6d1d.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn wir zum ersten Mal ein Dataset erstellen, wird der gesamte verf√ºgbare Poolbereich angezeigt. Dann legen wir das Kontingent fest - und √§ndern den Einh√§ngepunkt. Magie! </font></font></font></i> <br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/a18/3de/210/a183de210cdc57cd1421652201cbf2c3.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zvol ist gr√∂√ütenteils nur ein Datensatz ohne Dateisystemschicht, den wir hier durch ein v√∂llig normales ext4-</font></font></font></i> <br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Dateisystem ersetzen. Der ZFS-Datensatz entspricht in etwa einem standardm√§√üig bereitgestellten Dateisystem. Wie ein normales Dateisystem scheint es auf den ersten Blick ‚Äûnur ein weiterer Ordner‚Äú zu sein. Wie bei herk√∂mmlichen gemounteten Dateisystemen verf√ºgt auch jedes ZFS-Dataset √ºber eigene grundlegende Eigenschaften.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zun√§chst kann einem Datensatz ein Kontingent zugewiesen werden. Wenn installiert</font></font><code>zfs set quota=100G poolname/datasetname</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, k√∂nnen Sie nicht</font></font><code>/poolname/datasetname</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mehr als 100 GiB</font><font style="vertical-align: inherit;">in den bereitgestellten Ordner schreiben</font><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beachten Sie das Vorhandensein - und Fehlen - von Schr√§gstrichen am Anfang jeder Zeile? Jeder Datensatz hat seinen eigenen Platz sowohl in der ZFS-Hierarchie als auch in der System-Mount-Hierarchie. In der ZFS-Hierarchie gibt es keinen f√ºhrenden Schr√§gstrich. Sie beginnen mit dem Namen des Pools und dann mit dem Pfad von einem Datensatz zum n√§chsten. Zum Beispiel </font></font><code>pool/parent/child</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f√ºr ein Dataset, das </font></font><code>child</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unter dem √ºbergeordneten Dataset </font></font><code>parent</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in einem Pool mit einem Creative-Namen benannt ist </font></font><code>pool</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Standardm√§√üig wird die Mount - </font><font style="vertical-align: inherit;">Punkt des Datensatz auf seinen Namen in der ZFS - </font><font style="vertical-align: inherit;">Hierarchie entspricht, mit einem Schr√§gstrich am Anfang - der Pool mit dem Namen wird </font></font><code>pool</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">montiert , </font><font style="vertical-align: inherit;">wie </font></font><code>/pool</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">der Datensatz wird </font></font><code>parent</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in montiert </font></font><code>/pool/parent</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, und der Kind - </font><font style="vertical-align: inherit;">Datensatz </font><font style="vertical-align: inherit;">wird montiert </font></font><code>child</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in </font></font><code>/pool/parent/child</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Der System-Mount-Punkt f√ºr das Dataset kann jedoch ge√§ndert werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn wir angeben</font></font><code>zfs set mountpoint=/lol pool/parent/child</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, dann wird der Datensatz </font></font><code>pool/parent/child</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">im System als gemountet </font></font><code>/lol</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zus√§tzlich zu Datens√§tzen sollten wir Volumes (zvols) erw√§hnen. </font><font style="vertical-align: inherit;">Ein Volume √§hnelt ungef√§hr einem Datensatz, au√üer dass es tats√§chlich kein Dateisystem hat - es ist nur ein Blockger√§t. </font><font style="vertical-align: inherit;">Sie k√∂nnen beispielsweise </font></font><code>zvol</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einen Namen </font><font style="vertical-align: inherit;">erstellen </font></font><code>mypool/myzvol</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, ihn dann mit dem ext4-Dateisystem formatieren und dann dieses Dateisystem bereitstellen - jetzt haben Sie das ext4-Dateisystem, aber mit Unterst√ºtzung f√ºr alle ZFS-Sicherheitsfunktionen! </font><font style="vertical-align: inherit;">Dies mag auf einem Computer albern erscheinen, ist jedoch als Backend beim Exportieren eines iSCSI-Ger√§ts viel sinnvoller.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bl√∂cke</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/74b/4dd/d00/74b4ddd009e67db1b1b6c4467bcf6fa3.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine Datei wird durch einen oder mehrere Bl√∂cke dargestellt. Jeder Block wird auf einem virtuellen Ger√§t gespeichert. Die Blockgr√∂√üe entspricht normalerweise dem Parameter </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recordsize</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , kann jedoch auf </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 ^ ashift</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> reduziert werden, </font><font style="vertical-align: inherit;">wenn sie Metadaten oder eine kleine Datei enth√§lt. </font></font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/8d1/7fd/ad2/8d17fdad2eda641c801e5e6a302f6e38.png"><br>
<i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir </font><font style="vertical-align: inherit;">scherzen </font><font style="vertical-align: inherit;">wirklich, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wirklich</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nicht √ºber den gro√üen Leistungsschaden, wenn Sie zu wenig Ashift installieren.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Im ZFS-Pool werden alle Daten, einschlie√ülich Metadaten, in Bl√∂cken gespeichert. Die maximale Blockgr√∂√üe f√ºr jeden Datensatz wird in der Eigenschaft</font></font><code>recordsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Datensatzgr√∂√üe) definiert. Die Gr√∂√üe des Datensatzes kann variieren, dies √§ndert jedoch nicht die Gr√∂√üe oder Position von Bl√∂cken, die bereits in das Dataset geschrieben wurden. Sie gelten nur f√ºr neue Bl√∂cke, w√§hrend sie geschrieben werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sofern nicht anders angegeben, betr√§gt die aktuelle Aufzeichnungsgr√∂√üe standardm√§√üig 128 KB. Dies ist eine Art schwieriger Kompromiss, bei dem die Leistung nicht ideal, aber in den meisten F√§llen nicht schrecklich ist. </font></font><code>Recordsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kann auf einen beliebigen Wert von 4K bis 1M eingestellt werden (mit zus√§tzlichen Einstellungen k√∂nnen </font></font><code>recordsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie noch mehr einstellen, dies ist jedoch selten eine gute Idee). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Block bezieht sich auf die Daten nur einer Datei. Sie k√∂nnen nicht zwei verschiedene Dateien in einem Block zusammenfassen. Jede Datei besteht je nach Gr√∂√üe aus einem oder mehreren Bl√∂cken. Wenn die Dateigr√∂√üe kleiner als die Datensatzgr√∂√üe ist, wird sie in einem kleineren Block gespeichert. Beispielsweise belegt ein Block mit einer 2-KiB-Datei nur einen 4-KiB-Sektor auf der Festplatte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn die Datei gro√ü genug ist und mehrere Bl√∂cke erfordert, haben alle Datens√§tze mit dieser Datei eine Gr√∂√üe</font></font><code>recordsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&nbsp;- einschlie√ülich des letzten Eintrags, von dem sich der gr√∂√üte Teil als </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ungenutzter Speicherplatz</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> herausstellen </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">kann</font></a><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zvol-Volumes haben keine Eigenschaft, </font></font><code>recordsize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&nbsp;sondern eine entsprechende Eigenschaft </font></font><code>volblocksize</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sektoren</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der letzte, grundlegendste Baustein ist der Sektor. Dies ist die kleinste physische Einheit, die in die Basiseinheit geschrieben oder von dieser gelesen werden kann. Mehrere Jahrzehnte lang verwendeten die meisten Festplatten 512-Byte-Sektoren. In letzter Zeit sind die meisten Laufwerke f√ºr 4-KiB-Sektoren und in einigen - insbesondere SSDs - 8-KiB-Sektoren oder sogar mehr konfiguriert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ZFS verf√ºgt √ºber eine Eigenschaft, mit der Sie die Sektorgr√∂√üe manuell festlegen k√∂nnen. Dies ist eine Eigenschaft </font></font><code>ashift</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Es ist etwas verwirrend, dass Ashift eine Zweierpotenz ist. Zum Beispiel </font></font><code>ashift=9</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bedeutet dies eine Sektorgr√∂√üe von 2 ^ 9 oder 512 Bytes.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ZFS fragt das Betriebssystem nach detaillierten Informationen zu jedem Blockger√§t, wenn es dem neuen vdev hinzugef√ºgt wird, und stellt die Verschiebung basierend auf diesen Informationen theoretisch automatisch richtig ein. Leider l√ºgen viele Festplatten √ºber ihre Sektorgr√∂√üe, um die Kompatibilit√§t mit Windows XP aufrechtzuerhalten (das Festplatten mit anderen Sektorgr√∂√üen nicht verstehen konnte). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies bedeutet, dass dem ZFS-Administrator dringend empfohlen wird, die tats√§chliche Sektorgr√∂√üe seiner Ger√§te zu kennen und manuell zu installieren</font></font><code>ashift</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wenn eine zu kleine Verschiebung eingestellt ist, nimmt die Anzahl der Lese- / Schreibvorg√§nge astronomisch zu. Das Schreiben von 512-Byte-Sektoren in den realen 4-KiB-Sektor bedeutet also, den ersten ‚ÄûSektor‚Äú zu schreiben, dann den 4-KiB-Sektor zu lesen, ihn durch den zweiten 512-Byte-Sektor zu √§ndern, ihn in den neuen 4-KiB-Sektor zur√ºckzuschreiben und so weiter f√ºr jeden Eintrag. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In der realen Welt schl√§gt eine solche Strafe Samsung EVO- </font></font><code>ashift=13</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SSDs </font><font style="vertical-align: inherit;">, f√ºr die sie handeln muss </font><font style="vertical-align: inherit;">, aber diese SSDs liegen in Bezug auf ihre Sektorgr√∂√üe und sind daher standardm√§√üig festgelegt </font></font><code>ashift=9</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wenn ein erfahrener Systemadministrator diese Einstellung nicht √§ndert, ist diese SSD </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">langsamer als eine</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> normale magnetische Festplatte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Vergleich f√ºr eine zu gro√üe Gr√∂√üe</font></font><code>ashift</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gibt praktisch keine Strafe. </font><font style="vertical-align: inherit;">Es gibt keine wirkliche Abnahme der Produktivit√§t, und die Zunahme des nicht genutzten Speicherplatzes ist unendlich gering (oder gleich Null bei aktivierter Komprimierung). </font><font style="vertical-align: inherit;">Wir empfehlen daher dringend, auch Laufwerke zu installieren, die wirklich 512-Byte-Sektoren verwenden, </font></font><code>ashift=12</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">oder sogar </font></font><code>ashift=13</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sicher in die Zukunft zu schauen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Eigenschaft wird </font></font><code>ashift</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f√ºr jedes virtuelle vdev-Ger√§t festgelegt und </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nicht f√ºr den Pool</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , wie viele f√§lschlicherweise denken - und √§ndert sich nach der Installation nicht. </font><font style="vertical-align: inherit;">Wenn Sie </font></font><code>ashift</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">beim Hinzuf√ºgen eines neuen vdev zum Pool </font><font style="vertical-align: inherit;">versehentlich heruntergefahren wurden </font><font style="vertical-align: inherit;">, haben Sie diesen Pool unwiderruflich mit einem Ger√§t mit geringer Leistung kontaminiert. In der Regel gibt es keine andere M√∂glichkeit, als den Pool zu zerst√∂ren und von vorne zu beginnen. </font><font style="vertical-align: inherit;">Selbst das Entfernen von vdev rettet Sie nicht vor einem fehlerhaften Setup</font></font><code>ashift</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">!</font></font><br>
<br>
<h3>   </h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/38b/a1e/4a8/38ba1e4a8fa0e255081ed8db259a302f.gif"><br>
<i><font color="gray">      &nbsp;‚Äî     ,   </font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/90d/4cb/a35/90d4cba35ffa5a3e44a7ca5f61d4491b.gif"><br>
<i><font color="gray">         ,     </font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/c8b/2af/ffb/c8b2afffbc46f63f6a7fe1167edf5dcb.gif"><br>
<i><font color="gray">  ,      ,   ¬´ ¬ª   ¬´ ¬ª,        </font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/4c1/e2b/818/4c1e2b818077cb07d651527e214363fe.gif"><br>
<i><font color="gray">     ,       ‚Äî      ,     ,       </font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Copy on Write (CoW) ist die grundlegende Grundlage daf√ºr, was ZFS so gro√üartig macht. Das Grundkonzept ist einfach: Wenn Sie das herk√∂mmliche Dateisystem bitten, die Datei zu √§ndern, wird es genau das tun, was Sie angefordert haben. Wenn Sie das Dateisystem mit dem Kopieren w√§hrend der Aufnahme auffordern, dasselbe zu tun, wird "gut" angezeigt - aber es wird Sie anl√ºgen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Stattdessen schreibt das Copy-Write-Dateisystem die neue Version des ge√§nderten Blocks und aktualisiert dann die Dateimetadaten, um die Verbindung zum alten Block zu trennen und den neuen Block zuzuordnen, den Sie gerade geschrieben haben.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Trennen des alten Ger√§ts und das Verbinden des neuen Ger√§ts erfolgt in einem Arbeitsgang, sodass es nicht unterbrochen werden kann. Wenn Sie danach die Stromversorgung zur√ºcksetzen, haben Sie eine neue Version der Datei. Wenn Sie die Stromversorgung fr√ºher zur√ºcksetzen, haben Sie die alte Version. </font><font style="vertical-align: inherit;">In jedem Fall liegt kein Konflikt im Dateisystem vor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Kopieren beim Schreiben in ZFS erfolgt nicht nur auf Dateisystemebene, sondern auch auf Datentr√§gerverwaltungsebene. </font><font style="vertical-align: inherit;">Dies bedeutet, dass ZFS keinem Leerzeichen im Datensatz unterliegt (einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Loch im RAID</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) - ein Ph√§nomen, bei dem der Strip vor dem Systemabsturz nur teilweise aufzeichnen konnte und das Array nach einem Neustart besch√§digt wurde. </font><font style="vertical-align: inherit;">Hier ist der Streifen atomar, vdev ist immer konsistent und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bob ist dein Onkel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ZIL: ZFS-Absichtsprotokoll</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/567/71c/73f/56771c73f9a28ebaed161e02313deadb.png"><br>
<i><font color="gray"> ZFS     &nbsp;‚Äî  ,      ZIL,            </font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/cec/7c5/437/cec7c5437087f6816f9cdea5f6829820.png"><br>
<i><font color="gray"> ,   ZIL,    .      </font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/075/65a/d6b/07565ad6b2f431db3e6bc20cd24a653b.png"><br>
<i><font color="gray">SLOG,   LOG-, ‚Äî   &nbsp;‚Äî , ,  &nbsp;‚Äî&nbsp;vdev,  ZIL      </font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/927/0f7/539/9270f7539b759aa37896d41e04c4ec47.png"><br>
<i><font color="gray">      ZIL &nbsp;‚Äî    ZIL   SLOG,      </font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt zwei Hauptkategorien von Schreibvorg√§ngen - synchron (synchron) und asynchron (asynchron). Bei den meisten Workloads ist die √ºberwiegende Mehrheit der Schreibvorg√§nge asynchron. Mit dem Dateisystem k√∂nnen Sie sie aggregieren und stapelweise bereitstellen, wodurch die Fragmentierung verringert und der Durchsatz erheblich erh√∂ht wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Synchrone Aufnahmen sind eine ganz andere Sache. Wenn eine Anwendung ein synchrones Schreiben anfordert, teilt sie dem Dateisystem mit: "Sie m√ºssen dies </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jetzt in den</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> nichtfl√ºchtigen Speicher √ºbertragen </font><font style="vertical-align: inherit;">, und bis dahin kann ich nichts mehr tun." Daher sollten synchrone Aufzeichnungen sofort auf die Festplatte √ºbertragen werden - und wenn dies die Fragmentierung erh√∂ht oder die Bandbreite verringert, ist dies auch der Fall.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ZFS verarbeitet synchrone Datens√§tze anders als normale Dateisysteme. Anstatt sie sofort in den regul√§ren Speicher hochzuladen, zeichnet ZFS sie in einem speziellen Speicherbereich auf, der als ZFS-Absichtsprotokoll - ZFS-Absichtsprotokoll oder ZIL - bezeichnet wird. Der Trick besteht darin, dass diese Datens√§tze </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auch</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> im Speicher verbleiben und zusammen mit regul√§ren asynchronen Schreibanforderungen aggregiert werden, um sp√§ter als ganz normale TXGs (Transaktionsgruppen, Transaktionsgruppen) gespeichert zu werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Normalbetrieb wird ZIL aufgezeichnet und nie wieder gelesen. Wenn nach einigen Augenblicken Aufzeichnungen von ZIL im Hauptspeicher in normalem TXG aus dem RAM fixiert werden, werden sie von ZIL getrennt. Das einzige, was aus ZIL gelesen wird, ist das Importieren des Pools.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn ZFS abst√ºrzt - Betriebssystemabst√ºrze oder Stromausf√§lle -, wenn Daten in ZIL vorhanden sind, werden diese Daten beim n√§chsten Poolimport gelesen (z. B. beim Neustart des Notfallsystems). Alles, was sich in der ZIL befindet, wird gelesen, in TXG-Gruppen zusammengefasst, in den Hauptspeicher √ºbernommen und dann w√§hrend des Importvorgangs von der ZIL getrennt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine der vdev-Hilfsklassen hei√üt LOG oder SLOG, das sekund√§re LOG-Ger√§t. Er hat eine Aufgabe - dem Pool ein separates und vorzugsweise viel schnelleres vdev-Ger√§t mit sehr hohem Schreibwiderstand zum Speichern von ZIL zur Verf√ºgung zu stellen, anstatt ZIL im vdev-Hauptspeicher zu speichern. ZIL selbst verh√§lt sich unabh√§ngig vom Speicherort gleich. Wenn jedoch vdev mit LOG eine sehr hohe Schreibleistung aufweist, sind synchrone Schreibvorg√§nge schneller.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Hinzuf√ºgen von vdev mit LOG zum Pool </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kann</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die asynchrone Schreibleistung </font><b><font style="vertical-align: inherit;">nicht</font></b><font style="vertical-align: inherit;"> verbessern. Selbst wenn Sie alle Schreibvorg√§nge in ZIL erzwingen </font></font><code>zfs set sync=always</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, werden sie auf dieselbe Weise und im gleichen Tempo wie ohne Protokoll an das Hauptrepository in TXG gebunden. </font><font style="vertical-align: inherit;">Die einzige direkte Leistungsverbesserung ist die Verz√∂gerung bei der synchronen Aufzeichnung (da eine h√∂here Protokollgeschwindigkeit den Betrieb beschleunigt </font></font><code>sync</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einer Umgebung, in der bereits eine gro√üe Anzahl synchroner Schreibvorg√§nge erforderlich ist, kann vdev LOG jedoch indirekt asynchrone Schreibvorg√§nge und nicht zwischengespeicherte Lesevorg√§nge beschleunigen. </font><font style="vertical-align: inherit;">Das Hochladen von ZIL-Datens√§tzen in ein separates vdev-LOG bedeutet weniger Konkurrenz f√ºr IOPS im Prim√§rspeicher, was die Leistung aller Lese- und Schreibvorg√§nge in gewissem Ma√üe verbessert.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schnappsch√ºsse</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Schreibkopiermechanismus ist auch eine wesentliche Grundlage f√ºr atomare ZFS-Snapshots und inkrementelle asynchrone Replikation. </font><font style="vertical-align: inherit;">Das aktive Dateisystem verf√ºgt √ºber einen Zeigerbaum, der alle Datens√§tze mit aktuellen Daten markiert. Wenn Sie einen Snapshot erstellen, erstellen Sie einfach eine Kopie dieses Zeigerbaums. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn ein Datensatz im aktiven Dateisystem √ºberschrieben wird, schreibt ZFS zuerst die neue Version des Blocks in den nicht verwendeten Speicherplatz. </font><font style="vertical-align: inherit;">Anschlie√üend wird die alte Version des Blocks vom aktuellen Dateisystem getrennt. </font><font style="vertical-align: inherit;">Wenn sich ein Schnappschuss jedoch auf den alten Block bezieht, bleibt er unver√§ndert. </font><font style="vertical-align: inherit;">Der alte Block wird erst dann als freier Speicherplatz wiederhergestellt, wenn alle Snapshots, die mit diesem Block verkn√ºpft sind, zerst√∂rt wurden!</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reproduzieren</font></font></h3><br>
<img src="https://habrastorage.org/getpro/habr/post_images/e69/167/01d/e6916701d4aa3ff27bb42efc43be60da.png"><br>
<i><font color="gray">  Steam  2015   158&nbsp;   126&nbsp;927 .        rsync&nbsp;‚Äî  ZFS    ¬´ ¬ª  750% .</font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/25f/376/0ab/25f3760ab64d6647571b9c02804b39f0.png"><br>
<i><font color="gray">      40-     Windows 7&nbsp;‚Äî   .  ZFS   289  ,  rsync&nbsp;‚Äî  ¬´¬ª  161  ,    ,   rsync   --inplace.</font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/776/46b/a3a/77646ba3ac20eeb0933d7dc7d644296c.png"><br>
<i><font color="gray">    ,  rsync    .  1,9         &nbsp;‚Äî    ,   ZFS   1148  ,  rsync,    rsync --inplace</font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sobald Sie die Funktionsweise von Snapshots verstanden haben, k√∂nnen Sie die Essenz der Replikation leicht erfassen. Da ein Snapshot nur ein Baum von Zeigern auf Datens√§tze ist, </font></font><code>zfs send</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">senden wir diesen Baum und alle damit verbundenen Datens√§tze </font><font style="vertical-align: inherit;">, wenn wir einen </font><font style="vertical-align: inherit;">Snapshot erstellen. Wenn wir dies passieren </font></font><code>zfs send</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in </font></font><code>zfs receive</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auf das Zielobjekt, schreibt sie sowohl den eigentlichen Inhalt des Blocks und den Baum von Zeigern, die die Bl√∂cke auf den Zieldatensatz verweisen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im zweiten wird alles noch interessanter </font></font><code>zfs send</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Jetzt haben wir zwei Systeme, von denen jedes enth√§lt </font></font><code>poolname/datasetname@1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, und Sie schie√üen einen neuen Schnappschuss </font></font><code>poolname/datasetname@2</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Daher haben Sie im Quellpool </font></font><code>datasetname@1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und </font></font><code>datasetname@2</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und im Zielpool bisher nur den ersten Snapshot </font></font><code>datasetname@1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Da haben wir einen gemeinsamen Schnappschuss zwischen der Quelle und dem Ziel</font></font><code>datasetname@1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k√∂nnen wir </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">inkrementell</font></font></i> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tun </font></font><code>zfs send</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wenn wir dem System mitteilen </font></font><code>zfs send -i poolname/datasetname@1 poolname/datasetname@2</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, werden zwei Zeigerb√§ume verglichen. Alle Zeiger, die nur in vorhanden </font></font><code>@2</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sind, beziehen sich offensichtlich auf neue Bl√∂cke - daher ben√∂tigen wir den Inhalt dieser Bl√∂cke. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Auf einem Remote-System ist die inkrementelle Verarbeitung </font></font><code>send</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">genauso einfach. Zuerst zeichnen wir alle neuen Eintr√§ge auf, die im Stream enthalten sind </font></font><code>send</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, und f√ºgen dann Zeiger zu diesen Bl√∂cken hinzu. Voila, in unserem </font></font><code>@2</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">neuen System! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die asynchrone inkrementelle ZFS-Replikation ist eine enorme Verbesserung gegen√ºber fr√ºheren Nicht-Snapshot-Methoden wie rsync. In beiden F√§llen werden nur ge√§nderte Daten √ºbertragen - rsync muss jedoch zuerst </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gelesen werden</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von der Festplatte alle Daten auf beiden Seiten, um die Menge zu √ºberpr√ºfen und zu vergleichen. </font><font style="vertical-align: inherit;">Im Gegensatz dazu liest die ZFS-Replikation nur Zeigerb√§ume - und alle Bl√∂cke, die im allgemeinen Snapshot nicht dargestellt sind.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inline-Komprimierung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Copy-on-Write-Mechanismus vereinfacht auch das integrierte Komprimierungssystem. In einem herk√∂mmlichen Dateisystem ist die Komprimierung problematisch - sowohl die alte als auch die neue Version der ge√§nderten Daten befinden sich im selben Bereich. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Sie ein Datenelement in der Mitte einer Datei betrachten, das sein Leben als Megabyte von Nullen ab 0x00000000 usw. beginnt, ist es sehr einfach, es auf einen Sektor auf der Festplatte zu komprimieren. Aber was passiert, wenn wir dieses Megabyte Nullen durch ein Megabyte inkompressibler Daten wie JPEG oder pseudozuf√§lliges Rauschen ersetzen? Pl√∂tzlich ben√∂tigt dieses Megabyte an Daten nicht einen, sondern 256 Sektoren mit 4 KB, und an dieser Stelle auf der Festplatte ist nur ein Sektor reserviert.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ZFS hat kein solches Problem, da ge√§nderte Datens√§tze immer in nicht verwendeten Speicherplatz geschrieben werden - der urspr√ºngliche Block belegt nur einen 4-KiB-Sektor, und ein neuer Datensatz ben√∂tigt 256, dies ist jedoch kein Problem - ein k√ºrzlich ge√§ndertes Fragment aus der Mitte der Datei w√ºrde in nicht verwendeten Speicherplatz geschrieben Unabh√§ngig davon, ob sich die Gr√∂√üe ge√§ndert hat oder nicht, ist dies f√ºr ZFS eine normale Situation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die integrierte ZFS-Komprimierung ist standardm√§√üig deaktiviert und das System bietet Plug-In-Algorithmen - darunter LZ4, gzip (1-9), LZJB und ZLE.</font></font><br>
<br>
<ul>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LZ4</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ist ein Streaming-Algorithmus, der f√ºr die meisten Anwendungsf√§lle extrem schnelle Komprimierung und Dekomprimierung sowie Leistungssteigerungen bietet - selbst auf relativ langsamen CPUs.</font></font><br>
</li>
<li><b>GZIP</b> ‚Äî  ,       Unix-.        1-9,       CPU      9.       (   )  ,    &nbsp;   c CPU&nbsp;‚Äî    ,     .<br>
</li>
<li><b>LZJB</b> ‚Äî    ZFS.       , LZ4     .<br>
</li>
<li><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ZLE</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Zero Level Coding, Zero Level Coding. </font><font style="vertical-align: inherit;">Es ber√ºhrt √ºberhaupt keine normalen Daten, komprimiert jedoch gro√üe Folgen von Nullen. </font><font style="vertical-align: inherit;">N√ºtzlich f√ºr vollst√§ndig inkompressible Datens√§tze (z. B. JPEG, MP4 oder andere bereits komprimierte Formate), da inkompressible Daten ignoriert werden, jedoch nicht verwendeter Speicherplatz in den resultierenden Datens√§tzen komprimiert wird.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir empfehlen die LZ4-Komprimierung f√ºr fast alle Anwendungsf√§lle. </font><font style="vertical-align: inherit;">Die Leistungseinbu√üe f√ºr inkompressible Daten zu </font><font style="vertical-align: inherit;">begegnen ist sehr klein, und die </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Leistungsverst√§rkung</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr typische Daten ist signifikant. </font><font style="vertical-align: inherit;">Das Kopieren eines Images einer virtuellen Maschine f√ºr eine Neuinstallation des Windows-Betriebssystems (frisch installiertes Betriebssystem, noch keine Daten darin) </font><font style="vertical-align: inherit;">wurde in </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">diesem Test 2015</font></a></font><code>compression=lz4</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 27% schneller als mit </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">bestanden</font></a><font style="vertical-align: inherit;"> .</font></font><code>compression=none</code><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ARC - adaptiver Ersatzcache</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ZFS ist das einzige uns bekannte moderne Dateisystem, das einen eigenen Lese-Caching-Mechanismus verwendet und nicht auf den Seiten-Cache des Betriebssystems angewiesen ist, um Kopien k√ºrzlich gelesener Bl√∂cke im RAM zu speichern. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obwohl der eigene Cache nicht ohne Probleme ist, kann ZFS nicht so schnell wie der Kernel auf neue Speicherzuweisungsanforderungen reagieren, sodass ein neuer </font></font><code>malloc()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Speicherzuweisungsaufruf m√∂glicherweise fehlschl√§gt, wenn RAM ben√∂tigt wird, das derzeit von ARC belegt ist. </font><font style="vertical-align: inherit;">Aber es gibt gute Gr√ºnde, zumindest vorerst einen eigenen Cache zu verwenden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alle bekannten modernen Betriebssysteme, einschlie√ülich MacOS, Windows, Linux und BSD, verwenden den LRU-Algorithmus (Least Recent Used), um den Seitencache zu implementieren. Dies ist ein primitiver Algorithmus, der den zwischengespeicherten Block nach jedem Lesen in die Warteschlange stellt und die Bl√∂cke in der Warteschlange nach Bedarf verschiebt, um neue Cache-Fehler (Bl√∂cke, die von der Festplatte und nicht vom Cache gelesen werden sollten) hinzuzuf√ºgen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Normalerweise funktioniert der Algorithmus einwandfrei, aber auf Systemen mit gro√üen Arbeitsdatens√§tzen f√ºhrt LRU leicht zu Thrashing - Verdr√§ngung h√§ufig ben√∂tigter Bl√∂cke, um Platz f√ºr Bl√∂cke zu schaffen, die nie wieder aus dem Cache gelesen werden. </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BOGEN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&nbsp;- ein viel weniger naiver Algorithmus, der als "gewichteter" Cache betrachtet werden kann. Nach jedem Lesen des zwischengespeicherten Blocks wird es etwas ‚Äûschwerer‚Äú und es wird schwieriger, sich zu verdr√§ngen - und selbst nach dem Verdr√§ngen wird der Block </font><font style="vertical-align: inherit;">f√ºr einen bestimmten Zeitraum </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verfolgt</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ein Block, der herausgedr√ºckt wurde, dann aber in den Cache zur√ºckgelesen werden muss, wird ebenfalls "schwerer".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Endergebnis all dessen ist ein Cache mit einer viel gr√∂√üeren Trefferquote - dem Verh√§ltnis zwischen Treffern im Cache (aus dem Cache gelesen) und Fehlern (von der Festplatte gelesen). </font><font style="vertical-align: inherit;">Dies ist eine √§u√üerst wichtige Statistik. Der Cache trifft nicht nur selbst Service-Gr√∂√üenordnungen schneller, Cache-Misses k√∂nnen auch schneller bedient werden. Je mehr Cache-Hits, desto weniger gleichzeitige Festplattenanforderungen und desto geringer die Verz√∂gerung f√ºr die verbleibenden Misses, die bedient werden sollen Fahrt.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fazit</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir uns mit der grundlegenden Semantik von ZFS befasst haben - wie das Kopieren beim Schreiben funktioniert - sowie mit den Beziehungen zwischen Speicherpools, virtuellen Ger√§ten, Bl√∂cken, Sektoren und Dateien, k√∂nnen wir die tats√§chliche Leistung mit realen Zahlen diskutieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im n√§chsten Teil werden wir die tats√§chliche Leistung von Pools mit gespiegeltem vdev und RAIDz im Vergleich untereinander sowie im Vergleich zu herk√∂mmlichen Linux-Kernel-RAID-Topologien untersuchen, die wir </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zuvor</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> untersucht </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">haben</font></a><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zuerst wollten wir nur die Grundlagen betrachten - die ZFS - </font><font style="vertical-align: inherit;">Topologien selbst - aber nach </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dieser</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> werden wir bereit sein , </font><font style="vertical-align: inherit;">√ºber Fortgeschrittene ZFS - </font><font style="vertical-align: inherit;">Tuning und Tuning zu sprechen, einschlie√ülich der Verwendung von Hilfs vdev Typen wie L2ARC, SLOG und Sonder Allocation.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de504680/index.html">√úbersicht √ºber die NLP-Bibliothek von SpaL</a></li>
<li><a href="../de504682/index.html">Nostalgie Post: j2me, Schwerkraft trotzt, 64kb</a></li>
<li><a href="../de504686/index.html">Wie zeichnet man eine Katze?</a></li>
<li><a href="../de504688/index.html">Masken sind nutzlos: wissenschaftliche Kritik an der Sozialpolitik bei KOVID-19</a></li>
<li><a href="../de504690/index.html">Die Geschichte, wie ich Azure AD B2C f√ºr React and React Native konfiguriert habe Teil 3 (Tutorial)</a></li>
<li><a href="../de504694/index.html">So kompilieren Sie einen Dekorator - C ++, Python und seine eigene Implementierung. Teil 1</a></li>
<li><a href="../de504696/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 513 (12.05.2020-18.05.2020)</a></li>
<li><a href="../de504698/index.html">Onboarding an einem Remote-Standort</a></li>
<li><a href="../de504700/index.html">Sowjetische Grafiktafel "Skizze"</a></li>
<li><a href="../de504702/index.html">Die Leute wollen kein Englisch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
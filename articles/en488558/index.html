<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õîÔ∏è üë©üèæ‚Äçüè´ üë®‚Äçüíº Ensuring high availability of applications with Kafka Streams üêô üåò üíΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kafka Streams is a Java library for analyzing and processing data stored in Apache Kafka. As with any other streaming processing platform, it is capab...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Ensuring high availability of applications with Kafka Streams</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488558/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams is a Java library for analyzing and processing data stored in Apache Kafka. </font><font style="vertical-align: inherit;">As with any other streaming processing platform, it is capable of performing data processing with and / or without state preservation in real time. </font><font style="vertical-align: inherit;">In this post I will try to describe why achieving high availability (99.99%) is problematic in Kafka Streams and what we can do to achieve it.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What do we need to know</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Before describing the problem and possible solutions, let's look at the basic concepts of Kafka Streams. </font><font style="vertical-align: inherit;">If you have worked with Kafka APIs for Consumers / Producers, then most of these paradigms are familiar to you. </font><font style="vertical-align: inherit;">In the following sections, I will try to describe in a few words the storage of data in partitions, the rebalancing of consumer groups and how the basic concepts of Kafka clients fit into the Kafka Streams library.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Partitioning Data</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the Kafka world, producer applications send data as key-value pairs to a specific topic. </font><font style="vertical-align: inherit;">The topic itself is divided into one or more partitions in Kafka brokers. </font><font style="vertical-align: inherit;">Kafka uses a message key to indicate in which partition the data should be written. </font><font style="vertical-align: inherit;">Consequently, messages with the same key always end up in the same partition.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Consumer applications are organized into consumer groups, and each group can have one or more instances of consumers. </font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Each instance of a consumer in the consumer group is responsible for processing data from a unique set of partitions of the input topic.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Consumer instances are essentially a means of scaling up processing in your group of consumers.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka: Rebalancing Consumer Group</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As we said earlier, each instance of the consumer group receives a set of unique partitions from which it consumes data. </font><font style="vertical-align: inherit;">Whenever a new consumer joins a group, rebalancing must take place so that he gets a partition. </font><font style="vertical-align: inherit;">The same thing happens when the consumer dies, the rest of the consumer should take his partitions to ensure that all partitions are processed.</font></font><br>
<cut></cut><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the beginning of this post we got acquainted with the fact that the Kafka Streams library is built on the basis of APIs of producers and consumers and the data processing is organized in the same way as the standard solution on Kafka. In the Kafka Streams configuration, the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> field is </font><font style="vertical-align: inherit;">equivalent to </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">group.id</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in the consumer API. Kafka Streams pre-creates a certain number of threads and each of them performs data processing from one or more partitions of input topics. Speaking in the terminology of the Consumer API, streams essentially coincide with instances of Consumer from the same group. Threads are the main way to scale data processing in Kafka Streams, this can be done vertically by increasing the number of threads for each Kafka Streams application on one machine, or horizontally by adding an additional machine with the same application.id. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bb7/bd3/8ed/bb7bd38edd33f26a146c12a1dea385b5.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kafka.apache.org/21/documentation/streams/architecture</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are many more elements in Kafka Streams, such as tasks, processing topology, threading model, etc., which we will not discuss in this post. </font><font style="vertical-align: inherit;">More information can be found </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here.</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams: State Storage</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In stream processing, there are operations with and without state preservation. </font><font style="vertical-align: inherit;">The state is what allows the application to remember the necessary information that goes beyond the scope of the record currently being processed.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
State operations, such as count, any type of aggregation, joins, etc., are much more complicated. This is due to the fact that having only one record, you cannot determine the last state (say, count) for a given key, so you need to store the state of your stream in your application. As we discussed earlier, each thread processes a set of unique partitions; therefore, a thread processes only a subset of the entire data set. This means that each Kafka Streams application thread with the same application.id maintains its own isolated state. We won‚Äôt go into details about how the state is formed in Kafka Streams, but it‚Äôs important to understand that the state is restored using the change-log topic and is saved not only on the local disk, but also in Kafka Broker.Saving the state changes log in Kafka Broker as a separate topic is made not only for fault tolerance, but also so that you can easily deploy new instances of Kafka Streams with the same application.id. Since the state is stored as a change-log topic on the broker's side, a new instance can load its own state from this topic.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
More information about state storage can be found </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Why is high availability problematic with Kafka Streams?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We reviewed the basic concepts and principles of data processing with Kafka Streams. </font><font style="vertical-align: inherit;">Now let's try to combine all the parts together and analyze why achieving high availability can be problematic. </font><font style="vertical-align: inherit;">From the previous sections, we must remember:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The data in the Kafka topic is divided into partitions, which are distributed between the Kafka Streams streams.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kafka Streams applications with the same application.id are, in fact, one group of consumers, and each of its threads is a separate isolated instance of the consumer.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> For state operations, the thread maintains its own state, which is ‚Äúreserved‚Äù by the Kafka topic in the form of a change log.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br>
<h2>TransferWise SPaaS (Stream Processing as a Service)</h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Before highlighting the essence of this post, let me first tell you what we created in TransferWise and why high availability is very important to us. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In TransferWise, we have several nodes for streaming processing, and each node contains several instances of Kafka Streams for each product team. Kafka Streams instances that are designed for a specific development team have a special application.id and usually have more than 5 threads. In general, teams typically have 10-20 threads (equivalent to the number of instances of consumers) throughout the cluster. Applications that are deployed on nodes listen on input topics and perform several types of operations with and without state on input data and provide real-time data updates for subsequent downstream microservices.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Product teams need to update aggregated data in real time. </font><font style="vertical-align: inherit;">This is necessary in order to provide our customers with the ability to instantly transfer money. </font><font style="vertical-align: inherit;">Our usual SLA:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On any given day, 99.99% of aggregated data should be available in less than 10 seconds.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To give you an idea, during stress testing, Kafka Streams was able to process and aggregate 20,085 input messages per second. </font><font style="vertical-align: inherit;">Thus, 10 seconds of SLA under normal load sounded quite achievable. </font><font style="vertical-align: inherit;">Unfortunately, our SLA was not reached during the rolling update of the nodes on which the applications are deployed, and below I will describe why this happened.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sliding node update</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At TransferWise, we strongly believe in the continuous delivery of our software and usually release new versions of our services a couple of times a day. </font><font style="vertical-align: inherit;">Let's look at an example of a simple continuous service update and see what happens during the release process. </font><font style="vertical-align: inherit;">Again, we must remember that:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The data in the Kafka topic is divided into partitions, which are distributed between the Kafka Streams streams.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka Streams applications with the same application.id are, in fact, one group of consumers, and each of its threads is a separate isolated instance of the consumer.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For state operations, the thread maintains its own state, which is ‚Äúreserved‚Äù by the Kafka topic in the form of a change log.</font></font></li>
<li>       , Kafka      ,    .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A release process on a single node usually takes eight to nine seconds. </font><font style="vertical-align: inherit;">During the release, instances of Kafka Streams on the node ‚Äúgently reboot‚Äù. </font><font style="vertical-align: inherit;">Thus, for a single node, the time required to correctly restart the service is approximately eight to nine seconds. </font><font style="vertical-align: inherit;">Obviously, shutting down a Kafka Streams instance on a node causes a rebalancing of the consumer group. </font><font style="vertical-align: inherit;">Since the data is partitioned, all partitions that belonged to the bootable instance must be distributed between active Kafka Streams applications with the same application.id. </font><font style="vertical-align: inherit;">This also applies to aggregated data that has been saved to disk. </font><font style="vertical-align: inherit;">Until this process completes, data will not be processed.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Standby replicas</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To reduce rebalancing time for Kafka Streams applications, there is a concept of backup replicas, which are defined in the config as num.standby.replicas. Backup replicas are copies of the local state store. This mechanism makes it possible to replicate the state store from one instance of Kafka Streams to another. When the Kafka Streams thread dies for any reason, the duration of the state recovery process can be minimized. Unfortunately, for the reasons that I will explain below, even backup replicas will not help with a rolling service update.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Suppose we have two instances of Kafka Streams on two different machines: node-a and node-b. </font><font style="vertical-align: inherit;">For each of the Kafka Streams instances, num.standby.replicas = 1 is indicated on these 2 nodes. With this configuration, each Kafka Streams instance maintains its own copy of the repository on another node. </font><font style="vertical-align: inherit;">During a rolling update, we have the following situation:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The new version of the service has been deployed to node-a.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Kafka Streams instance on node-a is disabled.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rebalancing has begun.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The repository from node-a has already been replicated to node-b, since we specified the configuration num.standby.replicas = 1.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">node-b already has a shadow copy of node-a, so the rebalancing process happens almost instantly.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">node-a starts up again.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> node-a joins a group of consumers.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka broker sees a new instance of Kafka Streams and starts rebalancing.</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As we can see, num.standby.replicas helps only in scenarios of a complete shutdown of a node. </font><font style="vertical-align: inherit;">This means that if node-a crashed, then node-b could continue to work correctly almost instantly. </font><font style="vertical-align: inherit;">But in a rolling update situation, after disconnecting, node-a will join the group again, and this last step will cause a rebalance. </font><font style="vertical-align: inherit;">When node-a joins the consumer group after a reboot, it will be considered as a new instance of the consumer. </font><font style="vertical-align: inherit;">Again, we must remember that real-time data processing stops until a new instance restores its state from the change-log topic.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Please note that rebalancing partitions when a new instance is joined to a group does not apply to the Kafka Streams API, since this is exactly how the protocol of the Apache Kafka consumer group works.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Achievement: High Availability with Kafka Streams</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despite the fact that Kafka client libraries do not provide built-in functionality for the problem mentioned above, there are some tricks that can be used to achieve high cluster availability during a rolling update. </font><font style="vertical-align: inherit;">The idea behind backup replicas remains valid, and having backup machines when the time is right is a good solution that we use to ensure high availability in the event of instance failure.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The problem with our initial setup was that we had one group of consumers for all teams on all nodes. </font><font style="vertical-align: inherit;">Now, instead of one group of consumers, we have two, and the second acts as a ‚Äúhot‚Äù cluster. </font><font style="vertical-align: inherit;">In prod, nodes have a special variable CLUSTER_ID, which is added to the application.id of Kafka Streams instances. </font><font style="vertical-align: inherit;">Here is a sample Spring Boot application.yml configuration:</font></font><div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">application.yml</font></font></b><div class="spoiler_text"><code>spring.profiles: production<br>
streaming-pipelines:<br>
 team-a-stream-app-id: "${CLUSTER_ID}-team-a-stream-app"<br>
 team-b-stream-app-id: "${CLUSTER_ID}-team-b-stream-app"</code><br>
</div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At one point in time, only one of the clusters is in active mode, respectively, the backup cluster does not send messages in real time to downstream microservices. During the release of the release, the backup cluster becomes active, which allows for a rolling update on the first cluster. Since this is a completely different group of consumers, our customers do not even notice any violations in processing, and subsequent services continue to receive messages from the recently active cluster. One of the obvious disadvantages of using a backup group of consumers is the additional overhead and resource consumption, but, nevertheless, this architecture provides additional guarantees, control and fault tolerance of our streaming processing system.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition to adding an additional cluster, there are also tricks that can mitigate the problem with frequent rebalancing.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Increase group.initial.rebalance.delay.ms</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Starting with Kafka 0.11.0.0, the configuration group.initial.rebalance.delay.ms has been added. </font><font style="vertical-align: inherit;">According to the documentation, this setting is responsible for:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The amount of time in milliseconds that GroupCoordinator will delay the initial rebalancing of the group‚Äôs consumer.</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For example, if we set 60,000 milliseconds in this setting, then with a rolling update we may have a minute window for the release of the release. </font><font style="vertical-align: inherit;">If the Kafka Streams instance successfully restarts in this time window, no rebalancing will be called. </font><font style="vertical-align: inherit;">Please note that the data for which the restarted Kafka Streams instance was responsible will continue to be unavailable until the node returns to online mode. </font><font style="vertical-align: inherit;">For example, if an instance reboot takes about eight seconds, you will have eight seconds of downtime for the data that this instance is responsible for. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It should be noted that the main disadvantage of this concept is that in the event of a node failure, you will receive an additional delay of one minute during restoration, taking into account the current configuration.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Shrinking segment size in change-log topics</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The big delay in rebalancing Kafka Stream is due to the restoration of state stores from change-log topics. Change-log topics are compressed topics, which allows you to store the latest record for a particular key in the topic. I will briefly describe this concept below. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Topics in Kafka Broker are organized in segments. When a segment reaches the configured threshold size, a new segment is created and the previous one is compressed. By default, this threshold is set to 1 GB. As you probably know, the main data structure underlying the Kafka topics and their partitions is the log structure with a forward write, that is, when messages are sent to the topic, they are always added to the last ‚Äúactive‚Äù segment, and compression is not going on.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Therefore, most stored storage states in changelog are always in the ‚Äúactive segment‚Äù file and never compressed, resulting in millions of uncompressed changelog messages. </font><font style="vertical-align: inherit;">For Kafka Streams, this means that during rebalancing, when the Kafka Streams instance restores its state from the changelog topic, it needs to read a lot of redundant entries from the changelog topic. </font><font style="vertical-align: inherit;">Given that state stores only care about the last state, and not about history, this processing time is wasted. </font><font style="vertical-align: inherit;">Reducing the size of the segment will cause more aggressive data compression, so new instances of Kafka Streams applications can recover much faster.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Even though Kafka Streams does not provide a built-in ability to provide high availability during a rolling service update, this can still be done at the infrastructure level. </font><font style="vertical-align: inherit;">We must remember that Kafka Streams is not a ‚Äúcluster framework‚Äù unlike Apache Flink or Apache Spark. </font><font style="vertical-align: inherit;">It is a lightweight Java library that allows developers to create scalable applications for streaming data. </font><font style="vertical-align: inherit;">Despite this, it provides the necessary building blocks to achieve such ambitious streaming goals as ‚Äú99.99%‚Äù availability.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en488544/index.html">Remove code coverage from an already running Node.JS application</a></li>
<li><a href="../en488546/index.html">Hack The Box. JSON walkthrough. Vulnerability in Json.Net and LPE via SeImpersonatePrivilege</a></li>
<li><a href="../en488548/index.html">Experiment: how to learn to create popular texts in English (and why the English-speaking Habrists read so little)</a></li>
<li><a href="../en488550/index.html">Who wants to make cooperatives out of IT giants</a></li>
<li><a href="../en488552/index.html">Apple FAS and Parental Control Developers</a></li>
<li><a href="../en488560/index.html">Free Telegram bot hosting on Google Cloud Platform</a></li>
<li><a href="../en488564/index.html">Your first neural network on a graphics processing unit (GPU). Beginner's Guide</a></li>
<li><a href="../en488566/index.html">How a QA engineer saved an entire day by linking AutoTests in Visual Studio and Test IT</a></li>
<li><a href="../en488568/index.html">Do neural networks dream of electric money?</a></li>
<li><a href="../en488570/index.html">How the US Secret Service confused cyberpunk RPG with a textbook for hackers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
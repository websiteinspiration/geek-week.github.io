<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👌🏿 🙇🏼 🍬 ランダムフォレスト、主成分分析とハイパーパラメーターの最適化：Pythonでの分類問題の解決例 💝 🎪 🎽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="データ処理および分析の専門家には、分類モデルを作成するための多くのツールがあります。このようなモデルを開発するための最も一般的で信頼性の高い方法の1つは、ランダムフォレスト（RF）アルゴリズムを使用することです。RFアルゴリズムを使用して構築されたモデルのパフォーマンスを向上させるために、モデルのハ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ランダムフォレスト、主成分分析とハイパーパラメーターの最適化：Pythonでの分類問題の解決例</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/488342/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データ処理および分析の専門家には、分類モデルを作成するための多くのツールがあります。</font><font style="vertical-align: inherit;">このようなモデルを開発するための最も一般的で信頼性の高い方法の1つは、ランダムフォレスト（RF）アルゴリズムを使用することです。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RF</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">アルゴリズムを使用して構築されたモデルのパフォーマンスを向上させるために、モデル</font><font style="vertical-align: inherit;">のハイパーパラメーターの最適化を使用できます（ハイパー</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">パラメーターチューニング</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、HT）。</font><font style="vertical-align: inherit;">
さらに、データがモデルに転送される前に、</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">主成分分析</font></a><font style="vertical-align: inherit;">を使用して処理されるという広範囲なアプローチがあります。</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><img src="https://habrastorage.org/webt/tt/m5/h7/ttm5h7jbbx2u2wuc1var1azxwew.jpeg"></a><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、PCA）。</font><font style="vertical-align: inherit;">しかし、使用する価値はありますか？</font><font style="vertical-align: inherit;">分析者が特性の重要性を解釈するのに役立つRFアルゴリズムの主な目的ではありませんか？</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
はい、PCAアルゴリズムを使用すると、RFモデルの「機能の重要性」の分析において、各「機能」の解釈が少し複雑になる可能性があります。ただし、PCAアルゴリズムは特徴空間の次元を削減するため、RFモデルで処理する必要のある特徴の数が減少する可能性があります。計算量は、ランダムフォレストアルゴリズムの主な欠点の1つであることに注意してください（つまり、モデルの完了に時間がかかる場合があります）。 PCAアルゴリズムの適用は、モデリングの非常に重要な部分になる可能性があります。特に、数百または数千の機能で機能する場合はそうです。その結果、最も重要なことは、単に最も効果的なモデルを作成することであり、同時に属性の重要性を決定する際の精度を犠牲にすることができる場合、PCAは試してみる価値があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
さてポイントに。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">乳がんデータセット-Scikit-learnの「乳がん」</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で作業し</font><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">3つのモデルを作成し、それらの有効性を比較します。</font><font style="vertical-align: inherit;">具体的には、次のモデルについて話します。</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RFアルゴリズムに基づく基本モデル（このRFモデルは省略します）。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No. 1と同じモデルですが、主成分空間法（RF + PCA）を使用して特徴空間の次元の縮小が適用されるモデルです。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No. 2と同じモデルですが、ハイパーパラメーター最適化（RF + PCA + HT）を使用して構築されています。</font></font></li>
</ol><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.データをインポートする</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
はじめに、データを読み込み、Pandasデータフレームを作成します。</font><font style="vertical-align: inherit;">Scikit-learnから事前にクリアされた「おもちゃ」のデータセットを使用するため、その後、モデリングプロセスを開始できます。</font><font style="vertical-align: inherit;">ただし、そのようなデータを使用する場合でも、データフレーム（</font></font><code>df</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）に</font><font style="vertical-align: inherit;">適用される次のコマンドを使用して、データの予備分析を行うことから常に作業を開始することをお勧めします</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<ul>
<li><code>df.head()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -新しいデータフレームを見て、期待どおりに見えるかどうかを確認します。</font></font></li>
<li><code>df.info()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-データ型と列の内容の特徴を見つける。</font><font style="vertical-align: inherit;">続行する前にデータ型変換を実行する必要がある場合があります。</font></font></li>
<li><code>df.isna()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-データに値がないことを確認します</font></font><code>NaN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">対応する値がある場合は、何らかの方法で処理する必要がある場合があります。または、必要に応じて、データフレームから行全体を削除する必要がある場合があります。</font></font></li>
<li><code>df.describe()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -列のインジケーターの最小値、最大値、平均値を見つけ、列の平均二乗と予想される偏差のインジケーターを見つけます。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このデータセットでは、列</font></font><code>cancer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（癌）は、モデルを使用して予測する値を持つターゲット変数です。</font></font><code>0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「病気なし」を意味します。</font></font><code>1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-「病気の存在」</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_breast_cancer<font></font>
columns = [<span class="hljs-string">'mean radius'</span>, <span class="hljs-string">'mean texture'</span>, <span class="hljs-string">'mean perimeter'</span>, <span class="hljs-string">'mean area'</span>, <span class="hljs-string">'mean smoothness'</span>, <span class="hljs-string">'mean compactness'</span>, <span class="hljs-string">'mean concavity'</span>, <span class="hljs-string">'mean concave points'</span>, <span class="hljs-string">'mean symmetry'</span>, <span class="hljs-string">'mean fractal dimension'</span>, <span class="hljs-string">'radius error'</span>, <span class="hljs-string">'texture error'</span>, <span class="hljs-string">'perimeter error'</span>, <span class="hljs-string">'area error'</span>, <span class="hljs-string">'smoothness error'</span>, <span class="hljs-string">'compactness error'</span>, <span class="hljs-string">'concavity error'</span>, <span class="hljs-string">'concave points error'</span>, <span class="hljs-string">'symmetry error'</span>, <span class="hljs-string">'fractal dimension error'</span>, <span class="hljs-string">'worst radius'</span>, <span class="hljs-string">'worst texture'</span>, <span class="hljs-string">'worst perimeter'</span>, <span class="hljs-string">'worst area'</span>, <span class="hljs-string">'worst smoothness'</span>, <span class="hljs-string">'worst compactness'</span>, <span class="hljs-string">'worst concavity'</span>, <span class="hljs-string">'worst concave points'</span>, <span class="hljs-string">'worst symmetry'</span>, <span class="hljs-string">'worst fractal dimension'</span>]<font></font>
dataset = load_breast_cancer()<font></font>
data = pd.DataFrame(dataset[<span class="hljs-string">'data'</span>], columns=columns)<font></font>
data[<span class="hljs-string">'cancer'</span>] = dataset[<span class="hljs-string">'target'</span>]<font></font>
display(data.head())<font></font>
display(data.info())<font></font>
display(data.isna().sum())<font></font>
display(data.describe())</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bce/fb8/b60/bcefb8b60462b7658b40e1e56f7744ab.png"></div><br>
<i><font color="#999999">      .       .  , cancer,   ,    . 0  « ». 1 — « »</font></i><br>
 <br>
<h2><font color="#3AC1EF">2.        </font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、Scikit-learn関数を使用してデータを分割します</font></font><code>train_test_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。モデルにできるだけ多くのトレーニングデータを与えたいと考えています。ただし、モデルをテストするには、自由に使える十分なデータが必要です。一般に、データセットの行数が増えると、教育と見なすことができるデータの量も増えると言えます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
たとえば、数百万行ある場合、トレーニングデータの行の90％とテストデータの行の10％を強調表示することで、セットを分割できます。ただし、テストデータセットには569行しか含まれていません。そして、これはモデルのトレーニングとテストにはそれほど多くありません。結果として、トレーニングと検証データに関して公平にするために、セットを2つの等しい部分に分割します-50％-トレーニングデータと50％-検証データ。設置</font></font><code>stratify=y</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> トレーニングデータセットとテストデータセットの両方が、元のデータセットと同じ比率0と1を持つようにします。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
X = data.drop(<span class="hljs-string">'cancer'</span>, axis=<span class="hljs-number">1</span>)&nbsp;&nbsp;<font></font>
y = data[<span class="hljs-string">'cancer'</span>]&nbsp;<font></font>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.50</span>, random_state = <span class="hljs-number">2020</span>, stratify=y)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3.データのスケーリング</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデリングに進む前に、データを</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スケーリングして</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「中央揃え」および「標準化」する必要があり</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">スケーリングは、異なる量が異なる単位で表されるために実行されます。</font><font style="vertical-align: inherit;">この手順により、標識の重要性を判断する際に、標識間の「公正な戦い」を組織できます。</font><font style="vertical-align: inherit;">さらに、</font><font style="vertical-align: inherit;">後でモデルが対応するターゲットで機能できるように</font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、Pandasデータ型</font></font><code>Series</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">からNumPy配列</font><font style="vertical-align: inherit;">に変換</font><font style="vertical-align: inherit;">し</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
ss = StandardScaler()<font></font>
X_train_scaled = ss.fit_transform(X_train)<font></font>
X_test_scaled = ss.transform(X_test)<font></font>
y_train = np.array(y_train)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4.基本モデルのトレーニング（モデルNo. 1、RF）</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデル番号1を作成します。</font><font style="vertical-align: inherit;">その中で、ランダムフォレストアルゴリズムのみが使用されていることを思い出します。</font><font style="vertical-align: inherit;">すべての機能を使用し、デフォルト値を使用して構成されます（これらの設定の詳細は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sklearn.ensemble.RandomForestClassifier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">のドキュメントに記載されています</font><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">モデルを初期化します。</font><font style="vertical-align: inherit;">その後、スケーリングされたデータについて彼女をトレーニングします。</font><font style="vertical-align: inherit;">モデルの精度は、トレーニングデータで測定できます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> recall_score<font></font>
rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled, y_train)<font></font>
display(rfc.score(X_train_scaled, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
乳がんの予測におけるRFモデルにとって最も重要な特性を知ることに関心がある場合は、属性を参照することで、特性の重症度の指標を視覚化して定量化できます</font></font><code>feature_importances_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<pre><code class="python hljs">feats = {}
<span class="hljs-keyword">for</span> feature, importance <span class="hljs-keyword">in</span> zip(data.columns, rfc_1.feature_importances_):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;feats[feature] = importance<font></font>
importances = pd.DataFrame.from_dict(feats, orient=<span class="hljs-string">'index'</span>).rename(columns={<span class="hljs-number">0</span>: <span class="hljs-string">'Gini-Importance'</span>})<font></font>
importances = importances.sort_values(by=<span class="hljs-string">'Gini-Importance'</span>, ascending=<span class="hljs-literal">False</span>)<font></font>
importances = importances.reset_index()<font></font>
importances = importances.rename(columns={<span class="hljs-string">'index'</span>: <span class="hljs-string">'Features'</span>})<font></font>
sns.set(font_scale = <span class="hljs-number">5</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">1.7</span>)<font></font>
fig, ax = plt.subplots()<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">15</span>)<font></font>
sns.barplot(x=importances[<span class="hljs-string">'Gini-Importance'</span>], y=importances[<span class="hljs-string">'Features'</span>], data=importances, color=<span class="hljs-string">'skyblue'</span>)<font></font>
plt.xlabel(<span class="hljs-string">'Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'Features'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.title(<span class="hljs-string">'Feature Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
display(plt.show())<font></font>
display(importances)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a02/a8f/cd2/a02a8fcd28f87af338f364a70faeca3e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">標識の「重要性」の視覚化</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/830/176/e1f/830176e1fc9ce63bfedf2d727619253b.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">有意性指標</font></font></font></i><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.主成分の方法</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、基本的なRFモデルをどのように改善できるかを考えてみましょう。特徴空間の次元を削減する手法を使用すると、より少ない変数で初期データセットを提示し、同時にモデルの操作を保証するために必要な計算リソースの量を削減できます。 PCAを使用すると、これらの特徴の累積サンプル分散を調べて、どの特徴がデータの分散のほとんどを説明するかを理解できます。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PCA（</font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">オブジェクトを初期化して、</font><font style="vertical-align: inherit;">考慮する必要のあるコンポーネント（機能）の数を示し</font><font style="vertical-align: inherit;">ます</font><font style="vertical-align: inherit;">。必要なコンポーネントの数を決定する前に、生成されたすべてのコンポーネントの説明された分散を確認するために、このインジケーターを30に設定します。次に、</font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スケーリングされたデータに</font><font style="vertical-align: inherit;">転送し</font><font style="vertical-align: inherit;">ます</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">メソッドを使用し</font></font><code>pca_test.fit()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。</font><font style="vertical-align: inherit;">その後、データを視覚化します。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<font></font>
pca_test = PCA(n_components=<span class="hljs-number">30</span>)<font></font>
pca_test.fit(X_train_scaled)<font></font>
sns.set(style=<span class="hljs-string">'whitegrid'</span>)<font></font>
plt.plot(np.cumsum(pca_test.explained_variance_ratio_))<font></font>
plt.xlabel(<span class="hljs-string">'number of components'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'cumulative explained variance'</span>)<font></font>
plt.axvline(linewidth=<span class="hljs-number">4</span>, color=<span class="hljs-string">'r'</span>, linestyle = <span class="hljs-string">'--'</span>, x=<span class="hljs-number">10</span>, ymin=<span class="hljs-number">0</span>, ymax=<span class="hljs-number">1</span>)<font></font>
display(plt.show())<font></font>
evr = pca_test.explained_variance_ratio_<font></font>
cvr = np.cumsum(pca_test.explained_variance_ratio_)<font></font>
pca_df = pd.DataFrame()<font></font>
pca_df[<span class="hljs-string">'Cumulative Variance Ratio'</span>] = cvr<font></font>
pca_df[<span class="hljs-string">'Explained Variance Ratio'</span>] = evr<font></font>
display(pca_df.head(<span class="hljs-number">10</span>))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6eb/65f/acc/6eb65facc6c8b05f1e910d3b2b676d5e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用されるコンポーネントの数が10を超えた後、それらの数の増加は、説明された分散を大幅に増加しません</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f12/e3c/915/f12e3c915d761e1d4623051dac74cd8d.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このデータフレームには、累積分散比（データの説明された分散の累積サイズ）や説明された分散比（説明された分散の総量に対する各コンポーネントの寄与）などのインジケーターが含まれ</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
ます。上記のデータフレームを見ると、PCAを使用して30変数から10変数に移動していることがわかります。コンポーネントにデータの分散の95％を説明することができます。他の20個のコンポーネントは、分散の5％未満を占めます。つまり、それらを拒否することができます。このロジックに続いて、我々はのために10に30から部品点数を削減するPCAを使用</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">して</font></font><code>X_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。これらの人工的に作成された「縮小次元」データセットを</font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">とに</font><font style="vertical-align: inherit;">書き込みます</font></font><code>X_test_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<pre><code class="python hljs">pca = PCA(n_components=<span class="hljs-number">10</span>)<font></font>
pca.fit(X_train_scaled)<font></font>
X_train_scaled_pca = pca.transform(X_train_scaled)<font></font>
X_test_scaled_pca = pca.transform(X_test_scaled)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各コンポーネントは、ソース変数と対応する「重み」の線形結合です。</font><font style="vertical-align: inherit;">データフレームを作成することで、各コンポーネントのこれらの「重み」を確認できます。</font></font><br>
<br>
<pre><code class="python hljs">pca_dims = []
<span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(pca_df)):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;pca_dims.append(<span class="hljs-string">'PCA Component {}'</span>.format(x))<font></font>
pca_test_df = pd.DataFrame(pca_test.components_, columns=columns, index=pca_dims)<font></font>
pca_test_df.head(<span class="hljs-number">10</span>).T</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/086/a28/ae4/086a28ae45e9048811cf813d4868902e.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コンポーネント情報データフレーム</font></font></font></i><br>
 <br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6.データに主成分分析法を適用した後の基本的なRFモデルのトレーニング（モデルNo. 2、RF + PCA）</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで、別の基本的なRFモデルデータ</font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">渡すことができ</font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、モデルによって発行された予測の精度が向上したかどうかを確認できます。</font></font><br>
<br>
<pre><code class="python hljs">rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled_pca, y_train)<font></font>
display(rfc.score(X_train_scaled_pca, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルを以下で比較します。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7.ハイパーパラメーターの最適化。</font><font style="vertical-align: inherit;">ラウンド1：RandomizedSearchCV</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
主成分分析法を使用してデータを処理した後</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">モデル</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ハイパーパラメーター</font></a><font style="vertical-align: inherit;">の</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">最適化</font></a><font style="vertical-align: inherit;">を使用</font><font style="vertical-align: inherit;">して、RFモデルによって生成される予測の品質を向上させる</font><font style="vertical-align: inherit;">ことができます</font><font style="vertical-align: inherit;">。ハイパーパラメータは、モデルの「設定」のようなものと考えることができます。あるデータセットに最適な設定は別のデータセットでは機能しません。そのため、それらを最適化する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
RandomizedSearchCVアルゴリズムから始めることができます。これにより、広範囲の値をかなり大まかに調べることができます。 RFモデルのすべてのハイパーパラメータの説明は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ここにあります</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
作業の過程で</font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、各ハイパーパラメーターごとに、テストする必要のある値の範囲を含む</font><font style="vertical-align: inherit;">エンティティを生成</font><font style="vertical-align: inherit;">します。次に、オブジェクトを初期化します。</font></font><code>rs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">関数を使用し</font></font><code>RandomizedSearchCV()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">て、RFモデル</font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、反復数、および</font><font style="vertical-align: inherit;">実行する必要</font><font style="vertical-align: inherit;">がある</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">交差検証の</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">数を</font><font style="vertical-align: inherit;">渡し</font><font style="vertical-align: inherit;">ます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ハイパーパラメーターを</font></font><code>verbose</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用すると、モデルの操作中にモデルによって表示される情報の量を制御できます（モデルのトレーニング中の情報の出力など）。</font><font style="vertical-align: inherit;">ハイパーパラメータ</font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を使用すると、モデルの動作を保証するために使用する必要があるプロセッサコアの数を指定できます。</font><font style="vertical-align: inherit;">これ</font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を値に</font><font style="vertical-align: inherit;">設定する</font><font style="vertical-align: inherit;">と、</font></font><code>-1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">すべてのプロセッサコアが使用されるため、モデルの動作が速くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のハイパーパラメータの選択に取り組みます。</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -「ランダムフォレスト」内の「ツリー」の数。</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -分割を選択する機能の数。</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -木の最大深度。</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -ツリーノードを分割するために必要なオブジェクトの最小数。</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -葉のオブジェクトの最小数。</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -returnを使用してサブサンプルツリーを構築するために使用します。</font></font></li>
</ul><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<font></font>
n_estimators = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">100</span>, stop = <span class="hljs-number">1000</span>, num = <span class="hljs-number">10</span>)]<font></font>
max_features = [<span class="hljs-string">'log2'</span>, <span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">1</span>, stop = <span class="hljs-number">15</span>, num = <span class="hljs-number">15</span>)]<font></font>
min_samples_split = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
min_samples_leaf = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
bootstrap = [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]<font></font>
param_dist = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
rs = RandomizedSearchCV(rfc_2,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;param_dist,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_iter = <span class="hljs-number">100</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv = <span class="hljs-number">3</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose = <span class="hljs-number">1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_jobs=<span class="hljs-number">-1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random_state=<span class="hljs-number">0</span>)<font></font>
rs.fit(X_train_scaled_pca, y_train)<font></font>
rs.best_params_<font></font>
<span class="hljs-comment"># {'n_estimators': 700,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'min_samples_leaf': 2,</span>
<span class="hljs-comment"># 'max_features': 'log2',</span>
<span class="hljs-comment"># 'max_depth': 11,</span>
<span class="hljs-comment"># 'bootstrap': True}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
パラメータ</font></font><code>n_iter = 100</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><code>cv = 3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">使用</font><font style="vertical-align: inherit;">して</font><font style="vertical-align: inherit;">、300個のRFモデルを作成し、上記のハイパー</font><font style="vertical-align: inherit;">パラメータの</font><font style="vertical-align: inherit;">組み合わせをランダムに選択しました。</font></font><code>best_params_ </code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最高のモデルを作成できるようにする一連のパラメーターについては</font><font style="vertical-align: inherit;">、属性</font><font style="vertical-align: inherit;">を</font><font style="vertical-align: inherit;">参照してください</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">ただし、この段階では、次のラウンドの最適化で調査する価値のあるパラメーターの範囲に関する最も興味深いデータが得られない可能性があります。</font><font style="vertical-align: inherit;">検索を続ける価値がある値の範囲を見つけるために、RandomizedSearchCVアルゴリズムの結果を含むデータフレームを簡単に取得できます。</font></font><br>
<br>
<pre><code class="python hljs">rs_df = pd.DataFrame(rs.cv_results_).sort_values(<span class="hljs-string">'rank_test_score'</span>).reset_index(drop=<span class="hljs-literal">True</span>)<font></font>
rs_df = rs_df.drop([<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_score_time'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_score_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'params'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split0_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split1_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split2_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_test_score'</span>],<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis=<span class="hljs-number">1</span>)<font></font>
rs_df.head(<span class="hljs-number">10</span>)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/617/b8c/20b/617b8c20b787acc3c76c23d9235b4b5a.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RandomizedSearchCVアルゴリズムの結果</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
次に、X軸がハイパーパラメーター値であり、Y軸がモデルによって示される平均値である棒グラフを作成します。</font><font style="vertical-align: inherit;">これにより、ハイパーパラメーターのどの値が平均して最高のパフォーマンスを示すかを理解できるようになります。</font></font><br>
<br>
<pre><code class="python hljs">fig, axs = plt.subplots(ncols=<span class="hljs-number">3</span>, nrows=<span class="hljs-number">2</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">2</span>)<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">25</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_n_estimators'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'lightgrey'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.83</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'n_estimators'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_split'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'coral'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.85</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'min_samples_split'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_leaf'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'lightgreen'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'min_samples_leaf'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_features'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'wheat'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'max_features'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_depth'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'lightpink'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'max_depth'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_bootstrap'</span>,y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'skyblue'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'bootstrap'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
plt.show()</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/418/311/ba6/418311ba6c38bfcebbf152af810d6b58.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ハイパー</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
パラメーター</font><i><font color="#999999"><font style="vertical-align: inherit;">の値の</font></font></i><font style="vertical-align: inherit;">分析上記のグラフを分析すると、</font><i><font color="#999999"><font style="vertical-align: inherit;">ハイパー</font></font></i><font style="vertical-align: inherit;">パラメーターの各値が平均してモデルにどのように影響するかを説明する興味深いことがわかります。</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：300、500、700の値は、明らかに最良の平均結果を示しています。</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：2や7のような小さな値が最良の結果を示しているようです。</font><font style="vertical-align: inherit;">値23も見栄えが良いです。このハイパーパラメーターの2を超える値と、約23の値を調べることができます。</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：このハイパーパラメーターの値が小さいと、より良い結果が得られるという感じがあります。</font><font style="vertical-align: inherit;">これは、2と7の間の値を体験できることを意味します。</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：オプション</font></font><code>sqrt</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は最高の平均結果を与え</font><font style="vertical-align: inherit;">ます</font><font style="vertical-align: inherit;">。</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：ハイパーパラメーターの値とモデルの結果の間に明確な関係はありませんが、値2、3、7、11、15は見栄えが良いと感じています。</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：値</font></font><code>False</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は最良の平均結果を示します。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここで、これらの調査結果を使用して、ハイパーパラメーターの2番目のラウンドの最適化に進むことができます。</font><font style="vertical-align: inherit;">これにより、関心のある値の範囲が狭まります。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8.ハイパーパラメーターの最適化。</font><font style="vertical-align: inherit;">ラウンド2：GridSearchCV（モデルNo. 3、RF + PCA + HTのパラメーターの最終準備）</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
RandomizedSearchCVアルゴリズムを適用した後、GridSearchCVアルゴリズムを使用して、ハイパーパラメーターの最適な組み合わせをより正確に検索します。ここでは同じハイパーパラメータを調査しますが、現在は、それらの最良の組み合わせに対してより「徹底的な」検索を適用しています。 GridSearchCVアルゴリズムを使用して、ハイパーパラメーターの各組み合わせを調べます。これには、検索の反復回数を個別に設定する場合、RandomizedSearchCVアルゴリズムを使用するよりもはるかに多くの計算リソースが必要です。たとえば、3つのブロックで交差検証を行う6つのハイパーパラメーターのそれぞれについて10個の値を調査するには、10⁶x 3、つまり3,000,000個のモデルトレーニングセッションが必要です。そのため、RandomizedSearchCVを適用した後、調査したパラメーターの値の範囲を狭めた後、GridSearchCVアルゴリズムを使用します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、RandomizedSearchCVの助けを借りて見つけたものを使用して、最もよく表示されているハイパーパラメーターの値を調べます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<font></font>
n_estimators = [<span class="hljs-number">300</span>,<span class="hljs-number">500</span>,<span class="hljs-number">700</span>]<font></font>
max_features = [<span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">7</span>,<span class="hljs-number">11</span>,<span class="hljs-number">15</span>]<font></font>
min_samples_split = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">22</span>,<span class="hljs-number">23</span>,<span class="hljs-number">24</span>]<font></font>
min_samples_leaf = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<font></font>
bootstrap = [<span class="hljs-literal">False</span>]<font></font>
param_grid = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
gs = GridSearchCV(rfc_2, param_grid, cv = <span class="hljs-number">3</span>, verbose = <span class="hljs-number">1</span>, n_jobs=<span class="hljs-number">-1</span>)<font></font>
gs.fit(X_train_scaled_pca, y_train)<font></font>
rfc_3 = gs.best_estimator_<font></font>
gs.best_params_<font></font>
<span class="hljs-comment"># {'bootstrap': False,</span>
<span class="hljs-comment"># 'max_depth': 7,</span>
<span class="hljs-comment"># 'max_features': 'sqrt',</span>
<span class="hljs-comment"># 'min_samples_leaf': 3,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'n_estimators': 500}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ここでは、3つのブロックで540（3 x 1 x 5 x 6 x 6 x 1）モデルトレーニングセッションの交差検定を適用します。これにより、1620モデルのトレーニングセッションが提供されます。</font><font style="vertical-align: inherit;">そして今、RandomizedSearchCVとGridSearchCVを使用した後、属性に</font></font><code>best_params_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">移動して、ハイパーパラメーターのどの値がモデルが調査中のデータセットで最適に機能するかを確認できます（これらの値は、前のコードブロックの下部で確認できます） 。</font><font style="vertical-align: inherit;">これらのパラメーターは、モデル番号3を作成するために使用されます。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9.検証データでのモデルの品質の評価</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これで、作成したモデルを検証データで評価できます。</font><font style="vertical-align: inherit;">つまり、資料の冒頭で説明した3つのモデルについて話しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらのモデルをチェックしてください：</font></font><br>
<br>
<pre><code class="python hljs">y_pred = rfc.predict(X_test_scaled)<font></font>
y_pred_pca = rfc.predict(X_test_scaled_pca)<font></font>
y_pred_gs = gs.best_estimator_.predict(X_test_scaled_pca)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルの誤差行列を作成し、各モデルが乳がんをどれだけうまく予測できるかを調べます。</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix<font></font>
conf_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_pred), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_baseline_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_pca), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_tuned_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_gs), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
display(conf_matrix_baseline)<font></font>
display(<span class="hljs-string">'Baseline Random Forest recall score'</span>, recall_score(y_test, y_pred))<font></font>
display(conf_matrix_baseline_pca)<font></font>
display(<span class="hljs-string">'Baseline Random Forest With PCA recall score'</span>, recall_score(y_test, y_pred_pca))<font></font>
display(conf_matrix_tuned_pca)<font></font>
display(<span class="hljs-string">'Hyperparameter Tuned Random Forest With PCA Reduced Dimensionality recall score'</span>, recall_score(y_test, y_pred_gs))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f48/a9e/92f/f48a9e92fd5fdca613d6073e00bae2c6.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3つのモデルの作業結果</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
ここでは、メトリックの「完全性」（再現）が評価されます。</font><font style="vertical-align: inherit;">事実、私たちはがんの診断に取り組んでいます。</font><font style="vertical-align: inherit;">したがって、モデルによって発行された偽陰性の予測を最小限に抑えることに非常に関心があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このことから、基本的なRFモデルが最良の結果をもたらしたと結論付けることができます。</font><font style="vertical-align: inherit;">その完成率は94.97％でした。</font><font style="vertical-align: inherit;">テストデータセットには、がんの患者179人の記録がありました。</font><font style="vertical-align: inherit;">モデルはそれらの170を見つけました。</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">概要</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この研究は重要な観察を提供します。</font><font style="vertical-align: inherit;">主成分分析法とハイパーパラメーターの大規模最適化を使用するRFモデルは、標準設定の最も一般的なモデルと同じように機能しない場合があります。</font><font style="vertical-align: inherit;">しかし、これはあなた自身を最も単純なモデルだけに限定する理由ではありません。</font><font style="vertical-align: inherit;">別のモデルを試さなければ、どちらが最良の結果を示すかを言うことは不可能です。</font><font style="vertical-align: inherit;">また、患者のがんの存在を予測するために使用されるモデルの場合、モデルが優れているほど、より多くの命を救うことができると言えます。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">読者の皆様！</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">機械学習手法を使用してどのようなタスクを解決しますか？</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja488330/index.html">ジョージ・カーリンとの英語：表現学的単位についての独創的なスタンドアップを分析します</a></li>
<li><a href="../ja488332/index.html">ゼロ、1、2、フレディがあなたを迎えます</a></li>
<li><a href="../ja488336/index.html">波動関数折りたたみアルゴリズムを使用するためのヒント</a></li>
<li><a href="../ja488338/index.html">Googleインターンシップ：チューリッヒ、ロンドン、シリコンバレー</a></li>
<li><a href="../ja488340/index.html">職業：バックエンド開発者</a></li>
<li><a href="../ja488346/index.html">LinuxのPython 3.7仮想環境でのSCIPおよびGLPKを使用したor-toolsのインストール</a></li>
<li><a href="../ja488348/index.html">ウェビナー「10のアジャイルチャレンジと1時間でそれらを克服する方法」2月17日20:00モスクワ時間</a></li>
<li><a href="../ja488352/index.html">VDIコストの比較：オンプレミスとパブリッククラウド</a></li>
<li><a href="../ja488356/index.html">サンクトペテルブルグ国立海洋工科大学でのダッソー・システムズ製品のトレーニング</a></li>
<li><a href="../ja488360/index.html">ビッグデータの神話とデジタル文化</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
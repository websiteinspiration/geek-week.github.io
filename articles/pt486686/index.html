<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÜôÔ∏è üë®‚Äçüî¨ ü§¥üèø Sobre a implementa√ß√£o de uma biblioteca de aprendizado profundo em Python üïπÔ∏è üì† üëÉüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As tecnologias de aprendizado profundo percorreram um longo caminho em um curto per√≠odo de tempo - desde redes neurais simples a arquiteturas bastante...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Sobre a implementa√ß√£o de uma biblioteca de aprendizado profundo em Python</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/486686/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As tecnologias de aprendizado profundo percorreram um longo caminho em um curto per√≠odo de tempo - desde redes neurais simples a arquiteturas bastante complexas. Para apoiar a r√°pida dissemina√ß√£o dessas tecnologias, v√°rias bibliotecas e plataformas de aprendizado profundo foram desenvolvidas. Um dos principais objetivos dessas bibliotecas √© fornecer aos desenvolvedores interfaces simples para criar e treinar modelos de redes neurais. Essas bibliotecas permitem que seus usu√°rios prestem mais aten√ß√£o nas tarefas que est√£o sendo resolvidas, e n√£o nas sutilezas da implementa√ß√£o do modelo. Para fazer isso, pode ser necess√°rio ocultar a implementa√ß√£o de mecanismos b√°sicos por tr√°s de v√°rios n√≠veis de abstra√ß√£o. E isso, por sua vez, complica a compreens√£o dos princ√≠pios b√°sicos nos quais as bibliotecas de aprendizado profundo se baseiam.</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/bp/yi/sl/bpyislfb1o7e-qh7exvklh1oxuw.jpeg"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O artigo, cuja tradu√ß√£o estamos publicando, tem como objetivo analisar os recursos do dispositivo de blocos de constru√ß√£o de baixo n√≠vel das bibliotecas de aprendizado profundo. </font><font style="vertical-align: inherit;">Primeiro, falamos brevemente sobre a ess√™ncia do aprendizado profundo. </font><font style="vertical-align: inherit;">Isso nos permitir√° entender os requisitos funcionais do respectivo software. </font><font style="vertical-align: inherit;">Em seguida, analisamos o desenvolvimento de uma biblioteca de aprendizado profundo simples, mas funcional, em Python usando o NumPy. </font><font style="vertical-align: inherit;">Essa biblioteca √© capaz de fornecer treinamento completo para modelos simples de redes neurais. </font><font style="vertical-align: inherit;">Ao longo do caminho, falaremos sobre os v√°rios componentes das estruturas de aprendizado profundo. </font><font style="vertical-align: inherit;">A biblioteca que consideraremos √© muito pequena, com menos de 100 linhas de c√≥digo. </font><font style="vertical-align: inherit;">E isso significa que ser√° bastante simples descobrir isso. </font><font style="vertical-align: inherit;">O c√≥digo completo do projeto, com o qual trataremos, pode ser encontrado </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqui</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<a name="habracut"></a><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Informa√ß√£o geral</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Normalmente, as bibliotecas de aprendizado profundo (como TensorFlow e PyTorch) consistem nos componentes mostrados na figura a seguir.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c49/b9f/396/c49b9f39652c0260a9e30ee4e5dea146.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Componentes da estrutura de aprendizado profundo</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Vamos analisar esses componentes.</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ñç Operadores</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os conceitos de "operador" e "camada" (camada) s√£o geralmente usados ‚Äã‚Äãde forma intercambi√°vel. </font><font style="vertical-align: inherit;">Estes s√£o os elementos b√°sicos de qualquer rede neural. </font><font style="vertical-align: inherit;">Operadores s√£o fun√ß√µes vetoriais que transformam dados. </font><font style="vertical-align: inherit;">Entre os operadores usados ‚Äã‚Äãcom freq√º√™ncia, podemos distinguir como camadas lineares e de convolu√ß√£o, camadas de subamostragem (pooling), fun√ß√µes de ativa√ß√£o semi-lineares (ReLU) e sigm√≥ides (sigm√≥ides).</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PtOtimizadores (otimizadores)</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Otimizadores s√£o a base das bibliotecas de aprendizado profundo. </font><font style="vertical-align: inherit;">Eles descrevem m√©todos para ajustar os par√¢metros do modelo usando certos crit√©rios e levando em considera√ß√£o o objetivo da otimiza√ß√£o. </font><font style="vertical-align: inherit;">Entre os otimizadores conhecidos, destacam-se SGD, RMSProp e Adam.</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ñç Fun√ß√µes de perda</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As fun√ß√µes de perda s√£o express√µes matem√°ticas anal√≠ticas e diferenci√°veis ‚Äã‚Äãusadas como substitutas do objetivo de otimiza√ß√£o na resolu√ß√£o de um problema. </font><font style="vertical-align: inherit;">Por exemplo, a fun√ß√£o de entropia cruzada e a fun√ß√£o linear por partes s√£o geralmente usadas em problemas de classifica√ß√£o.</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ñç Inicializadores</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os inicializadores fornecem valores iniciais para os par√¢metros do modelo. </font><font style="vertical-align: inherit;">S√£o esses valores que os par√¢metros possuem no in√≠cio do treinamento. </font><font style="vertical-align: inherit;">Os inicializadores desempenham um papel importante no treinamento de redes neurais, pois par√¢metros iniciais malsucedidos podem significar que a rede aprender√° lentamente ou poder√° n√£o aprender nada. </font><font style="vertical-align: inherit;">Existem v√°rias maneiras de inicializar os pesos de uma rede neural. </font><font style="vertical-align: inherit;">Por exemplo - voc√™ pode atribuir a eles pequenos valores aleat√≥rios da distribui√ß√£o normal. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aqui est√° uma</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> p√°gina onde voc√™ pode aprender sobre os diferentes tipos de inicializadores.</font></font><br>
<br>
<h3><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ñç Regularizadores</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Regularizadores s√£o ferramentas que evitam a reciclagem da rede e ajudam a rede a obter generaliza√ß√£o. Voc√™ pode lidar com a reciclagem da rede de maneira expl√≠cita ou impl√≠cita. M√©todos expl√≠citos envolvem limita√ß√µes estruturais nos pesos. Por exemplo, minimizar suas normas L1 e L2, o que, consequentemente, torna os valores de peso melhor dispersos e distribu√≠dos de maneira mais uniforme. M√©todos impl√≠citos s√£o representados por operadores especializados que executam a transforma√ß√£o de representa√ß√µes intermedi√°rias. Isso √© feito atrav√©s da normaliza√ß√£o expl√≠cita, por exemplo, usando a t√©cnica de normaliza√ß√£o de pacotes (BatchNorm) ou alterando a conectividade de rede usando os algoritmos DropOut e DropConnect.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os componentes acima geralmente pertencem √† parte da interface da biblioteca. </font><font style="vertical-align: inherit;">Aqui, por "parte da interface", quero dizer as entidades com as quais o usu√°rio pode interagir. </font><font style="vertical-align: inherit;">Eles oferecem ferramentas convenientes para projetar com efici√™ncia uma arquitetura de rede neural. </font><font style="vertical-align: inherit;">Se falarmos sobre os mecanismos internos das bibliotecas, eles podem fornecer suporte para o c√°lculo autom√°tico de gradientes da fun√ß√£o de perda, levando em considera√ß√£o v√°rios par√¢metros do modelo. </font><font style="vertical-align: inherit;">Essa t√©cnica √© comumente chamada de Diferencia√ß√£o autom√°tica (AD).</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diferencia√ß√£o autom√°tica</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada biblioteca de aprendizado profundo fornece ao usu√°rio alguns recursos de diferencia√ß√£o autom√°tica. Isso lhe d√° a oportunidade de focar na descri√ß√£o da estrutura do modelo (gr√°fico de c√°lculos) e transferir a tarefa de calcular os gradientes para o m√≥dulo AD. Vamos dar um exemplo que nos permitir√° saber como tudo funciona. Suponha que desejamos calcular as derivadas parciais da fun√ß√£o a seguir em rela√ß√£o √†s suas vari√°veis ‚Äã‚Äãde entrada X‚ÇÅ e X‚ÇÇ: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y = sin (x‚ÇÅ) + X‚ÇÅ * X‚ÇÇ </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A figura a seguir, que eu emprestei </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">daqui</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , mostra o gr√°fico de c√°lculos e o c√°lculo de derivadas usando uma regra de cadeia.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/605/635/189/605635189c56a2f87927ec1a0c5b6318.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gr√°fico computacional e c√°lculo de derivadas por uma regra em cadeia</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
O que voc√™ v√™ aqui √© algo como um "modo reverso" de diferencia√ß√£o autom√°tica. </font><font style="vertical-align: inherit;">O conhecido algoritmo de propaga√ß√£o de erro de retorno √© um caso especial do algoritmo acima para o caso em que a fun√ß√£o localizada na parte superior √© uma fun√ß√£o de perda. </font><font style="vertical-align: inherit;">O AD explora o fato de que qualquer fun√ß√£o complexa consiste em opera√ß√µes aritm√©ticas elementares e fun√ß√µes elementares. </font><font style="vertical-align: inherit;">Como resultado, os derivativos podem ser calculados aplicando uma regra de cadeia a essas opera√ß√µes.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Implementa√ß√£o</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Na se√ß√£o anterior, examinamos os componentes necess√°rios para a cria√ß√£o de uma biblioteca de aprendizado profundo projetada para a cria√ß√£o e o treinamento completo de redes neurais. Para n√£o complicar o exemplo, imito o padr√£o de design da biblioteca </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caffe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aqui </font><font style="vertical-align: inherit;">. Aqui declaramos duas classes abstratas - </font></font><code>Function</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font><code>Optimizer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Al√©m disso, h√° uma classe </font></font><code>Tensor</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, que √© uma estrutura simples que cont√©m duas matrizes NumPy multidimensionais. Um deles √© projetado para armazenar valores de par√¢metros, o outro - para armazenar seus gradientes. Todos os par√¢metros em diferentes camadas (operadores) ser√£o do tipo </font></font><code>Tensor</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Antes de prosseguirmos, d√™ uma olhada no esbo√ßo geral da biblioteca.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d05/98c/068/d0598c068139ecda1f2aacbd9ea5f068.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diagrama UML da biblioteca</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
No momento da reda√ß√£o deste material, esta biblioteca cont√©m uma implementa√ß√£o da camada linear, da fun√ß√£o de ativa√ß√£o ReLU, da camada SoftMaxLoss e do otimizador SGD. Como resultado, verifica-se que a biblioteca pode ser usada para treinar modelos de classifica√ß√£o que consistem em camadas totalmente conectadas e usando uma fun√ß√£o de ativa√ß√£o n√£o linear. Agora vamos ver alguns detalhes sobre as classes abstratas que temos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma classe abstrata</font></font><code>Function</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fornece uma interface para operadores. Aqui est√° o c√≥digo dele:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span>&nbsp; <span class="hljs-title">Function</span>(<span class="hljs-params">object</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">raise</span> NotImplementedError<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">raise</span> NotImplementedError<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getParams</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> []</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos os operadores s√£o implementados atrav√©s da heran√ßa de uma classe abstrata </font></font><code>Function</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Cada operador deve fornecer uma implementa√ß√£o dos m√©todos </font></font><code>forward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Os operadores podem conter uma implementa√ß√£o de um m√©todo opcional </font></font><code>getParams()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que retorna seus par√¢metros (se houver). O m√©todo </font></font><code>forward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recebe dados de entrada e retorna o resultado de sua transforma√ß√£o pelo operador. Al√©m disso, ele resolve os problemas internos necess√°rios para o c√°lculo de gradientes. O m√©todo </font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aceita derivadas parciais da fun√ß√£o de perda em rela√ß√£o √†s sa√≠das do operador e implementa o c√°lculo das derivadas parciais da fun√ß√£o de perda em rela√ß√£o aos dados de entrada do operador e aos par√¢metros (se houver). Observe que o m√©todo</font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, em ess√™ncia, fornece √† nossa biblioteca a capacidade de executar diferencia√ß√£o autom√°tica. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para lidar com tudo isso com um exemplo espec√≠fico, vamos dar uma olhada na implementa√ß√£o da fun√ß√£o </font></font><code>Linear</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Linear</span>(<span class="hljs-params">Function</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,in_nodes,out_nodes</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.weights = Tensor((in_nodes,out_nodes))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.bias&nbsp; &nbsp; = Tensor((<span class="hljs-number">1</span>,out_nodes))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.type = <span class="hljs-string">'linear'</span><font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self,x</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output = np.dot(x,self.weights.data)+self.bias.data<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.input = x&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> output<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backward</span>(<span class="hljs-params">self,d_y</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.weights.grad += np.dot(self.input.T,d_y)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.bias.grad&nbsp; &nbsp; += np.sum(d_y,axis=<span class="hljs-number">0</span>,keepdims=<span class="hljs-literal">True</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grad_input &nbsp; &nbsp; &nbsp; &nbsp; = np.dot(d_y,self.weights.data.T)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> grad_input<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getParams</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> [self.weights,self.bias]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O m√©todo </font></font><code>forward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">implementa a transforma√ß√£o da visualiza√ß√£o </font></font><code>Y = X*W+b</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e retorna o resultado. Al√©m disso, ele salva o valor de entrada </font></font><code>X</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, pois √© necess√°rio calcular a derivada parcial da </font></font><code>dY</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fun√ß√£o de perda em rela√ß√£o ao valor de sa√≠da </font></font><code>Y</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no m√©todo </font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. O m√©todo </font></font><code>backward()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">recebe as derivadas parciais, calculadas com rela√ß√£o ao valor de entrada </font></font><code>X</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e aos par√¢metros </font></font><code>W</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font><code>b</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Al√©m disso, ele retorna as derivadas parciais calculadas em rela√ß√£o ao valor de entrada </font></font><code>X</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, que ser√£o transferidas para a camada anterior. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma classe abstrata </font></font><code>Optimizer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fornece uma interface para otimizadores:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Optimizer</span>(<span class="hljs-params">object</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,parameters</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.parameters = parameters<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self</span>):</span>&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">raise</span> NotImplementedError<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">zeroGrad</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.parameters:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p.grad = <span class="hljs-number">0.</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos os otimizadores s√£o implementados herdando da classe base </font></font><code>Optimizer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Uma classe que descreve uma otimiza√ß√£o espec√≠fica deve fornecer uma implementa√ß√£o do m√©todo </font></font><code>step()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Esse m√©todo atualiza os par√¢metros do modelo usando suas derivadas parciais calculadas em rela√ß√£o ao valor otimizado da fun√ß√£o de perda. </font><font style="vertical-align: inherit;">Um link para v√°rios par√¢metros do modelo √© fornecido na fun√ß√£o </font></font><code>__init__()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Observe que a funcionalidade universal para redefinir valores de gradiente √© implementada na pr√≥pria classe base. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, para entender melhor tudo isso, considere um exemplo espec√≠fico - a implementa√ß√£o do algoritmo de descida do gradiente estoc√°stico (SGD) com suporte para ajustar o momento e reduzir pesos:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SGD</span>(<span class="hljs-params">Optimizer</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,parameters,lr=<span class="hljs-number">.001</span>,weight_decay=<span class="hljs-number">0.0</span>,momentum = <span class="hljs-number">.9</span></span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().__init__(parameters)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.lr &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = lr<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.weight_decay = weight_decay<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.momentum &nbsp; &nbsp; = momentum<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.velocity &nbsp; &nbsp; = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> parameters:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.velocity.append(np.zeros_like(p.grad))<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">step</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> p,v <span class="hljs-keyword">in</span> zip(self.parameters,self.velocity):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v = self.momentum*v+p.grad+self.weight_decay*p.data<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p.data=p.data-self.lr*v</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A solu√ß√£o para o problema real</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora, temos todo o necess√°rio para treinar o modelo de rede neural (profunda) usando nossa biblioteca. </font><font style="vertical-align: inherit;">Para isso, precisamos das seguintes entidades:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelo: gr√°fico de c√°lculo.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dados e valor-alvo: dados para treinamento em rede.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fun√ß√£o de perda: substitui a meta de otimiza√ß√£o.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otimizador: um mecanismo para atualizar os par√¢metros do modelo.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O pseudo-c√≥digo a seguir descreve um ciclo de teste t√≠pico:</font></font><br>
<br>
<pre><code class="python hljs">model <span class="hljs-comment"># </span>
data,target <span class="hljs-comment"># </span>
loss_fn <span class="hljs-comment"># </span>
optim <span class="hljs-comment">#,         </span>
Repeat:<span class="hljs-comment">#   ,    ,     </span>
&nbsp;&nbsp;&nbsp;optim.zeroGrad() <span class="hljs-comment">#    </span>
&nbsp;&nbsp;&nbsp;output = model.forward(data) <span class="hljs-comment">#   </span>
&nbsp;&nbsp;&nbsp;loss &nbsp; = loss_fn(output,target) <span class="hljs-comment"># </span>
&nbsp;&nbsp;&nbsp;grad &nbsp; = loss.backward() <span class="hljs-comment">#      </span>
&nbsp;&nbsp;&nbsp;model.backward(grad) <span class="hljs-comment">#    </span>
&nbsp;&nbsp;&nbsp;optim.step() <span class="hljs-comment">#  </span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Embora isso n√£o seja necess√°rio na biblioteca de aprendizado profundo, pode ser √∫til incluir a funcionalidade acima em uma classe separada. </font><font style="vertical-align: inherit;">Isso nos permitir√° n√£o repetir as mesmas a√ß√µes ao aprender novos modelos (essa id√©ia corresponde √† filosofia das abstra√ß√µes de alto n√≠vel de estruturas como </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keras</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Para conseguir isso, declare uma classe </font></font><code>Model</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Model</span>():</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.computation_graph = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.parameters&nbsp; &nbsp; &nbsp; &nbsp; = []<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">add</span>(<span class="hljs-params">self,layer</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.computation_graph.append(layer)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.parameters+=layer.getParams()<font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__innitializeNetwork</span>(<span class="hljs-params">self</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> f.type==<span class="hljs-string">'linear'</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights,bias = f.getParams()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights.data = <span class="hljs-number">.01</span>*np.random.randn(weights.data.shape[<span class="hljs-number">0</span>],weights.data.shape[<span class="hljs-number">1</span>])<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bias.data&nbsp; &nbsp; = <span class="hljs-number">0.</span><font></font>
<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self,data,target,batch_size,num_epochs,optimizer,loss_fn</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss_history = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.__innitializeNetwork()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data_gen = DataGenerator(data,target,batch_size)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itr = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> X,Y <span class="hljs-keyword">in</span> data_gen:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.zeroGrad()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph: X=f.forward(X)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss = loss_fn.forward(X,Y)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grad = loss_fn.backward()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph[::<span class="hljs-number">-1</span>]: grad = f.backward(grad)&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss_history+=[loss]<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<span class="hljs-string">"Loss at epoch = {} and iteration = {}: {}"</span>.format(epoch,itr,loss_history[<span class="hljs-number">-1</span>]))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;itr+=<span class="hljs-number">1</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;optimizer.step()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> loss_history<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self,data</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;X = data<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> self.computation_graph: X = f.forward(X)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> X</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta classe inclui a seguinte funcionalidade:</font></font><br>
<br>
<ul>
<li>  :  <code>add()</code>   ,    .        <code>computation_graph</code>.</li>
<li> : ,   ,       ,    .</li>
<li> :    <code>fit()</code>       .       ,    .</li>
<li>  :  <code>predict()</code>   ,       ,   .</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como essa classe n√£o √© o alicerce b√°sico dos sistemas de aprendizado profundo, eu a implementei em um m√≥dulo separado </font></font><code>utilities.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Observe que o m√©todo </font></font><code>fit()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">usa uma classe </font></font><code>DataGenerator</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cuja implementa√ß√£o est√° no mesmo m√≥dulo. </font><font style="vertical-align: inherit;">Essa classe √© apenas um inv√≥lucro para dados de treinamento e gera minipacotes para cada itera√ß√£o de treinamento.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modelo de treinamento</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agora considere o √∫ltimo peda√ßo de c√≥digo no qual o modelo de rede neural √© treinado usando a biblioteca descrita acima. </font><font style="vertical-align: inherit;">Vou treinar uma rede multicamada em dados organizados em espiral. </font><font style="vertical-align: inherit;">Fui solicitado por </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">esta</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> publica√ß√£o. </font><font style="vertical-align: inherit;">C√≥digo para gerar esses dados e para a visualiza√ß√£o pode ser encontrada no arquivo </font></font><code>utilities.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/895/eb0/856/895eb085662368f9c1d171153a301fb0.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dados com tr√™s classes dispostas em espiral&nbsp;</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
A figura anterior mostra a visualiza√ß√£o dos dados nos quais iremos treinar o modelo. </font><font style="vertical-align: inherit;">Esses dados n√£o s√£o linearmente separ√°veis. </font><font style="vertical-align: inherit;">Podemos esperar que uma rede com uma camada oculta possa encontrar corretamente limites de decis√£o n√£o lineares. </font><font style="vertical-align: inherit;">Se voc√™ reunir tudo o que falamos, voc√™ obt√©m o seguinte fragmento de c√≥digo que permite treinar o modelo:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> dl_numpy <span class="hljs-keyword">as</span> DL
<span class="hljs-keyword">import</span> utilities<font></font>
<font></font>
batch_size&nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-number">20</span>
num_epochs&nbsp; &nbsp; &nbsp; &nbsp; = <span class="hljs-number">200</span>
samples_per_class = <span class="hljs-number">100</span>
num_classes &nbsp; &nbsp; &nbsp; = <span class="hljs-number">3</span>
hidden_units&nbsp; &nbsp; &nbsp; = <span class="hljs-number">100</span><font></font>
data,target &nbsp; &nbsp; &nbsp; = utilities.genSpiralData(samples_per_class,num_classes)<font></font>
model &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = utilities.Model()<font></font>
model.add(DL.Linear(<span class="hljs-number">2</span>,hidden_units))<font></font>
model.add(DL.ReLU())<font></font>
model.add(DL.Linear(hidden_units,num_classes))<font></font>
optim &nbsp; = DL.SGD(model.parameters,lr=<span class="hljs-number">1.0</span>,weight_decay=<span class="hljs-number">0.001</span>,momentum=<span class="hljs-number">.9</span>)<font></font>
loss_fn = DL.SoftmaxWithLoss()<font></font>
model.fit(data,target,batch_size,num_epochs,optim,loss_fn)<font></font>
predicted_labels = np.argmax(model.predict(data),axis=<span class="hljs-number">1</span>)<font></font>
accuracy &nbsp; &nbsp; &nbsp; &nbsp; = np.sum(predicted_labels==target)/len(target)<font></font>
print(<span class="hljs-string">"Model Accuracy = {}"</span>.format(accuracy))<font></font>
utilities.plot2DDataWithDecisionBoundary(data,target,model)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A imagem abaixo mostra os mesmos dados e os limites decisivos do modelo treinado.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/502/b0b/84f/502b0b84fee2c960c918494e8d63e33a.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dados e limites de decis√£o do modelo treinado</font></font></font></i><br>
 <br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sum√°rio</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dada a crescente complexidade dos modelos de aprendizado profundo, h√° uma tend√™ncia de aumentar os recursos das respectivas bibliotecas e aumentar a quantidade de c√≥digo necess√°ria para implementar esses recursos. Mas a funcionalidade mais b√°sica dessas bibliotecas ainda pode ser implementada de uma forma relativamente compacta. Embora a biblioteca que criamos possa ser usada para o treinamento de ponta a ponta de redes simples, ela ainda √©, de muitas maneiras, limitada. Estamos falando de limita√ß√µes no campo de recursos que permitem que estruturas de aprendizado profundo sejam usadas em √°reas como vis√£o de m√°quina, reconhecimento de fala e texto. Isso, √© claro, as possibilidades de tais estruturas n√£o s√£o limitadas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Acredito que todos possam participar do </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">projeto</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, o c√≥digo do qual examinamos aqui e, como exerc√≠cio, introduza nele o que eles gostariam de ver. </font><font style="vertical-align: inherit;">Aqui est√£o alguns mecanismos que voc√™ pode tentar se implementar:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Operadores: convolu√ß√£o, subamostragem.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otimizadores: Adam, RMSProp.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reguladores: BatchNorm, DropOut.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Espero que esse material tenha permitido que voc√™ veja pelo menos com o canto do olho o que est√° acontecendo nas entranhas das bibliotecas para aprendizado profundo. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Queridos leitores! </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quais bibliotecas de aprendizado profundo voc√™ usa?</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt486686/">https://habr.com/ru/post/pt486686/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt486676/index.html">Inevitabilidade da penetra√ß√£o do FPGA nos data centers</a></li>
<li><a href="../pt486678/index.html">Quartzo no n√∫cleo do ASP.NET</a></li>
<li><a href="../pt486680/index.html">ML, VR e rob√¥s (e um pouco de nuvem)</a></li>
<li><a href="../pt486682/index.html">Docker Compose: Simplifique usando Makefile</a></li>
<li><a href="../pt486684/index.html">Minha resposta para aqueles que acreditam que o valor do TDD √© exagerado</a></li>
<li><a href="../pt486688/index.html">Node.js, Tor, Puppeteer e Cheerio: raspagem an√¥nima da web</a></li>
<li><a href="../pt486690/index.html">5 dicas para escrever fun√ß√µes de seta com qualidade</a></li>
<li><a href="../pt486692/index.html">Recursos do console do Chrome que voc√™ talvez nunca tenha usado</a></li>
<li><a href="../pt486694/index.html">Not√≠cias do mundo do OpenStreetMap n¬∫ 496 (14/01/2020/20/01/2020)</a></li>
<li><a href="../pt486702/index.html">Eventos digitais em Moscou, de 3 a 9 de fevereiro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí∫ üë©‚Äçüë¶ üëåüèæ ITMO Research_ podcast: how to approach the synchronization of AR-content with the show on the scale of the whole stadium üö¢ üë®‚Äçüëß üéª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This is the first part of the text transcript of the second interview for our program ( Apple Podcasts , Yandex.Music ). Guest of release - Andrey Kar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ITMO Research_ podcast: how to approach the synchronization of AR-content with the show on the scale of the whole stadium</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/spbifmo/blog/504678/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is the first part of the text transcript of the second interview for our program ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apple Podcasts</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex.Music</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Guest of release - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrey Karsakov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kapc3d</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), Ph.D., senior researcher at the National Center for Cognitive Development, Associate Professor of the Department of Digital Transformations. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since 2012, Andrey has been working in the scientific group Visualization and Computer Graphics. </font><font style="vertical-align: inherit;">He is engaged in large-scale applied projects at the state and international level. </font><font style="vertical-align: inherit;">In this part of the conversation, we talk about his experience of AR-accompaniment of mass events.</font></font><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><img src="https://habrastorage.org/webt/rj/p5/xp/rjp5xp3nqieeb93gfgpwecl3k5i.jpeg"></a><a name="habracut"></a><br>
<sup><font color="#A9A9A9"><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Photo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ThisisEngineering RAEng</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Unsplash.com)</font></font></i></font></sup><br>
<br>
<hr><br>
<blockquote><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Project context and objectives</font></font></h3></blockquote><br>
<font color="#A9A9A9"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Timecode ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">audio version</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) - 00:41</font></font></font><br>
<br>
<hr><br>
<b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dmitrykabanov</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I would like to start with the European Games project. </font><font style="vertical-align: inherit;">It is multi-component, several teams participated in the preparation, and providing an augmented reality for a multi-thousand audience right during the event at the stadium is a rather serious task. </font><font style="vertical-align: inherit;">In terms of your participation, was this software in the first place?</font></font><br>
 <br>
<b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kapc3d</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yes, we made the software part and provided accompaniment during the show. It was necessary to monitor, monitor and launch everything in real time, and also to work with a television group. If we consider this project as a whole, we can talk about the opening and closing ceremonies of the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">European Games</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in Minsk, as well as about the opening ceremony of the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WorldSkills championship</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in Kazan. It was the same scheme of work, but different activities. Between them was a gap of two months. We prepared the project together with the guys from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sechenov.com</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Met them by chance at </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Science Fest</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">which took place in the fall of 2018. Our undergraduates showed their course project on the topic of VR. The guys approached us and asked what we were doing in our laboratory. It looked something like this: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- So you are working with VR, but are you able with augmented reality? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
‚ÄúWell, sort of, yes.‚Äù </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
- There is such a task, with such introductory ones. Can you do it?</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
We scratched our turnips a bit, there seems to be nothing unrealistic: </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Let's try to study everything in advance, and then we will find a solution. </font></font></i><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Do they only deal with media support? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Make a full stack. From the point of view of management and organization - they are fully engaged in directing, staging, selection of scenery, logistics and other technical support. But they wanted to do something special for the European Games. These special effects, such as mixed reality, have been doing for television for a long time, but they are not the most budgetary in terms of technical implementation. Therefore, the guys were looking for alternatives. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Let's discuss the problem in more detail. What was she like? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> There is an event. It lasts an hour and a half. We need to make sure that the audience who watches it live and those who are sitting in the stadium can see the effects with augmented reality with full synchronization with the live show in time and location on the site.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There were a number of technical limitations. It was impossible to do time synchronization via the Internet, because there were fears about the excessive load on the network with full stands and the prospect of attending the event by the heads of state, because of which mobile networks could jam. </font></font><br>
<br>
<sup><font color="#A9A9A9"><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrey Karsakov, photo from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ITMO University material</font></font></a></i></font></sup><br>
<img src="https://habrastorage.org/webt/cc/hn/zk/cchnzk6puivbybajyi8jjrzd4wu.jpeg" width="400" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We had two key components of this project - personal experience that people can get through mobile devices, and what goes on television broadcasting and information screens at the stadium itself. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If suddenly a person watches episodes of augmented reality through a mobile device and simultaneously hits the screen, he should see the same picture.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We needed two actually different systems to completely synchronize in time. But the peculiarity of such shows is that they are complex events, where a large number of technical services are involved and all operations are performed according to time codes. A time code is a specific point in time at which something starts: light, sound, people exit, opening stage petals, and so on. We had to adapt to this system so that everything would start at the right moment. Another feature was that scenes and episodes with augmented reality were scenically tied together. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But you still decided to abandon the use of time codes, because of the high risks of force majeure, or you initially calculated some power characteristics and realized that the load on the entire system would be quite high? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If you make a synchronization service for such an audience, then it is not very difficult. </font><font style="vertical-align: inherit;">Requests in any case will not fall at one time. </font><font style="vertical-align: inherit;">Yes, the load is high, but this is not an emergency. </font><font style="vertical-align: inherit;">The question is whether it is worth spending resources and time on it if the network is suddenly extinguished. </font><font style="vertical-align: inherit;">We were not sure that this would not happen. </font><font style="vertical-align: inherit;">Ultimately, everything worked, intermittently due to the load, but it worked, and we synchronized using the time code in a different way. </font><font style="vertical-align: inherit;">It was one of the global challenges.</font></font><br>
<br>
<hr><br>
<blockquote><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UX implementation challenges</font></font></h3></blockquote><br>
<font color="#A9A9A9"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Timecode ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">audio version</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) - 10:42</font></font></font><br>
<br>
<hr><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> We also had to consider that the stadium is not a classic concert venue, and synchronize the systems in space for mobile devices. So, some time ago, a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">story with augmented reality was</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> violated </font><font style="vertical-align: inherit;">at Eminem concerts, then there was a case with Loboda. </font></font><br>
<br>
<sup><font color="#A9A9A9"><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Photo by </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robert Bye</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Unsplash.com)</font></font></i></font></sup><br>
<img src="https://habrastorage.org/webt/jx/9s/ln/jx9slnnxhp34ash82x8hkng9pkc.jpeg" width="400" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But this is always an experience in front of you - the whole crowd is facing the scene, the synchronization is quite simple. In the case of the stadium, you need to understand which side you are on the circumference of, the relative position so that the stadium sits in the space that is in the virtual environment. It was a sour challenge. They tried to solve it in various ways, and we got a close case to what was implemented by Loboda, but not in everything.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We let the user decide where he is. They made the layout of the stadium, where people chose the sector, row, place. All this in four ‚Äúclicks‚Äù. Next, we had to determine the direction to the scene. To do this, we showed a silhouette of what a scene from a user angle should look like. He combined it, tapped and that's it - the scene sat down. We tried to simplify this process as much as possible. Still, 90% of viewers who wanted to watch the show are not the people who have experience with augmented reality. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Was there a separate application for this project? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yes, the application for iOS and Android, which we pushed to the side. There was a separate promotional campaign for it. It was previously described in detail how to download and more. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You need to understand that a person has nowhere to physically verify and learn how to use such an application. Therefore, the task of ‚Äútraining" the audience was complicated. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yes, yes. With UX, we caught a lot of cones, because the user wants the experience in three clicks: downloaded, installed, launched, it worked. Many are too lazy to go through complex tutorials, read training, and more. And we did not try to explain everything to the user in the tutorial as much as possible: a window will open here, access to the camera here, otherwise it will not work, and so on. No matter how many explanations you write, how much you chew in detail, whatever GIFs you insert, people don‚Äôt read this.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Minsk, we collected a large feedback pool for this part, and we have already changed a lot for the application in Kazan. </font><font style="vertical-align: inherit;">We drove there not only those phonograms and those time codes that correspond to a specific episode of augmented reality, but we took all the phonograms and time codes completely. </font><font style="vertical-align: inherit;">So the application heard what was happening at the time of launch, and - if the person hadn‚Äôt entered at that moment - it would give out information: "Comrade, I'm sorry, your AR episode will be in 15 minutes."</font></font><br>
<br>
<hr><br>
<blockquote><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A little bit about the architecture and approach to synchronization</font></font></h3></blockquote><br>
<font color="#A9A9A9"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Timecode ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">audio version</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) - 16:37</font></font></font><br>
<br>
<hr><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Still decided to do synchronization by sound? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yes, it happened by chance. We sorted through the options and came across a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cifrasoft</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> company </font><font style="vertical-align: inherit;">from Izhevsk. They do not really tricked out, but an iron-working SDK, which allows you to synchronize the sound with timing by sound. The system was positioned to work with TV, when you can output something in the application or give interactive content on the sound of conditional advertising. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But one thing is that you are sitting in your living room, and another is a multi-thousand stadium. How did you manage the quality of sound recording and its subsequent recognition? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There were many fears and doubts, but in most cases everything was recognized well. They build signatures on the soundtrack with their tricky algorithms - the total weighs less than the original audio file. When the microphone listens to ambient sound, it tries to find these features and recognize the track by them. In good conditions, the accuracy of synchronization is 0.1-0.2 seconds. That was more than enough. In poor conditions, the discrepancy was up to 0.5 seconds.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Much depends on the device. We worked with a large fleet of devices. For iPhones, these are just 10 models. They worked fine in terms of quality and other features. But with androids, the zoo is such that my mom. Not everywhere it turned out that sound synchronization worked. There were cases when on different devices, besides different tracks, it was impossible to hear because of some features. Somewhere low frequencies leave, somewhere high begin to wheeze. But if the device had a normalizer on the microphone, synchronization always worked. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Please tell us about architecture - what was used in the project? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We made the application on Unity - the easiest option in terms of multi-platform and graphics. Used AR Foundation. We immediately said that we would not like to complicate the system, so we limited ourselves to a fleet of devices that support ARKit and ARCore in order to have time to test everything. We made a plug-in for the Tsifirasoft SDK, it </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lies with us on GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . We made a content management system so that scripts run on a timeline.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We tinkered a bit with the particle system, because the user can log in at any time of a particular episode, and he needs to see everything from the moment from which he synchronized. Tinkering with a system that allows scripts to be played clearly in time so that a three-dimensional experience can be scrolled back and forth, like in a movie. If it works out of the box with classic animations, then I had to tinker with particle systems. At some point, they begin to spawn, and if you find yourself somewhere to the point of spawn, they have not yet been born, although they seem to be. But this problem, in fact, is easily solved.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For the mobile part, the architecture is quite simple. For broadcasting, everything is more complicated. We had limitations on iron. The condition was set from the customer: ‚ÄúHere we have such and such an iron park, roughly speaking, everything needs to work on it.‚Äù We immediately focused on the fact that we will work with relatively low-cost video capture cards. But budgetary does not mean that they are bad.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There was a restriction on hardware, on video capture cards and on working conditions - how we should get a picture. Capture cards - Blackmagic Design, worked according to the Internal keying scheme - this is when a video frame comes from the camera. The card has its own processing chip, which also has a frame that should be superimposed on top of the incoming one. The card mixes them - the more we touch nothing there and do not affect the frame from the video camera. The result through the video output, she spits out on the remote. This is a good method for applying captions and other similar things, but it is not very suitable for mixed reality effects, because there are many restrictions on the render pipeline. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In terms of real-time computing, object binding, or something else? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In terms of quality and achieving the desired effects. </font><font style="vertical-align: inherit;">Due to the fact that we do not know what overlay the image on top of. </font><font style="vertical-align: inherit;">We simply provide color and transparency information on top of the original stream. </font><font style="vertical-align: inherit;">Some effects like refractions, correct transparency, additional shadows with such a scheme cannot be achieved. </font><font style="vertical-align: inherit;">To do this, you need to render everything together. </font><font style="vertical-align: inherit;">For example, it will not work in any way to make the effect of air distortion from a fire or from hot asphalt. </font><font style="vertical-align: inherit;">The same with the transmission of the transparency effect taking into account the refractive index. </font><font style="vertical-align: inherit;">We initially made the content based on these restrictions, and tried to use the appropriate effects.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/gram.com/p/BzWbMrLokg4/embed/captioned/?cr=1&amp;v=12&amp;wp=658&amp;rd=https" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Did you have your content on the first project for the European Games? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> No, the main stage of content development was the guys from Sechenov.com. Their graphic artists drew basic content with animations and other things. And we integrated everything into the engine, added additional effects, adapted so that everything worked correctly.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If we talk about the pipeline, then for television we collected everything on Unreal Engine 4. It coincided that they just at that moment began to force their tools for mixed reality (mixed reality). </font><font style="vertical-align: inherit;">It turned out that everything is not so simple. </font><font style="vertical-align: inherit;">All tools are raw even now, we had to finish a lot manually. </font><font style="vertical-align: inherit;">In Minsk, we worked on a custom assembly of the engine, that is, we rewrote some things inside the engine so that, for example, we could draw shadows on top of real objects. </font><font style="vertical-align: inherit;">On that version of the engine, which was then relevant, there were no features that allowed this to be done using standard tools. </font><font style="vertical-align: inherit;">For this reason, our guys made their custom assembly in order to provide everything that was vital.</font></font><br>
<br>
<hr><br>
<blockquote><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Other nuances and adaptation to WorldSkills in Kazan</font></font></h3></blockquote><br>
<font color="#A9A9A9"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Timecode (for </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">audio version</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) - 31:37</font></font></font><br>
<br>
<hr><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But all this in a fairly short time? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The deadlines were for the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kazan project</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , for Minsk - normal. About six months to develop, but taking into account the fact that six people were involved. At the same time, they made the mobile part, developed tools for teleproduction. There was not only a picture output. For example, a tracking system with optics, for this it was necessary to do your own toolkit. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Was there an adaptation from one project to another? For a month and a half it was necessary to take advantage of developments and transfer the project with new content to a new site? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yes, it was a month and a half. We had planned a two-week vacation for the whole team after the Minsk project. But immediately after the closure, the guys from Sechenov.com come up and say: "Well, then let Kazan do it." We still managed to relax a bit, but switched to this project quickly enough. Completed something on the technical side. Most of the time was spent on content, because for WorldSkills we completely did it, just agreed with the director's team. There was only a script on their part. But it was easier - no extra iterations were needed. When you do the content yourself, you immediately see how it works in the engine, you can quickly edit and coordinate.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/4Uj1rUtb2vU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On the mobile part, we took into account all the subtleties that we had in Minsk. They made a new application design, reworked a bit of architecture, added tutorials, but tried to make it as short and clear as possible. Reduced the number of user steps from launching the application to viewing content. A month and a half was enough to make an adequate project. For a week and a half we went to the site. It was easier to work there, because all control over the project was in the hands of the organizers, it was not necessary to coordinate with other committees. It was easier and easier to work in Kazan and it was quite normal that there was less time. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dmitry:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But you decided to leave the approach to synchronization, as it was, by sound? </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yes, we left by the sound. It worked well. As they say, if it works, don‚Äôt touch it. We just took into account the nuances of the soundtrack quality. When they did the introduction, there was just a training episode so people could try before the show starts. It was surprising that when at the moment of playing a track at the stadium there is stormy applause, ‚Äúlive‚Äù, the system allows you to synchronize well on that track, but if the recorded applause is mixed with the track at that moment, the track ceases to be caught. These nuances were taken into account, and the sound was quite well synchronized. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS In the second part of the issue, we are talking about scientific visualization of data, modeling of processes in other projects, </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">game development</font></a><font style="vertical-align: inherit;"> and the master's program " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Technology for the development of computer games</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">". </font><font style="vertical-align: inherit;">We will publish the continuation in the following material. </font><font style="vertical-align: inherit;">You can listen and support us here:</font></font><br>
<br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apple podcasts</font></font></a></li>
</ul><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex.Music</font></font></a></li>
</ul><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Podfm</font></font></a></li>
</ul><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PPS Meanwhile, on the English version of Habr: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a closer look at ITMO University</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en504668/index.html">The digest of interesting materials for the mobile developer # 346 (May 25 - 31)</a></li>
<li><a href="../en504670/index.html">Unified State Exam in Computer Science or Suffering</a></li>
<li><a href="../en504672/index.html">DEVOXX UK. Kubernetes in production: Blue / Green deployment, autoscaling, and deployment automation. Part 2</a></li>
<li><a href="../en504674/index.html">Basis for a large modular SPA on Laravel + Vue + ElementUI with CRUD generator</a></li>
<li><a href="../en504676/index.html">Add a pinch of randomness to your game</a></li>
<li><a href="../en504680/index.html">Overview of SpaL's NLP Library</a></li>
<li><a href="../en504682/index.html">Nostalgia Post: j2me, Gravity Defied, 64kb</a></li>
<li><a href="../en504686/index.html">How to draw a cat</a></li>
<li><a href="../en504688/index.html">Masks are useless: scientific criticism of social policy at KOVID-19</a></li>
<li><a href="../en504690/index.html">The Tale of How I Configured Azure AD B2C on React and React Native Part 3 (Tutorial)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
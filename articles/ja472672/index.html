<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗼 ⚓️ 😢 「あなたのための記事を読む」という見出し。2019年7月〜9月 👩🏾‍💼 🔓 👨🏿‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは、ハブル！チャンネル#article_essenseから、Open Data Scienceコミュニティのメンバーによる科学記事のレビューを引き続き公開しています。誰よりも先に受け取りたい場合は、コミュニティに参加してください！
 

今日の記事：
 

1. Layer rotation...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>「あなたのための記事を読む」という見出し。2019年7月〜9月</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/472672/"><img src="https://habrastorage.org/webt/gx/-y/xl/gx-yxlo7xiz-5y8krpyoj3rgswq.png"><br>
<p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
こんにちは、ハブル！</font><font style="vertical-align: inherit;">チャンネル#article_essenseから、Open Data Scienceコミュニティのメンバーによる科学記事のレビューを引き続き公開しています。</font><font style="vertical-align: inherit;">誰よりも先に受け取りたい場合は、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">コミュニティに</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参加して</font><font style="vertical-align: inherit;">ください！</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">今日の記事：</font></font></p><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Layer rotation: a surprisingly powerful indicator of generalization in deep networks? (Université catholique de Louvain, Belgium, 2018)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Parameter-Efficient Transfer Learning for NLP (Google Research, Jagiellonian University, 2019) </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">RoBERTa: A Robustly Optimized BERT Pretraining Approach (University of Washington, Facebook AI, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (Google Research, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">How the Brain Transitions from Conscious to Subliminal Perception (USA, Argentina, Spain, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Large Memory Layers with Product Keys (Facebook AI Research, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches (Politecnico di Milano, University of Klagenfurt, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Omni-Scale Feature Learning for Person Re-Identification (University of Surrey, Queen Mary University, Samsung AI, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Neural reparameterization improves structural optimization (Google Research, 2019)</a></li>
</ol><a name="habracut"></a><br>
<div class="spoiler"><b class="spoiler_title">    :</b><div class="spoiler_text"><ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> —  2019</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> —  2018</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> 2017 —  2018</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> —  2017</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> 2017</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> 2017</a></li>
</ul></div></div><br>
<h3 id="1-layer-rotation-a-surprisingly-powerful-indicator-of-generalization-in-deep-networks">1. Layer rotation: a surprisingly powerful indicator of generalization in deep networks?</h3><br>
<p> : Simon Carbonnelle, Christophe De Vleeschouwer (Université catholique de Louvain, Belgium, 2018)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  error_derivative)</p><br>
<img src="https://habrastorage.org/webt/tt/n5/g8/ttn5g8j27-ihyqnwk0rowhg8oie.png" width="500" height="250"><br>
<p><br>
         : cosine distance         (       layer rotation).  ,     ,    1   ,      .      <strong>Layca</strong> (Layer-level Controlled Amount of weight rotation),    layer-wise learning rate    layer rotation.  ,     SGD       .           .</p><br>
<p> ,   : <strong>the larger the layer rotations, the better the generalization performance</strong>.        ,     :  MNIST, CIFAR-10/CIFAR-100, tiny ImageNet   ,      ResNet.</p><br>
<p>      :</p><br>
<ol>
<li><strong>Vanilla SGD</strong> ,         (       ), ,    : layer rotation     ;       .</li>
<li><strong>SGD + weight decay</strong>       :     ,       Layca.        .</li>
<li><strong>LR warmups</strong> ,  warmup  SGD    layer rotation, ,      Layca.</li>
<li><strong>Adaptive Gradient Methods</strong>    (         ,    SGD + weight decay) ,   layer rotation  :      ,     SGD —  .  ,         .    Layca     (           SGD).</li>
</ol><br>
<p>    .       1      MNIST,     ,     :   layer rotation        ,     .</p><br>
<p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   (tf/keras)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   .</a></p><br>
<h3 id="2-parameter-efficient-transfer-learning-for-nlp">2. Parameter-Efficient Transfer Learning for NLP</h3><br>
<p> : Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, Sylvain Gelly (Google Research, Jagiellonian University, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  zhirzemli)</p><br>
<img src="https://habrastorage.org/webt/ka/lg/gp/kalggpbjkmd8zc7ep451lysxpc8.png"><br>
<p><br>
   ,    fine-tuning’ NLP- (   BERT).   ,     ()   .    —    bottleneck’,         down-stream .        .</p><br>
<p><strong></strong><br>
  streaming- ( - ),  down-stream   —       . -, , -, , -,   ,    - :     .           :      .  ,         . ,    ,      ,    (~4%    )</p><br>
<p><strong></strong><br>
    :       2 .  layer-  transformer-based   skip-connection:  input (  )    input’.</p><br>
<p>    transformer  — 2.  —  multi-head attention’,  —  feed forward’.  ,        Adapter:    1-bottleneck     output’      input.  bottleneck   ,   output’  Input (skip-connection). ,      : 2md + m + d,  d —      , m —   bottleneck’ -. ,   BERT-base  (12 , 110 )    -bottlneck’ 128,    4.3%    </p><br>
<p><strong></strong><br>
     .           (   1 ),     — 3%   .     ,   ,    .</p><br>
<p><strong>Fine-Tuning</strong><br>
     dapter  (+    ).      near-identity .  ,         ,                ,     .</p><br>
<p>Learning rate   ,    finetuning’ BERT.       1e-04 lr.  , (   )         ,      clipping.  — Adam  warmup 10%</p><br>
<p><strong></strong><br>
     . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  Tensorflow</a>.<br>
 Torch    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">pytorch-transformers   Adapter-</a> (  README.md     )</p><br>
<h3 id="3-roberta-a-robustly-optimized-bert-pretraining-approach">3. RoBERTa: A Robustly Optimized BERT Pretraining Approach</h3><br>
<p> : Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov (University of Washington, Facebook AI, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  fuckai)</p><br>
<p>   BERT ,    GLUE   SOTA   NLP .        BERT   -    .</p><br>
<p>    BERT’:</p><br>
<ol>
<li>    10 ,  16 GB    160 GB</li>
<li>     </li>
<li>  next sentence prediction </li>
<li>  -  256   8</li>
<li> BPE       .</li>
</ol><br>
<p>     1024  Nvidia V100 (128 DGX-1 )   5 .</p><br>
<p><strong> :</strong></p><br>
<p><em>.</em>  Wiki   BookCorpus (16GB  ),     BERT,   3  ,   :</p><br>
<ol>
<li>-News 63    2.5   76GB</li>
<li>OpenWebText — ,   OpenAI  GPT2 .                . 38GB </li>
<li>Stories —    CommonCrawl  31GB</li>
</ol><br>
<p><em> .</em>   BERT’e     15%         .            .             ,    -   .    —       ,      .</p><br>
<p><em>Next Sentence Prediction objective.</em>          ?      —  SQuAD, MNLI, SST  RACE .</p><br>
<p><em>  -.</em>  ,    Machine Translation,  ,    -,     .       256 ,    BERT’e,  2k,     8k,  perplexity   ,    MNLI  SST-2 .</p><br>
<p><em>BPE.</em> BPE    BERT’a      subword units  .    ,              . OpenAI   GPT2     ,       subwords.   BPE   50k,      unknown .       BERT’   15   base    20  large,     5-10%.</p><br>
<p><strong>:</strong><br>
      BERT-large  XLNet-large.  RoBERTa -  ,   BERT-large.      GLUE .  single-task ,         GLUE    multi-task .  -  GLUE  single model ,  SOTA   9 .  -   , SOTA  4  9     glue .    SQuAD  - SOTA,  -   XLNet.     XLNet      QA     SQuAD.</p><br>
<img src="https://habrastorage.org/webt/5x/ue/u9/5xueu9hpmqwowfuf0yn1_zopqxy.png" width="500" height="250"><br>
<p><br>
SOTA  RACE ,     ,      4  ,    .       ,   ,   BERT,    CLF ,           .   4  —     .</p><br>
<p>     RoBERTa  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">fairseq </a>.  ,     . </p><br>
<h3 id="4-efficientnet-rethinking-model-scaling-for-convolutional-neural-networks">4. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h3><br>
<p> : Mingxing Tan, Quoc V. Le (Google Research, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  Alexander Denisenko)</p><br>
<img src="https://habrastorage.org/webt/ey/se/0k/eyse0kouanmvflpgz9ev--x1oqm.png" width="500" height="250"><br>
<p><br>
  ()         ( ) ,      .    ,    //.     MobileNet  ResNet.</p><br>
<p>  Neural Architecture Search       ,       – EfficientNets.       .  ImageNet EfficientNet-B7  state-of-the-art 84.4% top-1  97.1% top-5 accuracy,     8.4     6.1    ,      ConvNet.      –  SOTA  5  8   .</p><br>
<p><strong>Compound model scaling</strong><br>
 –            (      ) d,  (   ) w   r.        –   Accuracy(Net(d, w, r))  ,          FLOPS.</p><br>
<p>     ,         ,    .    FLOPS      ImageNet (  ).   ,   ,                    ,          .</p><br>
<p> compound scaling':  compound coefficient phi,       d, w  r: <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi><mo>=</mo><msup><mi>&amp;#x03B1;</mi><mi>&amp;#x03D5;</mi></msup><mo>,</mo><mi>w</mi><mo>=</mo><msup><mi>&amp;#x03B2;</mi><mi>&amp;#x03D5;</mi></msup><mo>,</mo><mi>r</mi><mo>=</mo><msup><mi>&amp;#x03B3;</mi><mi>&amp;#x03D5;</mi></msup><mo>,</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.679ex" height="2.884ex" viewBox="0 -916.9 10195.1 1241.8" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="801" y="0"></use><g transform="translate(1857,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B1" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="905" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="3019" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-77" x="3465" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="4459" y="0"></use><g transform="translate(5515,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B2" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="814" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="6613" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-72" x="7058" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="7787" y="0"></use><g transform="translate(8843,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B3" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="779" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="9916" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mo>=</mo><msup><mi>α</mi><mi>ϕ</mi></msup><mo>,</mo><mi>w</mi><mo>=</mo><msup><mi>β</mi><mi>ϕ</mi></msup><mo>,</mo><mi>r</mi><mo>=</mo><msup><mi>γ</mi><mi>ϕ</mi></msup><mo>,</mo></math></span></span><script type="math/tex" id="MathJax-Element-1">d = \alpha^\phi, w = \beta^\phi, r = \gamma^\phi,</script>  <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi><mo>,</mo><mi>&amp;#x03B2;</mi><mo>,</mo><mi>&amp;#x03B3;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.15ex" height="2.634ex" viewBox="0 -809.3 2647.8 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B1" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="640" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B2" x="1085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="1659" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B3" x="2104" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>α</mi><mo>,</mo><mi>β</mi><mo>,</mo><mi>γ</mi></math></span></span><script type="math/tex" id="MathJax-Element-2">\alpha, \beta, \gamma</script> – ,        . <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03D5;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.385ex" height="2.384ex" viewBox="0 -755.5 596.5 1026.6" role="img" focusable="false" style="vertical-align: -0.63ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϕ</mi></math></span></span><script type="math/tex" id="MathJax-Element-3">\phi</script> – ,     .</p><br>
<p><strong>Efficient-Net</strong><br>
    Multi-objective neural architecture search,  Accuracy  FLOPS  ,   -  .     EfficientNet-B0.  – Conv,     MBConv,   Conv11, Pool, FC.</p><br>
<p>     :</p><br>
<ol>
<li>   <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03D5;</mi><mo>=</mo><mn>1</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.646ex" height="2.384ex" viewBox="0 -755.5 2431.1 1026.6" role="img" focusable="false" style="vertical-align: -0.63ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="874" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-31" x="1930" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϕ</mi><mo>=</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-4">\phi = 1</script>,      <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi><mo>,</mo><mi>&amp;#x03B2;</mi><mo>,</mo><mi>&amp;#x03B3;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.15ex" height="2.634ex" viewBox="0 -809.3 2647.8 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B1" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="640" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B2" x="1085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="1659" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B3" x="2104" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>α</mi><mo>,</mo><mi>β</mi><mo>,</mo><mi>γ</mi></math></span></span><script type="math/tex" id="MathJax-Element-5">\alpha, \beta, \gamma</script>.</li>
<li> ,    d, w  r.  EffiientNet-B1. ,  <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03D5;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.385ex" height="2.384ex" viewBox="0 -755.5 596.5 1026.6" role="img" focusable="false" style="vertical-align: -0.63ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>ϕ</mi></math></span></span><script type="math/tex" id="MathJax-Element-6">\phi</script>,  EfficientNet-B2, … B7.</li>
</ol><br>
<p>    ResNet  MobileNet,      ImageNet, compound scaling           .     EfficientNet     ,   SOTA          . </p><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">.</a></p><br>
<h3 id="5-how-the-brain-transitions-from-conscious-to-subliminal-perception">5. How the Brain Transitions from Conscious to Subliminal Perception</h3><br>
<p> : Francesca Arese Lucini, Gino Del Ferraro, Mariano Sigman, Hernan A. Makse (USA, Argentina, Spain, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  error_derivative)</p><br>
<p>       <em>Dehaene, S, Naccache, L, Cohen, L, Le Bihan, D, Mangin, JF, Poline, JB, &amp; Rivie`re, D. Cerebral mechanisms of word masking and unconscious repetition priming</em>,           .</p><br>
<img src="https://habrastorage.org/webt/fi/o4/te/fio4terok3udte6bcmpajzfs_um.png" width="500" height="250"><br>
<p><br>
<strong>:</strong><br>
   (  4 ,   ,  ).     30 ms,      5 .</p><br>
<ol>
<li> «»       ,      .</li>
<li> «»     ,         . </li>
</ol><br>
<p><strong>:</strong><br>
          fMRI.     15 ,    5 ,  75 fMRI .  ,  voxel     ( : voxel —  3D ,     ) — 4x4x4mm.</p><br>
<p><strong>:</strong><br>
   voxel   .    —  ,       :    (   ).    :  cross-correlation matrix      ,       .       .</p><br>
<p>      «».     ,          (..         ).</p><br>
<p> :     -1,        .  —  -2,       . </p><br>
<p><strong>-2:</strong><br>
k-Core .  k-core       :  ,       k .       ,   k .      ,   ,    . ,  ,   k-core . </p><br>
<p><strong>:</strong><br>
     ,      .</p><br>
<ol>
<li>   k-core  /  k  .     k , .      U shape,          (   ,     ).</li>
<li><strong>  </strong> ,  k-core   k        .   k-core    k      ,      <em>fusiform gyrus &amp; left precentral gyrus</em>.          .</li>
</ol><br>
<p>          ,   rewiring,       (  ,      ).          k.  , U shape          ,       ,        .</p><br>
<p><strong>:</strong><br>
,  ,   ,              .     ,     ,      ,    -     (     , , ,     ).</p><br>
<p> ,   ,         ,       ,        ,         , ,    - . , ,            qualia.</p><br>
<h3 id="6-large-memory-layers-with-product-keys">6. Large Memory Layers with Product Keys</h3><br>
<p> : Guillaume Lample, Alexandre Sablayrolles, Marc'Aurelio Ranzato, Ludovic Denoyer, Hervé Jégou (Facebook AI Research, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  belerafon)</p><br>
<img src="https://habrastorage.org/webt/4b/_q/nm/4b_qnmw2tilj5zyscirkrogerrg.png"><br>
<p><br>
,       key-value        ,   .</p><br>
<p>    -    attention.    q,     k   v.  q,    k,    ,      value  .  ,       .    ,         .      ,         ,   .     -    q       (, -10).        .      .</p><br>
<p>   —     q   k   .   ,    "Product Keys".      ,         q   ,     .        -10   , ,     O(N)    ""  ,   (sqrt(N)).</p><br>
<p>        key-value .      ,    (  ,     ). ,   BERT      28  . ,          ,     .  : 12-       2  ,  24-  ,    perplexity     .</p><br>
<p>           (      self-attention). ,     -         .  ,         multy-head attention. ..    query  ,      value,     .         -.</p><br>
<p>       , ,        ,    ,    BERT  .      .</p><br>
<h3 id="7-are-we-really-making-much-progress-a-worrying-analysis-of-recent-neural-recommendation-approaches">7. Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches</h3><br>
<p> : Maurizio Ferrari Dacrema, Paolo Cremonesi, Dietmar Jannach (Politecnico di Milano, University of Klagenfurt, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 :   (  netcitizen)</p><br>
<img src="https://habrastorage.org/webt/zk/89/wu/zk89wuyudxpggdl6-0tyxe2wwrw.png"><br>
<p><br>
      DL    , ,             .</p><br>
<p><strong></strong><br>
            DL       top-n.    DL      KDD, SIGIR, TheWebConf (WWW)  RecSys     :</p><br>
<ol>
<li>   </li>
<li>   -      </li>
<li>     </li>
</ol><br>
<p><strong></strong></p><br>
<ol>
<li>   7/18 (39%)</li>
<li>       “”    train/test,     .,   , ,   .</li>
<li>    (Variational Autoencoders for Collaborative Filtering (Mult-VAE)  ±   )     KNN, SVD, PR.</li>
</ol><br>
<p><strong></strong><br>
 DL,       CV, NLP      ,       .</p><br>
<h3 id="8-omni-scale-feature-learning-for-person-re-identification">8. Omni-Scale Feature Learning for Person Re-Identification</h3><br>
<p> : Kaiyang Zhou, Yongxin Yang, Andrea Cavallaro, Tao Xiang (University of Surrey, Queen Mary University, Samsung AI, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a> (  graviton)</p><br>
<p> Person Re-Identification,    Face Recognition,    ,          .  (Kaiyang Zhou)        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">deep-person-reid</a>     ,      (OSNet),          Person Re-Identification.     .</p><br>
<p><strong>  </strong> Person Re-Identification:</p><br>
<img src="https://habrastorage.org/webt/6d/rq/jv/6drqjvwsyg33s_e7zv2t4nov0ts.png" width="500" height="250"><br>
<p><br>
<strong> :</strong></p><br>
<ol>
<li>  conv1x1  deepwise conv3x3   conv3x3   (figure 3).</li>
<li> ,      .    ResNeXt         ,     Inception      (figure 4).</li>
<li>     “aggregation gate”       .  ,    Inception     .</li>
</ol><br>
<img src="https://habrastorage.org/webt/ic/tc/9z/ictc9z6mcdkv3o0i23swu_f5zty.png"><br>
<p><br>
 OSNet       , ..      ,    :      (  ,  )   .</p><br>
<p><strong>  ReID </strong>  OSNet ( 2  )         (Market: R1 93.6%, mAP 81.0%  OSNet  R1 87.0%, mAP 69.5%  MobileNetV2)          ResNet  DenseNet (Market: R1 94.8%, mAP 84.9%  OSNet  R1 94.8%, mAP 86.0%  ResNet).</p><br>
<p>     <strong> </strong>:          . OSNet          “unsupervised domain adaptation” (          ).</p><br>
<p>    ImageNet,       MobileNetV2    ,    .</p><br>
<h3 id="9-neural-reparameterization-improves-structural-optimization">9. Neural reparameterization improves structural optimization</h3><br>
<p> : Stephan Hoyer, Jascha Sohl-Dickstein, Sam Greydanus (Google Research, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">→  </a><br>
 : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a> (  Arech)</p><br>
<img src="https://habrastorage.org/webt/ga/sd/hd/gasdhdqgy5febp9elrdgdhy9nqg.png"><br>
<p><br>
        / - .  ,      , ,   // / /,          .   ""  , — ,      .</p><br>
<p>     ?  :        (  UNet),       ,           ,    —  (,   , — ) . ,    ,    ,            .            .</p><br>
<p>    (     )       ,     —    (  99  66  116 ).          ,   .</p><br>
<p>..            ,   (  )         (          ). </p><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> .</a></p><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">      habr.</a></p></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja472658/index.html">未来についてのほぼすべてHolyJS 2019モスクワ</a></li>
<li><a href="../ja472660/index.html">デバイスのプロトタイプをすばやく作成する方法とそれが重要な理由。Yandex.Taxiを報告する</a></li>
<li><a href="../ja472662/index.html">誰と輸出に行くか</a></li>
<li><a href="../ja472668/index.html">製品思考。それは何であり、どのように開発するか</a></li>
<li><a href="../ja472670/index.html">ライムリー秋、ライムリー冬...</a></li>
<li><a href="../ja472674/index.html">Pythonプロジェクトの環境変数</a></li>
<li><a href="../ja472676/index.html">Slack、Jira、青い電気テープのみを使用して、メインチームを支援するためのジョーンズ部門を作成します</a></li>
<li><a href="../ja472682/index.html">C. elegansの薬物シナジーによる老化の減速</a></li>
<li><a href="../ja472684/index.html">fsync（）PostgreSQLへのサプライズ</a></li>
<li><a href="../ja472686/index.html">I486ベースのビデオスタジオ</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
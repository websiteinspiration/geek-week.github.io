<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ—¼ âš“ï¸ ğŸ˜¢ ã€Œã‚ãªãŸã®ãŸã‚ã®è¨˜äº‹ã‚’èª­ã‚€ã€ã¨ã„ã†è¦‹å‡ºã—ã€‚2019å¹´7æœˆã€œ9æœˆ ğŸ‘©ğŸ¾â€ğŸ’¼ ğŸ”“ ğŸ‘¨ğŸ¿â€ğŸ­</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ã“ã‚“ã«ã¡ã¯ã€ãƒãƒ–ãƒ«ï¼ãƒãƒ£ãƒ³ãƒãƒ«#article_essenseã‹ã‚‰ã€Open Data Scienceã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒ¡ãƒ³ãƒãƒ¼ã«ã‚ˆã‚‹ç§‘å­¦è¨˜äº‹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å¼•ãç¶šãå…¬é–‹ã—ã¦ã„ã¾ã™ã€‚èª°ã‚ˆã‚Šã‚‚å…ˆã«å—ã‘å–ã‚ŠãŸã„å ´åˆã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ ã—ã¦ãã ã•ã„ï¼
 

ä»Šæ—¥ã®è¨˜äº‹ï¼š
 

1. Layer rotation...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ã€Œã‚ãªãŸã®ãŸã‚ã®è¨˜äº‹ã‚’èª­ã‚€ã€ã¨ã„ã†è¦‹å‡ºã—ã€‚2019å¹´7æœˆã€œ9æœˆ</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/472672/"><img src="https://habrastorage.org/webt/gx/-y/xl/gx-yxlo7xiz-5y8krpyoj3rgswq.png"><br>
<p><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ã“ã‚“ã«ã¡ã¯ã€ãƒãƒ–ãƒ«ï¼</font><font style="vertical-align: inherit;">ãƒãƒ£ãƒ³ãƒãƒ«#article_essenseã‹ã‚‰ã€Open Data Scienceã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒ¡ãƒ³ãƒãƒ¼ã«ã‚ˆã‚‹ç§‘å­¦è¨˜äº‹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å¼•ãç¶šãå…¬é–‹ã—ã¦ã„ã¾ã™ã€‚</font><font style="vertical-align: inherit;">èª°ã‚ˆã‚Šã‚‚å…ˆã«å—ã‘å–ã‚ŠãŸã„å ´åˆã¯ã€</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">å‚åŠ ã—ã¦</font><font style="vertical-align: inherit;">ãã ã•ã„ï¼</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ä»Šæ—¥ã®è¨˜äº‹ï¼š</font></font></p><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Layer rotation: a surprisingly powerful indicator of generalization in deep networks? (UniversitÃ© catholique de Louvain, Belgium, 2018)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Parameter-Efficient Transfer Learning for NLP (Google Research, Jagiellonian University, 2019) </a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">RoBERTa: A Robustly Optimized BERT Pretraining Approach (University of Washington, Facebook AI, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks (Google Research, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">How the Brain Transitions from Conscious to Subliminal Perception (USA, Argentina, Spain, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Large Memory Layers with Product Keys (Facebook AI Research, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches (Politecnico di Milano, University of Klagenfurt, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Omni-Scale Feature Learning for Person Re-Identification (University of Surrey, Queen Mary University, Samsung AI, 2019)</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">Neural reparameterization improves structural optimization (Google Research, 2019)</a></li>
</ol><a name="habracut"></a><br>
<div class="spoiler"><b class="spoiler_title">    :</b><div class="spoiler_text"><ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> â€”  2019</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> â€”  2018</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> 2017 â€”  2018</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> â€”  2017</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> 2017</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> 2017</a></li>
</ul></div></div><br>
<h3 id="1-layer-rotation-a-surprisingly-powerful-indicator-of-generalization-in-deep-networks">1. Layer rotation: a surprisingly powerful indicator of generalization in deep networks?</h3><br>
<p> : Simon Carbonnelle, Christophe De Vleeschouwer (UniversitÃ© catholique de Louvain, Belgium, 2018)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  error_derivative)</p><br>
<img src="https://habrastorage.org/webt/tt/n5/g8/ttn5g8j27-ihyqnwk0rowhg8oie.png" width="500" height="250"><br>
<p><br>
         : cosine distance         (       layer rotation).  ,     ,    1   ,      .      <strong>Layca</strong> (Layer-level Controlled Amount of weight rotation),    layer-wise learning rate    layer rotation.  ,     SGD       .           .</p><br>
<p> ,   : <strong>the larger the layer rotations, the better the generalization performance</strong>.        ,     :  MNIST, CIFAR-10/CIFAR-100, tiny ImageNet   ,      ResNet.</p><br>
<p>      :</p><br>
<ol>
<li><strong>Vanilla SGD</strong> ,         (       ), ,    : layer rotation     ;       .</li>
<li><strong>SGD + weight decay</strong>       :     ,       Layca.        .</li>
<li><strong>LR warmups</strong> ,  warmup  SGD    layer rotation, ,      Layca.</li>
<li><strong>Adaptive Gradient Methods</strong>    (         ,    SGD + weight decay) ,   layer rotation  :      ,     SGD â€”  .  ,         .    Layca     (           SGD).</li>
</ol><br>
<p>    .       1      MNIST,     ,     :   layer rotation        ,     .</p><br>
<p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   (tf/keras)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">   .</a></p><br>
<h3 id="2-parameter-efficient-transfer-learning-for-nlp">2. Parameter-Efficient Transfer Learning for NLP</h3><br>
<p> : Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, Sylvain Gelly (Google Research, Jagiellonian University, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  zhirzemli)</p><br>
<img src="https://habrastorage.org/webt/ka/lg/gp/kalggpbjkmd8zc7ep451lysxpc8.png"><br>
<p><br>
   ,    fine-tuningâ€™ NLP- (   BERT).   ,     ()   .    â€”    bottleneckâ€™,         down-stream .        .</p><br>
<p><strong></strong><br>
  streaming- ( - ),  down-stream   â€”       . -, , -, , -,   ,    - :     .           :      .  ,         . ,    ,      ,    (~4%    )</p><br>
<p><strong></strong><br>
    :       2 .  layer-  transformer-based   skip-connection:  input (  )    inputâ€™.</p><br>
<p>    transformer  â€” 2.  â€”  multi-head attentionâ€™,  â€”  feed forwardâ€™.  ,        Adapter:    1-bottleneck     outputâ€™      input.  bottleneck   ,   outputâ€™  Input (skip-connection). ,      : 2md + m + d,  d â€”      , m â€”   bottleneckâ€™ -. ,   BERT-base  (12 , 110 )    -bottlneckâ€™ 128,    4.3%    </p><br>
<p><strong></strong><br>
     .           (   1 ),     â€” 3%   .     ,   ,    .</p><br>
<p><strong>Fine-Tuning</strong><br>
     dapter  (+    ).      near-identity .  ,         ,                ,     .</p><br>
<p>Learning rate   ,    finetuningâ€™ BERT.       1e-04 lr.  , (   )         ,      clipping.  â€” Adam  warmup 10%</p><br>
<p><strong></strong><br>
     . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">  Tensorflow</a>.<br>
 Torch    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">pytorch-transformers   Adapter-</a> (  README.md     )</p><br>
<h3 id="3-roberta-a-robustly-optimized-bert-pretraining-approach">3. RoBERTa: A Robustly Optimized BERT Pretraining Approach</h3><br>
<p> : Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov (University of Washington, Facebook AI, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  fuckai)</p><br>
<p>   BERT ,    GLUE   SOTA   NLP .        BERT   -    .</p><br>
<p>    BERTâ€™:</p><br>
<ol>
<li>    10 ,  16 GB    160 GB</li>
<li>     </li>
<li>  next sentence prediction </li>
<li>  -  256   8</li>
<li> BPE       .</li>
</ol><br>
<p>     1024  Nvidia V100 (128 DGX-1 )   5 .</p><br>
<p><strong> :</strong></p><br>
<p><em>.</em>  Wiki   BookCorpus (16GB  ),     BERT,   3  ,   :</p><br>
<ol>
<li>-News 63    2.5   76GB</li>
<li>OpenWebText â€” ,   OpenAI  GPT2 .                . 38GB </li>
<li>Stories â€”    CommonCrawl  31GB</li>
</ol><br>
<p><em> .</em>   BERTâ€™e     15%         .            .             ,    -   .    â€”       ,      .</p><br>
<p><em>Next Sentence Prediction objective.</em>          ?      â€”  SQuAD, MNLI, SST  RACE .</p><br>
<p><em>  -.</em>  ,    Machine Translation,  ,    -,     .       256 ,    BERTâ€™e,  2k,     8k,  perplexity   ,    MNLI  SST-2 .</p><br>
<p><em>BPE.</em> BPE    BERTâ€™a      subword units  .    ,              . OpenAI   GPT2     ,       subwords.   BPE   50k,      unknown .       BERTâ€™   15   base    20  large,     5-10%.</p><br>
<p><strong>:</strong><br>
      BERT-large  XLNet-large.  RoBERTa -  ,   BERT-large.      GLUE .  single-task ,         GLUE    multi-task .  -  GLUE  single model ,  SOTA   9 .  -   , SOTA  4  9     glue .    SQuAD  - SOTA,  -   XLNet.     XLNet      QA     SQuAD.</p><br>
<img src="https://habrastorage.org/webt/5x/ue/u9/5xueu9hpmqwowfuf0yn1_zopqxy.png" width="500" height="250"><br>
<p><br>
SOTA  RACE ,     ,      4  ,    .       ,   ,   BERT,    CLF ,           .   4  â€”     .</p><br>
<p>     RoBERTa  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">fairseq </a>.  ,     . </p><br>
<h3 id="4-efficientnet-rethinking-model-scaling-for-convolutional-neural-networks">4. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h3><br>
<p> : Mingxing Tan, Quoc V. Le (Google Research, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  Alexander Denisenko)</p><br>
<img src="https://habrastorage.org/webt/ey/se/0k/eyse0kouanmvflpgz9ev--x1oqm.png" width="500" height="250"><br>
<p><br>
  ()         ( ) ,      .    ,    //.     MobileNet  ResNet.</p><br>
<p>  Neural Architecture Search       ,       â€“ EfficientNets.       .  ImageNet EfficientNet-B7  state-of-the-art 84.4% top-1  97.1% top-5 accuracy,     8.4     6.1    ,      ConvNet.      â€“  SOTA  5  8   .</p><br>
<p><strong>Compound model scaling</strong><br>
 â€“            (      ) d,  (   ) w   r.        â€“   Accuracy(Net(d, w, r))  ,          FLOPS.</p><br>
<p>     ,         ,    .    FLOPS      ImageNet (  ).   ,   ,                    ,          .</p><br>
<p> compound scaling':  compound coefficient phi,       d, w  r: <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>d</mi><mo>=</mo><msup><mi>&amp;#x03B1;</mi><mi>&amp;#x03D5;</mi></msup><mo>,</mo><mi>w</mi><mo>=</mo><msup><mi>&amp;#x03B2;</mi><mi>&amp;#x03D5;</mi></msup><mo>,</mo><mi>r</mi><mo>=</mo><msup><mi>&amp;#x03B3;</mi><mi>&amp;#x03D5;</mi></msup><mo>,</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.679ex" height="2.884ex" viewBox="0 -916.9 10195.1 1241.8" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-64" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="801" y="0"></use><g transform="translate(1857,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B1" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="905" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="3019" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-77" x="3465" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="4459" y="0"></use><g transform="translate(5515,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B2" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="814" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="6613" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-72" x="7058" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="7787" y="0"></use><g transform="translate(8843,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B3" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="779" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="9916" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>d</mi><mo>=</mo><msup><mi>Î±</mi><mi>Ï•</mi></msup><mo>,</mo><mi>w</mi><mo>=</mo><msup><mi>Î²</mi><mi>Ï•</mi></msup><mo>,</mo><mi>r</mi><mo>=</mo><msup><mi>Î³</mi><mi>Ï•</mi></msup><mo>,</mo></math></span></span><script type="math/tex" id="MathJax-Element-1">d = \alpha^\phi, w = \beta^\phi, r = \gamma^\phi,</script>  <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi><mo>,</mo><mi>&amp;#x03B2;</mi><mo>,</mo><mi>&amp;#x03B3;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.15ex" height="2.634ex" viewBox="0 -809.3 2647.8 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B1" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="640" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B2" x="1085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="1659" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B3" x="2104" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Î±</mi><mo>,</mo><mi>Î²</mi><mo>,</mo><mi>Î³</mi></math></span></span><script type="math/tex" id="MathJax-Element-2">\alpha, \beta, \gamma</script> â€“ ,        . <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03D5;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.385ex" height="2.384ex" viewBox="0 -755.5 596.5 1026.6" role="img" focusable="false" style="vertical-align: -0.63ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Ï•</mi></math></span></span><script type="math/tex" id="MathJax-Element-3">\phi</script> â€“ ,     .</p><br>
<p><strong>Efficient-Net</strong><br>
    Multi-objective neural architecture search,  Accuracy  FLOPS  ,   -  .     EfficientNet-B0.  â€“ Conv,     MBConv,   Conv11, Pool, FC.</p><br>
<p>     :</p><br>
<ol>
<li>   <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03D5;</mi><mo>=</mo><mn>1</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.646ex" height="2.384ex" viewBox="0 -755.5 2431.1 1026.6" role="img" focusable="false" style="vertical-align: -0.63ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-3D" x="874" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-31" x="1930" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Ï•</mi><mo>=</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-4">\phi = 1</script>,      <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03B1;</mi><mo>,</mo><mi>&amp;#x03B2;</mi><mo>,</mo><mi>&amp;#x03B3;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.15ex" height="2.634ex" viewBox="0 -809.3 2647.8 1134.2" role="img" focusable="false" style="vertical-align: -0.755ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B1" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="640" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B2" x="1085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMAIN-2C" x="1659" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3B3" x="2104" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Î±</mi><mo>,</mo><mi>Î²</mi><mo>,</mo><mi>Î³</mi></math></span></span><script type="math/tex" id="MathJax-Element-5">\alpha, \beta, \gamma</script>.</li>
<li> ,    d, w  r.  EffiientNet-B1. ,  <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>&amp;#x03D5;</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.385ex" height="2.384ex" viewBox="0 -755.5 596.5 1026.6" role="img" focusable="false" style="vertical-align: -0.63ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=https://habr.com/ru/company/ods/blog/472672/&amp;usg=ALkJrhjclzzJeRLkuFNff-tSlH_MaYljiA#MJMATHI-3D5" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Ï•</mi></math></span></span><script type="math/tex" id="MathJax-Element-6">\phi</script>,  EfficientNet-B2, â€¦ B7.</li>
</ol><br>
<p>    ResNet  MobileNet,      ImageNet, compound scaling           .     EfficientNet     ,   SOTA          . </p><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">.</a></p><br>
<h3 id="5-how-the-brain-transitions-from-conscious-to-subliminal-perception">5. How the Brain Transitions from Conscious to Subliminal Perception</h3><br>
<p> : Francesca Arese Lucini, Gino Del Ferraro, Mariano Sigman, Hernan A. Makse (USA, Argentina, Spain, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  error_derivative)</p><br>
<p>       <em>Dehaene, S, Naccache, L, Cohen, L, Le Bihan, D, Mangin, JF, Poline, JB, &amp; Rivie`re, D. Cerebral mechanisms of word masking and unconscious repetition priming</em>,           .</p><br>
<img src="https://habrastorage.org/webt/fi/o4/te/fio4terok3udte6bcmpajzfs_um.png" width="500" height="250"><br>
<p><br>
<strong>:</strong><br>
   (  4 ,   ,  ).     30 ms,      5 .</p><br>
<ol>
<li> Â«Â»       ,      .</li>
<li> Â«Â»     ,         . </li>
</ol><br>
<p><strong>:</strong><br>
          fMRI.     15 ,    5 ,  75 fMRI .  ,  voxel     ( : voxel â€”  3D ,     ) â€” 4x4x4mm.</p><br>
<p><strong>:</strong><br>
   voxel   .    â€”  ,       :    (   ).    :  cross-correlation matrix      ,       .       .</p><br>
<p>      Â«Â».     ,          (..         ).</p><br>
<p> :     -1,        .  â€”  -2,       . </p><br>
<p><strong>-2:</strong><br>
k-Core .  k-core       :  ,       k .       ,   k .      ,   ,    . ,  ,   k-core . </p><br>
<p><strong>:</strong><br>
     ,      .</p><br>
<ol>
<li>   k-core  /  k  .     k , .      U shape,          (   ,     ).</li>
<li><strong>  </strong> ,  k-core   k        .   k-core    k      ,      <em>fusiform gyrus &amp; left precentral gyrus</em>.          .</li>
</ol><br>
<p>          ,   rewiring,       (  ,      ).          k.  , U shape          ,       ,        .</p><br>
<p><strong>:</strong><br>
,  ,   ,              .     ,     ,      ,    -     (     , , ,     ).</p><br>
<p> ,   ,         ,       ,        ,         , ,    - . , ,            qualia.</p><br>
<h3 id="6-large-memory-layers-with-product-keys">6. Large Memory Layers with Product Keys</h3><br>
<p> : Guillaume Lample, Alexandre Sablayrolles, Marc'Aurelio Ranzato, Ludovic Denoyer, HervÃ© JÃ©gou (Facebook AI Research, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  belerafon)</p><br>
<img src="https://habrastorage.org/webt/4b/_q/nm/4b_qnmw2tilj5zyscirkrogerrg.png"><br>
<p><br>
,       key-value        ,   .</p><br>
<p>    -    attention.    q,     k   v.  q,    k,    ,      value  .  ,       .    ,         .      ,         ,   .     -    q       (, -10).        .      .</p><br>
<p>   â€”     q   k   .   ,    "Product Keys".      ,         q   ,     .        -10   , ,     O(N)    ""  ,   (sqrt(N)).</p><br>
<p>        key-value .      ,    (  ,     ). ,   BERT      28  . ,          ,     .  : 12-       2  ,  24-  ,    perplexity     .</p><br>
<p>           (      self-attention). ,     -         .  ,         multy-head attention. ..    query  ,      value,     .         -.</p><br>
<p>       , ,        ,    ,    BERT  .      .</p><br>
<h3 id="7-are-we-really-making-much-progress-a-worrying-analysis-of-recent-neural-recommendation-approaches">7. Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches</h3><br>
<p> : Maurizio Ferrari Dacrema, Paolo Cremonesi, Dietmar Jannach (Politecnico di Milano, University of Klagenfurt, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 :   (  netcitizen)</p><br>
<img src="https://habrastorage.org/webt/zk/89/wu/zk89wuyudxpggdl6-0tyxe2wwrw.png"><br>
<p><br>
      DL    , ,             .</p><br>
<p><strong></strong><br>
            DL       top-n.    DL      KDD, SIGIR, TheWebConf (WWW)  RecSys     :</p><br>
<ol>
<li>   </li>
<li>   -      </li>
<li>     </li>
</ol><br>
<p><strong></strong></p><br>
<ol>
<li>   7/18 (39%)</li>
<li>       â€œâ€    train/test,     .,   , ,   .</li>
<li>    (Variational Autoencoders for Collaborative Filtering (Mult-VAE)  Â±   )     KNN, SVD, PR.</li>
</ol><br>
<p><strong></strong><br>
 DL,       CV, NLP      ,       .</p><br>
<h3 id="8-omni-scale-feature-learning-for-person-re-identification">8. Omni-Scale Feature Learning for Person Re-Identification</h3><br>
<p> : Kaiyang Zhou, Yongxin Yang, Andrea Cavallaro, Tao Xiang (University of Surrey, Queen Mary University, Samsung AI, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> </a> (  graviton)</p><br>
<p> Person Re-Identification,    Face Recognition,    ,          .  (Kaiyang Zhou)        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">deep-person-reid</a>     ,      (OSNet),          Person Re-Identification.     .</p><br>
<p><strong>  </strong> Person Re-Identification:</p><br>
<img src="https://habrastorage.org/webt/6d/rq/jv/6drqjvwsyg33s_e7zv2t4nov0ts.png" width="500" height="250"><br>
<p><br>
<strong> :</strong></p><br>
<ol>
<li>  conv1x1  deepwise conv3x3   conv3x3   (figure 3).</li>
<li> ,      .    ResNeXt         ,     Inception      (figure 4).</li>
<li>     â€œaggregation gateâ€       .  ,    Inception     .</li>
</ol><br>
<img src="https://habrastorage.org/webt/ic/tc/9z/ictc9z6mcdkv3o0i23swu_f5zty.png"><br>
<p><br>
 OSNet       , ..      ,    :      (  ,  )   .</p><br>
<p><strong>  ReID </strong>  OSNet ( 2  )         (Market: R1 93.6%, mAP 81.0%  OSNet  R1 87.0%, mAP 69.5%  MobileNetV2)          ResNet  DenseNet (Market: R1 94.8%, mAP 84.9%  OSNet  R1 94.8%, mAP 86.0%  ResNet).</p><br>
<p>     <strong> </strong>:          . OSNet          â€œunsupervised domain adaptationâ€ (          ).</p><br>
<p>    ImageNet,       MobileNetV2    ,    .</p><br>
<h3 id="9-neural-reparameterization-improves-structural-optimization">9. Neural reparameterization improves structural optimization</h3><br>
<p> : Stephan Hoyer, Jascha Sohl-Dickstein, Sam Greydanus (Google Research, 2019)<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">â†’  </a><br>
 : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a> (  Arech)</p><br>
<img src="https://habrastorage.org/webt/ga/sd/hd/gasdhdqgy5febp9elrdgdhy9nqg.png"><br>
<p><br>
        / - .  ,      , ,   // / /,          .   ""  , â€” ,      .</p><br>
<p>     ?  :        (  UNet),       ,           ,    â€”  (,   , â€” ) . ,    ,    ,            .            .</p><br>
<p>    (     )       ,     â€”    (  99  66  116 ).          ,   .</p><br>
<p>..            ,   (  )         (          ). </p><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="> .</a></p><br>
<p><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">      habr.</a></p></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja472658/index.html">æœªæ¥ã«ã¤ã„ã¦ã®ã»ã¼ã™ã¹ã¦HolyJS 2019ãƒ¢ã‚¹ã‚¯ãƒ¯</a></li>
<li><a href="../ja472660/index.html">ãƒ‡ãƒã‚¤ã‚¹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ã™ã°ã‚„ãä½œæˆã™ã‚‹æ–¹æ³•ã¨ãã‚ŒãŒé‡è¦ãªç†ç”±ã€‚Yandex.Taxiã‚’å ±å‘Šã™ã‚‹</a></li>
<li><a href="../ja472662/index.html">èª°ã¨è¼¸å‡ºã«è¡Œãã‹</a></li>
<li><a href="../ja472668/index.html">è£½å“æ€è€ƒã€‚ãã‚Œã¯ä½•ã§ã‚ã‚Šã€ã©ã®ã‚ˆã†ã«é–‹ç™ºã™ã‚‹ã‹</a></li>
<li><a href="../ja472670/index.html">ãƒ©ã‚¤ãƒ ãƒªãƒ¼ç§‹ã€ãƒ©ã‚¤ãƒ ãƒªãƒ¼å†¬...</a></li>
<li><a href="../ja472674/index.html">Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç’°å¢ƒå¤‰æ•°</a></li>
<li><a href="../ja472676/index.html">Slackã€Jiraã€é’ã„é›»æ°—ãƒ†ãƒ¼ãƒ—ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã®ã‚¸ãƒ§ãƒ¼ãƒ³ã‚ºéƒ¨é–€ã‚’ä½œæˆã—ã¾ã™</a></li>
<li><a href="../ja472682/index.html">C. elegansã®è–¬ç‰©ã‚·ãƒŠã‚¸ãƒ¼ã«ã‚ˆã‚‹è€åŒ–ã®æ¸›é€Ÿ</a></li>
<li><a href="../ja472684/index.html">fsyncï¼ˆï¼‰PostgreSQLã¸ã®ã‚µãƒ—ãƒ©ã‚¤ã‚º</a></li>
<li><a href="../ja472686/index.html">I486ãƒ™ãƒ¼ã‚¹ã®ãƒ“ãƒ‡ã‚ªã‚¹ã‚¿ã‚¸ã‚ª</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
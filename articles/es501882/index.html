<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçü§ù‚Äçüë®üèª ‚òéÔ∏è üé± C√≥mo usamos algoritmos de visi√≥n por computadora: procesamiento de video en un navegador m√≥vil usando OpenCV.js üßúüèæ üëÉüèº üç£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ya existen todas las posibilidades para identificar a una persona en l√≠nea, pero hasta ahora rara vez se usan. Tal vez fuimos uno de los primeros en i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>C√≥mo usamos algoritmos de visi√≥n por computadora: procesamiento de video en un navegador m√≥vil usando OpenCV.js</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/simbirsoft/blog/501882/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ya existen todas las posibilidades para identificar a una persona en l√≠nea, pero hasta ahora rara vez se usan. </font><font style="vertical-align: inherit;">Tal vez fuimos uno de los primeros en implementar el escenario √≥ptimo para el usuario: inicie sesi√≥n en el sitio desde un tel√©fono inteligente, tome una foto de su licencia de conducir o pasaporte y env√≠e datos al sistema. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Consideremos c√≥mo los algoritmos de visi√≥n por computadora ayudan a reconocer documentos en una transmisi√≥n de video directamente en navegadores m√≥viles. </font><font style="vertical-align: inherit;">En este art√≠culo, compartimos nuestra experiencia de c√≥mo usamos OpenCV.js para esto en SimbirSoft, qu√© dificultades son posibles, c√≥mo garantizar la velocidad y obtener una experiencia de usuario "suave" sin disminuir la velocidad.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jx/y7/u7/jxy7u7brc2ixo10gyheuhr19zcu.png"><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cual era la tarea</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El escenario empresarial para el algoritmo que se desarrolla es el siguiente. Un usuario que acceda al sitio desde un tel√©fono m√≥vil deber√≠a poder fotografiar sus documentos y enviarlos al sistema para su posterior procesamiento. Esto puede ser parte del proceso de identidad al solicitar el uso de cualquier servicio. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Una aplicaci√≥n web en este escenario es preferible a una aplicaci√≥n m√≥vil debido a su disponibilidad y tiempo reducido para completar la operaci√≥n. La p√°gina web no necesita instalaci√≥n y est√° lista para funcionar inmediatamente despu√©s de la carga. El usuario puede realizar las acciones que necesita, enviar una solicitud, inmediatamente despu√©s de recibir el enlace, sin distraerse con acciones adicionales. Desde una perspectiva comercial, estos factores aumentan la conversi√≥n y la efectividad comercial del proceso.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Desde un punto de vista arquitect√≥nico, se requiere el algoritmo para detectar directamente los l√≠mites del documento y recortar el exceso de fondo en la imagen. </font><font style="vertical-align: inherit;">La verificaci√≥n de identidad, autenticaci√≥n y verificaci√≥n de fraude ser√° implementada por otros componentes. </font><font style="vertical-align: inherit;">Sin embargo, es recomendable llevar a cabo al menos controles m√≠nimos para excluir el env√≠o de tarjetas de visita, rect√°ngulos de papel vac√≠os y otras im√°genes obviamente irrelevantes para procesar im√°genes.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Requisitos</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como parte de nuestro proyecto, exist√≠an los siguientes requisitos adicionales para el algoritmo:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la capacidad de trabajar en tiempo real: el flujo de video de la c√°mara no debe "reducir la velocidad" durante el funcionamiento del algoritmo;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la capacidad de trabajar en una amplia gama de contraste y textura de fondo: bajo contraste y contraste, fondo homog√©neo y heterog√©neo;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Compatibilidad con una amplia gama de modelos de tel√©fonos inteligentes, incluidos los modelos econ√≥micos lanzados hace varios a√±os.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finalmente, no hab√≠a un conjunto de datos para entrenar algoritmos de aprendizaje autom√°tico en el proyecto, y no hab√≠a forma de recopilarlo y marcarlo. </font><font style="vertical-align: inherit;">Solo tuvimos algunas muestras de prueba de los resultados de b√∫squeda de Google. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dada esta declaraci√≥n del problema, decidimos desarrollarnos en base a los algoritmos cl√°sicos de visi√≥n por computadora de la biblioteca opencv. </font><font style="vertical-align: inherit;">Una posibilidad alternativa era el uso de algoritmos de aprendizaje autom√°tico y redes neuronales, sin embargo, ya se descart√≥ en las primeras etapas del trabajo debido a los requisitos de rendimiento: cuando se aplica, no ser√≠a posible proporcionar procesamiento de trama en tiempo real en todos los dispositivos de destino.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Enfoque general y estructura de algoritmo</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La idea principal del algoritmo es un marco de referencia, a lo largo del cual es necesario alinear el documento. </font><font style="vertical-align: inherit;">Su uso persigue varios objetivos a la vez. </font><font style="vertical-align: inherit;">En primer lugar, proporcionar√° un tama√±o de imagen adecuado, suficiente para el procesamiento posterior de documentos. </font><font style="vertical-align: inherit;">En segundo lugar, como veremos m√°s adelante, se puede usar como uno de los filtros candidatos cuando se buscan bordes de documentos. </font><font style="vertical-align: inherit;">En tercer lugar, se puede utilizar para capturar y recortar la imagen si no se pueden encontrar los bordes del documento. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ru/et/bq/ruetbqsseuefny01b_anvvaa834.png"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Higo. </font><font style="vertical-align: inherit;">1. La estructura general del algoritmo.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La estructura general del algoritmo se muestra en la Fig. </font><font style="vertical-align: inherit;">1. Los cuadros de la transmisi√≥n de video se procesan en un ciclo, entre iteraciones de las cuales se establece un tiempo de espera para cumplir con el FPS deseado; nos detuvimos a 30 cuadros por segundo. </font><font style="vertical-align: inherit;">Esto le permite evitar "ralentizaciones" y reducir la carga en el procesador y el consumo de energ√≠a del dispositivo.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada marco procesado se somete a un preprocesamiento, durante el cual se realizan dos operaciones principales. En primer lugar, se crea una copia de un marco de un tama√±o fijo de 640x480, con el que funcionan los pasos adicionales del algoritmo. La imagen original tambi√©n permanece, el documento detectado se cortar√°. Esto ahorrar√° la calidad de la imagen final. En segundo lugar, la copia creada se traduce en tonos de gris. El algoritmo ignora el color del documento que se est√° procesando, ya que puede variar de un pa√≠s a otro e incluso en diferentes regiones del pa√≠s; un ejemplo es una licencia de conducir en los Estados Unidos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El primer paso para detectar un documento es buscar la cara en la imagen. El uso de esta heur√≠stica elimina la captura de tarjetas de presentaci√≥n y otras im√°genes obviamente irrelevantes. La b√∫squeda se realiza utilizando el est√°ndar opencv'shash </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CascadeClassifier.detectMultiScale ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y la cascada pre- </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entrenada haarcascade_frontalface_default</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Los tama√±os m√≠nimos y m√°ximos de las caras detectadas son limitados, lo que permite reducir los costos computacionales y tambi√©n limita a√∫n m√°s la escala del documento en la imagen. Una cara se considera detectada en la imagen cuando est√° en la parte izquierda o inferior izquierda, para pasaportes, del √°rea dentro del marco de referencia (Fig. 2). Esta es una medida adicional para garantizar la alineaci√≥n correcta del documento en la imagen.</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los ejemplos en este art√≠culo no contienen datos personales. </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/ws/mz/7w/wsmz7wghvpoyfdslngrf59jofms.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Higo. 2. El √°rea de la posici√≥n esperada de la cara en la imagen. El marco de soporte se muestra en rojo, los bordes del √°rea de la ubicaci√≥n esperada de la cara se muestran en verde.Despu√©s de la</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
detecci√≥n de la cara, procedemos a la detecci√≥n del borde. A menudo, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">findContours ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> se usa aqu√≠ </font><font style="vertical-align: inherit;">. Sin embargo, este enfoque funciona bien solo en casos contrastantes, por ejemplo, para una hoja de papel sobre un escritorio oscuro. Si el contraste es m√°s bajo, o la iluminaci√≥n es peor, o alguien sostiene una s√°bana en sus manos, cubriendo parte del borde con los dedos, los contornos detectados se dividen en componentes separados, "pierden" secciones significativas o no se detectan en absoluto.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por lo tanto, tomamos un enfoque diferente. Despu√©s de la binarizaci√≥n, primero pasamos la imagen a trav√©s del filtro de borde usando </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Canny ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , y luego miramos la imagen resultante para la l√≠nea usando la transformaci√≥n Huff </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HoughLines ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . El par√°metro umbral se establece inmediatamente lo suficientemente grande, igual a 30, para filtrar segmentos cortos y otros segmentos irrelevantes detectados.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El conjunto resultante de l√≠neas se filtra adicionalmente, dejando solo l√≠neas cerca del marco de referencia. Para hacer esto, primero traducimos las ecuaciones de las l√≠neas del marco a puntos en el sistema de coordenadas polares (rho, theta): theta siempre ser√° 0 o pi / 2, y rho ser√° √∫nico para cada l√≠nea. Despu√©s de eso, seleccionamos de las l√≠neas obtenidas de la transformaci√≥n Huff solo aquellas que se encuentran cerca de los puntos de control, de acuerdo con la m√©trica euclidiana, teniendo en cuenta la diferencia en la escala de los valores. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Distribuimos el conjunto de l√≠neas obtenidas despu√©s del filtrado en cuatro grupos correspondientes a las cuatro l√≠neas del marco de referencia, encontramos las intersecciones de las l√≠neas en pares entre los grupos, promediamos y obtenemos las coordenadas de los cuatro puntos: las esquinas del documento detectado (Fig.3).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zr/7g/lz/zr7glzo5dwn-mofan9fhnthwu8k.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Higo. 3. Filtrar l√≠neas y definir esquinas de documentos. Las l√≠neas verdes, resultado del filtrado, los puntos amarillos, detectaron las esquinas del documento.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
A continuaci√≥n, debe asegurarse de la calidad del marco. Para hacer esto, verificamos que el marco ha permanecido estacionario por √∫ltima vez. Para hacer esto, reste el marco al comienzo del per√≠odo del marco actual usando </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">absdiff ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y comp√°relo con el umbral. Antes de la resta, tambi√©n suavizamos las im√°genes con un filtro </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gaussiano GaussianBlur ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para reducir la influencia del ruido y otros factores aleatorios. Tambi√©n evaluamos el enfoque del marco calculando su Laplacian </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplacian ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , estimando su varianza y comparando el valor obtenido con un umbral.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si todas las verificaciones son exitosas, puede pasar a la parte final. </font><font style="vertical-align: inherit;">Recalculamos las coordenadas detectadas de los √°ngulos en el sistema de coordenadas de la imagen subexpuesta original y cortamos la regi√≥n resultante utilizando el m√©todo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">roi ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">El documento fue detectado con √©xito.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caracter√≠sticas de implementaci√≥n</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante el desarrollo del algoritmo, sus componentes principales se ensamblaron en un script de Python. Despu√©s de eso, el algoritmo fue portado a opencv.js y javascript, y luego a wasm. Este enfoque est√° dictado por consideraciones de conveniencia en todas las etapas. En Python, fue m√°s conveniente para nuestro equipo experimentar con varias variantes del algoritmo y llevar a cabo ajustes de par√°metros aproximados. La migraci√≥n a JavaScript permiti√≥ probar el funcionamiento del algoritmo en la plataforma de destino, incluidos varios dispositivos y navegadores. En funci√≥n de los resultados de estas comprobaciones, se realiz√≥ un ajuste fino de los par√°metros del algoritmo. Finalmente, reescribir secciones cr√≠ticas de c√≥digo en wasm nos permiti√≥ obtener un aumento de rendimiento adicional.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante la migraci√≥n, se descubrieron varias diferencias en la API de OpenCV, lo que result√≥ en cambios menores en la implementaci√≥n. Por ejemplo, la varianza de un laplaciano en python se considera simplemente como </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">laplaciano (). Var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Con OpenCV.js, no hay forma de usar NumPy, pero no se </font><font style="vertical-align: inherit;">ha proporcionado </font><font style="vertical-align: inherit;">una implementaci√≥n alternativa del m√©todo </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Soluci√≥n: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuente la funci√≥n meanStdDev ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> como la </font><font style="vertical-align: inherit;">desviaci√≥n est√°ndar (Listado 1).</font></font><br>
<br>
<pre><code class="javascript hljs">private isImageBlurry(image: cv.Mat): boolean {
		<span class="hljs-keyword">const</span> laplacian = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.Laplacian(image, laplacian, cv.CV_64F);<font></font>
		<span class="hljs-keyword">const</span> s_mat = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.meanStdDev(laplacian, <span class="hljs-keyword">new</span> cv.Mat(), s_mat);
		<span class="hljs-keyword">const</span> s = s_mat.data64F[<span class="hljs-number">0</span>];
		<span class="hljs-keyword">const</span> v = <span class="hljs-built_in">Math</span>.pow(s, <span class="hljs-number">2</span>);
		<span class="hljs-keyword">return</span> (v &lt; <span class="hljs-keyword">this</span>.laplacianVarianceThreshold);<font></font>
	}</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listado 1. Evaluaci√≥n del enfoque en la imagen a trav√©s de la varianza de Laplacian en opencv.js (TypeScript)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Otra caracter√≠stica fue la necesidad de reducir el tama√±o de la biblioteca. En su forma original, OpenCV.js tiene una capacidad de 7.9 MB. Su descarga a trav√©s de Internet ralentiza la inicializaci√≥n del algoritmo. La soluci√≥n a este problema es "recortar" los m√≥dulos no utilizados durante el proceso de ensamblaje de la biblioteca, lo que puede reducir significativamente el tama√±o del archivo de salida: logramos un tama√±o de 1.8 MB. La lista de componentes incluidos en el ensamblaje se puede configurar en el archivo de configuraci√≥n </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plataformas / js / opencv_js.config.py</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Listado 2).</font></font><br>
<br>
<pre><code class="javascript hljs">white_list = makeWhiteList([core, imgproc, objdetect, video, dnn, features2d, photo, aruco, calib3d])</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listado 2. La lista blanca original de m√≥dulos opencv incluidos en el ensamblaje para javascript</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Finalmente, se realiz√≥ una contribuci√≥n importante para garantizar el rendimiento requerido del algoritmo al pasarlo a Web Worker. </font><font style="vertical-align: inherit;">Este paso, junto con la restricci√≥n de FPS, nos permiti√≥ deshacernos de las "ralentizaciones" de la transmisi√≥n de video durante la operaci√≥n del algoritmo, que tuvo un efecto positivo en UX.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultados</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los ejemplos de captura y recorte de im√°genes se muestran en la Fig. </font><font style="vertical-align: inherit;">4. Se puede ver que el cultivo de la m√°s alta calidad se logra sobre un fondo uniforme oscuro, y la calidad m√°s baja se obtiene con un fondo no homog√©neo claro. </font><font style="vertical-align: inherit;">Este es el efecto esperado asociado con los gradientes obtenidos en diferentes fondos y utilizados para detectar los bordes de un documento. </font><font style="vertical-align: inherit;">Sobre un fondo oscuro, los gradientes son m√°s grandes que sobre un fondo claro, un fondo uniforme conduce a una menor variabilidad de los valores de gradiente. </font><font style="vertical-align: inherit;">Esto conduce a una detecci√≥n confiable de los l√≠mites y, como resultado, a un mejor cultivo. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/es/my/90/esmy90lihywocpj3-7p5bgttqkg.jpeg"><br>
<img src="https://habrastorage.org/webt/w4/uz/2l/w4uz2lnqlaajyd6eyplijsg72hc.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Higo. </font><font style="vertical-align: inherit;">4. Ejemplos de recorte de documentos utilizando un algoritmo.</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusi√≥n</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El art√≠culo presenta un algoritmo para detectar documentos en cuadros de una transmisi√≥n de video adecuada para su uso en navegadores m√≥viles, y tambi√©n analiza las caracter√≠sticas de su implementaci√≥n utilizando la biblioteca opencv.js. </font><font style="vertical-align: inherit;">El algoritmo le permite obtener la imagen de salida de los documentos en una calidad suficiente para su uso posterior por los algoritmos de autenticaci√≥n, verificaci√≥n de identidad, etc. </font><font style="vertical-align: inherit;">La velocidad de la implementaci√≥n resultante le permite obtener un UX "suave" sin "ralentizaciones" y p√©rdida de cuadros. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬°Gracias por la atenci√≥n! </font><font style="vertical-align: inherit;">Esperamos que encuentre √∫til este art√≠culo.</font></font></b></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es501868/index.html">C√≥mo no dejar que el contador se arroje o transfiramos 1C a la nube. Instrucciones paso a paso</a></li>
<li><a href="../es501870/index.html">N√∫mero m√°ximo de valores en enum Parte II</a></li>
<li><a href="../es501872/index.html">Lugar de estudio en sistemas cibern√©ticos.</a></li>
<li><a href="../es501874/index.html">Arquitecturas modernas de front-end (Parte 2)</a></li>
<li><a href="../es501880/index.html">Acerca de la traducci√≥n de "comienzos" y "comienzos" sin comenzar, comenzar y primero</a></li>
<li><a href="../es501884/index.html">C√≥mo los archivos electr√≥nicos de informaci√≥n m√©dica ayudar√°n a diagnosticar enfermedades de manera m√°s efectiva</a></li>
<li><a href="../es501886/index.html">El espacio no es tan simple como parece.</a></li>
<li><a href="../es501888/index.html">C√≥mo reducir los riesgos asociados con ransomware ransomware</a></li>
<li><a href="../es501890/index.html">React Native: guarda fotos y videos en la galer√≠a del dispositivo</a></li>
<li><a href="../es501892/index.html">No es mi pierna izquierda: un an√°lisis de la estructura cerebral de las personas con xenomelia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
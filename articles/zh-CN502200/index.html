<!doctype html>
<html class="no-js" lang="zh-CN">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👉🏼 👏🏼 💅🏼 熵：决策树如何制定决策 👨‍💼 🧝🏼 👨🏻‍🎨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在机器学习课程开始之前准备了文章的翻译。
 
 
 
 您是目前正在学习的数据科学专家。自从用Python或R编写第一行代码以来，您已经走了很长一段路。您知道Scikit-Learn就像手背一样。现在，您更多地坐在Kaggle而不是Facebook上。创建出色的随机森林和其他决策树集成模型并不陌生。...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>熵：决策树如何制定决策</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/502200/"><i><b><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在机器学习</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">课程开始之前准备了文章的翻译</font><font style="vertical-align: inherit;">。</font></font></b></i><br>
<br>
<img src="https://habrastorage.org/webt/az/2h/3e/az2h3eq1jejcxtd0g4wi4gmamki.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
您是目前正在学习的数据科学专家。自从用Python或R编写第一行代码以来，您已经走了很长一段路。您知道Scikit-Learn就像手背一样。现在，您更多地坐在Kaggle而不是Facebook上。创建出色的随机森林和其他决策树集成模型并不陌生。但是，您知道，如果不全面发展，您将不会有任何成就。您想更深入地了解流行的机器学习模型的复杂性和概念。好吧，我也是。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今天，我将讨论熵的概念-统计学中最重要的主题之一，随后我们将讨论信息增益（信息增益）的概念，并找出为什么这些基本概念构成了如何根据所获得的数据构建决策树的基础。</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
好。现在让我们超越吧。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
什么是熵？简单来说，熵不过是一种无序的量度。 （它也可以视为一种纯度的度量标准，很快您就会知道为什么了。但是我更喜欢混乱，因为它听起来更凉爽。）</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
熵</font><font style="vertical-align: inherit;">的</font><font style="vertical-align: inherit;">数学公式如下：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ey/wa/u-/eywau-ntm5stedcuyrelbhhoipu.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">熵。有时用H表示。</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
这里的p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">是我们数据元素/ i类的频率概率。为简单起见，假设我们只有两个类：正数和负数。然后，我将采用“ +”或“-”的值。如果我们在数据集中总共有100个点，其中30个点属于正类，而70个点属于负类，则p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">为3/10，而p</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将为7/10。这里的一切都很简单。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
如果从此示例中计算类的熵，则可以使用上面的公式得出：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/5_/hh/20/5_hh20bihmp119n_5vzmlq_vuyw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
熵约为0.88。该值被认为是很高的，也就是说，我们的熵或无序程度很高（即纯度较低）。熵的测量范围是0到1。根据数据集中的类数，熵的值可能大于1，但这意味着无序程度非常高。为了便于说明，在今天的文章中，熵将介于0到1之间。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
请看下面的图表。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jt/sx/zs/jtsxzsfwwbstp10fqo-rd0ndddw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在X轴上，每个圆中正类的点数得到反映，在Y轴上，相应的熵得到反映。您可以立即注意到图形的倒U形。原则上，如果圆中没有正元素，或者其中只有正元素，则熵在极值处最小。也就是说，当一个圆中有相同元素时，无序将为0。熵将在图的中间最高，其中正负元素将在圆内均匀分布。在这里，由于没有主要元素，因此将实现最大的熵或无序。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
是否有任何理由使用以2为底的对数来测量熵，或者为什么熵在0和1之间而不是在不同范围内测量？不，没有理由。这只是一个指标。了解发生这种情况的原因并不重要。重要的是要知道我们上面得到的是如何计算的以及它是如何工作的。熵是混淆或不确定性的一种度量，机器学习模型和数据科学专家的目标通常是减少这种不确定性。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
现在我们知道如何测量混乱。接下来，我们需要一个值来衡量目标变量/类别的其他信息（属性/自变量）中这种疾病的减轻程度。这是信息增益或信息增益起作用的地方。从数学的角度来看，可以写成如下：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/bn/el/t4/bnelt40yxay8hkbanig088mpk6a.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 我们简单地从熵Y中减去X的熵Y，以便计算关于Y的不确定性的减少，前提是存在关于X的有关X的信息。不确定性减小得越强，就可以从Y获得关于X的更多信息。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
让我们看一下列联表的简单示例更接近决策树如何使用熵和信息增益来决定在什么基础上打破数据学习过程中的节点的问题。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">示例：共轭表</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/s4/ea/e5/s4eae57mpuehp3mk_mjpmikuan0.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 在这里，我们的目标变量将是</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Liability</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，它只能采用两个值：</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ Normal”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ High”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。我们也只有一个标志，称为信用评级，它将价值分为三类：</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">``优秀''</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font><i><font style="vertical-align: inherit;">`` </font></i></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">好''</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">``差''</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。总共进行了14次观察。其中7个属于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">普通责任</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类别</font><font style="vertical-align: inherit;">，另外7个属于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">高责任</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类别</font><font style="vertical-align: inherit;">。这本身就是一个分裂。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
如果我们看第一行中值的总和，我们会发现我们有4个</font><font style="vertical-align: inherit;">基于</font><i><font style="vertical-align: inherit;">信用评级的</font></i></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">优秀</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">值观察值</font><font style="vertical-align: inherit;">。而且，我什至可以说我的目标变量被</font><i><font style="vertical-align: inherit;">“优秀”信用评级</font></i><font style="vertical-align: inherit;">所破坏</font><font style="vertical-align: inherit;">。在</font><font style="vertical-align: inherit;">属性</font><font style="vertical-align: inherit;">值为</font><i><font style="vertical-align: inherit;">“优秀”</font></i><font style="vertical-align: inherit;">的观察结果中</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信用评级</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">中有3个属于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">普通责任</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类别</font><font style="vertical-align: inherit;">，1个属于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">高责任</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类别</font><font style="vertical-align: inherit;">。同样，我可以</font><font style="vertical-align: inherit;">从列联表中</font><font style="vertical-align: inherit;">为其他</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信用等级</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">值计算出类似的结果</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
例如，我使用上面的列联表独立计算目标变量的熵，然后考虑到“ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信用评级”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">属性中的其他信息来计算其熵</font><font style="vertical-align: inherit;">。因此，我可以计算出“ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信用评级”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将为</font><font style="vertical-align: inherit;">“ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">责任”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">目标变量</font><font style="vertical-align: inherit;">提供多少其他信息</font><font style="vertical-align: inherit;">。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 因此，让我们开始吧。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/2v/2y/lg/2v2ylghvtk-f-e0eom6aeocsb1q.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 我们的目标变量的熵为1，这意味着由于元素在</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“正常”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“高”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">之间的均匀分布而造成的最大混乱</font><font style="vertical-align: inherit;">。下一步是</font><font style="vertical-align: inherit;">考虑到“ </font><i><font style="vertical-align: inherit;">信用评级”中的</font></i><font style="vertical-align: inherit;">其他信息</font><font style="vertical-align: inherit;">，计算“ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">责任”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">目标变量的熵</font><font style="vertical-align: inherit;">。为此，我们计算</font><font style="vertical-align: inherit;">每个</font><i><font style="vertical-align: inherit;">信用评级</font></i><font style="vertical-align: inherit;">值</font><font style="vertical-align: inherit;">的</font><i><font style="vertical-align: inherit;">责任</font></i><font style="vertical-align: inherit;">熵</font><font style="vertical-align: inherit;">，</font><font style="vertical-align: inherit;">并使用每个值的平均加权观察率将它们相加。当我们谈论决策树时，为什么我们使用加权平均值会变得更加清楚。</font><font style="vertical-align: inherit;">
 我们使用“ </font><i><font style="vertical-align: inherit;">信用评级”</font></i><font style="vertical-align: inherit;">属性获得了目标变量的熵</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><br>
<br>
<img src="https://habrastorage.org/webt/rt/_5/fh/rt_5fhldx4dfjcioh7d_uiori6e.png"><br>
 <br><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。现在，我们可以</font><font style="vertical-align: inherit;">从</font><i><font style="vertical-align: inherit;">信用评级中</font></i><font style="vertical-align: inherit;">计算信息</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">责任</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">收益</font><font style="vertical-align: inherit;">，</font><font style="vertical-align: inherit;">以了解此功能的信息量。</font><font style="vertical-align: inherit;">
 了解</font><i><font style="vertical-align: inherit;">信用评级</font></i><font style="vertical-align: inherit;">有助于我们减少</font><i><font style="vertical-align: inherit;">责任</font></i><font style="vertical-align: inherit;">目标变量的不确定性。</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。这不是一个应该起作用的好兆头吗？给我们有关目标变量的信息吗？好吧，由于这个原因，决策树使用了熵和信息增益。他们确定用什么标准将节点分成分支，以便在随后的每个分区中接近目标变量，并了解何时需要完成树的构造！ （当然，除了超参数（例如最大深度）之外）。在下面的示例中，使用决策树让我们看看这是如何工作的。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">示例：决策树</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
让我们看一个构建决策树的示例，其目的是预测个人的信用是否会被注销。人口将是30份。 16个属于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注销</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类</font><font style="vertical-align: inherit;">，其他14 </font><font style="vertical-align: inherit;">个属于</font><i><font style="vertical-align: inherit;">注销</font></i><font style="vertical-align: inherit;">类</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“不注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。我们将有两个符号，即</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ Balance”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，可以采用两个值：“ &lt;50K”或“&gt; 50K”，以及</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ Residence”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，其采用三个值：</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ OWN”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ RENT”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">或</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“ OTHER”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。我将演示决策树算法将如何决定首先打破哪个属性，以及哪个属性将提供更多信息，也就是说，它将通过使用熵和信息增益的概念来最好地消除目标变量的不确定性。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">症状1：平衡</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/9b/d8/xv/9bd8xviw3mxbiqj28zmdqbiaazs.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 这里的圆圈属于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类别，而星星对应于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“非注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类别</font><font style="vertical-align: inherit;">。按属性对父根分区</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">平衡</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将给我们2个继承节点。在左节点会有13个观察，其中12/13观测（概率0.92）从</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类</font><font style="vertical-align: inherit;">从类观测，只有1/13（概率0.08）</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“非注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。在右节点会有17个观测的观测30，其中13/17（概率0.76）从</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类</font><font style="vertical-align: inherit;">和4/17（概率0.24）从类观测的</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">“非注销”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
让我们计算根的熵，看看通过使用基于</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的分区，树可以减少不确定性多少</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yq/ke/do/yqkedojc2s80__h-vqqcptzewai.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 根据</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">余额进行</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">拆分</font><font style="vertical-align: inherit;">将获得0.37的信息增益。让我们为</font><i><font style="vertical-align: inherit;">居留</font></i><font style="vertical-align: inherit;">标志数一下</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">并比较结果。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">症状2：住宅</font></font></b><br>
<br>
<img src="https://habrastorage.org/webt/mx/tm/sd/mxtmsdt2hm0mamxkdxzqnb9v7mg.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
 基于分割树</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">公寓</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">会给你3个继承人节点。左后代节点将接收8个观测值，其中来自</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注销</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类的观测值的7/8（概率为0.88），</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">而非注销</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类的观测值只有1/8（概率0.12）</font><font style="vertical-align: inherit;">。平均后继节点将接收10个观测值，其中来自</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注销</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类的观测值的4/10（概率0.4）</font><font style="vertical-align: inherit;">和来自</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">非注销</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类的观测值的6/10（概率0.6）</font><font style="vertical-align: inherit;">。右继承人将收到12个观察值，其中来自</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注销</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类的观察值的5/12（概率0.42）</font><font style="vertical-align: inherit;">和来自</font><i><font style="vertical-align: inherit;">非注销</font></i><font style="vertical-align: inherit;">类的观察值的7/12（概率0.58）</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。我们已经知道父节点的熵，因此我们只需在分区后计算熵即可了解</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">属性的信息增益</font><font style="vertical-align: inherit;">。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/cb/zt/zf/cbztzffw12-wkj6cjfayt_jzlcq.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 从“ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">平衡”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">属性获得的信息收益</font><font style="vertical-align: inherit;">几乎</font><font style="vertical-align: inherit;">是</font><font style="vertical-align: inherit;">从“ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">住宅”</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">获得的信息的</font><font style="vertical-align: inherit;">三倍</font><font style="vertical-align: inherit;">！如果再次查看这些图，将会发现，根据</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance进行的</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分区</font><font style="vertical-align: inherit;">将比根据</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence进行</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">划分的</font><font style="vertical-align: inherit;">节点更干净</font><font style="vertical-align: inherit;">。但是，</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Residence中</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">最左边的节点</font><font style="vertical-align: inherit;">也很干净，但是加权平均值才在这里起作用。尽管节点是干净的，但它的观察次数最少，并且根据</font><i><font style="vertical-align: inherit;">Residence</font></i><font style="vertical-align: inherit;">，它的结果在常规重新计算和总熵的计算中丢失了</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。这很重要，因为我们正在寻找属性的一般信息内容，并且不希望最终结果因属性的稀有值而失真。</font><font style="vertical-align: inherit;">与</font><i><font style="vertical-align: inherit;">Residence</font></i><font style="vertical-align: inherit;">相比</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
，</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Balance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">属性本身</font><font style="vertical-align: inherit;">提供了有关目标变量的更多信息</font><font style="vertical-align: inherit;">。因此，我们的目标变量的熵降低了。决策树算法使用此结果根据</font><i><font style="vertical-align: inherit;">Balance</font></i><font style="vertical-align: inherit;">进行第一次拆分</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">以后决定在什么基础上打破以下节点。在现实世界中，当有两个以上的特征时，将首先根据信息最多的特征进行细分，然后再进行后续分解，因为每个附加特征都会重新计算信息增益，因为它与从每个特征单独获得的信息增益并不相同。熵和信息增益应在一个或几个分区发生后计算，这将影响最终结果。决策树随着深度的增加将重复此过程，直到达到某个深度或某种分裂导致超出某个阈值的更高的信息增益为止，该阈值也可以指定为超参数！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
就这样！</font><font style="vertical-align: inherit;">现在您知道了什么熵，信息增益以及如何计算它们。</font><font style="vertical-align: inherit;">现在，您了解了决策树本身（或作为整体的一部分）如何做出关于按属性划分的最佳顺序的决策，并决定了在学习可用数据时何时停止。</font><font style="vertical-align: inherit;">好吧，如果您必须向某人解释决策树是如何工作的，我希望您能够适当地完成这项任务。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
希望您从本文中学到了一些对自己有用的东西。</font><font style="vertical-align: inherit;">如果我错过了某件事或表达了自己的错误，请给我写信。</font><font style="vertical-align: inherit;">我将非常感谢您！</font><font style="vertical-align: inherit;">谢谢。</font></font><br>
<br>
<hr><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">了解有关该课程的更多信息。</font></font></a><br>
<br>
<hr></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN502178/index.html">oVirt在2小时内。第3部分。高级设置</a></li>
<li><a href="../zh-CN502180/index.html">周界消失的那一天。Microsoft和合作伙伴提供的安全解决方案</a></li>
<li><a href="../zh-CN502182/index.html">关于MikroTik或期待已久的SOCKS5</a></li>
<li><a href="../zh-CN502186/index.html">网络研讨会。信息安全：隔离的SOC</a></li>
<li><a href="../zh-CN502196/index.html">一个世纪前的数学方法中，发现了揭示时间本质的新钥匙。</a></li>
<li><a href="../zh-CN502202/index.html">铁路运输中无人技术的发展</a></li>
<li><a href="../zh-CN502204/index.html">在应用程序中使用Spring Shell时编写@SpringBootTest测试</a></li>
<li><a href="../zh-CN502206/index.html">Yandex记录了复古计算机的声音</a></li>
<li><a href="../zh-CN502208/index.html">Chrome扩展程序可隐藏YouTube上分散注意力的建议</a></li>
<li><a href="../zh-CN502234/index.html">Инсайды от сотрудника Facebook: как попасть на стажировку, получить оффер и все о работе в компании</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
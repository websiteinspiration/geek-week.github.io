<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äç‚öïÔ∏è üï∫üèª üë©‚Äçüë©‚Äçüë¶ YOLOv4 - le r√©seau neuronal en temps r√©el le plus pr√©cis du jeu de donn√©es Microsoft COCO ‚úåüèæ üßïüèæ üôèüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Darknet YOLOv4 est plus rapide / plus pr√©cis que Google TensorFlow EfficientDet et FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. 
 
 Le m√™me arti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>YOLOv4 - le r√©seau neuronal en temps r√©el le plus pr√©cis du jeu de donn√©es Microsoft COCO</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/503200/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Darknet YOLOv4 est plus rapide / plus pr√©cis que Google TensorFlow EfficientDet et FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le m√™me article sur medium</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium </font></font></a><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet </font></font></a><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Article</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/3h/nc/sr/3hncsroz9wt8u3ycqskubgu1xk8.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous montrerons quelques nuances de comparaison et d'utilisation de r√©seaux de neurones pour d√©tecter des objets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notre objectif √©tait de d√©velopper un algorithme de d√©tection d'objets pour une utilisation dans des produits r√©els, et pas seulement de faire avancer la science. </font><font style="vertical-align: inherit;">La pr√©cision du r√©seau de neurones YOLOv4 (608x608) est de 43,5% AP / 65,7% AP50 Microsoft-COCO-testdev. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">62 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (608x608 batch = 1) sur Tesla V100 - en utilisant Darknet-framework </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (416x416 batch = 4) sur RTX 2080 Ti - en utilisant TensorRT + tkDNN </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (416x416 batch = 1) sur Jetson AGX Xavier - en utilisant TensorRT + tkDNN</font></font><br>
<br>
<img src="https://habrastorage.org/webt/p_/ep/cl/p_epcl_aaw_trgeltekatagtqkg.jpeg"> <br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1_SiUOYUoOI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tout d'abord, quelques liens utiles.</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez lire une description d√©taill√©e des fonctionnalit√©s utilis√©es dans YOLOv4 dans cet article: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium.com/@jonathan_hui/yolov4-c9901eaa8e61</font></font></a></li>
<li>  YOLOv4: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://lutzroeder.github.io/netron/%3Furl%3D" rel="nofollow">lutzroeder.github.io/netron/?url=https%3A%2F%2Fraw.githubusercontent.com%2FAlexeyAB%2Fdarknet%2Fmaster%2Fcfg%2Fyolov4.cfg</a></li>
<li>     YOLOv4  GPU   Google-cloud  Jupyter Notebook ‚Äì      ,   - ¬´Open in Playground¬ª,         [ ] ‚Äì    ,  ,  ,    5    : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE</a>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">www.youtube.com/watch?v=mKAEGSxwOAY</a></li>
<li>  Darknet   : <br>
 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 </li>
</ul><br>
<h3>   </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notre r√©seau de neurones YOLOv4 et notre propre framework Darknet DL (C / C ++ / CUDA) sont meilleurs en vitesse FPS et en pr√©cision AP50: 95 et AP50 sur les jeux de donn√©es Microsoft COCO que les frameworks DL et r√©seaux de neurones: Google TensorFlow EfficientDet, FaceBook Detectron RetinaNet / MaskRCNN, PyTorch Yolov3-ASFF, et bien d'autres ... YOLOv4 atteint une pr√©cision de 43,5% AP / 65,7% AP50 sur le test Microsoft COCO √† une vitesse de 62 FPS TitanV ou 34 FPS RTX 2070. Contrairement √† d'autres d√©tecteurs modernes, YOLOv4 peut entra√Æner n'importe qui avec celui qui a la carte graphique de jeu nVidia avec 8-16 Go de VRAM. D√©sormais, non seulement les grandes entreprises peuvent former un r√©seau de neurones sur des centaines de GPU / TPU pour utiliser de grandes tailles de mini-lots afin d'obtenir une plus grande pr√©cision, nous renvoyons donc le contr√¥le de l'intelligence artificielle aux utilisateurs ordinaires, car pour YOLOv4, un grand mini-lot n'est pas n√©cessaire,peut √™tre limit√© √† une taille de 2 √† 8.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLOV4 est optimal pour une utilisation en temps r√©el, car le r√©seau se trouve </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur la courbe d'optimalit√© de Pareto</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans le </font><b><font style="vertical-align: inherit;">graphique</font></b><font style="vertical-align: inherit;"> AP (pr√©cision) / FPS (vitesse). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2k/77/as/2k77aszzprngk0qmtistcehkz8c.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Graphiques de pr√©cision (AP) et de vitesse (FPS) de nombreux r√©seaux de neurones pour d√©tecter des objets mesur√©s sur des GPU TitanV / TeslaV100, TitanXP / TeslaP100, TitanX / TeslaM40 pour les deux principaux indicateurs de pr√©cision AP50: 95 et AP50</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pour une comparaison √©quitable, nous prenons des donn√©es d'articles et comparer uniquement sur le GPU avec la m√™me architecture. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La plupart des t√¢ches pratiques ont les exigences minimales n√©cessaires pour les d√©tecteurs - ce sont la pr√©cision et la vitesse minimales acceptables. Habituellement, la vitesse minimale autoris√©e de 30 FPS (images par seconde) et plus pour les syst√®mes en temps r√©el. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme le montrent les graphiques, dans les syst√®mes en temps r√©el avec FPS 30 ou plus:</font></font><br>
<br>
<ul>
<li> YOLOv4-608   RTX 2070  <b>450$</b> (34 FPS)   <b>43.5% AP / 65.7% AP50</b></li>
<li> EfficientDet-D2   TitanV  <b>2250$</b> (42 FPS)   <b>43.0% AP / 62.3% AP50</b></li>
<li> EfficientDet-D0   RTX 2070  <b>450$</b> (34 FPS)   <b>33.8% AP / 52.2% AP50</b></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ceux. YOLOv4 n√©cessite </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un √©quipement 5 fois moins cher</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et plus pr√©cis que EfficientDet-D2 (Google-TensorFlow). Vous pouvez utiliser EfficientDet-D0 (Google-TensorFlow) alors le co√ªt de l'√©quipement sera le m√™me, mais la pr√©cision sera de 10% AP inf√©rieure. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, certains syst√®mes industriels ont des limites sur la dissipation thermique ou sur l'utilisation d'un syst√®me de refroidissement passif - dans ce cas, vous ne pouvez pas utiliser TitanV m√™me avec de l'argent. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque vous utilisez YOLOv4 (416x416) sur un GPU RTX 2080 Ti en utilisant TensorRT + tkDNN, nous atteignons une vitesse 2x plus rapide, et lorsque vous utilisez batch = 4, il est 3x-4x fois plus rapide - pour une comparaison honn√™te, nous ne pr√©sentons pas ces r√©sultats dans un article sur arxiv. org:</font></font><br>
<img src="https://habrastorage.org/webt/ci/j7/uq/cij7uqas0ypsjcpsfkhvdxuyxzs.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
R√©seau de neurones YOLOv4 (416x416) FP16 (Tensor Cores) batch = </font><font style="vertical-align: inherit;">1 atteint √† 32 FPS calculator nVidia Jetson AGX Xavier en utilisant les biblioth√®ques + tkDNN TensorRT: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN la</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
vitesse l√©g√®rement plus lente donne la biblioth√®que OpenCV-dnn compil√©e avec CUDA: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs .opencv.org / master / da / d9d / tutorial_dnn_yolo.html</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parfois, la vitesse (FPS) de certains r√©seaux de neurones dans les articles est indiqu√©e lors de l'utilisation d'une taille de lot √©lev√©e ou lors de tests avec un logiciel sp√©cialis√© (TensorRT), qui optimise le r√©seau et affiche une valeur FPS accrue. La comparaison de certains r√©seaux sur TRT avec d'autres r√©seaux sans TRT n'est pas juste. L'utilisation d'une taille de lot √©lev√©e augmente le FPS, mais augmente √©galement la latence (plut√¥t que de la diminuer) par rapport √† batch = 1. Si le r√©seau avec batch = 1 affiche 40 FPS, et avec batch = 32, il affiche 60 FPS, le d√©lai sera de 25 ms pour batch = 1 et de ~ 500 ms pour batch = 32, car seuls ~ 2 paquets (32 images chacun) seront trait√©s par seconde, c'est pourquoi l'utilisation de batch = 32 n'est pas acceptable dans de nombreux syst√®mes industriels. Par cons√©quent, nous avons compar√© les r√©sultats sur les graphiques uniquement avec batch = 1 et sans utiliser TensorRT.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tout processus peut √™tre contr√¥l√© par des personnes ou par des ordinateurs. Lorsqu'un syst√®me informatique agit avec un retard important en raison de la faible vitesse et fait trop d'erreurs, vous ne pouvez pas vous voir confier un contr√¥le complet sur les actions, dans ce cas, la personne contr√¥le le processus, et le syst√®me informatique ne donne que des indices - il s'agit d'un syst√®me de recommandation - la personne travaille et le syst√®me uniquement indique o√π des erreurs ont √©t√© commises. Lorsque le syst√®me fonctionne rapidement et avec une grande pr√©cision, un tel syst√®me peut contr√¥ler le processus de mani√®re ind√©pendante et une personne ne s'en occupe que. Par cons√©quent, la pr√©cision et la vitesse du syst√®me sont toujours importantes. S'il vous semble que 120 FPS pour YOLOv4 416x416 est trop pour votre t√¢che, et qu'il vaut mieux prendre l'algorithme plus lentement et plus pr√©cis√©ment, alors tr√®s probablement dans les t√¢ches r√©elles, vous utiliserez quelque chose de plus faible que le Tesla V100 250 Watt,par exemple, RTX 2060 / Jetson-Xavier 30-80 Watt, dans ce cas, vous obtiendrez 30 FPS sur YOLOv4 416x416 et d'autres r√©seaux de neurones √† 1-15 FPS ou ne d√©marrerez pas du tout.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caract√©ristiques de la formation de divers r√©seaux de neurones</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous devez former EfficientDet avec un mini-lot = taille 128 sur plusieurs GPU Tesla V100 32 Go, tandis que YOLOv4 a √©t√© form√© sur un seul GPU Tesla V100 32 Go avec mini-lot = 8 = lot / subdivisions, et peut √™tre form√© sur un jeu r√©gulier carte graphique 8-16 Go GPU-VRAM. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La nuance suivante est la difficult√© de former un r√©seau de neurones pour d√©tecter ses propres objets. </font><font style="vertical-align: inherit;">Peu importe combien de temps vous entra√Ænez d'autres r√©seaux sur le m√™me GPU 1080 Ti, vous n'obtiendrez pas la pr√©cision indiqu√©e dans le graphique ci-dessus. </font><font style="vertical-align: inherit;">La plupart des r√©seaux (EfficientDet, ASFF, ...) doivent √™tre form√©s sur 4 √† 128 GPU (avec une grande taille de mini-lot utilisant syncBN) et il est n√©cessaire de s'entra√Æner √† chaque fois pour chaque r√©solution de r√©seau, sans remplir les deux conditions, il est impossible d'atteindre la pr√©cision AP ou AP50 d√©clar√©e par eux.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/p4/sx/p3/p4sxp3ewxd9owskis23n6dyrv58.jpeg"><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez voir la d√©pendance de la pr√©cision de d√©tection des objets sur la taille du mini-lot dans d'autres d√©tecteurs, c'est-√†-dire </font><font style="vertical-align: inherit;">en utilisant 128 cartes vid√©o au lieu de 8 cartes vid√©o et la vitesse d'apprentissage est 10 fois plus √©lev√©e et la pr√©cision finale est 1,5 AP plus √©lev√©e - MegDet: un grand d√©tecteur d'objets en mini-lots </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1711.07240</font></font></a></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Yolo ASFF: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09516</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s [43], nous introduisons un sac de trucs dans le processus de formation, tels que l'algorithme de mixage [12], le calendrier des taux d'apprentissage cosinus [26] et la technique de normalisation des lots synchronis√©s [30].</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
EfficientDet: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09070</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La normalisation par lots synchronis√©e est ajout√©e apr√®s chaque convolution avec la d√©croissance de la norme de lot 0,99 et epsilon 1e-3. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Chaque mod√®le est form√© de 300 √©poques avec une taille totale de lot de 128 sur 32 c≈ìurs TPUv3.</font></font></blockquote><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">cloud.google.com/tpu/docs/types-zones#europe</a><br>
<blockquote>v3-32 TPU type (v3) ‚Äì 32 TPU v3 cores ‚Äì 512 GiB Total TPU memory</blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous devez utiliser 512 Go de TPU / GPU-RAM pour entra√Æner le mod√®le EfficientDet avec une normalisation de lot synchronis√©e √† lot = 128, tandis que le mini-lot = 8 et seulement 32 Go de RAM-GPU ont √©t√© utilis√©s pour entra√Æner YOLOv4. Malgr√© cela, YOLOv4 est plus rapide / plus pr√©cis que les r√©seaux publics, bien qu'il ne soit form√© qu'une seule fois avec une r√©solution de 512x512 par GPU (Tesla V100 32 Go / 16 Go). Dans le m√™me temps, l'utilisation de la plus petite taille de mini-lot et du GPU-VRAM ne conduit pas √† une perte de pr√©cision aussi dramatique que dans d'autres r√©seaux de neurones: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xi/ol/rs/xiolrsvx4vzpjvahb6kvambdvgq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Vous pouvez donc former l'intelligence artificielle localement sur votre PC, au lieu de t√©l√©charger Ensemble de donn√©es vers le cloud - cela garantit la protection de vos donn√©es personnelles et rend la formation en intelligence artificielle accessible √† tous.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il suffit de former notre r√©seau une fois avec une r√©solution de r√©seau 512x512, puis il peut √™tre utilis√© avec diff√©rentes r√©solutions de r√©seau dans la plage: [416x416 - 512x512 - 608x608]. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La plupart des autres mod√®les doivent √™tre form√©s √† chaque fois s√©par√©ment pour chaque r√©solution de r√©seau, pour cette raison, la formation prend beaucoup plus de temps.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caract√©ristiques de mesure de la pr√©cision des algorithmes de d√©tection d'objets</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez toujours trouver une image sur laquelle un algorithme fonctionnera mal, et un autre algorithme fonctionnera bien, et vice versa. Par cons√©quent, pour tester les algorithmes de d√©tection, un large ensemble de ~ 20 000 images et 80 types d'objets diff√©rents est utilis√© - MSCOCO test-dev dataset. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour que l'algorithme n'essaie pas de se souvenir simplement du hachage de chaque image et des coordonn√©es sur celle-ci (sur-ajustement), la pr√©cision de la d√©tection d'objet est toujours v√©rifi√©e sur les images et les √©tiquettes que l'algorithme n'a pas vues pendant la formation - cela garantit que l'algorithme peut d√©tecter des objets sur les images / vid√©os qu'il jamais vu.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour que personne ne puisse se tromper dans le calcul de la pr√©cision, dans le domaine public, il n'y a que des images de test-dev sur lesquelles vous d√©tectez et envoyez les r√©sultats au serveur d'√©valuation CodaLab, sur lequel le programme lui-m√™me compare vos r√©sultats avec des annotations de test qui ne sont accessibles √† personne. . </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'ensemble de donn√©es MSCOCO se compose de 3 parties</font></font></a><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tutoriel: 120 000 images et un fichier json avec les coordonn√©es de chaque objet</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Set de validation: 5000 images et un fichier json avec les coordonn√©es de chaque objet</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suite de tests: 41 000 images jpg sans les coordonn√©es des objets (certaines de ces images sont utilis√©es pour d√©terminer la pr√©cision des t√¢ches: d√©tection d'objets, segmentation d'instances, points cl√©s, ...)</font></font></li>
</ol><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caract√©ristiques du d√©veloppement de YOLOv4</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors du d√©veloppement de YOLOv4, j'ai d√ª d√©velopper moi-m√™me le r√©seau de neurones YOLOv4 et le framework Darknet en C / C ++ / CUDA. </font><font style="vertical-align: inherit;">Parce que </font><font style="vertical-align: inherit;">dans Darknet il n'y a pas de diff√©renciation automatique et d'ex√©cution automatique de la r√®gle de cha√Æne, alors tous les gradients doivent √™tre impl√©ment√©s manuellement. </font><font style="vertical-align: inherit;">D'un autre c√¥t√©, nous pouvons d√©roger au strict respect de la r√®gle de la cha√Æne, changer la r√©tropropagation et essayer des choses tr√®s simples pour augmenter la stabilit√© et la pr√©cision de l'apprentissage.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©sultats suppl√©mentaires lors de la cr√©ation de r√©seaux de neurones</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pas toujours le meilleur r√©seau pour classer les objets sera le meilleur en tant que colonne vert√©brale pour le r√©seau utilis√© pour d√©tecter les objets</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'utilisation de poids entra√Æn√©s avec des fonctionnalit√©s qui ont une pr√©cision accrue dans la classification peut affecter la pr√©cision du d√©tecteur (sur certains r√©seaux)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Toutes les fonctionnalit√©s mentionn√©es dans diverses √©tudes n'am√©liorent pas la pr√©cision du r√©seau.</font></font></li>
<li>                .</li>
<li>      BFLOPS  ,   BFLOPS    </li>
<li>                  ,     receptive field     ,       stride=2 / conv3x3,    weights (filters)      . </li>
</ul><br>
<h3>   YOLOv4</h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La d√©tection d'objets √† l'aide de mod√®les YOLOv4 form√©s est int√©gr√©e √† la biblioth√®que OpenCV-dnn </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/issues/17148</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> afin que vous puissiez utiliser YOLOv4 directement √† partir d'OpenCV sans utiliser le framework Darknet. </font><font style="vertical-align: inherit;">La biblioth√®que OpenCV prend en charge la mise en ≈ìuvre de r√©seaux de neurones sur le processeur, le GPU (nVidia GPU), le VPU (Intel Myriad X). </font><font style="vertical-align: inherit;">Plus de d√©tails: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs.opencv.org/master/da/d9d/tutorial_dnn_yolo.html Framework </font></font></a><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dnn):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemple C ++: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemple Python: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.py</font></font></a></li>
</ul><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Framework </font><b><font style="vertical-align: inherit;">Darknet</font></b><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instructions d'utilisation de YOLOv4 pour d√©tecter des objets: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-use-on-the-command-line</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instructions pour entra√Æner un r√©seau de neurones √† d√©tecter ses propres objets: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instructions pour la formation du classificateur CSPDarknet53 sur le jeu de donn√©es ILSVRC2012 (ImageNet): </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Classifier-on-ImageNet-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (ILSVRC2012)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instructions pour la formation de YOLOv4 sur le jeu de donn√©es MS COCO: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Detector-on-MS-COCO-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (trainvalno5k-2014) -dataset</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tkDNN + TensorRT</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Vitesse maximale de d√©tection d'objet √† l'aide de YOLOv4: TensorRT + tkDNN </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS - YOLOv4 (416x416 batch = 4) sur RTX 2080 Ti</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS - YOLOv4 (416x416 batch = 1) sur Jetson AGX Xavier</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'utilisation de YOLOv4 peut √™tre √©tendue pour d√©tecter des bo√Ætes 3D tourn√©es ou des points cl√©s / points de rep√®re faciaux, par exemple: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ouyanghuiyu/darknet_face_with_landmark</font></font></a><br>
<br>
<img src="https://habrastorage.org/webt/z7/vs/dv/z7vsdvhcpfbrgmdv1byhbpzd1cu.jpeg"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr503182/index.html">"Je suis le premier d√©veloppeur aveugle de mon entreprise." Partie 1</a></li>
<li><a href="../fr503184/index.html">Nous vous invitons √† la r√©union en ligne Zabbix</a></li>
<li><a href="../fr503192/index.html">oVirt en 2 heures. Partie 4. Op√©rations de base</a></li>
<li><a href="../fr503194/index.html">ISA ne pardonne pas les erreurs</a></li>
<li><a href="../fr503196/index.html">450 cours gratuits de la Ivy League</a></li>
<li><a href="../fr503204/index.html">Comment flasher Xiaomi Redmi 4 Prime / Pro / Premium sur Android 10</a></li>
<li><a href="../fr503208/index.html">Quel est le meilleur moment pour investir?</a></li>
<li><a href="../fr503210/index.html">Les sites de phishing peuvent-ils √™tre √©radiqu√©s?</a></li>
<li><a href="../fr503212/index.html">30 astuces pour terminer le cours en ligne</a></li>
<li><a href="../fr503214/index.html">Optimisation de la charge sur un projet Highload avec ElasticSearch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎎 🙅🏻 👩🏼‍🔬 ACL 2019会議メモ 🛳️ ♊️ 👩🏻‍🤝‍👨🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="計算言語学協会（ACL）の年次総会は、最高の自然言語処理会議です。 1962年から組織されています。カナダとオーストラリアの後、彼女はヨーロッパに戻り、フィレンツェに行進しました。したがって、今年は同様のEMNLPよりもヨーロッパの研究者に人気がありました。
 
 今年は2900点の投稿のうち660...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ACL 2019会議メモ</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/463241/"><img src="https://habrastorage.org/webt/to/6d/jy/to6djymeashzcthmzckiaiwlnsg.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
計算言語学協会（ACL）の年次総会は、最高の自然言語処理会議です。 1962年から組織されています。カナダとオーストラリアの後、彼女はヨーロッパに戻り、フィレンツェに行進しました。したがって、今年は同様のEMNLPよりもヨーロッパの研究者に人気がありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今年は2900点の投稿のうち660点が掲載されました。たくさん。会議の内容を客観的に見直すことはほとんど不可能です。そのため、今回の出来事から主観的な気持ちをお伝えします。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
カンファレンスに来て、ポスターセッションで</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Googleの</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">性別代名詞の決議</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に関するKaggleコンテスト</font><font style="vertical-align: inherit;">の</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">結果を紹介しました</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">私たちのソリューションは、事前</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニングされたBERTモデルの</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">使用に大きく依存していました</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">そして、結局のところ、これだけではありませんでした。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bertology</font></font></h2><br>
<img src="https://habrastorage.org/webt/ol/zh/ba/olzhbat3al984zylni9zvcrizqo.jpeg"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BERTに基づいて、その特性を説明し、地下室として使用する非常に多くの作品があり、Bertologyという用語さえ登場しました。</font><font style="vertical-align: inherit;">実際、BERTモデルは非常に成功しているため、大規模な研究グループでさえ、モデルをBERTと比較しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そのため、6月の初めに、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">XLNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に関する作品が登場し</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ました</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">会議直前</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">-ERNIE </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.0</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">と</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RoBERTa</font></font></a><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facebook RoBERTa</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
XLNetモデルが最初に導入されたとき、一部の研究者は、そのアーキテクチャとトレーニングの原則だけでなく、より良い結果を達成したと提案しました。</font><font style="vertical-align: inherit;">彼女はまた、BERTよりも大きく（ほぼ10倍）、長い（4倍の反復）ボディについても研究しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Facebookの研究者たちは、BERTがまだ最大値に達していないことを示しています。</font><font style="vertical-align: inherit;">彼らは、BERTモデルを教えるための最適化されたアプローチを提示しました-RoBERTa（堅牢に最適化されたBERTアプローチ）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルのアーキテクチャを変更せずに、トレーニング手順を変更しました。</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニングのボディ、バッチのサイズ、シーケンスの長さ、トレーニング時間を増やしました。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">次の文を予測するタスクはトレーニングから削除されました。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">彼らは動的にMASKトークン（モデルが事前トレーニング中に予測しようとするトークン）を生成し始めました。</font></font></li>
</ol><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BaiduによるERNIE 2.0</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最近のすべての人気モデル（BERT、GPT、XLM、RoBERTa、XLNet）と同様に、ERNIEは自己注意メカニズムを備えたトランスのコンセプトに基づいています。</font><font style="vertical-align: inherit;">他のモデルとの違いは、マルチタスク学習と継続学習の概念です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ERNIEはさまざまなタスクについて学習し、言語モデルの内部表現を常に更新します。</font><font style="vertical-align: inherit;">これらのタスクには、他のモデルと同様に、自己学習（自己監視および弱い監視）の目標があります。</font><font style="vertical-align: inherit;">そのようなタスクの例：</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文中の正しい語順を復元します。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">単語の大文字化。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">マスクされた単語の定義。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらのタスクでは、モデルは順次学習し、以前にトレーニングされたタスクに戻ります。</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RoBERTa対ERNIE</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
出版物では、RoBERTaとERNIEはほとんど同時に出現したため、相互に比較されていません。</font><font style="vertical-align: inherit;">それらはBERTおよびXLNetと比較されます。</font><font style="vertical-align: inherit;">しかし、ここで比較することはそれほど簡単ではありません。</font><font style="vertical-align: inherit;">たとえば、人気のある</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ベンチマーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">では、</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">GLUE</font></a><font style="vertical-align: inherit;"> &nbsp;XLNetはモデルの集合によって表されます。</font><font style="vertical-align: inherit;">また、Baiduの研究者は、単一モデルの比較により関心を持っています。</font><font style="vertical-align: inherit;">さらに、Baiduは中国の企業であるため、中国語での作業結果を比較することにも関心があります。</font><font style="vertical-align: inherit;">最近では、新しいベンチマークである</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SuperGLUE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が登場し</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ました</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">まだ多くの解決策はありませんが、RoBERTaが最初にここにあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、全体として、RoBERTaとERNIEはどちらもXLNetよりもパフォーマンスが高く、BERTよりも大幅にパフォーマンスが優れています。</font><font style="vertical-align: inherit;">同様に、RoBERTaはERNIEよりも少し優れています。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">知識のグラフ</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
事前トレーニング済みのネットワークと、ナレッジグラフ（ナレッジグラフ、KG）の形式でのルールの使用という2つのアプローチを組み合わせることに多くの作業が費やされています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
例：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ERNIE：情報エンティティを備えた拡張言語表現</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。このペーパーでは、BERT言語モデルでのナレッジグラフの使用に焦点を当てています。これにより、エンティティのタイプの決定などのタスクで最良の結果を得ることができます（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="></a><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">エンティティタイピング）および関係分類</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一般に、「セサミストリート」のキャラクターの名前でモデルの名前を選択する方法は、面白い結果をもたらします。たとえば、このERNIEは、上で書いたBaiduのERNIE 2.0とは関係ありません。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/um/6y/qp/um6yqpe7esqpdixrlodndhuf_pi.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
新しい知識の生成に関するもう1つの興味深い研究：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">COMET：自動知識グラフ構築のための常識的なトランスフォーマー</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">このペーパーでは、知識ベースのネットワークをトレーニングするために、トランスフォーマーに基づく新しいアーキテクチャを使用する可能性について検討します。</font><font style="vertical-align: inherit;">簡略化された形式の知識ベースは、主語、態度、目的語の多くのトリプルです。</font><font style="vertical-align: inherit;">彼らは、ATOMICとConceptNetの2つのナレッジベースデータセットを取得しました。</font><font style="vertical-align: inherit;">また、GPT（Generative Pre-trained Transformer）モデルに基づいてネットワークをトレーニングしました。</font><font style="vertical-align: inherit;">被験者と態度が入力され、オブジェクトを予測しようとしました。</font><font style="vertical-align: inherit;">したがって、彼らは入力主体と関係によってオブジェクトを生成するモデルを得ま​​した。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">指標</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
会議でのもう1つの興味深いトピックは、メトリックの選択でした。多くの場合、自然言語処理タスクでモデルの品質を評価することは難しいため、機械学習のこの領域の進行が遅くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
で</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">適切な得点範囲で勉強要約評価指標</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の記事、マキシムPeyarは、テキスト要約の問題のさまざまなメトリックの使用について説明します。これらのメトリックは常に互いに適切に相関するとは限らないため、さまざまなアルゴリズムの客観的な比較が妨げられます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
または、ここに興味深い仕事があります：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">マルチセンテンステキストの自動評価</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。その中で、著者は、いくつかの文のテキストを評価する必要があるタスクでBLEUとROUGEを置き換えることができるメトリックを提示します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BLEUメトリックは、精度-モデルの応答からの単語（またはnグラム）がターゲットに含まれる単語の数として表すことができます。 ROUGE is Recall-モデルの応答にターゲットからの単語（またはn-gram）がいくつ含まれるか。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この記事で提案されているメトリックは、WMD（Word Mover's Distance）メトリック（2つのドキュメント間の距離）に基づいています。これは、これらの単語のベクトル表現の空間における2つの文の単語間の最小距離に等しくなります。 WMDの詳細については</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、Word2Vec</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">および</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">GloVeのWMD</font></a><font style="vertical-align: inherit;">を使用するチュートリアル</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">を参照</font></a><font style="vertical-align: inherit;">し</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">てください</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼らの記事では、WMS（Word Mover's Similarity）という新しいメトリックを提供しています。</font></font><br>
<br>
<pre><code class="plaintext hljs">WMS(A, B) = exp(−WMD(A, B))</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次に、SMS（Sentence Mover's Similarity）を定義します。</font><font style="vertical-align: inherit;">WMSでのアプローチと同様のアプローチを使用します。</font><font style="vertical-align: inherit;">センテンスのベクトル表現として、それらはセンテンスワードの平均化されたベクトルを取ります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
WMSを計算するとき、単語はドキュメント内の頻度によって正規化されます。</font><font style="vertical-align: inherit;">SMSセンテンスを計算する場合、センテンス内の単語数によって正規化されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最後に、S + WMSメトリックはWMSとSMSの組み合わせです。</font><font style="vertical-align: inherit;">彼らの記事で、彼らは彼らの測定基準が人の手動評価とよりよく相関していると指摘します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">チャットボット</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私の意見では、会議の最も有用な部分はポスターセッションでした。すべてのレポートが面白かったわけではありませんが、1つを聞き始めた場合、レポートの途中で別のレポートに移動することはありません。ポスターについては別の問題です。ポスターセッションには数十人いる。あなたが好きなものを選択し、通常は技術的な詳細について開発者と直接話すことができます。ちなみに、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">会議のポスターが</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">掲載された面白いサイトがあり</font><font style="vertical-align: inherit;">ます。確かに、そこには2つの会議からのポスターがあり、サイトが更新されるかどうかは不明です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/tm/y9/z4/tmy9z4i7y1tzu2gxpk5kfheopqy.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ポスターセッションでは、大企業がしばしば興味深い作品を発表しました。たとえば、Facebookの記事「</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">導入後の対話から学ぶ：フィードボット、チャットボット！」</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼らのシステムの特徴は、ユーザー応答の拡張された使用です。</font><font style="vertical-align: inherit;">彼らは、ユーザーが会話にどれだけ満足しているかを評価する分類子を持っています。</font><font style="vertical-align: inherit;">彼らはさまざまなタスクにこの情報を使用します。</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">品質の指標として満足度の指標を使用します。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">彼らはモデルを訓練し、継続的学習のアプローチを適用します（継続的学習）。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ダイアログで直接使用します。</font><font style="vertical-align: inherit;">ユーザーが満足したら、人間の反応を表現します。</font><font style="vertical-align: inherit;">または、ユーザーが満足していない場合は何が悪いのかを尋ねます。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
レポートから、マイクロソフトの中国のチャットボットに関する興味深い話がありました。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">共感的なソーシャルチャットボットであるXiaoIceの設計と実装は</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
、人工知能技術の実装におけるリーダーの1つになりました。しかし、中国で何が起こっているかは、ヨーロッパではよく知られていないことがよくあります。 XiaoIceは素晴らしいプロジェクトです。それはすでに5年間存在しています。この時代の多くのチャットボットは現在働いていません。 2018年には、すでに6億6,000万人のユーザーがいました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このシステムには、おしゃべりボットとスキルシステムの両方があります。ボットにはすでに230のスキルがあります。つまり、週に約1つのスキルが追加されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
おしゃべりボットの品質を評価するために、彼らは対話の継続時間を使用します。</font><font style="vertical-align: inherit;">そして、よくあるように、数分ではなく、会話内のレプリカの数です。</font><font style="vertical-align: inherit;">彼らはこのメトリクスをセッションあたりの会話ターン数（CPS）と呼び、現時点では平均値が23であることを書きます。これは、同様のシステムの中で最良の指標です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一般的に、このプロジェクトは中国で非常に人気があります。</font><font style="vertical-align: inherit;">ボット自体に加えて、システムは詩を書き、絵を描き</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、服のコレクションをリリースし</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、歌を歌います。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">機械翻訳</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
私が出席したすべてのスピーチの中で、最も活発なのは、</font><font style="vertical-align: inherit;">百度研究を代表</font><font style="vertical-align: inherit;">する</font><font style="vertical-align: inherit;">梁黄の</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">同時通訳</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">レポートでした</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼は現代の同時通訳におけるそのような困難について話しました：</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">世界には3,000人の認定同時通訳しかありません。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">翻訳者は15〜20分しか継続して作業できません。</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">翻訳元テキストの約60％だけが翻訳されます。</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
全文翻訳はすでに良いレベルに達していますが、同時通訳についてはまだ改善の余地があります。</font><font style="vertical-align: inherit;">例として、彼はバイドゥ世界会議で機能した彼らの同時通訳システムを引用しました。</font><font style="vertical-align: inherit;">2017年と比較した2018年の翻訳の遅延は、10秒から3秒に短縮されました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多くのチームがこれを行うことはなく、稼働しているシステムはほとんどありません。</font><font style="vertical-align: inherit;">たとえば、Googleがオンラインで書き込んだフレーズを翻訳すると、常に最終フレーズが再作成されます。</font><font style="vertical-align: inherit;">そして、これは同時通訳ではありません。同時通訳では、すでに話されている言葉を変えることができないからです。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ko/z9/xg/koz9xgvrqfclne8wwzw02fxwrdy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
彼らのシステムでは、フレーズの一部である接頭辞翻訳を使用します。つまり、彼らはいくつかの単語を待って翻訳を開始し、ソースに何が表示されるかを推測しようとします。このシフトのサイズは言葉で測定され、適応的です。各ステップの後のシステムは、待つ価値があるかどうか、またはすでに翻訳することが可能かどうかを決定します。この遅延を評価するために、彼らは次のメトリックを導入します：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">平均</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">遅延</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">（AL）のメトリック</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
同時翻訳の主な問題は、言語の語順が異なることです。そして、コンテキストはこれと戦うのに役立ちます。たとえば、政治家のスピーチを翻訳する必要があることがよくありますが、彼らはかなりステレオタイプです。しかし、問題もあります。それからスピーカーはトランプについて冗談を言った。それで、もしブッシュがモスクワに飛んだならば、プーチンと会うためにそれが非常にありそうであると彼は言います。そしてトランプが飛行機に乗ったなら、彼は会ってゴルフをすることができます。一般的に、翻訳するとき、人々はしばしば思いつき、自分から何かを追加します。たとえば、ある種のジョークを翻訳する必要があり、すぐに翻訳できない場合は、「ジョークがここで言われた、ただ笑う」と言うことができます。</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
また、「The Best Long Paper」賞を受賞した機械翻訳に関する記事もありました。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ニューラル機械翻訳のトレーニングと推論の間のギャップを埋める</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そのような機械翻訳の問題について説明しています。</font><font style="vertical-align: inherit;">学習プロセスでは、既知の単語のコンテキストに基づいて単語ごとの翻訳を生成します。</font><font style="vertical-align: inherit;">モデルを使用するプロセスでは、新しく生成された単語のコンテキストに依存します。</font><font style="vertical-align: inherit;">モデルのトレーニングと使用には違いがあります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この不一致を減らすために、著者は、コンテキストのトレーニングの段階で、同じトレーニング中にモデルによって予測された単語を混合することを提案しています。</font><font style="vertical-align: inherit;">この記事では、そのような生成された単語の最適な選択について説明します。</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もちろん、会議は記事やレポートだけではありません。</font><font style="vertical-align: inherit;">また、コミュニケーション、デート、その他のネットワーキングでもあります。</font><font style="vertical-align: inherit;">さらに、会議の主催者は、どういうわけか参加者を楽しませようとしています。</font><font style="vertical-align: inherit;">ACLでは、メインパーティーでテノール、イタリアのパフォーマンスが行われました。</font><font style="vertical-align: inherit;">要約すると、他の会議の主催者からの発表がありました。</font><font style="vertical-align: inherit;">そして、参加者の間で最も激しい反応は、今年のメインパーティーは香港ディズニーランドで開催され、2020年には会議がドミニカ共和国で開催されるというEMNLPの主催者からのメッセージによって引き起こされました。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja463229/index.html">文化の中のジェットパック：映画</a></li>
<li><a href="../ja463231/index.html">Cisco 200-125 CCNA v3.0のトレーニング。14日目。VTP、プルーニング、ネイティブVLAN</a></li>
<li><a href="../ja463233/index.html">Cisco 200-125 CCNA v3.0のトレーニング。15日目遅い通信とポートセキュリティ</a></li>
<li><a href="../ja463237/index.html">ニューラルネットワークv 2.0で音楽を再生する方法</a></li>
<li><a href="../ja463239/index.html">8月22日-Alfa JS MeetUP SPb</a></li>
<li><a href="../ja463243/index.html">意識の操作。なぜそんなに簡単なのですか？</a></li>
<li><a href="../ja463245/index.html">TEW2でのDWHリポジトリの配置方法</a></li>
<li><a href="../ja463247/index.html">情報ツール、またはサービスとプロセスについて話し合う方法</a></li>
<li><a href="../ja463249/index.html">Game Dev Sim：ゲーム開発に関するボードゲーム</a></li>
<li><a href="../ja463251/index.html">OSMデータから都市のサブセット（任意の関係）を切り取る方法</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
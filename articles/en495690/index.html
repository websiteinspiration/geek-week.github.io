<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚘 🍐 👩🏾‍🎤 Web Audio API Concepts 👩🏻‍🤝‍👨🏾 🙎🏻 👲🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day, friends! 
 
 This article explains some concepts from the theory of music that the Web Audio API (WAA) operates on. Knowing these concepts, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Web Audio API Concepts</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/495690/"><img src="https://habrastorage.org/webt/_r/j3/qd/_rj3qdi2rvk5vwbvfskmddp8yic.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Good day, friends! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This article explains some concepts from the theory of music that the Web Audio API (WAA) operates on. </font><font style="vertical-align: inherit;">Knowing these concepts, you can make informed decisions when designing audio in an application. </font><font style="vertical-align: inherit;">This article will not make you an experienced sound engineer, but it will help you understand why WAA works the way it works.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audio circuit</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The essence of WAA is to perform some operations with sound within an audio context. This API has been specifically designed for modular routing. The basic operations with sound are audio nodes, interconnected and forming a routing diagram (audio routing graph). Several sources - with different types of channels - are processed within a single context. This modular design provides the necessary flexibility to create complex functions with dynamic effects.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Audio nodes are interconnected through inputs and outputs, form a chain that starts from one or more sources, passes through one or more nodes, and ends at the destination. </font><font style="vertical-align: inherit;">In principle, you can do without a destination, for example, if we just want to visualize some audio data. </font><font style="vertical-align: inherit;">A typical web audio workflow looks something like this:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Create an audio context</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inside the context, create sources - such as &lt;audio&gt;, an </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">oscillator (sound generator)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> or stream</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Create effect nodes such as </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">reverb</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , biquad filter, panner or compressor</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Select a destination for audio, such as speakers on a user's computer</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Establish a connection between sources through effects to a destination</font></font></li>
</ol><br>
<img src="https://habrastorage.org/webt/76/wq/vv/76wqvvwgifik6zojizkg_dxxb9q.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Channel designation</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The number of available audio channels is often indicated in numerical format, for example, 2.0 or 5.1. </font><font style="vertical-align: inherit;">This is called the channel designation. </font><font style="vertical-align: inherit;">The first digit indicates the full range of frequencies that the signal includes. </font><font style="vertical-align: inherit;">The second digit indicates the number of channels reserved for the low-frequency effect outputs - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">subwoofers</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Each input or output consists of one or more channels built according to a certain audio circuit. </font><font style="vertical-align: inherit;">There are various discrete channel structures such as mono, stereo, quad, 5.1, etc. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7z/rn/xy/7zrnxy_vaeyntkb3o5hgvbvs_k4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Audio sources can be obtained in many ways. </font><font style="vertical-align: inherit;">The sound may be:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Generated by JavaScript through an audio node (such as an oscillator)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Created from raw data using </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PCM (Pulse Code Modulation)</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Derived from HTML media elements (such as &lt;video&gt; or &lt;audio&gt;)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Derived from a WebRTC media stream (such as a webcam or microphone)</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audio data: what is in the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sample</font></font></a></h3><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sampling</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> means converting a continuous signal into a discrete (divided) (analog to digital) signal. </font><font style="vertical-align: inherit;">In other words, a continuous sound wave, such as a live concert, is converted into a sequence of samples, which allows the computer to process the audio in separate blocks.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audio Buffer: Frames, Samples, and Channels</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AudioBuffer accepts the number of channels as parameters (1 for mono, 2 for stereo, etc.), length - the number of sample frames inside the buffer, and sampling frequency - the number of frames per second. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A sample is a simple 32-bit floating-point value (float32), which is the value of the audio stream at a particular point in time and in a particular channel (left or right, etc.). A sample frame or frame is a set of values ​​of all channels reproduced at a certain point in time: all samples of all channels reproduced at the same time (two for stereo, six for 5.1, etc.). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The sampling rate is the number of samples (or frames, since all samples in a frame are played at one time), played back in one second, measured in hertz (Hz). The higher the frequency, the better the sound quality.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's look at mono and stereo buffers, each one second long, reproduced at a frequency of 44100 Hz:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mono buffer will have 44100 samples and 44100 frames. </font><font style="vertical-align: inherit;">The value of the “length” property is 44100</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The stereo buffer will have 88,200 samples, but also 44,100 frames. </font><font style="vertical-align: inherit;">The value of the “length” property will be 44100 - the length is equal to the number of frames</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/uq/hp/pq/uqhppqfp_yz_k_hk_axza9j7qgm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When the playback of the buffer begins, we first hear the leftmost frame of the sample, then the nearest right frame, etc. In the case of stereo, we hear both channels simultaneously. Sample frames are independent of the number of channels and provide the opportunity for very accurate audio processing. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note: to get the time in seconds from the number of frames, it is necessary to divide the number of frames by the sampling rate. To get the number of frames from the number of samples, divide the latter by the number of channels. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Example:</font></font><br>
<br>
<pre><code class="javascript hljs"><span class="hljs-keyword">let</span> context = <span class="hljs-keyword">new</span> AudioContext()
<span class="hljs-keyword">let</span> buffer = context.createBuffer(<span class="hljs-number">2</span>, <span class="hljs-number">22050</span>, <span class="hljs-number">44100</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note: in digital audio, 44100 Hz or 44.1 kHz is the standard sampling frequency. But why 44.1 kHz? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Firstly, because the range of audible frequencies (frequencies distinguishable by the human ear) varies from 20 to 20,000 Hz. According to Kotelnikov’s theorem, the sampling frequency should more than double the highest frequency in the signal spectrum. Therefore, the sampling frequency should be greater than 40 kHz. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secondly, the signals must be filtered using a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">low-pass filter.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">before sampling, otherwise there will be an overlap of spectral “tails” (frequency swapping, frequency masking, aliasing) and the shape of the reconstructed signal will be distorted. Ideally, a low-pass filter should pass frequencies below 20 kHz (without attenuation) and drop frequencies above 20 kHz. In practice, some transition band is required (between the passband and the suppression band), where the frequencies are partially attenuated. An easier and more economical way to do this is to use an anti-change filter. For a sampling frequency of 44.1 kHz, the transition band is 2.05 kHz. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the above example, we get a stereo buffer with two channels, reproduced in an audio context with a frequency of 44100 Hz (standard), 0.5 second long (22050 frames / 44100 Hz = 0.5 s).</font></font><br>
<br>
<pre><code class="javascript hljs"><span class="hljs-keyword">let</span> context = <span class="hljs-keyword">new</span> AudioContext()
<span class="hljs-keyword">let</span> buffer = context.createBuffer(<span class="hljs-number">1</span>, <span class="hljs-number">22050</span>, <span class="hljs-number">22050</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this case, we get a mono buffer with one channel, reproduced in an audio context with a frequency of 44100 Hz, it will oversampling to 44100 Hz (and increasing the frames to 44100), 1 second long (44100 frames / 44100 Hz = 1 s). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note: Audio resampling (“resampling”) is very similar to resizing (“resizing”) images. </font><font style="vertical-align: inherit;">Suppose we have a 16x16 image, but we want to fill this area with a 32x32 size. </font><font style="vertical-align: inherit;">We do resizing. </font><font style="vertical-align: inherit;">The result will be less quality (it may be blurry or torn depending on the zoom algorithm), but it works. </font><font style="vertical-align: inherit;">Resampled audio is the same thing: we save space, but in practice it’s unlikely to achieve high quality sound.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Planar and Striped Buffers</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
WAA uses a planar buffer format. </font><font style="vertical-align: inherit;">The left and right channels interact as follows:</font></font><br>
<br>
<pre><code class="javascript hljs">LLLLLLLLLLLLLLLLRRRRRRRRRRRRRRRR ( ,   <span class="hljs-number">16</span> )
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this case, each channel works independently of the others. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An alternative is to use an alternating format:</font></font><br>
<br>
<pre><code class="javascript hljs">LRLRLRLRLRLRLRLRLRLRLRLRLRLRLRLR ( ,   <span class="hljs-number">16</span> )
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This format is often used for MP3 decoding. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
WAA uses only the planar format, as it is better suited for sound processing. </font><font style="vertical-align: inherit;">The planar format is converted to alternating when data is sent to the sound card for playback. </font><font style="vertical-align: inherit;">When decoding MP3s, the inverse is converted.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audio channels</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Different buffers contain a different number of channels: from simple mono (one channel) and stereo (left and right channels) to more complex sets, such as quad and 5.1 with a different number of samples in each channel, which provides a richer (richer) sound. </font><font style="vertical-align: inherit;">Channels are usually represented by abbreviations:</font></font><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mono</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: M: mono</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stereo</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: L: left </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1: R: right</font></font><br>
 </td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quadro</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: L: left </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1: R: right </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3: SL: additional left (left channel creating the environment; surround left) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4: SR: additional right (surround right)</font></font><br>
 </td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.1</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: L: left </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1: R: right </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2: C: center </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3: LFE: subwoofer </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4: SL: extra left </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
5: SR: extra right</font></font><br>
 </td>
</tr>
</tbody></table></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Up-mixing and down-mixing</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When the number of channels at the input and output does not match, apply mixing up or down. </font><font style="vertical-align: inherit;">Mixing is controlled by the AudioNode.channelInterpretation property:</font></font><br>
<div class="scrollable-table"><table>
<thead>
<tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Input channels</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Output channels</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mixing rules</font></font></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="3"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Standard channel mixing schemes - used when the channelInterpretation property is set for speakers (speakers).</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 (Mono)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 (Stereo)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mix up from mono to stereo. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Input channel M is used for both output channels (L and R). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.L = input.M </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.R = input.M</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 (Mono)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 (Quad)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mix up from mono to quad. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Input channel M is used for the main channels (L and R). </font><font style="vertical-align: inherit;">Additional channels are muffled. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.L = input.M </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.R = input.M </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.SL = 0 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.SR = 0</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 (Mono)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6 (5.1)</font></font></td>
<td>     5.1.<br>
       ©.   (L, R, LFE, SL  SR) .<br>
output.L = 0<br>
output.R = 0<br>
output.C = input.M<br>
output.LFE = 0<br>
output.SL = 0<br>
output.SR = 0</td>
</tr>
<tr>
<td>2 ()</td>
<td>1 ()</td>
<td>     .<br>
   (L  R)     (M).<br>
output.M = 0.5 * (input.L + input.R)</td>
</tr>
<tr>
<td>2 ()</td>
<td>4 ()</td>
<td>     .<br>
  L  R      (L  R).   (SL  SR) .<br>
output.L = input.L<br>
output.R = input.R<br>
output.SL = 0<br>
output.SR = 0</td>
</tr>
<tr>
<td>2 ()</td>
<td>6 (5.1)</td>
<td>     5.1.<br>
  L  R      (L  R).    (SL  SR),   ©   (LFE) .<br>
output.L = input.L<br>
output.R = input.R<br>
output.C = 0<br>
output.LFE = 0<br>
output.SL = 0<br>
output.SR = 0</td>
</tr>
<tr>
<td>4 ()</td>
<td>1 ()</td>
<td>     .<br>
    (L, R, SL  SR)      (M).<br>
output.M = 0.25 * (input.L + input.R + input.SL + input.SR)</td>
</tr>
<tr>
<td>4 ()</td>
<td>2 ()</td>
<td>     .<br>
    (L  SL)       (L).   (R  SR) —   ®.<br>
output.L = 0.5 * (input.L + input.SL)<br>
output.R = 0.5 * (input.R + input.SR)</td>
</tr>
<tr>
<td>4 ()</td>
<td>6 (5.1)</td>
<td>     5.1.<br>
  L, R, SL  SR     .    ©   (LFE) .<br>
output.L = input.L<br>
output.R = input.R<br>
output.C = 0<br>
output.LFE = 0<br>
output.SL = input.SL<br>
output.SR = input.SR</td>
</tr>
<tr>
<td>6 (5.1)</td>
<td>1 ()</td>
<td>   5.1  .<br>
 (L  SL),  (R  SR)   ()     .   ,     ,       —      √2 / 2.  (LFE) .<br>
output.M = 0.7071 * (input.L + input.R) + input.C + 0.5 * (input.SL + input.SR)</td>
</tr>
<tr>
<td>6 (5.1)</td>
<td>2 ()</td>
<td>   5.1  .<br>
  ©       (SL  SR)         (L  R).             √2 / 2.  (LFE) .<br>
output.L = input.L + 0.7071 * (input.C + input.SL)<br>
output.R = input.R + 0.7071 * (input.C + input.SR)</td>
</tr>
<tr>
<td>6 (5.1)</td>
<td>4 ()</td>
<td>   5.1  .<br>
  ()      (L  R).           √2 / 2.     .  (LFE) .<br>
output.L = input.L + 0.7071 * input.C<br>
output.R = input.R + 0.7071 * input.C<br>
output.SL = input.SL<br>
output.SR = input.SR</td>
</tr>
<tr>
<td colspan="3">    — ,   channelInterpretation   discrete.</td>
</tr>
<tr>
<td> (x)</td>
<td> (y),  x&lt;y</td>
<td>  .<br>
        (   ). ,     , .</td>
</tr>
<tr>
<td> (x)</td>
<td> (y),  x&gt;y</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Each output channel is combined with its input analog (having the same index). </font><font style="vertical-align: inherit;">Channels that do not have corresponding output channels are discarded.</font></font></td>
</tr>
</tbody>
</table></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualization</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Visualization is based on receiving output audio data, such as data on amplitude or frequency, and their subsequent processing using any graphic technology. </font><font style="vertical-align: inherit;">WAA has an AnalyzerNode that does not distort the signal passing through it. </font><font style="vertical-align: inherit;">At the same time, it is able to extract data from audio and transfer it further, for example, to &amp; ltcanvas&gt;. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w3/03/tk/w303tkjj1p7imhxsaegp0vtabyu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The following methods can be used to extract data:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AnalyzerNode.getFloatByteFrequencyData () - copies the current frequency data to the Float32Array</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AnalyzerNode.getByteFrequencyData () - copies the current frequency data to a Uint8Array (unsigned byte array)</font></font></li>
<li>AnalyserNode.getFloatTimeDomainData() —            Float32Array</li>
<li>AnalyserNode.getByteTimeDomainData() —            Uint8Array</li>
</ul><br>
<h3></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Audio spatialization (processed by PannerNode and AudioListener) allows you to simulate the position and direction of the signal at a specific point in space, as well as the position of the listener. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The position of the panner is described using right-handed Cartesian coordinates; </font><font style="vertical-align: inherit;">for motion, the velocity vector necessary to create </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the Doppler effect is used</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ; for direction, the directivity cone is used. </font><font style="vertical-align: inherit;">This cone can be very large in the case of multidirectional sound sources. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rl/mj/tz/rlmjtz9l-3elsukt6gdnd81xbe4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The position of the listener is described as follows: movement - using the velocity vector, the direction where the head of the listener is - using two directional vectors, front and top. </font><font style="vertical-align: inherit;">Snapping is done to the top of the head and nose of the listener at right angles.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7q/-w/hk/7q-whktcaasufh9jfy8z6cigrbc.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Junction and branching</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A connection describes a process in which a ChannelMergerNode receives several input mono sources and combines them into a single multi-channel output signal. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vk/bv/qh/vkbvqhpvhnghgf55bx9umic_yhc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Branching is the reverse process (implemented through ChannelSplitterNode). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/6d/9c/y7/6d9cy7_hiinrgqscxxdsbe3x-zy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
An example of working with WAA can be found </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The source code for the example is </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here's</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> an article about how it all works. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Thank you for attention.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en495678/index.html">Competition VK Sup. Track ML. 4th place. How?</a></li>
<li><a href="../en495682/index.html">API reverse for its android application</a></li>
<li><a href="../en495684/index.html">5 reasons why interacting with your end users improves your code</a></li>
<li><a href="../en495686/index.html">Personal Las Vegas, or a game in the browser extension</a></li>
<li><a href="../en495688/index.html">Active Directory Based Zimbra Collaboration OSE User Synchronization</a></li>
<li><a href="../en495692/index.html">DIY and Open Source to help doctors</a></li>
<li><a href="../en495694/index.html">Mobile application reference service</a></li>
<li><a href="../en495696/index.html">How Prince of Persia Creator Overcomes Apple II's Memory Limits</a></li>
<li><a href="../en495698/index.html">Client-server architecture in pictures</a></li>
<li><a href="../en495700/index.html">Doom Boy ESP32</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
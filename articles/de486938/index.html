<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÖ ü¶á üìó Verst√§ndnis des maschinellen Lernmodells, das CAPTCHA bricht üóÑÔ∏è üóìÔ∏è ü§üüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo alle zusammen! Diesen Monat rekrutiert OTUS eine neue Gruppe f√ºr den Kurs f√ºr maschinelles Lernen . Nach g√§ngiger Tradition teilen wir Ihnen am ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Verst√§ndnis des maschinellen Lernmodells, das CAPTCHA bricht</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/486938/"><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo alle zusammen! </font><font style="vertical-align: inherit;">Diesen Monat rekrutiert OTUS eine neue Gruppe f√ºr den Kurs f√ºr </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">maschinelles Lernen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Nach g√§ngiger Tradition teilen wir Ihnen am Vorabend des Kursbeginns die √úbersetzung von interessantem Material zum Thema mit.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/cp/sm/jx/cpsmjxfi8zhhkhj2hdrbew0i66u.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Computer Vision ist eines der relevantesten und am besten erforschten Themen der KI [1]. Aktuelle Methoden zur L√∂sung von Problemen mit Faltungs-Neuronalen Netzen werden jedoch ernsthaft kritisiert, da solche Netze leicht zu t√§uschen sind. Um nicht unbegr√ºndet zu sein, m√∂chte ich Ihnen einige Gr√ºnde nennen: Netzwerke dieses Typs liefern mit hoher Sicherheit ein falsches Ergebnis f√ºr nat√ºrlich vorkommende Bilder, die keine statistischen Signale enthalten [2], auf die sich Faltungs-Neuronale Netzwerke st√ºtzen, f√ºr Bilder, die zuvor korrekt klassifiziert wurden. aber in denen sich ein Pixel [3] oder Bilder mit physischen Objekten, die der Szene hinzugef√ºgt wurden, aber das Klassifizierungsergebnis nicht √§ndern mussten [4], ge√§ndert haben. Tatsache ist, wenn wir wirklich intelligente Maschinen schaffen wollen,Es sollte uns vern√ºnftig erscheinen, in das Studium neuer Ideen zu investieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine dieser neuen Ideen ist Vicarious 'Anwendung des Recursive Cortical Network (RCN), das sich von den Neurowissenschaften inspirieren l√§sst. </font><font style="vertical-align: inherit;">Dieses Modell behauptete, es sei √§u√üerst effektiv beim Brechen von Text-Captcha, wodurch </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">viel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> um sich herum </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">geredet werde</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Aus diesem Grund habe ich beschlossen, mehrere Artikel zu schreiben, von denen jeder einen bestimmten Aspekt dieses Modells erkl√§rt. </font><font style="vertical-align: inherit;">In diesem Artikel werden wir √ºber seine Struktur sprechen und wie die Erzeugung von Bildern, die in den Materialien des Hauptartikels √ºber RCN [5] dargestellt werden, erzeugt wird.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Artikel wird davon ausgegangen, dass Sie bereits mit Faltungs-Neuronalen Netzen vertraut sind, daher werde ich viele Analogien mit ihnen ziehen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um sich auf die RCN-Erkennung vorzubereiten, m√ºssen Sie verstehen, dass RCNs auf der Idee basieren, die Form (Skizze des Objekts) vom Erscheinungsbild (seiner Textur) zu trennen, und dass es sich um ein generatives Modell handelt, nicht um ein diskriminierendes Modell, sodass wir damit Bilder wie in einem generativen generieren k√∂nnen gegnerische Netzwerke. </font><font style="vertical-align: inherit;">Zus√§tzlich wird eine parallele hierarchische Struktur verwendet, √§hnlich der Architektur von Faltungs-Neuronalen Netzen, die mit dem Stadium der Bestimmung der Form des Zielobjekts in den unteren Schichten beginnt, und dann wird sein Aussehen auf der oberen Schicht hinzugef√ºgt. </font><font style="vertical-align: inherit;">Im Gegensatz zu Faltungs-Neuronalen Netzen basiert das Modell, das wir betrachten, auf einer reichen theoretischen Basis grafischer Modelle anstelle von gewichteten Summen und Gradientenabstieg. </font><font style="vertical-align: inherit;">Lassen Sie uns nun die Merkmale der RCN-Struktur untersuchen.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feature-Layer</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der erste Layertyp in RCN wird als Feature-Layer bezeichnet. Wir werden das Modell schrittweise betrachten. Nehmen wir daher zun√§chst an, dass die gesamte Hierarchie des Modells nur aus √ºbereinander gestapelten Schichten dieses Typs besteht. Wir werden von abstrakten Konzepten auf hoher Ebene zu spezifischeren Merkmalen der unteren Ebenen √ºbergehen, wie in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 1 dargestellt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Eine Schicht dieses Typs besteht aus mehreren Knoten, die sich im zweidimensionalen Raum befinden, √§hnlich wie Merkmalskarten in Faltungs-Neuronalen Netzen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ht/iu/jv/htiujvk93pvm2-bjqthrweo_beq.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 1</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Mehrere √ºbereinander angeordnete Feature-Layer mit Knoten im zweidimensionalen Raum. Der √úbergang von der vierten zur ersten Schicht bedeutet den √úbergang vom Allgemeinen zum Besonderen.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Knoten besteht aus mehreren Kan√§len, von denen jeder ein separates Merkmal darstellt. Kan√§le sind bin√§re Variablen, die den Wert True oder False annehmen und angeben, ob ein diesem Kanal entsprechendes Objekt im endg√ºltig erzeugten Bild in der Koordinate (x, y) des Knotens vorhanden ist. Auf jeder Ebene haben Knoten den gleichen Kanaltyp.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nehmen wir als Beispiel eine Zwischenschicht und sprechen √ºber ihre Kan√§le und die obigen Schichten, um die Erkl√§rung zu vereinfachen. Die Liste der Kan√§le auf dieser Ebene besteht aus einer Hyperbel, einem Kreis und einer Parabel. Bei einem bestimmten Lauf beim Erzeugen des Bildes erforderten die Berechnungen der dar√ºber liegenden Ebenen einen Kreis in der Koordinate (1,1). Somit hat der Knoten (1, 1) einen Kanal, der dem Objekt "Kreis" im Wert True entspricht. Dies wirkt sich direkt auf einige Knoten in der darunter liegenden Ebene aus, dh, die Features der unteren Ebene, die dem Kreis in der Nachbarschaft (1,1) zugeordnet sind, werden auf True gesetzt. Diese Objekte niedrigerer Ebene k√∂nnen beispielsweise vier B√∂gen mit unterschiedlichen Ausrichtungen sein. Wenn die Merkmale der unteren Ebene aktiviert sind, aktivieren sie die Kan√§le auf den Ebenen noch tiefer, bis die letzte Ebene erreicht ist.Bilderzeugung. Die Aktivierungsvisualisierung wird in angezeigt</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 2</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie fragen sich vielleicht, wie wird klar, dass die Darstellung eines Kreises 4 B√∂gen betr√§gt? Und woher wei√ü RCN, dass es einen Kanal ben√∂tigt, um den Kreis darzustellen? Kan√§le und ihre Bindungen an andere Schichten werden in der RCN-Trainingsphase gebildet. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ao/gr/s9/aogrs9u-zi-guzvwobln0wng8rw.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 2:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Informationsfluss in Feature-Layern. Zeichenknoten sind Kapseln, die Scheiben enthalten, die Kan√§le darstellen. Einige der oberen und unteren Schichten wurden der Einfachheit halber in Form eines Parallelepipeds dargestellt, in Wirklichkeit bestehen sie jedoch auch aus Merkmalsknoten als Zwischenschichten. Bitte beachten Sie, dass die obere Zwischenschicht aus 3 Kan√§len und die zweite Schicht aus 4 Kan√§len besteht.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie k√∂nnen eine sehr starre und deterministische Methode zur Erzeugung des angenommenen Modells angeben, aber f√ºr Menschen werden kleine St√∂rungen der Kr√ºmmung des Kreises immer noch als Kreis betrachtet, wie Sie in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 3 sehen k√∂nnen</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/o1/pr/fr/o1prfrwawffkxyvl62yb1k3czag.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 3:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Viele Variationen der Konstruktion eines Kreises aus vier gekr√ºmmten B√∂gen aus Abbildung 2.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Es w√§re schwierig, jede dieser Variationen als separaten neuen Kanal in der Schicht zu betrachten. </font><font style="vertical-align: inherit;">In √§hnlicher Weise wird das Gruppieren von Variationen in dieselbe Entit√§t die Verallgemeinerung in neue Variationen erheblich erleichtern, wenn wir RCN etwas sp√§ter an die Klassifizierung anpassen, anstatt sie zu generieren. </font><font style="vertical-align: inherit;">Aber wie √§ndern wir RCN, um diese Gelegenheit zu bekommen?</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unterabtastungsebenen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dazu ben√∂tigen Sie einen neuen Layertyp - den Pooling-Layer. Es befindet sich zwischen zwei beliebigen Zeichenschichten und fungiert als Vermittler zwischen ihnen. Es besteht auch aus Kan√§len, sie haben jedoch ganzzahlige Werte, keine bin√§ren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um zu veranschaulichen, wie diese Ebenen funktionieren, kehren wir zum Kreisbeispiel zur√ºck. Anstatt 4 B√∂gen mit festen Koordinaten von der dar√ºber liegenden Merkmalsebene als Merkmal eines Kreises zu ben√∂tigen, wird die Suche auf der Unterabtastungsebene durchgef√ºhrt. Dann w√§hlt jeder aktivierte Kanal in der Unterabtastschicht einen Knoten auf der darunter liegenden Schicht in seiner N√§he aus, um eine leichte Verzerrung des Merkmals zu erm√∂glichen. Wenn wir also eine Kommunikation mit 9 Knoten direkt unter dem Unterabtastknoten herstellen, w√§hlt der Unterabtastungskanal bei jeder Aktivierung gleichm√§√üig einen dieser 9 Knoten aus und aktiviert ihn, und der Index des ausgew√§hlten Knotens ist der Status des Unterabtastkanals - eine Ganzzahl. In </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 4</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie k√∂nnen mehrere L√§ufe sehen, bei denen jeder Lauf einen anderen Satz von Knoten niedrigerer Ebene verwendet, sodass Sie auf verschiedene Arten einen Kreis erstellen k√∂nnen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ma/6t/oe/ma6toei3ncssielvv8cuff5e97i.gif"><br>
 <i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 4:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Betrieb von Unterabtastschichten. Jeder Frame in diesem GIF-Bild ist ein separater Start. Unterabtastknoten werden gew√ºrfelt. In diesem Bild haben die Unterabtastknoten 4 Kan√§le, die 4 Kan√§len der darunter liegenden Merkmalsebene entsprechen. Die obere und untere Schicht wurden vollst√§ndig aus dem Bild entfernt.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Trotz der Tatsache, dass wir die Variabilit√§t unseres Modells brauchten, w√§re es besser, wenn es zur√ºckhaltender und fokussierter bleiben w√ºrde. In den beiden vorhergehenden Abbildungen sehen einige Kreise zu seltsam aus, um sie wirklich als Kreise zu interpretieren, da die B√∂gen nicht miteinander verbunden sind, wie aus </font><b><font style="vertical-align: inherit;">Abbildung 5</font></b><font style="vertical-align: inherit;"> ersichtlich ist</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir m√∂chten vermeiden, sie zu generieren. Wenn wir also einen Mechanismus f√ºr Unterabtastungskan√§le hinzuf√ºgen k√∂nnten, um die Auswahl von Merkmalsknoten zu koordinieren und uns auf kontinuierliche Formen zu konzentrieren, w√§re unser Modell genauer. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ci/bc/oa/cibcoalwwxl1yawero5mnooydua.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 5:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Viele Optionen zum Erstellen eines Kreises. Die Optionen, die wir l√∂schen m√∂chten, sind mit roten Kreuzen markiert.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
RCN-Autoren verwendeten zu diesem Zweck eine laterale Verbindung in Unterabtastungsschichten. Im Wesentlichen haben Unterabtastkan√§le Verbindungen mit anderen Unterabtastkan√§len aus der unmittelbaren Umgebung, und diese Verbindungen erm√∂glichen es nicht, dass einige Zustandspaare gleichzeitig in zwei Kan√§len koexistieren. Tats√§chlich wird der Abtastbereich dieser beiden Kan√§le einfach begrenzt. In verschiedenen Versionen des Kreises erlauben diese Verbindungen beispielsweise nicht, dass sich zwei benachbarte B√∂gen voneinander entfernen. Dieser Mechanismus ist in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 6 dargestellt.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Auch diese Beziehungen werden in der Trainingsphase hergestellt. Es sollte beachtet werden, dass moderne k√ºnstliche neuronale Vanille-Netze keine lateralen Verbindungen in ihren Schichten haben, obwohl sie in biologischen neuronalen Netzen existieren, und es wird angenommen, dass sie eine Rolle bei der Konturintegration im visuellen Kortex spielen (aber offen gesagt hat der visuelle Kortex wo komplexeres Ger√§t, als es aus der vorherigen Aussage hervorgeht). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fi/tw/xj/fitwxjlp-0qrkgnvt8fhwflbadm.gif"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 6:</font></font></b> GIF-   RCN   .    ,         .  ,   RCN           ,     ,    .         .</i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bisher haben wir √ºber Zwischenschichten von RCN gesprochen, wir haben nur die oberste Schicht und die unterste Schicht, die mit den Pixeln des erzeugten Bildes interagiert. Die oberste Ebene ist eine regul√§re Feature-Ebene, in der die Kan√§le jedes Knotens Klassen unseres beschrifteten Datensatzes sind. Beim Generieren w√§hlen wir einfach den Speicherort und die Klasse aus, die wir erstellen m√∂chten, gehen zum Knoten mit dem angegebenen Speicherort und sagen, dass er den Kanal der von uns ausgew√§hlten Klasse aktiviert. Dadurch werden einige der Kan√§le in der darunter liegenden Unterabtastebene, dann die darunter liegende Feature-Ebene usw. aktiviert, bis die letzte Feature-Ebene erreicht ist. Basierend auf Ihrem Wissen √ºber Faltungs-Neuronale Netze sollten Sie denken, dass die oberste Schicht einen einzelnen Knoten hat, aber dies ist nicht der Fall, und dies ist einer der Vorteile von RCN.Eine Diskussion dieses Themas w√ºrde jedoch den Rahmen dieses Artikels sprengen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der letzte Feature-Layer ist eindeutig. Erinnerst du dich, ich habe dar√ºber gesprochen, wie RCNs Form und Aussehen trennen? Es ist diese Schicht, die f√ºr das Erhalten der Form des erzeugten Objekts verantwortlich ist. Daher sollte diese Ebene mit Features auf sehr niedriger Ebene arbeiten, den grundlegendsten Bausteinen jeder Form, die uns helfen, jede gew√ºnschte Form zu erzeugen. Kleine R√§nder, die sich in verschiedenen Winkeln drehen, sind durchaus geeignet, und genau diese verwenden die Autoren der Technologie.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Autoren haben die Attribute der letzten Ebene ausgew√§hlt, um ein 3x3-Fenster mit einem Rand mit einem bestimmten Drehwinkel darzustellen, den sie als Patch-Deskriptor bezeichnen. Die Anzahl der ausgew√§hlten Drehwinkel betr√§gt 16. Um sp√§ter ein Erscheinungsbild hinzuf√ºgen zu k√∂nnen, ben√∂tigen Sie au√üerdem zwei Ausrichtungen f√ºr jede Drehung, um feststellen zu k√∂nnen, ob sich der Hintergrund am linken oder am rechten Rand befindet, wenn es sich um Au√üenr√§nder handelt und zus√§tzliche Orientierung im Fall von inneren Grenzen (d. h. innerhalb des Objekts). In </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 7</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sind die Eigenschaften der letzten Schichtanordnung dargestellt, und in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 8 ist dargestellt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , wie die Deskriptoren von Patches eine bestimmte Form erzeugen k√∂nnen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/gz/2o/mp/gz2ompbptag8mfcmey7ngj7ynem.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 7:</font></font></b>    .  48   ( ) ,  16    3 .    ‚Äì      45 . ‚ÄúIN "   ,  ‚ÄúOUT‚Äù ‚Äî .</i><br>
<br>
<img src="https://habrastorage.org/webt/dv/wu/-e/dvwu-ea0vfc7ff9pz2zn12w-tcw.png"><br>
<i><b> 8:</b>    ¬´i¬ª     .</i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir die letzte Zeichenebene erreicht haben, haben wir ein Diagramm, in dem die Grenzen des Objekts bestimmt werden und das Verst√§ndnis, ob sich der Bereich au√üerhalb der Grenze befindet, intern oder extern ist. Es bleibt ein Erscheinungsbild hinzuzuf√ºgen, das jeden verbleibenden Bereich im Bild als IN oder OUT kennzeichnet und den Bereich √ºbermalt. Ein bedingtes Zufallsfeld kann hier helfen. Ohne auf mathematische Details einzugehen, weisen wir einfach jedem Pixel im endg√ºltigen Bild eine Wahrscheinlichkeitsverteilung nach Farbe und Zustand (IN oder OUT) zu. Diese Verteilung spiegelt Informationen wider, die am Rand der Karte abgerufen wurden. Wenn beispielsweise zwei benachbarte Pixel vorhanden sind, von denen eines IN und das andere OUT ist, steigt die Wahrscheinlichkeit, dass sie eine andere Farbe haben, stark an. Wenn sich zwei benachbarte Pixel auf gegen√ºberliegenden Seiten des inneren Randes befinden, ist die Wahrscheinlichkeitdas wird eine andere Farbe haben wird auch zunehmen. Wenn die Pixel innerhalb des Rahmens liegen und durch nichts voneinander getrennt sind, steigt die Wahrscheinlichkeit, dass sie dieselbe Farbe haben, aber die externen Pixel k√∂nnen geringf√ºgig voneinander abweichen und so weiter. Um das endg√ºltige Bild zu erhalten, treffen Sie einfach eine Auswahl aus der soeben installierten gemeinsamen Wahrscheinlichkeitsverteilung. Um das erzeugte Bild interessanter zu machen, k√∂nnen wir die Farben durch die Textur ersetzen. Wir werden diese Ebene nicht diskutieren, da RCN die Klassifizierung durchf√ºhren kann, ohne auf dem Erscheinungsbild zu basieren.Um das endg√ºltige Bild zu erhalten, treffen Sie einfach eine Auswahl aus der soeben installierten gemeinsamen Wahrscheinlichkeitsverteilung. Um das erzeugte Bild interessanter zu machen, k√∂nnen wir die Farben durch die Textur ersetzen. Wir werden diese Ebene nicht diskutieren, da RCN die Klassifizierung durchf√ºhren kann, ohne auf dem Erscheinungsbild zu basieren.Um das endg√ºltige Bild zu erhalten, treffen Sie einfach eine Auswahl aus der soeben installierten gemeinsamen Wahrscheinlichkeitsverteilung. Um das erzeugte Bild interessanter zu machen, k√∂nnen wir die Farben durch die Textur ersetzen. Wir werden diese Ebene nicht diskutieren, da RCN die Klassifizierung durchf√ºhren kann, ohne auf dem Erscheinungsbild zu basieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, wir werden heute hier enden. </font><font style="vertical-align: inherit;">Wenn Sie mehr √ºber RCN erfahren m√∂chten, lesen Sie diesen Artikel [5] und den Anhang mit zus√§tzlichen Materialien, oder lesen Sie meine anderen Artikel √ºber die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">logischen Schlussfolgerungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schulungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und Ergebnisse der Verwendung von RCN f√ºr </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verschiedene Datens√§tze</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quellen:</font></font></h4><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[1] R. Perrault, Y. Shoham, E. Brynjolfsson et al., Jahresbericht 2019 des AI Index 2019 (2019), Human-Centered AI Institute - Stanford University.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[2] D. Hendrycks, K. Zhao, S. Basart et al., Natural Adversarial Examples (2019), arXiv: 1907.07174. </font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[3] J. Su, D. Vasconcellos Vargas und S. Kouichi, Ein-Pixel-Angriff zur T√§uschung tiefer neuronaler Netze (2017), arXiv: 1710.08864.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[4] M. Sharif, S. Bhagavatula, L. Bauer, Ein allgemeiner Rahmen f√ºr kontroverse Beispiele mit Zielen (2017), arXiv: 1801.00349.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">[5] D. George, W. Lehrach, K. Kansky, et al., A Generative Vision Model that Trains with High Data Efficiency and Break Text-based CAPTCHAs (2017), Science Mag (Vol 358 ‚Äî Issue 6368).</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">[6] H. Liang, X. Gong, M. Chen, et al., Interactions Between Feedback and Lateral Connections in the Primary Visual Cortex (2017), Proceedings of the National Academy of Sciences of the United States of America.</a></li>
</ol><br>
<b>        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>  : <i>¬´  :    ¬ª</i>.</b></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de486938/">https://habr.com/ru/post/de486938/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de486924/index.html">Finde die Flagge und gib sie nicht weiter. Wie wir RBKmoney CTF ausgegeben haben</a></li>
<li><a href="../de486928/index.html">So erh√∂hen Sie Ihren Server auf Docker-basiertem RaspberryPI</a></li>
<li><a href="../de486930/index.html">Eine Auswahl unterhaltsamer statistischer Fakten # 4</a></li>
<li><a href="../de486932/index.html">Kybernetik in der UdSSR: Von der Pseudowissenschaft zum Allheilmittel</a></li>
<li><a href="../de486934/index.html">Wir testen eine kosteng√ºnstige industrielle LED-Lampe TL-PROM-50-5K mit ehrlichen Eigenschaften</a></li>
<li><a href="../de486942/index.html">Implementierung der algorithmischen Spieltheorie in Python mit Nashpy</a></li>
<li><a href="../de486944/index.html">Hewlett Packard Enterprise Webinare | Februar-April 2020</a></li>
<li><a href="../de486946/index.html">mache {Yoga} w√§hrend (R√ºckenschmerzen)</a></li>
<li><a href="../de486948/index.html">Wie w√§hle ich einen Editor aus und warum w√§hle ich NeoVim?</a></li>
<li><a href="../de486950/index.html">Antiquit√§ten: das gnadenlose Upgrade des 386. Computers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
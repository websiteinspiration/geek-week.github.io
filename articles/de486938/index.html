<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏅 🦇 📗 Verständnis des maschinellen Lernmodells, das CAPTCHA bricht 🗄️ 🗓️ 🤟🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo alle zusammen! Diesen Monat rekrutiert OTUS eine neue Gruppe für den Kurs für maschinelles Lernen . Nach gängiger Tradition teilen wir Ihnen am ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Verständnis des maschinellen Lernmodells, das CAPTCHA bricht</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/486938/"><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hallo alle zusammen! </font><font style="vertical-align: inherit;">Diesen Monat rekrutiert OTUS eine neue Gruppe für den Kurs für </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">maschinelles Lernen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Nach gängiger Tradition teilen wir Ihnen am Vorabend des Kursbeginns die Übersetzung von interessantem Material zum Thema mit.</font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/cp/sm/jx/cpsmjxfi8zhhkhj2hdrbew0i66u.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Computer Vision ist eines der relevantesten und am besten erforschten Themen der KI [1]. Aktuelle Methoden zur Lösung von Problemen mit Faltungs-Neuronalen Netzen werden jedoch ernsthaft kritisiert, da solche Netze leicht zu täuschen sind. Um nicht unbegründet zu sein, möchte ich Ihnen einige Gründe nennen: Netzwerke dieses Typs liefern mit hoher Sicherheit ein falsches Ergebnis für natürlich vorkommende Bilder, die keine statistischen Signale enthalten [2], auf die sich Faltungs-Neuronale Netzwerke stützen, für Bilder, die zuvor korrekt klassifiziert wurden. aber in denen sich ein Pixel [3] oder Bilder mit physischen Objekten, die der Szene hinzugefügt wurden, aber das Klassifizierungsergebnis nicht ändern mussten [4], geändert haben. Tatsache ist, wenn wir wirklich intelligente Maschinen schaffen wollen,Es sollte uns vernünftig erscheinen, in das Studium neuer Ideen zu investieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine dieser neuen Ideen ist Vicarious 'Anwendung des Recursive Cortical Network (RCN), das sich von den Neurowissenschaften inspirieren lässt. </font><font style="vertical-align: inherit;">Dieses Modell behauptete, es sei äußerst effektiv beim Brechen von Text-Captcha, wodurch </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">viel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> um sich herum </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">geredet werde</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Aus diesem Grund habe ich beschlossen, mehrere Artikel zu schreiben, von denen jeder einen bestimmten Aspekt dieses Modells erklärt. </font><font style="vertical-align: inherit;">In diesem Artikel werden wir über seine Struktur sprechen und wie die Erzeugung von Bildern, die in den Materialien des Hauptartikels über RCN [5] dargestellt werden, erzeugt wird.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Artikel wird davon ausgegangen, dass Sie bereits mit Faltungs-Neuronalen Netzen vertraut sind, daher werde ich viele Analogien mit ihnen ziehen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um sich auf die RCN-Erkennung vorzubereiten, müssen Sie verstehen, dass RCNs auf der Idee basieren, die Form (Skizze des Objekts) vom Erscheinungsbild (seiner Textur) zu trennen, und dass es sich um ein generatives Modell handelt, nicht um ein diskriminierendes Modell, sodass wir damit Bilder wie in einem generativen generieren können gegnerische Netzwerke. </font><font style="vertical-align: inherit;">Zusätzlich wird eine parallele hierarchische Struktur verwendet, ähnlich der Architektur von Faltungs-Neuronalen Netzen, die mit dem Stadium der Bestimmung der Form des Zielobjekts in den unteren Schichten beginnt, und dann wird sein Aussehen auf der oberen Schicht hinzugefügt. </font><font style="vertical-align: inherit;">Im Gegensatz zu Faltungs-Neuronalen Netzen basiert das Modell, das wir betrachten, auf einer reichen theoretischen Basis grafischer Modelle anstelle von gewichteten Summen und Gradientenabstieg. </font><font style="vertical-align: inherit;">Lassen Sie uns nun die Merkmale der RCN-Struktur untersuchen.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feature-Layer</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der erste Layertyp in RCN wird als Feature-Layer bezeichnet. Wir werden das Modell schrittweise betrachten. Nehmen wir daher zunächst an, dass die gesamte Hierarchie des Modells nur aus übereinander gestapelten Schichten dieses Typs besteht. Wir werden von abstrakten Konzepten auf hoher Ebene zu spezifischeren Merkmalen der unteren Ebenen übergehen, wie in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 1 dargestellt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Eine Schicht dieses Typs besteht aus mehreren Knoten, die sich im zweidimensionalen Raum befinden, ähnlich wie Merkmalskarten in Faltungs-Neuronalen Netzen. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ht/iu/jv/htiujvk93pvm2-bjqthrweo_beq.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 1</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Mehrere übereinander angeordnete Feature-Layer mit Knoten im zweidimensionalen Raum. Der Übergang von der vierten zur ersten Schicht bedeutet den Übergang vom Allgemeinen zum Besonderen.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Knoten besteht aus mehreren Kanälen, von denen jeder ein separates Merkmal darstellt. Kanäle sind binäre Variablen, die den Wert True oder False annehmen und angeben, ob ein diesem Kanal entsprechendes Objekt im endgültig erzeugten Bild in der Koordinate (x, y) des Knotens vorhanden ist. Auf jeder Ebene haben Knoten den gleichen Kanaltyp.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nehmen wir als Beispiel eine Zwischenschicht und sprechen über ihre Kanäle und die obigen Schichten, um die Erklärung zu vereinfachen. Die Liste der Kanäle auf dieser Ebene besteht aus einer Hyperbel, einem Kreis und einer Parabel. Bei einem bestimmten Lauf beim Erzeugen des Bildes erforderten die Berechnungen der darüber liegenden Ebenen einen Kreis in der Koordinate (1,1). Somit hat der Knoten (1, 1) einen Kanal, der dem Objekt "Kreis" im Wert True entspricht. Dies wirkt sich direkt auf einige Knoten in der darunter liegenden Ebene aus, dh, die Features der unteren Ebene, die dem Kreis in der Nachbarschaft (1,1) zugeordnet sind, werden auf True gesetzt. Diese Objekte niedrigerer Ebene können beispielsweise vier Bögen mit unterschiedlichen Ausrichtungen sein. Wenn die Merkmale der unteren Ebene aktiviert sind, aktivieren sie die Kanäle auf den Ebenen noch tiefer, bis die letzte Ebene erreicht ist.Bilderzeugung. Die Aktivierungsvisualisierung wird in angezeigt</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 2</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie fragen sich vielleicht, wie wird klar, dass die Darstellung eines Kreises 4 Bögen beträgt? Und woher weiß RCN, dass es einen Kanal benötigt, um den Kreis darzustellen? Kanäle und ihre Bindungen an andere Schichten werden in der RCN-Trainingsphase gebildet. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ao/gr/s9/aogrs9u-zi-guzvwobln0wng8rw.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 2:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Informationsfluss in Feature-Layern. Zeichenknoten sind Kapseln, die Scheiben enthalten, die Kanäle darstellen. Einige der oberen und unteren Schichten wurden der Einfachheit halber in Form eines Parallelepipeds dargestellt, in Wirklichkeit bestehen sie jedoch auch aus Merkmalsknoten als Zwischenschichten. Bitte beachten Sie, dass die obere Zwischenschicht aus 3 Kanälen und die zweite Schicht aus 4 Kanälen besteht.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie können eine sehr starre und deterministische Methode zur Erzeugung des angenommenen Modells angeben, aber für Menschen werden kleine Störungen der Krümmung des Kreises immer noch als Kreis betrachtet, wie Sie in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 3 sehen können</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/o1/pr/fr/o1prfrwawffkxyvl62yb1k3czag.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 3:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Viele Variationen der Konstruktion eines Kreises aus vier gekrümmten Bögen aus Abbildung 2.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Es wäre schwierig, jede dieser Variationen als separaten neuen Kanal in der Schicht zu betrachten. </font><font style="vertical-align: inherit;">In ähnlicher Weise wird das Gruppieren von Variationen in dieselbe Entität die Verallgemeinerung in neue Variationen erheblich erleichtern, wenn wir RCN etwas später an die Klassifizierung anpassen, anstatt sie zu generieren. </font><font style="vertical-align: inherit;">Aber wie ändern wir RCN, um diese Gelegenheit zu bekommen?</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unterabtastungsebenen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dazu benötigen Sie einen neuen Layertyp - den Pooling-Layer. Es befindet sich zwischen zwei beliebigen Zeichenschichten und fungiert als Vermittler zwischen ihnen. Es besteht auch aus Kanälen, sie haben jedoch ganzzahlige Werte, keine binären.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um zu veranschaulichen, wie diese Ebenen funktionieren, kehren wir zum Kreisbeispiel zurück. Anstatt 4 Bögen mit festen Koordinaten von der darüber liegenden Merkmalsebene als Merkmal eines Kreises zu benötigen, wird die Suche auf der Unterabtastungsebene durchgeführt. Dann wählt jeder aktivierte Kanal in der Unterabtastschicht einen Knoten auf der darunter liegenden Schicht in seiner Nähe aus, um eine leichte Verzerrung des Merkmals zu ermöglichen. Wenn wir also eine Kommunikation mit 9 Knoten direkt unter dem Unterabtastknoten herstellen, wählt der Unterabtastungskanal bei jeder Aktivierung gleichmäßig einen dieser 9 Knoten aus und aktiviert ihn, und der Index des ausgewählten Knotens ist der Status des Unterabtastkanals - eine Ganzzahl. In </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 4</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie können mehrere Läufe sehen, bei denen jeder Lauf einen anderen Satz von Knoten niedrigerer Ebene verwendet, sodass Sie auf verschiedene Arten einen Kreis erstellen können. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ma/6t/oe/ma6toei3ncssielvv8cuff5e97i.gif"><br>
 <i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 4:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Betrieb von Unterabtastschichten. Jeder Frame in diesem GIF-Bild ist ein separater Start. Unterabtastknoten werden gewürfelt. In diesem Bild haben die Unterabtastknoten 4 Kanäle, die 4 Kanälen der darunter liegenden Merkmalsebene entsprechen. Die obere und untere Schicht wurden vollständig aus dem Bild entfernt.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Trotz der Tatsache, dass wir die Variabilität unseres Modells brauchten, wäre es besser, wenn es zurückhaltender und fokussierter bleiben würde. In den beiden vorhergehenden Abbildungen sehen einige Kreise zu seltsam aus, um sie wirklich als Kreise zu interpretieren, da die Bögen nicht miteinander verbunden sind, wie aus </font><b><font style="vertical-align: inherit;">Abbildung 5</font></b><font style="vertical-align: inherit;"> ersichtlich ist</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir möchten vermeiden, sie zu generieren. Wenn wir also einen Mechanismus für Unterabtastungskanäle hinzufügen könnten, um die Auswahl von Merkmalsknoten zu koordinieren und uns auf kontinuierliche Formen zu konzentrieren, wäre unser Modell genauer. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ci/bc/oa/cibcoalwwxl1yawero5mnooydua.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 5:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Viele Optionen zum Erstellen eines Kreises. Die Optionen, die wir löschen möchten, sind mit roten Kreuzen markiert.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
RCN-Autoren verwendeten zu diesem Zweck eine laterale Verbindung in Unterabtastungsschichten. Im Wesentlichen haben Unterabtastkanäle Verbindungen mit anderen Unterabtastkanälen aus der unmittelbaren Umgebung, und diese Verbindungen ermöglichen es nicht, dass einige Zustandspaare gleichzeitig in zwei Kanälen koexistieren. Tatsächlich wird der Abtastbereich dieser beiden Kanäle einfach begrenzt. In verschiedenen Versionen des Kreises erlauben diese Verbindungen beispielsweise nicht, dass sich zwei benachbarte Bögen voneinander entfernen. Dieser Mechanismus ist in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 6 dargestellt.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Auch diese Beziehungen werden in der Trainingsphase hergestellt. Es sollte beachtet werden, dass moderne künstliche neuronale Vanille-Netze keine lateralen Verbindungen in ihren Schichten haben, obwohl sie in biologischen neuronalen Netzen existieren, und es wird angenommen, dass sie eine Rolle bei der Konturintegration im visuellen Kortex spielen (aber offen gesagt hat der visuelle Kortex wo komplexeres Gerät, als es aus der vorherigen Aussage hervorgeht). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fi/tw/xj/fitwxjlp-0qrkgnvt8fhwflbadm.gif"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 6:</font></font></b> GIF-   RCN   .    ,         .  ,   RCN           ,     ,    .         .</i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bisher haben wir über Zwischenschichten von RCN gesprochen, wir haben nur die oberste Schicht und die unterste Schicht, die mit den Pixeln des erzeugten Bildes interagiert. Die oberste Ebene ist eine reguläre Feature-Ebene, in der die Kanäle jedes Knotens Klassen unseres beschrifteten Datensatzes sind. Beim Generieren wählen wir einfach den Speicherort und die Klasse aus, die wir erstellen möchten, gehen zum Knoten mit dem angegebenen Speicherort und sagen, dass er den Kanal der von uns ausgewählten Klasse aktiviert. Dadurch werden einige der Kanäle in der darunter liegenden Unterabtastebene, dann die darunter liegende Feature-Ebene usw. aktiviert, bis die letzte Feature-Ebene erreicht ist. Basierend auf Ihrem Wissen über Faltungs-Neuronale Netze sollten Sie denken, dass die oberste Schicht einen einzelnen Knoten hat, aber dies ist nicht der Fall, und dies ist einer der Vorteile von RCN.Eine Diskussion dieses Themas würde jedoch den Rahmen dieses Artikels sprengen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der letzte Feature-Layer ist eindeutig. Erinnerst du dich, ich habe darüber gesprochen, wie RCNs Form und Aussehen trennen? Es ist diese Schicht, die für das Erhalten der Form des erzeugten Objekts verantwortlich ist. Daher sollte diese Ebene mit Features auf sehr niedriger Ebene arbeiten, den grundlegendsten Bausteinen jeder Form, die uns helfen, jede gewünschte Form zu erzeugen. Kleine Ränder, die sich in verschiedenen Winkeln drehen, sind durchaus geeignet, und genau diese verwenden die Autoren der Technologie.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Autoren haben die Attribute der letzten Ebene ausgewählt, um ein 3x3-Fenster mit einem Rand mit einem bestimmten Drehwinkel darzustellen, den sie als Patch-Deskriptor bezeichnen. Die Anzahl der ausgewählten Drehwinkel beträgt 16. Um später ein Erscheinungsbild hinzufügen zu können, benötigen Sie außerdem zwei Ausrichtungen für jede Drehung, um feststellen zu können, ob sich der Hintergrund am linken oder am rechten Rand befindet, wenn es sich um Außenränder handelt und zusätzliche Orientierung im Fall von inneren Grenzen (d. h. innerhalb des Objekts). In </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 7</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sind die Eigenschaften der letzten Schichtanordnung dargestellt, und in </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 8 ist dargestellt</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , wie die Deskriptoren von Patches eine bestimmte Form erzeugen können. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/gz/2o/mp/gz2ompbptag8mfcmey7ngj7ynem.png"><br>
<i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 7:</font></font></b>    .  48   ( ) ,  16    3 .    –      45 . “IN "   ,  “OUT” — .</i><br>
<br>
<img src="https://habrastorage.org/webt/dv/wu/-e/dvwu-ea0vfc7ff9pz2zn12w-tcw.png"><br>
<i><b> 8:</b>    «i»     .</i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nachdem wir die letzte Zeichenebene erreicht haben, haben wir ein Diagramm, in dem die Grenzen des Objekts bestimmt werden und das Verständnis, ob sich der Bereich außerhalb der Grenze befindet, intern oder extern ist. Es bleibt ein Erscheinungsbild hinzuzufügen, das jeden verbleibenden Bereich im Bild als IN oder OUT kennzeichnet und den Bereich übermalt. Ein bedingtes Zufallsfeld kann hier helfen. Ohne auf mathematische Details einzugehen, weisen wir einfach jedem Pixel im endgültigen Bild eine Wahrscheinlichkeitsverteilung nach Farbe und Zustand (IN oder OUT) zu. Diese Verteilung spiegelt Informationen wider, die am Rand der Karte abgerufen wurden. Wenn beispielsweise zwei benachbarte Pixel vorhanden sind, von denen eines IN und das andere OUT ist, steigt die Wahrscheinlichkeit, dass sie eine andere Farbe haben, stark an. Wenn sich zwei benachbarte Pixel auf gegenüberliegenden Seiten des inneren Randes befinden, ist die Wahrscheinlichkeitdas wird eine andere Farbe haben wird auch zunehmen. Wenn die Pixel innerhalb des Rahmens liegen und durch nichts voneinander getrennt sind, steigt die Wahrscheinlichkeit, dass sie dieselbe Farbe haben, aber die externen Pixel können geringfügig voneinander abweichen und so weiter. Um das endgültige Bild zu erhalten, treffen Sie einfach eine Auswahl aus der soeben installierten gemeinsamen Wahrscheinlichkeitsverteilung. Um das erzeugte Bild interessanter zu machen, können wir die Farben durch die Textur ersetzen. Wir werden diese Ebene nicht diskutieren, da RCN die Klassifizierung durchführen kann, ohne auf dem Erscheinungsbild zu basieren.Um das endgültige Bild zu erhalten, treffen Sie einfach eine Auswahl aus der soeben installierten gemeinsamen Wahrscheinlichkeitsverteilung. Um das erzeugte Bild interessanter zu machen, können wir die Farben durch die Textur ersetzen. Wir werden diese Ebene nicht diskutieren, da RCN die Klassifizierung durchführen kann, ohne auf dem Erscheinungsbild zu basieren.Um das endgültige Bild zu erhalten, treffen Sie einfach eine Auswahl aus der soeben installierten gemeinsamen Wahrscheinlichkeitsverteilung. Um das erzeugte Bild interessanter zu machen, können wir die Farben durch die Textur ersetzen. Wir werden diese Ebene nicht diskutieren, da RCN die Klassifizierung durchführen kann, ohne auf dem Erscheinungsbild zu basieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nun, wir werden heute hier enden. </font><font style="vertical-align: inherit;">Wenn Sie mehr über RCN erfahren möchten, lesen Sie diesen Artikel [5] und den Anhang mit zusätzlichen Materialien, oder lesen Sie meine anderen Artikel über die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">logischen Schlussfolgerungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schulungen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und Ergebnisse der Verwendung von RCN für </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verschiedene Datensätze</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quellen:</font></font></h4><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[1] R. Perrault, Y. Shoham, E. Brynjolfsson et al., Jahresbericht 2019 des AI Index 2019 (2019), Human-Centered AI Institute - Stanford University.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[2] D. Hendrycks, K. Zhao, S. Basart et al., Natural Adversarial Examples (2019), arXiv: 1907.07174. </font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[3] J. Su, D. Vasconcellos Vargas und S. Kouichi, Ein-Pixel-Angriff zur Täuschung tiefer neuronaler Netze (2017), arXiv: 1710.08864.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[4] M. Sharif, S. Bhagavatula, L. Bauer, Ein allgemeiner Rahmen für kontroverse Beispiele mit Zielen (2017), arXiv: 1801.00349.</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">[5] D. George, W. Lehrach, K. Kansky, et al., A Generative Vision Model that Trains with High Data Efficiency and Break Text-based CAPTCHAs (2017), Science Mag (Vol 358 — Issue 6368).</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">[6] H. Liang, X. Gong, M. Chen, et al., Interactions Between Feedback and Lateral Connections in the Primary Visual Cortex (2017), Proceedings of the National Academy of Sciences of the United States of America.</a></li>
</ol><br>
<b>        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>  : <i>«  :    »</i>.</b></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de486938/">https://habr.com/ru/post/de486938/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de486924/index.html">Finde die Flagge und gib sie nicht weiter. Wie wir RBKmoney CTF ausgegeben haben</a></li>
<li><a href="../de486928/index.html">So erhöhen Sie Ihren Server auf Docker-basiertem RaspberryPI</a></li>
<li><a href="../de486930/index.html">Eine Auswahl unterhaltsamer statistischer Fakten # 4</a></li>
<li><a href="../de486932/index.html">Kybernetik in der UdSSR: Von der Pseudowissenschaft zum Allheilmittel</a></li>
<li><a href="../de486934/index.html">Wir testen eine kostengünstige industrielle LED-Lampe TL-PROM-50-5K mit ehrlichen Eigenschaften</a></li>
<li><a href="../de486942/index.html">Implementierung der algorithmischen Spieltheorie in Python mit Nashpy</a></li>
<li><a href="../de486944/index.html">Hewlett Packard Enterprise Webinare | Februar-April 2020</a></li>
<li><a href="../de486946/index.html">mache {Yoga} während (Rückenschmerzen)</a></li>
<li><a href="../de486948/index.html">Wie wähle ich einen Editor aus und warum wähle ich NeoVim?</a></li>
<li><a href="../de486950/index.html">Antiquitäten: das gnadenlose Upgrade des 386. Computers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
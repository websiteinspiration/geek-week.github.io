<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêò ü§∑üèΩ üå¨Ô∏è Time Series Prediction Using Recurrent Neural Networks üí± üí≠ üéÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Remote mode of operation against the background of universal self-isolation can lead to very bad consequences. And emotional burnout - it‚Äôs still wher...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Time Series Prediction Using Recurrent Neural Networks</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/495884/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Remote mode of operation against the background of universal self-isolation can lead to very bad consequences. And emotional burnout - it‚Äôs still wherever it goes: after all, it‚Äôs not far from the roof. In this regard, like many, he tried to "calm" himself by allocating time for other classes - and began to translate the most interesting articles from English into Russian: "You give </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">machine-learning</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to the masses!".) We must pay tribute: it is great distracting. If you have suggestions for both semantic content and translation of this text for a Russian-speaking reader, join the discussion.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/3d7/fe4/946/3d7fe49466cad76814b37e73ec1bc49a.jpg" alt="image"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, here's a translation of the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Time series forecasting</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> page </font><font style="vertical-align: inherit;">from the tensorflow manual section: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">link</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . My additions along with illustrations for the translation are aimed at helping to understand the basic ideas in one of the most interesting areas of ML and econometrics in general - forecasting time series. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A small introduction before the translation. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The manual is a description of air temperature prediction based on one-dimensional time series </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(univariate time-series)</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and multivariate time series </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(multivariate time-series)</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . For each part, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">input data</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">should be prepared accordingly. Taking into account the meteorological data set considered in this guide, the separation is as follows: </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/8fa/31a/a75/8fa31aa7531d8589dcee2ae93454a430.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For questions about what to take for </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and what for </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , that is, how to prepare data for the class of supervised training, it will become clear from the following illustrations. I only note that the formation of the target vector (Y) for working with both one-dimensional and multi-dimensional time series is the same: the target vector is compiled on the basis of the sign </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T (degC)</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(air temperature). The difference between them is ‚Äúburied‚Äù in the formation of a set of features that are fed to the model‚Äôs input: in the case of a one-dimensional time series for predicting the temperature in the future, the input vector (X) consists of one feature: in fact, air temperature; and for multidimensional - more than one: in addition to air temperature, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p (mbar)</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (atmospheric pressure) and </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rho (g / m ** 3)</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (humidity) </font><font style="vertical-align: inherit;">are used in the example of the manual in question </font><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At first, a far-shallow, look, an example with temperature forecasting looks unconvincing from the point of view of applying a multidimensional input: for temperature forecasting, the most relevant sign will be temperature. However, this is absolutely not the case: in order to develop a qualitative forecast of air temperature, many factors must be taken into account, up to air friction on the earth's surface, etc. In addition, in practice, some things are far from obvious, and the target vector may be in the form of that hodgepodge (or borsch). In this regard, exploratory data analysis with the selection of the most relevant features for the subsequent formation of a multidimensional input is the only right decision. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, the translation of the manual is presented below. Additional text will be </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in italics</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Time Series Forecasting</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This guide is an introduction to time series forecasting using recurrent neural networks (RNS, from the English </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recurrent Neural Network, RNN</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">It consists of two parts: the first describes the prediction of air temperature based on a one-dimensional time series, and the second - based on a multidimensional time series.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-keyword">import</span> matplotlib <span class="hljs-keyword">as</span> mpl
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<font></font>
<font></font>
mpl.rcParams[<span class="hljs-string">'figure.figsize'</span>] = (<span class="hljs-number">8</span>, <span class="hljs-number">6</span>)<font></font>
mpl.rcParams[<span class="hljs-string">'axes.grid'</span>] = <span class="hljs-literal">False</span>
</code></pre><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A set of meteorological data</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
All examples of the manual use </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">time sequences of weather data</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> recorded at a hydrometeorological station at the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Institute of Biogeochemistry named after </font><font style="vertical-align: inherit;">Max Planck</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This data set includes measurements of 14 different meteorological indicators (such as air temperature, atmospheric pressure, humidity), carried out every 10 minutes since 2003. </font><font style="vertical-align: inherit;">To save time and memory usage, the manual will use data covering the period from 2009 to 2016. </font><font style="vertical-align: inherit;">This section of the dataset was prepared by Fran√ßois Chollet for his book, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deep Learning with Python</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<pre><code class="python hljs">zip_path = tf.keras.utils.get_file(<font></font>
    origin=<span class="hljs-string">'https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip'</span>,<font></font>
    fname=<span class="hljs-string">'jena_climate_2009_2016.csv.zip'</span>,<font></font>
    extract=<span class="hljs-literal">True</span>)<font></font>
csv_path, _ = os.path.splitext(zip_path)<font></font>
</code></pre><br>
<pre><code class="python hljs">df = pd.read_csv(csv_path)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's see what we have.</font></font><br>
<br>
<pre><code class="python hljs">df.head()
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/d5d/bfa/539/d5dbfa539de3da5ca04103b2db380a70.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The fact that the observation recording period is 10 minutes can be verified by the table above. Thus, in one hour you will have 6 observations. In turn, 144 (6x24) observations are accumulated per day. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's say you want to predict the temperature, which will be in 6 hours in the future. You make this forecast based on the data you have for a certain period: for example, you decide to use 5 days of observation. Therefore, to train the model, you must create a time interval containing the last 720 (5x144) observations (since different configurations are possible, this data set is a good basis for experiments). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The function below returns the above time intervals for training the model. Argument</font></font><code>history_size</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- this is the size of the last time interval, </font></font><code>target_size</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- an argument that determines how far into the future the model should learn to predict. </font><font style="vertical-align: inherit;">In other words, </font></font><code>target_size</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">is the target vector that needs to be predicted.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">univariate_data</span>(<span class="hljs-params">dataset, start_index, end_index, history_size, target_size</span>):</span><font></font>
  data = []<font></font>
  labels = []<font></font>
<font></font>
  start_index = start_index + history_size<font></font>
  <span class="hljs-keyword">if</span> end_index <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
    end_index = len(dataset) - target_size<font></font>
<font></font>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(start_index, end_index):<font></font>
    indices = range(i-history_size, i)<font></font>
    <span class="hljs-comment"># Reshape data from (history_size,) to (history_size, 1)</span>
    data.append(np.reshape(dataset[indices], (history_size, <span class="hljs-number">1</span>)))<font></font>
    labels.append(dataset[i+target_size])<font></font>
  <span class="hljs-keyword">return</span> np.array(data), np.array(labels)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In both parts of the manual, the first 300,000 rows of data will be used to train the model, the remaining ones to validate (validate) it. </font><font style="vertical-align: inherit;">In this case, the amount of training data is approximately 2100 days.</font></font><br>
<br>
<pre><code class="python hljs">TRAIN_SPLIT = <span class="hljs-number">300000</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To ensure reproducible results, the seed function is set.</font></font><br>
<br>
<pre><code class="python hljs">tf.random.set_seed(<span class="hljs-number">13</span>)
</code></pre><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Part 1. Forecasting based on a one-dimensional time series</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the first part, you will train the model using only one attribute - temperature; </font><font style="vertical-align: inherit;">the trained model will be used to predict future temperatures. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To get started, we extract only the temperature from the data set.</font></font><br>
<br>
<pre><code class="python hljs">uni_data = df[<span class="hljs-string">'T (degC)'</span>]<font></font>
uni_data.index = df[<span class="hljs-string">'Date Time'</span>]<font></font>
uni_data.head()<font></font>
</code></pre><br>
<code>Date Time<br>
01.01.2009 00:10:00 -8.02<br>
01.01.2009 00:20:00 -8.41<br>
01.01.2009 00:30:00 -8.51<br>
01.01.2009 00:40:00 -8.31<br>
01.01.2009 00:50:00 -8.27<br>
Name: T (degC), dtype: float64<br>
</code><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And let's see how this data changes over time.</font></font><br>
<br>
<pre><code class="python hljs">uni_data.plot(subplots=<span class="hljs-literal">True</span>)
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/208/b35/242/208b35242d3ce1ed30bd25d12d956703.jpg" alt="image"><br>
<br>
<pre><code class="python hljs">uni_data = uni_data.values
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Before training an artificial neural network (hereinafter - ANN), an important step is data scaling. </font><font style="vertical-align: inherit;">One of the common ways of performing the scaling is standardization ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">standardization</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), performed by subtracting the mean and dividing by the standard deviation for each characteristic. </font><font style="vertical-align: inherit;">You can also use a method </font></font><code><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow">tf.keras.utils.normalize</a></code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">that scales values ‚Äã‚Äãto the range [0,1]. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Note</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : standardization should only be carried out using training data.</font></font><br>
<br>
<pre><code class="python hljs">uni_train_mean = uni_data[:TRAIN_SPLIT].mean()<font></font>
uni_train_std = uni_data[:TRAIN_SPLIT].std()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We perform data standardization.</font></font><br>
<br>
<pre><code class="python hljs">uni_data = (uni_data-uni_train_mean)/uni_train_std
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, we will prepare the data for the model with a one-dimensional input. </font><font style="vertical-align: inherit;">The last 20 recorded observations of the temperature will be fed to the model, and the model must be trained to predict the temperature in the next time step.</font></font><br>
<br>
<pre><code class="python hljs">univariate_past_history = <span class="hljs-number">20</span>
univariate_future_target = <span class="hljs-number">0</span><font></font>
<font></font>
x_train_uni, y_train_uni = univariate_data(uni_data, <span class="hljs-number">0</span>, TRAIN_SPLIT,<font></font>
                                           univariate_past_history,<font></font>
                                           univariate_future_target)<font></font>
x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, <span class="hljs-literal">None</span>,<font></font>
                                       univariate_past_history,<font></font>
                                       univariate_future_target)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The results of applying the function </font></font><code>univariate_data</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">print</span> (<span class="hljs-string">'Single window of past history'</span>)
<span class="hljs-keyword">print</span> (x_train_uni[<span class="hljs-number">0</span>])
<span class="hljs-keyword">print</span> (<span class="hljs-string">'\n Target temperature to predict'</span>)
<span class="hljs-keyword">print</span> (y_train_uni[<span class="hljs-number">0</span>])
</code></pre><br>
<code>Single window of past history<br>
[[-1.99766294]<br>
 [-2.04281897]<br>
 [-2.05439744]<br>
 [-2.0312405 ]<br>
 [-2.02660912]<br>
 [-2.00113649]<br>
 [-1.95134907]<br>
 [-1.95134907]<br>
 [-1.98492663]<br>
 [-2.04513467]<br>
 [-2.08334362]<br>
 [-2.09723778]<br>
 [-2.09376424]<br>
 [-2.09144854]<br>
 [-2.07176515]<br>
 [-2.07176515]<br>
 [-2.07639653]<br>
 [-2.08913285]<br>
 [-2.09260639]<br>
 [-2.10418486]]<br>
<br>
Target temperature to predict<br>
-2.1041848598100876<br>
</code><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Addition: preparation of data for a model with a one-dimensional input is schematically shown in the following figure (for convenience, in this and subsequent figures, the data is presented in a raw form, before standardization, and also without the 'Date time' attribute as an index):</font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/fa0/d0f/530/fa0d0f530b3496324425eeb5e52baff7.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Now that the data suitably prepared, consider a concrete example. </font><font style="vertical-align: inherit;">The information transmitted to the ANN is highlighted in blue, a red cross indicates the future value that the ANN should predict.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_time_steps</span>(<span class="hljs-params">length</span>):</span>
  <span class="hljs-keyword">return</span> list(range(-length, <span class="hljs-number">0</span>))
</code></pre><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_plot</span>(<span class="hljs-params">plot_data, delta, title</span>):</span>
  labels = [<span class="hljs-string">'History'</span>, <span class="hljs-string">'True Future'</span>, <span class="hljs-string">'Model Prediction'</span>]<font></font>
  marker = [<span class="hljs-string">'.-'</span>, <span class="hljs-string">'rx'</span>, <span class="hljs-string">'go'</span>]<font></font>
  time_steps = create_time_steps(plot_data[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>])
  <span class="hljs-keyword">if</span> delta:<font></font>
    future = delta<font></font>
  <span class="hljs-keyword">else</span>:<font></font>
    future = <span class="hljs-number">0</span><font></font>
<font></font>
  plt.title(title)<font></font>
  <span class="hljs-keyword">for</span> i, x <span class="hljs-keyword">in</span> enumerate(plot_data):
    <span class="hljs-keyword">if</span> i:<font></font>
      plt.plot(future, plot_data[i], marker[i], markersize=<span class="hljs-number">10</span>,<font></font>
               label=labels[i])<font></font>
    <span class="hljs-keyword">else</span>:<font></font>
      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])<font></font>
  plt.legend()<font></font>
  plt.xlim([time_steps[<span class="hljs-number">0</span>], (future+<span class="hljs-number">5</span>)*<span class="hljs-number">2</span>])<font></font>
  plt.xlabel(<span class="hljs-string">'Time-Step'</span>)
  <span class="hljs-keyword">return</span> plt
</code></pre><br>
<pre><code class="python hljs">show_plot([x_train_uni[<span class="hljs-number">0</span>], y_train_uni[<span class="hljs-number">0</span>]], <span class="hljs-number">0</span>, <span class="hljs-string">'Sample Example'</span>)
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/589/38c/574/58938c5740abfb08ed0074a1233f512f.jpg" alt="image"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Basic solution (without involving machine learning)</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Before starting the model training, we will install a simple basic solution ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">baseline</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). It consists in the following: for a given input vector, the basic solution method ‚Äúscans‚Äù the entire history and predicts the next value as the average of the last 20 observations.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">baseline</span>(<span class="hljs-params">history</span>):</span>
  <span class="hljs-keyword">return</span> np.mean(history)
</code></pre><br>
<pre><code class="python hljs">show_plot([x_train_uni[<span class="hljs-number">0</span>], y_train_uni[<span class="hljs-number">0</span>], baseline(x_train_uni[<span class="hljs-number">0</span>])], <span class="hljs-number">0</span>,
           <span class="hljs-string">'Baseline Prediction Example'</span>)
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/bed/941/0ef/bed9410ef6b96ad25ab68a0a3ebac05a.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's see if we can surpass the result of ‚Äúaveraging‚Äù using a recurrent neural network. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recurrent Neural Network A</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
recurrent neural network (RNS) is a type of ANN that is well suited for solving time series problems. RNS step by step processes the time sequence of data, sorting through its elements and preserving the internal state obtained by processing the previous elements. You can find more information about RNS in the following </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">guide</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . This guide will use a specialized layer of RNC called </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Long Short-Term Memory ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LSTM</font></font></a></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Further using</font></font><code><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow">tf.data</a></code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Shuffle, batch, and cache the data set. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Addition: </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
More about the shuffle, batch and cache methods on the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tensorflow</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> page </font><font style="vertical-align: inherit;">:</font></font></i><br>
<br>
<pre><code class="python hljs">BATCH_SIZE = <span class="hljs-number">256</span>
BUFFER_SIZE = <span class="hljs-number">10000</span><font></font>
<font></font>
train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))<font></font>
train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()<font></font>
<font></font>
val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))<font></font>
val_univariate = val_univariate.batch(BATCH_SIZE).repeat()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The following visualization should help you understand what the data looks like after batch processing. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/002/e4b/3ed/002e4b3ed48fa5d17f34ccee2cbfc40d.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It can be seen that LSTM requires a certain form of data entry, which is provided to it.</font></font><br>
<br>
<pre><code class="python hljs">simple_lstm_model = tf.keras.models.Sequential([<font></font>
    tf.keras.layers.LSTM(<span class="hljs-number">8</span>, input_shape=x_train_uni.shape[<span class="hljs-number">-2</span>:]),<font></font>
    tf.keras.layers.Dense(<span class="hljs-number">1</span>)<font></font>
])<font></font>
<font></font>
simple_lstm_model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mae'</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Check the model output.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> val_univariate.take(<span class="hljs-number">1</span>):<font></font>
    print(simple_lstm_model.predict(x).shape)<font></font>
</code></pre><br>
<code>(256, 1)<br>
</code><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Addition: </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In general terms, RNSs work with sequences. </font><font style="vertical-align: inherit;">This means that the data supplied to the input of the model should have the following form: </font></font><br>
<br>
<code>[,  , - ]</code><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The form of training data for the model with a one-dimensional input has the following form:</font></font></i><br>
<br>
<code>print(x_train_uni.shape)<br>
(299980, 20, 1)</code><br>
<cut></cut><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, we will study the model. </font><font style="vertical-align: inherit;">Due to the large size of the data set and in order to save time, each epoch will go through only 200 steps ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">steps_per_epoch = 200</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) instead of the full training data, as is usually done.</font></font><br>
<br>
<pre><code class="python hljs">EVALUATION_INTERVAL = <span class="hljs-number">200</span>
EPOCHS = <span class="hljs-number">10</span><font></font>
<font></font>
simple_lstm_model.fit(train_univariate, epochs=EPOCHS,<font></font>
                      steps_per_epoch=EVALUATION_INTERVAL,<font></font>
                      validation_data=val_univariate, validation_steps=<span class="hljs-number">50</span>)
</code></pre><br>
<code>Train for 200 steps, validate for 50 steps<br>
Epoch 1/10<br>
200/200 [==============================] - 2s 11ms/step - loss: 0.4075 - val_loss: 0.1351<br>
Epoch 2/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.1118 - val_loss: 0.0360<br>
Epoch 3/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0289<br>
Epoch 4/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0444 - val_loss: 0.0257<br>
Epoch 5/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0299 - val_loss: 0.0235<br>
Epoch 6/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0224<br>
Epoch 7/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0206<br>
Epoch 8/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0200<br>
Epoch 9/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0254 - val_loss: 0.0182<br>
Epoch 10/10<br>
200/200 [==============================] - 1s 4ms/step - loss: 0.0228 - val_loss: 0.0174<br>
</code><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prediction using a simple LSTM model</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
After completing the preparation of a simple LSTM model, we will make several predictions.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> val_univariate.take(<span class="hljs-number">3</span>):<font></font>
  plot = show_plot([x[<span class="hljs-number">0</span>].numpy(), y[<span class="hljs-number">0</span>].numpy(),<font></font>
                    simple_lstm_model.predict(x)[<span class="hljs-number">0</span>]], <span class="hljs-number">0</span>, <span class="hljs-string">'Simple LSTM model'</span>)<font></font>
  plot.show()<font></font>
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/cf8/0f6/810/cf80f681038da62889884ae5de86722d.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It looks better than the base level. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that you‚Äôve become familiar with the basics, let's move on to the second part, which describes working with a multidimensional time series.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Part 2: Multidimensional Time Series Forecasting</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As stated, the original dataset contains 14 different meteorological indicators. </font><font style="vertical-align: inherit;">For simplicity and convenience, in the second part only three of them are considered - air temperature, atmospheric pressure and air density. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To use more features, their names must be added to the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">feature_considered</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> list </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">features_considered = [<span class="hljs-string">'p (mbar)'</span>, <span class="hljs-string">'T (degC)'</span>, <span class="hljs-string">'rho (g/m**3)'</span>]
</code></pre><br>
<pre><code class="python hljs">features = df[features_considered]<font></font>
features.index = df[<span class="hljs-string">'Date Time'</span>]<font></font>
features.head()<font></font>
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/1f8/589/b51/1f8589b51d64dcd9ba10e5f072df503e.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's see how these indicators change over time.</font></font><br>
<br>
<pre><code class="python hljs">features.plot(subplots=<span class="hljs-literal">True</span>)
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/7be/266/b59/7be266b59f38be1e4c365ee8562dffcd.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As before, the first step is to standardize the data set with the calculation of the average value and standard deviation of the training data.</font></font><br>
<br>
<pre><code class="python hljs">dataset = features.values<font></font>
data_mean = dataset[:TRAIN_SPLIT].mean(axis=<span class="hljs-number">0</span>)<font></font>
data_std = dataset[:TRAIN_SPLIT].std(axis=<span class="hljs-number">0</span>)
</code></pre><br>
<pre><code class="python hljs">dataset = (dataset-data_mean)/data_std
</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Addition: </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Further in the manual we will talk about point and interval forecasting. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The bottom line is as follows. If you need the model to predict one value in the future (for example, the temperature value after 12 hours) (one-step / single step model), then you must train the model so that it predicts only one value in the future. If the task is to predict the range of values ‚Äã‚Äãin the future (for example, hourly temperatures over the next 12 hours) (multi-step model), then the model should also be trained to predict the range of values ‚Äã‚Äãin the future. </font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/906/953/08e/90695308e69c21c37e772d98553209a4.png" alt="image"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Point prediction</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In this case, the model is trained to predict one value in the future based on some available history.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The function below performs the same task of organizing time intervals only with the difference that here it selects the latest observations based on a given step size.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">multivariate_data</span>(<span class="hljs-params">dataset, target, start_index, end_index, history_size,
                      target_size, step, single_step=False</span>):</span><font></font>
  data = []<font></font>
  labels = []<font></font>
<font></font>
  start_index = start_index + history_size<font></font>
  <span class="hljs-keyword">if</span> end_index <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
    end_index = len(dataset) - target_size<font></font>
<font></font>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(start_index, end_index):<font></font>
    indices = range(i-history_size, i, step)<font></font>
    data.append(dataset[indices])<font></font>
<font></font>
    <span class="hljs-keyword">if</span> single_step:<font></font>
      labels.append(target[i+target_size])<font></font>
    <span class="hljs-keyword">else</span>:<font></font>
      labels.append(target[i:i+target_size])<font></font>
<font></font>
  <span class="hljs-keyword">return</span> np.array(data), np.array(labels)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In this guide, the ANN operates on data for the last five (5) days, i.e. 720 observations (6x24x5). </font><font style="vertical-align: inherit;">Suppose that the selection of data is carried out not every 10 minutes, but every hour: within 60 minutes, sharp changes are not expected. </font><font style="vertical-align: inherit;">Therefore, the history of the last five days consists of 120 observations (720/6). </font><font style="vertical-align: inherit;">For a model that performs spot prediction, the goal is to read the temperature after 12 hours in the future. </font><font style="vertical-align: inherit;">In this case, the target vector will be the temperature after 72 (12x6) observations ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">see the following addition. - Approx. Translator</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<pre><code class="python hljs">past_history = <span class="hljs-number">720</span>
future_target = <span class="hljs-number">72</span>
STEP = <span class="hljs-number">6</span><font></font>
<font></font>
x_train_single, y_train_single = multivariate_data(dataset, dataset[:, <span class="hljs-number">1</span>], <span class="hljs-number">0</span>,<font></font>
                                                   TRAIN_SPLIT, past_history,<font></font>
                                                   future_target, STEP,<font></font>
                                                   single_step=<span class="hljs-literal">True</span>)<font></font>
x_val_single, y_val_single = multivariate_data(dataset, dataset[:, <span class="hljs-number">1</span>],<font></font>
                                               TRAIN_SPLIT, <span class="hljs-literal">None</span>, past_history,<font></font>
                                               future_target, STEP,<font></font>
                                               single_step=<span class="hljs-literal">True</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Check the time interval.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">print</span> (<span class="hljs-string">'Single window of past history : {}'</span>.format(x_train_single[<span class="hljs-number">0</span>].shape))
</code></pre><br>
<code>Single window of past history : (120, 3)<br>
</code><br>
<pre><code class="python hljs">train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))<font></font>
train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()<font></font>
<font></font>
val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))<font></font>
val_data_single = val_data_single.batch(BATCH_SIZE).repeat()<font></font>
</code></pre><br>
<pre><code class="python hljs">single_step_model = tf.keras.models.Sequential()<font></font>
single_step_model.add(tf.keras.layers.LSTM(<span class="hljs-number">32</span>,<font></font>
                                           input_shape=x_train_single.shape[<span class="hljs-number">-2</span>:]))<font></font>
single_step_model.add(tf.keras.layers.Dense(<span class="hljs-number">1</span>))<font></font>
<font></font>
single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=<span class="hljs-string">'mae'</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We will check our sample and derive loss curves at the stages of training and verification.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> val_data_single.take(<span class="hljs-number">1</span>):<font></font>
  print(single_step_model.predict(x).shape)<font></font>
</code></pre><br>
<code>(256, 1)<br>
</code><br>
<pre><code class="python hljs">single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,<font></font>
                                            steps_per_epoch=EVALUATION_INTERVAL,<font></font>
                                            validation_data=val_data_single,<font></font>
                                            validation_steps=<span class="hljs-number">50</span>)
</code></pre><br>
<code>Train for 200 steps, validate for 50 steps<br>
Epoch 1/10<br>
200/200 [==============================] - 4s 18ms/step - loss: 0.3090 - val_loss: 0.2646<br>
Epoch 2/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2624 - val_loss: 0.2435<br>
Epoch 3/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2616 - val_loss: 0.2472<br>
Epoch 4/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2567 - val_loss: 0.2442<br>
Epoch 5/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2263 - val_loss: 0.2346<br>
Epoch 6/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2416 - val_loss: 0.2643<br>
Epoch 7/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2411 - val_loss: 0.2577<br>
Epoch 8/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2410 - val_loss: 0.2388<br>
Epoch 9/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2447 - val_loss: 0.2485<br>
Epoch 10/10<br>
200/200 [==============================] - 2s 9ms/step - loss: 0.2388 - val_loss: 0.2422<br>
</code><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_train_history</span>(<span class="hljs-params">history, title</span>):</span>
  loss = history.history[<span class="hljs-string">'loss'</span>]<font></font>
  val_loss = history.history[<span class="hljs-string">'val_loss'</span>]<font></font>
<font></font>
  epochs = range(len(loss))<font></font>
<font></font>
  plt.figure()<font></font>
<font></font>
  plt.plot(epochs, loss, <span class="hljs-string">'b'</span>, label=<span class="hljs-string">'Training loss'</span>)<font></font>
  plt.plot(epochs, val_loss, <span class="hljs-string">'r'</span>, label=<span class="hljs-string">'Validation loss'</span>)<font></font>
  plt.title(title)<font></font>
  plt.legend()<font></font>
<font></font>
  plt.show()<font></font>
</code></pre><br>
<pre><code class="python hljs">plot_train_history(single_step_history,
                   <span class="hljs-string">'Single Step Training and validation loss'</span>)
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/baa/481/4df/baa4814df5d278c7be5a4daf629ec8e0.jpg" alt="image"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Addition: </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Data preparation for a model with a multidimensional input performing point prediction is shown schematically in the following figure. </font><font style="vertical-align: inherit;">For convenience and a more visual representation of data preparation, the argument </font></font><code>STEP</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">is 1. Note that in the given generator functions, the </font></font><u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">argument is </font></font><code>STEP </code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">intended only for the formation of the history</font></font></u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and not for the target vector. </font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/bfd/c0b/ef1/bfdc0bef1203da6840adcb4311455645.png" alt="image"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this case, it </font></font><code>x_train_single</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">has the form </font></font><code>(299280, 720, 3)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When </font></font><code>STEP=6</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, the form will take the following form: </font></font><code>(299280, 120, 3)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and the speed of the function will increase significantly. </font><font style="vertical-align: inherit;">In general, you need to give credit to the programmer: the generators presented in the manual are very voracious in terms of memory consumption. </font></font></i><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Performing a point prediction</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that the model is trained, we will perform several test predictions. The history of observations of 3 signs for the last five days, selected every hour (time interval = 120), is fed to the model input. Since our goal is to forecast only temperature, the past temperature values ‚Äã‚Äã( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">history</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) are </font><font style="vertical-align: inherit;">displayed in blue on the graph </font><font style="vertical-align: inherit;">. The forecast was made half a day into the future (hence the gap between history and the predicted value).</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> val_data_single.take(<span class="hljs-number">3</span>):<font></font>
  plot = show_plot([x[<span class="hljs-number">0</span>][:, <span class="hljs-number">1</span>].numpy(), y[<span class="hljs-number">0</span>].numpy(),<font></font>
                    single_step_model.predict(x)[<span class="hljs-number">0</span>]], <span class="hljs-number">12</span>,
                   <span class="hljs-string">'Single Step Prediction'</span>)<font></font>
  plot.show()<font></font>
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/6ac/a5b/ce3/6aca5bce3fef9de56f1fac299da5527c.jpg" alt="image"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interval forecasting</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In this case, on the basis of some available history, the model is trained to predict the interval of future values. </font><font style="vertical-align: inherit;">Thus, in contrast to a model that predicts only one value in the future, this model predicts a sequence of values ‚Äã‚Äãin the future. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Suppose, as in the case with the model performing point prediction, for the model performing interval prediction, the training data is the hourly measurements of the last five days (720/6). </font><font style="vertical-align: inherit;">However, in this case, the model must be trained to predict the temperature for the next 12 hours. </font><font style="vertical-align: inherit;">Since observations are recorded every 10 minutes, the output of the model should consist of 72 predictions. </font><font style="vertical-align: inherit;">To complete this task, it is necessary to prepare the data set again, but with a different target interval.</font></font><br>
<br>
<pre><code class="python hljs">future_target = <span class="hljs-number">72</span>
x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, <span class="hljs-number">1</span>], <span class="hljs-number">0</span>,<font></font>
                                                 TRAIN_SPLIT, past_history,<font></font>
                                                 future_target, STEP)<font></font>
x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, <span class="hljs-number">1</span>],<font></font>
                                             TRAIN_SPLIT, <span class="hljs-literal">None</span>, past_history,<font></font>
                                             future_target, STEP)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Check the selection.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">print</span> (<span class="hljs-string">'Single window of past history : {}'</span>.format(x_train_multi[<span class="hljs-number">0</span>].shape))
<span class="hljs-keyword">print</span> (<span class="hljs-string">'\n Target temperature to predict : {}'</span>.format(y_train_multi[<span class="hljs-number">0</span>].shape))
</code></pre><br>
<code>Single window of past history : (120, 3)<br>
<br>
Target temperature to predict : (72,)<br>
</code><br>
<pre><code class="python hljs">train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))<font></font>
train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()<font></font>
<font></font>
val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))<font></font>
val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()<font></font>
</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Addition: the difference in the formation of the target vector for the ‚Äúinterval model‚Äù from the ‚Äúpoint model‚Äù is seen in the following figure. </font></font></i><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/190/5c6/845/1905c6845d2746a1f0bc6ae88f913b99.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We will prepare the visualization.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">multi_step_plot</span>(<span class="hljs-params">history, true_future, prediction</span>):</span>
  plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">6</span>))<font></font>
  num_in = create_time_steps(len(history))<font></font>
  num_out = len(true_future)<font></font>
<font></font>
  plt.plot(num_in, np.array(history[:, <span class="hljs-number">1</span>]), label=<span class="hljs-string">'History'</span>)<font></font>
  plt.plot(np.arange(num_out)/STEP, np.array(true_future), <span class="hljs-string">'bo'</span>,<font></font>
           label=<span class="hljs-string">'True Future'</span>)
  <span class="hljs-keyword">if</span> prediction.any():<font></font>
    plt.plot(np.arange(num_out)/STEP, np.array(prediction), <span class="hljs-string">'ro'</span>,<font></font>
             label=<span class="hljs-string">'Predicted Future'</span>)<font></font>
  plt.legend(loc=<span class="hljs-string">'upper left'</span>)<font></font>
  plt.show()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On this and subsequent similar charts, the history and future data are hourly.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> train_data_multi.take(<span class="hljs-number">1</span>):<font></font>
  multi_step_plot(x[<span class="hljs-number">0</span>], y[<span class="hljs-number">0</span>], np.array([<span class="hljs-number">0</span>]))
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/245/beb/236/245beb236bc1f87f2d611ce8d2c0bc81.jpg" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since this task is a bit more complicated than the previous one, the model will consist of two LSTM layers. </font><font style="vertical-align: inherit;">Finally, since 72 predictions are performed, the output layer has 72 neurons.</font></font><br>
<br>
<pre><code class="python hljs">multi_step_model = tf.keras.models.Sequential()<font></font>
multi_step_model.add(tf.keras.layers.LSTM(<span class="hljs-number">32</span>,<font></font>
                                          return_sequences=<span class="hljs-literal">True</span>,<font></font>
                                          input_shape=x_train_multi.shape[<span class="hljs-number">-2</span>:]))<font></font>
multi_step_model.add(tf.keras.layers.LSTM(<span class="hljs-number">16</span>, activation=<span class="hljs-string">'relu'</span>))<font></font>
multi_step_model.add(tf.keras.layers.Dense(<span class="hljs-number">72</span>))<font></font>
<font></font>
multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=<span class="hljs-number">1.0</span>), loss=<span class="hljs-string">'mae'</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We will check our sample and derive loss curves at the stages of training and verification.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> val_data_multi.take(<span class="hljs-number">1</span>):
  <span class="hljs-keyword">print</span> (multi_step_model.predict(x).shape)
</code></pre><br>
<code>(256, 72)<br>
</code><br>
<pre><code class="python hljs">multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,<font></font>
                                          steps_per_epoch=EVALUATION_INTERVAL,<font></font>
                                          validation_data=val_data_multi,<font></font>
                                          validation_steps=<span class="hljs-number">50</span>)
</code></pre><br>
<code>Train for 200 steps, validate for 50 steps<br>
Epoch 1/10<br>
200/200 [==============================] - 21s 103ms/step - loss: 0.4952 - val_loss: 0.3008<br>
Epoch 2/10<br>
200/200 [==============================] - 18s 89ms/step - loss: 0.3474 - val_loss: 0.2898<br>
Epoch 3/10<br>
200/200 [==============================] - 18s 89ms/step - loss: 0.3325 - val_loss: 0.2541<br>
Epoch 4/10<br>
200/200 [==============================] - 18s 89ms/step - loss: 0.2425 - val_loss: 0.2066<br>
Epoch 5/10<br>
200/200 [==============================] - 18s 89ms/step - loss: 0.1963 - val_loss: 0.1995<br>
Epoch 6/10<br>
200/200 [==============================] - 18s 90ms/step - loss: 0.2056 - val_loss: 0.2119<br>
Epoch 7/10<br>
200/200 [==============================] - 18s 91ms/step - loss: 0.1978 - val_loss: 0.2079<br>
Epoch 8/10<br>
200/200 [==============================] - 18s 89ms/step - loss: 0.1957 - val_loss: 0.2033<br>
Epoch 9/10<br>
200/200 [==============================] - 18s 90ms/step - loss: 0.1977 - val_loss: 0.1860<br>
Epoch 10/10<br>
200/200 [==============================] - 18s 88ms/step - loss: 0.1904 - val_loss: 0.1863<br>
</code><br>
<pre><code class="python hljs">plot_train_history(multi_step_history, <span class="hljs-string">'Multi-Step Training and validation loss'</span>)
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/479/600/430/4796004305bd5b839ead7c35120ddc69.png" alt="image"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Performing an Interval Prediction</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
So, let's find out how successfully a trained ANN copes with forecasts of future temperature values.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">for</span> x, y <span class="hljs-keyword">in</span> val_data_multi.take(<span class="hljs-number">3</span>):<font></font>
  multi_step_plot(x[<span class="hljs-number">0</span>], y[<span class="hljs-number">0</span>], multi_step_model.predict(x)[<span class="hljs-number">0</span>])
</code></pre><br>
<img src="https://habrastorage.org/getpro/habr/post_images/a3a/2fa/3cd/a3a2fa3cd17ec79c04d9ab44a3d3ad2c.jpg" alt="image"><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Next steps</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This guide is a brief introduction to time series forecasting using RNS. Now you can try to predict the stock market and become a billionaire </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(in the original, just like that :). - Note translator)</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, you can write your own generator for preparing data instead of the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">uni / multivariate_data function</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in order to make more efficient use of memory. You can also familiarize yourself with the work of ‚Äú </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">time series windowing</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äù and bring its ideas to this guide. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For further understanding, it is recommended that you read Chapter 15 of the book </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúApplied Machine Learning with Scikit-Learn, Keras, and TensorFlow‚Äù</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Aurelien Geron, 2nd Edition) and Chapter 6 of the book</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúDeep Learning in Python‚Äù</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Francois Scholl). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Final addition </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
While staying at home, take care not only about your health, but also take pity on the computer by executing examples of the manual on a truncated data set. </font><font style="vertical-align: inherit;">For example, taking into account the proportion of 70x30 (training / testing), you can limit it as follows:</font></font></i><br>
<br>
<pre><code class="python hljs">dataset = features[<span class="hljs-number">300000</span>:].values<font></font>
TRAIN_SPLIT = <span class="hljs-number">85000</span></code></pre></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en495862/index.html">Trusted Types - a new way to protect web application code from XSS attacks</a></li>
<li><a href="../en495864/index.html">Creating a design system for the game: a detailed analysis of the approach</a></li>
<li><a href="../en495870/index.html">Tips & tricks working with Ceph in busy projects</a></li>
<li><a href="../en495880/index.html">The book ‚ÄúHead First. Learning Go ¬ª</a></li>
<li><a href="../en495882/index.html">The 9 best open source finds for March 2020</a></li>
<li><a href="../en495888/index.html">PyCon Russia has opened CFP for future speakers. Participation Forms and Expected Topics</a></li>
<li><a href="../en495890/index.html">Configuring a Nginx / LetsEncrypt Bundle in Docker Swarm</a></li>
<li><a href="../en495892/index.html">Do you really know what arrays are?</a></li>
<li><a href="../en495894/index.html">Javascript Performance Measurement</a></li>
<li><a href="../en495896/index.html">Use-sound Package: Sound Effects in React Applications</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
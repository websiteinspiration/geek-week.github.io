<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçæ üëÇüèº üå´Ô∏è Delta: Data Synchronization and Enrichment Platform ü¶ó ü¶è ‚úçüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In anticipation of the launch of a new stream at the Data Engineer course , we prepared a translation of interesting material.
 
 
 
 
 
 Overview
 We...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Delta: Data Synchronization and Enrichment Platform</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/487460/"><i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In anticipation of the launch of a new stream at the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Data Engineer</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> course </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">, we</font></a><font style="vertical-align: inherit;"> prepared a translation of interesting material.</font></font><br>
</b></i><br>
<br>
<img src="https://habrastorage.org/webt/pg/_y/c6/pg_yc6ttjvtbnkh2-rhe_eq1dnw.png"><br>
<br>
<hr><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Overview</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 We‚Äôll talk about a fairly popular pattern by which applications use several data stores, where each store is used for its own purposes, for example, to store the canonical form of data (MySQL, etc.), provide advanced search capabilities (ElasticSearch, etc. .), caching (Memcached, etc.) and others. Typically, when using multiple data storages, one of them works as the main storage, and the other as derivative storage. The only problem is how to synchronize these data stores.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We looked at a number of different patterns that tried to solve the problem of synchronizing multiple repositories, such as double-entry, distributed transactions, etc. </font><font style="vertical-align: inherit;">However, these approaches have significant limitations in terms of real-life use, reliability, and maintenance. </font><font style="vertical-align: inherit;">In addition to data synchronization, some applications also need to enrich data by invoking external services.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To solve these problems, Delta was developed. </font><font style="vertical-align: inherit;">Delta ultimately is a consistent, event-driven platform for synchronizing and enriching data.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Existing solutions</font></font></h3><br>
 <h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Double entry</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 To synchronize two data stores, you can use double recording, which writes to one store, and then immediately writes to another. The first record can be repeated, and the second can be interrupted if the first fails after exhausting the number of attempts. However, two data stores may stop synchronizing if writing to the second store fails. This problem is usually solved by creating a recovery procedure that can periodically re-transfer data from the first storage to the second or do this only if differences are found in the data. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problems:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Performing a recovery procedure is a specific job that cannot be reused. </font><font style="vertical-align: inherit;">In addition, data between storages remains out of sync until the recovery procedure is completed. </font><font style="vertical-align: inherit;">The solution is complicated if more than two data stores are used. </font><font style="vertical-align: inherit;">Finally, the recovery procedure can add stress to the original data source.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Change Log Table</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 When changes occur in a set of tables (for example, inserting, updating, and deleting records), change records are added to the log table as part of the same transaction. Another thread or process constantly requests events from the log table and writes them to one or more data storages, when it becomes necessary to delete events from the log table after confirming the record by all storages. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problems:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
This pattern should be implemented as a library and, ideally, without changing the application code using it. In a polyglot environment, the implementation of such a library must exist in any necessary language, but it is very difficult to ensure the coordination of the functions and behavior between languages.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Another problem lies in obtaining schema changes in systems that do not support transactional schema changes [1] [2], such as MySQL. </font><font style="vertical-align: inherit;">Therefore, a template for making a change (for example, changing a scheme) and writing it to the change log table will not always work.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Distributed Transactions</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Distributed transactions can be used to split a transaction between several heterogeneous data storages so that the operation is either committed in all the stores used or not committed in any of them. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problems:</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Distributed transactions are a very big problem for heterogeneous data warehouses. </font><font style="vertical-align: inherit;">By their nature, they can only rely on the smallest common denominator of the systems involved. </font><font style="vertical-align: inherit;">For example, XA transactions block execution if a failure occurs during the preparation process. </font><font style="vertical-align: inherit;">In addition, XA does not provide deadlock detection and does not support optimistic concurrency management schemes. </font><font style="vertical-align: inherit;">In addition, some systems like ElasticSearch do not support XA or any other heterogeneous transaction model. </font><font style="vertical-align: inherit;">Thus, ensuring atomicity of recording in various data storage technologies remains a very difficult task for applications [3].</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Delta</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Delta was designed to address the limitations of existing data synchronization solutions, and it also enriches data on the fly. Our goal was to abstract all these complex points from application developers so that they could fully concentrate on the implementation of business functionality. Next, we will describe ‚ÄúMovie Search,‚Äù the actual use case for Netflix's Delta. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Netflix makes extensive use of microservice architecture and each microservice typically serves one type of data. The main information about the film is taken out in a microservice called the Movie Service, as well as related data, such as information about producers, actors, vendors and so on, are managed by several other microservices (namely, Deal Service, Talent Service and Vendor Service).</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Business users at Netflix Studios often need to search by various criteria for films, which is why it is very important for them to be able to search all the data related to films. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Before Delta, the movie search team needed to retrieve data from several microservices before indexing movie data. In addition, the team had to develop a system that would periodically update the search index, requesting changes from other microservices, even if there were no changes at all. This system quickly became overgrown with complexity and became difficult to maintain. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tc/kb/t9/tckbt9vwkwiqmilkt4y18gjqbjs.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 1. Polling system before Delta</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 After using Delta, the system was simplified to an event-driven system, as shown in the following figure. CDC (Change-Data-Capture) events are sent to Keystone Kafka topics using the Delta-Connector. A Delta application built using the Delta Stream Processing Framework (based on Flink) receives CDC events from the topic, enriches them, invoking other microservices, and finally passes the enriched data to the search index in Elasticsearch. The whole process takes place in almost real time, that is, as soon as changes are recorded in the data warehouse, search indexes are updated. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/bz/lg/t4/bzlgt47eyfuw8wlbzv2dsx6i3ge.png"><br>
 <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 2. Data pipeline using Delta</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 In the following sections, we describe the work of the Delta-Connector, which connects to the repository and publishes CDC events at the transport level, which is a real-time data transmission infrastructure that directs CDC events to Kafka topics. </font><font style="vertical-align: inherit;">And at the very end, we‚Äôll talk about the Delta stream processing framework that application developers can use for processing and enrichment logic.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CDC (Change-Data-Capture)</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 We have developed a CDC service called Delta-Connector, which can capture committed changes from the data store in real time and write them to the stream. </font><font style="vertical-align: inherit;">Real-time changes are taken from the transaction log and storage dumps. </font><font style="vertical-align: inherit;">Dumps are used because transaction logs do not usually store the entire change history. </font><font style="vertical-align: inherit;">Changes are usually serialized as Delta events, so the recipient does not have to worry about where the change comes from. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Delta-Connector supports several additional features, such as:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ability to write custom output past Kafka.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The ability to activate manual dumps at any time for all tables, a specific table or for certain primary keys.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dumps can be picked up by chunks, so there is no need to start all over again in the event of a failure.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There is no need to put locks on tables, which is very important so that the write traffic to the database is never blocked by our service.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">High availability due to backups in AWS Availability Zones.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We currently support MySQL and Postgres, including deployments to AWS RDS and Aurora. </font><font style="vertical-align: inherit;">We also support Cassandra (multi-master). </font><font style="vertical-align: inherit;">You can learn more about the Delta-Connector on this </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">blog</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kafka and transport level</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Delta Event Transport layer is built on the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keystone</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> platform messaging service </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So historically, posting on Netflix has been optimized for increased availability rather than longevity (see </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">previous article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). A compromise was the potential inconsistency of broker data in various border scenarios. For example, the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unclean leader election</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is responsible for ensuring that the recipient potentially duplicates or loses events.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
With Delta, we wanted to get stronger guarantees of durability in order to ensure the delivery of CDC events to derivative storages. To do this, we proposed a specially designed Kafka cluster as an object of the first class. You can look at some broker settings in the table below: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ri/70/hn/ri70hnpnr5wmiedci0_n5clwlwc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Keystone Kafka clusters, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unclean leader election is</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> usually enabled to ensure publisher availability. This can result in message loss if an unsynchronized replica is selected as the leader. For the new highly reliable Kafka cluster, the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unclean leader election</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> option is </font><font style="vertical-align: inherit;">disabled to prevent message loss. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We also increased the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">replication factor</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from 2 to 3 and </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">minimum insync replicas</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from 1 to 2. Publishers writing to this cluster require acks from all others, ensuring that 2 out of 3 replicas will have the most up-to-date messages sent by the publisher.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When the broker instance exits, the new instance replaces the old one. However, the new broker will need to catch up with unsynchronized replicas, which can take several hours. To reduce the recovery time for this scenario, we started using the Amazon Elastic Block Store instead of local brokers disks. When a new instance replaces a completed broker instance, it attaches the EBS volume that the completed instance had and begins to catch up with new messages. This process reduces the time to eliminate the backlog from several hours to several minutes, since the new instance no longer needs to be replicated from an empty state. In general, separate storage and broker life cycles significantly reduce the effect of the broker change.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To further increase the guarantee of data delivery, we used </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a message tracking system</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to detect any loss of messages in extreme conditions (for example, clock synchronization in the section leader).</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stream processing framework</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The processing level at Delta is based on the Netflix SPaaS platform, which enables the integration of Apache Flink with the Netflix ecosystem. The platform provides a user interface that controls the deployment of Flink jobs and the orchestration of Flink clusters on top of our Titus container management platform. The interface also manages job configurations and allows users to make configuration changes dynamically without having to recompile Flink jobs. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Delta provides a stream processing framework for Flink and SPaaS- </font><b><i><font style="vertical-align: inherit;">based</font></i></b><font style="vertical-align: inherit;"> data, which uses </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">annotation-based</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DSL (Domain Specific Language) to abstract technical details. For example, to determine the step by which events will be enriched by calling external services, users need to write the next DSL, and the framework will create a model based on it that Flink will execute. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fu/l2/kn/ful2knsuaqitsat9p69qhitq-a4.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 3. DSL enrichment example in Delta</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
The processing framework not only shortens the learning curve, but also provides general flow processing functions, such as deduplication, schematization, as well as flexibility and fault tolerance to solve common problems at work.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The Delta Stream Processing Framework consists of two key modules, the DSL &amp; API module and the Runtime module. The DSL &amp; API module provides the DSL and UDF (User-Defined-Function) APIs so that users can write their own processing logic (such as filtering or transformations). The Runtime module provides an implementation of the DSL parser, which builds an internal representation of the processing steps in DAG models. The Execution component interprets DAG models to initialize the actual Flink statements and ultimately launch the Flink application. The architecture of the framework is illustrated in the following figure. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9_/gm/on/9_gmono77zxzhhorwhyghdkgdqq.png"> <br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 4. Delta Stream Processing Framework architecture</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
This approach has several advantages:</font></font><br>
<br>
<ul>
<li>     -      Flink   SPaaS.</li>
<li>      ,         -     (UDF).</li>
<li>  Delta   ,             ,     .</li>
</ul><br>
<br>
<h3>  </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Delta has been in production for over a year and plays a key role in many Netflix Studio applications. </font><font style="vertical-align: inherit;">It helped teams implement use cases such as search indexing, data storage, and event-driven workflows. </font><font style="vertical-align: inherit;">The following is an overview of the high-level architecture of the Delta platform. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/im/rf/dq/imrfdqholl1umfrm_pb4nqwy064.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Figure 5. The high-level architecture of Delta.</font></font></i><br>
 <br>
 <h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acknowledgments</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 We would like to thank the following people who contributed to the creation and development of Delta at Netflix: Allen Wang, Charles Zhao, Jaebin Yoon, Josh Snyder, Kasturi Chatterjee, Mark Cho, Olof Johansson, Piyush Goyal, Prashanth Ramdas, Raghuram Onti Srinivasan, Sandeep Gupta , Steven Wu, Tharanga Gamaethige, Yun Wang and Zhenzhong Xu.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sources</font></font></h3><br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dev.mysql.com/doc/refman/5.7/en/implicit-commit.html</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dev.mysql.com/doc/refman/5.7/en/cannot-roll-back.html</font></font></a></li>
<li>Martin Kleppmann, Alastair R. Beresford, Boerge Svingen: Online event processing. Commun. ACM 62(5): 43‚Äì49 (2019). DOI: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">doi.org/10.1145/3312527</a></li>
</ol><br>
<b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=">   </a>: ¬´Data Build Tool   Amazon Redshift¬ª.</b></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en487444/index.html">‚ÄúWhile drinking coffee, billed and received a push for payment‚Äù - innovations that allow you to conduct business 24/7</a></li>
<li><a href="../en487446/index.html">Can a company ‚Äúown‚Äù color?</a></li>
<li><a href="../en487448/index.html">Super-powers of ultra-thin materials: in materials science, 2D is the new 3D</a></li>
<li><a href="../en487450/index.html">We configure WireGuard on a Mikrotik router running OpenWrt</a></li>
<li><a href="../en487454/index.html">Who are these people? Why do they need me? and other scrum master problems</a></li>
<li><a href="../en487462/index.html">Webix JavaScript library through the eyes of a beginner. Part 4. Work with data. CRUD</a></li>
<li><a href="../en487470/index.html">Calibry: 3D Breakthrough Price Breakthrough</a></li>
<li><a href="../en487486/index.html">Sega Dreamcast Anatomy: Console Second Life</a></li>
<li><a href="../en487488/index.html">Cases for applying network anomaly analysis tools: detecting the spread of malicious code</a></li>
<li><a href="../en487490/index.html">XSL transformation on MS SQL without CLR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
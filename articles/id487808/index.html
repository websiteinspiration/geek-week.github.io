<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👺 👦 🧑🏽 Recurrent Neural Networks (RNN) dengan Keras 👩🏾‍🏭 👩🏻‍💼 🍣</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Terjemahan dari Panduan Jaringan Syaraf Tiruan Rekursif dari Tensorflow.org. Materi tersebut membahas kemampuan bawaan Keras / Tensorflow 2.0 untuk pe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Recurrent Neural Networks (RNN) dengan Keras</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487808/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Terjemahan dari Panduan Jaringan Syaraf Tiruan Rekursif dari Tensorflow.org. </font><font style="vertical-align: inherit;">Materi tersebut membahas kemampuan bawaan Keras / Tensorflow 2.0 untuk penyambungan cepat, serta kemungkinan menyesuaikan lapisan dan sel. </font><font style="vertical-align: inherit;">Kasus dan keterbatasan penggunaan inti CuDNN juga dipertimbangkan, yang memungkinkan untuk mempercepat proses pembelajaran jaringan saraf.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/xt/_q/nj/xt_qnjgfjengqoqd4gizkq4j_wk.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jaringan saraf rekursif (RNN) adalah kelas jaringan saraf yang baik untuk memodelkan data serial, seperti deret waktu atau bahasa alami. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jika secara skematis, layer RNN menggunakan loop </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untuk mengulangi urutan waktu, sementara menyimpan dalam keadaan internal, menyandikan informasi tentang langkah-langkah yang telah dilihatnya. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras RNN API dirancang dengan fokus pada: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kemudahan penggunaan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : built-in lapisan </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memungkinkan Anda dengan cepat membangun model rekursif tanpa harus membuat pengaturan konfigurasi yang rumit. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kustomisasi yang mudah</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Anda juga dapat menentukan lapisan sel RNN Anda sendiri (bagian dalam loop)</font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) dengan perilaku khusus dan menggunakannya dengan lapisan umum `tf.keras.layers.RNN` (the` for` loop itu sendiri). </font><font style="vertical-align: inherit;">Ini akan memungkinkan Anda dengan cepat membuat prototipe berbagai ide penelitian dengan cara yang fleksibel, dengan kode minimal.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instalasi</font></font></h2><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> collections
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Membangun model yang sederhana</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras memiliki tiga lapisan RNN bawaan:</font></font><br>
<br>
<ol>
<li><code>tf.keras.layers.SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, RNN yang terhubung penuh di mana output dari langkah waktu sebelumnya harus diteruskan ke langkah berikutnya.</font></font></li>
<li><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, pertama kali diusulkan dalam artikel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mempelajari frasa menggunakan RNN codec untuk terjemahan mesin statistik</font></font></a></li>
<li><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, pertama kali diusulkan dalam artikel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Memori Jangka Pendek Jangka Panjang</font></font></a></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pada awal 2015, Keras memperkenalkan Python dan LSTM dan GRU implementasi open source pertama yang dapat digunakan kembali. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Berikut ini adalah contoh dari </font></font><code>Sequential</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">model yang memproses urutan bilangan bulat dengan menumpuk setiap bilangan bulat dalam vektor 64 dimensi, lalu memproses urutan vektor menggunakan lapisan </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()
<span class="hljs-comment">#   Embedding      1000, </span>
<span class="hljs-comment">#     64.</span>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#   LSTM  128  .</span>
model.add(layers.LSTM(<span class="hljs-number">128</span>))<font></font>
<font></font>
<span class="hljs-comment">#   Dense  10    softmax.</span>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Output dan Status</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secara default, output dari layer RNN berisi satu vektor per elemen. Vektor ini adalah output dari sel RNN terakhir yang berisi informasi tentang seluruh urutan input. Dimensi output ini </font></font><code>(batch_size, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, di mana </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sesuai dengan argumen yang </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">diteruskan ke konstruktor lapisan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lapisan RNN juga dapat mengembalikan seluruh urutan output untuk setiap elemen (satu vektor untuk setiap langkah), jika Anda menentukan </font></font><code>return_sequences=True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Dimensi dari output ini adalah </font></font><code>(batch_size, timesteps, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#  GRU  3D   (batch_size, timesteps, 256)</span>
model.add(layers.GRU(<span class="hljs-number">256</span>, return_sequences=<span class="hljs-literal">True</span>))<font></font>
<font></font>
<span class="hljs-comment">#  SimpleRNN  2D   (batch_size, 128)</span>
model.add(layers.SimpleRNN(<span class="hljs-number">128</span>))<font></font>
<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selain itu, layer RNN dapat mengembalikan status internal terakhirnya. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Status yang dikembalikan dapat digunakan nanti untuk melanjutkan eksekusi RNN atau </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untuk menginisialisasi RNN lainnya</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Pengaturan ini biasanya digunakan dalam model encoder-decoder, urutan ke urutan, di mana keadaan akhir dari pembuat kode digunakan untuk keadaan awal dekoder. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agar lapisan RNN mengembalikan keadaan internal, atur parameter </font></font><code>return_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke nilai </font></font><code>True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">saat membuat lapisan. Perhatikan bahwa ada </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 tensor status, dan </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hanya satu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk menyesuaikan keadaan awal layer, cukup panggil layer dengan argumen tambahan </font></font><code>initial_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Perhatikan bahwa dimensi harus cocok dengan dimensi elemen lapisan, seperti dalam contoh berikut.</font></font><br>
<br>
<pre><code class="python hljs">encoder_vocab = <span class="hljs-number">1000</span>
decoder_vocab = <span class="hljs-number">2000</span><font></font>
<font></font>
encoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=<span class="hljs-number">64</span>)(encoder_input)<font></font>
<font></font>
<span class="hljs-comment">#       </span><font></font>
output, state_h, state_c = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, return_state=<span class="hljs-literal">True</span>, name=<span class="hljs-string">'encoder'</span>)(encoder_embedded)<font></font>
encoder_state = [state_h, state_c]<font></font>
<font></font>
decoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=<span class="hljs-number">64</span>)(decoder_input)<font></font>
<font></font>
<span class="hljs-comment">#  2     LSTM    </span><font></font>
decoder_output = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, name=<span class="hljs-string">'decoder'</span>)(decoder_embedded, initial_state=encoder_state)<font></font>
output = layers.Dense(<span class="hljs-number">10</span>)(decoder_output)<font></font>
<font></font>
model = tf.keras.Model([encoder_input, decoder_input], output)<font></font>
model.summary()<font></font>
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lapisan RNN dan sel RNN</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
API RNN, selain lapisan RNN bawaan, juga menyediakan API tingkat sel. </font><font style="vertical-align: inherit;">Tidak seperti lapisan RNN, yang memproses seluruh paket urutan input, sel RNN hanya memproses satu langkah waktu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sel berada di dalam siklus </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lapisan RNN. </font><font style="vertical-align: inherit;">Membungkus sel dengan lapisan </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memberi Anda lapisan yang mampu memproses paket urutan, mis. </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Secara matematis, </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ini memberikan hasil yang sama dengan </font></font><code>LSTM(10)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Sebenarnya, implementasi layer ini di dalam TF v1.x hanya untuk membuat sel RNN yang sesuai dan membungkusnya dalam lapisan RNN. </font><font style="vertical-align: inherit;">Namun, penggunaan embedded layer </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memungkinkan penggunaan CuDNN yang dapat memberi Anda kinerja yang lebih baik.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ada tiga sel RNN bawaan, masing-masing sesuai dengan lapisan RNN-nya sendiri.</font></font><br>
<br>
<ul>
<li><code>tf.keras.layers.SimpleRNNCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cocok dengan layer </font></font><code>SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.GRUCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cocok dengan layer </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.LSTMCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cocok dengan layer </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Abstraksi sel bersama-sama dengan kelas umum </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">membuatnya sangat mudah untuk mengimplementasikan arsitektur RNN khusus untuk penelitian Anda.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Status penyimpanan lintas batch</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saat memproses urutan panjang (mungkin tanpa akhir), Anda mungkin ingin menggunakan pola </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">status lintas-batch</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Biasanya, keadaan internal lapisan RNN diatur ulang dengan setiap paket data baru (mis. Setiap contoh yang melihat lapisan diasumsikan independen dari masa lalu). Lapisan akan mempertahankan status hanya selama pemrosesan elemen ini. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Namun, jika Anda memiliki urutan yang sangat panjang, akan berguna untuk memecahnya menjadi yang lebih pendek dan mentransfernya ke lapisan RNN secara bergantian tanpa mengatur ulang keadaan lapisan. Dengan demikian, sebuah layer dapat menyimpan informasi tentang seluruh urutan, meskipun hanya akan melihat satu urutan pada satu waktu. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda dapat melakukan ini dengan menetapkan `stateful = True` di konstruktor.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jika Anda memiliki urutan `s = [t0, t1, ... t1546, t1547]`, Anda dapat membaginya misalnya menjadi:</font></font><br>
<br>
<pre><code class="python hljs">s1 = [t0, t1, ... t100]<font></font>
s2 = [t101, ... t201]<font></font>
...<font></font>
s16 = [t1501, ... t1547]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kemudian Anda dapat memprosesnya dengan:</font></font><br>
<br>
<pre><code class="python hljs">lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> sub_sequences:<font></font>
  output = lstm_layer(s)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saat Anda ingin membersihkan kondisinya, gunakan </font></font><code>layer.reset_states()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<blockquote><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Catatan:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dalam hal ini, diasumsikan bahwa contoh </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dalam paket ini adalah kelanjutan dari contoh </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">paket sebelumnya. </font><font style="vertical-align: inherit;">Ini berarti bahwa semua paket berisi jumlah elemen yang sama (ukuran paket). </font><font style="vertical-align: inherit;">Misalnya, jika paket berisi </font></font><code>[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, paket selanjutnya harus berisi </font></font><code>[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ini adalah contoh lengkapnya:</font></font><br>
<br>
<pre><code class="python hljs">paragraph1 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph2 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph3 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
<font></font>
lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)<font></font>
output = lstm_layer(paragraph1)<font></font>
output = lstm_layer(paragraph2)<font></font>
output = lstm_layer(paragraph3)<font></font>
<font></font>
<span class="hljs-comment"># reset_states()      initial_state.</span>
<span class="hljs-comment">#  initial_state   ,      .</span>
lstm_layer.reset_states()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN dua arah</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk urutan selain seri waktu (mis. Teks), sering terjadi bahwa model RNN berfungsi lebih baik jika memproses urutan tidak hanya dari awal hingga akhir, tetapi juga sebaliknya. Misalnya, untuk memprediksi kata berikutnya dalam sebuah kalimat, seringkali berguna untuk mengetahui konteks di sekitar kata tersebut, dan bukan hanya kata-kata di depannya. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras menyediakan API sederhana untuk membuat RNNs dua arah: pembungkus </font></font><code>tf.keras.layers.Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">64</span>, return_sequences=<span class="hljs-literal">True</span>), <font></font>
                               input_shape=(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)))<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">32</span>)))<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di bawah penutup, </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lapisan RNN yang ditransfer </font></font><code>go_backwards</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">akan disalin </font><font style="vertical-align: inherit;">dan bidang </font><font style="vertical-align: inherit;">lapisan yang baru disalin akan </font><font style="vertical-align: inherit;">dibalik </font><font style="vertical-align: inherit;">, dan dengan demikian data input akan diproses dalam urutan terbalik. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Output dari ` </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN secara default akan menjadi jumlah dari output dari lapisan maju dan output dari lapisan balik. </font><font style="vertical-align: inherit;">Jika Anda membutuhkan perilaku penggabungan lainnya, mis. </font><font style="vertical-align: inherit;">gabungkan, ubah parameter `merge_mode` dalam konstruktor wrapper` Bidirectional`.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Optimalisasi Kinerja dan Core CuDNN di TensorFlow 2.0</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam TensorFlow 2.0, lapisan LSTM dan GRU bawaan dapat digunakan secara default pada inti CuDNN jika prosesor grafis tersedia. </font><font style="vertical-align: inherit;">Dengan perubahan ini, lapisan sebelumnya </font></font><code>keras.layers.CuDNNLSTM/CuDNNGRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sudah usang, dan Anda dapat membangun model Anda tanpa khawatir tentang peralatan yang akan bekerja. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Karena kernel CuDNN dibangun dengan beberapa asumsi, ini berarti bahwa layer </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tidak akan dapat menggunakan layer kernel CuDNN jika Anda mengubah pengaturan default dari layer LSTM atau GRU bawaan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Misalnya.</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mengubah fungsi </font></font><code>activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dari </font></font><code>tanh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke yang lain.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mengubah fungsi </font></font><code>recurrent_activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dari </font></font><code>sigmoid</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke yang lain.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penggunaan </font></font><code>recurrent_dropout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&gt; 0.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menyetelnya </font></font><code>unroll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke True, yang menyebabkan LSTM / GRU untuk menguraikan internal </font></font><code>tf.while_loop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menjadi loop dikerahkan </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setel </font></font><code>use_bias</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke Salah.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menggunakan topeng ketika data input tidak dibenarkan (jika topeng cocok dengan data yang benar-benar selaras, CuDNN masih dapat digunakan. Ini adalah kasus yang paling umum).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jika memungkinkan gunakan kernel CuDNN</font></font></h3><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">64</span>
<span class="hljs-comment">#    MNIST    (batch_size, 28, 28).</span>
<span class="hljs-comment">#     (28, 28) (   ).</span>
input_dim = <span class="hljs-number">28</span><font></font>
<font></font>
units = <span class="hljs-number">64</span>
output_size = <span class="hljs-number">10</span>  <span class="hljs-comment">#   0  9</span><font></font>
<font></font>
<span class="hljs-comment">#  RNN </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_model</span>(<span class="hljs-params">allow_cudnn_kernel=True</span>):</span>
  <span class="hljs-comment"># CuDNN     ,     .</span>
  <span class="hljs-comment">#   `LSTM(units)`    CuDNN,</span>
  <span class="hljs-comment">#   RNN(LSTMCell(units))   non-CuDNN .</span>
  <span class="hljs-keyword">if</span> allow_cudnn_kernel:
    <span class="hljs-comment">#  LSTM      CuDNN.</span>
    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(<span class="hljs-literal">None</span>, input_dim))
  <span class="hljs-keyword">else</span>:
    <span class="hljs-comment">#  LSTMCell  RNN    CuDNN.</span><font></font>
    lstm_layer = tf.keras.layers.RNN(<font></font>
        tf.keras.layers.LSTMCell(units),<font></font>
        input_shape=(<span class="hljs-literal">None</span>, input_dim))<font></font>
  model = tf.keras.models.Sequential([<font></font>
      lstm_layer,<font></font>
      tf.keras.layers.BatchNormalization(),<font></font>
      tf.keras.layers.Dense(output_size)]<font></font>
  )<font></font>
  <span class="hljs-keyword">return</span> model
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Memuat dataset MNIST</font></font></h3><br>
<pre><code class="python hljs">mnist = tf.keras.datasets.mnist<font></font>
<font></font>
(x_train, y_train), (x_test, y_test) = mnist.load_data()<font></font>
x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span>
sample, sample_label = x_train[<span class="hljs-number">0</span>], y_train[<span class="hljs-number">0</span>]</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Buat instance dari model dan kompilasi</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami telah memilih </font></font><code>sparse_categorical_crossentropy</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sebagai fungsi kerugian. </font><font style="vertical-align: inherit;">Output dari model memiliki dimensi </font></font><code>[batch_size, 10]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Jawaban dari model adalah vektor integer, masing-masing angka berada dalam kisaran dari 0 hingga 9.</font></font><br>
<br>
<pre><code class="python hljs">model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
<font></font>
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
              optimizer=<span class="hljs-string">'sgd'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<pre><code class="python hljs">model.fit(x_train, y_train,<font></font>
          validation_data=(x_test, y_test),<font></font>
          batch_size=batch_size,<font></font>
          epochs=<span class="hljs-number">5</span>)</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bangun model baru tanpa inti CuDNN</font></font></h3><br>
<pre><code class="python hljs">slow_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">False</span>)<font></font>
slow_model.set_weights(model.get_weights())<font></font>
slow_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
                   optimizer=<span class="hljs-string">'sgd'</span>, <font></font>
                   metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
slow_model.fit(x_train, y_train, <font></font>
               validation_data=(x_test, y_test), <font></font>
               batch_size=batch_size,<font></font>
               epochs=<span class="hljs-number">1</span>)  <span class="hljs-comment">#         .</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti yang Anda lihat, model yang dibangun dengan CuDNN jauh lebih cepat untuk pelatihan daripada model yang menggunakan inti TensorFlow biasa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Model yang sama dengan dukungan CuDNN dapat digunakan untuk output dalam lingkungan prosesor tunggal. </font><font style="vertical-align: inherit;">Anotasi </font></font><code>tf.device</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hanya menunjukkan perangkat yang digunakan. </font><font style="vertical-align: inherit;">Model akan berjalan secara default pada CPU jika GPU tidak tersedia. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda tidak perlu khawatir tentang perangkat keras yang sedang Anda kerjakan. </font><font style="vertical-align: inherit;">Bukankah itu keren?</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">'CPU:0'</span>):<font></font>
  cpu_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
  cpu_model.set_weights(model.get_weights())<font></font>
  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, <span class="hljs-number">0</span>)), axis=<span class="hljs-number">1</span>)<font></font>
  print(<span class="hljs-string">'Predicted result is: %s, target result is: %s'</span> % (result.numpy(), sample_label))<font></font>
  plt.imshow(sample, cmap=plt.get_cmap(<span class="hljs-string">'gray'</span>))
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN dengan input daftar / kamus, atau input bersarang</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Struktur bersarang memungkinkan Anda memasukkan lebih banyak informasi dalam satu langkah waktu. </font><font style="vertical-align: inherit;">Misalnya, bingkai video dapat berisi input audio dan video secara bersamaan. </font><font style="vertical-align: inherit;">Dimensi data dalam hal ini mungkin:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam contoh lain, data tulisan tangan dapat memiliki koordinat x dan y untuk posisi pena saat ini, serta informasi tekanan. </font><font style="vertical-align: inherit;">Jadi data dapat direpresentasikan sebagai berikut:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kode berikut membangun contoh sel RNN khusus yang berfungsi dengan input terstruktur tersebut.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tentukan sel pengguna yang mendukung input / output bersarang</font></font></h3><br>
<pre><code class="python hljs">NestedInput = collections.namedtuple(<span class="hljs-string">'NestedInput'</span>, [<span class="hljs-string">'feature1'</span>, <span class="hljs-string">'feature2'</span>])<font></font>
NestedState = collections.namedtuple(<span class="hljs-string">'NestedState'</span>, [<span class="hljs-string">'state1'</span>, <span class="hljs-string">'state2'</span>])<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NestedCell</span>(<span class="hljs-params">tf.keras.layers.Layer</span>):</span><font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, unit_1, unit_2, unit_3, **kwargs</span>):</span><font></font>
    self.unit_1 = unit_1<font></font>
    self.unit_2 = unit_2<font></font>
    self.unit_3 = unit_3<font></font>
    self.state_size = NestedState(state1=unit_1, <font></font>
                                  state2=tf.TensorShape([unit_2, unit_3]))<font></font>
    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))<font></font>
    super(NestedCell, self).__init__(**kwargs)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build</span>(<span class="hljs-params">self, input_shapes</span>):</span>
    <span class="hljs-comment"># #  input_shape  2 , [(batch, i1), (batch, i2, i3)]</span>
    input_1 = input_shapes.feature1[<span class="hljs-number">1</span>]<font></font>
    input_2, input_3 = input_shapes.feature2[<span class="hljs-number">1</span>:]<font></font>
<font></font>
    self.kernel_1 = self.add_weight(<font></font>
        shape=(input_1, self.unit_1), initializer=<span class="hljs-string">'uniform'</span>, name=<span class="hljs-string">'kernel_1'</span>)<font></font>
    self.kernel_2_3 = self.add_weight(<font></font>
        shape=(input_2, input_3, self.unit_2, self.unit_3),<font></font>
        initializer=<span class="hljs-string">'uniform'</span>,<font></font>
        name=<span class="hljs-string">'kernel_2_3'</span>)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span>(<span class="hljs-params">self, inputs, states</span>):</span>
    <span class="hljs-comment">#     [(batch, input_1), (batch, input_2, input_3)]</span>
    <span class="hljs-comment">#     [(batch, unit_1), (batch, unit_2, unit_3)]</span><font></font>
    input_1, input_2 = tf.nest.flatten(inputs)<font></font>
    s1, s2 = states<font></font>
<font></font>
    output_1 = tf.matmul(input_1, self.kernel_1)<font></font>
    output_2_3 = tf.einsum(<span class="hljs-string">'bij,ijkl-&gt;bkl'</span>, input_2, self.kernel_2_3)<font></font>
    state_1 = s1 + output_1<font></font>
    state_2_3 = s2 + output_2_3<font></font>
<font></font>
    output = [output_1, output_2_3]<font></font>
    new_states = NestedState(state1=state_1, state2=state_2_3)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> output, new_states
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bangun Model RNN dengan Nested Input / Output</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mari kita membangun model Keras yang menggunakan layer </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan sel khusus yang baru saja kita tentukan.</font></font><br>
<br>
<pre><code class="python hljs">unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Latih model pada data yang dihasilkan secara acak</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Karena kami tidak memiliki dataset yang baik untuk model ini, kami menggunakan data acak yang dihasilkan oleh perpustakaan Numpy untuk demonstrasi.</font></font><br>
<br>
<pre><code class="python hljs">input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))<font></font>
input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))<font></font>
target_1_data = np.random.random((batch_size * num_batch, unit_1))<font></font>
target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))<font></font>
input_data = [input_1_data, input_2_data]<font></font>
target_data = [target_1_data, target_2_data]<font></font>
<font></font>
model.fit(input_data, target_data, batch_size=batch_size)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dengan sebuah layer, </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anda hanya perlu menentukan logika matematika dari satu langkah dalam urutan, dan layer </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">akan menangani iterasi dari urutan untuk Anda. </font><font style="vertical-align: inherit;">Ini adalah cara yang luar biasa ampuh untuk membuat prototipe RNNs tipe baru dengan cepat (mis. Varian LSTM). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah verifikasi, terjemahan juga akan muncul di Tensorflow.org. </font><font style="vertical-align: inherit;">Jika Anda ingin berpartisipasi dalam menerjemahkan dokumentasi situs web Tensorflow.org ke dalam bahasa Rusia, silakan hubungi secara pribadi atau komentar. </font><font style="vertical-align: inherit;">Segala koreksi dan komentar sangat dihargai.</font></font></i></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id487798/index.html">Bagaimana kami bermigrasi dari Oracle JDK dan Java Web Mulai ke AdoptOpenJDK dan OpenWebStart</a></li>
<li><a href="../id487800/index.html">Mengapa penting untuk memberi tahu pelamar apa yang salah selama wawancara (dan bagaimana melakukannya dengan benar)</a></li>
<li><a href="../id487802/index.html">UPS Cerdas APC yang tidak terputus, dan cara memasaknya</a></li>
<li><a href="../id487804/index.html">Pertemuan Tim Pertumbuhan di Raiffeisenbank</a></li>
<li><a href="../id487806/index.html">Membuat API Deno kecil</a></li>
<li><a href="../id487812/index.html">Pengujian Led Spectrum Led Polandia E27</a></li>
<li><a href="../id487814/index.html">Kecepatan dan keandalan lebih tinggi, dan harganya lebih rendah. Kingston KC2000 Solid State Drive Baru</a></li>
<li><a href="../id487822/index.html">AvitoTech On Tour: Pertemuan Android di Nizhny Novgorod</a></li>
<li><a href="../id487824/index.html">Tinjauan umum lampu LED Spectrum Led GU10 dari Eropa</a></li>
<li><a href="../id487826/index.html">Tinjauan umum lampu LED dari Led Spectrum Polandia E14</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
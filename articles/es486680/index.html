<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïù ‚õÖÔ∏è üåÅ ML, VR y Robots (y un poco de nube) üë®üèª‚Äçüíª üë∞üèº ‚òïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬°Hola a todos! 
 
 Quiero hablar sobre un proyecto muy aburrido en el que la rob√≥tica, el aprendizaje autom√°tico (y juntos, esto es el aprendizaje rob...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>ML, VR y Robots (y un poco de nube)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/486680/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬°Hola a todos! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quiero hablar sobre un proyecto muy aburrido en el que la rob√≥tica, el aprendizaje autom√°tico (y juntos, esto es el aprendizaje rob√≥tico), la realidad virtual y un poco de tecnolog√≠a en la nube se entrecruzaron. </font><font style="vertical-align: inherit;">Y todo esto tiene sentido. </font><font style="vertical-align: inherit;">Despu√©s de todo, es realmente conveniente pasar a un robot, mostrar qu√© hacer y luego entrenar pesos en el servidor ML utilizando los datos almacenados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debajo del corte, diremos c√≥mo funciona ahora, y algunos detalles sobre cada uno de los aspectos que tuvieron que desarrollarse.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/t0/kx/wi/t0kxwiicqakswvomnrwz-iycc2o.jpeg"><br>
<a name="habracut"></a><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para qu√©</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para empezar, vale la pena revelar un poco. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parece que los robots armados con Deep Learning est√°n a punto de expulsar a las personas de sus trabajos en todas partes. </font><font style="vertical-align: inherit;">De hecho, no todo es tan sencillo. </font><font style="vertical-align: inherit;">Cuando las acciones se repiten estrictamente, los procesos ya est√°n realmente bien automatizados. </font><font style="vertical-align: inherit;">Si hablamos de "robots inteligentes", es decir, aplicaciones donde la visi√≥n por computadora y los algoritmos ya son suficientes. </font><font style="vertical-align: inherit;">Pero tambi√©n hay muchas historias extremadamente complicadas. </font><font style="vertical-align: inherit;">Los robots apenas pueden hacer frente a la variedad de objetos con los que tienen que lidiar y a la diversidad del entorno.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Puntos clave</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hay 3 cosas clave en t√©rminos de implementaci√≥n que a√∫n no se encuentran en todas partes: </font></font><br>
<br>
<ul>
<li>       (data-driven learning). ..   ,    ,     ,    . ,     .</li>
<li>   ()    </li>
<li>  -  (Human-machine collaboration) </li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El segundo tambi√©n es importante porque en este momento observaremos un cambio en los enfoques de aprendizaje, algoritmos, detr√°s de ellos y herramientas inform√°ticas. </font><font style="vertical-align: inherit;">Los algoritmos de percepci√≥n y control ser√°n m√°s flexibles. </font><font style="vertical-align: inherit;">Una actualizaci√≥n de robot cuesta dinero. </font><font style="vertical-align: inherit;">Y la calculadora se puede usar de manera m√°s eficiente si servir√° a varios robots a la vez. </font><font style="vertical-align: inherit;">Este concepto se llama "rob√≥tica en la nube". </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Con este √∫ltimo, todo es simple: la inteligencia artificial no est√° lo suficientemente desarrollada en este momento para proporcionar el 100% de confiabilidad y precisi√≥n en todas las situaciones requeridas por las empresas. </font><font style="vertical-align: inherit;">Por lo tanto, el operador supervisor, que a veces puede ayudar a los robots de las salas, no le har√° da√±o.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esquema</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para empezar, sobre una plataforma de software / red que proporciona todas las funciones descritas: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fd/6y/fi/fd6yfi2svby-3l7hkn9lxxt3neo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Componentes:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El robot env√≠a una transmisi√≥n de video 3D al servidor y recibe el control en respuesta. </font></font></li>
<li>    :  - ,      (, , , )</li>
<li>  ML  ( ),        ,   ,  .      ‚Äî  3D   ,     . </li>
<li> -  ,  3D       ,   UI   .   ‚Äî . </li>
</ol><br>
<h4> </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hay 2 modos de funcionamiento del robot: autom√°tico y manual. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En modo manual, el robot funciona si el servicio ML a√∫n no est√° entrenado. </font><font style="vertical-align: inherit;">Luego, el robot pasa de autom√°tico a manual, a pedido del operador (vi comportamientos extra√±os mientras observaba el robot) o cuando los servicios de ML detectan una anomal√≠a. </font><font style="vertical-align: inherit;">Acerca de la detecci√≥n de anomal√≠as ser√° m√°s tarde, esta es una parte muy importante, sin la cual es imposible aplicar el enfoque propuesto. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La evoluci√≥n del control es la siguiente:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La tarea para el robot se forma en t√©rminos legibles por humanos y se describen indicadores de rendimiento.</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El operador se conecta al robot en VR y realiza la tarea dentro del flujo de trabajo existente durante alg√∫n tiempo</font></font><br>
</li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La parte de ML se entrena sobre los datos recibidos</font></font><br>
</li>
<li>      ,     ML             <br>
</li>
<li>              <br>
</li>
</ol><br>
<h4>       3D</h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Muy a menudo, los robots utilizan el entorno ROS (sistema operativo del robot), que de hecho es un marco para administrar "nodos" (nodos), cada uno de los cuales proporciona parte de la funcionalidad del robot. En general, esta es una forma relativamente conveniente de programar robots, que de alguna manera se asemeja a la arquitectura de microservicio de las aplicaciones web en su esencia. La principal ventaja de ROS es el est√°ndar de la industria y ya hay una gran cantidad de m√≥dulos necesarios para crear un robot. Incluso los brazos rob√≥ticos industriales pueden tener un m√≥dulo de interfaz ROS. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lo m√°s simple es crear un modelo de puente entre nuestra parte del servidor y ROS. Por ejemplo, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tal</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ahora nuestro proyecto utiliza una versi√≥n m√°s desarrollada del "nodo" ROS, que inicia sesi√≥n y sondea el microservicio del registro al que el servidor de retransmisi√≥n puede conectarse un robot en particular. El c√≥digo fuente se proporciona solo como un ejemplo de instrucciones para instalar el m√≥dulo ROS. Al principio, cuando dominas este marco (ROS), todo parece bastante hostil, pero la documentaci√≥n es bastante buena, y despu√©s de un par de semanas, los desarrolladores comienzan a usar su funcionalidad con bastante confianza. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Interesante: el problema de la compresi√≥n del flujo de datos 3D, que debe producirse directamente en el robot.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No es tan f√°cil comprimir el mapa de profundidad. </font><font style="vertical-align: inherit;">Incluso con un peque√±o grado de compresi√≥n del flujo RGB, se permite una distorsi√≥n local muy grave del brillo de los p√≠xeles reales en los bordes o cuando se permiten objetos en movimiento. </font><font style="vertical-align: inherit;">El ojo casi no se da cuenta de esto, pero tan pronto como se permiten las mismas distorsiones en el mapa de profundidad, al renderizar en 3D todo se vuelve muy malo: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/kv/1l/6-/kv1l6-qgxaqxhsf1a-zl67hymtk.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(del </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">art√≠culo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estos defectos en los bordes estropean en gran medida la escena 3D, porque </font><font style="vertical-align: inherit;">solo hay mucha basura en el aire.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comenzamos a utilizar la compresi√≥n cuadro por cuadro: JPEG para RGB y PNG para un mapa de profundidad con peque√±os hacks. </font><font style="vertical-align: inherit;">Este m√©todo comprime la transmisi√≥n de 30FPS para una resoluci√≥n de esc√°ner 3D de 640x480 a 25 Mbps. </font><font style="vertical-align: inherit;">Tambi√©n se puede proporcionar una mejor compresi√≥n si el tr√°fico es cr√≠tico para la aplicaci√≥n. </font><font style="vertical-align: inherit;">Hay c√≥decs de flujo 3D comerciales que tambi√©n se pueden usar para comprimir este flujo.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Control de realidad virtual.</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Despu√©s de calibrar el marco de referencia de la c√°mara y el robot (y ya escribimos </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un art√≠culo sobre calibraci√≥n</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), el brazo del robot se puede controlar en realidad virtual. </font><font style="vertical-align: inherit;">El controlador establece tanto la posici√≥n en 3D XYZ como la orientaci√≥n. </font><font style="vertical-align: inherit;">Para algunos roboruk, solo 3 coordenadas ser√°n suficientes, pero con un gran n√∫mero de grados de libertad, la orientaci√≥n de la herramienta especificada por el controlador tambi√©n debe transmitirse. </font><font style="vertical-align: inherit;">Adem√°s, hay suficientes controles en los controladores para ejecutar comandos del robot, como encender / apagar la bomba, controlar la pinza y otros. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inicialmente, se decidi√≥ utilizar el marco de JavaScript para el marco A de realidad virtual, basado en el motor WebVR. </font><font style="vertical-align: inherit;">Y los primeros resultados (demostraci√≥n en video al final del art√≠culo para el brazo de 4 coordenadas) se obtuvieron en el marco A.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De hecho, result√≥ que WebVR (o A-frame) era una soluci√≥n fallida por varias razones:</font></font><br>
<br>
<ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">compatibilidad principalmente con FireFox</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , y fue en FireFox que el marco de marco A no liber√≥ recursos de textura (el resto de los navegadores hicieron frente) hasta que el consumo de memoria alcanz√≥ 16 GB</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">interacci√≥n limitada con controladores de realidad virtual y casco. </font><font style="vertical-align: inherit;">Entonces, por ejemplo, no fue posible agregar marcas adicionales con las que puede establecer la posici√≥n, por ejemplo, de los codos del operador.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La aplicaci√≥n requer√≠a m√∫ltiples subprocesos o varios procesos. </font><font style="vertical-align: inherit;">En un hilo / proceso, fue necesario descomprimir los cuadros de video, en otro - dibujar. </font><font style="vertical-align: inherit;">Como resultado, todo se organiz√≥ a trav√©s de los trabajadores, pero el tiempo de desempaque lleg√≥ a 30 ms, y la renderizaci√≥n en realidad virtual se debe hacer a una frecuencia de 90FPS.</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todas estas deficiencias resultaron en el hecho de que la representaci√≥n del marco no tuvo tiempo en los 10 ms asignados y hubo contracciones muy desagradables en la realidad virtual. Probablemente, todo podr√≠a superarse, pero la identidad de cada navegador era un poco molesta. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora decidimos partir hacia el puerto C #, OpenTK y C # de la biblioteca OpenVR. Todav√≠a hay una alternativa: la unidad. Escriben que Unity es para principiantes ... pero dif√≠cil. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lo m√°s importante que necesitaba ser encontrado y conocido para ganar libertad:</font></font><br>
<br>
<pre><code class="cs hljs">VRTextureBounds_t bounds = <span class="hljs-keyword">new</span> VRTextureBounds_t() { uMin = <span class="hljs-number">0</span>, vMin = <span class="hljs-number">0</span>, uMax = <span class="hljs-number">1f</span>, vMax = <span class="hljs-number">1f</span> }; <font></font>
OpenVR.Compositor.Submit(EVREye.Eye_Left, <span class="hljs-keyword">ref</span> leftTexture, <span class="hljs-keyword">ref</span> bounds, EVRSubmitFlags.Submit_Default);<font></font>
OpenVR.Compositor.Submit(EVREye.Eye_Right, <span class="hljs-keyword">ref</span> rightTexture, <span class="hljs-keyword">ref</span> bounds, EVRSubmitFlags.Submit_Default);
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
(este es el c√≥digo para enviar dos texturas a los ojos izquierdo y derecho del casco), </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
es decir </font><font style="vertical-align: inherit;">dibuje en OpenGL en la textura que ven los diferentes ojos y env√≠elo a las gafas. </font><font style="vertical-align: inherit;">Joy no conoc√≠a l√≠mites cuando result√≥ que llenaba el ojo izquierdo de rojo y el derecho de azul. </font><font style="vertical-align: inherit;">Solo un par de d√≠as y ahora el mapa de profundidad y RGB que viene a trav√©s de webSocket se transfiri√≥ al modelo poligonal en 10 ms en lugar de 30 en JS. </font><font style="vertical-align: inherit;">Y luego simplemente interrogue las coordenadas y los botones de los controladores, ingrese el sistema de eventos para los botones, procese los clics del usuario, ingrese la m√°quina de estado para la interfaz de usuario y ahora puede tomar un vaso del espresso:</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/EuBNaGZctf8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ahora la calidad del Realsense D435 es algo deprimente, pero pasar√° tan pronto como instalemos al menos </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un esc√°ner 3D tan interesante de Microsoft</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , cuya nube de puntos es mucho m√°s precisa.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lado del servidor</font></font></h4><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Servidor de retransmisi√≥n</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
El elemento funcional principal es el retransmisor del servidor (servidor en el medio), que recibe una transmisi√≥n de video del robot con im√°genes en 3D y lecturas del sensor y el estado del robot y lo distribuye entre los consumidores. Datos de entrada: cuadros empaquetados y lecturas de sensores que provienen de TCP / IP. La distribuci√≥n a los consumidores se realiza mediante sockets web (un mecanismo muy conveniente para transmitir a varios consumidores, incluido un navegador). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s, el servidor de almacenamiento provisional almacena el flujo de datos en el almacenamiento en la nube S3 para que luego pueda usarse para la capacitaci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cada servidor de retransmisi√≥n admite la API http, que le permite conocer su estado actual, lo cual es conveniente para monitorear las conexiones actuales.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La tarea de retransmisi√≥n es bastante dif√≠cil, tanto desde el punto de vista de la inform√°tica como desde el punto de vista del tr√°fico. Por lo tanto, aqu√≠ seguimos la l√≥gica de que los servidores de retransmisi√≥n se implementan en una variedad de servidores en la nube. Y eso significa que debe realizar un seguimiento de qui√©n se est√° conectando a d√≥nde (especialmente si los robots y los operadores est√°n en diferentes regiones). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Registrarse</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
El m√°s confiable ahora ser√° dif√≠cil de configurar para cada robot a qu√© servidores se puede conectar (la redundancia no afectar√°). El servicio de gesti√≥n de ML est√° asociado con el robot, sondea el servidor de retransmisi√≥n para determinar a cu√°l est√° conectado el robot y se conecta al correspondiente, si, por supuesto, tiene suficientes derechos para esto. La aplicaci√≥n del operador funciona de manera similar.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lo mas agradable! Debido a que el entrenamiento de robots es un servicio, el servicio solo es visible para nosotros en el interior. Por lo tanto, su interfaz puede ser lo m√°s conveniente posible para nosotros. Aquellos. es una consola en el navegador (hay una biblioteca </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">terminalJS</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que </font><font style="vertical-align: inherit;">es hermosa en su simplicidad </font><font style="vertical-align: inherit;">, que es muy f√°cil de modificar si desea funciones adicionales, como la finalizaci√≥n autom√°tica de TAB o la reproducci√≥n del historial de llamadas) y se ve as√≠: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/wl/vl/yo/wlvlyojuytiepjvhzexlxr-ixcq.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esto, por supuesto, es un tema separado para el debate, por qu√© la l√≠nea de comandos muy c√≥modo. Por cierto, es especialmente conveniente hacer pruebas unitarias de dicha interfaz.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Adem√°s de la API http, este servicio implementa un mecanismo para registrar usuarios con tokens temporales, operadores de inicio / cierre de sesi√≥n, administradores y robots, soporte de sesi√≥n, claves de cifrado de sesi√≥n para el cifrado de tr√°fico entre el servidor de retransmisi√≥n y el robot. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todo esto se hace en Python con Flask, una pila muy cercana para los desarrolladores de ML (es decir, nosotros). </font><font style="vertical-align: inherit;">S√≠, adem√°s, la infraestructura existente de CI / CD para microservicios est√° en t√©rminos amigables con Flask.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problema de retraso</font></font></h4> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si queremos controlar los manipuladores en tiempo real, entonces el retraso m√≠nimo es extremadamente √∫til. </font><font style="vertical-align: inherit;">Si el retraso es demasiado grande (m√°s de 300 ms), entonces es muy dif√≠cil controlar los manipuladores en funci√≥n de la imagen en el casco virtual. </font><font style="vertical-align: inherit;">En nuestra soluci√≥n, debido a la compresi√≥n cuadro por cuadro (es decir, no hay almacenamiento en b√∫fer) y al no usar herramientas est√°ndar como GStreamer, el retraso incluso teniendo en cuenta el servidor intermedio es de aproximadamente 150-200 ms. </font><font style="vertical-align: inherit;">El tiempo de transmisi√≥n a trav√©s de la red es de unos 80 ms. </font><font style="vertical-align: inherit;">El resto del retraso es causado por la c√°mara Realsense D435 y la frecuencia de captura limitada.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por supuesto, este es un problema de altura completa que surge en el modo de "seguimiento", cuando el manipulador en su realidad sigue constantemente al controlador del operador en la realidad virtual. </font><font style="vertical-align: inherit;">En el modo de moverse a un punto dado XYZ, el retraso no causa ning√∫n problema al operador.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parte ML</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hay 2 tipos de servicios: gesti√≥n y formaci√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El servicio de capacitaci√≥n recopila los datos almacenados en el almacenamiento S3 e inicia el reentrenamiento de los pesos del modelo. </font><font style="vertical-align: inherit;">Al final de la capacitaci√≥n, los pesos se env√≠an al servicio de gesti√≥n. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El servicio de gesti√≥n no es diferente en t√©rminos de datos de entrada y salida de la aplicaci√≥n del operador. </font><font style="vertical-align: inherit;">Del mismo modo, el flujo de entrada RGBD (RGB + Profundidad), las lecturas del sensor y el estado del robot, los comandos de control de salida. </font><font style="vertical-align: inherit;">Debido a esta identidad, parece posible capacitarse en el marco del concepto de ‚Äúcapacitaci√≥n basada en datos‚Äù.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El estado del robot (y las lecturas del sensor) es una historia clave para ML. Define el contexto. Por ejemplo, un robot tendr√° una m√°quina de estados que es caracter√≠stica de su funcionamiento, que determina en gran medida qu√© tipo de control es necesario. Estos 2 valores se transmiten junto con cada trama: el modo operativo y el vector de estado del robot. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y un poco sobre el entrenamiento:</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
en la demostraci√≥n al final del art√≠culo fue la tarea de encontrar un objeto (un cubo para ni√±os) en una escena 3D. Esta es una tarea b√°sica para las aplicaciones de pick &amp; place. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El entrenamiento se bas√≥ en un par de marcos "antes y despu√©s" y designaci√≥n de objetivos obtenidos con control manual: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/n6/v2/s3/n6v2s3v59u7eumxhdh3gxucngxq.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debido a la presencia de dos mapas de profundidad, fue f√°cil calcular la m√°scara del objeto movido en el marco: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/6a/vm/k-/6avmk-ue2jfndgwzy08zdb0qtqe.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
adem√°s, se proyectan xyz en el plano de la c√°mara y puede seleccionar la vecindad del objeto capturado:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ha/_s/o-/ha_so-yh4xmxwsp4dkoo42tct9i.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En realidad con este barrio y funcionar√°. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Primero obtenemos XY entrenando a Unet una red convolucional para la segmentaci√≥n de cubos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Luego, necesitamos determinar la profundidad y comprender si la imagen es anormal frente a nosotros. </font><font style="vertical-align: inherit;">Esto se hace usando un codificador autom√°tico en RGB y un codificador autom√°tico condicional en profundidad. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arquitectura del modelo para el codificador autom√°tico de entrenamiento: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xf/q4/ex/xfq4exzon5b63cucrz6aqi8kflm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, la l√≥gica del trabajo:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">buscar un m√°ximo en el "mapa de calor" (determinar las coordenadas angulares u = x / zv = y / z del objeto) que excede el umbral</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">luego el codificador autom√°tico reconstruye la vecindad del punto encontrado para todas las hip√≥tesis en profundidad (con un paso dado de min_depth a max_depth) y selecciona la profundidad a la cual la discrepancia entre la reconstrucci√≥n y la entrada es m√≠nima</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Teniendo las coordenadas angulares u, v y profundidad, puede obtener las coordenadas x, y, z</font></font></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un ejemplo de reconstrucci√≥n de codificador autom√°tico de un mapa de profundidades de cubo con una profundidad correctamente definida: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/av/1t/bu/av1tbu5dyvflda-_-lpbdw0t0qs.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
en parte, la idea de un m√©todo de b√∫squeda de profundidad se basa en un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">art√≠culo sobre conjuntos de codificadores autom√°ticos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este enfoque funciona bien para objetos de varias formas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero, en general, hay muchos enfoques diferentes para encontrar un objeto XYZ a partir de una imagen RGBD. Por supuesto, es necesario en la pr√°ctica y en una gran cantidad de datos elegir el m√©todo m√°s preciso. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tambi√©n estaba la tarea de detectar anomal√≠as, para esto necesitamos una red convolucional de segmentaci√≥n para aprender de las m√°scaras disponibles. Luego, de acuerdo con esta m√°scara, puede evaluar la precisi√≥n de la reconstrucci√≥n del codificador autom√°tico en el mapa de profundidad y RGB. Debido a esta discrepancia, uno puede decidir sobre la presencia de una anomal√≠a.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Debido a este m√©todo, es posible detectar la aparici√≥n de objetos no vistos previamente en el marco, que sin embargo son detectados por el algoritmo de b√∫squeda primario.</font></font><br>
<br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Demostraci√≥n</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La comprobaci√≥n y depuraci√≥n de toda la plataforma de software creada se realiz√≥ en el stand:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C√°mara 3D Realsense D435</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 coordenadas Dobot Magician</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Casco VR HTC Vive</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Servidores en Yandex Cloud (reduce la latencia en comparaci√≥n con la nube de AWS)</font></font></li>
</ul><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/G5rBhaxHL_E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En el video, ense√±amos c√≥mo encontrar un cubo en una escena 3D realizando una tarea en VR pick &amp; place. </font><font style="vertical-align: inherit;">Alrededor de 50 ejemplos fueron suficientes para entrenar en un cubo. </font><font style="vertical-align: inherit;">Luego el objeto cambia y se muestran unos 30 ejemplos m√°s. </font><font style="vertical-align: inherit;">Despu√©s de volver a entrenar, el robot puede encontrar un nuevo objeto. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El proceso completo dur√≥ aproximadamente 15 minutos, de los cuales aproximadamente la mitad del modelo de entrenamiento pes√≥. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y en este video, YuMi controla en realidad virtual. </font><font style="vertical-align: inherit;">Para aprender a manipular objetos, debe evaluar la orientaci√≥n y ubicaci√≥n de la herramienta. </font><font style="vertical-align: inherit;">La matem√°tica se basa en un principio similar, pero ahora se encuentra en la etapa de prueba y desarrollo.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Q0yTey1srBM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusi√≥n</font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Big data y Deep learning no es todo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estamos cambiando el enfoque del aprendizaje, avanzando hacia la forma en que las personas aprenden cosas nuevas, repitiendo lo que ven. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El aparato matem√°tico "bajo el cap√≥", que desarrollaremos en aplicaciones reales, est√° dirigido al problema de la interpretaci√≥n y el control sensibles al contexto. </font><font style="vertical-align: inherit;">El contexto aqu√≠ es informaci√≥n natural disponible de sensores de robot o informaci√≥n externa sobre el proceso actual. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Y, cuanto m√°s procesos tecnol√≥gicos dominemos, m√°s se desarrollar√° la estructura del "cerebro en las nubes", y se entrenar√°n sus partes individuales. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Fortalezas de este enfoque:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la posibilidad de aprender a manipular objetos variables </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aprender en un entorno cambiante (por ejemplo, robots m√≥viles)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tareas mal estructuradas</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">poco tiempo de comercializaci√≥n; </font><font style="vertical-align: inherit;">Puede realizar el objetivo incluso en modo manual utilizando los operadores</font></font><br>
</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Limitaci√≥n:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">necesidad de internet confiable y bueno</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se necesitan m√©todos adicionales para lograr una alta precisi√≥n, por ejemplo, c√°maras en el manipulador mismo</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Actualmente estamos trabajando en aplicar nuestro enfoque a la tarea est√°ndar de selecci√≥n y colocaci√≥n de varios objetos. </font><font style="vertical-align: inherit;">Pero nos parece (¬°naturalmente!) Que √©l es capaz de m√°s. </font><font style="vertical-align: inherit;">¬øAlguna idea de d√≥nde m√°s probar tu mano? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
¬°Gracias por su atenci√≥n!</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es486680/">https://habr.com/ru/post/es486680/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es486670/index.html">Pasaporte electr√≥nico de la Federaci√≥n Rusa, parte 2020 del ballet Marleson</a></li>
<li><a href="../es486672/index.html">OpenVINO Hackathon: Reconociendo la voz y la emoci√≥n en la Raspberry Pi</a></li>
<li><a href="../es486674/index.html">El resumen de materiales frescos del mundo del front-end para la √∫ltima semana No. 400 (27 de enero - 2 de febrero de 2020)</a></li>
<li><a href="../es486676/index.html">Inevitabilidad de la penetraci√≥n de FPGA en centros de datos</a></li>
<li><a href="../es486678/index.html">Cuarzo en ASP.NET Core</a></li>
<li><a href="../es486682/index.html">Docker Compose: Simplifique usando Makefile</a></li>
<li><a href="../es486686/index.html">Acerca de implementar una biblioteca de aprendizaje profundo en Python</a></li>
<li><a href="../es486688/index.html">Node.js, Tor, Titiritero y Cheerio: raspado web an√≥nimo</a></li>
<li><a href="../es486690/index.html">5 consejos para escribir funciones de flecha de calidad</a></li>
<li><a href="../es486692/index.html">Funciones de la consola Chrome que quiz√°s nunca hayas usado</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
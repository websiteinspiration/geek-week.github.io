<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöë ‚ôíÔ∏è ‚ÜòÔ∏è Video calls with virtual background and open source tools ü•£ üè∑Ô∏è ‚§¥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Now that many of us are quarantined due to COVID-19 , video calls have become a much more frequent occurrence than before. In particular, the ZOOM  se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Video calls with virtual background and open source tools</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/498458/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Now that many of us are </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quarantined</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> due to </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">COVID-19</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , video calls have become a much more frequent occurrence than before. In particular, the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ZOOM</font></font></a> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> service </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">suddenly</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> became very popular. Probably the most interesting Zoom feature is support for the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Virtual Background</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . It allows users to interactively replace the background behind them with any image or video.</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><div style="text-align:center;"><img src="https://habrastorage.org/webt/wf/46/1p/wf461pvjwrwmpzvkvnhyvzcf8xy.jpeg"></div></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I have been using Zoom at work for a long time, at open-source meetings on Kubernetes, usually doing this from a corporate laptop. Now, when I‚Äôm working from home, I am inclined to use a more powerful and convenient personal desktop computer to solve some of my open source tasks. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unfortunately, Zoom only supports a background removal method known as ‚Äú </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">chroma key</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äù or ‚Äú </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">green screen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äù. To use this method, it is necessary that the background be represented by some solid color, ideally green, and be uniformly lit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since I do not have a green screen, I decided to simply implement my own background removal system. And this, of course, is much better than putting things in order in the apartment, or the constant use of a work laptop.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As it turned out, using ready-made open source components and writing just a few lines of your own code, you can get very decent results.</font></font><br>
<a name="habracut"></a><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reading camera data</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's start from the beginning and answer the following question: "How to get video from a webcam that we will process?" </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since I use Linux on my home computer (when I‚Äôm not playing games), I decided to use the </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">Open CV </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Python bindings</font></font></a> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that I‚Äôm already familiar with. </font><font style="vertical-align: inherit;">In addition to </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">V4L2</font></a><font style="vertical-align: inherit;"> -bindings for reading data from a webcam, they include useful basic video processing functions. </font><font style="vertical-align: inherit;">
Reading a frame from a webcam in python-opencv is very simple:</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> cv2<font></font>
cap = cv2.VideoCapture(<span class="hljs-string">'/dev/video0'</span>)<font></font>
success, frame = cap.read()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To improve the results when working with my camera, I applied the following settings before capturing video from it:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#    720p @ 60 FPS</span>
height, width = <span class="hljs-number">720</span>, <span class="hljs-number">1280</span><font></font>
cap.set(cv2.CAP_PROP_FRAME_WIDTH ,width)<font></font>
cap.set(cv2.CAP_PROP_FRAME_HEIGHT,height)<font></font>
cap.set(cv2.CAP_PROP_FPS, <span class="hljs-number">60</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It seems like most video conferencing programs limit video to 720p @ 30 FPS, or lower. </font><font style="vertical-align: inherit;">But we, in any case, may not read every frame. </font><font style="vertical-align: inherit;">Such settings set the upper limit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Put the frame capture mechanism in a loop. </font><font style="vertical-align: inherit;">Now we have access to the video stream from the camera!</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;success, frame = cap.read()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can save the frame for test purposes as follows:</font></font><br>
<br>
<pre><code class="python hljs">cv2.imwrite(<span class="hljs-string">"test.jpg"</span>, frame)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After that, we can make sure that the camera is working. </font><font style="vertical-align: inherit;">Great!</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/96c/1ea/155/96c1ea155c714c5f1c8ab70f737444f8.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I hope you are not against my beard</font></font></font></i><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Background detection</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that we have access to the video stream, we‚Äôll think about how to detect the background by making it possible to replace it by finding it. But this is already a rather difficult task. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Although there is a feeling that the creators of Zoom never talk about exactly how the program removes the background, the way the system behaves makes me think about what could have done without neural networks. It's hard to explain, but the results look exactly like that. In addition, I found an article on how </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Microsoft Teams</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> implements </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">background blur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> using a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">convolutional neural network</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In principle, creating your own neural network is not so difficult. There are many articles and scientific papers on </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">image segmentation.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. There are lots of open source libraries and tools. But we need a very specialized dataset to get good results. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In particular, we need a lot of images resembling those obtained from a webcam, with a perfect picture of a person in the foreground. Each pixel of such a picture should be marked as different from the background. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Building such a dataset in preparation for training a neural network may not require much effort. This is due to the fact that the team of researchers from Google has already done all the hardest and put into the open source a pre-trained neural network for segmenting people. This network is called </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">BodyPix</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . It works very well! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
BodyPix is ‚Äã‚Äãnow only available in a form suitable for </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TensorFlow.js</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. As a result, it is easiest to apply using the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">body-pix-node</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> library </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To speed up the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">network output</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (forecast) in the browser, it is preferable to use the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">WebGL</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> backend, but in the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Node.js</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> environment </font><font style="vertical-align: inherit;">you can use the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tensorflow GPU backend</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (note that for this you will need a video card from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NVIDIA</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which I have). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order to simplify the project setup, we will use a small containerized environment that provides the TensorFlow GPU and Node.js. Using it all with </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nvidia-docker</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- much easier than collecting the necessary dependencies on your computer yourself. </font><font style="vertical-align: inherit;">To do this, you only need Docker and the latest graphics drivers on your computer. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here is the contents of the file </font></font><code>bodypix/package.json</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="json hljs">{
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"name"</span>: <span class="hljs-string">"bodypix"</span>,
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"version"</span>: <span class="hljs-string">"0.0.1"</span>,
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"dependencies"</span>: {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"@tensorflow-models/body-pix"</span>: <span class="hljs-string">"^2.0.5"</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">"@tensorflow/tfjs-node-gpu"</span>: <span class="hljs-string">"^1.7.1"</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;}<font></font>
}<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here is the file </font></font><code>bodypix/Dockerfile</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#  ,   TensorFlow GPU</span>
FROM nvcr.io/nvidia/cuda:<span class="hljs-number">10.0</span>-cudnn7-runtime-ubuntu18<span class="hljs-number">.04</span>
<span class="hljs-comment">#  node</span><font></font>
RUN apt update &amp;&amp; apt install -y curl make build-essential \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; curl -sL https://deb.nodesource.com/setup_12.x | bash - \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; apt-get -y install nodejs \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; mkdir /.npm \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&amp;&amp; chmod <span class="hljs-number">777</span> /.npm
<span class="hljs-comment"># ,    &nbsp;</span>
<span class="hljs-comment">#   tfjs-node-gpu      GPU :(</span><font></font>
ENV TF_FORCE_GPU_ALLOW_GROWTH=true<font></font>
<span class="hljs-comment">#  node-</span><font></font>
WORKDIR /src<font></font>
COPY package.json /src/<font></font>
RUN npm install<font></font>
<span class="hljs-comment">#      </span><font></font>
COPY app.js /src/<font></font>
ENTRYPOINT node /src/app.js<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now let's talk about getting results. </font><font style="vertical-align: inherit;">But I warn you right away: I am not a Node.js expert! </font><font style="vertical-align: inherit;">This is just the result of my evening experiments, so be lenient to me :-). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The following simple script is busy processing a binary mask image sent to the server using an HTTP POST request. </font><font style="vertical-align: inherit;">A mask is a two-dimensional array of pixels. </font><font style="vertical-align: inherit;">Pixels represented by zeros are the background. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here is the file code </font></font><code>app.js</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="javascript hljs"><span class="hljs-keyword">const</span> tf = <span class="hljs-built_in">require</span>(<span class="hljs-string">'@tensorflow/tfjs-node-gpu'</span>);
<span class="hljs-keyword">const</span> bodyPix = <span class="hljs-built_in">require</span>(<span class="hljs-string">'@tensorflow-models/body-pix'</span>);
<span class="hljs-keyword">const</span> http = <span class="hljs-built_in">require</span>(<span class="hljs-string">'http'</span>);
<span class="hljs-function">(<span class="hljs-params"><span class="hljs-keyword">async</span> (</span>) =&gt;</span> {
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">const</span> net = <span class="hljs-keyword">await</span> bodyPix.load({
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">architecture</span>: <span class="hljs-string">'MobileNetV1'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">outputStride</span>: <span class="hljs-number">16</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">multiplier</span>: <span class="hljs-number">0.75</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">quantBytes</span>: <span class="hljs-number">2</span>,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">const</span> server = http.createServer();<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;server.on(<span class="hljs-string">'request'</span>, <span class="hljs-keyword">async</span> (req, res) =&gt; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">var</span> chunks = [];<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;req.on(<span class="hljs-string">'data'</span>, (chunk) =&gt; {<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;chunks.push(chunk);<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;req.on(<span class="hljs-string">'end'</span>, <span class="hljs-keyword">async</span> () =&gt; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">const</span> image = tf.node.decodeImage(Buffer.concat(chunks));<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;segmentation = <span class="hljs-keyword">await</span> net.segmentPerson(image, {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">flipHorizontal</span>: <span class="hljs-literal">false</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">internalResolution</span>: <span class="hljs-string">'medium'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-attr">segmentationThreshold</span>: <span class="hljs-number">0.7</span>,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.writeHead(<span class="hljs-number">200</span>, { <span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/octet-stream'</span> });<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.write(Buffer.from(segmentation.data));<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.end();<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tf.dispose(image);<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;});<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;server.listen(<span class="hljs-number">9000</span>);<font></font>
})();<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To convert a frame to a mask, we, in a Python script, can use the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">numpy</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">requests</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> packages </font><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_mask</span>(<span class="hljs-params">frame, bodypix_url=<span class="hljs-string">'http://localhost:9000'</span></span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;_, data = cv2.imencode(<span class="hljs-string">".jpg"</span>, frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;r = requests.post(<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;url=bodypix_url,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data=data.tobytes(),<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;headers={<span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/octet-stream'</span>})
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     numpy-</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     uint8[width * height]   0  1</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = np.frombuffer(r.content, dtype=np.uint8)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = mask.reshape((frame.shape[<span class="hljs-number">0</span>], frame.shape[<span class="hljs-number">1</span>]))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The result is approximately the following.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e51/7db/e3c/e517dbe3ce6eee99d646a8e4257a627f.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mask</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
While I was doing all this, I came across the</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> next</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tweet.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5a5/c4b/4dd/5a5c4b4dda480f0fa58807ec5b89b457.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is definitely the best background for video calls.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Now that we have a mask to separate the foreground from the background, replacing the background with something else will be very simple. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I took the background image from the tweet branch and cut it so that I get a 16x9 picture.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/900/311/537/900311537df81d74a682ddfd447a85a5.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Background image</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
After that I did the following:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#    (     16:9)</span>
replacement_bg_raw = cv2.imread(<span class="hljs-string">"background.jpg"</span>)<font></font>
<font></font>
<span class="hljs-comment">#    ,       (width &amp; height   )</span>
width, height = <span class="hljs-number">720</span>, <span class="hljs-number">1280</span><font></font>
replacement_bg = cv2.resize(replacement_bg_raw, (width, height))<font></font>
<font></font>
<span class="hljs-comment">#     ,   </span>
inv_mask = <span class="hljs-number">1</span>-mask
<span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> range(frame.shape[<span class="hljs-number">2</span>]):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame[:,:,c] = frame[:,:,c]*mask + replacement_bg[:,:,c]*inv_mask<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
That's what I got after that.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/500/fbf/e3b/500fbfe3ba3753878562533ced87ed69.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The result of replacing the background.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Such a mask is obviously not accurate enough, the reason for this is the performance trade-offs that we made when setting up BodyPix. </font><font style="vertical-align: inherit;">In general, while everything looks more or less tolerant. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But, when I looked at this background, one idea came to me.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Interesting experiments</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that we‚Äôve figured out how to mask, we‚Äôll ask how to improve the result. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first obvious step is to soften the edges of the mask. </font><font style="vertical-align: inherit;">For example, this can be done like this:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post_process_mask</span>(<span class="hljs-params">mask</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.dilate(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.erode(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This will improve the situation a bit, but there isn‚Äôt much progress. </font><font style="vertical-align: inherit;">And a simple replacement is quite boring. </font><font style="vertical-align: inherit;">But, since we got to all this ourselves, this means that we can do anything with the picture, and not just remove the background. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Given that we are using a virtual background from Star Wars, I decided to create a hologram effect in order to make the picture more interesting. </font><font style="vertical-align: inherit;">This, in addition, allows you to smooth out the blur of the mask. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, update the post-processing code:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post_process_mask</span>(<span class="hljs-params">mask</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.dilate(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.blur(mask.astype(float), (<span class="hljs-number">30</span>,<span class="hljs-number">30</span>))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The edges are now blurry. </font><font style="vertical-align: inherit;">This is good, but we still need to create a hologram effect. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hollywood holograms usually have the following properties:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A pale color or monochrome picture - as if drawn by a bright laser.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">An effect reminiscent of scan lines or something like a grid - as if the image is displayed in several rays.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúGhost effect‚Äù - as if the projection is performed in layers or as if the correct distance at which it should be displayed were not maintained during the creation of the projection.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All these effects can be implemented step by step. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, to color the image in a shade of blue, we can use the method </font></font><code>applyColorMap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#     -  </span><font></font>
holo = cv2.applyColorMap(frame, cv2.COLORMAP_WINTER)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next - add a sweep line with an effect reminiscent of leaving in halftone:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#    bandLength    10-30%,</span>
<span class="hljs-comment">#    bandGap.</span>
bandLength, bandGap = <span class="hljs-number">2</span>, <span class="hljs-number">3</span>
<span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(holo.shape[<span class="hljs-number">0</span>]):
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> y % (bandLength+bandGap) &lt; bandLength:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;holo[y,:,:] = holo[y,:,:] * np.random.uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, we implement the ‚Äúghost effect‚Äù by adding shifted weighted copies of the current effect to the image:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># shift_img : https://stackoverflow.com/a/53140617</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shift_img</span>(<span class="hljs-params">img, dx, dy</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dy, axis=<span class="hljs-number">0</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dx, axis=<span class="hljs-number">1</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dy&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:dy, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dy&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[dy:, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dx&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, :dx] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dx&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, dx:] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> img<font></font>
<font></font>
<span class="hljs-comment">#    : holo * 0.2 + shifted_holo * 0.8 + 0</span>
holo2 = cv2.addWeighted(holo, <span class="hljs-number">0.2</span>, shift_img(holo1.copy(), <span class="hljs-number">5</span>, <span class="hljs-number">5</span>), <span class="hljs-number">0.8</span>, <span class="hljs-number">0</span>)<font></font>
holo2 = cv2.addWeighted(holo2, <span class="hljs-number">0.4</span>, shift_img(holo1.copy(), <span class="hljs-number">-5</span>, <span class="hljs-number">-5</span>), <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And finally, we want to keep some of the original colors, so we combine the holographic effect with the original frame, doing something like adding a ‚Äúghost effect‚Äù:</font></font><br>
<br>
<pre><code class="python hljs">holo_done = cv2.addWeighted(img, <span class="hljs-number">0.5</span>, holo2, <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here's what a frame with a hologram effect looks like:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8ba/bda/21c/8babda21c3f11e9fa3867faf65e14c24.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A frame with a hologram effect</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
This frame itself looks pretty good. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now let's try to combine it with the background.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/297/7b7/ce4/2977b7ce4f9efdedd6632ffb0a3ad621.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Image overlaid on the background.</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Done! </font><font style="vertical-align: inherit;">(I promise - this kind of video will look more interesting).</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video output</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And now I must say that we have missed something here. </font><font style="vertical-align: inherit;">The fact is that we still cannot use all of these for making video calls. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order to fix this, we will use </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pyfakewebcam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v4l2loopback</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to create a dummy webcam. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, we plan to attach this camera to the Docker. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, create a </font></font><code>fakecam/requirements.txt</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dependency description </font><font style="vertical-align: inherit;">file </font><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">numpy==<span class="hljs-number">1.18</span><span class="hljs-number">.2</span>
opencv-python==<span class="hljs-number">4.2</span><span class="hljs-number">.0</span><span class="hljs-number">.32</span>
requests==<span class="hljs-number">2.23</span><span class="hljs-number">.0</span>
pyfakewebcam==<span class="hljs-number">0.1</span><span class="hljs-number">.0</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now create a file </font></font><code>fakecam/Dockerfile</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">for the application that implements the capabilities of a dummy camera:</font></font><br>
<br>
<pre><code class="python hljs">FROM python:<span class="hljs-number">3</span>-buster
<span class="hljs-comment">#   pip</span><font></font>
RUN pip install --upgrade pip<font></font>
<span class="hljs-comment">#   opencv</span><font></font>
RUN apt-get update &amp;&amp; \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;apt-get install -y \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`<span class="hljs-comment"># opencv requirements` \</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;libsm6 libxext6 libxrender-dev \<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`<span class="hljs-comment"># opencv video opening requirements` \</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;libv4l-dev<font></font>
<span class="hljs-comment">#    requirements.txt</span><font></font>
WORKDIR /src<font></font>
COPY requirements.txt /src/<font></font>
RUN pip install --no-cache-dir -r /src/requirements.txt<font></font>
<span class="hljs-comment">#   </span><font></font>
COPY background.jpg /data/<font></font>
<span class="hljs-comment">#     (     )</span><font></font>
COPY fake.py /src/<font></font>
ENTRYPOINT python -u fake.py<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now, from the command line, install v4l2loopback:</font></font><br>
<br>
<pre><code class="bash hljs">sudo apt install v4l2loopback-dkms
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Set up a dummy camera:</font></font><br>
<br>
<pre><code class="python hljs">sudo modprobe -r v4l2loopback<font></font>
sudo modprobe v4l2loopback devices=<span class="hljs-number">1</span> video_nr=<span class="hljs-number">20</span> card_label=<span class="hljs-string">"v4l2loopback"</span> exclusive_caps=<span class="hljs-number">1</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To ensure the functionality of some applications (Chrome, Zoom), we need a setting </font></font><code>exclusive_caps</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">The mark </font></font><code>card_label</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">is set only to ensure the convenience of choosing a camera in applications. </font><font style="vertical-align: inherit;">Indication of the number </font></font><code>video_nr=20</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">leads to the creation of the device </font></font><code>/dev/video20</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">if the corresponding number is not busy, and it is unlikely to be busy. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now we‚Äôll make changes to the script to create a dummy camera:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment"># ,  ,   ,   ,  width  height</span>
fake = pyfakewebcam.FakeWebcam(<span class="hljs-string">'/dev/video20'</span>, width, height)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It should be noted that pyfakewebcam expects images with RGB channels (Red, Green, Blue - red, green, blue), and Open CV works with the order of BGR channels (Blue, Green, Red). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can fix this before outputting the frame, and then send the frame like this:</font></font><br>
<br>
<pre><code class="python hljs">frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<font></font>
fake.schedule_frame(frame)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here is the full script code </font></font><code>fakecam/fake.py</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> pyfakewebcam<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_mask</span>(<span class="hljs-params">frame, bodypix_url=<span class="hljs-string">'http://localhost:9000'</span></span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;_, data = cv2.imencode(<span class="hljs-string">".jpg"</span>, frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;r = requests.post(<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;url=bodypix_url,<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data=data.tobytes(),<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;headers={<span class="hljs-string">'Content-Type'</span>: <span class="hljs-string">'application/octet-stream'</span>})<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = np.frombuffer(r.content, dtype=np.uint8)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = mask.reshape((frame.shape[<span class="hljs-number">0</span>], frame.shape[<span class="hljs-number">1</span>]))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post_process_mask</span>(<span class="hljs-params">mask</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.dilate(mask, np.ones((<span class="hljs-number">10</span>,<span class="hljs-number">10</span>), np.uint8) , iterations=<span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = cv2.blur(mask.astype(float), (<span class="hljs-number">30</span>,<span class="hljs-number">30</span>))
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> mask<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shift_image</span>(<span class="hljs-params">img, dx, dy</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dy, axis=<span class="hljs-number">0</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;img = np.roll(img, dx, axis=<span class="hljs-number">1</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dy&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:dy, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dy&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[dy:, :] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> dx&gt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, :dx] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">elif</span> dx&lt;<span class="hljs-number">0</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img[:, dx:] = <span class="hljs-number">0</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> img<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hologram_effect</span>(<span class="hljs-params">img</span>):</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#    </span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;holo = cv2.applyColorMap(img, cv2.COLORMAP_WINTER)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#   </span>
&nbsp;&nbsp;&nbsp;&nbsp;bandLength, bandGap = <span class="hljs-number">2</span>, <span class="hljs-number">3</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(holo.shape[<span class="hljs-number">0</span>]):
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">if</span> y % (bandLength+bandGap) &lt; bandLength:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;holo[y,:,:] = holo[y,:,:] * np.random.uniform(<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#  </span>
&nbsp;&nbsp;&nbsp;&nbsp;holo_blur = cv2.addWeighted(holo, <span class="hljs-number">0.2</span>, shift_image(holo.copy(), <span class="hljs-number">5</span>, <span class="hljs-number">5</span>), <span class="hljs-number">0.8</span>, <span class="hljs-number">0</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;holo_blur = cv2.addWeighted(holo_blur, <span class="hljs-number">0.4</span>, shift_image(holo.copy(), <span class="hljs-number">-5</span>, <span class="hljs-number">-5</span>), <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     </span>
&nbsp;&nbsp;&nbsp;&nbsp;out = cv2.addWeighted(img, <span class="hljs-number">0.5</span>, holo_blur, <span class="hljs-number">0.6</span>, <span class="hljs-number">0</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> out<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_frame</span>(<span class="hljs-params">cap, background_scaled</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;_, frame = cap.read()<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#      (  ,   )</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#       </span>
&nbsp;&nbsp;&nbsp;&nbsp;mask = <span class="hljs-literal">None</span>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">while</span> mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">try</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mask = get_mask(frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">except</span> requests.RequestException:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<span class="hljs-string">"mask request failed, retrying"</span>)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment"># -   </span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;mask = post_process_mask(mask)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame = hologram_effect(frame)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#     </span>
&nbsp;&nbsp;&nbsp;&nbsp;inv_mask = <span class="hljs-number">1</span>-mask
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> range(frame.shape[<span class="hljs-number">2</span>]):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;frame[:,:,c] = frame[:,:,c]*mask + background_scaled[:,:,c]*inv_mask<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> frame<font></font>
<font></font>
<span class="hljs-comment">#     </span>
cap = cv2.VideoCapture(<span class="hljs-string">'/dev/video0'</span>)<font></font>
height, width = <span class="hljs-number">720</span>, <span class="hljs-number">1280</span><font></font>
cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)<font></font>
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)<font></font>
cap.set(cv2.CAP_PROP_FPS, <span class="hljs-number">60</span>)<font></font>
<font></font>
<span class="hljs-comment">#   </span>
fake = pyfakewebcam.FakeWebcam(<span class="hljs-string">'/dev/video20'</span>, width, height)<font></font>
<font></font>
<span class="hljs-comment">#    </span>
background = cv2.imread(<span class="hljs-string">"/data/background.jpg"</span>)<font></font>
background_scaled = cv2.resize(background, (width, height))<font></font>
<font></font>
<span class="hljs-comment">#    </span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame = get_frame(cap, background_scaled)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-comment">#    RGB-</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;fake.schedule_frame(frame)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now collect the images:</font></font><br>
<br>
<pre><code class="python hljs">docker build -t bodypix ./bodypix<font></font>
docker build -t fakecam ./fakecam<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Run them:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span><font></font>
docker network create --driver bridge fakecam<font></font>
<span class="hljs-comment">#   bodypix</span><font></font>
docker run -d \<font></font>
&nbsp;&nbsp;--name=bodypix \<font></font>
&nbsp;&nbsp;--network=fakecam \<font></font>
&nbsp;&nbsp;--gpus=all --shm-size=<span class="hljs-number">1</span>g --ulimit memlock=<span class="hljs-number">-1</span> --ulimit stack=<span class="hljs-number">67108864</span> \<font></font>
&nbsp;&nbsp;bodypix<font></font>
<span class="hljs-comment">#  ,  ,      ,  ,</span>
<span class="hljs-comment">#           </span>
<span class="hljs-comment"># ,     `sudo groupadd $USER video`</span><font></font>
docker run -d \<font></font>
&nbsp;&nbsp;--name=fakecam \<font></font>
&nbsp;&nbsp;--network=fakecam \<font></font>
&nbsp;&nbsp;-p <span class="hljs-number">8080</span>:<span class="hljs-number">8080</span> \<font></font>
&nbsp;&nbsp;-u <span class="hljs-string">"$$(id -u):$$(getent group video | cut -d: -f3)"</span> \<font></font>
&nbsp;&nbsp;$$(find /dev -name <span class="hljs-string">'video*'</span> -printf <span class="hljs-string">"--device %p "</span>) \<font></font>
&nbsp;&nbsp;fakecam<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It remains only to consider that this must be started before the camera is opened when working with any applications. </font><font style="vertical-align: inherit;">And in Zoom or somewhere else you need to select a camera </font></font><code>v4l2loopback</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">/ </font></font><code>/dev/video20</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Summary</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here is a clip that demonstrates the results of my work.</font></font><br>
<br>
<div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Your browser does not support HTML5 video.</font></font><source src="https://elder.dev/posts/open-source-virtual-background/holo-demo.webm" type="video/webm"></video></div></div></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Background change result</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
See! </font><font style="vertical-align: inherit;">I‚Äôm calling from the Millennium Falcon using the open source technology stack for working with the camera! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What I did, I really liked. </font><font style="vertical-align: inherit;">And I will definitely take advantage of all this at the next video conference. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dear readers! </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Are you planning to change what is visible during video calls behind you for something else?</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><img src="https://habrastorage.org/webt/iq/fi/b4/iqfib45pgphfrxv--zfemt0qnmw.jpeg"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en498446/index.html">Job Questions: Imaginary Stability, False Devotion and Positioning</a></li>
<li><a href="../en498450/index.html">MultiSim redundancy - what it is and how it works</a></li>
<li><a href="../en498452/index.html">Django: A Quick Guide to Internationalization</a></li>
<li><a href="../en498454/index.html">Tales of the developers of your favorite games about what they are proud of</a></li>
<li><a href="../en498456/index.html">CSS Scroll Snapping Practice</a></li>
<li><a href="../en498462/index.html">Infinite scroll with banners, or How to do with three views</a></li>
<li><a href="../en498466/index.html">How lasers and sensors help keep judges nervous</a></li>
<li><a href="../en498472/index.html">Single Page Application Docker Image</a></li>
<li><a href="../en498476/index.html">Accessibility How to make the application accessible to users with disabilities</a></li>
<li><a href="../en498478/index.html">What is Windows PowerShell and what does it eat? Part 5: Access to external objects</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
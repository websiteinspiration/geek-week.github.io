<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì© „ÄΩÔ∏è üíÖüèª Catastrophic Cloud: How It Works üç™ ‚úàÔ∏è üëû</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, Habr! 
 
 After the New Year holidays, we restarted a disaster-resistant cloud based on two sites. Today we‚Äôll tell you how it works and show w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Catastrophic Cloud: How It Works</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/486186/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hello, Habr! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After the New Year holidays, we restarted a disaster-resistant cloud based on two sites. </font><font style="vertical-align: inherit;">Today we‚Äôll tell you how it works and show what happens to client virtual machines when individual cluster elements fail and the whole site falls (spoiler - everything is fine with them). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/no/xs/p9/noxsp98upzfesoanpuhefetyilq.jpeg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Disaster-proof cloud storage at the OST site.</font></font></i><a name="habracut"></a><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What is inside</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Under the hood of the cluster are Cisco UCS servers with VMware ESXi hypervisor, two INFINIDAT InfiniBox F2240 storage systems, Cisco Nexus network equipment, as well as Brocade SAN switches. </font><font style="vertical-align: inherit;">The cluster is spaced into two sites - OST and NORD, i.e., in each data center an identical set of equipment. </font><font style="vertical-align: inherit;">Actually, this makes it catastrophic. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Within one platform, the main elements are also duplicated (hosts, SAN switches, network card). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Two sites are connected by dedicated fiber optic paths, also reserved. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A few words about storage. </font><font style="vertical-align: inherit;">The first disaster-resistant cloud we built on NetApp. </font><font style="vertical-align: inherit;">INFINIDAT was chosen here, and here's why:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Active-Active replication option. </font><font style="vertical-align: inherit;">It allows the virtual machine to remain operational even if one of the storage systems completely fails. </font><font style="vertical-align: inherit;">I‚Äôll tell you more about replication later.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Three disk controllers for increased system resiliency. </font><font style="vertical-align: inherit;">Usually there are two.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ready solution. </font><font style="vertical-align: inherit;">An already assembled rack came to us, which only needs to be connected to the network and configured.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Attentive technical support. </font><font style="vertical-align: inherit;">INFINIDAT engineers constantly analyze logs and events of storage systems, install new versions in the firmware, and help with configuration.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Here are some photos from unpacking:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ro/r1/9i/ror19i6ohplap3nzivyq9dxqaog.png"><br>
<br>
<img src="https://habrastorage.org/webt/rg/zm/of/rgzmofi67yaghzz7fziewaka3fw.jpeg"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">How does it work</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The cloud is already resilient within itself. It protects the client from single hardware and software failures. Catastrophic will help protect against mass failures within the same site: for example, failure of the storage system (or SDS cluster, which happens often :)), mass errors in the storage network and more. Well and most importantly: such a cloud saves when an entire site becomes inaccessible due to fire, blackout, raider capture, </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">alien landings.</font></font></s><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
In all of these cases, client virtual machines continue to run, and here's why.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The cluster scheme is designed so that any ESXi host with client virtual machines can access either of two storage systems. If the storage on the OST site fails, then the virtual machines will continue to work: the hosts on which they work will access the storage on NORD for data. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vu/pq/0u/vupq0uycl3yelwrujymst8jqpke.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is how the connection diagram in the cluster looks.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
This is possible due to the fact that an Inter-Switch Link is configured between the SAN factories of the two sites: the Fabric A OST SAN switch is connected to the Fabric A NORD SAN switch, similarly to Fabric B SAN switches.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Well, so that all these intricacies of SAN factories make sense, Active-Active replication is configured between the two storage systems: information is written almost simultaneously to the local and remote storage systems, RPO = 0. It turns out that on one SHD the original data is stored, on the other - their replica. Data is replicated at the storage volume level, and VM data (its disks, configuration file, swap file, etc.) is already stored on them. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The ESXi host sees the primary volume and its replica as a single storage device. There are 24 paths from the ESXi host to each disk device:</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
12 paths associate it with the local storage (optimal paths), and the remaining 12 - with the remote (not optimal paths). In a normal situation, ESXi accesses data on the local storage using ‚Äúoptimal‚Äù paths. If this storage system fails, ESXi loses its optimal paths and switches to ‚Äúnon-optimal‚Äù ones. Here's how it looks in the diagram. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tl/zu/rp/tlzurpwt1mspwdpbjeb53ydas4i.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The scheme of a disaster-resistant cluster.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
All client networks are established on both sites through a common network factory. Provider Edge (PE) runs on each site, on which client networks are terminated. PEs are combined into a single cluster. If PE fails on one site, all traffic is redirected to the second site. Thanks to this, virtual machines from the site without PE remain available over the network for the client.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let us now see what will happen to the client virtual machines in case of various failures. </font><font style="vertical-align: inherit;">Let's start with the lightest options and end with the most serious - the failure of the entire site. </font><font style="vertical-align: inherit;">In the examples, the main site will be OST, and the backup, with data replicas, will be NORD.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What happens to a client virtual machine if ... </font></font></h3><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Replication Link Fails.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The replication between the storage systems of the two sites stops. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ESXi will only work with local disk devices (along the optimal paths). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Virtual machines continue to work. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xd/1u/rs/xd1urscyrw5ldefaecvzg2sxsbg.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There is a gap ISL (Inter-Switch Link).</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The case is unlikely. Unless some mad excavator digs up several optical routes at once, which pass through independent routes and are brought to the sites through different inputs. But anyway. In this case, ESXi hosts lose half of their paths and can only access their local storage. Replicas are collected, but hosts will not be able to access them. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Virtual machines work normally. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/eh/pg/p2/ehpgp21qksqs333elaz_px8hohs.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Refuses a SAN switch on one of the sites.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ESXi hosts lose some of their storage paths. In this case, the hosts on the site where the switch failed will work only through their own HBA. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the same time, virtual machines continue to work normally. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vz/_1/0w/vz_10wdyjuu3yp9flx0-kyiog9w.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">All SAN switches on one of the sites fail.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Let's say such a disaster happened at the OST site. In this case, ESXi hosts on this site will lose all paths to their disk devices. The standard VMware vSphere HA mechanism comes into play: it will restart all the OST platform virtual machines in NORD after a maximum of 140 seconds. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Virtual machines running on the hosts of the NORD site work normally. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/yg/le/w8/yglew89bonr-aubz9dw85jxbnb0.gif"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Refuses ESXi host on one site.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here the vSphere HA mechanism works again: virtual machines from a failed host are restarted on other hosts - on the same or remote site. The restart time of the virtual machine is up to 1 minute. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If all ESXi hosts of the OST platform fail, there are no options: VMs restart on another. The restart time is the same. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ij/ri/no/ijrino56s-akqtzivujr3en3ejy.gif"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Refuses storage on the same site.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Let's say the storage system refused at the OST site. Then the OST ESXi hosts switch to work with storage replicas in NORD. After the failed storage system returns to the system, forced replication occurs, the OST ESXi hosts will again start contacting the local storage system. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Virtual machines have been working all this time. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ng/gk/vy/nggkvy-lk3dbjs-zfop2racir3u.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fails one of the sites.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this case, all virtual machines will restart on the backup site through the vSphere HA mechanism. VM restart time - 140 seconds. In this case, all network settings of the virtual machine will be saved, and it remains available to the client over the network. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To restart the machines on the backup site without problems, each site is only half full. The second half is the reserve in case all virtual machines are moved from the second, injured site. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/oa/hg/hr/oahghrsypij8je-zwym7trlj0-g.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A disaster-proof cloud based on two data centers protects against such failures.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This pleasure is not cheap, because, in addition to the main resources, you need a reserve on the second site. </font><font style="vertical-align: inherit;">Therefore, they place business-critical services in such a cloud, the long downtime of which incurs large financial and reputational losses, or if disaster tolerance requirements are imposed on the information system from the regulators or internal regulations of the company. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sources:</font></font></b><br>
<br>
<ol>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">www.infinidat.com/sites/default/files/resource-pdfs/DS-INFBOX-190331-US_0.pdf</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">support.infinidat.com/hc/en-us/articles/207057109-InfiniBox-best-practices-guides</font></font></a></li>
</ol></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en486174/index.html">I have zero turnover</a></li>
<li><a href="../en486176/index.html">Corporate Email Correspondence Memo</a></li>
<li><a href="../en486178/index.html">FOSS News No. 1 - review of free and open source news for January 27 - February 2, 2020</a></li>
<li><a href="../en486180/index.html">Tips and sources for creating serverless applications</a></li>
<li><a href="../en486184/index.html">How to use search effectively</a></li>
<li><a href="../en486188/index.html">Introducing PostgreSQL wal-g backup system</a></li>
<li><a href="../en486190/index.html">Our experience in developing a CSI driver in Kubernetes for Yandex.Cloud</a></li>
<li><a href="../en486192/index.html">Cyber ‚Äã‚Äãfraudsters hack mobile operators to get to phone numbers of subscribers</a></li>
<li><a href="../en486194/index.html">About backups in Proxmox VE</a></li>
<li><a href="../en486198/index.html">Talking is hard. Essays on Communicating with Non-Programmers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔹 👩🏽‍🍳 💑 Web Audio API-Konzepte 🤦🏻 👇🏼 🌦️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Tag, Freunde! 
 
 In diesem Artikel werden einige Konzepte aus der Musiktheorie erläutert, mit denen die Web Audio API (WAA) arbeitet. Wenn Sie ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Web Audio API-Konzepte</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/495690/"><img src="https://habrastorage.org/webt/_r/j3/qd/_rj3qdi2rvk5vwbvfskmddp8yic.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Guten Tag, Freunde! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Artikel werden einige Konzepte aus der Musiktheorie erläutert, mit denen die Web Audio API (WAA) arbeitet. </font><font style="vertical-align: inherit;">Wenn Sie diese Konzepte kennen, können Sie fundierte Entscheidungen treffen, wenn Sie Audio in einer Anwendung entwerfen. </font><font style="vertical-align: inherit;">Dieser Artikel macht Sie nicht zu einem erfahrenen Toningenieur, aber er hilft Ihnen zu verstehen, warum WAA so funktioniert, wie es funktioniert.</font></font><br>
<a name="habracut"></a><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audio-Schaltung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Essenz von WAA besteht darin, einige Operationen mit Ton in einem Audiokontext auszuführen. Diese API wurde speziell für das modulare Routing entwickelt. Die Grundoperationen mit Sound sind Audioknoten, die miteinander verbunden sind und ein Routing-Diagramm (Audio-Routing-Diagramm) bilden. Mehrere Quellen - mit unterschiedlichen Kanaltypen - werden in einem einzigen Kontext verarbeitet. Dieser modulare Aufbau bietet die notwendige Flexibilität, um komplexe Funktionen mit dynamischen Effekten zu erstellen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Audioknoten sind über Ein- und Ausgänge miteinander verbunden, bilden eine Kette, die von einer oder mehreren Quellen ausgeht, durch einen oder mehrere Knoten verläuft und am Ziel endet. </font><font style="vertical-align: inherit;">Grundsätzlich können Sie beispielsweise auf ein Ziel verzichten, wenn Sie nur einige Audiodaten visualisieren möchten. </font><font style="vertical-align: inherit;">Ein typischer Web-Audio-Workflow sieht ungefähr so ​​aus:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie einen Audiokontext</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie im Kontext Quellen wie &lt;audio&gt;, einen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oszillator (Soundgenerator)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder einen Stream</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie </font><font style="vertical-align: inherit;">Effektknoten </font><font style="vertical-align: inherit;">wie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hall</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Biquad-Filter, Panner oder Kompressor</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wählen Sie ein Ziel für Audio aus, z. B. Lautsprecher auf dem Computer eines Benutzers</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stellen Sie durch Effekte eine Verbindung zwischen Quellen zu einem Ziel her</font></font></li>
</ol><br>
<img src="https://habrastorage.org/webt/76/wq/vv/76wqvvwgifik6zojizkg_dxxb9q.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kanalbezeichnung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Anzahl der verfügbaren Audiokanäle wird häufig in numerischem Format angegeben, z. B. 2.0 oder 5.1. </font><font style="vertical-align: inherit;">Dies wird als Kanalbezeichnung bezeichnet. </font><font style="vertical-align: inherit;">Die erste Ziffer gibt den gesamten Frequenzbereich an, den das Signal enthält. </font><font style="vertical-align: inherit;">Die zweite Ziffer gibt die Anzahl der Kanäle an, die für die Niederfrequenzeffektausgänge - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Subwoofer</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - reserviert sind </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Eingang oder Ausgang besteht aus einem oder mehreren Kanälen, die gemäß einer bestimmten Audio-Schaltung aufgebaut sind. </font><font style="vertical-align: inherit;">Es gibt verschiedene diskrete Kanalstrukturen wie Mono, Stereo, Quad, 5.1 usw. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7z/rn/xy/7zrnxy_vaeyntkb3o5hgvbvs_k4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Audioquellen können auf viele Arten erhalten werden. </font><font style="vertical-align: inherit;">Der Ton kann sein:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wird von JavaScript über einen Audioknoten (z. B. einen Oszillator) generiert.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellt aus Rohdaten mit </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PCM (Pulse Code Modulation)</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abgeleitet von HTML-Medienelementen (wie &lt;video&gt; oder &lt;audio&gt;)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abgeleitet von einem WebRTC-Medienstrom (z. B. einer Webcam oder einem Mikrofon)</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audiodaten: Was ist im </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beispiel</font></font></a></h3><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abtasten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bedeutet, ein kontinuierliches Signal in ein diskretes (geteiltes) (analoges zu digitales) Signal umzuwandeln. </font><font style="vertical-align: inherit;">Mit anderen Worten, eine kontinuierliche Schallwelle, wie beispielsweise ein Live-Konzert, wird in eine Folge von Samples umgewandelt, die es dem Computer ermöglichen, das Audio in separaten Blöcken zu verarbeiten.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audiopuffer: Frames, Samples und Kanäle</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AudioBuffer akzeptiert die Anzahl der Kanäle als Parameter (1 für Mono, 2 für Stereo usw.), die Länge - die Anzahl der Sample-Frames im Puffer und die Sampling-Frequenz - die Anzahl der Frames pro Sekunde. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Beispiel ist ein einfacher 32-Bit-Gleitkommawert (float32), der der Wert des Audiostreams zu einem bestimmten Zeitpunkt und in einem bestimmten Kanal (links oder rechts usw.) ist. Ein Sample-Frame oder Frame ist eine Reihe von Werten aller Kanäle, die zu einem bestimmten Zeitpunkt wiedergegeben werden: Alle Abtastwerte aller gleichzeitig wiedergegebenen Kanäle (zwei für Stereo, sechs für 5.1 usw.). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Abtastrate ist die Anzahl der Abtastwerte (oder Frames, da alle Samples in einem Frame gleichzeitig abgespielt werden), die in einer Sekunde wiedergegeben und in Hertz (Hz) gemessen werden. Je höher die Frequenz, desto besser die Klangqualität.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schauen wir uns Mono- und Stereopuffer an, die jeweils eine Sekunde lang sind und mit einer Frequenz von 44100 Hz reproduziert werden:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Monopuffer hat 44100 Samples und 44100 Frames. </font><font style="vertical-align: inherit;">Der Wert der Eigenschaft "length" beträgt 44100</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Stereopuffer enthält 88.200 Samples, aber auch 44.100 Frames. </font><font style="vertical-align: inherit;">Der Wert der Eigenschaft "length" ist 44100 - die Länge entspricht der Anzahl der Frames</font></font></li>
</ul><br>
<img src="https://habrastorage.org/webt/uq/hp/pq/uqhppqfp_yz_k_hk_axza9j7qgm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn die Wiedergabe des Puffers beginnt, hören wir zuerst das Bild ganz links des Samples, dann das nächste Bild rechts usw. Bei Stereo hören wir beide Kanäle gleichzeitig. Sample-Frames sind unabhängig von der Anzahl der Kanäle und bieten die Möglichkeit einer sehr genauen Audioverarbeitung. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hinweis: Um die Zeit in Sekunden aus der Anzahl der Frames zu ermitteln, muss die Anzahl der Frames durch die Abtastrate dividiert werden. Teilen Sie letztere durch die Anzahl der Kanäle, um die Anzahl der Frames aus der Anzahl der Samples zu ermitteln. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beispiel:</font></font><br>
<br>
<pre><code class="javascript hljs"><span class="hljs-keyword">let</span> context = <span class="hljs-keyword">new</span> AudioContext()
<span class="hljs-keyword">let</span> buffer = context.createBuffer(<span class="hljs-number">2</span>, <span class="hljs-number">22050</span>, <span class="hljs-number">44100</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hinweis: Bei digitalem Audio sind 44100 Hz oder 44,1 kHz die Standardabtastfrequenz. Aber warum 44,1 kHz? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Erstens, weil der Bereich der hörbaren Frequenzen (vom menschlichen Ohr unterscheidbare Frequenzen) zwischen 20 und 20.000 Hz variiert. Nach dem Satz von Kotelnikov sollte die Abtastfrequenz die höchste Frequenz im Signalspektrum mehr als verdoppeln. Daher sollte die Abtastfrequenz größer als 40 kHz sein. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zweitens müssen die Signale mit einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tiefpassfilter gefiltert werden.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andernfalls kommt es zu einer Überlappung der spektralen „Schwänze“ (Frequenzwechsel, Frequenzmaskierung, Aliasing), und die Form des rekonstruierten Signals wird verzerrt. Idealerweise sollte ein Tiefpassfilter Frequenzen unter 20 kHz (ohne Dämpfung) durchlassen und Frequenzen über 20 kHz fallen lassen. In der Praxis ist ein gewisses Übergangsband (zwischen dem Durchlassband und dem Unterdrückungsband) erforderlich, in dem die Frequenzen teilweise gedämpft sind. Eine einfachere und wirtschaftlichere Möglichkeit hierfür ist die Verwendung eines Änderungsfilters. Bei einer Abtastfrequenz von 44,1 kHz beträgt das Übergangsband 2,05 kHz. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im obigen Beispiel erhalten wir einen Stereopuffer mit zwei Kanälen, der in einem Audiokontext mit einer Frequenz von 44100 Hz (Standard) und einer Länge von 0,5 Sekunden (22050 Bilder / 44100 Hz = 0,5 s) wiedergegeben wird.</font></font><br>
<br>
<pre><code class="javascript hljs"><span class="hljs-keyword">let</span> context = <span class="hljs-keyword">new</span> AudioContext()
<span class="hljs-keyword">let</span> buffer = context.createBuffer(<span class="hljs-number">1</span>, <span class="hljs-number">22050</span>, <span class="hljs-number">22050</span>)
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Fall erhalten wir einen Monopuffer mit einem Kanal, der in einem Audiokontext mit einer Frequenz von 44100 Hz wiedergegeben wird. Er wird auf 44100 Hz überabtastet (und die Frames auf 44100 erhöht) und 1 Sekunde lang (44100 Frames / 44100 Hz = 1 s). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hinweis: Das Audio-Resampling („Resampling“) ist dem Ändern der Größe („Resizing“) von Bildern sehr ähnlich. </font><font style="vertical-align: inherit;">Angenommen, wir haben ein 16x16-Bild, möchten diesen Bereich jedoch mit einer Größe von 32x32 füllen. </font><font style="vertical-align: inherit;">Wir ändern die Größe. </font><font style="vertical-align: inherit;">Das Ergebnis ist von geringerer Qualität (je nach Zoom-Algorithmus kann es verschwommen oder zerrissen sein), aber es funktioniert. </font><font style="vertical-align: inherit;">Resampled Audio ist dasselbe: Wir sparen Platz, aber in der Praxis ist es unwahrscheinlich, dass eine hohe Klangqualität erzielt wird.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Planare und gestreifte Puffer</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
WAA verwendet ein planares Pufferformat. </font><font style="vertical-align: inherit;">Der linke und der rechte Kanal interagieren wie folgt:</font></font><br>
<br>
<pre><code class="javascript hljs">LLLLLLLLLLLLLLLLRRRRRRRRRRRRRRRR ( ,   <span class="hljs-number">16</span> )
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Fall arbeitet jeder Kanal unabhängig von den anderen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Alternative ist die Verwendung eines alternativen Formats:</font></font><br>
<br>
<pre><code class="javascript hljs">LRLRLRLRLRLRLRLRLRLRLRLRLRLRLRLR ( ,   <span class="hljs-number">16</span> )
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dieses Format wird häufig für die MP3-Decodierung verwendet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
WAA verwendet nur das planare Format, da es für die Tonverarbeitung besser geeignet ist. </font><font style="vertical-align: inherit;">Das planare Format wird alternierend konvertiert, wenn Daten zur Wiedergabe an die Soundkarte gesendet werden. </font><font style="vertical-align: inherit;">Beim Decodieren von MP3s wird das Inverse konvertiert.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Audiokanäle</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Verschiedene Puffer enthalten eine unterschiedliche Anzahl von Kanälen: von einfachem Mono (ein Kanal) und Stereo (linker und rechter Kanal) bis zu komplexeren Sets wie Quad und 5.1 mit einer unterschiedlichen Anzahl von Samples in jedem Kanal, die einen satteren (satteren) Klang liefern. </font><font style="vertical-align: inherit;">Kanäle werden normalerweise durch Abkürzungen dargestellt:</font></font><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mono</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: M: Mono</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stereo</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: L: links </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1: R: rechts</font></font><br>
 </td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quadro</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: L: links </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1: R: rechts </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3: SL: zusätzlich links (linker Kanal schafft die Umgebung; Surround links) </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4: SR: zusätzlich rechts (Surround rechts)</font></font><br>
 </td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5.1</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0: L: links </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1: R: rechts </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2: C: Mitte </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3: LFE: Subwoofer </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
4: SL: extra links </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
5: SR: extra rechts</font></font><br>
 </td>
</tr>
</tbody></table></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aufmischen und Abmischen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn die Anzahl der Kanäle am Ein- und Ausgang nicht übereinstimmt, mischen Sie nach oben oder unten. </font><font style="vertical-align: inherit;">Das Mischen wird durch die AudioNode.channelInterpretation-Eigenschaft gesteuert:</font></font><br>
<div class="scrollable-table"><table>
<thead>
<tr>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eingangskanäle</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ausgangskanäle</font></font></th>
<th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mischregeln</font></font></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="3"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Standard-Kanalmischungsschemata - werden verwendet, wenn die Eigenschaft channelInterpretation für Lautsprecher (Lautsprecher) festgelegt ist.</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 (Mono)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 (Stereo)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mischen Sie von Mono zu Stereo. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Eingangskanal M wird für beide Ausgangskanäle (L und R) verwendet. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.L = input.M </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.R = input.M</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 (Mono)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 (Quad)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mischen Sie von Mono zu Quad. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Eingangskanal M wird für die Hauptkanäle (L und R) verwendet. </font><font style="vertical-align: inherit;">Zusätzliche Kanäle werden gedämpft. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.L = input.M </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.R = input.M </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.SL = 0 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
output.SR = 0</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 (Mono)</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6 (5.1)</font></font></td>
<td>     5.1.<br>
       ©.   (L, R, LFE, SL  SR) .<br>
output.L = 0<br>
output.R = 0<br>
output.C = input.M<br>
output.LFE = 0<br>
output.SL = 0<br>
output.SR = 0</td>
</tr>
<tr>
<td>2 ()</td>
<td>1 ()</td>
<td>     .<br>
   (L  R)     (M).<br>
output.M = 0.5 * (input.L + input.R)</td>
</tr>
<tr>
<td>2 ()</td>
<td>4 ()</td>
<td>     .<br>
  L  R      (L  R).   (SL  SR) .<br>
output.L = input.L<br>
output.R = input.R<br>
output.SL = 0<br>
output.SR = 0</td>
</tr>
<tr>
<td>2 ()</td>
<td>6 (5.1)</td>
<td>     5.1.<br>
  L  R      (L  R).    (SL  SR),   ©   (LFE) .<br>
output.L = input.L<br>
output.R = input.R<br>
output.C = 0<br>
output.LFE = 0<br>
output.SL = 0<br>
output.SR = 0</td>
</tr>
<tr>
<td>4 ()</td>
<td>1 ()</td>
<td>     .<br>
    (L, R, SL  SR)      (M).<br>
output.M = 0.25 * (input.L + input.R + input.SL + input.SR)</td>
</tr>
<tr>
<td>4 ()</td>
<td>2 ()</td>
<td>     .<br>
    (L  SL)       (L).   (R  SR) —   ®.<br>
output.L = 0.5 * (input.L + input.SL)<br>
output.R = 0.5 * (input.R + input.SR)</td>
</tr>
<tr>
<td>4 ()</td>
<td>6 (5.1)</td>
<td>     5.1.<br>
  L, R, SL  SR     .    ©   (LFE) .<br>
output.L = input.L<br>
output.R = input.R<br>
output.C = 0<br>
output.LFE = 0<br>
output.SL = input.SL<br>
output.SR = input.SR</td>
</tr>
<tr>
<td>6 (5.1)</td>
<td>1 ()</td>
<td>   5.1  .<br>
 (L  SL),  (R  SR)   ()     .   ,     ,       —      √2 / 2.  (LFE) .<br>
output.M = 0.7071 * (input.L + input.R) + input.C + 0.5 * (input.SL + input.SR)</td>
</tr>
<tr>
<td>6 (5.1)</td>
<td>2 ()</td>
<td>   5.1  .<br>
  ©       (SL  SR)         (L  R).             √2 / 2.  (LFE) .<br>
output.L = input.L + 0.7071 * (input.C + input.SL)<br>
output.R = input.R + 0.7071 * (input.C + input.SR)</td>
</tr>
<tr>
<td>6 (5.1)</td>
<td>4 ()</td>
<td>   5.1  .<br>
  ()      (L  R).           √2 / 2.     .  (LFE) .<br>
output.L = input.L + 0.7071 * input.C<br>
output.R = input.R + 0.7071 * input.C<br>
output.SL = input.SL<br>
output.SR = input.SR</td>
</tr>
<tr>
<td colspan="3">    — ,   channelInterpretation   discrete.</td>
</tr>
<tr>
<td> (x)</td>
<td> (y),  x&lt;y</td>
<td>  .<br>
        (   ). ,     , .</td>
</tr>
<tr>
<td> (x)</td>
<td> (y),  x&gt;y</td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jeder Ausgangskanal wird mit seinem analogen Eingang (mit demselben Index) kombiniert. </font><font style="vertical-align: inherit;">Kanäle ohne entsprechende Ausgangskanäle werden verworfen.</font></font></td>
</tr>
</tbody>
</table></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualisierung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Visualisierung basiert auf dem Empfang von Audioausgabedaten, z. B. Daten zur Amplitude oder Frequenz, und deren anschließender Verarbeitung mithilfe einer beliebigen Grafiktechnologie. </font><font style="vertical-align: inherit;">WAA verfügt über einen AnalyzerNode, der das durchgelassene Signal nicht verzerrt. </font><font style="vertical-align: inherit;">Gleichzeitig können Daten aus Audio extrahiert und weiter übertragen werden, z. B. an &amp; ltcanvas&gt;. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w3/03/tk/w303tkjj1p7imhxsaegp0vtabyu.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die folgenden Methoden können zum Extrahieren von Daten verwendet werden:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AnalyzerNode.getFloatByteFrequencyData () - kopiert die aktuellen Frequenzdaten in das Float32Array</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AnalyzerNode.getByteFrequencyData () - kopiert die aktuellen Frequenzdaten in ein Uint8Array (vorzeichenloses Byte-Array)</font></font></li>
<li>AnalyserNode.getFloatTimeDomainData() —            Float32Array</li>
<li>AnalyserNode.getByteTimeDomainData() —            Uint8Array</li>
</ul><br>
<h3></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit der Audio-Räumlichkeit (verarbeitet von PannerNode und AudioListener) können Sie die Position und Richtung des Signals an einem bestimmten Punkt im Raum sowie die Position des Hörers simulieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Position des Panners wird mit rechtshändigen kartesischen Koordinaten beschrieben. </font><font style="vertical-align: inherit;">Für die Bewegung wird der Geschwindigkeitsvektor verwendet, der zur Erzeugung </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">des Doppler-Effekts</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> erforderlich </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">ist</font></a><font style="vertical-align: inherit;"> . Für die Richtung wird der Richtungskegel verwendet. </font><font style="vertical-align: inherit;">Dieser Kegel kann bei multidirektionalen Schallquellen sehr groß sein. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rl/mj/tz/rlmjtz9l-3elsukt6gdnd81xbe4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Position des Hörers wird wie folgt beschrieben: Bewegung - unter Verwendung des Geschwindigkeitsvektors, der Richtung, in der sich der Kopf des Hörers befindet - unter Verwendung von zwei Richtungsvektoren, vorne und oben. </font><font style="vertical-align: inherit;">Das Einrasten erfolgt an der Oberseite des Kopfes und der Nase des Hörers im rechten Winkel.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/7q/-w/hk/7q-whktcaasufh9jfy8z6cigrbc.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kreuzung und Verzweigung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Verbindung beschreibt einen Prozess, bei dem ein ChannelMergerNode mehrere Eingangs-Monoquellen empfängt und diese zu einem einzigen mehrkanaligen Ausgangssignal kombiniert. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/vk/bv/qh/vkbvqhpvhnghgf55bx9umic_yhc.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Verzweigung ist der umgekehrte Prozess (implementiert über ChannelSplitterNode). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/6d/9c/y7/6d9cy7_hiinrgqscxxdsbe3x-zy.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Beispiel für die Arbeit mit WAA finden Sie </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Der Quellcode für das Beispiel ist </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ein Artikel darüber, wie alles funktioniert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vielen Dank für Ihre Aufmerksamkeit.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de495678/index.html">Wettbewerb VK Sup. Track ML. 4. Platz. Wie?</a></li>
<li><a href="../de495682/index.html">API Reverse für seine Android-Anwendung</a></li>
<li><a href="../de495684/index.html">5 Gründe, warum die Interaktion mit Ihren Endbenutzern Ihren Code verbessert</a></li>
<li><a href="../de495686/index.html">Persönliches Las Vegas oder ein Spiel in der Browser-Erweiterung</a></li>
<li><a href="../de495688/index.html">Active Directory-basierte OSE-Benutzersynchronisierung für Zimbra Collaboration</a></li>
<li><a href="../de495692/index.html">DIY und Open Source helfen Ärzten</a></li>
<li><a href="../de495694/index.html">Referenzdienst für mobile Anwendungen</a></li>
<li><a href="../de495696/index.html">Wie Prince of Persia Creator die Speicherbeschränkungen von Apple II überwindet</a></li>
<li><a href="../de495698/index.html">Client-Server-Architektur in Bildern</a></li>
<li><a href="../de495700/index.html">Doom Boy ESP32</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="pt">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>☝🏿 🥖 🛌🏾 Deepfakes e deep media: um novo campo de batalha para segurança 🕥 🥈 🤾🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este artigo faz parte de uma edição especial do VB. Leia a série completa aqui: IA e segurança .
 
 O número de diphakes - mídia que tira uma foto, áu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Deepfakes e deep media: um novo campo de batalha para segurança</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/501068/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/je/nd/hrjendr1wj5jz4hjefypyqo2gqy.jpeg"></div></a><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este artigo faz parte de uma edição especial do VB. Leia a série completa aqui: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IA e segurança</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
O número de diphakes - mídia que tira uma foto, áudio ou vídeo existente e substitui a personalidade da pessoa por outra pessoa usando IA - está crescendo rapidamente. Isso é preocupante, não apenas porque essas falsificações podem ser usadas para influenciar a opinião das pessoas durante as eleições ou para envolver alguém em crimes, mas também porque elas já foram abusadas para criar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pornografia falsa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">enganar o diretor de uma empresa de energia britânica</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Antecipando esse tipo de nova realidade, a união de instituições acadêmicas, empresas de tecnologia e organizações sem fins lucrativos está desenvolvendo maneiras de identificar mídias enganosas geradas pela IA. </font><font style="vertical-align: inherit;">O trabalho deles mostra que as ferramentas de detecção são apenas uma solução viável a curto prazo, enquanto a corrida armamentista diftêmica está apenas começando.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Texto difuso</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anteriormente, a melhor prosa criada pela IA era mais como textos do jogo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mad Libs do</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que o romance “Bunches of Wrath”, mas os modelos de linguagem modernos agora podem escrever textos que são próximos em apresentação e persuasão aos escritos por uma pessoa. </font><font style="vertical-align: inherit;">Por exemplo, o modelo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GPT-2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , lançado pela empresa de pesquisa OpenAI de São Francisco, cria fragmentos no estilo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de artigos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou scripts </font><font style="vertical-align: inherit;">no estilo </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">da New Yorker</font></a><font style="vertical-align: inherit;"> para Brainstorming </font><font style="vertical-align: inherit;">em questão de segundos </font><font style="vertical-align: inherit;">. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pesquisadores</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O Centro de Terrorismo, Extremismo e Contra-Terrorismo do Instituto Middlebury sugeriu que o GPT-2 e outros modelos semelhantes pudessem ser criados para defender a superioridade da raça branca, o islamismo jihadista e outras ideologias ameaçadoras - e isso levanta ainda mais preocupações.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/px/lx/fqpxlxj7iafxgiyvtrlle1pd254.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acima: Frontend GPT-2, um modelo de linguagem treinado da empresa de pesquisa OpenAI. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imagem cortesia de: OpenAI</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Em busca de um sistema capaz de detectar conteúdo sintético, pesquisadores da Escola de Ciência e Engenharia de Computadores Paul G. Allen da Universidade de Washington e do Instituto de Inteligência Artificial desenvolveram o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Grover</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , um algoritmo que eles afirmam poder selecionar 92% dos difagos no teste um conjunto composto de dados abertos do Common Crawl Corpus. A equipe explica seu sucesso com uma abordagem de direitos autorais, que, segundo eles, ajudou a entender os recursos da linguagem criada pela IA. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma equipe de cientistas do Harvard e do MIT-IBM Watson AI Lab lançou separadamente </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Giant Language Model Test Room</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, um ambiente da web que tenta determinar se o texto foi escrito usando um modelo de IA. </font><font style="vertical-align: inherit;">Dado o contexto semântico, ela prediz quais palavras têm maior probabilidade de aparecer em uma frase, essencialmente escrevendo seu próprio texto. </font><font style="vertical-align: inherit;">Se as palavras da amostra sendo testada corresponderem a 10, 100 ou 1000 palavras mais prováveis, o indicador ficará verde, amarelo ou vermelho, respectivamente. </font><font style="vertical-align: inherit;">Na verdade, ela usa seu próprio texto previsível como orientação para identificar conteúdo gerado artificialmente.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vídeos Dipfake</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A IA moderna, gerando vídeo, é tão perigosa e tem os mesmos, se não ótimos, recursos que sua contrapartida natural. Um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artigo acadêmico</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> publicado pela startup de Hong Kong SenseTime, Universidade de Tecnologia Nanyang e Instituto de Automação da Academia Chinesa de Ciências detalha a estrutura que edita imagens usando áudio para sintetizar vídeo realista. E pesquisadores da Hyperconnect em Seul desenvolveram recentemente a ferramenta </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MarioNETte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que pode manipular as características faciais de uma figura histórica, político ou CEO, sintetizando um rosto animado pelos movimentos de outra pessoa.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No entanto, mesmo os dipfakes mais realistas contêm artefatos que os emitem. “Os difusores criados por sistemas generativos estudam um conjunto de imagens reais em um vídeo, ao qual você adiciona novas imagens e depois gera um novo vídeo com novas imagens”, diz Ishay Rosenberg, chefe do grupo de treinamento profundo da empresa de cibersegurança Deep Instinct. “O vídeo resultante é um pouco diferente como resultado de alterações na distribuição de dados gerados artificialmente e na distribuição de dados no vídeo original. Esses chamados "vislumbres na matriz" são o que os detectores diftênicos são capazes de distinguir ".</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/jg/ba/nn/jgbanndfcnaymr8ggieay3n5vko.gif"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acima: dois vídeos falsos criados usando as técnicas mais avançadas. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imagem cortesia de: SenseTime</font></font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
No verão passado, uma equipe da Universidade da Califórnia em Berkeley e da Universidade do Sul da Califórnia preparou um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para procurar por "unidades de ação facial" exatas - dados sobre movimentos faciais, carrapatos e expressões, inclusive ao levantar o lábio superior e virar a cabeça quando as pessoas franzir a testa - para identificar vídeos falsos com uma precisão de mais de 90%. Da mesma forma, em agosto de 2018, os participantes do Programa Forense de Mídia da Agência de Projetos de Pesquisa Avançada de Defesa dos EUA (DARPA) testaram </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sistemas</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">capaz de detectar vídeos gerados por IA com base em sinais como piscadas não naturais, movimentos estranhos da cabeça, cor incomum dos olhos e muito mais. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Atualmente, várias startups estão comercializando ferramentas semelhantes para detectar imagens de vídeo falsas. O laboratório de Amsterdã, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deeptrace Labs,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oferece um conjunto de ferramentas de monitoramento destinadas a classificar dipfakes que são carregados em redes sociais, plataformas de hospedagem de vídeo e redes de desinformação. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dessa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> propôs métodos para melhorar os detectores falsos treinados em aparelhos de vídeo falsos. E em julho de 2018, a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Truepic levantou US $ 8 milhões.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">financiar seu serviço para a detecção profunda de falhas em vídeos e fotos. Em dezembro de 2018, a empresa adquiriu a startup Fourandsix, cujo detector de imagens falsificadas recebeu uma licença DARPA.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/ys/o-/y6/yso-y6hqoqnnhtvgrmvwm4pmiio.png"></div><br>
<font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acima: Imagens Dipfake editadas pela AI.</font></font><br>
</font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Além de desenvolver sistemas totalmente treinados, várias empresas publicaram um corpo de texto na esperança de que a comunidade de pesquisadores desenvolva novos métodos para detectar falsificações. Para acelerar esse processo, o Facebook, juntamente com o Amazon Web Services (AWS), o Partnership on AI e acadêmicos de várias universidades, lideraram o Deepfake Detection Challenge. O programa possui um conjunto de amostras de vídeo com rótulos indicando que alguns deles foram afetados pela inteligência artificial. Em setembro de 2019, o Google lançou uma </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">coleção de falsificações visuais</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">como parte do teste FaceForensics, criado pela Universidade Técnica de Munique e pela Universidade de Nápoles Federico II. </font><font style="vertical-align: inherit;">E, mais recentemente, pesquisadores do SenseTime, juntamente com a Universidade de Tecnologia Nanyang em Cingapura, desenvolveram o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DeeperForensics-1.0</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , um conjunto de dados para detectar falsificações que eles afirmam ser o maior do gênero.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dipfake Audio</font></font></h2><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A IA e o aprendizado de máquina</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> não são apenas adequados para sintetizar vídeo e texto, mas também podem copiar vozes. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inúmeros </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">estudos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> demonstraram que apenas um pequeno conjunto de dados é necessário para recriar o discurso de uma pessoa. Sistemas comerciais como o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Resemble</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e o Lyrebird requerem alguns minutos de gravações de áudio, enquanto modelos sofisticados, como a mais recente implementação do Baidu Deep Voice, só podem copiar a voz de uma amostra de 3,7 segundos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Não existem muitas ferramentas para detectar diques de áudio, mas as soluções estão começando a aparecer.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DWK_iYBl8cA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Há alguns meses, a equipe do Resemble lançou uma ferramenta de código aberto chamada Resemblyzer, que usa IA e aprendizado de máquina para detectar dipfakes, adquirindo amostras de voz de alto nível e prevendo se são reais ou simuladas. Depois de receber um arquivo de áudio com fala, ele cria uma representação matemática resumindo as características da voz gravada. Isso permite que os desenvolvedores comparem a semelhança dos dois votos ou descubram quem está falando no momento.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em janeiro de 2019, como parte da Google News Initiative, o Google lançou um corpus de fala contendo "milhares" de frases faladas usando modelos de conversão de texto em fala. </font><font style="vertical-align: inherit;">Foram retiradas amostras de artigos em inglês lidos por 68 diferentes vozes sintéticas em diferentes dialetos. </font><font style="vertical-align: inherit;">O caso está disponível para todos os participantes do </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ASVspoof 2019</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , um concurso cujo objetivo é promover contramedidas contra fala falsa.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Muito a perder</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nenhum dos detectores alcançou precisão perfeita, e os pesquisadores ainda não descobriram como identificar autoria falsa. Deep Instinct Rosenberg espera que isso inspire maus atores a espalhar falsificações. "Mesmo que um dipfake criado por um invasor seja detectado, apenas o dipfake corre o risco de ser divulgado", disse ele. "Para um ator, o risco de ser pego é mínimo, portanto há poucas restrições contra a criação de falsificações." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A teoria de Rosenberg é apoiada </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">por um relatório do Deeptrace</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que encontrou </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">14.698</font></a><font style="vertical-align: inherit;"> vídeos falsos online durante sua contagem mais recente em junho e julho de 2019. Durante um período de sete meses, seu número aumentou 84%. A grande maioria (96%) é de vídeos pornográficos com mulheres.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dado esses números, Rosenberg argumenta que as empresas que “perdem muito” devido aos difamadores devem desenvolver e implementar tecnologia de detecção profunda em seus produtos, o que, na sua opinião, é semelhante aos programas antivírus. E nesta área apareceram mudanças; </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Facebook anunciou no início de janeiro</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> que usaria uma combinação de sistemas automatizados e manuais para detectar conteúdo falso, e o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Twitter sugeriu recentemente a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sinalização de diphakes e a exclusão dos que poderiam ser prejudiciais.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obviamente, as tecnologias subjacentes à geração de dipfakes são apenas ferramentas e têm grande potencial para boas ações. Michael Klozer, chefe da Data &amp; Trust na Access Partnership, uma empresa de consultoria, disse que a tecnologia já está sendo usada para melhorar o diagnóstico médico e a detecção de câncer, preencher lacunas no mapeamento do universo e aprimorar o treinamento de veículos não tripulados. Portanto, ele alerta contra o uso de campanhas gerais para bloquear a IA generativa. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Desde que os líderes começaram a aplicar as normas legais existentes em casos diplomáticos, é muito importante agora não se livrar de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tecnologias valiosas</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">livrar-se de falsificações ”, disse Klozer. </font><font style="vertical-align: inherit;">"Em última análise, a jurisprudência e as normas sociais relativas ao uso dessa nova tecnologia não estão maduras o suficiente para criar linhas vermelhas brilhantes que delineiam o uso e abuso justos".</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt501056/index.html">Por que, quando e como usar multithreading e multiprocessing em Python</a></li>
<li><a href="../pt501058/index.html">A solução de início rápido do Teamcenter ajuda os fabricantes de equipamentos industriais a reduzir o tempo de projeto em 25%</a></li>
<li><a href="../pt501060/index.html">JetBrains .NET Days Online, 13 a 14 de maio</a></li>
<li><a href="../pt501062/index.html">Todos os relatórios da parte on-line gratuita do PHP Russia com falantes estrangeiros podem ser vistos na tradução</a></li>
<li><a href="../pt501064/index.html">Para o voo do navio experimental chinês. Infográficos e colagens.</a></li>
<li><a href="../pt501076/index.html">Mês removido. Resumimos e compartilhamos hacks de vida dos líderes dos grupos de trabalho dos Jet Infosystems</a></li>
<li><a href="../pt501084/index.html">Serviços observáveis ​​em Angular</a></li>
<li><a href="../pt501086/index.html">Summ3r do h4ck 2020. Tutorial de verão sobre segurança digital</a></li>
<li><a href="../pt501088/index.html">Especifique-o. Relatório Yandex</a></li>
<li><a href="../pt501090/index.html">Viagem multicluster K8S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
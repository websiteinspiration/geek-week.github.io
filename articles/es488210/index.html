<!doctype html>
<html class="no-js" lang="es">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòû üëú üë©‚Äç‚öñÔ∏è Reconocer objetos en Android usando TensorFlow: desde la preparaci√≥n de datos hasta el lanzamiento en el dispositivo üà≥ ü§öüèº üìú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La capacitaci√≥n de redes neuronales en el reconocimiento de patrones es un proceso largo y que requiere muchos recursos. Especialmente cuando solo hay...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Reconocer objetos en Android usando TensorFlow: desde la preparaci√≥n de datos hasta el lanzamiento en el dispositivo</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/488210/"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La capacitaci√≥n de redes neuronales en el reconocimiento de patrones es un proceso largo y que requiere muchos recursos. </font><font style="vertical-align: inherit;">Especialmente cuando solo hay una computadora port√°til econ√≥mica, y no una computadora con una tarjeta gr√°fica potente. </font><font style="vertical-align: inherit;">En este caso, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Colaboratory</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vendr√° al </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">rescate</font></a><font style="vertical-align: inherit;"> , que ofrece usar la GPU de nivel Tesla K80 totalmente gratis ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m√°s</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este art√≠culo describe el proceso de preparaci√≥n de datos, la capacitaci√≥n del modelo de flujo de tensor en Google Colaboratory y su lanzamiento en un dispositivo Android.</font></font></p><br>
<h2 id="podgotovka-dannyh"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparaci√≥n de datos</font></font></h2><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como ejemplo, intentemos entrenar una red neuronal para reconocer los dados blancos sobre un fondo negro. </font><font style="vertical-align: inherit;">En consecuencia, para empezar, debe crear un conjunto de datos suficiente para el entrenamiento (por ahora, deteng√°monos en ~ 100 fotos).</font></font></p><br>
<p><img src="https://habrastorage.org/webt/q1/a9/7z/q1a97zueu96rei1w4tx2bxmlpzg.png"></p><a name="habracut"></a><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para la capacitaci√≥n, utilizaremos la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">API de detecci√≥n de objetos de Tensorflow</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Prepararemos todos los datos necesarios para la capacitaci√≥n en una computadora port√°til. </font><font style="vertical-align: inherit;">Necesitamos un entorno </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conda</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y </font><strong><font style="vertical-align: inherit;">un administrador de gesti√≥n de</font></strong><font style="vertical-align: inherit;"> dependencias </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Instrucciones de instalaci√≥n </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">aqu√≠</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creemos un entorno para el trabajo:</font></font></p><br>
<pre><code class="bash hljs">conda create -n object_detection_prepare pip python=3.6</code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y activarlo:</font></font></p><br>
<pre><code class="bash hljs">conda activate object_detection_prepare</code></pre><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Establezca las dependencias que necesitamos:</font></font></p><br>
<pre><code class="bash hljs">pip install --ignore-installed --upgrade tensorflow==1.14<font></font>
pip install --ignore-installed pandas<font></font>
pip install --ignore-installed Pillow<font></font>
pip install lxml<font></font>
conda install pyqt=5</code></pre><br>
<p>  <strong>object_detection</strong>,        <strong>object_detection/images</strong>.</p><br>
<blockquote> Google Colab     ,        ,         <strong>"tcmalloc: large alloc...."</strong>.</blockquote><p>  <strong>object_detection/preprocessing</strong>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> .</p><br>
<p>     : </p><br>
<pre><code class="bash hljs">python ./object_detection/preprocessing/image_resize.py -i ./object_detection/images --imageWidth=800 --imageHeight=600</code></pre><br>
<p>       ,     800x600     <strong>object_detection/images/resized</strong>.        <strong>object_detection/images</strong>.</p><br>
<p>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">labelImg</a>.</p><br>
<p>  <strong>labelImg</strong>  <strong>object_detection</strong></p><br>
<p>   <strong>labelImg</strong> </p><br>
<pre><code class="bash hljs"><span class="hljs-built_in">cd</span> [FULL_PATH]/object_detection/labelImg </code></pre><br>
<p>  : </p><br>
<pre><code class="bash hljs">pyrcc5 -o libs/resources.py resources.qrc</code></pre><br>
<p>       (     ):</p><br>
<pre><code class="bash hljs">python labelImg.py</code></pre><br>
<p><img src="https://habrastorage.org/webt/dg/-4/ho/dg-4hojgkwt6irfuphncnnnulhq.png"></p><br>
<p> ‚ÄúOpen dir‚Äù   <strong>object_detection/images</strong>     ,        .        (1, 2, 3, 4, 5, 6).   ( *.xml)    .</p><br>
<p>  <strong>object_detection/training_demo</strong>,       Google Colab  .</p><br>
<p>   ( )       <strong>80/20</strong>       <strong>object_detection/training_demo/images/train</strong>  <strong>object_detection/training_demo/images/test</strong>.</p><br>
<p>  <strong>object_detection/training_demo/annotations</strong>,          .     <strong>label_map.pbtxt</strong>,         .    :</p><br>
<div class="spoiler"><b class="spoiler_title">label_map.pbtxt</b><div class="spoiler_text"><pre><code class="json hljs">item {<font></font>
    id: <span class="hljs-number">1</span>
    name: '<span class="hljs-number">1</span>'<font></font>
}<font></font>
<font></font>
item {<font></font>
    id: <span class="hljs-number">2</span>
    name: '<span class="hljs-number">2</span>'<font></font>
}<font></font>
<font></font>
item {<font></font>
    id: <span class="hljs-number">3</span>
    name: '<span class="hljs-number">3</span>'<font></font>
}<font></font>
<font></font>
item {<font></font>
    id: <span class="hljs-number">4</span>
    name: '<span class="hljs-number">4</span>'<font></font>
}<font></font>
<font></font>
item {<font></font>
    id: <span class="hljs-number">5</span>
    name: '<span class="hljs-number">5</span>'<font></font>
}<font></font>
<font></font>
item {<font></font>
    id: <span class="hljs-number">6</span>
    name: '<span class="hljs-number">6</span>'<font></font>
}</code></pre></div></div><br>
<p> ,       ?     ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TFRecord</a>.       [1].</p><br>
<p>    : <strong>xml</strong> -&gt; <strong>csv</strong>  <strong>csv</strong> -&gt; <strong>record</strong></p><br>
<p>   preprocessing :</p><br>
<pre><code class="bash hljs"><span class="hljs-built_in">cd</span> [FULL_PATH]\object_detection\preprocessing</code></pre><br>
<p><strong>1.</strong> xml  csv</p><br>
<p> :</p><br>
<pre><code class="bash hljs">python xml_to_csv.py -i [FULL_PATH]/object_detection/training_demo/images/train -o [FULL_PATH]/object_detection/training_demo/annotations/train_labels.csv</code></pre><br>
<p> :</p><br>
<pre><code class="bash hljs">python xml_to_csv.py -i [FULL_PATH]/object_detection/training_demo/images/<span class="hljs-built_in">test</span> -o [FULL_PATH]/object_detection/training_demo/annotations/test_labels.csv</code></pre><br>
<p><strong>2.</strong>  csv  record</p><br>
<p> :</p><br>
<pre><code class="bash hljs">python generate_tfrecord.py --label_map_path=[FULL_PATH]\object_detection\training_demo\annotations\label_map.pbtxt --csv_input=[FULL_PATH]\object_detection\training_demo\annotations\train_labels.csv --output_path=[FULL_PATH]\object_detection\training_demo\annotations\train.record --img_path=[FULL_PATH]\object_detection\training_demo\images\train</code></pre><br>
<p> :</p><br>
<pre><code class="bash hljs">python generate_tfrecord.py --label_map_path=[FULL_PATH]\object_detection\training_demo\annotations\label_map.pbtxt --csv_input=[FULL_PATH]\object_detection\training_demo\annotations\test_labels.csv --output_path=[FULL_PATH]\object_detection\training_demo\annotations\test.record --img_path=[FULL_PATH]\object_detection\training_demo\images\<span class="hljs-built_in">test</span></code></pre><br>
<p>     ,    ,   .</p><br>
<p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>.</p><br>
<p>    <strong>ssdlite_mobilenet_v2_coco</strong>,        <strong>android</strong> .</p><br>
<p>        <strong>object_detection/training_demo/pre-trained-model</strong>.</p><br>
<p>  - <br>
<strong>object_detection/training_demo/pre-trained-model/ssdlite_mobilenet_v2_coco_2018_05_09</strong></p><br>
<p>     <strong>pipeline.config</strong>  <strong>object_detection/training_demo/training</strong>     <strong>ssdlite_mobilenet_v2_coco.config</strong>.</p><br>
<p>       ,  :</p><br>
<p><strong>1.</strong>   </p><br>
<pre><code class="cpp hljs">model.ssd.num_classes: <span class="hljs-number">6</span></code></pre><br>
<p><strong>2.</strong>    (      ),         ,   </p><br>
<pre><code class="cpp hljs">train_config.batch_size: <span class="hljs-number">18</span>
train_config.num_steps: <span class="hljs-number">20000</span>
train_config.fine_tune_checkpoint:<span class="hljs-string">"./training_demo/pre-trained-model/ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt"</span></code></pre><br>
<p><strong>3.</strong>       (<strong>object_detection/training_demo/images/train</strong>)</p><br>
<pre><code class="cpp hljs">eval_config.num_examples: <span class="hljs-number">64</span></code></pre><br>
<p><strong>4.</strong>       </p><br>
<pre><code class="cpp hljs">train_input_reader.label_map_path: <span class="hljs-string">"./training_demo/annotations/label_map.pbtxt"</span>
train_input_reader.tf_record_input_reader.input_path:<span class="hljs-string">"./training_demo/annotations/train.record"</span></code></pre><br>
<p><strong>5.</strong>      </p><br>
<pre><code class="cpp hljs">eval_input_reader.label_map_path: <span class="hljs-string">"./training_demo/annotations/label_map.pbtxt"</span>
eval_input_reader.tf_record_input_reader.input_path:<span class="hljs-string">"./training_demo/annotations/test.record"</span></code></pre><br>
<p> ,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>.</p><br>
<p>   <strong>training_demo</strong>   <strong>training_demo.zip</strong>   Google Drive.</p><br>
<div class="spoiler"><b class="spoiler_title">   </b><div class="spoiler_text"><blockquote> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>     google drive    Google Colab,           </blockquote></div></div><br>
<p>    ,   .</p><br>
<h2 id="obuchenie-modeli"> </h2><br>
<p> Google Drive  <strong>training_demo.zip</strong>,   <strong>Get shareable link</strong>       <strong>id</strong>  :</p><br>
<p>drive.google.com/open?id=<strong>[YOUR_FILE_ID_HERE]</strong></p><br>
<p>    Google Colab ‚Äî     Google Drive.</p><br>
<p><img src="https://habrastorage.org/webt/fl/o3/ee/flo3eeezvo-q42lngwpxamixtsg.png"></p><br>
<p>      CPU.   GPU,    runtime.</p><br>
<p><img src="https://habrastorage.org/webt/37/ko/ap/37koapmnqw-l9cuvxw7gbjomxds.png"></p><br>
<p><img src="https://habrastorage.org/webt/ng/b0/mm/ngb0mmui99onkgqergw8uo88ba8.png"></p><br>
<p>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>.</p><br>
<p>    :</p><br>
<p><strong>1.</strong>   TensorFlow Models:</p><br>
<pre><code class="bash hljs">!git <span class="hljs-built_in">clone</span> https://github.com/tensorflow/models.git                                                </code></pre><br>
<p><strong>2.</strong>  protobuf      object_detection:</p><br>
<pre><code class="bash hljs">!apt-get -qq install libprotobuf-java protobuf-compiler                                               <font></font>
%<span class="hljs-built_in">cd</span> ./models/research/<font></font>
!protoc object_detection/protos/*.proto --python_out=.<font></font>
%<span class="hljs-built_in">cd</span> ../..</code></pre><br>
<p><strong>3.</strong>       PYTHONPATH: </p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> os<font></font>
os.environ[<span class="hljs-string">'PYTHONPATH'</span>] += <span class="hljs-string">":/content/models/research/"</span>
os.environ[<span class="hljs-string">'PYTHONPATH'</span>] += <span class="hljs-string">":/content/models/research/slim"</span>
os.environ[<span class="hljs-string">'PYTHONPATH'</span>] += <span class="hljs-string">":/content/models/research/object_detection"</span>
os.environ[<span class="hljs-string">'PYTHONPATH'</span>] += <span class="hljs-string">":/content/models/research/object_detection/utils"</span></code></pre><br>
<p><strong>4.</strong>     Google Drive  PyDrive  :</p><br>
<pre><code class="python hljs">!pip install -U -q PyDrive<font></font>
<font></font>
<span class="hljs-keyword">from</span> pydrive.auth <span class="hljs-keyword">import</span> GoogleAuth
<span class="hljs-keyword">from</span> pydrive.drive <span class="hljs-keyword">import</span> GoogleDrive
<span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> auth
<span class="hljs-keyword">from</span> oauth2client.client <span class="hljs-keyword">import</span> GoogleCredentials<font></font>
<font></font>
auth.authenticate_user()<font></font>
gauth = GoogleAuth()<font></font>
gauth.credentials = GoogleCredentials.get_application_default()<font></font>
drive = GoogleDrive(gauth)</code></pre><br>
<p><strong>5.</strong>   (  id  )   :</p><br>
<pre><code class="python hljs">drive_file_id=<span class="hljs-string">"[YOUR_FILE_ID_HERE]"</span><font></font>
<font></font>
training_demo_zip = drive.CreateFile({<span class="hljs-string">'id'</span>: drive_file_id})<font></font>
training_demo_zip.GetContentFile(<span class="hljs-string">'training_demo.zip'</span>)<font></font>
<font></font>
!unzip training_demo.zip<font></font>
!rm training_demo.zip</code></pre><br>
<p><strong>6.</strong>   :</p><br>
<pre><code class="bash hljs">!python ./models/research/object_detection/legacy/train.py --logtostderr --train_dir=./training_demo/training --pipeline_config_path=./training_demo/training/ssdlite_mobilenet_v2_coco.config</code></pre><br>
<div class="spoiler"><b class="spoiler_title"> </b><div class="spoiler_text"><p><strong>--train_dir</strong>=./training_demo/training ‚Äî   ,   <br>
 </p><br>
<p><strong>--pipeline_config_path</strong>=./training_demo/training/ssdlite_mobilenet_v2_coco.config ‚Äî   </p></div></div><br>
<p><strong>7.</strong>     frozen graph,    :</p><br>
<pre><code class="bash hljs">!python /content/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix /content/training_demo/training/model.ckpt-[CHECKPOINT_NUMBER]<font></font>
 --output_directory /content/training_demo/training/output_inference_graph_v1.pb</code></pre><br>
<div class="spoiler"><b class="spoiler_title"> </b><div class="spoiler_text"><p><strong>--pipeline_config_path</strong> /content/training_demo/training/ssdlite_mobilenet_v2_coco.config ‚Äî   </p><br>
<p><strong>--trained_checkpoint_prefix</strong> /content/training_demo/training/model.ckpt-[CHECKPOINT_NUMBER] ‚Äî   ,    .</p><br>
<p><strong>--output_directory</strong> /content/training_demo/training/output_inference_graph_v1.pb ‚Äî   </p><br>
<p>  <strong>[CHECKPOINT_NUMBER]</strong>,     <strong>content/training_demo/training/</strong>. <strong></strong>       model.ckpt-1440.index, model.ckpt-1440.meta. 1440 ‚Äî   <strong>[CHECKPOINT_NUMBER]</strong>    .</p></div></div><br>
<p><img src="https://habrastorage.org/webt/g-/m8/kf/g-m8kf5wi515656u-kha_bebbe8.png"></p><br>
<p>        .             ~20000  .</p><br>
<p><img src="https://habrastorage.org/webt/rm/et/nq/rmetnqjmwcurf-gg5kfgc0w-hqu.png"></p><br>
<p><strong>8.</strong>     tflite.<br>
  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tensorflow lite</a>      <strong>tflite</strong>.       <strong>frozen graph</strong>     <strong>tflite</strong> (       <strong>export_inference_graph.py</strong>):</p><br>
<pre><code class="bash hljs">!python /content/models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix /content/training_demo/training/model.ckpt-[CHECKPOINT_NUMBER] --output_directory /content/training_demo/training/output_inference_graph_tf_lite.pb</code></pre><br>
<p>   <strong>tflite</strong>      ,       <strong>output_inference_graph_tf_lite.pb</strong>:</p><br>
<p><img src="https://habrastorage.org/webt/bi/bl/nr/biblnrzykjebdm7fcbri14qhipq.png"></p><br>
<p>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Netron</a>.          .</p><br>
<p><img src="https://habrastorage.org/webt/yq/wb/og/yqwbogkc-dr3hk6pem3cpfx5gly.png"><br>
<img src="https://habrastorage.org/webt/dm/2i/b5/dm2ib5a058pwphfh9vcpiad-h_0.png"></p><br>
<p>    pb   tflite :</p><br>
<pre><code class="bash hljs">!tflite_convert --output_file=/content/training_demo/training/model_q.tflite  --graph_def_file=/content/training_demo/training/output_inference_graph_tf_lite_v1.pb/tflite_graph.pb --input_arrays=normalized_input_image_tensor  --output_arrays=<span class="hljs-string">'TFLite_Detection_PostProcess'</span>,<span class="hljs-string">'TFLite_Detection_PostProcess:1'</span>,<span class="hljs-string">'TFLite_Detection_PostProcess:2'</span>,<span class="hljs-string">'TFLite_Detection_PostProcess:3'</span> --input_shapes=1,300,300,3 --enable_select_tf_ops --allow_custom_ops  --inference_input_type=QUANTIZED_UINT8 --inference_type=FLOAT --mean_values=128 --std_dev_values=128</code></pre><br>
<div class="spoiler"><b class="spoiler_title"> </b><div class="spoiler_text"><p><strong>--output_file</strong>=/content/training_demo/training/model_q.tflite ‚Äî    </p><br>
<p><strong>--graph_def_file</strong>=/content/training_demo/training/output_inference_graph_tf_lite_v1.pb/tflite_graph.pb ‚Äî   frozen graph,   </p><br>
<p><strong>--input_arrays</strong>=normalized_input_image_tensor ‚Äî   ,    </p><br>
<p><strong>--output_arrays</strong>='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' ‚Äî   ,    </p><br>
<p><strong>--input_shapes</strong>=1,300,300,3 ‚Äî   ,    </p><br>
<p><strong>--enable_select_tf_ops</strong> ‚Äî    runtime TensorFlow Lite</p><br>
<p><strong>--allow_custom_ops</strong> ‚Äî   TensorFlow Lite Optimizing Converter </p><br>
<p><strong>--inference_type</strong>=FLOAT ‚Äî         </p><br>
<p><strong>--inference_input_type</strong>=QUANTIZED_UINT8 ‚Äî         </p><br>
<p><strong>--mean_values</strong>=128 <strong>--std_dev_values</strong>=128 ‚Äî       ,   QUANTIZED_UINT8</p></div></div><br>
<p>         Google Drive:</p><br>
<pre><code class="bash hljs">!zip -r ./training_demo/training.zip ./training_demo/training/<font></font>
<font></font>
training_result = drive.CreateFile({<span class="hljs-string">'title'</span>: <span class="hljs-string">'training_result.zip'</span>})<font></font>
training_result.SetContentFile(<span class="hljs-string">'training_demo/training.zip'</span>)<font></font>
training_result.Upload()</code></pre><br>
<blockquote>   Invalid client secrets file,       google drive.</blockquote><br>
<h2 id="zapusk-modeli-na-android-ustroystve">   android </h2><br>
<p>  android    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a>  object detection,        kotlin  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CameraX</a>.     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>. </p><br>
<p>CameraX            <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageAnalysis</a>.      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ObjectDetectorAnalyzer</a>. </p><br>
<p>        :</p><br>
<p><strong>1.</strong>        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">YUV</a> .        RGB :</p><br>
<pre><code class="kotlin hljs"><span class="hljs-keyword">val</span> rgbArray = convertYuvToRgb(image)</code></pre><br>
<p><strong>2.</strong>     (,   ,       ,     300x300),        Bitmap     :</p><br>
<pre><code class="kotlin hljs"><span class="hljs-keyword">val</span> rgbBitmap = getRgbBitmap(rgbArray, image.width, image.height)
<span class="hljs-keyword">val</span> transformation =  getTransformation(rotationDegrees, image.width, image.height)<font></font>
Canvas(resizedBitmap).drawBitmap(rgbBitmap, transformation, <span class="hljs-literal">null</span>)</code></pre><br>
<p><strong>3.</strong>  bitmap   ,      :</p><br>
<pre><code class="kotlin hljs">ImageUtil.storePixels(resizedBitmap, inputArray)
<span class="hljs-keyword">val</span> objects = detect(inputArray)</code></pre><br>
<p><strong>4.</strong>       RecognitionResultOverlayView       :</p><br>
<pre><code class="kotlin hljs"><span class="hljs-keyword">val</span> scaleFactorX = measuredWidth / result.imageWidth.toFloat()
<span class="hljs-keyword">val</span> scaleFactorY = measuredHeight / result.imageHeight.toFloat()<font></font>
<font></font>
result.objects.forEach { obj -&gt;<font></font>
    <span class="hljs-keyword">val</span> left = obj.location.left * scaleFactorX
    <span class="hljs-keyword">val</span> top = obj.location.top * scaleFactorY
    <span class="hljs-keyword">val</span> right = obj.location.right * scaleFactorX
    <span class="hljs-keyword">val</span> bottom = obj.location.bottom * scaleFactorY<font></font>
<font></font>
    canvas.drawRect(left, top, right, bottom, boxPaint)<font></font>
    canvas.drawText(obj.text, left, top - <span class="hljs-number">25f</span>, textPaint)<font></font>
}</code></pre><br>
<p>     ,    assets     <strong>training_demo/training/model_q.tflite</strong> (   <strong>detect.tflite</strong>)     <strong>labelmap.txt</strong>,    :</p><br>
<div class="spoiler"><b class="spoiler_title">detect.tflite</b><div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-number">1</span>
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
<span class="hljs-number">5</span>
<span class="hljs-number">6</span></code></pre></div></div><br>
<p>      <strong>SSD Mobilenet V1</strong>,       1,    0,   labelOffset  1  0   collectDetectionResult  ObjectDetector.</p><br>
<p>  .<br>
   ,       Xiaomi Redmi 4X :</p><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/GXtiLAjPlHg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<blockquote>     :<br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://tensorflow-object-detection-api-tutorial.readthedocs.io</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10</a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://lutzroeder.github.io/netron/</a></li>
</ul><br>
</blockquote></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es488196/index.html">Inserciones de Android: lidiar con los miedos y prepararse para Android Q</a></li>
<li><a href="../es488198/index.html">¬øA qu√© le temen los Timlids y por qu√© deber√≠an dejar de hacerlo?</a></li>
<li><a href="../es488200/index.html">El debate sobre el primer lenguaje de programaci√≥n: la decisi√≥n final</a></li>
<li><a href="../es488202/index.html">PVS-Studio ahora est√° en Chocolatey: comprobando Chocolatey desde Azure DevOps</a></li>
<li><a href="../es488208/index.html">Aniversario DUMP2020 - 4 d√≠as que no olvidar√°</a></li>
<li><a href="../es488212/index.html">Informe DORA State of DevOps 2019, ahora tambi√©n en ruso</a></li>
<li><a href="../es488214/index.html">Materiales de Kazan Go-mitap: an√°lisis XML, gopls, drone.io y trabajo con migraciones</a></li>
<li><a href="../es488218/index.html">Confesi√≥n de un especialista en TI</a></li>
<li><a href="../es488220/index.html">Mejores empleadores de TI rusos 2019: calificaci√≥n anual de Habr Career</a></li>
<li><a href="../es488222/index.html">C√≥mo hice un juego para el Bloc de notas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
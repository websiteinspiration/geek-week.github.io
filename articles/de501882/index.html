<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👅 👨🏼‍⚖️ 🚵 Wie wir Computer-Vision-Algorithmen verwenden: Videoverarbeitung in einem mobilen Browser mit OpenCV.js 🧔🏽 🧓🏿 👋🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es gibt bereits alle Möglichkeiten, eine Person online zu identifizieren, aber bisher werden sie nur selten verwendet. Vielleicht haben wir als einer ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Wie wir Computer-Vision-Algorithmen verwenden: Videoverarbeitung in einem mobilen Browser mit OpenCV.js</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/simbirsoft/blog/501882/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gibt bereits alle Möglichkeiten, eine Person online zu identifizieren, aber bisher werden sie nur selten verwendet. </font><font style="vertical-align: inherit;">Vielleicht haben wir als einer der Ersten das optimale Szenario für den Benutzer implementiert: Melden Sie sich von einem Smartphone aus auf der Website an, machen Sie ein Foto Ihres Führerscheins oder Reisepasses und senden Sie Daten an das System. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Betrachten wir, wie Computer-Vision-Algorithmen helfen, Dokumente in einem Videostream direkt in mobilen Browsern zu erkennen. </font><font style="vertical-align: inherit;">In diesem Artikel teilen wir unsere Erfahrungen mit, wie wir OpenCV.js bei SimbirSoft dafür verwendet haben, welche Schwierigkeiten möglich sind, wie man Geschwindigkeit sicherstellt und eine „reibungslose“ Benutzeroberfläche erhält, ohne sich zu verlangsamen.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jx/y7/u7/jxy7u7brc2ixo10gyheuhr19zcu.png"><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was war die Aufgabe?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Geschäftsszenario für den zu entwickelnden Algorithmus ist wie folgt. Ein Benutzer, der von einem Mobiltelefon aus auf die Website zugreift, sollte in der Lage sein, seine Dokumente zu fotografieren und zur weiteren Verarbeitung an das System zu senden. Dies kann Teil des Identitätsprozesses sein, wenn Sie die Nutzung von Diensten beantragen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Webanwendung in diesem Szenario ist einer mobilen Anwendung aufgrund ihrer Verfügbarkeit und der kürzeren Zeit für den Abschluss des Vorgangs vorzuziehen. Die Webseite muss nicht installiert werden und ist sofort nach dem Laden betriebsbereit. Der Benutzer kann die erforderlichen Aktionen - Einreichen eines Antrags - unmittelbar nach Erhalt des Links ausführen, ohne durch zusätzliche Aktionen abgelenkt zu werden. Aus geschäftlicher Sicht erhöhen diese Faktoren die Umwandlung und die wirtschaftliche Effektivität des Prozesses.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aus architektonischer Sicht ist der Algorithmus erforderlich, um die Grenzen des Dokuments direkt zu erkennen und den überschüssigen Hintergrund im Bild zuzuschneiden. </font><font style="vertical-align: inherit;">Die Überprüfung der Identität, Authentifizierung und Betrugsprüfung wird von anderen Komponenten durchgeführt. </font><font style="vertical-align: inherit;">Es ist jedoch ratsam, mindestens minimale Überprüfungen durchzuführen, um das Senden von Visitenkarten, leeren Papierrechtecken und anderen offensichtlich irrelevanten Bildern für die Verarbeitung von Bildern auszuschließen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bedarf</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Rahmen unseres Projekts wurden folgende zusätzliche Anforderungen an den Algorithmus gestellt:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Fähigkeit, in Echtzeit zu arbeiten: Der Videostream von der Kamera sollte während des Betriebs des Algorithmus nicht „langsamer“ werden.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Fähigkeit, in einem breiten Spektrum von Kontrast- und Hintergrundtexturen zu arbeiten: kontrastarmer und kontrastarmer, homogener und heterogener Hintergrund;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unterstützung für eine Vielzahl von Smartphone-Modellen, einschließlich Budgetmodellen, die vor einigen Jahren veröffentlicht wurden.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schließlich gab es im Projekt keinen Datensatz zum Trainieren von Algorithmen für maschinelles Lernen, und es gab keine Möglichkeit, ihn zu sammeln und zu markieren. </font><font style="vertical-align: inherit;">Wir hatten nur wenige Testmuster aus den Suchergebnissen von Google. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Angesichts dieser Problemstellung haben wir uns entschlossen, basierend auf den klassischen Computer-Vision-Algorithmen aus der opencv-Bibliothek zu entwickeln. </font><font style="vertical-align: inherit;">Eine alternative Möglichkeit war die Verwendung von Algorithmen für maschinelles Lernen und neuronalen Netzen, die jedoch aufgrund von Leistungsanforderungen bereits in den frühen Arbeitsphasen verworfen wurden: Bei Anwendung wäre es nicht möglich, auf allen Zielgeräten eine Echtzeit-Rahmenverarbeitung bereitzustellen.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Allgemeiner Ansatz und Algorithmusstruktur</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Hauptidee des Algorithmus ist ein Referenzrahmen, entlang dessen das Dokument ausgerichtet werden muss. </font><font style="vertical-align: inherit;">Seine Verwendung verfolgt mehrere Ziele gleichzeitig. </font><font style="vertical-align: inherit;">Erstens wird eine geeignete Bildgröße bereitgestellt, die für die weitere Verarbeitung von Dokumenten ausreicht. </font><font style="vertical-align: inherit;">Zweitens kann es, wie wir später sehen werden, als einer der Kandidatenfilter bei der Suche nach Dokumentgrenzen verwendet werden. </font><font style="vertical-align: inherit;">Drittens kann es zum Erfassen und Zuschneiden des Bildes verwendet werden, wenn die Ränder des Dokuments nicht gefunden wurden. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ru/et/bq/ruetbqsseuefny01b_anvvaa834.png"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feige. </font><font style="vertical-align: inherit;">1. Die allgemeine Struktur des Algorithmus</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die allgemeine Struktur des Algorithmus ist in Abb. 1 dargestellt. </font><font style="vertical-align: inherit;">1. Bilder aus dem Videostream werden in einem Zyklus verarbeitet, zwischen dessen Iterationen ein Zeitlimit festgelegt wird, das den gewünschten FPS entspricht. Wir haben bei 30 Bildern pro Sekunde angehalten. </font><font style="vertical-align: inherit;">Auf diese Weise können Sie „Verlangsamungen“ vermeiden und die Belastung des Prozessors sowie den Stromverbrauch des Geräts verringern.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder verarbeitete Rahmen wird einer Vorverarbeitung unterzogen, während der zwei grundlegende Operationen ausgeführt werden. Zunächst wird eine Kopie eines Frames mit einer festen Größe von 640 x 480 erstellt, mit der die weiteren Schritte des Algorithmus arbeiten. Das Originalbild bleibt ebenfalls erhalten, das erkannte Dokument wird daraus ausgeschnitten. Dadurch wird die Qualität des endgültigen Bildes gespeichert. Zweitens wird die erstellte Kopie in Graustufen übersetzt. Die Farbe des zu verarbeitenden Dokuments wird vom Algorithmus ignoriert, da sie von Land zu Land und sogar in verschiedenen Regionen des Landes variieren kann. Ein Beispiel ist ein Führerschein in den USA.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der erste Schritt beim Erkennen eines Dokuments besteht darin, nach dem Gesicht im Bild zu suchen. Die Verwendung dieser Heuristik eliminiert die Erfassung von Visitenkarten und anderen offensichtlich irrelevanten Bildern. Die Suche wird mit dem Standard-CascadeClassifier.detectMultiScale </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">() von opencv'shash</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vorab trainierten</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kaskade </font><i><font style="vertical-align: inherit;">haarcascade_frontalface_default durchgeführt</font></i><font style="vertical-align: inherit;"> . Die minimale und maximale Größe der erkannten Gesichter ist begrenzt, wodurch die Rechenkosten gesenkt werden können und der Maßstab des Dokuments im Bild weiter eingeschränkt wird. Ein Gesicht wird im Bild als erkannt betrachtet, wenn es sich links oder unten links für Pässe als Teil des Bereichs innerhalb des Referenzrahmens befindet (Abb. 2). Dies ist eine zusätzliche Maßnahme, um die korrekte Ausrichtung des Dokuments im Bild sicherzustellen.</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Beispiele in diesem Artikel enthalten keine personenbezogenen Daten. </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/ws/mz/7w/wsmz7wghvpoyfdslngrf59jofms.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feige. 2. Der Bereich der erwarteten Position des Gesichts im Bild. Der Stützrahmen wird rot angezeigt, die Ränder des Bereichs der erwarteten Position des Gesichts werden grün angezeigt.</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Nach der Gesichtserkennung fahren wir mit der Rahmenerkennung fort. Oft wird hier </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">findContours ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> verwendet </font><font style="vertical-align: inherit;">. Dieser Ansatz funktioniert jedoch nur in kontrastierenden Fällen, z. B. bei einem Blatt Papier, das auf einem dunklen Schreibtisch liegt. Wenn der Kontrast geringer ist oder die Beleuchtung schlechter ist oder jemand ein Blatt in der Hand hält und einen Teil des Randes mit den Fingern bedeckt, zerfallen die erkannten Konturen in separate Komponenten, „verlieren“ wichtige Abschnitte oder werden überhaupt nicht erkannt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deshalb haben wir einen anderen Ansatz gewählt. Nach der Binarisierung führen wir das Bild zuerst mit </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Canny ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> durch den </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rahmenfilter</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und betrachten dann das resultierende Bild für die Linie mit der Huff-Transformation </font><i><font style="vertical-align: inherit;">HoughLines ()</font></i><font style="vertical-align: inherit;"> . Der Schwellenwertparameter wird sofort groß genug auf 30 gesetzt, um erkannte kurze und andere irrelevante Segmente zu filtern.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der resultierende Satz von Linien wird zusätzlich gefiltert, so dass nur Linien in der Nähe des Referenzrahmens verbleiben. Dazu übersetzen wir zuerst die Gleichungen der Rahmenlinien in Punkte im Polarkoordinatensystem (Rho, Theta) - Theta ist immer 0 oder pi / 2, und Rho ist für jede Linie eindeutig. Danach wählen wir aus den aus der Huff-Transformation erhaltenen Linien nur diejenigen aus, die in der Nähe der Kontrollpunkte liegen - gemäß der euklidischen Metrik unter Berücksichtigung des Unterschieds in der Skala der Werte. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir verteilen den Satz von Linien, der nach dem Filtern erhalten wurde, in vier Gruppen, die den vier Linien des Referenzrahmens entsprechen, finden die Schnittpunkte der Linien paarweise zwischen den Gruppen, mitteln und erhalten die Koordinaten der vier Punkte - die Ecken des erkannten Dokuments (Abb. 3).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zr/7g/lz/zr7glzo5dwn-mofan9fhnthwu8k.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feige. 3. Linien filtern und Dokumentecken definieren. Grüne Linien - das Ergebnis der Filterung, gelbe Punkte - erkannten Ecken des Dokuments</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Als Nächstes müssen Sie die Qualität des Rahmens sicherstellen. Dazu überprüfen wir, ob der Frame zum letzten Mal stationär geblieben ist. Subtrahieren Sie dazu den Frame zu Beginn des Zeitraums mit </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">absdiff ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> vom aktuellen Frame </font><font style="vertical-align: inherit;">und vergleichen Sie ihn mit dem Schwellenwert. Vor der Subtraktion glätten wir die Bilder zusätzlich mit einem Gaußschen Filter </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GaussianBlur ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , um den Einfluss von Rauschen und anderen Zufallsfaktoren zu verringern. Wir bewerten auch den Fokus des Rahmens, indem wir seinen Laplace- </font><font style="vertical-align: inherit;">Wert </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplace ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> berechnen </font><font style="vertical-align: inherit;">, seine Varianz schätzen und den erhaltenen Wert mit einem Schwellenwert vergleichen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn alle Prüfungen erfolgreich sind, können Sie mit dem letzten Teil fortfahren. </font><font style="vertical-align: inherit;">Wir berechnen die erkannten Koordinaten der Winkel neu in das Koordinatensystem des ursprünglichen, unterbelichteten Bildes und schneiden den resultierenden Bereich mit der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">roi ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -Methode </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Das Dokument wurde erfolgreich erkannt.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Implementierungsfunktionen</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Während der Entwicklung des Algorithmus wurden seine Hauptkomponenten in einem Python-Skript zusammengestellt. Danach wurde der Algorithmus nach opencv.js und Javascript und dann nach wasm portiert. Dieser Ansatz wird durch Überlegungen zur Zweckmäßigkeit in allen Phasen bestimmt. Auf Python war es für unser Team bequemer, mit verschiedenen Varianten des Algorithmus zu experimentieren und grobe Parametereinstellungen vorzunehmen. Durch die Portierung auf Javascript konnte die Funktionsweise des Algorithmus auf der Zielplattform getestet werden, auch auf verschiedenen Geräten und Browsern. Basierend auf den Ergebnissen dieser Überprüfungen wurde eine Feinabstimmung der Algorithmusparameter durchgeführt. Durch das Umschreiben kritischer Codeabschnitte auf wasm konnten wir schließlich eine zusätzliche Leistungssteigerung erzielen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Während der Migration wurden einige Unterschiede in der OpenCV-API festgestellt, die zu geringfügigen Änderungen in der Implementierung führten. Zum Beispiel wird die Varianz eines Laplace in Python einfach als </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplace () betrachtet. Var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Mit OpenCV.js gibt es keine Möglichkeit, NumPy zu verwenden, es wurde jedoch keine alternative Implementierung der </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -Methode </font><font style="vertical-align: inherit;">bereitgestellt. Lösung: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zählen Sie die</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Funktion </font><i><font style="vertical-align: inherit;">meanStdDev ()</font></i><font style="vertical-align: inherit;"> als </font><font style="vertical-align: inherit;">Standardabweichung (Listing 1).</font></font><br>
<br>
<pre><code class="javascript hljs">private isImageBlurry(image: cv.Mat): boolean {
		<span class="hljs-keyword">const</span> laplacian = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.Laplacian(image, laplacian, cv.CV_64F);<font></font>
		<span class="hljs-keyword">const</span> s_mat = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.meanStdDev(laplacian, <span class="hljs-keyword">new</span> cv.Mat(), s_mat);
		<span class="hljs-keyword">const</span> s = s_mat.data64F[<span class="hljs-number">0</span>];
		<span class="hljs-keyword">const</span> v = <span class="hljs-built_in">Math</span>.pow(s, <span class="hljs-number">2</span>);
		<span class="hljs-keyword">return</span> (v &lt; <span class="hljs-keyword">this</span>.laplacianVarianceThreshold);<font></font>
	}</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listing 1. Bewertung des Fokus auf das Bild anhand der Varianz des Laplace in opencv.js (TypeScript)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Ein weiteres Merkmal war die Notwendigkeit, die Größe der Bibliothek zu reduzieren. In seiner ursprünglichen Form hat OpenCV.js eine Kapazität von 7,9 MB. Der Download über das Internet verlangsamt die Initialisierung des Algorithmus. Die Lösung für dieses Problem besteht darin, die nicht verwendeten Module während des Zusammenbaus der Bibliothek zu „trimmen“, was die Größe der Ausgabedatei erheblich reduzieren kann: Wir haben es geschafft, eine Größe von 1,8 MB zu erreichen. Die Liste der in der Assembly enthaltenen Komponenten kann in der Konfigurationsdatei </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">platform / js / opencv_js.config.py</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Listing 2) </font><font style="vertical-align: inherit;">konfiguriert werden </font><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="javascript hljs">white_list = makeWhiteList([core, imgproc, objdetect, video, dnn, features2d, photo, aruco, calib3d])</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listing 2. Die ursprüngliche Whitelist der OpenCV-Module, die in der Assembly für Javascript enthalten sind</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Schließlich wurde ein wichtiger Beitrag zur Sicherstellung der erforderlichen Leistung des Algorithmus geleistet, indem er in Web Worker verschoben wurde. </font><font style="vertical-align: inherit;">Dieser Schritt, zusammen mit der Einschränkung von FPS, ermöglichte es uns, die "Verlangsamungen" des Videostreams während des Betriebs des Algorithmus zu beseitigen, was sich positiv auf UX auswirkte.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ergebnisse</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beispiele für das Aufnehmen und Zuschneiden von Bildern sind in Abb. 1 dargestellt. </font><font style="vertical-align: inherit;">4. Es ist ersichtlich, dass das Zuschneiden mit der höchsten Qualität auf einem dunklen, gleichmäßigen Hintergrund erzielt wird und die niedrigste Qualität mit einem hellen inhomogenen Hintergrund erzielt wird. </font><font style="vertical-align: inherit;">Dies ist der erwartete Effekt, der mit den Verläufen verbunden ist, die auf verschiedenen Hintergründen erhalten und zum Erkennen der Ränder eines Dokuments verwendet werden. </font><font style="vertical-align: inherit;">Vor einem dunklen Hintergrund sind die Gradienten größer als auf einem hellen Hintergrund, ein gleichmäßiger Hintergrund führt zu einer geringeren Variabilität der Gradientenwerte. </font><font style="vertical-align: inherit;">Dies führt zu einer zuverlässigen Erkennung von Grenzen und damit zu einem besseren Zuschneiden. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/es/my/90/esmy90lihywocpj3-7p5bgttqkg.jpeg"><br>
<img src="https://habrastorage.org/webt/w4/uz/2l/w4uz2lnqlaajyd6eyplijsg72hc.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Feige. </font><font style="vertical-align: inherit;">4. Beispiele für das Zuschneiden von Dokumenten mithilfe eines Algorithmus</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fazit</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Artikel enthält einen Algorithmus zum Erkennen von Dokumenten in Frames aus einem Videostream, der für die Verwendung in mobilen Browsern geeignet ist, und berücksichtigt auch die Funktionen seiner Implementierung mithilfe der Bibliothek opencv.js. </font><font style="vertical-align: inherit;">Mit dem Algorithmus können Sie das Ausgabebild von Dokumenten in einer Qualität erhalten, die für die weitere Verwendung durch Algorithmen zur Authentifizierung, Identitätsprüfung usw. ausreicht. </font><font style="vertical-align: inherit;">Die Geschwindigkeit der resultierenden Implementierung ermöglicht es Ihnen, eine "reibungslose" UX ohne "Verlangsamungen" und Frame-Verlust zu erhalten. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vielen Dank für Ihre Aufmerksamkeit! </font><font style="vertical-align: inherit;">Wir hoffen, dass Sie diesen Artikel nützlich finden.</font></font></b></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de501868/index.html">Wie man den Buchhalter sich nicht werfen lässt oder Wir übertragen 1C in die Cloud. Schritt-für-Schritt-Anleitung</a></li>
<li><a href="../de501870/index.html">Maximale Anzahl von Werten in Aufzählung Teil II</a></li>
<li><a href="../de501872/index.html">Studienort in kybernetischen Systemen</a></li>
<li><a href="../de501874/index.html">Moderne Frontend-Architekturen (Teil 2)</a></li>
<li><a href="../de501880/index.html">Über die Übersetzung von "Anfängen" und "Anfängen" ohne Anfang, Anfang und zuerst</a></li>
<li><a href="../de501884/index.html">Wie elektronische medizinische Informationsarchive helfen, Krankheiten effektiver zu diagnostizieren</a></li>
<li><a href="../de501886/index.html">Der Raum ist nicht so einfach, wie es sich anhört.</a></li>
<li><a href="../de501888/index.html">So reduzieren Sie die mit Ransomware Ransomware verbundenen Risiken</a></li>
<li><a href="../de501890/index.html">React Native - Speichern Sie Fotos und Videos in der Gerätegalerie</a></li>
<li><a href="../de501892/index.html">Nicht mein linkes Bein: Eine Analyse der Gehirnstruktur von Menschen mit Xenomelia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
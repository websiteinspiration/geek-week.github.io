<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤷🏼 💯 🙇🏻 光学式テキスト認識技術をどのように作成したか。YandexのOCR 👩🏼‍🎓 🈯️ 🚼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="こんにちは！今日、Habrの読者に、45の言語で機能し、Yandex.Cloudユーザーがアクセスできるテキスト認識テクノロジーを作成した方法、設定したタスク、および解決方法について説明します。同様のプロジェクトに取り組んでいる場合、または今日どのようにしてアリスがロシア語に翻訳できるようにトルコの...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>光学式テキスト認識技術をどのように作成したか。YandexのOCR</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/475956/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こんにちは！今日、Habrの読者に、45の言語で機能し、Yandex.Cloudユーザーがアクセスできるテキスト認識テクノロジーを作成した方法、設定したタスク、および解決方法について説明します。同様のプロジェクトに取り組んでいる場合、または今日どのようにしてアリスがロシア語に翻訳できるようにトルコの店の看板を撮影する必要があるのか​​を知りたい場合に便利です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fm/c4/rx/fmc4rxrj9iczvwvfjku7cm-nwim.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
光学式文字認識（OCR）テクノロジーは、何十年もの間世界で開発されてきました。 Yandexでは、サービスを改善し、ユーザーにより多くのオプションを提供するために、独自のOCRテクノロジーを開発し始めました。画像はインターネットの大部分を占めており、それらを理解する能力がなければ、インターネットでの検索は不完全になります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
画像解析ソリューションの人気はますます高まっています。これは、人工ニューラルネットワークと高品質のセンサーを備えたデバイスの急増によるものです。そもそもスマートフォンについてだけでなく、スマートフォンについても話していることは明らかです。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキスト認識の分野におけるタスクの複雑さは絶えず増大しています-それはすべて、スキャンされたドキュメントの認識から始まりました。その後、</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">認識が</font></a><font style="vertical-align: inherit;">追加されました</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">生まれたデジタル写真とインターネットからのテキスト。</font><font style="vertical-align: inherit;">次に、モバイルカメラの人気が高まる</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">につれ</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、優れたカメラショットの認識（</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">フォーカスシーンテキスト</font></a><font style="vertical-align: inherit;">）が行われます。</font><font style="vertical-align: inherit;">さらに、パラメータがさらに複雑になります。テキストは</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">、</font></a><font style="vertical-align: inherit;">レシートの</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">写真</font></a><font style="vertical-align: inherit;">から</font><font style="vertical-align: inherit;">店の</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">棚</font></a><font style="vertical-align: inherit;">や看板</font><font style="vertical-align: inherit;">まで、さまざまなカテゴリの、曲がりやスパイラルで</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">書かれた</font></a><font style="vertical-align: inherit;">あいまいな（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">偶発的なシーンのテキスト</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）場合</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">が</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">あります</font><font style="vertical-align: inherit;">。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">私たちはどちらに行った</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキスト認識は、コンピュータービジョンタスクの別のクラスです。</font><font style="vertical-align: inherit;">多くのコンピュータービジョンアルゴリズムと同様に、ニューラルネットワークが普及する前は、主に手動機能とヒューリスティックに基づいていました。</font><font style="vertical-align: inherit;">しかし、最近では、ニューラルネットワークアプローチへの移行に伴い、テクノロジーの品質が大幅に向上しています。</font><font style="vertical-align: inherit;">写真の例を見てください。</font><font style="vertical-align: inherit;">これがどのように起こったか、私はさらに教えます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今日の認識結果を2018年の初めの結果と比較します。</font></font><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><img src="https://habrastorage.org/webt/uf/ux/-g/ufux-gtblu3a_fc96rdowuul7co.png"></td>
<td><img src="https://habrastorage.org/webt/so/pa/yg/sopaygej-n6c9gurt75zfwa-f3y.png"></td>
</tr>
<tr>
<td><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2018 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
保湿</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
n HOミセルの</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
贅沢な滑らかさの水。</font><font style="vertical-align: inherit;">
使用の</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
穏やかな多機能</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
式</font><font style="vertical-align: inherit;">
アルコール、染料、パラベンなしで</font><font style="vertical-align: inherit;">
クレンジングローションや</font><font style="vertical-align: inherit;">
トニックの</font><font style="vertical-align: inherit;">代わりに</font><font style="vertical-align: inherit;">
Sl FORの</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">手段として</font><font style="vertical-align: inherit;">
...</font></font><br><font style="vertical-align: inherit;"></font><br><font style="vertical-align: inherit;"></font><br><font style="vertical-align: inherit;"></font><br><font style="vertical-align: inherit;"></font><br><font style="vertical-align: inherit;"></font></i></b></td>
<td><b><i>2019<br>
<br>
- <br>
« »<br>
AUBY    <br>
 <br>
    <br>
  <br>
,   <br>
  .<br>
 , , <br>
…</i></b></td>
</tr>
</tbody></table></div><h3>    </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
旅の始めに、ロシア語と英語の認識技術を作成しました。主な使用例は、インターネットからのテキストと写真の写真ページでした。しかし、作業の過程で、これだけでは不十分であることに気付きました。画像のテキストは、どの言語でも、どの表面でも見つかり、写真の品質が非常に異なる場合がありました。これは、認識がどのような状況でも、すべてのタイプの受信データで機能することを意味します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
そして、ここで私たちは多くの困難に直面しています。以下はほんの一部です。</font></font><br>
<br>
<ul>
<li><b></b>.  ,     ,    —  , ,   ,       -. -           (,         ),     (     ử  ừ   ).           .</li>
<li><b></b>.     ,      :         ,     ,      .      ,   .    ,  .       .</li>
<li><b> </b>.    ,     ,   ,   ,    .</li>
<li><b></b>.      ,     -,         .</li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出モデルの選択</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキストを認識する最初のステップは、その位置を決定することです（検出）。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキスト検出は、個々のオブジェクト認識タスク、と考えることができ</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、文字</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">言葉</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">や</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">行を</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">オブジェクトとして機能することができます</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、モデルが他の言語にスケーリングされることが重要でした（現在、45言語をサポートしています）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
テキスト検出に関する多くの研究記事では、個々の</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">単語の</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">位置を予測するモデルを使用してい</font><b><font style="vertical-align: inherit;">ます</font></b><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">しかし、</font><b><font style="vertical-align: inherit;">普遍的なモデルの</font></b><font style="vertical-align: inherit;">場合</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このアプローチにはいくつかの制限があります。たとえば、中国語の単語の概念そのものは、たとえば英語の単語の概念とは根本的に異なります。中国語の個々の単語はスペースで区切られていません。タイ語では、1つの文のみがスペースで破棄されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ロシア語、中国語、タイ語の同じテキストの例を次に示し</font><b><font style="vertical-align: inherit;">ます。</font></b></font><br>
<br>
<code>  .    .<br>
今天天气很好 这是一个美丽的一天散步。<br>
สภาพอากาศสมบูรณ์แบบในวันนี้ มันเป็นวันที่สวยงามสำหรับเดินเล่นกันหน่อยแล้ว</code><br>
<br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">しかし、今度はアスペクト比の点で非常に可変です。このため、これらのモデルは多くの事前定義されたアスペクト比を持つ候補領域/アンカーボックスに基づいているため、ライン予測のそのような一般的な検出モデル（SSDまたはRCNNベースなど）の可能性は限られています。さらに、線は任意の形状、たとえば曲線を持つことができるため、線を定性的に説明するには、回転角度があっても、四角形を説明するだけでは十分ではありません。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
個々の</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文字</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の位置</font><b><font style="vertical-align: inherit;">は</font></b><font style="vertical-align: inherit;">ローカルで説明され</font><font style="vertical-align: inherit;">ているという事実にもかかわらず</font><font style="vertical-align: inherit;">、それらの欠点は、別の後処理ステップが必要になることです。文字を単語と行に接着するためのヒューリスティックを選択する必要があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、私たちは検出の基礎を取りました</font></font><b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SegLinkモデル</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、行/単語をさらに2つのローカルエンティティに分割することの主なアイデア：セグメントとそれらの間の関係。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">検出器のアーキテクチャ</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
モデルのアーキテクチャはSSDに基づいており、SSDはいくつかのスケールの機能でオブジェクトの位置を予測します。個々の「セグメント」の座標を予測することに加えて、隣接するセグメント間の「接続」、つまり2つのセグメントが同じ線に属しているかどうかも予測されます。 「接続」は、同じスケールの標識の隣接するセグメントと、隣接するスケールの隣接領域にあるセグメントの両方で予測されます（標識の異なるスケールのセグメントは、サイズがわずかに異なり、同じラインに属している場合があります）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
各スケールについて、各特徴セルは対応する「セグメント」に関連付けられています。</font><font style="vertical-align: inherit;">スケールl上のポイント（x、y）の</font><font style="vertical-align: inherit;">各セグメントs </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（x、y、l）</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">について、以下</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
が</font><font style="vertical-align: inherit;">トレーニングされます。</font><font style="vertical-align: inherit;">-p </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このセグメントがテキストかどうか。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
- X </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、Y </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、W </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、S</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、H </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、S</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、θ </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">S</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -ベースの座標と線分の傾きの角度のオフセット。</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
-l番目のスケール（L </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></sup><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s、s '</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、s'から{s </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（x '、y'、l）</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> } / s </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（x、y、l）</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">に</font><font style="vertical-align: inherit;">隣接するセグメントとの「接続」の存在に対するスコア8 </font><font style="vertical-align: inherit;">、ここでx –1≤x '≤x + 1、y – 1≤y'≤y + 1）; </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
-l-1スケール（L </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c </font></font></sup><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s、s '</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、s'から{s </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（x '、y'、l-1）</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> }に</font><font style="vertical-align: inherit;">隣接するセグメントとの「接続」の存在に対する4スコア</font><font style="vertical-align: inherit;">。ここで、2x≤x '≤2x + 1 、2y≤y '≤2y + 1）（これは、隣接するスケール上のフィーチャの次元が正確に2倍異なるために当てはまります）。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fn/ox/en/fnoxen3f1izpei9ecdbdl_eq2xk.png"><br>
<h5><sup><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SegLink Detector </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">セグメントのリンクによる自然画像内の</font></a><font style="vertical-align: inherit;">方向付けられた</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">テキストの検出</font></a><font style="vertical-align: inherit;">からの操作図</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"></font></a></sub></sup></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このような予測によれば、テキストである確率がしきい値αより大きいすべてのセグメントを頂点とし、確率がしきい値βより大きいすべての結合をエッジとすると、セグメントは連結されたコンポーネントを形成し、それぞれがテキストの線を表します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果として得られるモデルは</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">高い汎化能力を備えてい</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。ロシア語と英語のデータに対する最初のアプローチで訓練されたとしても、定性的には中国語とアラビア語のテキストが見つかりました。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10スクリプト</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
検出のためにすべての言語ですぐに機能するモデルを作成できた場合、行の認識のために、そのようなモデルを取得することははるかに困難です。したがって、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スクリプトごとに個別のモデル</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（キリル文字、ラテン語、アラビア語、ヘブライ語、ギリシャ語、アルメニア語、グルジア語、韓国語、タイ語）を使用することにしました。象形文字の交差が大きいため、中国語と日本語には別々の一般モデルが使用されます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクリプト全体に共通のモデルは、各言語の個別のモデルと1 p.p未満異なります。</font><font style="vertical-align: inherit;">品質。</font><font style="vertical-align: inherit;">同時に、1つのモデルの作成と実装は、たとえば25モデル（モデルでサポートされているラテン語の数）よりも簡単です。</font><font style="vertical-align: inherit;">しかし、すべての言語で英語が頻繁に存在するため、すべてのモデルは、メインスクリプトに加えてラテン文字を予測できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
認識に使用するモデルを理解するために、受け取った行が認識に使用できる10個のスクリプトの1つに属しているかどうかを最初に判断します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ラインに沿ってスクリプトを一意に決定できるとは限らないことに注意してください。</font><font style="vertical-align: inherit;">たとえば、数字または単一のラテン文字が多くのスクリプトに含まれているため、モデルの出力クラスの1つは「未定義」スクリプトです。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">スクリプト定義</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
スクリプトを定義するために、別の分類子を作成しました。</font><font style="vertical-align: inherit;">スクリプトを定義するタスクは、認識のタスクよりもはるかに単純であり、ニューラルネットワークは合成データで簡単に再トレーニングできます。</font><font style="vertical-align: inherit;">したがって、私たちの実験では</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、文字列認識問題の事前トレーニング</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">によって、モデルの品質が大幅に向上しました</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">これを行うには、まず、利用可能なすべての言語の認識問題についてネットワークをトレーニングしました。</font><font style="vertical-align: inherit;">その後、結果のバックボーンを使用して、モデルをスクリプト分類タスクに初期化しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
個々の行のスクリプトは非常にうるさいことがよくありますが、画像全体としては、英語が混在しているメイン（またはロシアのユーザーの場合）に加えて、ほとんどの場合、1つの言語のテキストが含まれています。</font><font style="vertical-align: inherit;">したがって</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">増加する</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">安定性のために、画像スクリプトのより安定した予測を得るために、画像からのラインの予測を集約します。</font><font style="vertical-align: inherit;">予測されたクラスが「不定」である行は、集計では考慮されません。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ライン認識</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
次のステップでは、各行とそのスクリプトの位置をすでに決定している場合、その</font><font style="vertical-align: inherit;">上に表示される</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">特定のスクリプトからの文字のシーケンス</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、つまりピクセルのシーケンスから</font><b><font style="vertical-align: inherit;">文字のシーケンス</font></b><font style="vertical-align: inherit;">を</font><b><font style="vertical-align: inherit;">認識して、文字</font></b><font style="vertical-align: inherit;">のシーケンスを予測する必要があります。多くの実験の後、次のシーケンス2シーケンス注意ベースモデルに</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_0/6k/sf/_06ksfdetbjobwudopmi4xq0j4c.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
到達しました。エンコーダーでCNN + BiLSTMを使用すると、ローカルコンテキストとグローバルコンテキストの両方をキャプチャする標識を取得できます。テキストの場合、これは重要です-多くの場合、1つのフォントで記述されます（フォント情報で同様の文字を区別する方がはるかに簡単です）。また、スペースで書かれた2つの文字を連続したものと区別するために、行のグローバル統計も必要です。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">興味深い観察</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：結果のモデルでは、特定のシンボルのアテンションマスクの出力を使用して、画像内のその位置を予測できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これ</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、モデルの注意</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><b><font style="vertical-align: inherit;">明確に「集中」</font></b><font style="vertical-align: inherit;">しようとする</font><b><font style="vertical-align: inherit;">きっかけになりました</font></b><font style="vertical-align: inherit;">。このようなアイデアは、記事「</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">フォーカシングの注意：自然画像での正確なテキスト認識に向けて</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">」などの記事で見つかりました</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
注意メカニズムは特徴空間全体に確率分布を与えるため、このステップで予測された文字に対応するマスク内の注意出力の合計を追加の損失として取ると、それに直接焦点を合わせる「注意」の部分が得られます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
損失-logとして入力する（Σ </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I、j∈M </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トン</font></font></sub></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> α </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I、J</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）、ここで、M</font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">はt番目の文字のマスク、αは注意の出力です。与えられたシンボルに焦点を合わせるための「注意」を奨励し、ニューラルネットワークの学習を支援します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
個々の文字の場所が不明または不正確なトレーニング例（すべてのトレーニングデータに、単語ではなく個々の文字のレベルでマーキングがあるわけではない）の場合、この用語は最終的な損失では考慮されませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
もう1つの優れた機能：このアーキテクチャにより、追加の変更なし</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">で右から左への線</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">の</font><b><font style="vertical-align: inherit;">認識</font></b><font style="vertical-align: inherit;">を予測できます</font><font style="vertical-align: inherit;">（これは、アラビア語、ヘブライ語などの言語では重要です）。</font><font style="vertical-align: inherit;">モデル自体が認識を右から左に発行し始めます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">高速モデルと低速モデル</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その過程で問題が発生しました。</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「背の高い」フォント</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、つまりフォントが垂直方向に伸びている場合、モデルの動作が不十分でした。これは、ネットワークの畳み込み部分のアーキテクチャのストライドとプルにより、注意レベルの標識の次元が元の画像の次元の8分の1であることが原因でした。そして、ソース画像内のいくつかの隣接する文字の位置は、同じ特徴ベクトルの位置に対応する可能性があり、そのような例ではエラーにつながる可能性があります。フィーチャーの次元をより狭くするアーキテクチャを使用すると、品質が向上するだけでなく、処理時間も長くなります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この問題を解決し</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">、処理時間の増加</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を</font><b><font style="vertical-align: inherit;">回避するため</font></b><font style="vertical-align: inherit;">に、モデルに次の改良を加えました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/po/pp/ob/poppobis-rbsdqtyrbgyaq8jzik.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ストライドの多い高速モデルとストライドの少ない低速モデルの両方をトレーニングしました。</font><font style="vertical-align: inherit;">モデルパラメーターが異なるようになったレイヤーに、認識エラーが少ないモデルを予測する別のネットワーク出力を追加しました。</font><font style="vertical-align: inherit;">モデルの総損失は、L </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">small</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> + L </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">big</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> + L </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">qualityで構成されていました</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">したがって、中間層では、モデルはこの例の「複雑さ」を決定することを学びました。</font><font style="vertical-align: inherit;">さらに、アプリケーション段階では、例の「複雑さ」の一般的な部分と予測がすべてのラインで考慮され、その出力に応じて、しきい値に従って、高速モデルまたは低速モデルが将来使用されました。</font><font style="vertical-align: inherit;">これにより、長いモデルの品質とほとんど変わらない品質が得られましたが、速度は推定30％ではなく5％しか増加しませんでした。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">トレーニングデータ</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
高品質のモデルを作成する上で重要な段階は、大規模で多様なトレーニングサンプルの準備です。</font><font style="vertical-align: inherit;">テキストの「合成」性質により、大量の例を生成し、実際のデータで適切な結果を得ることが可能になります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
合成データを生成する最初のアプローチの後、得られたモデルの結果を注意深く調べたところ、トレーニングセットの作成に使用されるテキストに偏りがあるため、モデルが1文字の「I」をうまく認識できないことがわかりました。</font><font style="vertical-align: inherit;">したがって、</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一連の「問題のある」例</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">を明確に生成し、</font><font style="vertical-align: inherit;">それをモデルの初期データに追加すると、品質が大幅に向上しました。</font><font style="vertical-align: inherit;">このプロセスを何度も繰り返し、ますます複雑なスライスを追加して、認識の品質を向上させました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
重要な点は、生成される</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">データは多様であり、実際のデータに類似している必要があるということ</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">です。また、モデルで紙のテキストの写真を処理し、合成データセット全体に風景の上に書かれたテキストが含まれている場合、これは機能しない可能性があります。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
別の重要なステップは、現在の認識が誤っている例をトレーニングするために使用することです。マークアップのない写真が多数ある場合は、現在の認識システムの出力が不明な出力を取得して、それらだけをマークすることで、マークアップのコストを削減できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
複雑な例については、Yandex.Tolokサービスのユーザーに有料で写真を撮って送っていただくようお願いしました</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">特定の「複雑な」グループの画像</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> -たとえば、商品のパッケージの写真：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/tm/zx/0k/tmzx0kmyswtdxz6u_ri_yfxdrzy.png" width="50%"><img src="https://habrastorage.org/webt/n9/pb/ru/n9pbrufm0gcwp8lggc9bk9kxaxe.png" width="50%"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">「複雑な」データに対する作業の質</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
本のページやスキャンしたドキュメントだけでなく、道路標識、広告、製品のパッケージのテキストも認識または翻訳する必要がある場合があるため、複雑な写真を扱う機会をユーザーに提供したいと考えています。したがって、本や文書の流れに関する作業の質を高く維持しながら（このトピックには別の話をします）、「複雑な画像のセット」に特に注意を払います。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
上記の方法で、ユーザーに役立つ可能性のある野生のテキストを含む一連の画像をまとめました。看板の写真、お知らせ、タブレット、本の表紙、家電製品のテキスト、服、およびオブジェクトです。このデータセット（以下のリンク）で、アルゴリズムの品質を評価しました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
比較のための測定基準として、データセット内の単語認識の正確さと完全性の標準的な測定基準と、Fメジャーを使用しました。</font><font style="vertical-align: inherit;">認識された単語は、その座標がマークアップされた単語の座標（IoU&gt; 0.3）に対応し、認識がマークされたケースと正確に一致する場合、正しく検出されたと見なされます。</font><font style="vertical-align: inherit;">結果のデータセットに関する図：</font></font><br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">認識システム</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">完全</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">正確さ</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fメジャー</font></font></td>
</tr>
<tr>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex Vision</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">73.99</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">86.57</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">79.79</font></font></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果を再現するためのデータセット、指標、スクリプトは、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こちらから</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">入手でき</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
更新。</font><font style="vertical-align: inherit;">友人たち、私たちのテクノロジーをアビーの類似のソリューションと比較すると、多くの論争が起こりました。</font><font style="vertical-align: inherit;">私たちは、コミュニティや業界の仲間の意見を尊重します。</font><font style="vertical-align: inherit;">しかし同時に、結果には自信があるので、この方法で決定しました。比較から他の製品の結果を削除し、それらとテスト方法について再度話し合い、一般的な合意に達した結果に戻ります。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">次のステップ</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
検出や認識などの個々のステップの合流点では、常に問題が発生します。検出モデルのわずかな変更でも認識モデルを変更する必要があるため、エンドツーエンドのソリューションの作成を積極的に試みています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
すでに説明した技術を改善する方法に加えて、ドキュメント構造の分析の方向性を開発します。これは、情報を抽出するときに基本的に重要であり、ユーザーの間で要求されます。</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">結論</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ユーザーはすでに便利なテクノロジーに慣れており、迷うことなくカメラの電源を入れ、店の看板、レストランのメニュー、または外国語の本のページをポイントすると、すぐに翻訳を受け取ります。私たちは45の言語のテキストを正確な精度で認識し、機会は拡大するだけです。 Yandex.Cloud内の一連のツールを使用すると、Yandexが長年にわたって行ってきたベストプラクティスを使用したいすべての人が利用できます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
今日では、完成したテクノロジーを独自のアプリケーションに統合し、それを使用して新しい製品を作成し、独自のプロセスを自動化できます。 OCRのドキュメントは</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">こちらから</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">入手でき</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">ます</font></a><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
何を読む：</font></font><br>
<br>
<ol>
<li><a name="karatzas1"></a>D. Karatzas, S. R. Mestre, J. Mas, F. Nourbakhsh, and P. P. Roy, “ICDAR 2011 robust reading competition-challenge 1: reading text in born-digital images (web and email),” in Document Analysis and Recognition (ICDAR), 2011 International Conference on. IEEE, 2011, pp. 1485–1490.</li>
<li><a name="karatzas2"></a>Karatzas D. et al. ICDAR 2015 competition on robust reading //2015 13th International Conference on Document Analysis and Recognition (ICDAR). – IEEE, 2015. – . 1156-1160.</li>
<li><a name="chng"></a>Chee-Kheng Chng et. al. ICDAR2019 Robust Reading Challenge on Arbitrary-Shaped Text (RRC-ArT) [<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">arxiv:1909.07145v1</a>] </li>
<li><a name="icdar2019"></a>ICDAR 2019 Robust Reading Challenge on Scanned Receipts OCR and Information Extraction <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">rrc.cvc.uab.es/?ch=13</a></li>
<li><a name="shopsign"></a>ShopSign: a Diverse Scene Text Dataset of Chinese Shop Signs in Street Views [<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">arxiv:1903.10412</a>]</li>
<li><a name="seglink"></a>Baoguang Shi, Xiang Bai, Serge Belongie Detecting Oriented Text in Natural Images by Linking Segments [<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">arxiv:1703.06520</a>].</li>
<li><a name="focusing"></a>Zhanzhan Cheng, Fan Bai, Yunlu Xu, Gang Zheng, Shiliang Pu, Shuigeng Zhou Focusing Attention: Towards Accurate Text Recognition in Natural Images [<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u=">arxiv:1709.02054</a>].</li>
</ol></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja475940/index.html">Vueストアフロント：2番目のシェルアプローチ</a></li>
<li><a href="../ja475942/index.html">OAuthおよびOpenID Connect Guideの図解</a></li>
<li><a href="../ja475944/index.html">ランニングは、よりリモートな人にとって理想的なスポーツです。パート2：物理学と材料</a></li>
<li><a href="../ja475948/index.html">JHレインウォーター「猫の放牧方法」（パート2）：習得する必要のあるすべてのこと</a></li>
<li><a href="../ja475950/index.html">ロボットがゴルフボールの収集に限定するのはなぜですか？テニスもあります</a></li>
<li><a href="../ja475958/index.html">ITの少女が集まった物語</a></li>
<li><a href="../ja475968/index.html">興味深いニュースVue 3</a></li>
<li><a href="../ja475974/index.html">電車でハッカソンを作った方法とそれから来たもの</a></li>
<li><a href="../ja475978/index.html">電車の本部は何のためですか？</a></li>
<li><a href="../ja475980/index.html">接続性、アーキテクチャ、チーム編成が低い</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå≠ ‚öóÔ∏è üßëüèº‚Äçü§ù‚Äçüßëüèº MASK-RCNN for finding roofs from drone images üë©üèº‚ÄçüöÄ üì° üòÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In a white and white city on a white and white street there were white and white houses ... And how quickly can you find all the roofs of houses in th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>MASK-RCNN for finding roofs from drone images</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/500752/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ad9/eb5/21e/ad9eb521e7c2fcb232116aa876742ee3.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In a white and white city on a white and white street there were white and white houses ... And how quickly can you find all the roofs of houses in this photo? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Increasingly, one can hear about the government‚Äôs plans to conduct a complete inventory of real estate in order to clarify cadastral data. For the primary solution to this problem, a simple method can be applied based on the calculation of the roof area of ‚Äã‚Äãcapital buildings from aerial photographs and further comparison with cadastral data. Unfortunately, manual search and calculation takes a lot of time, and since new houses are demolished and built continuously, the calculation needs to be repeated again and again. The hypothesis immediately arises that this process can be automated using machine learning algorithms, in particular, Computer Vision. In this article I will talk about how we are at </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NORBIT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> solved this problem and what difficulties they encountered.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Spoiler - we </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">did it</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">The ML service developed is based on a deep machine learning model based on convolution neural networks. </font><font style="vertical-align: inherit;">The service accepts images from unmanned aerial vehicles as an input; at the output, it generates a GeoJSON file with the markup of found capital construction objects with reference to geographical coordinates. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, it looks like this:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/892/528/0ab892528db9a5c84fd26d0e30329b5a.png"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Problems</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's start with the technical problems we encountered:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">there is a significant difference between winter and summer aerial photographs (a model trained only in summer photographs is completely unable to find roofs in winter);</font></font></li>
<li>            ,       ;</li>
<li>  ,          (  ),     (     )      ,           ;</li>
<li>   ,     ,         (     ).        ;</li>
<li>  (,   )     .</li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And drones sometimes bring these photos:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/663/809/821/66380982148bc07c8309f8d106ecfc38.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I would also like to note the problems that could have been, but we did not touch:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">we had no task to perform inference for a limited time (for example, directly at the time of the flight), which immediately solved all possible problems with performance;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">at the input for processing, we immediately received high-quality high-resolution images (using lenses with a focal length of 21 mm at a height of 250 m, which is 5 cm / px) from our customer, the Shakhty company, could use their expertise in the geolocation of objects on maps, and they also had the opportunity to establish a specific set of requirements for future UAV flights, which ultimately greatly reduced the likelihood of very unique tiles that were not in the training set;</font></font></li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The first solution to the problem, stroke using the Boundary box&nbsp;</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A few words about what tools we used to create the solution.</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anaconda is a convenient package management system for Python and R.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tensorflow is an open source machine learning software library developed by Google.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keras is an add-on for the frameworks Deeplearning4j, TensorFlow and Theano.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV is a library of algorithms for computer vision, image processing, and general-purpose open-source numerical algorithms.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Flask is a framework for creating web applications in the Python programming language.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As the OS used Ubuntu 18.04. </font><font style="vertical-align: inherit;">With drivers on the GPU (NVIDIA) in Ubuntu, everything is in order, so the task is usually solved with one command:</font></font><br>
<br>
<code>&gt; sudo apt install nvidia-cuda-toolkit</code><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tile Preparation</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first task we faced was to split the flyby images into tiles (2048x2048 px). </font><font style="vertical-align: inherit;">You could write your own script, but then you would have to think about maintaining the geographical location of each tile. </font><font style="vertical-align: inherit;">It was easier to use a ready-made solution, for example, GeoServer - it is open source software that allows you to publish geodata on the server. </font><font style="vertical-align: inherit;">In addition, GeoServer solved another problem for us - convenient display of the result of automatic marking on the map. </font><font style="vertical-align: inherit;">This can be done locally, for example, in qGIS, but for a distributed command and demonstration, a web resource is more convenient. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To perform tiling, you need to specify the required scale and size in the settings.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/688/b29/4d1/688b294d129f14dddc810ca0defdef44.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For translations between coordinate systems, we used the pyproj library:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> pyproj <span class="hljs-keyword">import</span> Proj, transform<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Converter</span>:</span>
&nbsp;&nbsp;&nbsp;&nbsp;P3857 = Proj(init=<span class="hljs-string">'epsg:3857'</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;P4326 = Proj(init=<span class="hljs-string">'epsg:4326'</span>)<font></font>
...<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_3857_to_GPS</span>(<span class="hljs-params">self, point</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x, y = point<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> transform(self.P3857, self.P4326, x, y)
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_GPS_to_3857</span>(<span class="hljs-params">self, point</span>):</span><font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x, y = point<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">return</span> transform(self.P4326, self.P3857, x, y)<font></font>
...</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, it was possible to easily form one large layer from all the polygons and lay it on top of the substrate.&nbsp;</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b8/9f6/428/2b89f642889bdc551871a35ba43a7c03.png"></div><br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To install GeoServer software, you must complete the following steps.</font></font></b>
                        <div class="spoiler_text"><ol>
<li> Java  8.</li>
<li> GeoServer.       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="> </a></li>
<li>     , ,&nbsp;<code>/usr/share/geoserver</code></li>
<li>      &nbsp;<br>
<br>
<strong><code>echo ¬´export GEOSERVER_HOME=/usr/share/geoserver¬ª &gt;&gt; ~/.profile</code></strong></li>
<li>   :<br>
<br>
<strong><code>sudo groupadd geoserver</code></strong></li>
<li> ,     ,   :<br>
<br>
<strong><code>sudo usermod -a -G geoserver &lt;user_name&gt;</code></strong></li>
<li> -  :<br>
<br>
<strong><code>sudo chown -R :geoserver /usr/share/geoserver/</code></strong></li>
<li>    :<br>
<br>
<strong><code>sudo chmod -R g+rwx /usr/share/geoserver/</code></strong></li>
<li> GeoServer&nbsp;<br>
<br>
<strong><code>cd geoserver/bin &amp;&amp; sh startup.sh</code></strong></li>
</ol></div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
GeoServer is not the only application that allows us to solve our problem. </font><font style="vertical-align: inherit;">As an alternative, for example, you can consider ArcGIS for Server, but this product is proprietary, so we did not use it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, each tile had to find all the visible roofs. </font><font style="vertical-align: inherit;">The first approach to solving the problem was to use the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">object_detection</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> from the models / research Tensorflow set. </font><font style="vertical-align: inherit;">In this way, classes on images can be found and localized with a rectangular selection (boundary box).&nbsp;</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Training data markup&nbsp;</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obviously, for training the model you need a labeled dataset. By a lucky coincidence, in addition to circling around, in our bins the dataset for 50 thousand roofs was preserved from the good old days, when all datasets for training were still in the public domain everywhere. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The exact size of the training sample required to obtain acceptable model accuracy is rather difficult to predict in advance. It can vary depending on the quality of the images, their degree of dissimilarity to each other, and the conditions in which the model will be used in production. We had cases when 200 pieces were enough, and sometimes 50 thousand marked samples were also missing. In the event of a shortage of marked-up images, we usually add augmentation methods: turns, mirror reflections, color grading, etc.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now there are many services available that allow you to mark up images - both with open source code for installation on your computer / server, and corporate solutions that include the work of external assessors, for example Yandex.Tolok. </font><font style="vertical-align: inherit;">In this project, we used the simplest </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VGG Image Annotator</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Alternatively, you can try </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">coco-annotator</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> or </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">label-studio</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">We usually use the latter for marking up text and audio files.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5b1/46b/39c/5b146b39c6413ebde30c1a0a6f25421a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For training on markup of various annotators, you usually need to perform a small shift of fields, an example for </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VGG</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order to correctly calculate the area of ‚Äã‚Äãthe roof that fell into the area of ‚Äã‚Äãrectangular allocation, it is necessary to observe several conditions:</font></font><br>
<br>
<ul>
<li>     /     .          :</li>
</ul><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b0c/41a/80e/b0c41a80e0ae785794143da7b38dfbbf.png"></div><br>
<ul>
<li>,    ,      :</li>
</ul><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/092/1de/dcb/0921dedcbc4effc0430d11cd8dea8401.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To solve the second problem, you can try to train a separate model that would determine the correct angle of rotation of the tile for marking, but everything turned out a little easier. </font><font style="vertical-align: inherit;">People themselves strive to reduce entropy, so they align all man-made structures in relation to each other, especially with dense buildings. </font><font style="vertical-align: inherit;">If you look from above, then in a localized area, fences, walkways, planting, greenhouses, arbors will be parallel or perpendicular to the boundaries of the roofs. </font><font style="vertical-align: inherit;">It remains only to find all the clear lines and calculate the most common angle of inclination to the vertical. </font><font style="vertical-align: inherit;">For this, OpenCV has a great HoughLinesP tool.&nbsp;</font></font><br>
<br>
<pre><code class="python hljs">...<font></font>
<font></font>
lines = cv2.HoughLinesP(edges, <span class="hljs-number">1</span>, np.pi/<span class="hljs-number">180</span>, <span class="hljs-number">50</span>, minLineLength=minLineLength, maxLineGap=<span class="hljs-number">5</span>)
<span class="hljs-keyword">if</span> lines <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;length = image.shape[<span class="hljs-number">0</span>]<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;angles = []<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> x1, y1, x2, y2 <span class="hljs-keyword">in</span> lines[<span class="hljs-number">0</span>]:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;angle = math.degrees(math.atan2(y2 ‚Äî y1, x2 - x1))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;angles.append(angle)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;parts_angles.append(angles)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;median_angle = np.median(angles)<font></font>
...<font></font>
<font></font>
<span class="hljs-comment">#    &nbsp;</span><font></font>
<font></font>
<span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, image.shape[<span class="hljs-number">0</span>]<span class="hljs-number">-1</span>, image.shape[<span class="hljs-number">0</span>] // count_crops):
&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, image.shape[<span class="hljs-number">1</span>]<span class="hljs-number">-1</span>, image.shape[<span class="hljs-number">1</span>] // count_crops):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;get_line(image[x:x+image.shape[<span class="hljs-number">0</span>]//count_crops, y:y+image.shape[<span class="hljs-number">1</span>]//count_crops, :])<font></font>
...<font></font>
<font></font>
<span class="hljs-comment">#      </span><font></font>
<font></font>
np.median([a <span class="hljs-keyword">if</span> a&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">90</span>+a <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> np.array(parts_angles).flatten()])</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
After finding the angle, we rotate the image using the affine transformation:</font></font><br>
<br>
<pre><code class="python hljs">
h, w = image.shape[:<span class="hljs-number">2</span>]<font></font>
image_center = (w/<span class="hljs-number">2</span>, h/<span class="hljs-number">2</span>)<font></font>
<font></font>
<span class="hljs-keyword">if</span> size <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;radians = math.radians(angle)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;sin = math.sin(radians)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;cos = math.cos(radians)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;size = (int((h * abs(sin)) + (w * abs(cos))), int((h * abs(cos)) + (w * abs(sin))))<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;rotation_matrix = cv2.getRotationMatrix2D(image_center, angle, <span class="hljs-number">1</span>)<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;rotation_matrix[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>] += ((size[<span class="hljs-number">0</span>] / <span class="hljs-number">2</span>) ‚Äî image_center[<span class="hljs-number">0</span>])<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;rotation_matrix[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>] += ((size[<span class="hljs-number">1</span>] / <span class="hljs-number">2</span>) ‚Äî image_center[<span class="hljs-number">1</span>])
<span class="hljs-keyword">else</span>:<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;rotation_matrix = cv2.getRotationMatrix2D(image_center, angle, <span class="hljs-number">1</span>)<font></font>
<font></font>
cv2.warpAffine(image, rotation_matrix, size)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The full example code is </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Here's what it looks like:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b2/032/15c/2b203215c7a688dc7639e7993643a99e.png"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/594/423/c1b/594423c1b3e52a8e4fcd383b20a04b05.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The method of turning tiles and marking with rectangles works faster than marking with masks, almost all roofs are found, but in production this method is used only as an auxiliary one due to several drawbacks:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">there are many overflights where there are a large number of non-rectangular roofs, because of this there is too much manual work to refine the area,</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sometimes found at home with different orientations on the same tile,</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sometimes there are many false lines on the tiles, which ultimately leads to a wrong turn. </font><font style="vertical-align: inherit;">It looks like this:</font></font></li>
</ul><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d4/ba0/30c/6d4ba030c0784c6ee7366486b3a8f03c.png"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/691/5fd/a10/6915fda10769dc9b5d96522737d6aef6.png"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The final solution based on Mask-RCNN</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The second attempt was to search for and highlight roofs by masks pixel by pixel, and then automatically outline the contours of the masks found and create vector polygons.&nbsp;&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
There are already enough materials on the principles of operation, types and tasks of convolutional neural networks, including those in Russian, so we will not go into them in this article. Let us dwell only on one specific implementation, Mask-RCNN - an architecture for localizing and highlighting the contours of objects in images. There are other excellent solutions with their advantages and disadvantages, for example, UNet, but it was possible to achieve better quality on Mask-RCNN.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the process of its development, it went through several stages. The first version of R-CNN was developed in 2014. The principle of its work is to highlight small areas in the image, for each of which an estimate is made of the probability of the presence of a target object in this area. R-CNN did an excellent job with the task, but its speed left much to be desired. The logical development was the Fast R-CNN and Faster R-CNN networks, which received improvements in the image crawl algorithm, which allowed to significantly increase the speed. At the exit to Faster R-CNN, a marking appears with a rectangular selection indicating the boundaries of the object, which is not always enough to solve the problem.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mask R-CNN also adds a pixel-by-pixel mask overlay to get the exact outline of the object.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The boundary box and masks can be clearly seen on the result of the model's operation (the filter by the minimum building area is enabled):</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d6e/d0c/756/d6ed0c7567ed2894bbe11161fc91af55.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conventionally, there are 4 stages in the operation of this network:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">standard for all convolutional neural networks, the allocation of features in the image, such as lines, bends, contrasting boundaries and others;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Region Proposal Network (RPN) scans small fragments of the image, called anchors (anchors) and determines whether this anchor contains signs characteristic of the target class (in our case, the roof);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Region of Interest Classification and Bounding Box. </font><font style="vertical-align: inherit;">At this stage, the network, based on the results of the previous stage, is trying to highlight large rectangular areas in the photograph, presumably containing the target object;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Segmentation Masks. </font><font style="vertical-align: inherit;">At this stage, the mask of the desired object is obtained from the rectangular area obtained by applying the boundary box.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition, the network turned out to be very flexible in configuration, and we were able to rebuild it to process images with additional information layers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The use of exclusively RGB images did not allow us to achieve the necessary recognition accuracy (the model missed entire buildings, there was an average error of 15% in calculating the roof area), so we supplied the model with additional useful data, for example, height maps obtained by </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">photogrammetry.</font></font></a>&nbsp;<br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7cc/801/ac8/7cc801ac8060a3b99a2bb26415d2fe38.png"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Metrics used to evaluate model quality</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When determining the quality of models, we most often used the Intersection over Union (IoU) metric</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8cc/486/5be/8cc4865be494cc0bee045c618df9ff59.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sample code for calculating IoU using geometry.shapely library:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> shapely.geometry <span class="hljs-keyword">import</span> Polygon<font></font>
<font></font>
true_polygon = Polygon([(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">6</span>), (<span class="hljs-number">5</span>, <span class="hljs-number">6</span>), (<span class="hljs-number">5</span>, <span class="hljs-number">2</span>)])<font></font>
predicted_polygon = Polygon([(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">7</span>), (<span class="hljs-number">6</span>, <span class="hljs-number">7</span>), (<span class="hljs-number">6</span>, <span class="hljs-number">3</span>)])<font></font>
print(true_polygon.intersection(predicted_polygon).area / true_polygon.union(predicted_polygon).area)<font></font>
<font></font>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.3333333333333333</span>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tracking the training process of models is conveniently controlled using Tensorboard, a convenient metric control tool that allows you to receive real-time data on model quality and compare them with other models.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/31c/a7a/b20/31ca7ab20d4583360b3058b59277bc10.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tensorboard provides data on many different metrics. </font><font style="vertical-align: inherit;">The most interesting for us are:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">val_mrcnn_bbox_loss - shows how well the model locates objects (i.e. imposes a boundary box);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">val_mrcnn_mask_loss - shows how well the model segments objects (i.e. imposes a mask).</font></font></li>
</ul><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model training and validation</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When training, we used the standard practice of randomly dividing a dataset into 3 parts - training, validation and test. In the learning process, the quality of the model is evaluated on a validation sample, and upon completion passes the final test on test data that were closed from it in the learning process.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We did our first training starts on a small set of summer shots and, deciding to check how good our model will be in winter, we expectedly received a disappointing result. </font><font style="vertical-align: inherit;">The option of using different models for different seasons, of course, is an excellent way out of the situation, but it would entail a number of inconveniences, so we decided to try to make the model universal. </font><font style="vertical-align: inherit;">By experimenting with different configurations of the layers, and also closing the weight of individual layers from changes in weight, we found the optimal strategy for training the model by applying alternately summer and winter pictures to the input.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creating a background service for recognition</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now that we have a functioning model, we can make a background API service from a recognition script that takes an image as input and generates json with roof polygons found at the output. </font><font style="vertical-align: inherit;">This does not directly affect the solution of the problem, but it may be useful to someone.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ubuntu uses systemd, and an example will be given specifically for this system. </font><font style="vertical-align: inherit;">The code of the service itself can be viewed </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">User units are located in the / etc / systemd / system directory, where we will create our service file. </font><font style="vertical-align: inherit;">
Edit the file:</font></font><br>
<br>
<code>cd /etc/systemd/system<br>
<br>
sudo touch my_srv.service</code><br>
<br><font style="vertical-align: inherit;"></font><br>
<br>
<pre><code class="bash hljs">sudo vim my_srv.service
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The systemd unit consists of three sections:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[Unit] - describes the order and condition of the start (for example, you can tell the process to wait for the start of a certain service and only then start it yourself);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[Service] - describes startup parameters;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[Install] - describes the behavior of the service when adding it to startup.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result, our file will look like this:</font></font><br>
<br>
<pre><code class="bash hljs">[Unit]<font></font>
Description=my_test_unit<font></font>
<font></font>
[Service]<font></font>
WorkingDirectory=/home/user/test_project<font></font>
User=root<font></font>
ExecStart=/home/user/test_project/venv/bin/python3 /home/user/test_project/script.py<font></font>
<font></font>
[Install]<font></font>
WantedBy=multi-user.target<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now reload the systemd configuration and run our service:</font></font><br>
<br>
<pre><code class="bash hljs">sudo systemctl daemon-reload<font></font>
sudo systemctl start my_srv.service<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
This is a simple example of a background process, systemd supports many different parameters that allow you to flexibly configure the behavior of the service, but nothing more complicated is required for our task.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">findings</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main result of the project was the ability to automatically detect inconsistencies in the actual development and information contained in the cadastral data. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As a result of evaluating the accuracy of the model on the test data, the following values ‚Äã‚Äãwere obtained: the number of found roofs - 91%, the accuracy of the roof outline polygons - 94%. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
It was possible to achieve an acceptable quality of the models in summer and winter flights, but the recognition quality may decrease in the pictures immediately after a snowfall. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Now even the Sydney Opera House will not slip away from the eyes of our model.&nbsp;</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/zs/c1/yl/zsc1yl0dgkkhjahgjk3vssn8swc.jpeg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We plan to put this service with a trained model on our demostand. </font><font style="vertical-align: inherit;">If you are interested in trying the service on your own photos, send applications to ai@norbit.ru.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en500732/index.html">Artificial intelligence and the crisis of theories of consciousness</a></li>
<li><a href="../en500734/index.html"># GitLab 12.10 released with requirements management and automatic CI scaling on AWS Fargate</a></li>
<li><a href="../en500742/index.html">Clustering Quality Assessment: Properties, Metrics, GitHub Code</a></li>
<li><a href="../en500744/index.html">‚ÄúTo hear you better, my speaker‚Äù: how to broadcast better from home</a></li>
<li><a href="../en500746/index.html">Boxing rack for SMD and other small things</a></li>
<li><a href="../en500754/index.html">How to become a dollar millionaire in 30 years, lying on the couch</a></li>
<li><a href="../en500756/index.html">Remote All-Power. How does streaming at JUG Ru Group online conferences work?</a></li>
<li><a href="../en500758/index.html">Key trends in the cybersecurity and information security market 2020-2021 versus forecast 2019-2020</a></li>
<li><a href="../en500760/index.html">How to kill zombies more efficiently with ZeroTier</a></li>
<li><a href="../en500764/index.html">Draw a speech: Software Automatic Mouth</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
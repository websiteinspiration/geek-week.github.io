<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöë üë© üöÜ Ihr erster BERT: Eine illustrierte Anleitung ü§üüèø üêã ‚ôèÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Fortschritte beim maschinellen Lernen f√ºr die Verarbeitung nat√ºrlicher Sprachen haben sich in den letzten Jahren erheblich beschleunigt. Models ve...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Ihr erster BERT: Eine illustrierte Anleitung</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/498144/"><p><img src="https://habrastorage.org/webt/1t/0s/2u/1t0s2udwz_c-rqf3jvlxkigemhm.png" alt="Bert-Distilbert-Satz-Klassifikation"></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Fortschritte beim maschinellen Lernen f√ºr die Verarbeitung nat√ºrlicher Sprachen haben sich in den letzten Jahren erheblich beschleunigt. Models verlie√üen die Forschungslabors und wurden zur Grundlage f√ºhrender digitaler Produkte. Ein gutes Beispiel daf√ºr ist die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k√ºrzlich erfolgte Ank√ºndigung, dass das BERT-Modell zur Hauptkomponente der Google-Suche geworden ist</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Google ist der Ansicht, dass dieser Schritt (dh die Einf√ºhrung eines fortschrittlichen Modells zum Verst√§ndnis der nat√ºrlichen Sprache in der Suchmaschine) "den gr√∂√üten Durchbruch in den letzten f√ºnf Jahren und einen der bedeutendsten in der Geschichte der Suchmaschinen" darstellt.</font></font></p><br>
<p>  ‚Äì         BERT'   . ,  ,         ,     ,    .</p><br>
<p>     ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"></a>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb" rel="nofollow">Colab</a>.</p><a name="habracut"></a><br>
<h1 id="dannye-sst2">: SST2</h1><br>
<p>        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">SST2</a>,      ,        ( 1),   ( 0):</p><br>
<p><img src="https://habrastorage.org/webt/zn/el/tu/zneltu_kmrm0a2l1duybrs6ust8.png" alt="sst2"></p><br>
<h1 id="modeli-klassifikaciya-tonalnosti-predlozheniy">:   </h1><br>
<p>  ‚Äì  ,     ( ,     )    1 (      ),  0 ( ).      :</p><br>
<p><img src="https://habrastorage.org/webt/f4/mk/px/f4mkpxxli5t3izoldbz2qzfucei.png" alt="Stimmungsklassifikator-1.png"></p><br>
<p>        :</p><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">DistilBERT</a>          . DistilBERT     BERT',         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">HuggingFace</a>.       ,       .</li>
<li>  ‚Äì      scikit learn,     DistilBERT'        (1  0 ).</li>
</ul><br>
<p>,      ,     768.      ,     .</p><br>
<p><img src="https://habrastorage.org/webt/0v/2c/2f/0v2c2fzigdyzff3vqurbanyc2tk.png" alt="distilbert-bert-sentiment-classifier.png"></p><br>
<p> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BERT, ELMO     (  NLP   )</a>:       (     [CLS]).</p><br>
<h1 id="obuchenie-modeli"> </h1><br>
<p>  ,     ,      .   DistilBERT',         .       ,     ,     ¬´¬ª BERT',       .   ,     ,  BERT       ,   [CLS] . ,         ,    .   ,   , BERT           . </p><br>
<p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">transformers</a>   DistilBERT',     .</p><br>
<p><img src="https://habrastorage.org/webt/lx/du/gi/lxdugirbo9cgxehjoggycphulr8.png" alt="Modelltraining"></p><br>
<h1 id="obzor-rukovodstva"> </h1><br>
<p>,    .     DistilBERT'     2  .</p><br>
<p><img src="https://habrastorage.org/webt/bb/uv/_t/bbuv_tdc97jm9upvgj1gcyefemy.png" alt="Bert-Distilbert-Tutorial-Satz-Einbettung"></p><br>
<p>       DistilBERT'.       Scikit Learn. ,  ,         :</p><br>
<p><img src="https://habrastorage.org/webt/r_/e3/mq/r_e3mqtxvjry5xoabovb7il_iec.png" alt="Bert-Distilbert-Zug-Test-Split-Satz-Einbettung"></p><br>
<p><em>        distilBERT' ( #1)   ,           ( #2).   ,    sklearn    ,    ,      75%  ,       </em></p><br>
<p>       :</p><br>
<p><img src="https://habrastorage.org/webt/wn/f6/9k/wnf69kgqr5azls-edvk6gidjoui.png" alt="Bert-Training-Logistik-Regression"></p><br>
<h1 id="kak-vychislyaetsya-predskazannoe-znachenie">   </h1><br>
<p>       ,   ,    ,      .</p><br>
<p>    ¬´a visually stunning rumination on love¬ª.     BERT'  ,     .    ,      (   [CLS]     [SEP]   ).</p><br>
<p><img src="https://habrastorage.org/webt/rd/cu/me/rdcumeyavzwbbbleog8_tv1y0o8.png" alt="Bert-Distilbert-Tokenization-1"></p><br>
<p>          ,       .         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Word2vec  </a>.</p><br>
<p><img src="https://habrastorage.org/webt/-8/o5/tv/-8o5tv8c37kuyvnzvgcr9dt6vam.png" alt="Bert-Distilbert-Tokenization-2-Token-IDs"></p><br>
<p>        :</p><br>
<pre><code class="python hljs">tokenizer.encode(<span class="hljs-string">"a visually stunning rumination on love"</span>, add_special_tokens=<span class="hljs-literal">True</span>)</code></pre><br>
<p>          DistilBERT'.</p><br>
<p>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BERT, ELMO     (  NLP   )</a>,      :</p><br>
<p><img src="https://habrastorage.org/webt/3u/i-/gl/3ui-glcku_tpcg8cjoghffb0vt0.png"></p><br>
<h1 id="prohodya-cherez-distilbert">  DistilBERT</h1><br>
<p>     DistilBERT'   ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> BERT'</a>.        ,   768    .</p><br>
<p><img src="https://habrastorage.org/webt/oq/nf/ip/oqnfip8zglclubfblimrqvwrdz8.png" alt="Bert-Modell-Eingabe-Ausgabe-1"></p><br>
<p>      ,   ,    (  [CLS] ).           .</p><br>
<p><img src="https://habrastorage.org/webt/vr/-x/my/vr-xmyzsavuid9mrskzpysxbvhw.png" alt="bert-model-calssification-output-vector-cls"></p><br>
<p>        ,        ,      .         :</p><br>
<p><img src="https://habrastorage.org/webt/jm/oy/or/jmoyorskol1nxvxarefclben_ky.png" alt="bert-distilbert-satz-klassifikationsbeispiel"></p><br>
<p>     ,        .</p><br>
<h1 id="kod"></h1><br>
<p>          .        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Colab</a>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">github</a>.</p><br>
<p>    :</p><br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> transformers <span class="hljs-keyword">as</span> ppb <span class="hljs-comment"># pytorch transformers</span>
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split</code></pre><br>
<p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"></a>    github,          pandas:</p><br>
<pre><code class="python hljs">df = pd.read_csv(<span class="hljs-string">'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv'</span>, delimiter=<span class="hljs-string">'\t'</span>, header=<span class="hljs-literal">None</span>)</code></pre><br>
<p>  df.head()  ,    5    ,     :</p><br>
<pre><code class="python hljs">df.head()</code></pre><br>
<p><img src="https://habrastorage.org/webt/t2/-_/tl/t2-_tljwx7gvvwsoqs3hlt6w7ya.png" alt="sst2-df-head"></p><br>
<h1 id="zagruzka-predobuchennoy-modeli-distilbert-i-tokenizatora">   DistilBERT  </h1><br>
<pre><code class="python hljs">model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, <span class="hljs-string">'distilbert-base-uncased'</span>)<font></font>
<font></font>
<span class="hljs-comment">##  BERT  distilBERT?   :</span>
<span class="hljs-comment">#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')</span><font></font>
<font></font>
<span class="hljs-comment">#   / </span><font></font>
tokenizer = tokenizer_class.from_pretrained(pretrained_weights)<font></font>
model = model_class.from_pretrained(pretrained_weights)</code></pre><br>
<p>     .  ,        ,     .     .             (          ,  2000).</p><br>
<h1 id="tokenizaciya"></h1><br>
<pre><code class="python hljs">tokenized = df[<span class="hljs-number">0</span>].apply((<span class="hljs-keyword">lambda</span> x: tokenizer.encode(x, add_special_tokens=<span class="hljs-literal">True</span>)))</code></pre><br>
<p>       .</p><br>
<p><img src="https://habrastorage.org/webt/le/zs/gr/lezsgrmkronylp8wh-kays3c0c8.png" alt="sst2-text-to-tokenized-ids-bert-beispiel"></p><br>
<p>      (  Series/DataFrame  pandas) .   DistilBERT    ,               0 (padding).   ,      ( ,            Python).</p><br>
<p> ,   /,    BERT':</p><br>
<p><img src="https://habrastorage.org/webt/u7/uz/ma/u7uzma5jjkbif--qi60zgb0xyy8.png" alt="Bert-Input-Tensor"></p><br>
<h1 id="obrabotka-v-distilberte">  DistilBERT'</h1><br>
<p>           DistilBERT.</p><br>
<pre><code class="python hljs">input_ids = torch.tensor(np.array(padded))<font></font>
<font></font>
<span class="hljs-keyword">with</span> torch.no_grad():<font></font>
    last_hidden_states = model(input_ids)</code></pre><br>
<p>     <strong>last_hidden_states</strong>    DistilBERT',      ( ,     ,      DistilBERT).   ,   2000 (..    2000 ), 66 (          2000 ), 278 (     DistilBERT).</p><br>
<p><img src="https://habrastorage.org/webt/yi/bf/lp/yibflpzn_dbzi72nvns_q92gaqw.png" alt="Bert-Distilbert-Output-Tensor-Vorhersagen"></p><br>
<h1 id="raspakovka-vyhodnogo-tenzora-berta">   BERT'</h1><br>
<p>   3-d  .       :</p><br>
<p><img src="https://habrastorage.org/webt/kq/cr/k1/kqcrk198-zwu5t10mtsq4pxri3i.png" alt="Bert-Output-Tensor"></p><br>
<h1 id="puteshestvie-podhodit-k-koncu">   </h1><br>
<p>       .        :</p><br>
<p><img src="https://habrastorage.org/webt/ie/a4/ob/iea4ob8zt474ku1j4uw1uthupdq.png" alt="Bert-Input-Output-Tensor-Recap"></p><br>
<h1 id="poluchenie-samoy-vazhnoy-chasti">   </h1><br>
<p>       BERT'   [CLS].          .</p><br>
<p><img src="https://habrastorage.org/webt/84/5i/pd/845ipdjygzhjk4t-k6vj4hrbmem.png" alt="Bert-Output-Tensor-Auswahl"></p><br>
<p> ,    3d   ,     2d :</p><br>
<pre><code class="python hljs"><span class="hljs-comment">#        ,      </span>
features = last_hidden_states[<span class="hljs-number">0</span>][:,<span class="hljs-number">0</span>,:].numpy()</code></pre><br>
<p>   <strong>features</strong>  2d  numpy,         .</p><br>
<p><img src="https://habrastorage.org/webt/sg/e7/_i/sge7_iy7hdtmvxyk41ajpm4xt_a.png" alt="Bert-Output-Cls-Satz-Einbettungen"></p><br>
<p><em>,      BERT'</em></p><br>
<h1 id="nabor-dannyh-dlya-logisticheskoy-regressii">    </h1><br>
<p>,       BERT',    ,        .   768 ,         .</p><br>
<p><img src="https://habrastorage.org/webt/ul/33/yn/ul33ynyfjqqgqwuk-uvwe3mty1k.png" alt="Logistik-Regressions-Dataset-Features-Labels"></p><br>
<p><em>  ,      .     BERT'   [CLS] ( #0),    (.  ).        ,    ‚Äì       ,       BERT/DistilBERT</em></p><br>
<p> ,             ,             .</p><br>
<pre><code class="python hljs">labels = df[<span class="hljs-number">1</span>]<font></font>
train_features, test_features, train_labels, test_labels = train_test_split(features, labels)</code></pre><br>
<p>         :</p><br>
<p><img src="https://habrastorage.org/webt/r_/e3/mq/r_e3mqtxvjry5xoabovb7il_iec.png" alt="Bert-Distilbert-Zug-Test-Split-Satz-Einbettung"></p><br>
<p>        .</p><br>
<pre><code class="python hljs">lr_clf = LogisticRegression()<font></font>
lr_clf.fit(train_features, train_labels)</code></pre><br>
<p> ,        .</p><br>
<pre><code class="python hljs">lr_clf.score(test_features, test_labels)</code></pre><br>
<p>  ,    (accuracy)  ‚Äì 81%.</p><br>
<h1 id="benchmarki"></h1><br>
<p> :        ‚Äì <strong>96.8</strong>. DistilBERT     ,       ‚Äì ,   .    BERT     ,       (    downstream task).   DistilBERT'      <strong>90.7</strong>.   BERT'  <strong>94.9</strong>.</p><br>
<h1 id="noutbuk"></h1><br>
<p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"></a>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Colab</a>.</p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das ist alles! </font><font style="vertical-align: inherit;">Eine gute erste Bekanntschaft ist passiert. </font><font style="vertical-align: inherit;">Der n√§chste Schritt besteht darin, sich der Dokumentation zuzuwenden und zu versuchen, Ihre eigenen H√§nde zu optimieren. </font><font style="vertical-align: inherit;">Sie k√∂nnen auch ein bisschen zur√ºckgehen und von distilBERT zu BERT gehen und sehen, wie es funktioniert.</font></font></p><br>
<p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vielen Dank an </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cl√©ment Delangue</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Victor Sanh</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und das Huggingface-Team, das Feedback zu fr√ºheren Versionen dieses Handbuchs gegeben hat.</font></font></p><br>
<h1 id="avtory"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Autoren</font></font></h1><br>
<ul>
<li><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Original</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jay Alammar</font></font></a></li>
<li><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√úbersetzung</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ekaterina Smirnova</font></font></a></li>
<li><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bearbeitung und Layout</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Shkarin Sergey</font></font></a></li>
</ul></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de498132/index.html">PostgreSQL-Rezepte: Auto-Failover und Auto-Rejoin im Docker-Schwarm</a></li>
<li><a href="../de498134/index.html">Wie kann man Code mit Symfony 5-Bundles wiederverwenden? Teil 1. Mindestb√ºndel</a></li>
<li><a href="../de498136/index.html">Gespr√§ch mit Polina Gurtova √ºber die Zukunft und Gegenwart von Frontend. Die Organisatoren von DUMP 2020 stellen einige wichtige Fragen.</a></li>
<li><a href="../de498138/index.html">Leben nach dem Grundstudium: Wie ich mich entschieden habe, was ich als n√§chstes tun soll, wenn es bereits Hochschulbildung und Arbeit gibt</a></li>
<li><a href="../de498140/index.html">Replizieren Sie dies. Webinare Apache Ignite und GridGain</a></li>
<li><a href="../de498146/index.html">Sechs intelligente Sicherheitstrends, auf die Sie achten sollten</a></li>
<li><a href="../de498150/index.html">Klempnerprogrammierer oder die Geschichte eines Lecks und die Schwierigkeiten, damit umzugehen</a></li>
<li><a href="../de498154/index.html">Kalender der kostenlosen IT-Veranstaltungen online vom 20. bis 26. April</a></li>
<li><a href="../de498156/index.html">F #, Morphologie von Bin√§rbildern</a></li>
<li><a href="../de498158/index.html">Remote Marathon Woche 1: Arbeitsplatz</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
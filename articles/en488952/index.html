<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💎 ✌🏽 👩🏽‍🤝‍👨🏿 Phrase sentiment analysis using neural networks ☔️ 👩🏿‍🤝‍👩🏽 👇🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello everyone! 
 
 All people who receive higher education, without being expelled, nevertheless reach the stage of writing a diploma. I was no excep...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Phrase sentiment analysis using neural networks</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488952/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hello everyone! </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All people who receive higher education, without being expelled, nevertheless reach the stage of writing a diploma. I was no exception. I wanted to implement something interesting and master the hitherto unexplored, so I drew attention to the topic of neural networks and artificial intelligence in general. And the task that I solved with the help of it is the analysis of the tonality of the text, which is already widely used in various monitoring systems. I will try to describe the process of its solution in this article.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In short, the goal is to understand whether a phrase has a positive connotation or a negative one. </font><font style="vertical-align: inherit;">I want to say right away that this problem can be solved in several ways, and not only by neural networks. </font><font style="vertical-align: inherit;">We can make dictionaries in which the positions of words are marked, etc. </font><font style="vertical-align: inherit;">(all methods are in abundance on the hub), but each method may go further according to the article, so we will leave their review for later.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Data</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first task on my way was collecting and preprocessing data for training. </font><font style="vertical-align: inherit;">A good dataset for such a case is the corpus of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">short texts by</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Y. Rubtsova, previously divided into negative and positive sentences collected on Twitter. </font><font style="vertical-align: inherit;">What is especially convenient - all this exists in CSV format.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Training preparation</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pay attention to the form in which the data is presented - a lot of emoticons, links, unnecessary characters, hits. </font><font style="vertical-align: inherit;">All this is not important information and only interferes with learning, moreover, everything must be removed in Latin. </font><font style="vertical-align: inherit;">Therefore, the text would be good to preprocess.</font></font><br>
<a name="habracut"></a><br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">preprocessText</span>(<span class="hljs-params">text</span>):</span>
    text = text.lower().replace(<span class="hljs-string">""</span>, <span class="hljs-string">""</span>)<font></font>
    text = re.sub(<span class="hljs-string">'((www\.[^\s]+)|(https?://[^\s]+))'</span>, <span class="hljs-string">' '</span>, text)<font></font>
    text = re.sub(<span class="hljs-string">'@[^\s]+'</span>, <span class="hljs-string">' '</span>, text)<font></font>
    text = re.sub(<span class="hljs-string">'[^a-zA-Z--1-9]+'</span>, <span class="hljs-string">' '</span>, text)<font></font>
    text = re.sub(<span class="hljs-string">' +'</span>, <span class="hljs-string">' '</span>, text)
    <span class="hljs-keyword">return</span> text.strip()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Having run away all the sentences from the file, we bring them to lower case, replace "" with "e", references, mentions, we simply remove the English words for lack of meaning. </font><font style="vertical-align: inherit;">In short, we make them the same type, cleaning out the “garbage” that is superfluous for training.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tools</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, if you have a supercomputer at home, you can scroll down this section further, looking for an interesting part. </font><font style="vertical-align: inherit;">I advise the rest of the service </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Colab</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which allows you to run Jupyter Notebooks (and who haven’t heard about it, to help the search engine) using only a browser, and all the work is done on a virtual machine in the cloud. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The temporary size of the session that you are given to work is limited to 12 hours - you can finish earlier, after which everything is reset.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We write our beautiful code</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Like any other newcomer to machine learning, I chose Python - because it's simple, and libraries are a whole cloud. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
First, the package manager will execute one important command, the meaning of which I will explain a little later. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ef/wk/9v/efwk9vhtlfmarfrjwrtioznbtui.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next, we import the libraries that we will use when training the grid and preparing the data, I think many of them are familiar to you. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fz/kj/yy/fzkjyyqk5gfj5athvrusah6wfoy.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally to the point. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, why did we download and import the Tensorflow-text library? The fact is that phrases cannot be “fed” to the grid in the form in which it is readable to us. This is where Word Embedding comes in, a term I haven’t found an adequate translation for, and in general I doubt its existence. But roughly speaking, we are talking about matching a vector to a word. This is well said </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We need to convert entire sentences into a vector, so we use a ready-made solution from Google - Universal Sentence Encoder. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/z9/dc/iw/z9dciwgfbyqex0rm1mkwilkpcfg.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can download it from the hub </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . There, by the way, there are many more interesting ready-made solutions that can be used when learning a neural network, so as not to bother yourself. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/qr/a5/t7/qra5t7k5ae9_tpdbosafn2yerds.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All tweets are classified by class - bad / good. We create a pandas-dataframe in which they are sorted by class (the bad ones are not visible in the picture, due to the fact that they fit in). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/sd/dl/ux/sddlux3whlfto8mu7jtelxoktvi.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We prepared the data - let's get down to the model itself. To do this, use the Keras framework.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers
<span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential, load_model<font></font>
model = tf.keras.Sequential()<font></font>
<font></font>
model.add(<font></font>
  tf.keras.layers.Dense(<font></font>
    units=<span class="hljs-number">256</span>,<font></font>
    input_shape=(X_train.shape[<span class="hljs-number">1</span>], ),<font></font>
    activation=<span class="hljs-string">'relu'</span><font></font>
  )<font></font>
)<font></font>
model.add(<font></font>
  tf.keras.layers.Dropout(rate=<span class="hljs-number">0.5</span>)<font></font>
)<font></font>
<font></font>
model.add(<font></font>
  tf.keras.layers.Dense(<font></font>
    units=<span class="hljs-number">128</span>,<font></font>
    activation=<span class="hljs-string">'relu'</span><font></font>
  )<font></font>
)<font></font>
model.add(<font></font>
  tf.keras.layers.Dropout(rate=<span class="hljs-number">0.5</span>)<font></font>
)<font></font>
<font></font>
model.add(tf.keras.layers.Dense(<span class="hljs-number">2</span>, activation=<span class="hljs-string">'softmax'</span>))<font></font>
model.compile(<font></font>
    loss=<span class="hljs-string">'categorical_crossentropy'</span>,<font></font>
    optimizer=tf.keras.optimizers.Adam(<span class="hljs-number">0.001</span>),<font></font>
    metrics=[<span class="hljs-string">'accuracy'</span>]<font></font>
)<font></font>
<font></font>
history = model.fit(<font></font>
    X_train, y_train,<font></font>
    epochs=<span class="hljs-number">10</span>,<font></font>
    batch_size=<span class="hljs-number">16</span>,<font></font>
    validation_split=<span class="hljs-number">0.1</span>,<font></font>
    verbose=<span class="hljs-number">1</span>,<font></font>
    shuffle=<span class="hljs-literal">True</span><font></font>
)<font></font>
<font></font>
model.evaluate(X_test, y_test)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A little about the model itself. It has input, hidden, and output layers. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Each layer has its own activation function. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A little explanation: In artificial neural networks, the neuron activation function determines the output signal, which is determined by the input signal or a set of input signals. You can read more </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , by the way a lot of them exist for different tasks, but we will work only with 2. We </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
assign the activation function </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ReLu to the</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> first 2 layers </font><font style="vertical-align: inherit;">. The </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">day off</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">Softmax</font></a><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In addition to adding layers, you can notice the word “Dropout”. What is it? Oddly enough, in addition to the problem of under-learning of a neural network, when its predictions are not true, there is the problem of over-training - the model explains well only examples from the training sample, adapting to the training examples, instead of learning to classify examples that were not involved in the training. That is corny on the new data, your beautiful model, who had done her job superbly before, simply “flies” and starts to surprise you unpleasantly. So Dropout is engaged in the fact that with some specified probability it “turns off” neurons from the grid, so that they cease to participate in the learning process. Then the results from several networks are averaged (when a neuron is excluded from the network, a new one is obtained).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
By the way, a great </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> for those who are interested. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can start learning!</font></font><br>
<br>
<pre><code class="plaintext hljs">Train on 53082 samples, validate on 5898 samples<font></font>
Epoch 1/10<font></font>
53082/53082 [==============================] - 12s 223us/sample - loss: 0.5451 - accuracy: 0.7207 - val_loss: 0.5105 - val_accuracy: 0.7397<font></font>
Epoch 2/10<font></font>
53082/53082 [==============================] - 11s 213us/sample - loss: 0.5129 - accuracy: 0.7452 - val_loss: 0.5000 - val_accuracy: 0.7523<font></font>
Epoch 3/10<font></font>
53082/53082 [==============================] - 11s 215us/sample - loss: 0.4885 - accuracy: 0.7624 - val_loss: 0.4914 - val_accuracy: 0.7538<font></font>
Epoch 4/10<font></font>
53082/53082 [==============================] - 11s 215us/sample - loss: 0.4686 - accuracy: 0.7739 - val_loss: 0.4865 - val_accuracy: 0.7589<font></font>
Epoch 5/10<font></font>
53082/53082 [==============================] - 11s 214us/sample - loss: 0.4474 - accuracy: 0.7889 - val_loss: 0.4873 - val_accuracy: 0.7616<font></font>
Epoch 6/10<font></font>
53082/53082 [==============================] - 11s 216us/sample - loss: 0.4272 - accuracy: 0.8004 - val_loss: 0.4878 - val_accuracy: 0.7603<font></font>
Epoch 7/10<font></font>
53082/53082 [==============================] - 11s 213us/sample - loss: 0.4081 - accuracy: 0.8111 - val_loss: 0.4986 - val_accuracy: 0.7594<font></font>
Epoch 8/10<font></font>
53082/53082 [==============================] - 11s 215us/sample - loss: 0.3899 - accuracy: 0.8241 - val_loss: 0.5101 - val_accuracy: 0.7564<font></font>
Epoch 9/10<font></font>
53082/53082 [==============================] - 11s 215us/sample - loss: 0.3733 - accuracy: 0.8315 - val_loss: 0.5035 - val_accuracy: 0.7633<font></font>
Epoch 10/10<font></font>
53082/53082 [==============================] - 11s 215us/sample - loss: 0.3596 - accuracy: 0.8400 - val_loss: 0.5239 - val_accuracy: 0.7620<font></font>
6554/6554 [==============================] - 0s 53us/sample - loss: 0.5249 - accuracy: 0.7524<font></font>
[0.5249265961105736, 0.752365]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, 10 eras have passed. </font><font style="vertical-align: inherit;">For those who are not at all familiar with such concepts, I will explain the definition from the Internet: The era is one iteration in the learning process, including the presentation of all examples from the training set and, possibly, checking the quality of training on the control set. </font><font style="vertical-align: inherit;">So all our data went 10 times completely through the whole process.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Result</font></font></h3><br>
<img src="https://habrastorage.org/webt/gx/pa/sn/gxpasnk8c0ti4aigvbkpcgyoude.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Of course, the network will be needed more than once and it would be nice to know how to save it for posterity, so that they do not have to re-train it and all that. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The structure is saved in JSON format, and the weights are written to a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h5</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> file </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The search engine is full of guides on how to crank the reverse process of initializing the network from these files, so I will not describe it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Using the predict method, we will try to find out the opinion of the network and the tonal component of 2 obviously different phrases in this regard. True, they still need to be reduced to a matrix form first, but we already know how to do this using a ready-made solution.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At the output, we see 2 numbers - the probability that the phrase belongs to the “negative” / “positive” classes. </font><font style="vertical-align: inherit;">I think the picture clearly shows that there is a difference) So similar words were in the end and the network did a great job with their relationship to their classes.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So, I want to say that mastering advanced tools for developing neural networks and solving simple problems, having correctly determined the necessary steps to solve it and having read the theory a bit, seems to be quite an easy task. </font><font style="vertical-align: inherit;">I would like to note that I saw several articles on the topic of tonal analysis on Habré, but it was still interesting to try something easier and without a huge mass of text, although you need to study the theory unconditionally :) </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can find the code </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> if you put an asterisk on the project, it will be great. </font><font style="vertical-align: inherit;">If you need files with weights and network structure, as well as processed data - write to the comments, add to the repository.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en488942/index.html">Artifacts for UX eaters and teams: what is it, why are they needed and how to choose</a></li>
<li><a href="../en488944/index.html">How coronavirus affects biotechnology stocks</a></li>
<li><a href="../en488946/index.html">Python console menu</a></li>
<li><a href="../en488948/index.html">UPD. Testing the REST API on Golang. 120 000 [# / sec] is not the limit?</a></li>
<li><a href="../en488950/index.html">Time in a cellular machine</a></li>
<li><a href="../en488954/index.html">How to explain your point of view to the robot</a></li>
<li><a href="../en488956/index.html">Organization of documentation and translation, for example, iondv. framework</a></li>
<li><a href="../en488958/index.html">Transcript of my interview with Ruby author</a></li>
<li><a href="../en488960/index.html">Programming, Immunity and the Army</a></li>
<li><a href="../en488962/index.html">Can I write scripts in C ++?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="ja">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💃🏻 👩🏿‍🔬 💆🏼 AIを使用したゲーム内のキャラクターのリアルなアニメーション 🕸️ 🏿 👇🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="エジンバラ大学の開発者は、ゲームでリアルなキャラクターの動きを作成するための新しいアルゴリズムを導入しました。ニューラルネットワークはモーションキャプチャの軌道で訓練され、実際の人々の動きをコピーしようとしますが、同時にそれらをビデオゲームのキャラクターに適応させます。
 
 1つのニューラルネット...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>AIを使用したゲーム内のキャラクターのリアルなアニメーション</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/474252/"><img src="https://habrastorage.org/webt/2w/dk/ed/2wdkedknmc5jpfb6gznv2hmrqqg.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
エジンバラ大学の開発者は、ゲームでリアルなキャラクターの動きを作成するための新しいアルゴリズムを導入しました。ニューラルネットワークはモーションキャプチャの軌道で訓練され、実際の人々の動きをコピーしようとしますが、同時にそれらをビデオゲームのキャラクターに適応させます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1つのニューラルネットワークは、ゲーム内の複数のアクションを一度に管理できます。ドアを開けて、アイテムを動かして、家具を使って。同時に、彼女は脚と腕の位置を動的に変更して、キャラクターがさまざまなサイズの引き出しを現実的に保持したり、さまざまなサイズの椅子に座ったり、さまざまな高さの通路に這ったりできるようにします。</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
通常、AIを使用するゲームのキャラクターの制御下では、物理学の法則を模倣するある種の物理エンジンに基づいて、手足の努力を完全に制御することを意味します。これは、強化学習と呼ばれる機械学習のドメインです。残念ながら、このようにして、</font><font style="vertical-align: inherit;">現実的な動き</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">まだ</font><font style="vertical-align: inherit;">実現</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">できてい</font></a><font style="vertical-align: inherit;">ません</font><font style="vertical-align: inherit;">。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
一方、ニューラルネットワークをトレーニングして、モーションキャプチャを使用してキャプチャされた実際の人々の動きをシミュレートすることもできます。このようにして、約1年前に、3Dキャラクターのリアルなアニメーションが大幅に進歩しました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zn/yw/6w/znyw6woqcwlbfqzji3ywh_azzce.gif"><br>
<br>
<img src="https://habrastorage.org/webt/u1/l-/t3/u1l-t3ymdu6-e5nrs-c1pzqzhsc.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このトピックに関していくつかの連続した科学的研究がありましたが、最も完全な説明は</font><font style="vertical-align: inherit;">、DeepMimicニューラルネットワーク専用の</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Towards a Virtual Stuntman</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">にあります（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www.youtube.com/watch?v=vppFvq2quQ0</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
主なアイデアは、トレーニング中に人間の動きをシミュレートして、以前のようにモーションキャプチャトラックの最初からではなく、パス全体のランダムなポイントからエピソードを開始することです。既存の強化学習アルゴリズムは、開始点の近くを調査するため、ほとんどの場合、パスの最後に到達しませんでした。しかし、各エピソードがトラック全体に沿って始まる場合、ニューラルネットワークが軌道全体を繰り返すことを学習する可能性が高くなります。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/3y/49/wj/3y49wjtdya9u6do5etxd3cvm-oe.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
その後、このアイデアはまったく異なる分野で取り上げられました。たとえば、ゲームを通じてニューラルネットワークをプレイするように人々に教え、最初からではなくランダムなポイントからエピソードを開始することで（具体的には、この場合は、最後から徐々に開始します）、OpenAIはニューラルネットワークを教えました</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ゲームMontezuma's Revengeに合格し</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ます。以前は通常の強化学習アルゴリズムに屈しませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このトリックがないと、複雑な動きをコピーするようにニューラルネットワークをトレーニングしようとしても、ニューラルネットワークがより短いパスを見つけたため、失敗に終わりました。全体の軌道についてはそれほど大きな報酬を与えていませんが、それでも何らかの報酬がありました。たとえば、宙返りをする代わりに、ニューラルネットワークは単にわずかに跳ね返り、背中にはね返りました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/do/fi/ga/dofigaucbz2itdi4f8rqwns0tac.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
しかし、このアプローチでは、問題のないニューラルネットワークはほとんどすべての複雑さの軌跡を調査します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6e/dw/e8/6edwe8z8lyxtfi6pk67tdmsdcye.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
DeepMimicの主な問題は、ビデオゲームへの直接の適用を妨げていましたが、ニューラルネットワークをトレーニングして、いくつかの異なるアニメーションを一度に実行することができませんでした。アニメーションごとに個別のニューラルネットワークをトレーニングする必要がありました。著者はそれらをさまざまな方法で組み合わせようとしましたが、3〜4個を超えるアニメーションを組み合わせることができませんでした。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
新しい作品では、この問題も完全には解決されていませんが、異なるアニメーション間のスムーズな移行に向けて多くの進歩がありました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
この問題は、現在存在する同様のアニメーションニューラルネットワークすべてに影響することに注意してください。たとえば、</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">このニューラルネットワーク</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">は、モーションキャプチャーの模倣についても訓練を受けており、物理的なエンジンでヒューマノイドキャラクターの膨大な数の筋肉（326！）を正直に制御できます。持ち上げられたウェイトのさまざまなウェイトとさまざまな関節の怪我に適応します。しかし同時に、アニメーションごとに、個別のトレーニング済みニューラルネットワークが必要です。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このようなニューラルネットワークの目的は、人間のアニメーションを繰り返すことだけではないことを理解してください。そして、物理エンジンでそれを繰り返します。同時に、強化学習アルゴリズムにより、このトレーニングは信頼性が高く、干渉に強くなっています。次に、そのようなニューラルネットワークは、形状や質量が人とは異なる物理ロボットに転送できますが、人の動きを現実的に繰り返し続けます（すでに述べたように、この効果はまだ達成されていません）。または、上記の作業のように、足の怪我をした人がどのように動くかを仮想的に探索して、より快適な補綴物を開発することもできます。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
最初のDeepMimicに戻ると、そのような適応の始まりがありました。赤いボールを動かすことが可能で、キャラクターは毎回彼にボールを投げました。ターゲットを正確に打つための投げる力を狙って測定します。彼は唯一のモーションキャプチャトラックで訓練を受けましたが、そのような機会はありません。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ap/cm/rl/apcmrlwabrcrpjahbh0ogm6budi.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
したがって、これは本格的なAIトレーニングと見なすことができ、人間の動きを模倣することで、学習を高速化し、視覚的に魅力的な動きを身近なものにすることができます（ただし、ニューラルネットワークの観点からは、同時に最適ではない場合があります）。</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">新しい仕事</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">はこの方向にさらに進んだ。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7c6oQP1u2eQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
物理的なエンジンはなく、ビデオゲーム用の純粋なアニメーションシステムです。しかし、重点は複数のアニメーション間の現実的な切り替えにあります。また、ゲームアイテムとのやり取り：アイテムの移動、家具の使用、ドアの開け方。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/j8/6p/rw/j86prwghqyqp7b9clvhqszkreky.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ニューラルネットワークのアーキテクチャは2つの部分で構成されています。 1つ（ゲーティングネットワーク）は、状態の現在の状態と現在の目標に基づいて、使用するアニメーションを選択し、もう1つ（モーション予測ネットワーク）は、アニメーションの次のフレームを予測します。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/np/rw/gk/nprwgkyhzzmgsvf6cb7hbxbq5bm.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
これらすべては、シミュレーション強化学習を使用して、モーションキャプチャトラックのセットでトレーニングされました。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ただし、この作業の主な成果は異なります。開発者がニューラルネットワークに教えて、さまざまなサイズのオブジェクトを操作し、さまざまな幅または高さの通路に押し込む方法を教えました。これにより、腕と脚の位置がリアルになり、ゲームでキャラクターが相互作用するオブジェクトのサイズに対応します。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
秘密は簡単でした：増強！</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まず、モーションキャプチャトラックから、椅子の肘掛けとの手の接触点を特定しました。次に、椅子のモデルを幅の広いモデルに置き換え、モーションキャプチャの軌道を再計算して、手が同じ位置でアームレストに触れたが、幅の広い椅子の上にあるようにしました。そして、彼らはニューラルネットワークにモーションキャプチャーによって生成されたこの新しい軌道をシミュレートするように強制しました。同様に、箱の寸法、通路の高さなども同様です。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/5f/u5/eb/5fu5ebnogiwpxpxytwmjcwtl6hw.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
プレイヤーが相互作用する環境のさまざまな3Dモデルでこれを何度も繰り返し、ニューラルネットワークはさまざまなサイズのオブジェクトを現実的に処理することを学びました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/6c/5n/x9/6c5nx9quioedhbdcju4lgju4d8a.gif"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ゲーム自体の環境と対話するには、オブジェクトをボクセル化して、ニューラルネットワークの入力でセンサーとして機能するようにする必要がありました。</font></font><br>
<br>
<img src="https://habrastorage.org/webt/dz/y8/ed/dzy8edprhfcp98mpoaw5gtivjy4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
結果は、ゲームキャラクターにとって非常に優れたアニメーションです。アクション間のスムーズな移行と、さまざまなサイズのオブジェクトとリアルに対話する機能。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
まだ視聴されていない場合は、ビデオをご覧になることを強くお勧めします。それは彼らがこれをどのように達成したかを非常に詳細に説明しています。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
このアプローチは、4本足の動物を含むアニメーションに使用でき、動物やモンスターの動きの卓越した品質とリアリズムを実現します。</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/uFJvRYtjQ4c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">参考文献</font></font></h4><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ビデオ</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
作品の詳細な説明を含む</font></font><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ソース</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> PDFファイルを含む</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;">プロジェクトページ</font></a><font style="vertical-align: inherit;">：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ja&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SIGGRAPH_Asia_2019 / Paper.pdf</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ja474238/index.html">会議会話：8時間の会話型AIの理論と実践</a></li>
<li><a href="../ja474240/index.html">Orleans 3.0がリリースされました</a></li>
<li><a href="../ja474244/index.html">SpaceFusion：インタラクティブAIのための非構造化隠しスペースの構造化</a></li>
<li><a href="../ja474246/index.html">JavaScript Meetup SuperJob：ビデオレポート</a></li>
<li><a href="../ja474250/index.html">すべての家庭のVPNまたはドラゴンを飼いならす方法</a></li>
<li><a href="../ja474254/index.html">Reactのスライダーにクールなスティッキーエフェクトを作成する</a></li>
<li><a href="../ja474256/index.html">Идея о поиске людей в лесу</a></li>
<li><a href="../ja474268/index.html">デジタル回路の認識。非同期カウントトリガー</a></li>
<li><a href="../ja474274/index.html">ナレッジグラフ。複数、時間的、活動的アプローチ</a></li>
<li><a href="../ja474276/index.html">「深い強化トレーニング。AlphaGoと他のテクノロジー」：本の発表</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
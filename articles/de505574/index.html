<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé£ üë©üèæ‚Äçüè´ ü•ò Verst√§rktes Lernen durch wettbewerbsf√§hige neuronale Netze üé± üà∑Ô∏è üìÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im klassischen Spiel "Tic-Tac-Toe" besteht die M√∂glichkeit, alle wahrscheinlichen Z√ºge zu pr√§sentieren - und nie zu verlieren. Ich nutzte diese Gelege...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Verst√§rktes Lernen durch wettbewerbsf√§hige neuronale Netze</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/505574/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im klassischen Spiel "Tic-Tac-Toe" besteht die M√∂glichkeit, alle wahrscheinlichen Z√ºge zu pr√§sentieren - und nie zu verlieren. Ich nutzte diese Gelegenheit als Ma√ü f√ºr mein Training im neuronalen Netzwerk des Spiels. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Verst√§rkung des Trainings ist n√ºtzlich f√ºr Aufgaben, bei denen eine mehrdeutige Entscheidung getroffen wird, was aufgrund der vielen Optionen f√ºr die Auswahl einer Aktion mit jeweils unterschiedlichen Ergebnissen kompliziert ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nat√ºrlich sieht Tic-Tac-Toe nicht nach einem schwierigen Spiel aus, um sie mit Verst√§rkungen zu trainieren. Es ist jedoch gut geeignet, um die Trainingsmethodik durch wettbewerbsf√§hige Netzwerke zu beherrschen, wodurch die Qualit√§t verbessert und der Zeitaufwand f√ºr das Training des Netzwerks verringert wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als n√§chstes beschreibe ich den allgemeinen Lernalgorithmus mit Verst√§rkung durch wettbewerbsf√§hige Netzwerke im Kontext eines Tic-Tac-Toe-Spiels mit einer Demonstration eines trainierten Netzwerks, um ‚Äûsinnvolle‚Äú Bewegungen auszuf√ºhren, dh zu spielen.</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aufzeichnen eines Spiels eines trainierten Netzwerks. </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trainieren Sie das Netzwerk von Grund auf. </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quellen.</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Sie k√∂nnen auch ein vorab </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">trainiertes</font></a><font style="vertical-align: inherit;"> Modell von GitHub aus eingeben, indem Sie auf die entsprechende Schaltfl√§che klicken, um sofort mit dem Testen eines neuronalen Netzwerks zu beginnen.</font></font><br>
<a name="habracut"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die ersten Schritte beim Training neuronaler Netze</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zus√§tzlich zu der Tatsache, dass ein Neuron eine Aktivierungsfunktion hat, die die resultierende L√∂sung eines neuronalen Netzwerks √§ndert, k√∂nnen wir auch sagen, dass Neuronen Netzwerkspeicher sind. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jede Schicht erh√∂ht die Trainingszeit aufgrund der Ausbreitung des Umkehrfehlers durch die Schichten "nach oben", und das Signal verblasst allm√§hlich, bevor es die "oberen" Schichten erreicht, die den Weg der Entscheidungsfindung beginnen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nach mehreren Optionen f√ºr Netzwerkeinstellungen kam ich zu dem Schluss, dass es f√ºr ein einfaches Spiel mit einem 3x3-Feld ausreichen w√ºrde, ein einschichtiges Netzwerk mit 128 Neuronen zu verwenden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Netzwerk sollte nicht zu viel Speicher haben, dies kann zu einer Umschulung f√ºhren - dem vollst√§ndigen Speichern aller Optionen f√ºr das Ergebnis des Spiels. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die St√§rke neuronaler Netze in der Ausdruckskraft der Ann√§herung einer L√∂sung basierend auf Eingabedaten unter Bedingungen mit begrenztem Speicher.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Allgemeine Regeln f√ºr die F√∂rderung von Agenten</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
F√ºr die relative Vorhersage durch ein neuronales Netzwerk hat jede Zelle eine dynamische Belohnung, die von ihrer Bedeutung f√ºr den Agenten im Moment abh√§ngt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Am Ausgang sagt das neuronale Netzwerk den Index der Zelle voraus, in die der Agent gehen wird. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Belohnungen von Zellen haben die folgende Verteilung: </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Je weniger Z√ºge gemacht werden, desto h√∂her ist die Belohnung von 0,1 auf 1,0. Eine </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
besetzte Zelle hat eine Belohnung von -1,0. Eine </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
verlorene Zelle erh√§lt eine Belohnung von -0,4. Eine </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
freie Zelle hat eine Belohnung. 0,1 Ein </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zug in eine freie Zelle erh√∂ht ihre Belohnung auf 0,2. Eine </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
gewinnende Zelle eines Gegners hat eine Belohnung von 0,5 </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Gewinn eines Slots bringt eine Belohnung von 1,0</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wettbewerbsf√§higes neuronales Netzwerktraining</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
W√§hrend des Wettbewerbs werden die Agenten in einem Wettbewerbsumfeld geschult, was zu neuen Ergebnissen des Spiels f√ºhrt und die Qualit√§t des Trainings f√ºr neue Situationen verbessert. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jeder Agent hat sein eigenes Feld, um zu trainieren, in eine freie Zelle zu gehen und gewinnbringende Kombinationen von Z√ºgen zu erstellen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agenten spielen 9 Spiele zu Hause und wechseln dann f√ºr 1 Spiel in das Wettbewerbsfeld, wo das Spiel bis zum Sieger mit einem Limit von 9 Z√ºgen gespielt wird. Dann wird alles erneut wiederholt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Am Ende jedes Spiels werden beide Netzwerke auf eine neue Erfahrung der Rivalit√§t auf einem gemeinsamen Spielfeld trainiert.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gegnerpr√§vention</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Netzwerk muss trainiert werden, um auf dem Feld um den Sieg zu k√§mpfen, d. H. </font><font style="vertical-align: inherit;">Belohnung f√ºr die erfolgreiche Verhinderung des Gewinnens eines Gegners durch Erh√∂hung der Zellbelohnung. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine weitere Metrik f√ºr das Training neuronaler Netze sind die Indikatoren f√ºr den Sieg bei Wettbewerben. </font><font style="vertical-align: inherit;">Wenn die Gewinnspanne f√ºr einen Spieler zu gro√ü ist, lernt das Netzwerk wahrscheinlich falsch, und der Grund daf√ºr sind falsche Belohnungen f√ºr die Aktionen von Agenten, oder andere Aktionen und deren Belohnungen wurden nicht ber√ºcksichtigt. </font><font style="vertical-align: inherit;">Das beste Ergebnis des Trainings kann als eine Situation angesehen werden, in der die Netzwerke fast gleich sind und ungef√§hr gleich oft gewinnen und verlieren.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wettbewerbsf√§higes Lernen mit einem Mann</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Implementierung des Trainings eines neuronalen Netzwerks zum Spielen mit Menschen unterscheidet sich nicht wesentlich von der Konkurrenz zwischen Agenten. </font><font style="vertical-align: inherit;">Der einzige gravierende Unterschied ist, dass die Person zun√§chst vern√ºnftig spielt. </font><font style="vertical-align: inherit;">Eine Partei mit einem solchen Gegner schafft zus√§tzliche Situationen f√ºr den Agenten, die sich g√ºnstig auf seine Spielerfahrung und dementsprechend auf sein Training auswirken.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fertigstellung</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das neuronale Netzwerk lernte das Tic-Tac-Toe erst nach Einf√ºhrung des Wettbewerbsalgorithmus, wodurch es lernte, wie man als Reaktion auf die Bewegungen des Gegners Bewegungen ausf√ºhrt, wenn auch nicht perfekt, wie urspr√ºnglich geplant. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Generell denke ich, dass das Projekt erfolgreich abgeschlossen wurde - das Ziel wurde erreicht.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vielen Dank f√ºr Ihre Aufmerksamkeit!</font></font></h2><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ps Trainiere wettbewerbsf√§hige Netzwerke, damit du einfache Spiele aus einem anderen Blickwinkel betrachten kannst.</font></font></i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de505554/index.html">Beim Wettbewerb ‚ÄûJunge Techniker und Erfinder‚Äú werden echte junge Erfinder nicht ben√∂tigt</a></li>
<li><a href="../de505556/index.html">Apple verfolgt gepl√ºnderte iPhones und gibt Pl√ºnderer der Polizei</a></li>
<li><a href="../de505558/index.html">Amazon DeepLens Deep Learning Kamera. Ein Projekt entpacken, verbinden und bereitstellen</a></li>
<li><a href="../de505560/index.html">Der zweite Satz f√ºr ein Produktmanagementprogramm im CS-Center: Was die Sch√ºler sagen</a></li>
<li><a href="../de505568/index.html">√úbertragen von Dateien mit Pipes und anderen kleinen Dingen auf Delphi</a></li>
<li><a href="../en486014/index.html">SLAC Tour: US Department of Energy National Accelerator Laboratory at Stanford</a></li>
<li><a href="../en486018/index.html">Session Survey Results</a></li>
<li><a href="../en486024/index.html">Really simple graphics in R for science and journalism</a></li>
<li><a href="../en486028/index.html">Neural networks in the production of dentures</a></li>
<li><a href="../en486030/index.html">TL-SREET 55 5K LED Street Light Review</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👇🏻 👩🏾‍✈️ 😞 Wie zählen wir Menschen, die Computer Vision verwenden? 🔼 👩🏾‍✈️ 👩‍❤️‍👨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fotos aus offenen Quellen
 
 Massenversammlungen von Menschen verursachen Probleme in verschiedenen Bereichen (Einzelhandel, öffentliche Dienste, Bank...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Wie zählen wir Menschen, die Computer Vision verwenden?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/center2m/blog/496616/"><img src="https://habrastorage.org/webt/b2/gt/vy/b2gtvy54vvgxucterhxudpe5y58.png" alt="Bild"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fotos aus offenen Quellen</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Massenversammlungen von Menschen verursachen Probleme in verschiedenen Bereichen (Einzelhandel, </font><i><font style="vertical-align: inherit;">öffentliche</font></i><font style="vertical-align: inherit;"> Dienste, Banken, Entwickler). Kunden müssen Informationen über die Anzahl der Personen an vielen Orten kombinieren und überwachen: in Servicebüros, Verwaltungsgebäuden, auf Baustellen usw. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Aufgaben der Personenzählung haben vorgefertigte Lösungen, z. B. die Verwendung von Kameras mit integrierter Analyse. In vielen Fällen ist es jedoch wichtig, eine große Anzahl von Kameras zu verwenden, die zuvor in verschiedenen Abteilungen installiert wurden. Darüber hinaus ist eine Lösung, die die Besonderheiten eines bestimmten Kunden berücksichtigt, für ihn besser.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unsere Namen sind Tatyana Voronova und Elvira Dyaminova. Wir beschäftigen uns mit Datenanalysen im Center 2M. Obwohl das Thema das einfachste zu sein scheint, was derzeit bei Computer-Vision-Problemen berücksichtigt wird, müssen selbst bei diesem Problem in Bezug auf die Praxis (Implementierung) viele komplexe und nicht triviale Teilaufgaben gelöst werden. </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Zweck unseres Artikels ist es, die Komplexität und die grundlegenden Ansätze für Computer-Vision-Probleme am Beispiel der Lösung eines der Grundprobleme aufzuzeigen.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Für die folgenden Materialien möchten wir Kollegen gewinnen: Entwickler, Ingenieure, Projektmanager für Videoanalysen, damit sie über die beteiligten Computerressourcen, Geschwindigkeitsmessungen, die Nuancen der Kommunikation mit Kunden und Projektimplementierungsgeschichten sprechen. Wir werden uns auf einige der verwendeten Datenanalysemethoden konzentrieren.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beginnen wir mit der folgenden Anweisung: Sie müssen die Anzahl der Personen in der Warteschlange im Servicebüro anzeigen. </font><font style="vertical-align: inherit;">Wenn die Warteschlange gemäß den internen Regeln des Kundenunternehmens als kritisch eingestuft wird, wird das interne Szenario ausgearbeitet:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benachrichtigung über die Notwendigkeit, einen zusätzlichen Eingang / eine zusätzliche Kasse zu eröffnen;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Manageranruf;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Informationen über die Notwendigkeit, Personenströme an andere (kostenlosere) Kassen umzuleiten.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
So erspart unsere Arbeit den Kunden viele Nerven.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Verwendete Modelle für maschinelles Lernen</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Personen Silhouetten Erkennung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zunächst haben wir uns für ein bereits geschultes Modell zur Erkennung von Personen (Silhouetten) entschieden, da solche Aufgaben ziemlich gute Lösungen bieten, beispielsweise die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Definition von Silhouetten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In der TensorFlow-Bibliothek gibt es also eine große Anzahl </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vorgefertigter Modelle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nach der Durchführung der Tests haben wir uns zunächst für zwei Architekturen entschieden: Faster R-CNN und YOLO v2. Später, nachdem die neue Version erschienen war, haben wir YOLO v3 hinzugefügt. </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beschreibung der Modelle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Beispiel für ein Erkennungsergebnis für YOLO v2 (im Folgenden werden Bilder aus freien Quellen aufgenommen - wir können keine Bilder von Kundenkameras veröffentlichen): </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7d/7t/ci/7d7tciq9yzbof4hsrp00ckrbh7o.jpeg" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Beispiel für ein Erkennungsergebnis für Faster R-CNN:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/lg/qg/gq/lgqggq6y-hq6bbkmpkynivfy1co.jpeg" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Vorteil von YOLO ist, dass das Modell schneller reagiert, und bei einigen Aufgaben ist dies wichtig. In der Praxis haben wir jedoch festgestellt, dass die Verwendung von Faster R-CNN korrekter ist, wenn es nicht möglich ist, eine vorab trainierte Version des Modells zu verwenden und eine Umschulung für Ihr spezielles Trainingsset erforderlich ist. Wenn die Kamera weit genug von Personen entfernt installiert wurde (die Höhe der Silhouette beträgt weniger als 100 Pixel für eine Auflösung von 1920 x 1080) oder zusätzlich die persönliche Schutzausrüstung einer Person erkannt werden musste: Helme, Befestigungselemente, Schutzkleidungselemente, in solchen Situationen ergibt sich die Qualität des Trainings in Ihrem eigenen Datensatz (bis zu 10) tausend verschiedene Objekte) für YOLO v2 waren wir nicht zufrieden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLO v3 zeigte akzeptable Ergebnisse, jedoch ergaben Geschwindigkeitstests keinen signifikanten Vorteil für YOLO v3 im Vergleich zu schnellerem R-CNN. Darüber hinaus haben wir einen Weg gefunden, die Erkennungsgeschwindigkeit durch Stapelverarbeitung (Gruppenverarbeitung von Bildern) und selektive Analyse von Bildern zu erhöhen (mehr dazu weiter unten).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für alle Modelltypen haben wir die Genauigkeit durch Nachbearbeitung der Ergebnisse verbessert: Wir haben Ausreißer in Werten entfernt und die häufigsten Werte für eine Reihe aufeinanderfolgender Frames verwendet. Eine Sekunde von einer Kamera entspricht normalerweise 25-50 Bildern. Um die Leistung zu verbessern (mit zunehmender Anzahl von Kameras), analysieren wir natürlich nicht jedes Bild, aber es ist oft möglich, über einen Zeitraum von mehreren Sekunden eine endgültige Antwort zu geben, dh mehrere Bilder zu verwenden. Diese Entscheidung kann dynamisch getroffen werden, wobei die Gesamtzahl der Kameras (Videostreams zur Verarbeitung) und die verfügbare Rechenleistung berücksichtigt werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Beispiel für die Verwendung des Faster R-CNN-Modells, das auf unserem eigenen Datensatz trainiert wurde: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/cn/b9/8i/cnb98ihri3ztp_kd6eanszvv2g4.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jetzt führen wir Tests mit dem </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">SSD-300-</font></a><font style="vertical-align: inherit;"> Modell durch</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Wir hoffen, dass wir dadurch die Produktivität steigern und gleichzeitig eine akzeptable Qualität der Anerkennung erhalten.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen Sie Ihren eigenen Trainingsdatensatz</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Fällen, in denen Sie Ihr eigenes Lernset erstellen möchten, haben wir für uns das folgende Verfahren entwickelt:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir sammeln Videoclips mit den erforderlichen Objekten: Kundenvideos, öffentlich zugängliche Videos (angelegte Videos, Überwachungskameras);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir schneiden und filtern Videofragmente so, dass der resultierende Datensatz über verschiedene Erkennungsobjekte verteilt ist.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir verteilen Frames zwischen Markern, um die erforderlichen Objekte hervorzuheben. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein Beispiel für ein Markup-Tool</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Überprüfen Sie selektiv die Ergebnisse der Marker.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bei Bedarf führen wir eine Augmentation durch: Normalerweise fügen wir Windungen hinzu, reflektieren, ändern die Schärfe (bilden einen erweiterten markierten Datensatz).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erkennungszonen verwenden</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eines der Probleme beim Zählen von Personen in einer Linie ist der Schnittpunkt der Sichtbereiche mehrerer Kameras. </font><font style="vertical-align: inherit;">In einem Raum kann mehr als eine Kamera installiert werden. Daher ist es wichtig, den überlappenden Bildbereich beizubehalten. Wenn eine Person das Sichtfeld mehrerer Kameras betritt, sollte dies einmal berücksichtigt werden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einigen Situationen müssen Personen nur in einem bestimmten Bereich des Raums (in der Nähe der Servicefenster) oder der Plattform (in der Nähe der Ausrüstung) erkannt werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aus offensichtlichen Gründen ist es falsch zu überprüfen, ob das Rahmenrechteck (Kasten / Rahmen), das die gesamte Person einschränkt, in die Zone (Polygon) fällt. </font><font style="vertical-align: inherit;">In dieser Situation wird der Boden (Drittel / Hälfte) des Rechtecks ​​in Punkte - Knoten (ein Raster von 10 mal 10 Knoten wird genommen) unterteilt und das Fallen in die Zone der einzelnen ausgewählten Knoten wird überprüft. </font><font style="vertical-align: inherit;">"Signifikante" Knoten werden vom Systemadministrator basierend auf der Geometrie des Raums zugewiesen (die Standardwerte werden ebenfalls ausgewählt - wenn die Einstellung für einen bestimmten Raum nicht eingegeben wird). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/fl/ck/6w/flck6wqyyr5ojbwpeuqebuidzoe.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Darüber hinaus wird die Anwendung der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mask R-CNN-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Architektur </font><font style="vertical-align: inherit;">für unsere Aufgaben </font><font style="vertical-align: inherit;">getestet </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Mit dieser Methode können Sie den Umriss der Silhouette bestimmen. Auf diese Weise können Sie </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bei der Analyse des Schnittpunkts mit einer Zone nicht mehr ein Randrechteck verwenden</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<img src="https://habrastorage.org/webt/et/wy/oq/etwyoqwuuebhqh4jyxmf8j509-0.jpeg" alt="Bild"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein anderer Ansatz: Kopferkennung (Modelltraining)</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Qualität wird nicht immer durch Auswahl eines Modells, Erhöhen / Ändern des Trainingssatzes und anderer rein ML-Methoden erreicht. Manchmal kann eine entscheidende Verbesserung nur erreicht werden, indem die gesamte Formulierung des Problems geändert wird (zum Beispiel in unserem Problem). In diesen Warteschlangen drängen sich die Menschen und überlappen sich daher, sodass die Erkennungsqualität häufig nicht ausreicht, um nur diese Methode unter realen Bedingungen anzuwenden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nehmen Sie das Bild unten. Wir schließen unsere Augen vor der Tatsache, dass das Bild auf dem Telefon aufgenommen wurde und der Neigungswinkel nicht dem Neigungswinkel von CCTV-Kameras entspricht. Der Rahmen enthält 18 Personen, und das Silhouettenerkennungsmodell identifizierte 11 Personen: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/tw/qe/lr/twqelrrbt5dsacykfcb_2vm1zwe.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die Ergebnisse zu verbessern, haben wir uns von der Definition von Silhouetten zur Definition von Zielen bewegt. Zu diesem Zweck wurde das Faster R-CNN-Modell anhand eines Datensatzes aus trainiert</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Link</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (der Datensatz enthält Frames mit einer unterschiedlichen Anzahl von Personen, einschließlich großer Cluster, unter denen sich Personen unterschiedlicher Rassen und Altersgruppen befinden). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Außerdem haben wir den Datensatz mit Rahmen aus dem Material (von den Kameras) des Kunden um etwa ein Drittel angereichert (hauptsächlich aufgrund der Tatsache, dass der ursprüngliche Datensatz nur wenige Köpfe in Hüten hatte). Ein </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tutorial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> war nützlich, um ein Modell selbst zu lernen </font><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Hauptprobleme sind die Bildqualität und die Größe der Objekte. Die Köpfe haben unterschiedliche Größen (wie aus dem obigen Bild ersichtlich), und die Rahmen der Kameras des Kunden hatten eine Auflösung von 640 x 480. Aus diesem Grund werden interessante Objekte (Hauben, Weihnachtskugeln, Stuhllehnen) manchmal als Köpfe erkannt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zum Beispiel haben wir im Trainingsdatensatz Köpfe beschriftet:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/q6/u6/di/q6u6di-qwgmrlotfsyxeynpx-1q.png" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Dies sind Köpfe in einem Datensatz. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/rn/2r/es/rn2resr7gorbgtezqs7jhoozzhs.jpeg" alt="Bild"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- und das ist die Rückenlehne des Stuhls, aber das Modell möchte glauben, dass dies der Kopf ist. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Allgemeinen kommt dieses Modell jedoch in Fällen mit einer massiven Konzentration von Menschen recht gut zurecht. Im obigen Rahmen identifizierte unser Modell also 15 Personen: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/b2/gt/vy/b2gtvy54vvgxucterhxudpe5y58.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In diesem Bild konnte das Modell also nicht nur drei Köpfe finden, die durch Fremdkörper erheblich blockiert waren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die Qualität des Modells zu verbessern, können Sie die aktuellen Kameras durch Kameras mit einer höheren Auflösung ersetzen und zusätzlich den Trainingsdatensatz sammeln und markieren.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es sollte jedoch berücksichtigt werden, dass bei einer kleinen Anzahl von Personen die Methode zur Erkennung durch Silhouetten und nicht durch Köpfe besser geeignet ist, da es schwieriger ist, die Silhouette vollständig zu überlappen oder mit Fremdkörpern zu verwechseln. </font><font style="vertical-align: inherit;">Wenn es jedoch eine Menschenmenge gibt, gibt es keinen Ausweg. Um die Anzahl der Personen in einer Reihe zu zählen, wurde beschlossen, zwei Modelle parallel zu verwenden - für Köpfe und Silhouetten - und die Antwort zu kombinieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Silhouetten und Köpfe, ein Beispiel für ein Erkennungsergebnis:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ku/rf/jt/kurfjth3rdirwguzsqnsrgnketg.png" alt="Bild"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Genauigkeitswertung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Beim Testen des Modells wurden Rahmen ausgewählt, die nicht an der Schulung teilgenommen haben (Datensatz mit einer unterschiedlichen Anzahl von Personen auf dem Rahmen, in verschiedenen Winkeln und verschiedenen Größen). Um die Qualität des Modells zu bewerten, haben wir Rückruf und Präzision verwendet. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rückruf</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Vollständigkeit zeigt, welchen Anteil von Objekten, die </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tatsächlich</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zur positiven Klasse gehören, richtig vorhergesagt haben. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Präzision</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Genauigkeit zeigt, welchen Anteil von Objekten, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> als Objekte einer positiven Klasse </font><b><font style="vertical-align: inherit;">erkannt wurden</font></b><font style="vertical-align: inherit;"> , korrekt vorhergesagt wurden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei Bildern von Kameras auf Teststandorten (Bilder in diesen Räumen befanden sich im Datensatz) Metriken: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9k/dc/to/9kdctoymo_ibp2pyhzxhnllrtkk.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei Bildern von neuen Kameras (diese Räume befanden sich nicht im Datensatz):</font></font><br>
<br>
<img src="https://habrastorage.org/webt/wn/pc/a0/wnpca03c5bbmnermgoiuh9zegzy.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn der Kunde eine Ziffer, eine Kombination aus Genauigkeit und Vollständigkeit, benötigte, gaben wir ein </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">harmonisches Mittel</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> oder </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F-Maß an</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> :</font></font><br>
<img src="https://habrastorage.org/webt/ye/3o/aw/ye3oawilyj5rh_cvzpxr0c0sx3w.png" alt="Bild"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Berichterstattung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein wichtiger Teil des Dienstes ist die Statistik. Zusammen mit einzelnen Frames (und von ihnen gezählten engagierten Personen) möchten Kunden die Ergebnisse in Form von vorgefertigten Berichten (Dashboards) mit durchschnittlicher / maximaler Belegung für verschiedene Zeitintervalle anzeigen. Das Ergebnis ist oft in Form von Grafiken und Diagrammen interessant, die die Verteilung der Anzahl der Personen über die Zeit charakterisieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In unserer Lösung für den Rahmen wird beispielsweise die Anzahl der Personen für beide Modelle (Silhouetten und Köpfe) berechnet und das Maximum ausgewählt. Befinden sich mehrere Kameras im Raum, wird die Bildüberlappungszone (über die Schnittstelle voreingestellt) gespeichert, und wenn eine Person den Bereich mehrerer Kameras betritt, wird sie einmal berücksichtigt.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Als nächstes wird der Wert der Anzahl von Personen in der Warteschlange für mehrere aufeinanderfolgende Rahmen gebildet - für das Intervall </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Δt</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Innerhalb einer Stunde werden Werte für mehrere solcher Intervalle für jeden Raum entladen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Größe des Zeitintervalls und die Anzahl der Intervalle werden basierend auf der Anzahl der Räume und der verwendeten Rechenleistung bestimmt. Für jedes Intervall wird ein Array von Werten mit der Anzahl der Personen im Raum gebildet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der häufigste Wert (Modus) wird ausgewählt. Wenn mehrere Werte mit derselben Frequenz vorhanden sind, wird das Maximum ausgewählt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der resultierende Wert ist die Anzahl der Personen in der Warteschlange zum Zeitpunkt </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">unmittelbar nach dem fraglichen Intervall. </font><font style="vertical-align: inherit;">In nur einer Stunde wird eine Reihe von Werten für verschiedene Intervalle erhalten - dh Werte zu den Zeitpunkten </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t_1, t_2 .... </font><font style="vertical-align: inherit;">t_n</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Weiter für </font></font><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t_1, t_2 .... </font><font style="vertical-align: inherit;">t_n werden die</font></font></i></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Maximal- und Durchschnittswerte der Anzahl der Personen berechnet - diese Werte werden im Bericht als Spitzen- und Durchschnittslasten für eine bestimmte Stunde angezeigt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diagramm der zeitlichen Verteilung der Personen bei maximaler Belastung (einfaches Beispiel): </font></font><br>
<br>
<img src="https://habrastorage.org/webt/um/nb/zp/umnbzpjh1aj_0gdt1qhwywj8niu.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diagramm der zeitlichen Verteilung der Personen bei durchschnittlicher Belastung (einfaches Beispiel):</font></font><br>
<br>
<img src="https://habrastorage.org/webt/rj/h4/rx/rjh4rxxkyftekb8tspvwylamwu8.png" alt="Bild"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menschenmassen</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Abschließend möchte ich der Vollständigkeit halber das Thema sehr großer Menschenmengen erwähnen, zum Beispiel Menschenmengen in Stadien an Orten mit starkem Menschenverkehr. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei diesen Aufgaben geht es darum, die Größe der Menge zu schätzen: Wenn es sich um eine Menge von 300 Personen handelt, wird eine Antwort von 312 oder 270 als akzeptabel angesehen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In der Praxis mussten wir solche Probleme nicht mithilfe von Videoanalysen lösen (wenn es sich um eine organisierte Veranstaltung handelt, ist es für jede Person einfacher, ein Etikett auszustellen). Wir haben jedoch Tests durchgeführt. Für solche Aufgaben werden separate Methoden verwendet, eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Übersicht über die Methoden</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Ergebnis des Modells aus der Überprüfung (auf CSRNet vorab trainiertes Modell) wurde reproduziert:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vq/ks/-k/vqks-kmt4kykj1vuls2t9dr18sc.png" alt="Bild"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Winkel ist wichtig für die Einstellungen dieses Modells. Wenn der Aufnahmeort festgelegt ist, ist das Ergebnis besser als bei Anwendung auf verschiedene Bilder. </font><font style="vertical-align: inherit;">Im Allgemeinen besteht die Möglichkeit, dieses Modell neu zu trainieren. Die Qualität kann während des Modellbetriebs verbessert werden, wenn echtes Video von installierten Kameras eingeschaltet ist. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Autoren des Artikels: Tatyana Voronova (</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tvoronova</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), Elvira Dyaminova (</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Elviraa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></i></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de496600/index.html">В рамках импортозамещения Москва закупает ПО Microsoft на 90 млн рублей</a></li>
<li><a href="../de496608/index.html">Food Design Digest, März 2020</a></li>
<li><a href="../de496610/index.html">Router Banana Pi R64 - Debian, Wireguard, ILV</a></li>
<li><a href="../de496612/index.html">Ja, mein alter Laptop ist um ein Vielfaches leistungsstärker als Ihr Produktionsserver</a></li>
<li><a href="../de496614/index.html">Wie haben sich die Habrachen in 5 Jahren verändert? Oder "280 Wochen später"</a></li>
<li><a href="../de496620/index.html">Beliebte Fehler in Englisch bei IT-Fachleuten</a></li>
<li><a href="../de496626/index.html">Geselle und Drachen: Wie man dem Praktikanten hilft, sich als Team anzupassen</a></li>
<li><a href="../de496630/index.html">Interface Bikes Giftiger Großvater. "Artefakte mein Arsch!" (s1 e5)</a></li>
<li><a href="../de496634/index.html">Schule 21 für den Antragsteller</a></li>
<li><a href="../de496638/index.html">F #, Markierungsalgorithmus für verbundene Bildkomponenten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
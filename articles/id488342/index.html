<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎀 😗 👩🏾‍⚕️ Random Forest, metode komponen utama dan optimalisasi hyperparameters: contoh penyelesaian masalah klasifikasi dengan Python 👏🏽 🉐 💩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Spesialis pemrosesan dan analisis data memiliki banyak alat untuk membuat model klasifikasi. Salah satu metode yang paling populer dan dapat diandalka...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Random Forest, metode komponen utama dan optimalisasi hyperparameters: contoh penyelesaian masalah klasifikasi dengan Python</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/488342/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spesialis pemrosesan dan analisis data memiliki banyak alat untuk membuat model klasifikasi. </font><font style="vertical-align: inherit;">Salah satu metode yang paling populer dan dapat diandalkan untuk mengembangkan model tersebut adalah dengan menggunakan algoritma Random Forest (RF). </font><font style="vertical-align: inherit;">Untuk mencoba meningkatkan kinerja model yang dibangun menggunakan algoritma </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RF</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Anda dapat menggunakan optimisasi hyperparameter model ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hyperparameter Tuning</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , HT). </font><font style="vertical-align: inherit;">
Selain itu, ada pendekatan luas yang menurutnya data, sebelum dipindahkan ke model, diproses menggunakan </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">Analisis Komponen Utama.</font></a></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><img src="https://habrastorage.org/webt/tt/m5/h7/ttm5h7jbbx2u2wuc1var1azxwew.jpeg"></a><br>
<br><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, PCA). </font><font style="vertical-align: inherit;">Tetapi apakah itu layak untuk digunakan? </font><font style="vertical-align: inherit;">Bukankah tujuan utama dari algoritma RF untuk membantu analis mengartikan pentingnya sifat-sifat tersebut?</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ya, penggunaan algoritma PCA dapat menyebabkan sedikit komplikasi dari interpretasi setiap "fitur" dalam analisis "pentingnya fitur" dari model RF. Namun, algoritma PCA mengurangi dimensi ruang fitur, yang dapat menyebabkan penurunan jumlah fitur yang perlu diproses oleh model RF. Harap dicatat bahwa volume perhitungan adalah salah satu kelemahan utama dari algoritma hutan acak (yaitu, ini bisa memakan waktu lama untuk menyelesaikan model). Penerapan algoritma PCA dapat menjadi bagian yang sangat penting dalam pemodelan, terutama dalam kasus di mana mereka bekerja dengan ratusan atau bahkan ribuan fitur. Akibatnya, jika hal yang paling penting adalah menciptakan model yang paling efektif, dan pada saat yang sama Anda dapat mengorbankan keakuratan dalam menentukan pentingnya sifat-sifat tersebut, maka PCA mungkin patut dicoba.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang to the point. </font><font style="vertical-align: inherit;">Kami akan bekerja dengan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dataset kanker payudara</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">Scikit-belajar "kanker payudara"</font></a><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Kami akan membuat tiga model dan membandingkan efektivitasnya. </font><font style="vertical-align: inherit;">Yaitu, kita berbicara tentang model-model berikut:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model dasar berdasarkan pada algoritma RF (kami akan menyingkat model RF ini).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model yang sama dengan No. 1, tetapi di mana pengurangan dimensi ruang fitur diterapkan menggunakan metode komponen utama (RF + PCA).</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model yang sama dengan No. 2, tetapi dibangun menggunakan optimisasi hyperparameter (RF + PCA + HT).</font></font></li>
</ol><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. Impor data</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Untuk memulai, muat data dan buat bingkai data Pandas. </font><font style="vertical-align: inherit;">Karena kita menggunakan set data "mainan" yang telah dibersihkan dari Scikit-learn, maka setelah itu kita sudah dapat memulai proses pemodelan. </font><font style="vertical-align: inherit;">Tetapi bahkan ketika menggunakan data tersebut, Anda disarankan untuk selalu mulai bekerja dengan melakukan analisis awal data menggunakan perintah berikut yang diterapkan pada bingkai data ( </font></font><code>df</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">):</font></font><br>
<br>
<ul>
<li><code>df.head()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - untuk melihat bingkai data baru dan melihat apakah itu terlihat seperti yang diharapkan.</font></font></li>
<li><code>df.info()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- untuk mengetahui fitur tipe data dan konten kolom. </font><font style="vertical-align: inherit;">Mungkin perlu melakukan konversi tipe data sebelum melanjutkan.</font></font></li>
<li><code>df.isna()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- untuk memastikan bahwa tidak ada nilai dalam data </font></font><code>NaN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Nilai yang sesuai, jika ada, mungkin perlu diproses entah bagaimana, atau, jika perlu, mungkin perlu untuk menghapus seluruh baris dari bingkai data.</font></font></li>
<li><code>df.describe()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - untuk mengetahui nilai rata-rata minimum, maksimum, rata-rata dari indikator dalam kolom, untuk mengetahui indikator rata-rata kuadrat dan kemungkinan penyimpangan dalam kolom.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam dataset kami, kolom </font></font><code>cancer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(kanker) adalah variabel target yang nilainya ingin diprediksi menggunakan model. </font></font><code>0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">berarti "tidak ada penyakit." </font></font><code>1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- "Kehadiran penyakit."</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_breast_cancer<font></font>
columns = [<span class="hljs-string">'mean radius'</span>, <span class="hljs-string">'mean texture'</span>, <span class="hljs-string">'mean perimeter'</span>, <span class="hljs-string">'mean area'</span>, <span class="hljs-string">'mean smoothness'</span>, <span class="hljs-string">'mean compactness'</span>, <span class="hljs-string">'mean concavity'</span>, <span class="hljs-string">'mean concave points'</span>, <span class="hljs-string">'mean symmetry'</span>, <span class="hljs-string">'mean fractal dimension'</span>, <span class="hljs-string">'radius error'</span>, <span class="hljs-string">'texture error'</span>, <span class="hljs-string">'perimeter error'</span>, <span class="hljs-string">'area error'</span>, <span class="hljs-string">'smoothness error'</span>, <span class="hljs-string">'compactness error'</span>, <span class="hljs-string">'concavity error'</span>, <span class="hljs-string">'concave points error'</span>, <span class="hljs-string">'symmetry error'</span>, <span class="hljs-string">'fractal dimension error'</span>, <span class="hljs-string">'worst radius'</span>, <span class="hljs-string">'worst texture'</span>, <span class="hljs-string">'worst perimeter'</span>, <span class="hljs-string">'worst area'</span>, <span class="hljs-string">'worst smoothness'</span>, <span class="hljs-string">'worst compactness'</span>, <span class="hljs-string">'worst concavity'</span>, <span class="hljs-string">'worst concave points'</span>, <span class="hljs-string">'worst symmetry'</span>, <span class="hljs-string">'worst fractal dimension'</span>]<font></font>
dataset = load_breast_cancer()<font></font>
data = pd.DataFrame(dataset[<span class="hljs-string">'data'</span>], columns=columns)<font></font>
data[<span class="hljs-string">'cancer'</span>] = dataset[<span class="hljs-string">'target'</span>]<font></font>
display(data.head())<font></font>
display(data.info())<font></font>
display(data.isna().sum())<font></font>
display(data.describe())</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bce/fb8/b60/bcefb8b60462b7658b40e1e56f7744ab.png"></div><br>
<i><font color="#999999">      .       .  , cancer,   ,    . 0  « ». 1 — « »</font></i><br>
 <br>
<h2><font color="#3AC1EF">2.        </font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang pisahkan data menggunakan fungsi Scikit-learn </font></font><code>train_test_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Kami ingin memberikan model sebanyak mungkin data pelatihan. Namun, kita perlu memiliki data yang cukup untuk menguji model. Secara umum, kita dapat mengatakan bahwa, ketika jumlah baris dalam kumpulan data meningkat, demikian juga jumlah data yang dapat dianggap mendidik. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Misalnya, jika ada jutaan baris, Anda dapat membagi set dengan menyoroti 90% dari baris untuk data pelatihan dan 10% untuk data uji. Tetapi kumpulan data uji hanya berisi 569 baris. Dan ini bukan untuk pelatihan dan pengujian model. Sebagai hasilnya, agar adil dalam kaitannya dengan data pelatihan dan verifikasi, kami akan membagi set menjadi dua bagian yang sama - 50% - data pelatihan dan 50% - data verifikasi. Kami memasang</font></font><code>stratify=y</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> untuk memastikan bahwa set data pelatihan dan tes memiliki rasio yang sama dengan 0 dan 1 seperti set data asli.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
X = data.drop(<span class="hljs-string">'cancer'</span>, axis=<span class="hljs-number">1</span>)&nbsp;&nbsp;<font></font>
y = data[<span class="hljs-string">'cancer'</span>]&nbsp;<font></font>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.50</span>, random_state = <span class="hljs-number">2020</span>, stratify=y)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3. Penskalaan data</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sebelum melanjutkan ke pemodelan, Anda perlu "memusat" dan "membakukan" data dengan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menskalanya</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Penskalaan dilakukan karena fakta bahwa jumlah yang berbeda dinyatakan dalam unit yang berbeda. </font><font style="vertical-align: inherit;">Prosedur ini memungkinkan Anda untuk mengatur "pertarungan yang adil" antara tanda-tanda dalam menentukan kepentingannya. </font><font style="vertical-align: inherit;">Selain itu, kami mengonversi </font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dari tipe data Pandas </font></font><code>Series</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke array NumPy sehingga nantinya model dapat bekerja dengan target yang sesuai.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<font></font>
ss = StandardScaler()<font></font>
X_train_scaled = ss.fit_transform(X_train)<font></font>
X_test_scaled = ss.transform(X_test)<font></font>
y_train = np.array(y_train)</code></pre><br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4. Pelatihan model dasar (model No. 1, RF)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang buat model nomor 1. </font><font style="vertical-align: inherit;">Di dalamnya, kita ingat bahwa hanya algoritma Random Forest yang digunakan. </font><font style="vertical-align: inherit;">Ini menggunakan semua fitur dan dikonfigurasi menggunakan nilai default (detail tentang pengaturan ini dapat ditemukan dalam dokumentasi untuk </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sklearn.ensemble.RandomForestClassifier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Inisialisasi model. </font><font style="vertical-align: inherit;">Setelah itu, kami akan melatihnya tentang data yang diskalakan. </font><font style="vertical-align: inherit;">Keakuratan model dapat diukur pada data pelatihan:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> recall_score<font></font>
rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled, y_train)<font></font>
display(rfc.score(X_train_scaled, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jika kita tertarik untuk mengetahui sifat mana yang paling penting untuk model RF dalam memprediksi kanker payudara, kita dapat memvisualisasikan dan mengukur indeks keparahan sifat dengan merujuk pada atribut </font></font><code>feature_importances_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="python hljs">feats = {}
<span class="hljs-keyword">for</span> feature, importance <span class="hljs-keyword">in</span> zip(data.columns, rfc_1.feature_importances_):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;feats[feature] = importance<font></font>
importances = pd.DataFrame.from_dict(feats, orient=<span class="hljs-string">'index'</span>).rename(columns={<span class="hljs-number">0</span>: <span class="hljs-string">'Gini-Importance'</span>})<font></font>
importances = importances.sort_values(by=<span class="hljs-string">'Gini-Importance'</span>, ascending=<span class="hljs-literal">False</span>)<font></font>
importances = importances.reset_index()<font></font>
importances = importances.rename(columns={<span class="hljs-string">'index'</span>: <span class="hljs-string">'Features'</span>})<font></font>
sns.set(font_scale = <span class="hljs-number">5</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">1.7</span>)<font></font>
fig, ax = plt.subplots()<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">15</span>)<font></font>
sns.barplot(x=importances[<span class="hljs-string">'Gini-Importance'</span>], y=importances[<span class="hljs-string">'Features'</span>], data=importances, color=<span class="hljs-string">'skyblue'</span>)<font></font>
plt.xlabel(<span class="hljs-string">'Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'Features'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
plt.title(<span class="hljs-string">'Feature Importance'</span>, fontsize=<span class="hljs-number">25</span>, weight = <span class="hljs-string">'bold'</span>)<font></font>
display(plt.show())<font></font>
display(importances)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a02/a8f/cd2/a02a8fcd28f87af338f364a70faeca3e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualisasi "pentingnya" tanda</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/830/176/e1f/830176e1fc9ce63bfedf2d727619253b.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Indikator signifikansi</font></font></font></i><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5. Metode komponen utama</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang mari kita bertanya bagaimana kita dapat meningkatkan model RF dasar. Dengan menggunakan teknik mengurangi dimensi ruang fitur, dimungkinkan untuk menyajikan set data awal melalui variabel yang lebih sedikit dan pada saat yang sama mengurangi jumlah sumber daya komputasi yang diperlukan untuk memastikan operasi model. Menggunakan PCA, Anda dapat mempelajari varians sampel kumulatif dari fitur-fitur ini untuk memahami fitur apa yang menjelaskan sebagian besar varian dalam data. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami menginisialisasi objek PCA ( </font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), menunjukkan jumlah komponen (fitur) yang perlu dipertimbangkan. Kami menetapkan indikator ini ke 30 untuk melihat perbedaan yang dijelaskan dari semua komponen yang dihasilkan sebelum memutuskan berapa banyak komponen yang kami butuhkan. Lalu kami transfer ke </font></font><code>pca_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">data yang diskalakan</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menggunakan metode ini </font></font><code>pca_test.fit()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Setelah itu kami memvisualisasikan data.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<font></font>
pca_test = PCA(n_components=<span class="hljs-number">30</span>)<font></font>
pca_test.fit(X_train_scaled)<font></font>
sns.set(style=<span class="hljs-string">'whitegrid'</span>)<font></font>
plt.plot(np.cumsum(pca_test.explained_variance_ratio_))<font></font>
plt.xlabel(<span class="hljs-string">'number of components'</span>)<font></font>
plt.ylabel(<span class="hljs-string">'cumulative explained variance'</span>)<font></font>
plt.axvline(linewidth=<span class="hljs-number">4</span>, color=<span class="hljs-string">'r'</span>, linestyle = <span class="hljs-string">'--'</span>, x=<span class="hljs-number">10</span>, ymin=<span class="hljs-number">0</span>, ymax=<span class="hljs-number">1</span>)<font></font>
display(plt.show())<font></font>
evr = pca_test.explained_variance_ratio_<font></font>
cvr = np.cumsum(pca_test.explained_variance_ratio_)<font></font>
pca_df = pd.DataFrame()<font></font>
pca_df[<span class="hljs-string">'Cumulative Variance Ratio'</span>] = cvr<font></font>
pca_df[<span class="hljs-string">'Explained Variance Ratio'</span>] = evr<font></font>
display(pca_df.head(<span class="hljs-number">10</span>))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6eb/65f/acc/6eb65facc6c8b05f1e910d3b2b676d5e.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah jumlah komponen yang digunakan melebihi 10, peningkatan jumlahnya tidak banyak meningkatkan varian yang dijelaskan</font></font></font></i><br>
 <br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f12/e3c/915/f12e3c915d761e1d4623051dac74cd8d.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kerangka data ini berisi indikator seperti Cumulative Variance Ratio (ukuran kumulatif dari varians yang dijelaskan dari data) dan Explained Variance Ratio (kontribusi masing-masing komponen terhadap total volume dari varian yang dijelaskan)</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Jika Anda melihat pada kerangka data di atas, ternyata menggunakan PCA untuk berpindah dari 30 variabel menjadi 10 untuk komponen memungkinkan untuk menjelaskan 95% dari dispersi data. 20 komponen lainnya menyumbang kurang dari 5% dari varians, yang berarti bahwa kita dapat menolaknya. Mengikuti logika ini, kami menggunakan PCA untuk mengurangi jumlah komponen dari 30 menjadi 10 untuk</font></font><code>X_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan</font></font><code>X_test</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Kami menulis ini artifisial diciptakan “mengurangi dimensi” Data set di</font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan di</font></font><code>X_test_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">pca = PCA(n_components=<span class="hljs-number">10</span>)<font></font>
pca.fit(X_train_scaled)<font></font>
X_train_scaled_pca = pca.transform(X_train_scaled)<font></font>
X_test_scaled_pca = pca.transform(X_test_scaled)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setiap komponen adalah kombinasi linear dari variabel sumber dengan "bobot" yang sesuai. </font><font style="vertical-align: inherit;">Kita dapat melihat "bobot" ini untuk setiap komponen dengan membuat bingkai data.</font></font><br>
<br>
<pre><code class="python hljs">pca_dims = []
<span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, len(pca_df)):<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;pca_dims.append(<span class="hljs-string">'PCA Component {}'</span>.format(x))<font></font>
pca_test_df = pd.DataFrame(pca_test.components_, columns=columns, index=pca_dims)<font></font>
pca_test_df.head(<span class="hljs-number">10</span>).T</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/086/a28/ae4/086a28ae45e9048811cf813d4868902e.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dataframe Informasi Komponen</font></font></font></i><br>
 <br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6. Pelatihan model RF dasar setelah menerapkan metode komponen utama ke data (model No. 2, RF + PCA)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang kita dapat meneruskan ke data model RF dasar lainnya </font></font><code>X_train_scaled_pca</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan </font></font><code>y_train</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan dapat mencari tahu apakah ada peningkatan dalam akurasi prediksi yang dikeluarkan oleh model.</font></font><br>
<br>
<pre><code class="python hljs">rfc = RandomForestClassifier()<font></font>
rfc.fit(X_train_scaled_pca, y_train)<font></font>
display(rfc.score(X_train_scaled_pca, y_train))<font></font>
<span class="hljs-comment"># 1.0</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Model membandingkan di bawah ini.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7. Optimalisasi hiperparameter. </font><font style="vertical-align: inherit;">Babak 1: RandomizedSearchCV</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setelah memproses data menggunakan metode komponen utama, Anda dapat mencoba menggunakan </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optimisasi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> model </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">hiperparameter</font></a><font style="vertical-align: inherit;"> untuk meningkatkan kualitas prediksi yang dihasilkan oleh model RF. Hyperparameters dapat dianggap sebagai sesuatu seperti "pengaturan" model. Pengaturan yang sempurna untuk satu set data tidak akan berfungsi untuk yang lain - itu sebabnya Anda perlu mengoptimalkannya. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda bisa mulai dengan algoritma RandomizedSearchCV, yang memungkinkan Anda untuk menjelajahi kira-kira berbagai nilai. Deskripsi semua hiperparameter untuk model RF dapat ditemukan di </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sini</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dalam perjalanan kerja, kami menghasilkan entitas </font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yang berisi, untuk setiap hyperparameter, rentang nilai yang perlu diuji. Selanjutnya, kita inisialisasi objek.</font></font><code>rs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menggunakan fungsi </font></font><code>RandomizedSearchCV()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, meneruskannya model RF </font></font><code>param_dist</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,, jumlah iterasi dan jumlah </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">validasi silang</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> yang perlu dilakukan. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hyperparameter </font></font><code>verbose</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memungkinkan Anda untuk mengontrol jumlah informasi yang ditampilkan oleh model selama operasinya (seperti output informasi selama pelatihan model). </font><font style="vertical-align: inherit;">Hyperparameter </font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memungkinkan Anda menentukan berapa banyak inti prosesor yang perlu Anda gunakan untuk memastikan pengoperasian model. </font><font style="vertical-align: inherit;">Mengaturnya </font></font><code>n_jobs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ke nilai </font></font><code>-1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">akan mengarah ke model yang lebih cepat, karena ini akan menggunakan semua inti prosesor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami akan terlibat dalam pemilihan hyperparameter berikut:</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - jumlah "pohon" di "hutan acak".</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - jumlah fitur untuk memilih pemisahan.</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - kedalaman maksimum pohon.</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - jumlah minimum objek yang diperlukan untuk membelah simpul pohon.</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - jumlah minimum objek dalam daun.</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - digunakan untuk membangun pohon subsampel dengan pengembalian.</font></font></li>
</ul><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV<font></font>
n_estimators = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">100</span>, stop = <span class="hljs-number">1000</span>, num = <span class="hljs-number">10</span>)]<font></font>
max_features = [<span class="hljs-string">'log2'</span>, <span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">1</span>, stop = <span class="hljs-number">15</span>, num = <span class="hljs-number">15</span>)]<font></font>
min_samples_split = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
min_samples_leaf = [int(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> np.linspace(start = <span class="hljs-number">2</span>, stop = <span class="hljs-number">50</span>, num = <span class="hljs-number">10</span>)]<font></font>
bootstrap = [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>]<font></font>
param_dist = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
rs = RandomizedSearchCV(rfc_2,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;param_dist,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_iter = <span class="hljs-number">100</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv = <span class="hljs-number">3</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose = <span class="hljs-number">1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_jobs=<span class="hljs-number">-1</span>,&nbsp;<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random_state=<span class="hljs-number">0</span>)<font></font>
rs.fit(X_train_scaled_pca, y_train)<font></font>
rs.best_params_<font></font>
<span class="hljs-comment"># {'n_estimators': 700,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'min_samples_leaf': 2,</span>
<span class="hljs-comment"># 'max_features': 'log2',</span>
<span class="hljs-comment"># 'max_depth': 11,</span>
<span class="hljs-comment"># 'bootstrap': True}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dengan nilai-nilai parameter </font></font><code>n_iter = 100</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan </font></font><code>cv = 3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, kami menciptakan 300 model RF, secara acak memilih kombinasi dari </font><font style="vertical-align: inherit;">parameter </font><font style="vertical-align: inherit;">hiper yang disajikan di atas. </font><font style="vertical-align: inherit;">Kami dapat merujuk ke atribut </font></font><code>best_params_ </code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untuk informasi tentang serangkaian parameter yang memungkinkan Anda untuk membuat model terbaik. </font><font style="vertical-align: inherit;">Tetapi pada tahap ini, ini mungkin tidak memberi kami data paling menarik tentang rentang parameter yang perlu ditelusuri dalam putaran optimasi berikutnya. </font><font style="vertical-align: inherit;">Untuk mengetahui rentang nilai mana yang layak untuk terus dicari, kita dapat dengan mudah mendapatkan bingkai data yang berisi hasil dari algoritma RandomizedSearchCV.</font></font><br>
<br>
<pre><code class="python hljs">rs_df = pd.DataFrame(rs.cv_results_).sort_values(<span class="hljs-string">'rank_test_score'</span>).reset_index(drop=<span class="hljs-literal">True</span>)<font></font>
rs_df = rs_df.drop([<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_fit_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'mean_score_time'</span>,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_score_time'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'params'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split0_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split1_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'split2_test_score'</span>,&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'std_test_score'</span>],<font></font>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;axis=<span class="hljs-number">1</span>)<font></font>
rs_df.head(<span class="hljs-number">10</span>)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/617/b8c/20b/617b8c20b787acc3c76c23d9235b4b5a.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasil dari algoritma RandomizedSearchCV</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Sekarang kita akan membuat grafik batang yang, pada sumbu X, adalah nilai hyperparameter, dan pada sumbu Y adalah nilai rata-rata yang ditunjukkan oleh model. </font><font style="vertical-align: inherit;">Ini akan memungkinkan untuk memahami nilai hiperparameter apa, secara rata-rata, menunjukkan kinerja terbaiknya.</font></font><br>
<br>
<pre><code class="python hljs">fig, axs = plt.subplots(ncols=<span class="hljs-number">3</span>, nrows=<span class="hljs-number">2</span>)<font></font>
sns.set(style=<span class="hljs-string">"whitegrid"</span>, color_codes=<span class="hljs-literal">True</span>, font_scale = <span class="hljs-number">2</span>)<font></font>
fig.set_size_inches(<span class="hljs-number">30</span>,<span class="hljs-number">25</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_n_estimators'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'lightgrey'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.83</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'n_estimators'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_split'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'coral'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.85</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'min_samples_split'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_min_samples_leaf'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'lightgreen'</span>)<font></font>
axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'min_samples_leaf'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_features'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>], color=<span class="hljs-string">'wheat'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>].set_title(label = <span class="hljs-string">'max_features'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_max_depth'</span>, y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], color=<span class="hljs-string">'lightpink'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_ylim([<span class="hljs-number">.80</span>,<span class="hljs-number">.93</span>])axs[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>].set_title(label = <span class="hljs-string">'max_depth'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
sns.barplot(x=<span class="hljs-string">'param_bootstrap'</span>,y=<span class="hljs-string">'mean_test_score'</span>, data=rs_df, ax=axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], color=<span class="hljs-string">'skyblue'</span>)<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_ylim([<span class="hljs-number">.88</span>,<span class="hljs-number">.92</span>])<font></font>
axs[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>].set_title(label = <span class="hljs-string">'bootstrap'</span>, size=<span class="hljs-number">30</span>, weight=<span class="hljs-string">'bold'</span>)<font></font>
plt.show()</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/418/311/ba6/418311ba6c38bfcebbf152af810d6b58.jpg"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Analisis nilai-nilai hiperparameter</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Jika kita menganalisis grafik di atas, kita dapat melihat beberapa hal menarik yang berbicara tentang bagaimana, secara rata-rata, setiap nilai dari hiperparameter mempengaruhi model.</font></font><br>
<br>
<ul>
<li><code>n_estimators</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: nilai 300, 500, 700, tampaknya, menunjukkan hasil rata-rata terbaik.</font></font></li>
<li><code>min_samples_split</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: Nilai-nilai kecil seperti 2 dan 7 tampaknya menunjukkan hasil terbaik. </font><font style="vertical-align: inherit;">Nilai 23 juga terlihat bagus. Anda dapat memeriksa beberapa nilai hyperparameter ini lebih dari 2, dan juga beberapa nilai sekitar 23.</font></font></li>
<li><code>min_samples_leaf</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: Ada perasaan bahwa nilai-nilai kecil dari hyperparameter ini memberikan hasil yang lebih baik. </font><font style="vertical-align: inherit;">Ini berarti bahwa kita dapat mengalami nilai antara 2 dan 7.</font></font></li>
<li><code>max_features</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: opsi </font></font><code>sqrt</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memberikan hasil rata-rata tertinggi.</font></font></li>
<li><code>max_depth</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: tidak ada hubungan yang jelas antara nilai hyperparameter dan hasil model, tetapi ada perasaan bahwa nilai 2, 3, 7, 11, 15 terlihat bagus.</font></font></li>
<li><code>bootstrap</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: nilai </font></font><code>False</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menunjukkan hasil rata-rata terbaik.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang, dengan menggunakan temuan ini, kita dapat beralih ke putaran kedua optimasi hyperparameters. </font><font style="vertical-align: inherit;">Ini akan mempersempit rentang nilai yang kami minati.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8. Optimalisasi hiperparameter. </font><font style="vertical-align: inherit;">Babak 2: GridSearchCV (persiapan akhir parameter untuk model No. 3, RF + PCA + HT)</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setelah menerapkan algoritma RandomizedSearchCV, kami akan menggunakan algoritma GridSearchCV untuk melakukan pencarian yang lebih akurat untuk kombinasi hyperparameter terbaik. Hyperparameter yang sama diselidiki di sini, tetapi sekarang kami menerapkan pencarian yang lebih "menyeluruh" untuk kombinasi terbaiknya. Dengan menggunakan algoritma GridSearchCV, setiap kombinasi hyperparameter diperiksa. Ini membutuhkan lebih banyak sumber daya komputasi daripada menggunakan algoritma RandomizedSearchCV ketika kami secara independen mengatur jumlah iterasi pencarian. Misalnya, meneliti 10 nilai untuk masing-masing 6 hiperparameter dengan validasi silang dalam 3 blok akan memerlukan 10⁶ x 3, atau 3.000.000 sesi pelatihan model. Itu sebabnya kami menggunakan algoritma GridSearchCV setelah, setelah menerapkan RandomizedSearchCV, kami mempersempit rentang nilai dari parameter yang dipelajari.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jadi, menggunakan apa yang kami temukan dengan bantuan RandomizedSearchCV, kami memeriksa nilai-nilai hyperparameters yang telah menunjukkan diri mereka yang terbaik:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV<font></font>
n_estimators = [<span class="hljs-number">300</span>,<span class="hljs-number">500</span>,<span class="hljs-number">700</span>]<font></font>
max_features = [<span class="hljs-string">'sqrt'</span>]<font></font>
max_depth = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">7</span>,<span class="hljs-number">11</span>,<span class="hljs-number">15</span>]<font></font>
min_samples_split = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">22</span>,<span class="hljs-number">23</span>,<span class="hljs-number">24</span>]<font></font>
min_samples_leaf = [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<font></font>
bootstrap = [<span class="hljs-literal">False</span>]<font></font>
param_grid = {<span class="hljs-string">'n_estimators'</span>: n_estimators,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_features'</span>: max_features,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'max_depth'</span>: max_depth,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_split'</span>: min_samples_split,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'min_samples_leaf'</span>: min_samples_leaf,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="hljs-string">'bootstrap'</span>: bootstrap}<font></font>
gs = GridSearchCV(rfc_2, param_grid, cv = <span class="hljs-number">3</span>, verbose = <span class="hljs-number">1</span>, n_jobs=<span class="hljs-number">-1</span>)<font></font>
gs.fit(X_train_scaled_pca, y_train)<font></font>
rfc_3 = gs.best_estimator_<font></font>
gs.best_params_<font></font>
<span class="hljs-comment"># {'bootstrap': False,</span>
<span class="hljs-comment"># 'max_depth': 7,</span>
<span class="hljs-comment"># 'max_features': 'sqrt',</span>
<span class="hljs-comment"># 'min_samples_leaf': 3,</span>
<span class="hljs-comment"># 'min_samples_split': 2,</span>
<span class="hljs-comment"># 'n_estimators': 500}</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Di sini kami menerapkan validasi silang dalam 3 blok untuk sesi pelatihan model 540 (3 x 1 x 5 x 6 x 6 x 1), yang memberikan 1620 sesi pelatihan model. </font><font style="vertical-align: inherit;">Dan sekarang, setelah kami menggunakan RandomizedSearchCV dan GridSearchCV, kita dapat beralih ke atribut </font></font><code>best_params_</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untuk mencari tahu nilai hyperparameters mana yang memungkinkan model bekerja paling baik dengan kumpulan data yang diteliti (nilai-nilai ini dapat dilihat di bagian bawah blok kode sebelumnya) . </font><font style="vertical-align: inherit;">Parameter ini digunakan untuk membuat model nomor 3.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9. Evaluasi kualitas model pada data verifikasi</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sekarang Anda dapat mengevaluasi model yang dibuat pada data verifikasi. </font><font style="vertical-align: inherit;">Yaitu, kita berbicara tentang ketiga model yang dijelaskan di awal materi. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lihat model-model ini:</font></font><br>
<br>
<pre><code class="python hljs">y_pred = rfc.predict(X_test_scaled)<font></font>
y_pred_pca = rfc.predict(X_test_scaled_pca)<font></font>
y_pred_gs = gs.best_estimator_.predict(X_test_scaled_pca)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Buat matriks kesalahan untuk model dan cari tahu seberapa baik masing-masing dari mereka dapat memprediksi kanker payudara:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix<font></font>
conf_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_pred), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_baseline_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_pca), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
conf_matrix_tuned_pca = pd.DataFrame(confusion_matrix(y_test, y_pred_gs), index = [<span class="hljs-string">'actual 0'</span>, <span class="hljs-string">'actual 1'</span>], columns = [<span class="hljs-string">'predicted 0'</span>, <span class="hljs-string">'predicted 1'</span>])<font></font>
display(conf_matrix_baseline)<font></font>
display(<span class="hljs-string">'Baseline Random Forest recall score'</span>, recall_score(y_test, y_pred))<font></font>
display(conf_matrix_baseline_pca)<font></font>
display(<span class="hljs-string">'Baseline Random Forest With PCA recall score'</span>, recall_score(y_test, y_pred_pca))<font></font>
display(conf_matrix_tuned_pca)<font></font>
display(<span class="hljs-string">'Hyperparameter Tuned Random Forest With PCA Reduced Dimensionality recall score'</span>, recall_score(y_test, y_pred_gs))</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f48/a9e/92f/f48a9e92fd5fdca613d6073e00bae2c6.png"></div><br>
<i><font color="#999999"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hasil karya tiga model</font></font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Di sini metrik "kelengkapan" (recall) dievaluasi. </font><font style="vertical-align: inherit;">Faktanya adalah bahwa kita sedang berhadapan dengan diagnosis kanker. </font><font style="vertical-align: inherit;">Karena itu, kami sangat tertarik untuk meminimalkan ramalan negatif palsu yang dikeluarkan oleh model. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dengan ini, kita dapat menyimpulkan bahwa model RF dasar memberikan hasil terbaik. </font><font style="vertical-align: inherit;">Tingkat kelengkapannya adalah 94,97%. </font><font style="vertical-align: inherit;">Dalam dataset uji, ada catatan 179 pasien yang menderita kanker. </font><font style="vertical-align: inherit;">Model menemukan 170 di antaranya.</font></font><br>
<br>
<h2><font color="#3AC1EF"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ringkasan</font></font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Penelitian ini memberikan pengamatan penting. </font><font style="vertical-align: inherit;">Terkadang model RF, yang menggunakan metode komponen utama dan optimisasi skala besar dari hiperparameter, mungkin tidak berfungsi sebaik model paling umum dengan pengaturan standar. </font><font style="vertical-align: inherit;">Tapi ini bukan alasan untuk membatasi diri hanya pada model yang paling sederhana. </font><font style="vertical-align: inherit;">Tanpa mencoba model yang berbeda, tidak mungkin untuk mengatakan mana yang akan menunjukkan hasil terbaik. </font><font style="vertical-align: inherit;">Dan dalam kasus model yang digunakan untuk memprediksi keberadaan kanker pada pasien, kita dapat mengatakan bahwa semakin baik model - semakin banyak nyawa dapat diselamatkan. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pembaca yang budiman! </font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tugas apa yang Anda selesaikan menggunakan metode pembelajaran mesin?</font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id488330/index.html">Bahasa Inggris bersama George Karlin: kami menganalisis kemandirian tentang unit-unit ungkapan</a></li>
<li><a href="../id488332/index.html">Nol, satu, dua, Freddy akan menjemputmu</a></li>
<li><a href="../id488336/index.html">Kiat untuk Menggunakan Algoritma Fungsi Runtuh Gelombang</a></li>
<li><a href="../id488338/index.html">Google Magang: Zurich, London, dan Lembah Silikon</a></li>
<li><a href="../id488340/index.html">Profesi: Pengembang Backend</a></li>
<li><a href="../id488346/index.html">Menginstal atau-alat dengan SCIP dan GLPK di lingkungan virtual Python 3.7 di Linux</a></li>
<li><a href="../id488348/index.html">Webinar "Sepuluh Tantangan Agile Top dan Cara Mengatasi Mereka dalam Satu Jam" 17 Februari pukul 20:00 waktu Moskow</a></li>
<li><a href="../id488352/index.html">Perbandingan Biaya VDI: On-premise versus Cloud Publik</a></li>
<li><a href="../id488356/index.html">Pelatihan di Universitas Teknik Kelautan State Petersburg untuk produk Dassault Systèmes</a></li>
<li><a href="../id488360/index.html">Mitos Data Besar dan Budaya Digital</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
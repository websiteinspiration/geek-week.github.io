<!doctype html>
<html class="no-js" lang="id">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✍🏽 💆 🚣🏾 YOLOv4 - jaringan saraf real-time paling akurat pada dataset COCO Microsoft 💇🏾 🧓🏾 🏵️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Darknet YOLOv4 lebih cepat / lebih akurat daripada Google TensorFlow EfficientDet dan FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. 
 
 Artikel y...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>YOLOv4 - jaringan saraf real-time paling akurat pada dataset COCO Microsoft</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/503200/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Darknet YOLOv4 lebih cepat / lebih akurat daripada Google TensorFlow EfficientDet dan FaceBook Pytorch / Detectron RetinaNet / MaskRCNN. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Artikel yang sama pada media</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font><b><font style="vertical-align: inherit;">Kode </font></b></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sedang</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet </font></a><b><font style="vertical-align: inherit;">Artikel</font></b><font style="vertical-align: inherit;"> : </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></a></font><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"></font></a><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"></font></a><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/webt/3h/nc/sr/3hncsroz9wt8u3ycqskubgu1xk8.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kami akan menunjukkan beberapa nuansa membandingkan dan menggunakan jaringan saraf untuk mendeteksi objek. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tujuan kami adalah untuk mengembangkan algoritma deteksi objek untuk digunakan dalam produk nyata, dan tidak hanya memajukan ilmu pengetahuan. </font><font style="vertical-align: inherit;">Keakuratan jaringan saraf YOLOv4 (608x608) adalah 43,5% AP / 65,7% AP50 Microsoft-COCO-testdev. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">62 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (608x608 batch = 1) pada Tesla V100 - dengan menggunakan Darknet-framework </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (416x416 batch = 4) pada RTX 2080 Ti - dengan menggunakan TensorRT + tkDNN </font></font><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - YOLOv4 (416x416 batch = 1) pada Jetson AGX Xavier - dengan menggunakan TensorRT + tkDNN</font></font><br>
<br>
<img src="https://habrastorage.org/webt/p_/ep/cl/p_epcl_aaw_trgeltekatagtqkg.jpeg"> <br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1_SiUOYUoOI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pertama, beberapa tautan bermanfaat.</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anda dapat membaca deskripsi terperinci tentang fitur yang digunakan di YOLOv4 dalam artikel ini: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">medium.com/@jonathan_hui/yolov4-c9901eaa8e61</font></font></a></li>
<li>  YOLOv4: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://lutzroeder.github.io/netron/%3Furl%3D" rel="nofollow">lutzroeder.github.io/netron/?url=https%3A%2F%2Fraw.githubusercontent.com%2FAlexeyAB%2Fdarknet%2Fmaster%2Fcfg%2Fyolov4.cfg</a></li>
<li>     YOLOv4  GPU   Google-cloud  Jupyter Notebook –      ,   - «Open in Playground»,         [ ] –    ,  ,  ,    5    : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE</a>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">www.youtube.com/watch?v=mKAEGSxwOAY</a></li>
<li>  Darknet   : <br>
 — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 — <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">  Darknet YOLOv4</a><br>
 </li>
</ul><br>
<h3>   </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jaringan saraf YOLOv4 kami dan kerangka kerja Darknet DL kami sendiri (C / C ++ / CUDA) lebih baik dalam kecepatan FPS dan akurasi AP50: 95 dan AP50 pada kumpulan data COCO Microsoft daripada kerangka kerja DL dan jaringan saraf: Google TensorFlow EfficientDet, FaceBook Detectron RetinaNet / MaskRCNN, PyTorch Yolov3-ASFF, dan banyak lainnya ... YOLOv4 mencapai akurasi 43,5% AP / 65,7% AP50 pada tes COCO Microsoft pada kecepatan 62 FPS TitanV atau 34 FPS RTX 2070. Tidak seperti detektor modern lainnya, YOLOv4 dapat melatih siapa pun dengan siapa pun yang memiliki kartu grafis nVidia gaming dengan VRAM 8-16 GB. Sekarang, tidak hanya perusahaan besar yang dapat melatih jaringan saraf pada ratusan GPU / TPU untuk menggunakan ukuran mini-batch besar untuk mencapai akurasi yang lebih tinggi, jadi kami mengembalikan kontrol kecerdasan buatan kepada pengguna biasa, karena untuk YOLOv4 mini-lot besar tidak diperlukan,dapat dibatasi hingga ukuran 2 - 8.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
YOLOV4 optimal untuk menggunakan waktu nyata, karena jaringan terletak </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pada kurva optimalitas Pareto</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dalam </font><b><font style="vertical-align: inherit;">grafik</font></b><font style="vertical-align: inherit;"> AP (akurasi) / FPS (kecepatan). </font></font><br>
<br>
<img src="https://habrastorage.org/webt/2k/77/as/2k77aszzprngk0qmtistcehkz8c.png"><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Grafik akurasi (AP) dan kecepatan (FPS) dari banyak jaringan saraf untuk mendeteksi objek yang diukur pada GPU TitanV / TeslaV100, TitanXP / TeslaP100, TitanX / TeslaM40 untuk dua indikator utama akurasi AP50: 95 dan AP50</font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Untuk perbandingan yang adil, kami mengambil data dari artikel dan bandingkan hanya pada GPU dengan arsitektur yang sama. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sebagian besar tugas praktis memiliki persyaratan minimum yang diperlukan untuk detektor - ini adalah akurasi dan kecepatan minimum yang dapat diterima. Biasanya kecepatan minimum yang diijinkan 30 FPS (bingkai per detik) dan lebih tinggi untuk sistem waktu nyata. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Seperti dapat dilihat dari grafik, dalam sistem Real-time dengan FPS 30 atau lebih:</font></font><br>
<br>
<ul>
<li> YOLOv4-608   RTX 2070  <b>450$</b> (34 FPS)   <b>43.5% AP / 65.7% AP50</b></li>
<li> EfficientDet-D2   TitanV  <b>2250$</b> (42 FPS)   <b>43.0% AP / 62.3% AP50</b></li>
<li> EfficientDet-D0   RTX 2070  <b>450$</b> (34 FPS)   <b>33.8% AP / 52.2% AP50</b></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Itu YOLOv4 membutuhkan </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">peralatan 5 kali lebih murah</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dan lebih akurat daripada EfficientDet-D2 (Google-TensorFlow). Anda dapat menggunakan EfficientDet-D0 (Google-TensorFlow) maka biaya peralatan akan sama, tetapi akurasinya akan lebih rendah 10% AP. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Selain itu, beberapa sistem industri memiliki keterbatasan dalam pembuangan panas atau penggunaan sistem pendingin pasif - dalam hal ini Anda tidak dapat menggunakan TitanV bahkan dengan uang. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Saat menggunakan YOLOv4 (416x416) pada RTX 2080 Ti GPU menggunakan TensorRT + tkDNN, kami mencapai kecepatan 2x kali lebih cepat, dan ketika menggunakan batch = 4 itu 3x-4x kali lebih cepat - untuk perbandingan yang jujur, kami tidak menyajikan hasil ini dalam artikel di arxiv. org:</font></font><br>
<img src="https://habrastorage.org/webt/ci/j7/uq/cij7uqas0ypsjcpsfkhvdxuyxzs.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jaringan saraf YOLOv4 (416x416) FP16 (Tensor Cores) batch = </font><font style="vertical-align: inherit;">1 mencapai pada 32 kalkulator FPS nVidia Jetson AGX Xavier menggunakan perpustakaan + tkDNN TensorRT: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
kecepatan lebih lambat memberikan perpustakaan OpenCV-dnn yang dikompilasi dengan CUDA: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dokumen .opencv.org / master / da / d9d / tutorial_dnn_yolo.html</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kadang-kadang kecepatan (FPS) dari beberapa jaringan saraf dalam artikel diindikasikan saat menggunakan ukuran batch yang tinggi atau ketika pengujian dengan perangkat lunak khusus (TensorRT), yang mengoptimalkan jaringan dan menunjukkan peningkatan nilai FPS. Perbandingan beberapa jaringan di TRT dengan jaringan lain tanpa TRT tidak adil. Menggunakan ukuran batch yang tinggi meningkatkan FPS, tetapi juga meningkatkan latensi (daripada menguranginya) dibandingkan dengan batch = 1. Jika jaringan dengan batch = 1 menunjukkan 40 FPS, dan dengan batch = 32 itu menunjukkan 60 FPS, maka penundaan akan menjadi 25 ms untuk batch = 1, dan ~ 500 ms untuk batch = 32, karena hanya ~ 2 paket (masing-masing 32 gambar) akan diproses per detik, itulah sebabnya menggunakan batch = 32 tidak dapat diterima di banyak sistem industri. Oleh karena itu, kami membandingkan hasil pada grafik hanya dengan batch = 1 dan tanpa menggunakan TensorRT.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setiap proses dapat dikendalikan oleh orang atau oleh komputer. Ketika sebuah sistem komputer bertindak dengan penundaan besar karena kecepatan rendah dan membuat terlalu banyak kesalahan, maka ia tidak dapat dipercayakan dengan kontrol penuh atas tindakan, dalam hal ini orang tersebut mengendalikan prosesnya, dan sistem komputer hanya memberikan petunjuk - ini adalah sistem rekomendasi - orang tersebut bekerja, dan sistem hanya sistem menceritakan di mana kesalahan dibuat. Ketika sistem bekerja dengan cepat dan dengan akurasi tinggi, sistem seperti itu dapat mengontrol proses secara mandiri, dan seseorang hanya menjaganya. Karena itu, akurasi dan kecepatan sistem selalu penting. Jika menurut Anda 120 FPS untuk YOLOv4 416x416 terlalu banyak untuk tugas Anda, dan lebih baik mengambil algoritme lebih lambat dan lebih akurat, maka kemungkinan besar dalam tugas nyata Anda akan menggunakan sesuatu yang lebih lemah daripada Tesla V100 250 Watt,misalnya, RTX 2060 / Jetson-Xavier 30-80 Watt, dalam hal ini Anda akan mendapatkan 30 FPS pada YOLOv4 416x416, dan jaringan saraf lainnya pada 1-15 FPS atau tidak akan memulai sama sekali.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fitur pelatihan berbagai jaringan saraf</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda harus melatih EfficientDet dengan ukuran mini-batch = 128 pada beberapa Tesla V100 32GB GPU, sementara YOLOv4 dilatih hanya pada satu Tesla V100 32GB GPU dengan mini-batch = 8 = batch / subdivisi, dan dapat dilatih pada permainan reguler kartu grafis GPU 8-16GB-VRAM. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nuansa selanjutnya adalah kesulitan melatih jaringan saraf untuk mendeteksi objeknya sendiri. </font><font style="vertical-align: inherit;">Tidak peduli berapa lama Anda melatih jaringan lain pada GPU 1080 Ti yang sama, Anda tidak akan mendapatkan akurasi yang ditunjukkan pada grafik di atas. </font><font style="vertical-align: inherit;">Sebagian besar jaringan (EfficientDet, ASFF, ...) perlu dilatih pada 4 - 128 GPU (dengan ukuran mini-batch besar menggunakan syncBN) dan perlu untuk melatih setiap kali baru untuk setiap resolusi jaringan, tanpa memenuhi kedua kondisi tidak mungkin untuk mencapai akurasi AP atau AP50 yang dinyatakan oleh mereka.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/p4/sx/p3/p4sxp3ewxd9owskis23n6dyrv58.jpeg"><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anda dapat melihat ketergantungan akurasi pendeteksian objek pada ukuran minibatch di detektor lain, yaitu </font><font style="vertical-align: inherit;">menggunakan 128 kartu video, bukan 8 kartu video dan kecepatan belajar adalah 10 kali lebih tinggi dan akurasi akhir 1,5 AP lebih tinggi - MegDet: A Detector Mini-Batch Obyek Besar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1711.07240</font></font></a></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Yolo ASFF: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09516</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mengikuti [43], kami memperkenalkan sekumpulan trik dalam proses pelatihan, seperti algoritma mixup [12], jadwal tingkat pembelajaran cosinus [26], dan teknik normalisasi bets yang disinkronkan [30].</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
EfficientDet: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/1911.09070</font></font></a> <br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Normalisasi bets yang disinkronkan ditambahkan setelah setiap konvolusi dengan peluruhan norma bets 0,99 dan epsilon 1e-3. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Setiap model dilatih 300 zaman dengan ukuran total batch 128 pada 32 inti TPUv3.</font></font></blockquote><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow">cloud.google.com/tpu/docs/types-zones#europe</a><br>
<blockquote>v3-32 TPU type (v3) – 32 TPU v3 cores – 512 GiB Total TPU memory</blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda harus menggunakan 512 GB TPU / GPU-RAM untuk melatih model EfficientDet dengan normalisasi batch tersinkronisasi pada batch = 128, sedangkan mini-batch = 8 dan hanya 32 GB GPU-RAM digunakan untuk melatih YOLOv4. Meskipun demikian, YOLOv4 lebih cepat / lebih akurat daripada jaringan publik, meskipun hanya dilatih 1 kali dengan resolusi 512x512 per 1 GPU (Tesla V100 32GB / 16GB). Pada saat yang sama, menggunakan ukuran mini-batch yang lebih kecil dan GPU-VRAM tidak menyebabkan kehilangan akurasi yang dramatis seperti pada jaringan saraf lainnya: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xi/ol/rs/xiolrsvx4vzpjvahb6kvambdvgq.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sumber: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv.org/abs/2004.10934</font></font></a></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Sehingga Anda dapat melatih kecerdasan buatan secara lokal pada PC Anda, alih-alih mengunduh Kumpulan data ke cloud - ini menjamin perlindungan data pribadi Anda dan membuat pelatihan kecerdasan buatan tersedia untuk semua orang.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cukup untuk melatih jaringan kami sekali dengan resolusi jaringan 512x512, dan kemudian dapat digunakan dengan resolusi jaringan yang berbeda dalam jangkauan: [416x416 - 512x512 - 608x608]. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sebagian besar model lain perlu dilatih setiap waktu secara terpisah untuk setiap resolusi jaringan, karena ini, pelatihan membutuhkan waktu lebih lama.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fitur pengukuran akurasi algoritma deteksi objek</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Anda selalu dapat menemukan gambar di mana satu algoritma akan bekerja dengan buruk, dan algoritma lainnya akan bekerja dengan baik, dan sebaliknya. Oleh karena itu, untuk menguji algoritma pendeteksian, satu set besar ~ 20.000 gambar dan 80 jenis objek digunakan - dataset uji-dev MSCOCO. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agar algoritma tidak mencoba untuk hanya mengingat hash dari setiap gambar dan koordinat di atasnya (overfitting), keakuratan deteksi objek selalu diperiksa pada gambar dan label bahwa algoritma tidak melihat selama pelatihan - ini memastikan bahwa algoritma dapat mendeteksi objek pada gambar / video yang itu tidak pernah melihat.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Agar tidak ada yang bisa membuat kesalahan dalam menghitung akurasi, dalam domain publik hanya ada gambar uji dev yang Anda deteksi, dan mengirim hasilnya ke server evaluasi CodaLab, di mana program itu sendiri membandingkan hasil Anda dengan anotasi uji yang tidak dapat diakses oleh siapa pun . </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dataset MSCOCO terdiri dari 3 bagian</font></font></a><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tutorial: 120.000 gambar dan file json dengan koordinat masing-masing objek</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kumpulan validasi: 5.000 gambar dan file json dengan koordinat masing-masing objek</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Test suite: 41.000 jpg-gambar tanpa koordinat objek (beberapa gambar ini digunakan untuk menentukan akurasi dalam tugas: Deteksi Objek, Segmentasi Instans, Keypoints, ...)</font></font></li>
</ol><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fitur pengembangan YOLOv4</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ketika mengembangkan YOLOv4, saya harus mengembangkan jaringan saraf YOLOv4 dan kerangka Darknet pada C / C ++ / CUDA sendiri. </font><font style="vertical-align: inherit;">Karena </font><font style="vertical-align: inherit;">di Darknet tidak ada diferensiasi otomatis dan eksekusi aturan rantai otomatis, maka semua gradien harus diimplementasikan secara manual. </font><font style="vertical-align: inherit;">Di sisi lain, kita dapat beralih dari ketaatan pada aturan rantai, mengubah backpropagation dan mencoba hal-hal yang sangat sepele untuk meningkatkan stabilitas dan akurasi pembelajaran.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Temuan tambahan saat membuat jaringan saraf</font></font></h3><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tidak selalu jaringan terbaik untuk mengklasifikasikan objek akan menjadi yang terbaik sebagai tulang punggung untuk jaringan yang digunakan untuk mendeteksi objek</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menggunakan bobot yang dilatih dengan fitur yang meningkatkan akurasi dalam klasifikasi dapat memengaruhi akurasi detektor (pada beberapa jaringan)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tidak semua fitur yang dinyatakan dalam berbagai penelitian meningkatkan akurasi jaringan.</font></font></li>
<li>                .</li>
<li>      BFLOPS  ,   BFLOPS    </li>
<li>                  ,     receptive field     ,       stride=2 / conv3x3,    weights (filters)      . </li>
</ul><br>
<h3>   YOLOv4</h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Deteksi objek menggunakan model YOLOv4 yang terlatih dibangun di perpustakaan OpenCV-dnn </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/issues/17148</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sehingga Anda dapat menggunakan YOLOv4 langsung dari OpenCV tanpa menggunakan kerangka Darknet. </font><font style="vertical-align: inherit;">Pustaka OpenCV mendukung implementasi jaringan saraf pada CPU, GPU (GPU nVidia), VPU (Intel Myriad X). </font><font style="vertical-align: inherit;">Lebih detail: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs.opencv.org/master/da/d9d/tutorial_dnn_yolo.html kerangka </font></font></a><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenCV</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dnn):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Contoh C ++: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.cpp</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Contoh Python: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/opencv/opencv/blob/master/samples/dnn/object_detection.py</font></font></a></li>
</ul><br>
<b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kerangka </font><b><font style="vertical-align: inherit;">Darknet</font></b><font style="vertical-align: inherit;"> :</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Petunjuk untuk menggunakan YOLOv4 untuk mendeteksi objek: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-use-on-the-command-line</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Petunjuk untuk melatih jaringan saraf untuk mendeteksi objeknya sendiri: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instruksi untuk melatih classifier CSPDarknet53 pada dataset ILSVRC2012 (ImageNet): </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Classifier-on-ImageNet-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (ILSVRC2012)</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Instruksi untuk pelatihan YOLOv4 pada set data MS COCO: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/AlexeyAB/darknet/wiki/Train-Detector-on-MS-COCO-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (trainvalno5k-2014) -dataset</font></font></li>
</ul><br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tkDNN + TensorRT</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Kecepatan deteksi objek maksimum menggunakan YOLOv4: TensorRT + tkDNN </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ceccocats/tkDNN</font></font></a><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">400 FPS - YOLOv4 (416x416 batch = 4) pada RTX 2080 Ti</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">32 FPS - YOLOv4 (416x416 batch = 1) di Jetson AGX Xavier</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Penggunaan YOLOv4 dapat diperluas untuk mendeteksi 3D-Rotated-Bboxes atau titik kunci / landmark wajah, misalnya: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github.com/ouyanghuiyu/darknet_face_with_landmark</font></font></a><br>
<br>
<img src="https://habrastorage.org/webt/z7/vs/dv/z7vsdvhcpfbrgmdv1byhbpzd1cu.jpeg"></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id503182/index.html">"Saya pengembang buta pertama di perusahaan saya." Bagian 1</a></li>
<li><a href="../id503184/index.html">Kami mengundang Anda ke pertemuan online Zabbix</a></li>
<li><a href="../id503192/index.html">OVirt dalam 2 jam. Bagian 4. Operasi dasar</a></li>
<li><a href="../id503194/index.html">ISA tidak memaafkan kesalahan</a></li>
<li><a href="../id503196/index.html">450 kursus gratis dari Liga Ivy</a></li>
<li><a href="../id503204/index.html">Cara mem-flash Xiaomi Redmi 4 Prime / Pro / Premium di Android 10</a></li>
<li><a href="../id503208/index.html">Kapan waktu terbaik untuk berinvestasi?</a></li>
<li><a href="../id503210/index.html">Apakah situs phishing dapat diberantas?</a></li>
<li><a href="../id503212/index.html">30 hacks kehidupan untuk menyelesaikan kursus online</a></li>
<li><a href="../id503214/index.html">Memuat pengoptimalan pada proyek Highload dengan ElasticSearch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
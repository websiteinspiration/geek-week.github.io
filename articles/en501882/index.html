<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📽️ 👩🏼‍🍳 👩🏿‍🤝‍👨🏻 How we use computer vision algorithms: video processing in a mobile browser using OpenCV.js ✒️ 👍🏽 👩‍👩‍👧‍👦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="There are already all the possibilities for identifying a person online, but so far they are rarely used. Perhaps we were one of the first to implemen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>How we use computer vision algorithms: video processing in a mobile browser using OpenCV.js</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/simbirsoft/blog/501882/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">There are already all the possibilities for identifying a person online, but so far they are rarely used. </font><font style="vertical-align: inherit;">Perhaps we were one of the first to implement the optimal scenario for the user - log in to the site from a smartphone, take a photo of your driver’s license or passport and send data to the system. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's consider how computer vision algorithms help to recognize documents in a video stream directly in mobile browsers. </font><font style="vertical-align: inherit;">In this article, we share our experience of how we used OpenCV.js for this at SimbirSoft, what difficulties are possible, how to ensure speed and get a “smooth” UX without slowing down.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/jx/y7/u7/jxy7u7brc2ixo10gyheuhr19zcu.png"><br>
<a name="habracut"></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What was the task</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The business scenario for the algorithm being developed is as follows. A user accessing the site from a mobile phone should be able to photograph his documents and send them to the system for further processing. This may be part of the identity process when applying for the use of any services. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A web application in this scenario is preferable to a mobile application because of its availability and reduced time to complete the operation. The web page does not need installation and is ready to work immediately after loading. The user can proceed to perform the actions he needs - submitting an application - immediately after receiving the link, without being distracted by additional actions. From a business perspective, these factors increase the conversion and commercial effectiveness of the process.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
From an architectural point of view, the algorithm is required to directly detect the boundaries of the document and crop the excess background in the image. </font><font style="vertical-align: inherit;">Verification of identity, authentication and fraud checks will be implemented by other components. </font><font style="vertical-align: inherit;">However, it is advisable to carry out at least minimal checks to exclude sending business cards, empty paper rectangles and other obviously irrelevant images for processing images.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Requirements</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As part of our project, there were the following additional requirements for the algorithm:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the ability to work in real time: the video stream from the camera should not “slow down” during the operation of the algorithm;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the ability to work in a wide range of contrast and background texture: low-contrast and contrast, homogeneous and heterogeneous background;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Support for a wide range of smartphone models, including budget models released several years ago.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, there was no dataset for training machine learning algorithms in the project, and there was no way to collect and mark it up. </font><font style="vertical-align: inherit;">We only had a few test samples from Google’s search results. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Given this statement of the problem, we decided to develop based on the classical computer vision algorithms from the opencv library. </font><font style="vertical-align: inherit;">An alternative possibility was the use of machine learning algorithms and neural networks, however, it was discarded already in the early stages of work due to performance requirements: when applied, it would not be possible to provide real-time frame processing on all target devices.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">General approach and algorithm structure</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main idea of ​​the algorithm is a reference frame, along which it is necessary to align the document. </font><font style="vertical-align: inherit;">Its use pursues several goals at once. </font><font style="vertical-align: inherit;">Firstly, it will provide a suitable image size, sufficient for further processing of documents. </font><font style="vertical-align: inherit;">Secondly, as we will see later, it can be used as one of the candidate filters when searching for document borders. </font><font style="vertical-align: inherit;">Thirdly, it can be used to capture and crop the image if the borders of the document could not be found. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ru/et/bq/ruetbqsseuefny01b_anvvaa834.png"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">1. The general structure of the algorithm</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The general structure of the algorithm is shown in Fig. </font><font style="vertical-align: inherit;">1. Frames from the video stream are processed in a cycle, between iterations of which a timeout is set to comply with the desired FPS - we stopped at 30 frames per second. </font><font style="vertical-align: inherit;">This allows you to avoid “slowdowns" and reduce the load on the processor and power consumption of the device.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Each processed frame undergoes preprocessing, during which two main operations are performed. Firstly, a copy of a frame of a fixed size of 640x480 is created, with which the further steps of the algorithm work. The original image also remains, the detected document will be cut out of it. This will save the quality of the final image. Secondly, the created copy is translated in shades of gray. The color of the document being processed is ignored by the algorithm, since it can vary from country to country and even in different regions within the country - an example is a driver’s license in the United States.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first step in detecting a document is to search for the face in the image. The use of this heuristic eliminates the capture of business cards and other obviously irrelevant images. The search is performed using the standard opencv'shash </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CascadeClassifier.detectMultiScale ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and the pre- </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">trained</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> cascade </font><i><font style="vertical-align: inherit;">haarcascade_frontalface_default</font></i><font style="vertical-align: inherit;"> . The minimum and maximum sizes of detected faces are limited, which allows to reduce computational costs, and also further limits the scale of the document in the image. A face is considered detected in the image when it is in the left - or lower left, for passports - part of the area inside the reference frame (Fig. 2). This is an additional measure to ensure the correct alignment of the document in the image.</font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The examples in this article do not contain personal data. </font></font></i><br>
<br>
<img src="https://habrastorage.org/webt/ws/mz/7w/wsmz7wghvpoyfdslngrf59jofms.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 2. The area of ​​the expected position of the face in the image. The support frame is shown in red, the borders of the area of ​​the expected location of the face are shown in green.</font></font><br>
</i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
After face detection, we proceed to the border detection. Often </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">findContours ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> is used here </font><font style="vertical-align: inherit;">. However, this approach works well only in contrasting cases, for example, for a sheet of paper lying on a dark desk. If the contrast is lower, or the lighting is worse, or someone is holding a sheet in their hands, covering part of the border with their fingers, the detected contours break up into separate components, “lose” significant sections or are not detected at all.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Therefore, we took a different approach. After binarization, we first pass the image through the border filter using </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Canny ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and then look at the resulting picture for the line using the Huff transform </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HoughLines ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . The threshold parameter is immediately set large enough, equal to 30 - to filter detected short and other irrelevant segments.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The resulting set of lines is additionally filtered, leaving only lines close to the reference frame. To do this, we first translate the equations of the frame lines to points in the polar coordinate system (rho, theta) - theta will always be 0 or pi / 2, and rho will be unique for each line. After that, we select from the lines obtained from the Huff transform only those that lie in the vicinity of the control points - according to the Euclidean metric, taking into account the difference in the scale of the values. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
We distribute the set of lines obtained after filtering into four groups corresponding to the four lines of the reference frame, find the intersections of the lines in pairs between the groups, average and obtain the coordinates of the four points - the corners of the detected document (Fig. 3).</font></font><br>
<br>
<img src="https://habrastorage.org/webt/zr/7g/lz/zr7glzo5dwn-mofan9fhnthwu8k.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 3. Filtering lines and defining document corners. Green lines - the result of filtering, yellow dots - detected corners of the document.</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Next, you need to make sure the quality of the frame. To do this, we verify that the frame has remained stationary for the last time. To do this, subtract the frame at the beginning of the period from the current frame using </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">absdiff ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and compare it with the threshold. Before subtraction, we additionally smooth the images with a Gaussian filter </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GaussianBlur ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to reduce the influence of noise and other random factors. We also evaluate the focus of the frame by calculating its Laplacian </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplacian ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , estimating its variance and comparing the obtained value with a threshold.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
If all the checks are successful, you can proceed to the final part. </font><font style="vertical-align: inherit;">We recalculate the detected coordinates of the angles into the coordinate system of the original, underexposed image and cut the resulting region using the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">roi ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> method </font><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">The document was detected successfully.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Implementation Features</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
During the development of the algorithm, its main components were assembled in a python script. After that, the algorithm was ported to opencv.js and javascript, and then to wasm. This approach is dictated by considerations of convenience at all stages. On python, it was more convenient for our team to experiment with various variants of the algorithm and carry out rough parameter settings. Porting to javascript made it possible to test the operation of the algorithm on the target platform, including on various devices and browsers. Based on the results of these checks, fine tuning of the algorithm parameters was carried out. Finally, rewriting critical sections of code on wasm allowed us to get an additional performance boost.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
During the migration, a number of differences were discovered in the OpenCV API, which resulted in minor changes in the implementation. For example, the variance of a Laplacian in python is considered simply as </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laplacian (). Var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . With OpenCV.js, there is no way to use NumPy, but no alternative implementation of the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">var ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> method has </font><font style="vertical-align: inherit;">been provided. Solution: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Count the meanStdDev ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> function as the </font><font style="vertical-align: inherit;">standard deviation (Listing 1).</font></font><br>
<br>
<pre><code class="javascript hljs">private isImageBlurry(image: cv.Mat): boolean {
		<span class="hljs-keyword">const</span> laplacian = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.Laplacian(image, laplacian, cv.CV_64F);<font></font>
		<span class="hljs-keyword">const</span> s_mat = <span class="hljs-keyword">new</span> cv.Mat();<font></font>
		cv.meanStdDev(laplacian, <span class="hljs-keyword">new</span> cv.Mat(), s_mat);
		<span class="hljs-keyword">const</span> s = s_mat.data64F[<span class="hljs-number">0</span>];
		<span class="hljs-keyword">const</span> v = <span class="hljs-built_in">Math</span>.pow(s, <span class="hljs-number">2</span>);
		<span class="hljs-keyword">return</span> (v &lt; <span class="hljs-keyword">this</span>.laplacianVarianceThreshold);<font></font>
	}</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listing 1. Assessing the focus on the image through the variance of the Laplacian in opencv.js (TypeScript)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Another feature was the need to reduce the size of the library. In its original form, OpenCV.js has a capacity of 7.9 MB. Its download via the Internet slows down the initialization of the algorithm. The solution to this problem is to “trim” the unused modules during the library assembly process, which can significantly reduce the output file size: we managed to achieve a size of 1.8 MB. The list of components included in the assembly can be configured in the configuration file </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">platforms / js / opencv_js.config.py</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (Listing 2).</font></font><br>
<br>
<pre><code class="javascript hljs">white_list = makeWhiteList([core, imgproc, objdetect, video, dnn, features2d, photo, aruco, calib3d])</code></pre><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listing 2. The original white list of opencv modules included in the assembly for javascript</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Finally, an important contribution to ensuring the required performance of the algorithm was made by moving it to Web Worker. </font><font style="vertical-align: inherit;">This step, together with the restriction of FPS, allowed us to get rid of the “slowdowns” of the video stream during the operation of the algorithm, which had a positive effect on UX.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">results</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Examples of capturing and cropping images are shown in Fig. </font><font style="vertical-align: inherit;">4. It can be seen that the highest quality cropping is achieved on a dark uniform background, and the lowest quality is obtained with a light inhomogeneous background. </font><font style="vertical-align: inherit;">This is the expected effect associated with the gradients obtained on different backgrounds and used to detect the borders of a document. </font><font style="vertical-align: inherit;">Against a dark background, the gradients are larger than on a light background, a uniform background leads to less variability of the gradient values. </font><font style="vertical-align: inherit;">This leads to reliable detection of boundaries and, as a result, to better cropping. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/es/my/90/esmy90lihywocpj3-7p5bgttqkg.jpeg"><br>
<img src="https://habrastorage.org/webt/w4/uz/2l/w4uz2lnqlaajyd6eyplijsg72hc.jpeg"><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">4. Examples of cropping documents using an algorithm</font></font></i><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The article presents an algorithm for detecting documents on frames from a video stream, suitable for use in mobile browsers, and also considers the features of its implementation using the opencv.js library. </font><font style="vertical-align: inherit;">The algorithm allows you to get the output image of documents in a quality sufficient for further use by algorithms for authentication, identity verification, etc. </font><font style="vertical-align: inherit;">The speed of the resulting implementation allows you to get a “smooth” UX without “slowdowns” and frame loss. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thank you for the attention! </font><font style="vertical-align: inherit;">We hope you find this article useful.</font></font></b></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en501868/index.html">How not to let the accountant throw himself or We transfer 1C to the cloud. Step-by-step instruction</a></li>
<li><a href="../en501870/index.html">Maximum number of values ​​in enum Part II</a></li>
<li><a href="../en501872/index.html">Place of study in cybernetic systems</a></li>
<li><a href="../en501874/index.html">Modern Front End Architectures (Part 2)</a></li>
<li><a href="../en501880/index.html">About the translation of "beginnings" and "beginnings" without begin, start and first</a></li>
<li><a href="../en501884/index.html">How electronic medical information archives will help diagnose diseases more effectively</a></li>
<li><a href="../en501886/index.html">Space is not as simple as it sounds.</a></li>
<li><a href="../en501888/index.html">How to reduce the risks associated with ransomware ransomware</a></li>
<li><a href="../en501890/index.html">React Native - save photos and videos to the device gallery</a></li>
<li><a href="../en501892/index.html">Not My Left Leg: An Analysis of the Brain Structure of People with Xenomelia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
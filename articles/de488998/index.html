<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍙 🙊 🤲🏻 Warum KI-Anforderungen die Sache nur noch schlimmer machen können 🙁 🙋🏼 👸🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durch die Schaffung transparenterer neuronaler Netze können wir beginnen, ihnen übermäßig zu vertrauen. Es kann sich lohnen, die Methoden zu ändern, m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Warum KI-Anforderungen die Sache nur noch schlimmer machen können</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488998/"><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Durch die Schaffung transparenterer neuronaler Netze können wir beginnen, ihnen übermäßig zu vertrauen. </font><font style="vertical-align: inherit;">Es kann sich lohnen, die Methoden zu ändern, mit denen sie ihre Arbeit erklären.</font></font></h3><br>
<img src="https://cdn.technologyreview.com/i/images/sa-gettyimages-97233294-web.jpg?sw=1272&amp;cx=0&amp;cy=0&amp;cw=3000&amp;ch=1688"><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apol Esan, der</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> einmal vor Gericht stand, fuhr mit einem Roboterauto von Uber. Anstatt sich um den leeren Fahrersitz zu sorgen, wurden die Passagiere gebeten, einen „beruhigenden“ Bildschirm zu sehen, auf dem zu sehen war, wie das Auto die Straße sah: Gefahren wurden in Orange und Rot gezeichnet, sichere Bereiche in Dunkelblau. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für Esan, der die Interaktion von Menschen mit KI am Georgia Institute of Technology in Atlanta untersucht, war die Botschaft, die sie ihm zu vermitteln versuchten, verständlich: "Keine Sorge, dies sind die Gründe, warum sich die Maschine so verhält." Etwas im fremden Bild der Straße beruhigte jedoch nicht, sondern betonte die Seltsamkeit des Geschehens. Esan fragte sich: Was wäre, wenn das Robomobil es wirklich erklären könnte?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Erfolg von Deep Learning basiert auf unsicherer Auswahl im Code: Die besten neuronalen Netze passen sich an und passen sich an, um sie weiter zu verbessern, und praktische Ergebnisse überholen ihr theoretisches Verständnis. Zusammenfassend sind die Details der Funktionsweise des trainierten Modells normalerweise unbekannt. Wir sind es bereits gewohnt, KI als Black Box zu betrachten.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und meistens passt es zu uns - wenn es um Aufgaben wie das Spielen von Go, das Übersetzen von Text oder das Aufnehmen der nächsten Serie mit Netflix geht. Wenn KI jedoch dazu verwendet wird, Entscheidungen in Bereichen wie Strafverfolgung, medizinische Diagnostik und Roboterfahrzeuge zu treffen, müssen wir verstehen, wie sie ihre Entscheidungen trifft, und wissen, wann sie sich als falsch herausstellen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Menschen brauchen die Möglichkeit, einer automatischen Lösung nicht zuzustimmen oder sie abzulehnen, sagt </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Iris Hawley</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , Informatikerin am Williams College in Williamstown, Massachusetts. Und ohne sie werden die Menschen dieser Technologie widerstehen. „Schon jetzt kann man beobachten, wie dies in Form von Reaktionen der Menschen auf Gesichtserkennungssysteme geschieht“, sagt sie.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esan ist Teil einer kleinen, aber wachsenden Gruppe von Forschern, die versuchen, die Fähigkeit der KI zu verbessern, uns zu erklären und uns zu helfen, in die Black Box zu blicken. Der Zweck der Schaffung der sogenannten Die Interpretation oder Erklärung durch AI (III) soll den Menschen helfen, zu verstehen, welche Anzeichen von Daten das neuronale Netzwerk wirklich lernt - und zu entscheiden, ob sich das resultierende Modell als genau und unvoreingenommen herausstellt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eine Lösung besteht darin, Systeme für maschinelles Lernen (MO) zu erstellen, die die Innenseiten ihrer Arbeit demonstrieren - die sogenannten Aquarium-KI anstelle der KI in der Blackbox. Aquariummodelle sind normalerweise radikal vereinfachte Versionen des NS, in denen es einfacher ist zu verfolgen, wie sich einzelne Daten auf das Modell auswirken. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
„Es gibt Menschen in dieser Gemeinde, die die Verwendung von Aquarienmodellen in Situationen mit hohen Einsätzen fordern“, sagt er</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jennifer Worthman Vaughn</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , IT-Spezialistin bei Microsoft Research. "Und insgesamt stimme ich zu." Einfache Aquarienmodelle können genauso gut wie komplexere NS mit bestimmten Arten von strukturierten Daten wie Tabellen oder Statistiken funktionieren. Und in einigen Fällen ist das genug. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es hängt jedoch alles vom Arbeitsbereich ab. Wenn wir aus unscharfen Daten wie Bildern oder Text lernen möchten, haben wir keine andere Wahl, als tiefe - und daher undurchsichtige - neuronale Netze zu verwenden. Die Fähigkeit solcher NS, eine sinnvolle Verbindung zwischen einer Vielzahl unterschiedlicher Merkmale zu finden, hängt mit ihrer Komplexität zusammen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und auch hier kann Aquarium MO helfen. Eine Lösung besteht darin, die Daten zweimal durchzugehen und das unvollständige Aquarienmodell als Debugging-Schritt zu trainieren, um potenzielle Fehler zu erkennen, die Sie beheben möchten. Nach dem Bereinigen der Daten können Sie auch ein genaueres KI-Modell in einer Black Box trainieren. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein solches Gleichgewicht ist jedoch schwer aufrechtzuerhalten. Zu viel Transparenz kann zu einer Informationsüberflutung führen. In einer </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Studie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> aus dem Jahr 2018, in der die Interaktion von nicht geschulten Benutzern mit MO-Tools untersucht wurde, stellte Vaughn fest, dass transparente Modelle die Suche und Korrektur von Modellfehlern tatsächlich erschweren können.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein anderer Ansatz besteht darin, eine Visualisierung einzuschließen, die mehrere Schlüsseleigenschaften des Modells und der zugrunde liegenden Daten zeigt. Die Idee ist, ernsthafte Probleme mit dem Auge zu identifizieren. Beispielsweise kann sich ein Modell zu stark auf bestimmte Attribute stützen, was ein Signal für eine Vorspannung sein kann. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese Visualisierungstools sind in kurzer Zeit äußerst beliebt geworden. Aber gibt es eine Verwendung für sie? In der ersten </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Studie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dieser Art versuchten Vaughn und das Team, diese Frage zu beantworten, und fanden schließlich mehrere schwerwiegende Probleme.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Team verwendete zwei beliebte Interpretationswerkzeuge, die mithilfe von Grafiken und Diagrammen einen Überblick über das Modell geben. Dabei wird notiert, auf welche Daten das Modell während des Trainings hauptsächlich geachtet hat. Elf KI-Profis mit unterschiedlichen Hintergründen, Hintergründen und Hintergründen wurden von Microsoft eingestellt. Sie nahmen an einer Simulation der Interaktion mit dem MO-Modell teil, die auf Nationaleinkommensdaten aus der US-Volkszählung von 1994 trainiert wurde. Das Experiment wurde speziell entwickelt, um zu simulieren, wie Datenwissenschaftler Interpretationswerkzeuge verwenden, um ihre täglichen Aufgaben auszuführen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Team fand etwas Erstaunliches. Ja, manchmal haben Tools dazu beigetragen, fehlende Werte in den Daten zu finden. All diese Nützlichkeit hat jedoch im Vergleich zu der Tendenz zu übermäßigem Vertrauen in Visualisierungen sowie zu Fehlern in ihrem Verständnis nachgelassen. Manchmal konnten Benutzer nicht einmal beschreiben, was genau die Visualisierungen zeigen. Dies führte zu falschen Annahmen bezüglich des Datensatzes, der Modelle und der Interpretationswerkzeuge selbst. Es weckte auch falsches Vertrauen in die Werkzeuge und weckte die Begeisterung, diese Modelle in die Praxis umzusetzen, obwohl es den Teilnehmern manchmal so vorkam, als ob etwas schief gehen würde. Was unangenehm ist, es hat funktioniert, auch wenn die Ausgabe speziell angepasst wurde, so dass die Erklärungen der Arbeit keinen Sinn machten.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die Ergebnisse zu bestätigen, führten die Forscher eine Online-Umfrage unter 200 Fachleuten aus Moskau durch, die über Mailinglisten und soziale Netzwerke angezogen wurde. Sie fanden ähnliche Verwirrung und unbegründetes Vertrauen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um die Sache noch schlimmer zu machen, waren viele Umfrageteilnehmer bereit, mithilfe von Visualisierungen Entscheidungen über die Modellimplementierung zu treffen, obwohl sie erkannten, dass sie die zugrunde liegende Mathematik nicht verstanden hatten. „Es war besonders überraschend zu sehen, dass Menschen die Seltsamkeiten in den Daten mit Erklärungen begründen“, sagt </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Harmanpreet Kaur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> von der University of Michigan, Mitautor der Studie. "Die Verzerrung der Automatisierung ist ein sehr wichtiger Faktor, den wir nicht berücksichtigt haben."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Oh, das ist eine Verzerrung der Automatisierung. Mit anderen Worten, Menschen neigen dazu, Computern zu vertrauen. Und das ist kein neues Phänomen. Von Flugzeugautopiloten bis hin zu Rechtschreibprüfungssystemen vertrauen Menschen laut Untersuchungen häufig Systemlösungen, auch wenn sie offensichtlich falsch liegen. Wenn dies jedoch mit Tools geschieht, die speziell zur Korrektur dieses Phänomens entwickelt wurden, haben wir ein noch größeres Problem. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Was kann man dagegen tun? Einige glauben, dass ein Teil der Probleme der ersten Welle von III damit zusammenhängt, dass Forscher des Verteidigungsministeriums darin dominieren, von denen die meisten Experten sind, die KI-Systeme verwenden. Tim Miller von der University of Melbourne untersucht die Verwendung von KI-Systemen durch Menschen: „Dies ist eine psychiatrische Klinik unter der Kontrolle von Psychos.“</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies erkannte Esan auf dem Rücksitz eines Uber-Autos ohne Fahrer. Es wird einfacher sein zu verstehen, was das automatisierte System tut - und zu sehen, wo es falsch ist -, wenn es seine Handlungen so erklärt, wie es eine Person tun würde. Esan und sein Kollege </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mark Riddle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> entwickeln ein MO-System, das </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">automatisch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ähnliche Erklärungen in natürlicher Sprache </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">generiert</font></a><font style="vertical-align: inherit;"> . In einem frühen Prototyp nahm das Paar ein neuronales Netzwerk, trainierte, um ein klassisches Spiel aus den 1980er Jahren, Frogger, zu spielen, und trainierte es, um vor jedem Zug Erklärungen zu geben. </font></font><br>
<br>
<img src="https://cdn.technologyreview.com/i/images/explainable-ai--frogger-0-25-screenshot.png?sw=2500&amp;cx=0&amp;cy=0&amp;cw=492&amp;ch=326"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zwischen den Autos ... Ich komme nicht durch ... Ich werde auf die Lücke warten ...</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu diesem Zweck zeigten sie dem System viele Beispiele dafür, wie Leute dieses Spiel spielen, und kommentierten Aktionen laut. Dann nahmen sie ein neuronales Netzwerk, das von einer Sprache in eine andere übersetzt wurde, und passten es an, um Spielaktionen in Erklärungen in einer natürlichen Sprache zu übersetzen. Und jetzt, wenn die Nationalversammlung eine Aktion im Spiel sieht, „übersetzt“ sie sie in eine Erklärung. Das Ergebnis ist eine KI, die Frogger spielt und Dinge wie "nach links bewegen, um bei jeder Bewegung hinter dem blauen Lastwagen zu sein" sagt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Arbeit von Esan und Riddle ist nur der Anfang. Erstens ist nicht klar, ob das MO-System seine Handlungen immer in natürlicher Sprache erklären kann. Nehmen Sie AlphaZero von DeepMind und spielen Sie das Go-Brettspiel. Eine der erstaunlichsten Eigenschaften dieses Programms ist, dass es einen gewinnbringenden Zug machen kann, an den menschliche Spieler in diesem bestimmten Moment des Spiels nicht einmal denken konnten. Wenn AlphaZero seine Bewegungen erklären könnte, wäre das sinnvoll?</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gründe können helfen, ob wir sie verstehen oder nicht, sagt Esan: „Das Ziel eines III mit Fokus auf Menschen ist nicht nur, den Benutzer dazu zu bringen, zu akzeptieren, was die KI sagt - sondern auch einige Gedanken anzuregen.“ Riddle erinnert sich an eine Sendung des Spiels zwischen DeepMind AI und dem koreanischen Meister Lee Sedol. Kommentatoren diskutierten, was AlphaZero sieht und denkt. "Aber AlphaZero funktioniert nicht so", sagt Riddle. "Es schien mir jedoch, dass die Kommentare notwendig waren, um zu verstehen, was geschah."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und obwohl diese neue Welle von III-Forschern der Meinung ist, dass wenn mehr Menschen KI-Systeme verwenden, sollten diese Menschen von Anfang an am Design teilnehmen - und verschiedene Menschen brauchen unterschiedliche Erklärungen. Dies wird durch eine neue Studie von Howley und ihren Kollegen bestätigt, in der sie zeigten, dass die Fähigkeit der Menschen, interaktive oder statische Visualisierung zu verstehen, von ihrem Bildungsniveau abhängt. Stellen Sie sich vor, die KI diagnostiziert Krebs, sagt Esan. Ich möchte, dass sich die Erklärung, die er dem Onkologen gibt, von der Erklärung für den Patienten unterscheidet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Letztendlich möchten wir, dass AI nicht nur Wissenschaftlern, die mit Daten und Ärzten arbeiten, sondern auch Polizisten, die ein Bilderkennungssystem verwenden, Lehrern, die in der Schule Analyseprogramme verwenden, Schülern, die versuchen, die Arbeit von Bändern in sozialen Netzwerken zu verstehen, und zuvor erklären kann jede Person auf dem Rücksitz eines Robomobils. </font><font style="vertical-align: inherit;">„Wir haben immer gewusst, dass die Menschen der Technologie zu sehr vertrauen, und dies gilt insbesondere für KI-Systeme“, sagt Riddle. </font><font style="vertical-align: inherit;">"Je öfter Sie das System als intelligent bezeichnen, desto mehr Menschen sind zuversichtlich, dass es intelligenter ist als Menschen." </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Erklärungen, die jeder verstehen konnte, könnten diese Illusion zerstören.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de488960/index.html">Programmierung, Immunität und Armee</a></li>
<li><a href="../de488962/index.html">Kann ich Skripte in C ++ schreiben?</a></li>
<li><a href="../de488964/index.html">Dringende Aufgaben. Möge der Erretter kommen</a></li>
<li><a href="../de488990/index.html">Übersicht über die Vollmaske von UNIX 5100, Filter dazu, Vergleich mit den Modellen UNIX 5000, 6100 und Maske PPM-88</a></li>
<li><a href="../de488994/index.html">DDR5? Ja, wir haben DDR4 kaum getroffen</a></li>
<li><a href="../de489000/index.html">So montieren Sie einen coolen Mitap: 16 Tipps von drei „Serien-Mitapern“. Leader-IT-Veranstaltungen # 1</a></li>
<li><a href="../de489002/index.html">Verteilte Radsatzregistrierung: Erfahrung mit Hyperledger Fabric</a></li>
<li><a href="../de489004/index.html">Handy mit Disc Dialer</a></li>
<li><a href="../de489008/index.html">Routing in komplexen Chatbots mit dem Hobot-Framework</a></li>
<li><a href="../de489010/index.html">Wir teilen die größte Datenschicht in Russland zum Online-Lernen mit Projekten in den Bereichen Linguistik, Personalisierung, Peddesign, ML</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
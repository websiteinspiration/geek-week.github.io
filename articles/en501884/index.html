<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçüé® üèê üë©üèΩ‚Äçüîß How electronic medical information archives will help diagnose diseases more effectively üíø ‚úàÔ∏è üë®üèø‚Äçü§ù‚Äçüë®üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="According to IDC forecasts, by 2025, the total amount of data stored in healthcare organizations will increase to 2.3 zettabytes, and various medical ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>How electronic medical information archives will help diagnose diseases more effectively</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hpe/blog/501884/"><img src="https://habrastorage.org/webt/yy/ky/tq/yykytqufs5en1hf9oof-gte7r6m.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
According to IDC forecasts, by 2025, the total amount of data stored in healthcare organizations will increase to 2.3 zettabytes, and various medical images will account for up to 80-90% of the used storage capacity. The importance of efficient storage of medical images is important by the following example.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the diagnostic department of a hospital in Tucson (Arizona), up to 40 x-ray images are taken for two mammals using a MRI scan for mammography (diagnosis of breast cancer based on X-ray, ultrasound and MRI). as well as two to five biopsies. In 80% of cases, old patient images taken two years ago and earlier are used to interpret the results of mammography, and in difficult cases, images taken 10 years ago may be needed. To quickly retrieve old photographs from the archive, the PACS (Picture Archiving And Communication System) digital hospital system is used.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The use of old images stored in PACS significantly reduces the risk of errors in the diagnosis of malignant tumors and saves patients with a benign tumor from having to have a mammogram and even a biopsy again just to make sure their tumor is not malignant. </font><font style="vertical-align: inherit;">At the same time, comparison with old images reduces the risk of erroneous interpretation of images of malignant tumors and allows you to quickly assign the patient the appropriate treatment of pathology and additional analyzes.</font></font><br>
<br>
<h3><font color="#0dab7f"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Features of long-term storage of medical image archives</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
What should be the ideal storage system that is used as the storage system for PACS? Obviously, given the large size of medical images, it must be highly scalable so that it can store the results of analyzes of each patient, accumulated over several decades. The second requirement is to ensure quick search and retrieval of data from the archive, without which it is impossible to use old images to interpret the results of new surveys.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Finally, when storing medical images, it is necessary to completely eliminate the possibility of "data leakage", loss and accidental or intentional deletion or damage. A feature of storing data in PACS is the relatively modest I / O performance requirements: it is obvious that the analysis results are written to the archive only once and never change, and only a limited number of users can send requests to extract this data from the archive. Patient data is usually requested no more than once a year.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/ho/ai/xw/hoaixwwdwbg77s67irnf4t38hok.jpeg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Traditional enterprise-class storage systems are not suitable for PACS primarily because of the too high cost of data storage, which is largely due to the high performance that is unnecessary for medical image archives when servicing transactional applications, and cheaper entry-level storage systems do not have the scalability required for PACS archives.</font></font><br>
<br>
<h3><font color="#0dab7f"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perhaps the best solution for storing medical images</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The main solution for storing medical images and other unstructured content in healthcare organizations is the use of file and object storage systems with high scalability and low cost of storage per gigabyte. One of the leaders in this storage segment is Scality, which is promoting its software-defined storage, Scality RING. The first version of Scality RING was released in 2010. This is a scale-out solution that uses peer-to-peer connections and a shared-nothing distributed architecture that is deployed on standard x86 servers. Scality RING supports S3 and Swift object data access protocols, simple HTTP APIs, and file access. Last year, Scality managed to double the number of installations of its systems in healthcare.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Scality RING software is deployed on a cluster consisting of a minimum configuration of three storage nodes, and implements a set of intelligent data access services, as well as data protection and system management. At the upper level are scalable data access services (connectors), which provide data to applications via SMB, NFS and S3 protocols, as well as a supervisor for centralized management and monitoring of system status. Connectors are usually installed directly on storage nodes, but they can also be deployed on dedicated servers.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Middle-level storage Scality RING is a distributed virtual file system with several data protection mechanisms, system self-healing processes and system management and monitoring services. The bottom level of the stack is the distributed storage level that the virtual storage nodes and the I / O daemons form, which abstract the physical storage servers and disk interfaces.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The heart of the storage tier is scalable key-value distributed object storage based on the second generation peer-to-peer routing protocol. Routing provides efficient horizontal storage scaling and search across a very large number of nodes. The software for these storage services is deployed on all servers with the necessary computing power and capacity of the disk subsystem. The servers (nodes) on which the Scality RING software is deployed are connected by a standard IP-based network factory, for example, using 10/25/40/100 Gigabit Ethernet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Scality RING includes the following software components: connector servers, a distributed MESA DBMS for storing metadata, storage nodes, I / O daemons, and a web-based management portal. MESA provides object indexing and metadata management used at the Scality Scale-out file system (SOFS) abstraction level. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Scality RING connectors provide application access to data stored on servers. They support many data access protocols, including the Amazon Web Services (AWS) S3 object based on the Representational State Transfer (REST) ‚Äã‚Äãstandard, as well as the NFS, SMB, and FUSE file protocols. A single application can simultaneously use multiple RING connectors to access data if you need to scale I / O horizontally or serve many users in parallel.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A storage node is a virtual process that is responsible for objects associated with the allocated part of a distributed key hash of a key (keyspace) RING. Daemons of storage nodes (the so-called bizoid) ensure the immutability of data stored on disk in a low-level local file system. Six virtual storage nodes are deployed on one physical server (host). Each biziod is an instance of a low-level process that controls input / output operations on a specific physical disk and maintains the correspondence of object keys to the addresses of specific objects on this disk.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To ensure high availability of object storage (up to 14 nines), instead of the classic RAID technology, Scality RING uses various data protection mechanisms optimized for distributed systems, including local and geographically distributed replication and erasure coding, which can be combined with replication erasure coding in one connector. When storing small objects (up to 60 Kbytes in size), replication is a more cost-effective protection solution, and for large ones - erasure coding, in which large data sets do not need to be replicated. During replication, six levels of the Class of Service (CoS) service class are used from 0 to 5, which corresponds to saving 3-5 replicas of an object, and all replicas are stored on different disks.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In the case of using erasure coding, the Reed-Solomon error correction mechanism is used, in which, instead of storing several replicas of an object, it is divided into ‚Äúdata chunks‚Äù that are written together with parity chunks. </font><font style="vertical-align: inherit;">These pieces are distributed among RING nodes, and you can restore data from them when one or more nodes fail. </font><font style="vertical-align: inherit;">Also, high fault tolerance of RING is ensured by the share-nothing architecture, in which there is no main (‚Äúmaster‚Äù) node, the failure of which can lead to the failure of the entire system.</font></font><br>
<br>
<h3><font color="#0dab7f"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scality RING Ecosystem</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Although Scality RING can be deployed on any standard x86 server architecture, Gartner, in its Magic Quadrant for Distributed File Systems and Object Storage, notes that its implementation requires careful equipment selection and detailed project design, as well as deep IT immersion - customer‚Äôs specialists in Scality technology. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Since 2014, Hewlett Packard Enterprise, a strategic partner of Scality, offers two server models from the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HPE Apollo 4000 Gen10 series</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which were developed specifically for Big Data analytics </font><font style="vertical-align: inherit;">, as a joint platform solution for Scality RING software-defined object storage </font><font style="vertical-align: inherit;">and object storage: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HPE Apollo 4200</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">providing ultra-high storage density (up to 392 TB in a 2U height enclosure accommodating 28 full-size LFF disks or 54 2.5-inch SFF drives) and designed for hyper- </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">scaling of HPE Apollo 4510</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> capacities </font><font style="vertical-align: inherit;">based on 4U chassis (68 full-size disks per chassis, more 9 petabytes in a standard 42U server rack). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Both HPE Apollo 4000 Gen10 models allow you to flexibly configure the disk subsystem to meet specific storage node performance and capacity requirements and support </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">HPE iLO 5</font></a><font style="vertical-align: inherit;"> server remote management tools </font><font style="vertical-align: inherit;">familiar to users of </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HPE ProLiant</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> servers </font><font style="vertical-align: inherit;">that help you quickly deploy a large number of Scality RING storage nodes and effectively manage them.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The joint solution of HPE and Scality is positioned as a global repository of unstructured data (including archives), when large bandwidth and capacity are much more important than the minimum delay in accessing stored data. It scales to several thousand nodes of data storage and access, providing storage of hundreds of petabytes of data and trillions of objects in one namespace.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For additional protection of stored information, you can use various backup software packages, since Scality has certified its cloud storage for compatibility with VEEAM, Commvault, Microfocus Data Protector, Cloudera, MAPR and WEKA.IO products, and the use of Scality RING in healthcare as an archive of medical images provides certification for compatibility with PACS systems Fujifilm, GE Healthcare, Philips and several other vendors.</font></font><br>
<br>
<h3><font color="#0dab7f"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Healthcare Scality Ring Case Studies</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Currently, in France alone, more than a dozen of the largest hospitals use Scality Ring storage from 400 TB to 6 PB for storing archives of medical images. For example, a large joint installation of HPE and Scality is implemented at the Assistance Publique H√¥pitaux de Marseille (AP-HM), which combines four Marseille hospitals with 3400 beds and is the third largest in France. At AP-HM hospitals, 2,000 doctors and 8,500 other medical staff work.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Until 2011, the AP-HM used EMC Centera to store PACS images. By this time, the total volume of medical images was 60 TB, but they were replicated to protect the data, so they occupied 120 TB of capacity. Each year, hospital PACS generated another 20 TB of new images. In 2011, AP-HM replaced Centera with a NAS-system and by 2017 the volume of images increased to 320 TB, and the growth rate increased to 40 TB per year. As the NAS was running out of warranty, and the storage capacity of this storage was no longer sufficient due to the rapid growth of data volumes, the management of the AP-HM hospitals decided to replace again.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
When choosing a new storage system, it was necessary to ensure compatibility with all applications used in hospitals, including support for CIFS and NFS file protocols, scaling over several petabytes, reliable protection and data security. </font><font style="vertical-align: inherit;">AP-HM selected HPE and Scality RING and built a RING cluster distributed across three data centers from six HPE Apollo 4510 storage servers, as well as two </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">HPE ProLiant DL360 servers</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that store META metadata databases. </font><font style="vertical-align: inherit;">The main applications are the Carestream PACS system from GE Healthcare, which records the images obtained as a result of radiological studies and the genomics archive. </font><font style="vertical-align: inherit;">Medical images and other data are backed up using Commvault software.</font></font><br>
<br>
<h3><font color="#0dab7f"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Availability of Scality Ring in Russia</font></font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HPE and Scality have gained extensive experience in collaborative projects. With the implementation of Scality RING in medical institutions in Russia, certified engineers from the HPE‚Äôs Moscow office are ready to help the customer. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Under Factory Express, HPE supplies Apollo 4000 Gen10 preconfigured to customer requirements for rapid deployment of the Scality RING cluster, and also offers the Reference Architecture of these server systems for the RING cluster. Since May last year, HPE has been delivering the Base Bundle starter pack of Apollo 4200 Gen10 servers with an initial capacity of 240 TB and pre-installed Scality RING software. To deploy the Base Bundle, you only need to set the network speed and the required storage capacity.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
You can get additional information about the Scality Ring, as well as get acquainted with the interface and examples of integration with backup software at the HPE technical webinar, which will be held on June 17. </font><font style="vertical-align: inherit;">Registration is available at: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bit.ly/3bA9HP7</font></font></a></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en501870/index.html">Maximum number of values ‚Äã‚Äãin enum Part II</a></li>
<li><a href="../en501872/index.html">Place of study in cybernetic systems</a></li>
<li><a href="../en501874/index.html">Modern Front End Architectures (Part 2)</a></li>
<li><a href="../en501880/index.html">About the translation of "beginnings" and "beginnings" without begin, start and first</a></li>
<li><a href="../en501882/index.html">How we use computer vision algorithms: video processing in a mobile browser using OpenCV.js</a></li>
<li><a href="../en501886/index.html">Space is not as simple as it sounds.</a></li>
<li><a href="../en501888/index.html">How to reduce the risks associated with ransomware ransomware</a></li>
<li><a href="../en501890/index.html">React Native - save photos and videos to the device gallery</a></li>
<li><a href="../en501892/index.html">Not My Left Leg: An Analysis of the Brain Structure of People with Xenomelia</a></li>
<li><a href="../en501894/index.html">RosCom Freedom invites to Privacy Day and Pandemic Hackathon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
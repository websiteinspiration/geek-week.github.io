<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌧️ 🎬 🙅🏿 Réseaux de neurones récurrents (RNN) avec Keras 💑 🏳️‍🌈 👨🏾‍🏫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traduction du Recursive Neural Network Guide de Tensorflow.org. Le document traite à la fois des capacités intégrées de Keras / Tensorflow 2.0 pour un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Réseaux de neurones récurrents (RNN) avec Keras</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487808/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Traduction du Recursive Neural Network Guide de Tensorflow.org. </font><font style="vertical-align: inherit;">Le document traite à la fois des capacités intégrées de Keras / Tensorflow 2.0 pour un maillage rapide, ainsi que de la possibilité de personnaliser les couches et les cellules. </font><font style="vertical-align: inherit;">Les cas et les limites de l'utilisation du noyau CuDNN sont également considérés, ce qui permet d'accélérer le processus d'apprentissage du réseau neuronal.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/xt/_q/nj/xt_qnjgfjengqoqd4gizkq4j_wk.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les réseaux de neurones récursifs (RNN) sont une classe de réseaux de neurones qui sont bons pour modéliser des données série, telles que les séries chronologiques ou le langage naturel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si schématiquement, la couche RNN utilise une boucle </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour itérer sur une séquence ordonnée dans le temps, tout en stockant dans un état interne, des informations codées sur les étapes qu'il a déjà vues. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras API RNN est conçu avec un accent sur: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facilité d'utilisation</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : intégrée dans les </font><font style="vertical-align: inherit;">couches </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous permettent de construire rapidement un modèle récursif sans avoir à définir des paramètres de configuration complexes. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Personnalisation facile</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : vous pouvez également définir votre propre couche de cellules RNN (partie intérieure de la boucle</font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) avec un comportement personnalisé et l'utiliser avec une couche commune de `tf.keras.layers.RNN` (la boucle` for` elle-même). </font><font style="vertical-align: inherit;">Cela vous permettra de prototyper rapidement diverses idées de recherche de manière flexible, avec un minimum de code.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation</font></font></h2><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> collections
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Construire un modèle simple</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras a trois couches RNN intégrées:</font></font><br>
<br>
<ol>
<li><code>tf.keras.layers.SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, un RNN entièrement connecté dans lequel la sortie de l'étape de temps précédente doit être passée à l'étape suivante.</font></font></li>
<li><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, proposé pour la première fois dans l'article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Étudier des phrases en utilisant le codec RNN pour la traduction automatique statistique</font></font></a></li>
<li><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, d'abord proposé dans l'article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mémoire à court terme à long terme</font></font></a></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Début 2015, Keras a présenté les premières implémentations Python open source réutilisables et LSTM et GRU. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici un exemple d'un </font></font><code>Sequential</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modèle qui traite des séquences d'entiers en imbriquant chaque entier dans un vecteur à 64 dimensions, puis en traitant des séquences de vecteurs à l'aide d'une couche </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()
<span class="hljs-comment">#   Embedding      1000, </span>
<span class="hljs-comment">#     64.</span>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#   LSTM  128  .</span>
model.add(layers.LSTM(<span class="hljs-number">128</span>))<font></font>
<font></font>
<span class="hljs-comment">#   Dense  10    softmax.</span>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sorties et états</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par défaut, la sortie de la couche RNN contient un vecteur par élément. Ce vecteur est la sortie de la dernière cellule RNN contenant des informations sur la séquence d'entrée entière. La dimension de cette sortie </font></font><code>(batch_size, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, où </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond à l'argument </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">passé au constructeur de couche. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La couche RNN peut également renvoyer la séquence de sortie entière pour chaque élément (un vecteur pour chaque étape), si vous le spécifiez </font></font><code>return_sequences=True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. La dimension de cette sortie est </font></font><code>(batch_size, timesteps, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#  GRU  3D   (batch_size, timesteps, 256)</span>
model.add(layers.GRU(<span class="hljs-number">256</span>, return_sequences=<span class="hljs-literal">True</span>))<font></font>
<font></font>
<span class="hljs-comment">#  SimpleRNN  2D   (batch_size, 128)</span>
model.add(layers.SimpleRNN(<span class="hljs-number">128</span>))<font></font>
<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, la couche RNN peut retourner son ou ses états internes finaux. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les états renvoyés peuvent être utilisés ultérieurement pour reprendre l'exécution du RNN ou </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour initialiser un autre RNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ce paramètre est généralement utilisé dans le modèle codeur-décodeur, séquence à séquence, où l'état final du codeur est utilisé pour l'état initial du décodeur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour que la couche RNN retourne son état interne, définissez le paramètre </font></font><code>return_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur value </font></font><code>True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lors de la création de la couche. Notez qu'il y a </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 tenseurs d'état, et </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un seul. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour ajuster l'état initial d'un calque, appelez simplement le calque avec un argument supplémentaire </font></font><code>initial_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notez que la dimension doit correspondre à la dimension de l'élément de calque, comme dans l'exemple suivant.</font></font><br>
<br>
<pre><code class="python hljs">encoder_vocab = <span class="hljs-number">1000</span>
decoder_vocab = <span class="hljs-number">2000</span><font></font>
<font></font>
encoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=<span class="hljs-number">64</span>)(encoder_input)<font></font>
<font></font>
<span class="hljs-comment">#       </span><font></font>
output, state_h, state_c = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, return_state=<span class="hljs-literal">True</span>, name=<span class="hljs-string">'encoder'</span>)(encoder_embedded)<font></font>
encoder_state = [state_h, state_c]<font></font>
<font></font>
decoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=<span class="hljs-number">64</span>)(decoder_input)<font></font>
<font></font>
<span class="hljs-comment">#  2     LSTM    </span><font></font>
decoder_output = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, name=<span class="hljs-string">'decoder'</span>)(decoder_embedded, initial_state=encoder_state)<font></font>
output = layers.Dense(<span class="hljs-number">10</span>)(decoder_output)<font></font>
<font></font>
model = tf.keras.Model([encoder_input, decoder_input], output)<font></font>
model.summary()<font></font>
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Couches RNN et cellules RNN</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'API RNN, en plus des couches RNN intégrées, fournit également des API au niveau des cellules. </font><font style="vertical-align: inherit;">Contrairement aux couches RNN, qui traitent des paquets entiers de séquences d'entrée, une cellule RNN ne traite qu'un seul pas de temps. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La cellule est à l'intérieur du cycle de la </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">couche RNN. </font><font style="vertical-align: inherit;">Envelopper une cellule avec une couche </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous donne une couche capable de traiter des paquets de séquence, par exemple </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mathématiquement, </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cela donne le même résultat que </font></font><code>LSTM(10)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">En fait, l'implémentation de cette couche à l'intérieur de TF v1.x consistait uniquement à créer la cellule RNN correspondante et à l'envelopper dans la couche RNN. </font><font style="vertical-align: inherit;">Cependant, l'utilisation de couches intégrées </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">permet l'utilisation de CuDNN qui peut vous donner de meilleures performances.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il existe trois cellules RNN intégrées, chacune correspondant à sa propre couche RNN.</font></font><br>
<br>
<ul>
<li><code>tf.keras.layers.SimpleRNNCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond au calque </font></font><code>SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.GRUCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond au calque </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.LSTMCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond au calque </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'abstraction d'une cellule avec une classe commune </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">facilite l'implémentation d'architectures RNN personnalisées pour votre recherche.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">État de sauvegarde inter-lots</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors du traitement de longues séquences (éventuellement sans fin), vous souhaiterez peut-être utiliser le modèle d’ </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">état croisé</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Habituellement, l'état interne de la couche RNN est réinitialisé avec chaque nouveau paquet de données (c'est-à-dire que chaque exemple qui voit la couche est supposé être indépendant du passé). La couche ne conservera son état que pendant la durée de traitement de cet élément. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, si vous avez de très longues séquences, il est utile de les décomposer en séquences plus courtes et de les transférer à tour de rôle dans la couche RNN sans réinitialiser l'état de la couche. Ainsi, une couche peut stocker des informations sur la séquence entière, bien qu'elle ne verra qu'une seule sous-séquence à la fois. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez le faire en définissant `stateful = True` dans le constructeur.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si vous avez la séquence `s = [t0, t1, ... t1546, t1547]`, vous pouvez la diviser par exemple en:</font></font><br>
<br>
<pre><code class="python hljs">s1 = [t0, t1, ... t100]<font></font>
s2 = [t101, ... t201]<font></font>
...<font></font>
s16 = [t1501, ... t1547]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, vous pouvez le traiter avec:</font></font><br>
<br>
<pre><code class="python hljs">lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> sub_sequences:<font></font>
  output = lstm_layer(s)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque vous souhaitez nettoyer la condition, utilisez </font></font><code>layer.reset_states()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<blockquote><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Remarque:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dans ce cas, il est supposé que l'exemple </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de ce package est une continuation de l'exemple du </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">package précédent. </font><font style="vertical-align: inherit;">Cela signifie que tous les packages contiennent le même nombre d'éléments (taille du package). </font><font style="vertical-align: inherit;">Par exemple, si le package contient </font></font><code>[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, le package suivant doit contenir </font></font><code>[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici un exemple complet:</font></font><br>
<br>
<pre><code class="python hljs">paragraph1 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph2 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph3 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
<font></font>
lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)<font></font>
output = lstm_layer(paragraph1)<font></font>
output = lstm_layer(paragraph2)<font></font>
output = lstm_layer(paragraph3)<font></font>
<font></font>
<span class="hljs-comment"># reset_states()      initial_state.</span>
<span class="hljs-comment">#  initial_state   ,      .</span>
lstm_layer.reset_states()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN bidirectionnel</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour les séquences autres que les séries chronologiques (par exemple les textes), il arrive souvent que le modèle RNN fonctionne mieux s'il traite la séquence non seulement du début à la fin, mais vice versa. Par exemple, pour prédire le mot suivant dans une phrase, il est souvent utile de connaître le contexte autour du mot, et pas seulement les mots devant lui. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras fournit une API simple pour créer de tels RNN bidirectionnels: un wrapper </font></font><code>tf.keras.layers.Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">64</span>, return_sequences=<span class="hljs-literal">True</span>), <font></font>
                               input_shape=(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)))<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">32</span>)))<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sous le capot, la </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">couche RNN transférée </font></font><code>go_backwards</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sera copiée </font><font style="vertical-align: inherit;">et le champ de la </font><font style="vertical-align: inherit;">couche nouvellement copiée sera </font><font style="vertical-align: inherit;">retourné </font><font style="vertical-align: inherit;">, et ainsi les données d'entrée seront traitées dans l'ordre inverse. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La sortie de ` </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN par défaut sera la somme de la sortie de la couche avant et de la sortie de la couche inverse. </font><font style="vertical-align: inherit;">Si vous avez besoin d'un autre comportement de fusion, par exemple </font><font style="vertical-align: inherit;">concaténation, modifiez le paramètre `merge_mode` dans le constructeur de wrapper` bidirectionnel`.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Optimisation des performances et noyau CuDNN dans TensorFlow 2.0</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans TensorFlow 2.0, les couches LSTM et GRU intégrées sont utilisables par défaut des cœurs CuDNN si un processeur graphique est disponible. </font><font style="vertical-align: inherit;">Avec ce changement, les couches précédentes </font></font><code>keras.layers.CuDNNLSTM/CuDNNGRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sont obsolètes et vous pouvez construire votre modèle sans vous soucier de l'équipement sur lequel il fonctionnera. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Étant donné que le noyau CuDNN est construit avec certaines hypothèses, cela signifie que la couche </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ne pourra pas utiliser la couche du noyau CuDNN si vous modifiez les paramètres par défaut des couches LSTM ou GRU intégrées</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Par exemple.</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changer une fonction </font></font><code>activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de </font></font><code>tanh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quelque chose d'autre.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changer une fonction </font></font><code>recurrent_activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de </font></font><code>sigmoid</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quelque chose d'autre.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utilisation </font></font><code>recurrent_dropout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&gt; 0.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un réglage </font></font><code>unroll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur True, ce </font><font style="vertical-align: inherit;">qui provoque LSTM / GRU pour décomposer le interne </font></font><code>tf.while_loop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dans une boucle déployée </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Réglez </font></font><code>use_bias</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur False.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utiliser des masques lorsque les données d'entrée ne sont pas justifiées à droite (si le masque correspond aux données strictement alignées à droite, CuDNN peut toujours être utilisé. C'est le cas le plus courant).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si possible, utilisez des noyaux CuDNN</font></font></h3><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">64</span>
<span class="hljs-comment">#    MNIST    (batch_size, 28, 28).</span>
<span class="hljs-comment">#     (28, 28) (   ).</span>
input_dim = <span class="hljs-number">28</span><font></font>
<font></font>
units = <span class="hljs-number">64</span>
output_size = <span class="hljs-number">10</span>  <span class="hljs-comment">#   0  9</span><font></font>
<font></font>
<span class="hljs-comment">#  RNN </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_model</span>(<span class="hljs-params">allow_cudnn_kernel=True</span>):</span>
  <span class="hljs-comment"># CuDNN     ,     .</span>
  <span class="hljs-comment">#   `LSTM(units)`    CuDNN,</span>
  <span class="hljs-comment">#   RNN(LSTMCell(units))   non-CuDNN .</span>
  <span class="hljs-keyword">if</span> allow_cudnn_kernel:
    <span class="hljs-comment">#  LSTM      CuDNN.</span>
    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(<span class="hljs-literal">None</span>, input_dim))
  <span class="hljs-keyword">else</span>:
    <span class="hljs-comment">#  LSTMCell  RNN    CuDNN.</span><font></font>
    lstm_layer = tf.keras.layers.RNN(<font></font>
        tf.keras.layers.LSTMCell(units),<font></font>
        input_shape=(<span class="hljs-literal">None</span>, input_dim))<font></font>
  model = tf.keras.models.Sequential([<font></font>
      lstm_layer,<font></font>
      tf.keras.layers.BatchNormalization(),<font></font>
      tf.keras.layers.Dense(output_size)]<font></font>
  )<font></font>
  <span class="hljs-keyword">return</span> model
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chargement de l'ensemble de données MNIST</font></font></h3><br>
<pre><code class="python hljs">mnist = tf.keras.datasets.mnist<font></font>
<font></font>
(x_train, y_train), (x_test, y_test) = mnist.load_data()<font></font>
x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span>
sample, sample_label = x_train[<span class="hljs-number">0</span>], y_train[<span class="hljs-number">0</span>]</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Créez une instance du modèle et compilez-la</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons choisi </font></font><code>sparse_categorical_crossentropy</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en fonction des pertes. </font><font style="vertical-align: inherit;">La sortie du modèle a une dimension </font></font><code>[batch_size, 10]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">La réponse du modèle est un vecteur entier, chacun des nombres est compris entre 0 et 9.</font></font><br>
<br>
<pre><code class="python hljs">model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
<font></font>
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
              optimizer=<span class="hljs-string">'sgd'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<pre><code class="python hljs">model.fit(x_train, y_train,<font></font>
          validation_data=(x_test, y_test),<font></font>
          batch_size=batch_size,<font></font>
          epochs=<span class="hljs-number">5</span>)</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Construisez un nouveau modèle sans noyau CuDNN</font></font></h3><br>
<pre><code class="python hljs">slow_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">False</span>)<font></font>
slow_model.set_weights(model.get_weights())<font></font>
slow_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
                   optimizer=<span class="hljs-string">'sgd'</span>, <font></font>
                   metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
slow_model.fit(x_train, y_train, <font></font>
               validation_data=(x_test, y_test), <font></font>
               batch_size=batch_size,<font></font>
               epochs=<span class="hljs-number">1</span>)  <span class="hljs-comment">#         .</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous pouvez le voir, le modèle construit avec CuDNN est beaucoup plus rapide pour la formation que le modèle utilisant le noyau TensorFlow habituel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le même modèle avec prise en charge CuDNN peut être utilisé pour la sortie dans un environnement à processeur unique. </font><font style="vertical-align: inherit;">L'annotation </font></font><code>tf.device</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indique simplement l'appareil utilisé. </font><font style="vertical-align: inherit;">Le modèle s'exécutera par défaut sur le CPU si le GPU n'est pas disponible. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous n'avez simplement pas à vous soucier du matériel sur lequel vous travaillez. </font><font style="vertical-align: inherit;">N'est-ce pas cool?</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">'CPU:0'</span>):<font></font>
  cpu_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
  cpu_model.set_weights(model.get_weights())<font></font>
  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, <span class="hljs-number">0</span>)), axis=<span class="hljs-number">1</span>)<font></font>
  print(<span class="hljs-string">'Predicted result is: %s, target result is: %s'</span> % (result.numpy(), sample_label))<font></font>
  plt.imshow(sample, cmap=plt.get_cmap(<span class="hljs-string">'gray'</span>))
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN avec entrée liste / dictionnaire ou entrée imbriquée</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les structures imbriquées vous permettent d'inclure plus d'informations en une seule fois. </font><font style="vertical-align: inherit;">Par exemple, une image vidéo peut contenir simultanément des entrées audio et vidéo. </font><font style="vertical-align: inherit;">La dimension des données dans ce cas peut être:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans un autre exemple, les données manuscrites peuvent avoir à la fois des coordonnées x et y pour la position actuelle du stylet, ainsi que des informations de pression. </font><font style="vertical-align: inherit;">Ainsi, les données peuvent être représentées comme suit:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le code suivant crée un exemple de cellule RNN personnalisée qui fonctionne avec une telle entrée structurée.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Définissez une cellule utilisateur prenant en charge les entrées / sorties imbriquées</font></font></h3><br>
<pre><code class="python hljs">NestedInput = collections.namedtuple(<span class="hljs-string">'NestedInput'</span>, [<span class="hljs-string">'feature1'</span>, <span class="hljs-string">'feature2'</span>])<font></font>
NestedState = collections.namedtuple(<span class="hljs-string">'NestedState'</span>, [<span class="hljs-string">'state1'</span>, <span class="hljs-string">'state2'</span>])<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NestedCell</span>(<span class="hljs-params">tf.keras.layers.Layer</span>):</span><font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, unit_1, unit_2, unit_3, **kwargs</span>):</span><font></font>
    self.unit_1 = unit_1<font></font>
    self.unit_2 = unit_2<font></font>
    self.unit_3 = unit_3<font></font>
    self.state_size = NestedState(state1=unit_1, <font></font>
                                  state2=tf.TensorShape([unit_2, unit_3]))<font></font>
    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))<font></font>
    super(NestedCell, self).__init__(**kwargs)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build</span>(<span class="hljs-params">self, input_shapes</span>):</span>
    <span class="hljs-comment"># #  input_shape  2 , [(batch, i1), (batch, i2, i3)]</span>
    input_1 = input_shapes.feature1[<span class="hljs-number">1</span>]<font></font>
    input_2, input_3 = input_shapes.feature2[<span class="hljs-number">1</span>:]<font></font>
<font></font>
    self.kernel_1 = self.add_weight(<font></font>
        shape=(input_1, self.unit_1), initializer=<span class="hljs-string">'uniform'</span>, name=<span class="hljs-string">'kernel_1'</span>)<font></font>
    self.kernel_2_3 = self.add_weight(<font></font>
        shape=(input_2, input_3, self.unit_2, self.unit_3),<font></font>
        initializer=<span class="hljs-string">'uniform'</span>,<font></font>
        name=<span class="hljs-string">'kernel_2_3'</span>)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span>(<span class="hljs-params">self, inputs, states</span>):</span>
    <span class="hljs-comment">#     [(batch, input_1), (batch, input_2, input_3)]</span>
    <span class="hljs-comment">#     [(batch, unit_1), (batch, unit_2, unit_3)]</span><font></font>
    input_1, input_2 = tf.nest.flatten(inputs)<font></font>
    s1, s2 = states<font></font>
<font></font>
    output_1 = tf.matmul(input_1, self.kernel_1)<font></font>
    output_2_3 = tf.einsum(<span class="hljs-string">'bij,ijkl-&gt;bkl'</span>, input_2, self.kernel_2_3)<font></font>
    state_1 = s1 + output_1<font></font>
    state_2_3 = s2 + output_2_3<font></font>
<font></font>
    output = [output_1, output_2_3]<font></font>
    new_states = NestedState(state1=state_1, state2=state_2_3)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> output, new_states
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Créer un modèle RNN avec entrée / sortie imbriquée</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Construisons un modèle Keras qui utilise une couche </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et une cellule personnalisée que nous venons de définir.</font></font><br>
<br>
<pre><code class="python hljs">unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Former le modèle sur des données générées aléatoirement</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme nous ne disposons pas d'un bon ensemble de données pour ce modèle, nous utilisons des données aléatoires générées par la bibliothèque Numpy pour la démonstration.</font></font><br>
<br>
<pre><code class="python hljs">input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))<font></font>
input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))<font></font>
target_1_data = np.random.random((batch_size * num_batch, unit_1))<font></font>
target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))<font></font>
input_data = [input_1_data, input_2_data]<font></font>
target_data = [target_1_data, target_2_data]<font></font>
<font></font>
model.fit(input_data, target_data, batch_size=batch_size)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec une couche, </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous n'avez qu'à déterminer la logique mathématique d'une seule étape dans la séquence, et la couche </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gérera l'itération de la séquence pour vous. </font><font style="vertical-align: inherit;">C'est un moyen incroyablement puissant pour prototyper rapidement de nouveaux types de RNN (par exemple la variante LSTM). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Après vérification, la traduction apparaîtra également sur Tensorflow.org. </font><font style="vertical-align: inherit;">Si vous souhaitez participer à la traduction de la documentation du site Web Tensorflow.org en russe, veuillez contacter personnellement ou commenter. </font><font style="vertical-align: inherit;">Toutes les corrections et commentaires sont appréciés.</font></font></i></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr487798/index.html">Comment nous avons migré d'Oracle JDK et Java Web Start vers AdoptOpenJDK et OpenWebStart</a></li>
<li><a href="../fr487800/index.html">Pourquoi est-il important de dire au demandeur ce qui n'a pas fonctionné pendant l'entretien (et comment le faire correctement)</a></li>
<li><a href="../fr487802/index.html">Onduleur APC Smart sans coupure et comment les cuisiner</a></li>
<li><a href="../fr487804/index.html">Meetup Growth Teams à Raiffeisenbank</a></li>
<li><a href="../fr487806/index.html">Création d'une petite API Deno</a></li>
<li><a href="../fr487812/index.html">Test du spectre LED polonais Led E27</a></li>
<li><a href="../fr487814/index.html">La vitesse et la fiabilité sont plus élevées et le prix est plus bas. Nouveaux disques SSD Kingston KC2000</a></li>
<li><a href="../fr487822/index.html">AvitoTech On Tour: rencontre Android à Nizhny Novgorod</a></li>
<li><a href="../fr487824/index.html">Aperçu des lampes LED Spectrum Led GU10 d'Europe</a></li>
<li><a href="../fr487826/index.html">Vue d'ensemble des lampes LED de Poland Spectrum Led E14</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
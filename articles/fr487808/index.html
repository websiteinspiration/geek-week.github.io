<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåßÔ∏è üé¨ üôÖüèø R√©seaux de neurones r√©currents (RNN) avec Keras üíë üè≥Ô∏è‚Äçüåà üë®üèæ‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traduction du Recursive Neural Network Guide de Tensorflow.org. Le document traite √† la fois des capacit√©s int√©gr√©es de Keras / Tensorflow 2.0 pour un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>R√©seaux de neurones r√©currents (RNN) avec Keras</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/487808/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Traduction du Recursive Neural Network Guide de Tensorflow.org. </font><font style="vertical-align: inherit;">Le document traite √† la fois des capacit√©s int√©gr√©es de Keras / Tensorflow 2.0 pour un maillage rapide, ainsi que de la possibilit√© de personnaliser les couches et les cellules. </font><font style="vertical-align: inherit;">Les cas et les limites de l'utilisation du noyau CuDNN sont √©galement consid√©r√©s, ce qui permet d'acc√©l√©rer le processus d'apprentissage du r√©seau neuronal.</font></font><br>
 <br>
<img src="https://habrastorage.org/webt/xt/_q/nj/xt_qnjgfjengqoqd4gizkq4j_wk.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les r√©seaux de neurones r√©cursifs (RNN) sont une classe de r√©seaux de neurones qui sont bons pour mod√©liser des donn√©es s√©rie, telles que les s√©ries chronologiques ou le langage naturel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si sch√©matiquement, la couche RNN utilise une boucle </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour it√©rer sur une s√©quence ordonn√©e dans le temps, tout en stockant dans un √©tat interne, des informations cod√©es sur les √©tapes qu'il a d√©j√† vues. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras API RNN est con√ßu avec un accent sur: </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facilit√© d'utilisation</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : int√©gr√©e dans les </font><font style="vertical-align: inherit;">couches </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous permettent de construire rapidement un mod√®le r√©cursif sans avoir √† d√©finir des param√®tres de configuration complexes. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Personnalisation facile</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : vous pouvez √©galement d√©finir votre propre couche de cellules RNN (partie int√©rieure de la boucle</font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) avec un comportement personnalis√© et l'utiliser avec une couche commune de `tf.keras.layers.RNN` (la boucle` for` elle-m√™me). </font><font style="vertical-align: inherit;">Cela vous permettra de prototyper rapidement diverses id√©es de recherche de mani√®re flexible, avec un minimum de code.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Installation</font></font></h2><br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import, division, print_function, unicode_literals<font></font>
<font></font>
<span class="hljs-keyword">import</span> collections
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<font></font>
<font></font>
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<font></font>
<font></font>
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Construire un mod√®le simple</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras a trois couches RNN int√©gr√©es:</font></font><br>
<br>
<ol>
<li><code>tf.keras.layers.SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, un RNN enti√®rement connect√© dans lequel la sortie de l'√©tape de temps pr√©c√©dente doit √™tre pass√©e √† l'√©tape suivante.</font></font></li>
<li><code>tf.keras.layers.GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, propos√© pour la premi√®re fois dans l'article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√âtudier des phrases en utilisant le codec RNN pour la traduction automatique statistique</font></font></a></li>
<li><code>tf.keras.layers.LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, d'abord propos√© dans l'article </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">M√©moire √† court terme √† long terme</font></font></a></li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D√©but 2015, Keras a pr√©sent√© les premi√®res impl√©mentations Python open source r√©utilisables et LSTM et GRU. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici un exemple d'un </font></font><code>Sequential</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mod√®le qui traite des s√©quences d'entiers en imbriquant chaque entier dans un vecteur √† 64 dimensions, puis en traitant des s√©quences de vecteurs √† l'aide d'une couche </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()
<span class="hljs-comment">#   Embedding      1000, </span>
<span class="hljs-comment">#     64.</span>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#   LSTM  128  .</span>
model.add(layers.LSTM(<span class="hljs-number">128</span>))<font></font>
<font></font>
<span class="hljs-comment">#   Dense  10    softmax.</span>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sorties et √©tats</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par d√©faut, la sortie de la couche RNN contient un vecteur par √©l√©ment. Ce vecteur est la sortie de la derni√®re cellule RNN contenant des informations sur la s√©quence d'entr√©e enti√®re. La dimension de cette sortie </font></font><code>(batch_size, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, o√π </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond √† l'argument </font></font><code>units</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pass√© au constructeur de couche. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La couche RNN peut √©galement renvoyer la s√©quence de sortie enti√®re pour chaque √©l√©ment (un vecteur pour chaque √©tape), si vous le sp√©cifiez </font></font><code>return_sequences=True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. La dimension de cette sortie est </font></font><code>(batch_size, timesteps, units)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
model.add(layers.Embedding(input_dim=<span class="hljs-number">1000</span>, output_dim=<span class="hljs-number">64</span>))<font></font>
<font></font>
<span class="hljs-comment">#  GRU  3D   (batch_size, timesteps, 256)</span>
model.add(layers.GRU(<span class="hljs-number">256</span>, return_sequences=<span class="hljs-literal">True</span>))<font></font>
<font></font>
<span class="hljs-comment">#  SimpleRNN  2D   (batch_size, 128)</span>
model.add(layers.SimpleRNN(<span class="hljs-number">128</span>))<font></font>
<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, la couche RNN peut retourner son ou ses √©tats internes finaux. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les √©tats renvoy√©s peuvent √™tre utilis√©s ult√©rieurement pour reprendre l'ex√©cution du RNN ou </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour initialiser un autre RNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ce param√®tre est g√©n√©ralement utilis√© dans le mod√®le codeur-d√©codeur, s√©quence √† s√©quence, o√π l'√©tat final du codeur est utilis√© pour l'√©tat initial du d√©codeur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour que la couche RNN retourne son √©tat interne, d√©finissez le param√®tre </font></font><code>return_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur value </font></font><code>True</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lors de la cr√©ation de la couche. Notez qu'il y a </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 tenseurs d'√©tat, et </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un seul. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour ajuster l'√©tat initial d'un calque, appelez simplement le calque avec un argument suppl√©mentaire </font></font><code>initial_state</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Notez que la dimension doit correspondre √† la dimension de l'√©l√©ment de calque, comme dans l'exemple suivant.</font></font><br>
<br>
<pre><code class="python hljs">encoder_vocab = <span class="hljs-number">1000</span>
decoder_vocab = <span class="hljs-number">2000</span><font></font>
<font></font>
encoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=<span class="hljs-number">64</span>)(encoder_input)<font></font>
<font></font>
<span class="hljs-comment">#       </span><font></font>
output, state_h, state_c = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, return_state=<span class="hljs-literal">True</span>, name=<span class="hljs-string">'encoder'</span>)(encoder_embedded)<font></font>
encoder_state = [state_h, state_c]<font></font>
<font></font>
decoder_input = layers.Input(shape=(<span class="hljs-literal">None</span>, ))<font></font>
decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=<span class="hljs-number">64</span>)(decoder_input)<font></font>
<font></font>
<span class="hljs-comment">#  2     LSTM    </span><font></font>
decoder_output = layers.LSTM(<font></font>
    <span class="hljs-number">64</span>, name=<span class="hljs-string">'decoder'</span>)(decoder_embedded, initial_state=encoder_state)<font></font>
output = layers.Dense(<span class="hljs-number">10</span>)(decoder_output)<font></font>
<font></font>
model = tf.keras.Model([encoder_input, decoder_input], output)<font></font>
model.summary()<font></font>
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Couches RNN et cellules RNN</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'API RNN, en plus des couches RNN int√©gr√©es, fournit √©galement des API au niveau des cellules. </font><font style="vertical-align: inherit;">Contrairement aux couches RNN, qui traitent des paquets entiers de s√©quences d'entr√©e, une cellule RNN ne traite qu'un seul pas de temps. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La cellule est √† l'int√©rieur du cycle de la </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">couche RNN. </font><font style="vertical-align: inherit;">Envelopper une cellule avec une couche </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous donne une couche capable de traiter des paquets de s√©quence, par exemple </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Math√©matiquement, </font></font><code>RNN(LSTMCell(10))</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cela donne le m√™me r√©sultat que </font></font><code>LSTM(10)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">En fait, l'impl√©mentation de cette couche √† l'int√©rieur de TF v1.x consistait uniquement √† cr√©er la cellule RNN correspondante et √† l'envelopper dans la couche RNN. </font><font style="vertical-align: inherit;">Cependant, l'utilisation de couches int√©gr√©es </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">permet l'utilisation de CuDNN qui peut vous donner de meilleures performances.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il existe trois cellules RNN int√©gr√©es, chacune correspondant √† sa propre couche RNN.</font></font><br>
<br>
<ul>
<li><code>tf.keras.layers.SimpleRNNCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond au calque </font></font><code>SimpleRNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.GRUCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond au calque </font></font><code>GRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><code>tf.keras.layers.LSTMCell</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">correspond au calque </font></font><code>LSTM</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'abstraction d'une cellule avec une classe commune </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">facilite l'impl√©mentation d'architectures RNN personnalis√©es pour votre recherche.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√âtat de sauvegarde inter-lots</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lors du traitement de longues s√©quences (√©ventuellement sans fin), vous souhaiterez peut-√™tre utiliser le mod√®le d‚Äô </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√©tat crois√©</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Habituellement, l'√©tat interne de la couche RNN est r√©initialis√© avec chaque nouveau paquet de donn√©es (c'est-√†-dire que chaque exemple qui voit la couche est suppos√© √™tre ind√©pendant du pass√©). La couche ne conservera son √©tat que pendant la dur√©e de traitement de cet √©l√©ment. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, si vous avez de tr√®s longues s√©quences, il est utile de les d√©composer en s√©quences plus courtes et de les transf√©rer √† tour de r√¥le dans la couche RNN sans r√©initialiser l'√©tat de la couche. Ainsi, une couche peut stocker des informations sur la s√©quence enti√®re, bien qu'elle ne verra qu'une seule sous-s√©quence √† la fois. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous pouvez le faire en d√©finissant `stateful = True` dans le constructeur.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si vous avez la s√©quence `s = [t0, t1, ... t1546, t1547]`, vous pouvez la diviser par exemple en:</font></font><br>
<br>
<pre><code class="python hljs">s1 = [t0, t1, ... t100]<font></font>
s2 = [t101, ... t201]<font></font>
...<font></font>
s16 = [t1501, ... t1547]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ensuite, vous pouvez le traiter avec:</font></font><br>
<br>
<pre><code class="python hljs">lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> sub_sequences:<font></font>
  output = lstm_layer(s)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lorsque vous souhaitez nettoyer la condition, utilisez </font></font><code>layer.reset_states()</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<blockquote><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Remarque:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dans ce cas, il est suppos√© que l'exemple </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de ce package est une continuation de l'exemple du </font></font><code>i</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">package pr√©c√©dent. </font><font style="vertical-align: inherit;">Cela signifie que tous les packages contiennent le m√™me nombre d'√©l√©ments (taille du package). </font><font style="vertical-align: inherit;">Par exemple, si le package contient </font></font><code>[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, le package suivant doit contenir </font></font><code>[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici un exemple complet:</font></font><br>
<br>
<pre><code class="python hljs">paragraph1 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph2 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
paragraph3 = np.random.random((<span class="hljs-number">20</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>)).astype(np.float32)<font></font>
<font></font>
lstm_layer = layers.LSTM(<span class="hljs-number">64</span>, stateful=<span class="hljs-literal">True</span>)<font></font>
output = lstm_layer(paragraph1)<font></font>
output = lstm_layer(paragraph2)<font></font>
output = lstm_layer(paragraph3)<font></font>
<font></font>
<span class="hljs-comment"># reset_states()      initial_state.</span>
<span class="hljs-comment">#  initial_state   ,      .</span>
lstm_layer.reset_states()</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN bidirectionnel</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour les s√©quences autres que les s√©ries chronologiques (par exemple les textes), il arrive souvent que le mod√®le RNN fonctionne mieux s'il traite la s√©quence non seulement du d√©but √† la fin, mais vice versa. Par exemple, pour pr√©dire le mot suivant dans une phrase, il est souvent utile de conna√Ætre le contexte autour du mot, et pas seulement les mots devant lui. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Keras fournit une API simple pour cr√©er de tels RNN bidirectionnels: un wrapper </font></font><code>tf.keras.layers.Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br>
<br>
<pre><code class="python hljs">model = tf.keras.Sequential()<font></font>
<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">64</span>, return_sequences=<span class="hljs-literal">True</span>), <font></font>
                               input_shape=(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)))<font></font>
model.add(layers.Bidirectional(layers.LSTM(<span class="hljs-number">32</span>)))<font></font>
model.add(layers.Dense(<span class="hljs-number">10</span>))<font></font>
<font></font>
model.summary()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sous le capot, la </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">couche RNN transf√©r√©e </font></font><code>go_backwards</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sera copi√©e </font><font style="vertical-align: inherit;">et le champ de la </font><font style="vertical-align: inherit;">couche nouvellement copi√©e sera </font><font style="vertical-align: inherit;">retourn√© </font><font style="vertical-align: inherit;">, et ainsi les donn√©es d'entr√©e seront trait√©es dans l'ordre inverse. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La sortie de ` </font></font><code>Bidirectional</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN par d√©faut sera la somme de la sortie de la couche avant et de la sortie de la couche inverse. </font><font style="vertical-align: inherit;">Si vous avez besoin d'un autre comportement de fusion, par exemple </font><font style="vertical-align: inherit;">concat√©nation, modifiez le param√®tre `merge_mode` dans le constructeur de wrapper` bidirectionnel`.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Optimisation des performances et noyau CuDNN dans TensorFlow 2.0</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans TensorFlow 2.0, les couches LSTM et GRU int√©gr√©es sont utilisables par d√©faut des c≈ìurs CuDNN si un processeur graphique est disponible. </font><font style="vertical-align: inherit;">Avec ce changement, les couches pr√©c√©dentes </font></font><code>keras.layers.CuDNNLSTM/CuDNNGRU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sont obsol√®tes et vous pouvez construire votre mod√®le sans vous soucier de l'√©quipement sur lequel il fonctionnera. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√âtant donn√© que le noyau CuDNN est construit avec certaines hypoth√®ses, cela signifie que la couche </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ne pourra pas utiliser la couche du noyau CuDNN si vous modifiez les param√®tres par d√©faut des couches LSTM ou GRU int√©gr√©es</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Par exemple.</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changer une fonction </font></font><code>activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de </font></font><code>tanh</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quelque chose d'autre.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changer une fonction </font></font><code>recurrent_activation</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de </font></font><code>sigmoid</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quelque chose d'autre.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utilisation </font></font><code>recurrent_dropout</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">&gt; 0.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un r√©glage </font></font><code>unroll</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur True, ce </font><font style="vertical-align: inherit;">qui provoque LSTM / GRU pour d√©composer le interne </font></font><code>tf.while_loop</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dans une boucle d√©ploy√©e </font></font><code>for</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©glez </font></font><code>use_bias</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sur False.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utiliser des masques lorsque les donn√©es d'entr√©e ne sont pas justifi√©es √† droite (si le masque correspond aux donn√©es strictement align√©es √† droite, CuDNN peut toujours √™tre utilis√©. C'est le cas le plus courant).</font></font></li>
</ul><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si possible, utilisez des noyaux CuDNN</font></font></h3><br>
<pre><code class="python hljs">batch_size = <span class="hljs-number">64</span>
<span class="hljs-comment">#    MNIST    (batch_size, 28, 28).</span>
<span class="hljs-comment">#     (28, 28) (   ).</span>
input_dim = <span class="hljs-number">28</span><font></font>
<font></font>
units = <span class="hljs-number">64</span>
output_size = <span class="hljs-number">10</span>  <span class="hljs-comment">#   0  9</span><font></font>
<font></font>
<span class="hljs-comment">#  RNN </span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build_model</span>(<span class="hljs-params">allow_cudnn_kernel=True</span>):</span>
  <span class="hljs-comment"># CuDNN     ,     .</span>
  <span class="hljs-comment">#   `LSTM(units)`    CuDNN,</span>
  <span class="hljs-comment">#   RNN(LSTMCell(units))   non-CuDNN .</span>
  <span class="hljs-keyword">if</span> allow_cudnn_kernel:
    <span class="hljs-comment">#  LSTM      CuDNN.</span>
    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(<span class="hljs-literal">None</span>, input_dim))
  <span class="hljs-keyword">else</span>:
    <span class="hljs-comment">#  LSTMCell  RNN    CuDNN.</span><font></font>
    lstm_layer = tf.keras.layers.RNN(<font></font>
        tf.keras.layers.LSTMCell(units),<font></font>
        input_shape=(<span class="hljs-literal">None</span>, input_dim))<font></font>
  model = tf.keras.models.Sequential([<font></font>
      lstm_layer,<font></font>
      tf.keras.layers.BatchNormalization(),<font></font>
      tf.keras.layers.Dense(output_size)]<font></font>
  )<font></font>
  <span class="hljs-keyword">return</span> model
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chargement de l'ensemble de donn√©es MNIST</font></font></h3><br>
<pre><code class="python hljs">mnist = tf.keras.datasets.mnist<font></font>
<font></font>
(x_train, y_train), (x_test, y_test) = mnist.load_data()<font></font>
x_train, x_test = x_train / <span class="hljs-number">255.0</span>, x_test / <span class="hljs-number">255.0</span>
sample, sample_label = x_train[<span class="hljs-number">0</span>], y_train[<span class="hljs-number">0</span>]</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cr√©ez une instance du mod√®le et compilez-la</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons choisi </font></font><code>sparse_categorical_crossentropy</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en fonction des pertes. </font><font style="vertical-align: inherit;">La sortie du mod√®le a une dimension </font></font><code>[batch_size, 10]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">La r√©ponse du mod√®le est un vecteur entier, chacun des nombres est compris entre 0 et 9.</font></font><br>
<br>
<pre><code class="python hljs">model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
<font></font>
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
              optimizer=<span class="hljs-string">'sgd'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<pre><code class="python hljs">model.fit(x_train, y_train,<font></font>
          validation_data=(x_test, y_test),<font></font>
          batch_size=batch_size,<font></font>
          epochs=<span class="hljs-number">5</span>)</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Construisez un nouveau mod√®le sans noyau CuDNN</font></font></h3><br>
<pre><code class="python hljs">slow_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">False</span>)<font></font>
slow_model.set_weights(model.get_weights())<font></font>
slow_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>), <font></font>
                   optimizer=<span class="hljs-string">'sgd'</span>, <font></font>
                   metrics=[<span class="hljs-string">'accuracy'</span>])<font></font>
slow_model.fit(x_train, y_train, <font></font>
               validation_data=(x_test, y_test), <font></font>
               batch_size=batch_size,<font></font>
               epochs=<span class="hljs-number">1</span>)  <span class="hljs-comment">#         .</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous pouvez le voir, le mod√®le construit avec CuDNN est beaucoup plus rapide pour la formation que le mod√®le utilisant le noyau TensorFlow habituel. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le m√™me mod√®le avec prise en charge CuDNN peut √™tre utilis√© pour la sortie dans un environnement √† processeur unique. </font><font style="vertical-align: inherit;">L'annotation </font></font><code>tf.device</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indique simplement l'appareil utilis√©. </font><font style="vertical-align: inherit;">Le mod√®le s'ex√©cutera par d√©faut sur le CPU si le GPU n'est pas disponible. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous n'avez simplement pas √† vous soucier du mat√©riel sur lequel vous travaillez. </font><font style="vertical-align: inherit;">N'est-ce pas cool?</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">with</span> tf.device(<span class="hljs-string">'CPU:0'</span>):<font></font>
  cpu_model = build_model(allow_cudnn_kernel=<span class="hljs-literal">True</span>)<font></font>
  cpu_model.set_weights(model.get_weights())<font></font>
  result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, <span class="hljs-number">0</span>)), axis=<span class="hljs-number">1</span>)<font></font>
  print(<span class="hljs-string">'Predicted result is: %s, target result is: %s'</span> % (result.numpy(), sample_label))<font></font>
  plt.imshow(sample, cmap=plt.get_cmap(<span class="hljs-string">'gray'</span>))
</code></pre><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RNN avec entr√©e liste / dictionnaire ou entr√©e imbriqu√©e</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les structures imbriqu√©es vous permettent d'inclure plus d'informations en une seule fois. </font><font style="vertical-align: inherit;">Par exemple, une image vid√©o peut contenir simultan√©ment des entr√©es audio et vid√©o. </font><font style="vertical-align: inherit;">La dimension des donn√©es dans ce cas peut √™tre:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans un autre exemple, les donn√©es manuscrites peuvent avoir √† la fois des coordonn√©es x et y pour la position actuelle du stylet, ainsi que des informations de pression. </font><font style="vertical-align: inherit;">Ainsi, les donn√©es peuvent √™tre repr√©sent√©es comme suit:</font></font><br>
<br>
<pre><code class="plaintext hljs">[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le code suivant cr√©e un exemple de cellule RNN personnalis√©e qui fonctionne avec une telle entr√©e structur√©e.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D√©finissez une cellule utilisateur prenant en charge les entr√©es / sorties imbriqu√©es</font></font></h3><br>
<pre><code class="python hljs">NestedInput = collections.namedtuple(<span class="hljs-string">'NestedInput'</span>, [<span class="hljs-string">'feature1'</span>, <span class="hljs-string">'feature2'</span>])<font></font>
NestedState = collections.namedtuple(<span class="hljs-string">'NestedState'</span>, [<span class="hljs-string">'state1'</span>, <span class="hljs-string">'state2'</span>])<font></font>
<font></font>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NestedCell</span>(<span class="hljs-params">tf.keras.layers.Layer</span>):</span><font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, unit_1, unit_2, unit_3, **kwargs</span>):</span><font></font>
    self.unit_1 = unit_1<font></font>
    self.unit_2 = unit_2<font></font>
    self.unit_3 = unit_3<font></font>
    self.state_size = NestedState(state1=unit_1, <font></font>
                                  state2=tf.TensorShape([unit_2, unit_3]))<font></font>
    self.output_size = (unit_1, tf.TensorShape([unit_2, unit_3]))<font></font>
    super(NestedCell, self).__init__(**kwargs)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build</span>(<span class="hljs-params">self, input_shapes</span>):</span>
    <span class="hljs-comment"># #  input_shape  2 , [(batch, i1), (batch, i2, i3)]</span>
    input_1 = input_shapes.feature1[<span class="hljs-number">1</span>]<font></font>
    input_2, input_3 = input_shapes.feature2[<span class="hljs-number">1</span>:]<font></font>
<font></font>
    self.kernel_1 = self.add_weight(<font></font>
        shape=(input_1, self.unit_1), initializer=<span class="hljs-string">'uniform'</span>, name=<span class="hljs-string">'kernel_1'</span>)<font></font>
    self.kernel_2_3 = self.add_weight(<font></font>
        shape=(input_2, input_3, self.unit_2, self.unit_3),<font></font>
        initializer=<span class="hljs-string">'uniform'</span>,<font></font>
        name=<span class="hljs-string">'kernel_2_3'</span>)<font></font>
<font></font>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span>(<span class="hljs-params">self, inputs, states</span>):</span>
    <span class="hljs-comment">#     [(batch, input_1), (batch, input_2, input_3)]</span>
    <span class="hljs-comment">#     [(batch, unit_1), (batch, unit_2, unit_3)]</span><font></font>
    input_1, input_2 = tf.nest.flatten(inputs)<font></font>
    s1, s2 = states<font></font>
<font></font>
    output_1 = tf.matmul(input_1, self.kernel_1)<font></font>
    output_2_3 = tf.einsum(<span class="hljs-string">'bij,ijkl-&gt;bkl'</span>, input_2, self.kernel_2_3)<font></font>
    state_1 = s1 + output_1<font></font>
    state_2_3 = s2 + output_2_3<font></font>
<font></font>
    output = [output_1, output_2_3]<font></font>
    new_states = NestedState(state1=state_1, state2=state_2_3)<font></font>
<font></font>
    <span class="hljs-keyword">return</span> output, new_states
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cr√©er un mod√®le RNN avec entr√©e / sortie imbriqu√©e</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Construisons un mod√®le Keras qui utilise une couche </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">et une cellule personnalis√©e que nous venons de d√©finir.</font></font><br>
<br>
<pre><code class="python hljs">unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])unit_1 = <span class="hljs-number">10</span>
unit_2 = <span class="hljs-number">20</span>
unit_3 = <span class="hljs-number">30</span><font></font>
<font></font>
input_1 = <span class="hljs-number">32</span>
input_2 = <span class="hljs-number">64</span>
input_3 = <span class="hljs-number">32</span>
batch_size = <span class="hljs-number">64</span>
num_batch = <span class="hljs-number">100</span>
timestep = <span class="hljs-number">50</span><font></font>
<font></font>
cell = NestedCell(unit_1, unit_2, unit_3)<font></font>
rnn = tf.keras.layers.RNN(cell)<font></font>
<font></font>
inp_1 = tf.keras.Input((<span class="hljs-literal">None</span>, input_1))<font></font>
inp_2 = tf.keras.Input((<span class="hljs-literal">None</span>, input_2, input_3))<font></font>
<font></font>
outputs = rnn(NestedInput(feature1=inp_1, feature2=inp_2))<font></font>
<font></font>
model = tf.keras.models.Model([inp_1, inp_2], outputs)<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'adam'</span>, loss=<span class="hljs-string">'mse'</span>, metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Former le mod√®le sur des donn√©es g√©n√©r√©es al√©atoirement</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme nous ne disposons pas d'un bon ensemble de donn√©es pour ce mod√®le, nous utilisons des donn√©es al√©atoires g√©n√©r√©es par la biblioth√®que Numpy pour la d√©monstration.</font></font><br>
<br>
<pre><code class="python hljs">input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))<font></font>
input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))<font></font>
target_1_data = np.random.random((batch_size * num_batch, unit_1))<font></font>
target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))<font></font>
input_data = [input_1_data, input_2_data]<font></font>
target_data = [target_1_data, target_2_data]<font></font>
<font></font>
model.fit(input_data, target_data, batch_size=batch_size)<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec une couche, </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous n'avez qu'√† d√©terminer la logique math√©matique d'une seule √©tape dans la s√©quence, et la couche </font></font><code>tf.keras.layers.RNN</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g√©rera l'it√©ration de la s√©quence pour vous. </font><font style="vertical-align: inherit;">C'est un moyen incroyablement puissant pour prototyper rapidement de nouveaux types de RNN (par exemple la variante LSTM). </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s v√©rification, la traduction appara√Ætra √©galement sur Tensorflow.org. </font><font style="vertical-align: inherit;">Si vous souhaitez participer √† la traduction de la documentation du site Web Tensorflow.org en russe, veuillez contacter personnellement ou commenter. </font><font style="vertical-align: inherit;">Toutes les corrections et commentaires sont appr√©ci√©s.</font></font></i></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr487798/index.html">Comment nous avons migr√© d'Oracle JDK et Java Web Start vers AdoptOpenJDK et OpenWebStart</a></li>
<li><a href="../fr487800/index.html">Pourquoi est-il important de dire au demandeur ce qui n'a pas fonctionn√© pendant l'entretien (et comment le faire correctement)</a></li>
<li><a href="../fr487802/index.html">Onduleur APC Smart sans coupure et comment les cuisiner</a></li>
<li><a href="../fr487804/index.html">Meetup Growth Teams √† Raiffeisenbank</a></li>
<li><a href="../fr487806/index.html">Cr√©ation d'une petite API Deno</a></li>
<li><a href="../fr487812/index.html">Test du spectre LED polonais Led E27</a></li>
<li><a href="../fr487814/index.html">La vitesse et la fiabilit√© sont plus √©lev√©es et le prix est plus bas. Nouveaux disques SSD Kingston KC2000</a></li>
<li><a href="../fr487822/index.html">AvitoTech On Tour: rencontre Android √† Nizhny Novgorod</a></li>
<li><a href="../fr487824/index.html">Aper√ßu des lampes LED Spectrum Led GU10 d'Europe</a></li>
<li><a href="../fr487826/index.html">Vue d'ensemble des lampes LED de Poland Spectrum Led E14</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
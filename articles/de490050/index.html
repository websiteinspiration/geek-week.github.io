<!doctype html>
<html class="no-js" lang="de">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔇 👩‍❤️‍💋‍👨 ↖️ Streaming von Spaltendaten mit Apache Arrow 🕙 🏉 🔡</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine Übersetzung des Artikels wurde speziell für Studenten des Data Engineer- Kurses erstellt .
 
 
 
 In den letzten Wochen haben Nong Li und ich Apa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Streaming von Spaltendaten mit Apache Arrow</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/490050/"><b><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine Übersetzung des Artikels wurde speziell für Studenten des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Data Engineer-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kurses erstellt </font><font style="vertical-align: inherit;">.</font></font></i></b><br>
<br>
<img src="https://habrastorage.org/webt/6b/3m/kz/6b3mkzihfzscol1hedy_gppa2f0.png"><br>
<hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den letzten Wochen haben </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nong Li und ich </font></font></a><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apache Arrow</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ein </font><font style="vertical-align: inherit;">binäres Streaming-Format </font><font style="vertical-align: inherit;">hinzugefügt </font><font style="vertical-align: inherit;">, das das vorhandene Direktzugriffs- / IPC-Dateiformat ergänzt. </font><font style="vertical-align: inherit;">Wir haben Implementierungen in Java- und C ++ - und Python-Bindungen. </font><font style="vertical-align: inherit;">In diesem Artikel werde ich Ihnen erklären, wie das Format funktioniert, und zeigen, wie Sie einen sehr hohen Datendurchsatz für DataFrame-Pandas erzielen können.</font></font><a name="habracut"></a><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Spalten-Daten-Streaming</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Eine häufig gestellte Frage von Arrow-Benutzern ist die Frage nach den hohen Kosten für das Verschieben großer Mengen tabellarischer Daten von einem zeilenorientierten oder zeilenorientierten Format in ein Spaltenformat. Bei Datensätzen mit mehreren Gigabyte kann das Transponieren im Speicher oder auf der Festplatte eine überwältigende Aufgabe sein. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Für das Streaming von Daten besteht eine Option, unabhängig davon, ob es sich bei den Quelldaten um Zeichenfolgen oder Spalten handelt, darin, kleine Zeilenpakete zu senden, von denen jede ein Spaltenlayout enthält. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Apache Arrow wird eine Sammlung von speicherinternen Spaltenarrays, die einen Tabellenblock darstellen, als Datensatzstapel bezeichnet. Um eine einzelne Datenstruktur einer logischen Tabelle darzustellen, können mehrere Datensatzpakete zusammengestellt werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im vorhandenen Dateiformat mit wahlfreiem Zugriff zeichnen wir Metadaten auf, die das Tabellenlayout und die Position der Blöcke am Ende der Datei enthalten. Auf diese Weise können Sie jedes Datensatzpaket oder jede Spalte aus dem Datensatz äußerst kostengünstig auswählen. </font><font style="vertical-align: inherit;">In einem Streaming-Format senden wir eine Reihe von Nachrichten: ein Schema und dann ein oder mehrere Pakete von Datensätzen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die verschiedenen Formate sehen ungefähr so ​​aus wie in dieser Abbildung:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/of/kd/jq/ofkdjqyesvfqkmj92jntxjuqani.png"><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyArrow Streaming: Anwendung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Um Ihnen zu zeigen, wie dies funktioniert, werde ich ein Beispieldatensatz erstellen, das einen einzelnen Stream-Block darstellt:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">import</span> time
<span class="hljs-attribute">import</span> numpy as np
<span class="hljs-attribute">import</span> pandas as pd
<span class="hljs-attribute">import</span> pyarrow as pa<font></font>
<font></font>
<span class="hljs-attribute">def</span> generate_data(total_size, ncols):
    <span class="hljs-attribute">nrows</span> = int(total_size / ncols / np.dtype('float<span class="hljs-number">64</span>').itemsize)
    <span class="hljs-attribute">return</span> pd.DataFrame({<font></font>
        '<span class="hljs-attribute">c</span>' + str(i): np.random.randn(nrows)
        <span class="hljs-attribute">for</span> i in range(ncols)<font></font>
    })	</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Angenommen, wir möchten 1 GB Daten aufzeichnen, die aus Blöcken von jeweils 1 MB bestehen, was insgesamt 1024 Blöcken entspricht. </font><font style="vertical-align: inherit;">Erstellen wir zunächst den ersten 1-MB-Datenrahmen mit 16 Spalten:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">KILOBYTE</span> = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">10</span>
<span class="hljs-attribute">MEGABYTE</span> = KILOBYTE * KILOBYTE
<span class="hljs-attribute">DATA_SIZE</span> = <span class="hljs-number">1024</span> * MEGABYTE
<span class="hljs-attribute">NCOLS</span> = <span class="hljs-number">16</span><font></font>
<font></font>
<span class="hljs-attribute">df</span> = generate_data(MEGABYTE, NCOLS)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Dann konvertiere ich sie zu </font></font><code>pyarrow.RecordBatch</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">batch</span> = pa.RecordBatch.from_pandas(df)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Jetzt werde ich einen Ausgabestream erstellen, der in den RAM schreibt und Folgendes erstellt </font></font><code>StreamWriter</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">sink</span> = pa.InMemoryOutputStream()
<span class="hljs-attribute">stream_writer</span> = pa.StreamWriter(sink, batch.schema)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Dann schreiben wir 1024 Chunks, die schließlich einen 1-GB-Datensatz bilden:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">for</span> i in range(DATA_SIZE // MEGABYTE):
    <span class="hljs-attribute">stream_writer</span>.write_batch(batch)</code></pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Da wir im RAM geschrieben haben, können wir den gesamten Stream in einem Puffer abrufen:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">In</span><span class="hljs-meta"> [13]: source = sink.get_result()

In [14]: source
Out[14]: &lt;pyarrow.io.Buffer at 0x7f2df7118f80&gt;

In [15]: source.size
Out[15]: 1074750744</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Da sich diese Daten im Speicher befinden, ist das Auslesen von Pfeilaufzeichnungspaketen eine Nullkopieoperation. </font><font style="vertical-align: inherit;">Ich öffne StreamReader, lese die Daten ein </font></font><code>pyarrow.Table</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">und konvertiere sie dann in </font></font><code>DataFrame pandas</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">In</span><span class="hljs-meta"> [16]: reader = pa.StreamReader(source)

In [17]: table = reader.read_all()

In [18]: table
Out[18]: &lt;pyarrow.table.Table at 0x7fae8281f6f0&gt;

In [19]: df = table.to_pandas()

In [20]: df.memory_usage().sum()
Out[20]: 1073741904</span></code></pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Das alles ist natürlich gut, aber Sie können Fragen haben. </font><font style="vertical-align: inherit;">Wie schnell geht das? </font><font style="vertical-align: inherit;">Wie wirkt sich die Blockgröße auf die Leistung beim Abrufen von DataFrame-Pandas aus?</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Streaming-Leistung</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Wenn die Größe des Streaming-Blocks abnimmt, steigen die Kosten für die Rekonstruktion einer kontinuierlichen DataFrame-Spalte in Pandas aufgrund ineffizienter Cache-Zugriffsschemata. Die Arbeit mit C ++ - Datenstrukturen und -Arrays und ihren Speicherpuffern ist ebenfalls mit einem gewissen Aufwand verbunden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie oben erwähnt, stellt sich für 1 MB auf meinem Laptop (Quad-Core Xeon E3-1505M) Folgendes heraus:</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">In</span><span class="hljs-meta"> [20]: %timeit pa.StreamReader(source).read_all().to_pandas()
10 loops, best of 3: 129 ms per loop</span></code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Es stellt sich heraus, dass die effektive Bandbreite 7,75 Gbit / s für die Wiederherstellung eines 1-Gbit-Datenrahmens mit 1024 Blöcken zu je 1 MB beträgt. </font><font style="vertical-align: inherit;">Was passiert, wenn wir größere oder kleinere Stücke verwenden? </font><font style="vertical-align: inherit;">Hier sind die Ergebnisse: Die </font></font><br>
<br>
<img src="https://habrastorage.org/webt/_2/qz/4j/_2qz4j7k7keun29itu0bx-cnklw.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Leistung sinkt erheblich von 256 KB auf 64 KB. </font><font style="vertical-align: inherit;">Ich war überrascht, dass 1-MB-Chunks schneller als 16 MB verarbeitet wurden. </font><font style="vertical-align: inherit;">Es lohnt sich, eine gründlichere Studie durchzuführen und zu verstehen, ob dies eine Normalverteilung ist oder ob etwas anderes sie beeinflusst. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei der aktuellen Implementierung des Formats werden die Daten im Prinzip nicht komprimiert, daher ist die Größe im Speicher und in den Drähten ungefähr gleich. </font><font style="vertical-align: inherit;">In Zukunft kann die Komprimierung eine zusätzliche Option sein.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gesamt</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Das Streaming von Spaltendaten kann eine effektive Möglichkeit sein, große Datenmengen mithilfe kleiner Blöcke an Spaltenanalysewerkzeuge wie Pandas zu übertragen. </font><font style="vertical-align: inherit;">Datendienste, die zeilenorientierten Speicher verwenden, können kleine Datenblöcke übertragen und transponieren, die für den L2- und L3-Cache Ihres Prozessors bequemer sind. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vollständiger Code</font></font><br>
<br>
<pre><code class="apache hljs"><span class="hljs-attribute">import</span> time
<span class="hljs-attribute">import</span> numpy as np
<span class="hljs-attribute">import</span> pandas as pd
<span class="hljs-attribute">import</span> pyarrow as pa<font></font>
<font></font>
<span class="hljs-attribute">def</span> generate_data(total_size, ncols):
    <span class="hljs-attribute">nrows</span> = total_size / ncols / np.dtype('float<span class="hljs-number">64</span>').itemsize
    <span class="hljs-attribute">return</span> pd.DataFrame({<font></font>
        '<span class="hljs-attribute">c</span>' + str(i): np.random.randn(nrows)
        <span class="hljs-attribute">for</span> i in range(ncols)<font></font>
    })<font></font>
<font></font>
<span class="hljs-attribute">KILOBYTE</span> = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">10</span>
<span class="hljs-attribute">MEGABYTE</span> = KILOBYTE * KILOBYTE
<span class="hljs-attribute">DATA_SIZE</span> = <span class="hljs-number">1024</span> * MEGABYTE
<span class="hljs-attribute">NCOLS</span> = <span class="hljs-number">16</span><font></font>
<font></font>
<span class="hljs-attribute">def</span> get_timing(f, niter):
    <span class="hljs-attribute">start</span> = time.clock_gettime(time.CLOCK_REALTIME)
    <span class="hljs-attribute">for</span> i in range(niter):
        <span class="hljs-attribute">f</span>()
    <span class="hljs-attribute">return</span> (time.clock_gettime(time.CLOCK_REALTIME) - start) / NITER<font></font>
<font></font>
<span class="hljs-attribute">def</span> read_as_dataframe(klass, source):
    <span class="hljs-attribute">reader</span> = klass(source)
    <span class="hljs-attribute">table</span> = reader.read_all()
    <span class="hljs-attribute">return</span> table.to_pandas()
<span class="hljs-attribute">NITER</span> = <span class="hljs-number">5</span>
<span class="hljs-attribute">results</span> =<span class="hljs-meta"> []</span><font></font>
<font></font>
<span class="hljs-attribute">CHUNKSIZES</span> =<span class="hljs-meta"> [16 * KILOBYTE, 64 * KILOBYTE, 256 * KILOBYTE, MEGABYTE, 16 * MEGABYTE]</span><font></font>
<font></font>
<span class="hljs-attribute">for</span> chunksize in CHUNKSIZES:
    <span class="hljs-attribute">nchunks</span> = DATA_SIZE // chunksize
    <span class="hljs-attribute">batch</span> = pa.RecordBatch.from_pandas(generate_data(chunksize, NCOLS))<font></font>
<font></font>
    <span class="hljs-attribute">sink</span> = pa.InMemoryOutputStream()
    <span class="hljs-attribute">stream_writer</span> = pa.StreamWriter(sink, batch.schema)<font></font>
<font></font>
    <span class="hljs-attribute">for</span> i in range(nchunks):
        <span class="hljs-attribute">stream_writer</span>.write_batch(batch)<font></font>
<font></font>
    <span class="hljs-attribute">source</span> = sink.get_result()<font></font>
<font></font>
    <span class="hljs-attribute">elapsed</span> = get_timing(lambda: read_as_dataframe(pa.StreamReader, source), NITER)<font></font>
<font></font>
    <span class="hljs-attribute">result</span> = (chunksize, elapsed)
    <span class="hljs-attribute">print</span>(result)
    <span class="hljs-attribute">results</span>.append(result)</code></pre></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de490034/index.html">ML REPA Meetup bei der Raffeisenbank: Rundfunk weiter</a></li>
<li><a href="../de490040/index.html">Python-Sellerie in Windows mit Docker-Verwaltung</a></li>
<li><a href="../de490042/index.html">Positive Technologies-Studie: 7 von 8 Finanzinstituten können über das Internet in das Netzwerk eintreten</a></li>
<li><a href="../de490044/index.html">CRM-Implementierung mit den Augen des Kunden</a></li>
<li><a href="../de490046/index.html">NDA für Entwicklung - „Restklausel“ und andere Möglichkeiten, sich zu schützen</a></li>
<li><a href="../de490052/index.html">iOS-Apps können Daten aus der Zwischenablage des Geräts + der MacOS-Umfrage zur Bedrohungsüberwachung stehlen</a></li>
<li><a href="../de490054/index.html">17 Überraschungen für mein erstes Jahr mit dem Tesla Model 3</a></li>
<li><a href="../de490056/index.html">Black Box: Protokollierung vergessen</a></li>
<li><a href="../de490060/index.html">Wissensdiagramm suchen: Aufbau aus mehreren Quellen</a></li>
<li><a href="../de490066/index.html">Von China zum Südpol: Gemeinsam das Neutrino-Massen-Rätsel lösen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
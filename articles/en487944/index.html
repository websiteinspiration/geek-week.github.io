<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üß¶ üîé üï¢ Machine learning in the energy sector, or not only everyone can watch tomorrow üôãüèΩ üî≥ üõåüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Accurate prediction of future events is a promising and interesting task in many areas: from weather forecasting to fintech (stock quotes, exchange ra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Machine learning in the energy sector, or not only everyone can watch tomorrow</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/487944/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Accurate prediction of future events is a promising and interesting task in many areas: from weather forecasting to fintech (stock quotes, exchange rates). Machine learning today can significantly reduce the time and labor involved in making management decisions.&nbsp; </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;">For</font></a><font style="vertical-align: inherit;"> about half a year, </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
our Data Science team at </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NORBIT</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> experimented using various machine learning models to solve classification and regression problems, and to optimize b2b business processes. But when the task of predicting the time series appeared, it turned out that the available materials on this topic on the network were not enough to develop a quick solution.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5bc/9c4/544/5bc9c4544398d7da8702bc31396a5a5f.jpg"></div><a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The essence of the task was to </font><font style="vertical-align: inherit;">predict </font><font style="vertical-align: inherit;">with maximum accuracy (average absolute error in percent, or </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MAPE</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> &lt;3%) the hourly consumption of the whole city for the next three days (72 hours) for the needs of one large electricity generating company.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The maximum permissible error of 3% is a very high indicator for the accuracy of forecasts. Before the use of machine learning, the error was in the range of 3-23%, which directly led to financial losses, since with insufficient generation of electric energy, additional capacities had to be bought in the wholesale electricity market (which is much more expensive than self-generated), with overproduction - sold in the market cheaper than they could sell to the city. Also, the negative effect of the deviation of the planned load from the actual one is a change in the frequency of the alternating current in the network.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Many factors prevent the achievement of high accuracy of forecasting, for example, with a sudden increase in temperature, people immediately reach for consoles from air conditioners, and when they drop, they get heaters from the mezzanines; during the holidays or big football matches include TVs, etc. While some events are cyclical and potentially predictable, others are completely absent. Suppose, suddenly, due to an accident, the steel shop ceased to work and all forecasts turned into a pumpkin (in our target city there were no large production enterprises). There was a rather interesting example of a problem in making forecasts in the energy sector, when one of the spikes in changes in the amount of electricity generated was caused by the ship stranded on a lake, and the captain agreed with the owners of hydroelectric power plants to reduce water discharge.Naturally, the machine learning model could not predict this event on the basis of historical data.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The good news for us is that the customer provided such ‚Äúspecial days‚Äù in the terms of reference that allowed an average forecast error of 8%. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All that the customer provided is the historical data of the hourly electricity consumption for 3 years and the name of the city.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c7c/85a/2b7/c7c85a2b744484fbd82af3e1bdb862c1.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first task for preparing the construction of a machine learning model is visualization and the search for additional factors that can influence the forecast. </font><font style="vertical-align: inherit;">The degree of such influence is conveniently visually assessed using a heat map of the correlation of attributes. </font><font style="vertical-align: inherit;">The dark square in this case means the unconditional inverse relationship of the quantities (the larger one value, the smaller the other, and vice versa), white - direct:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<font></font>
<font></font>
<font></font>
<span class="hljs-comment"># df - pandas DataFrame  </span>
sns.heatmap(df.corr());</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d67/1d1/306/d671d13066c5d1f0c338a2bb9be98f1b.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As far as I know, in the models that are used to forecast electricity consumption in the Russian Federation, 2 factors are used - the history of consumption and the temperature forecast.&nbsp;</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3e1/5ca/23a/3e15ca23a39908cf524e78005da4fd75.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In winter and autumn, energy consumption is higher - low temperature and a relatively short daylight hours. </font><font style="vertical-align: inherit;">The ‚Äúday of the week‚Äù factor also affects the amount of energy spent - on weekends it drops sharply. </font><font style="vertical-align: inherit;">Peaks in consumption occur on Wednesday or Thursday.</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e09/f0f/a6a/e09f0fa6a5c2f9e31e71ee34e8dac852.png"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f96/e98/50c/f96e9850cf5ac194495fc8b53b4d75e1.png"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a09/51c/eab/a0951ceabb827dc253d38b4c647dc07e.png"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b86/e99/d10/b86e99d107cdbd1346b68559949b4792.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Inside one day on weekdays, the peak values ‚Äã‚Äãof energy consumption occur at 11-12 hours and gradually fall with a sharp drop after nine in the evening.&nbsp;</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/habr/post_images/6de/c6a/0a8/6dec6a0a8e0f111ae5e3ccd0a9e41d2e.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Everything is as in the textbooks:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b99/bb8/bb1/b99bb8bb1741dac3610d86d62cb31fea.jpg"></div><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daily winter and summer daily consumption schedules for industrial and cultural centers. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modeling</font></font></h2><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prophet</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first idea how to make the task as fast as possible is to take Prophet from Facebook. </font><font style="vertical-align: inherit;">I already had experience using it, and I remembered it as ‚Äúa thing that simply and quickly works out of the box.‚Äù </font><font style="vertical-align: inherit;">Prophet wants to see the columns ‚Äúds‚Äù and ‚Äúy‚Äù in the pandas data frame, i.e. </font><font style="vertical-align: inherit;">date in the format YYYY-MM-DD HH: MM: SS, and the target is consumption per hour, respectively (examples of work are in the </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documentation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<pre><code class="python hljs">df = pd.read_pickle(<span class="hljs-string">'full.pkl'</span>)<font></font>
pjme = df.loc[:<span class="hljs-string">'2018-06-01 23:00'</span>].rename(columns={<span class="hljs-string">'hour_value'</span>: <span class="hljs-string">'y'</span>})&nbsp;<font></font>
pjme[<span class="hljs-string">'ds'</span>] = pjme.index<font></font>
split_date = <span class="hljs-string">'2018-03-01 23:00'</span><font></font>
pjme_train = pjme.loc[pjme.index &lt;= split_date]<font></font>
pjme_test = pjme.loc[pjme.index &gt; split_date]<font></font>
<font></font>
<font></font>
playoffs = pd.DataFrame({<font></font>
&nbsp; <span class="hljs-string">'holiday'</span>: <span class="hljs-string">'playoff'</span>,
&nbsp; <span class="hljs-string">'ds'</span>: df[(df.rest_day == <span class="hljs-number">1</span>)|(df.is_weekend == <span class="hljs-number">1</span>)].index,
&nbsp; <span class="hljs-string">'lower_window'</span>: <span class="hljs-number">0</span>,
&nbsp; <span class="hljs-string">'upper_window'</span>: <span class="hljs-number">1</span>,<font></font>
})<font></font>
<font></font>
<font></font>
model = Prophet(holidays=playoffs)<font></font>
model.fit(pjme_train.reset_index())<font></font>
forecast = model.predict(df=pjme_test.reset_index())</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/736/115/46c/73611546c9eefe230cffebb3c65f3909.png"></div><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/978/5ba/082/9785ba0828d2286f48c6fd4014a6039f.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The predictions of the ‚Äúprophet‚Äù looked objective, but the error was 7‚Äì17% higher than the permissible, therefore, I did not conduct further experiments on this framework.</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sarimaax</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The second attempt to solve this problem was using SARIMAX. </font><font style="vertical-align: inherit;">The method is quite time-consuming for selecting coefficients, but it was possible to reduce the forecast error compared to Prophet to 6-11%.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Unfortunately, only the result for the weekly predictions remained, but it was these predictive data that I used as additional features in the boosting models. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For the forecast, you need to select the SARIMA parameters (p, d, q) (P, D, Q, s):</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p is the autoregressive order (AR), which allows you to add the past values ‚Äã‚Äãof the time series (can be expressed as "tomorrow, it will probably snow if it has snowed in the last few days");</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d is the order of integration of the source data (it determines the number of previous time points to be subtracted from the current value);</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">q is the order of the moving average (MA), which allows you to set the error of the model in the form of a linear combination of the previously observed error values;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P - p, but seasonal;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D - d, but seasonal;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Q - q, but seasonal;</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s is the dimension of seasonality (month, quarter, etc.).</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On the seasonal expansion of the weekly history, you can see the trend and seasonality, which allows seasonal_decompose to be displayed:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> statsmodels.api <span class="hljs-keyword">as</span> sm<font></font>
sm.tsa.seasonal_decompose(df_week).plot()</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/41f/12d/fb541f12da571be70fe715fc97ab93e4.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
According to the graphs of autocorrelation and partial autocorrelation, he selected the initial approximations of the parameters for the SARIMAX model: p = 0, P = 1, q = 2, Q = 2.</font></font><br>
<br>
<pre><code class="python hljs">sm.graphics.tsa.plot_acf(df_week.diff_week[<span class="hljs-number">52</span>:].values.squeeze(), lags=<span class="hljs-number">60</span>, ax=ax)<font></font>
sm.graphics.tsa.plot_pacf(df_week.diff_week[<span class="hljs-number">52</span>:].values.squeeze(), lags=<span class="hljs-number">60</span>, ax=ax)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/87f/683/0d7/87f6830d7d1eafbecc5defa299f20011.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And the final selected values ‚Äã‚Äãare (0, 2, 2) x (1, 2, 0, 52). </font><font style="vertical-align: inherit;">As a result, the consumption forecast graph looked like this:</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2f4/b66/920/2f4b66920297d473ed2493f5a2fa8d65.png"></div><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Boosting</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
At this point, it became apparent that without the use of additional external factors, the necessary accuracy could not be achieved. First of all, these are weather factors: temperature, pressure, humidity, wind strength and direction, precipitation.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
The first attempt was an attempt to buy an archive of weather in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. The guys have excellent API and technical support, but specifically in our city there were quite a lot of gaps in the data. As a result, I bought the archive in the openweathermap.org service for $ 10. It is important to note that, despite the fact that the weather is a very useful factor, forecast errors will obviously spoil the final MAPE model. I met information that the correct solution to this problem would be in training to use not the actual historical values ‚Äã‚Äãof the weather, but weather forecasts for three days, but, unfortunately, I did not have such an opportunity.&nbsp; </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I also added signs of the time of day, day of the week, holidays, the serial number of the day in the year, as well as a large number of time lags and average values ‚Äã‚Äãfor previous periods.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
All the data after scaling (MinMaxScale) and One Hot Encoding (the values ‚Äã‚Äãof each categorical item become separate columns with 0 and 1, so the item with three values ‚Äã‚Äãbecomes three different columns, and the unit will be in only one of them) I used in a small competition of three popular boost models XGBoost, LightGBM and CatBoost.&nbsp;</font></font><br>
<br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">XGBoost</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A lot of good has been written about XGBoost. </font><font style="vertical-align: inherit;">Presented at the SIGKDD conference in 2016, he made a splash and still holds a leading position. </font><font style="vertical-align: inherit;">Interesting </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">material</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> for those who have not heard about it. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Let's prepare the data for the model:&nbsp;</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> MinMaxScaler, StandardScaler
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<font></font>
<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gen_data</span>(<span class="hljs-params">
&nbsp; &nbsp; stop_day = <span class="hljs-string">'2018-06-01 23:00'</span>,&nbsp;
&nbsp; &nbsp; drop_columns = [],
&nbsp; &nbsp; test_size=<span class="hljs-number">0.15</span>,
&nbsp; &nbsp; is_dummies=True,
&nbsp; &nbsp; is_target_scale=False</span>):</span><font></font>
<font></font>
&nbsp; &nbsp; df = pd.read_pickle(<span class="hljs-string">'full.pkl'</span>)<font></font>
&nbsp; &nbsp; df = df.loc[:stop_day]<font></font>
&nbsp; &nbsp; scaler = MinMaxScaler()<font></font>
&nbsp; &nbsp; target_scaler = StandardScaler()<font></font>
&nbsp; &nbsp; y = df.hour_total<font></font>
&nbsp; &nbsp;&nbsp;<font></font>
&nbsp; &nbsp; <span class="hljs-keyword">if</span> is_target_scale: &nbsp; &nbsp; &nbsp; &nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; y = target_scaler.fit_transform(y.values.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)).reshape(<span class="hljs-number">1</span>,<span class="hljs-number">-1</span>)[<span class="hljs-number">0</span>]<font></font>
&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<font></font>
&nbsp; &nbsp; X = df.drop([<span class="hljs-string">'hour_value'</span>, *drop_columns], axis=<span class="hljs-number">1</span>)<font></font>
&nbsp; &nbsp; num_columns = X.select_dtypes(include=[<span class="hljs-string">'float64'</span>]).columns<font></font>
&nbsp; &nbsp; X[num_columns] = scaler.fit_transform(X[num_columns])<font></font>
&nbsp; &nbsp;&nbsp;<font></font>
&nbsp; &nbsp; <span class="hljs-keyword">if</span> is_dummies:<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; X = pd.get_dummies(X)<font></font>
<font></font>
&nbsp; &nbsp; train_count_hours = len(X) - <span class="hljs-number">72</span>
&nbsp; &nbsp; valid_count_hours = len(X) - int(len(X) * <span class="hljs-number">0.2</span>)<font></font>
&nbsp; &nbsp; X_test &nbsp;= X[train_count_hours:]<font></font>
&nbsp; &nbsp; y_test &nbsp;= y[train_count_hours:]<font></font>
&nbsp; &nbsp; X = X[:train_count_hours]<font></font>
&nbsp; &nbsp; y = y[:train_count_hours]<font></font>
<font></font>
&nbsp; &nbsp; <span class="hljs-comment">#           ,       </span>
&nbsp; &nbsp; X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=<span class="hljs-number">42</span>)<font></font>
&nbsp; &nbsp; train_dates = X_train.index<font></font>
&nbsp; &nbsp; val_dates = X_test.index<font></font>
&nbsp; &nbsp; <span class="hljs-keyword">return</span> X, y, X_train, X_val, y_train, y_val, X_test, y_test, target_scaler</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
I‚Äôm teaching a model using the best previously selected hyperparameters:</font></font><br>
<br>
<pre><code class="python hljs">X, y, X_train, X_val, y_train, y_val, X_test, y_test, _ = gen_data(<font></font>
&nbsp; &nbsp; stop_day = stop_day,&nbsp;<font></font>
&nbsp; &nbsp; drop_columns = drop_columns,<font></font>
&nbsp; &nbsp; test_size=<span class="hljs-number">0.1</span>,<font></font>
&nbsp; &nbsp; is_dump=<span class="hljs-literal">True</span>,<font></font>
&nbsp; &nbsp; is_target_scale=<span class="hljs-literal">False</span>)<font></font>
<font></font>
<font></font>
params_last = {<font></font>
&nbsp; &nbsp; <span class="hljs-string">'base_score'</span>: <span class="hljs-number">0.5</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'booster'</span>: <span class="hljs-string">'gbtree'</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'colsample_bylevel'</span>: <span class="hljs-number">1</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'colsample_bynode'</span>: <span class="hljs-number">1</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'colsample_bytree'</span>: <span class="hljs-number">0.4</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'gamma'</span>: <span class="hljs-number">0</span>,
&nbsp; &nbsp; <span class="hljs-string">'max_depth'</span>: <span class="hljs-number">2</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'min_child_weight'</span>: <span class="hljs-number">5</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'reg_alpha'</span>: <span class="hljs-number">0</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'reg_lambda'</span>: <span class="hljs-number">1</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'seed'</span>: <span class="hljs-number">38</span>,
&nbsp; &nbsp; <span class="hljs-string">'subsample'</span>: <span class="hljs-number">0.7</span>,&nbsp;
&nbsp; &nbsp; <span class="hljs-string">'verbosity'</span>: <span class="hljs-number">1</span>,
&nbsp; &nbsp; <span class="hljs-string">'learning_rate'</span>:<span class="hljs-number">0.01</span><font></font>
}<font></font>
<font></font>
<font></font>
reg = xgb.XGBRegressor(**params_last, n_estimators=<span class="hljs-number">2000</span>)<font></font>
print(X_train.columns)<font></font>
reg.fit(X_train, y_train,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; eval_set=[(X_val, y_val)],<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; early_stopping_rounds=<span class="hljs-number">20</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; verbose=<span class="hljs-literal">False</span>)<font></font>
<font></font>
<font></font>
y_pred = reg.predict(X_test)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/41c/c3a/372/41cc3a372cc3c4cd7557637ffcea78f5.png"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lightgbm</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
LightGBM is a framework from Microsoft whose main advantage is the speed of learning on really large data sets. </font><font style="vertical-align: inherit;">And also, unlike XGBoost, LightGBM can work with categories, uses less memory. </font><font style="vertical-align: inherit;">Here </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://medium.com/%40pushkarmandot/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">then</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> there is more.</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb
<span class="hljs-keyword">from</span> lightgbm <span class="hljs-keyword">import</span> LGBMRegressor
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> mean_squared_error<font></font>
<font></font>
<font></font>
stop_day = <span class="hljs-string">'2018-06-01 23:00'</span>
start_day_for_iterate = datetime.strptime(stop_day, <span class="hljs-string">'%Y-%m-%d %H:%M'</span>)<font></font>
test_size = <span class="hljs-number">0.2</span><font></font>
<font></font>
X, y, X_train, X_val, y_train, y_val, X_test, y_test, _ = gen_data(<font></font>
&nbsp; &nbsp; stop_day = stop_day,&nbsp;<font></font>
&nbsp; &nbsp; drop_columns = drop_columns,<font></font>
&nbsp; &nbsp; test_size=test_size,<font></font>
&nbsp; &nbsp; is_dump=<span class="hljs-literal">True</span>,<font></font>
&nbsp; &nbsp; drop_weekend=<span class="hljs-literal">False</span>,<font></font>
&nbsp; &nbsp; is_target_scale=<span class="hljs-literal">False</span>)<font></font>
<font></font>
<font></font>
model = LGBMRegressor(boosting_type=<span class="hljs-string">'gbdt'</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; num_leaves=<span class="hljs-number">83</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; max_depth=<span class="hljs-number">-1</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; learning_rate=<span class="hljs-number">0.008</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; n_estimators=<span class="hljs-number">15000</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; max_bin=<span class="hljs-number">255</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; subsample_for_bin=<span class="hljs-number">50000</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; min_split_gain=<span class="hljs-number">0</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; min_child_weight=<span class="hljs-number">3</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; min_child_samples=<span class="hljs-number">10</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; subsample=<span class="hljs-number">0.3</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; subsample_freq=<span class="hljs-number">1</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; colsample_bytree=<span class="hljs-number">0.5</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reg_alpha=<span class="hljs-number">0.1</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; reg_lambda=<span class="hljs-number">0</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; seed=<span class="hljs-number">38</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; silent=<span class="hljs-literal">False</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; nthread=<span class="hljs-number">-1</span>)<font></font>
<font></font>
<font></font>
history = model.fit(X_train, y_train,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; eval_metric=<span class="hljs-string">'rmse'</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; eval_set=[(X_val, y_val)],<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; early_stopping_rounds=<span class="hljs-number">40</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; verbose = <span class="hljs-number">0</span>)<font></font>
<font></font>
<font></font>
y_pred = model.predict(X_test, num_iteration=model.best_iteration_)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a11/9a0/0a0/a119a00a0e6637edef5c7e533024da8e.png"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Catboost</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
CatBoost is an advanced library of gradient boosting on open source decision trees "from </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yandex</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . The advantageous difference of the model is the convenience of working with datasets containing categorical attributes - you can transfer data containing categories to the model without conversion to numbers, and it reveals patterns on its own, by hand nothing needs to be twisted, and the quality of the prediction remains high.</font></font><br>
<br>
<pre><code class="python hljs">cat_features=np.where(X.dtypes == <span class="hljs-string">'category'</span>)[<span class="hljs-number">0</span>]<font></font>
eval_dataset = Pool(X_test, y_test)<font></font>
<font></font>
model = CatBoostRegressor(learning_rate=<span class="hljs-number">0.5</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; eval_metric=<span class="hljs-string">'RMSE'</span>,&nbsp;<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; leaf_estimation_iterations=<span class="hljs-number">3</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; depth=<span class="hljs-number">3</span>)<font></font>
<font></font>
model.fit(X_train, y_train,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; eval_set=(X_val, y_val),<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cat_features=cat_features,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; plot=<span class="hljs-literal">True</span>,<font></font>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; verbose=<span class="hljs-literal">True</span>)<font></font>
<font></font>
y_pred = model.predict(X_test)</code></pre><br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/986/11f/7f2/98611f7f25c035c0f44d5d99ac4a70b5.png"></div><br>
<h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">XGBoost vs. </font><font style="vertical-align: inherit;">LightGBM vs. </font><font style="vertical-align: inherit;">Catboost</font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In order not to repeat numerous articles, I will give a comparative table </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from here</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/010/910/097/010910097094035b0bc891663bb4b867.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
To calculate the MAPE error, I took the last known month (28 days) and, moving the window with a resolution of one hour, I made a forecast for the next 72 hours. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
And in my impromptu competition the prizes were: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
3rd place: my favorite - XGBoost - with the lowest forecast quality; </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
2nd place: CatBoost as the most convenient and ‚Äúall out of the box‚Äù; </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1st place: LightGBM as the fastest and most accurate.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
For a more accurate comparison of the models, I used R2 (R-squared or determination coefficient, showing how much the conditional variance of the model differs from the variance of real values) and RMSLE (Root Mean Squared Logarithmic Error, or the root mean square logarithmic error, which is, in fact, the distance between two points on the plane - real value and predicted).&nbsp;</font></font><br>
<br>
<div class="scrollable-table"><table>
<tbody><tr>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Metrics</font></font></b></td>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lightgbm</font></font></b></td>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Catboost</font></font></b></td>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">XGBoost</font></font></b></td>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prophet</font></font></b></td>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sarimaax</font></font></b></td>
</tr>
<tr>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r2</font></font></b></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.94137</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.93984</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.92909</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.81435</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.73778</font></font></td>
</tr>
<tr>
<td><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Msle</font></font></b></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.02468</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.02477</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.01219</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.00829</font></font></td>
<td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.00658</font></font></td>
</tr>
</tbody></table></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
But all this, of course, in relation to my task. </font><font style="vertical-align: inherit;">On other data in different hands, everything can be completely different.&nbsp;</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Next time, I will share another story of our own on forecasting employee outflows for the task of planning recruitment in our company.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">By the way, our team is growing, and we are looking for people!</font></font></b><div class="spoiler_text"><ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Senior Consultant (management consulting and budgeting)</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Senior Integration Consultant</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bitrix24 Consultant</font></font></a></li>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CRM Project Manager</font></font></a></li>
</ul></div></div></div>
      
    </div><p class="reference-to-source js-reference-to-source">Source: https://habr.com/ru/post/undefined/</p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../en487930/index.html">Lecture night I want to gamedev</a></li>
<li><a href="../en487932/index.html">Ideal normal maps for Unity (and other programs)</a></li>
<li><a href="../en487934/index.html">How we optimized our DNS server using GO tools</a></li>
<li><a href="../en487938/index.html">Introducing effector-dom using the example task list</a></li>
<li><a href="../en487940/index.html">Reproducible computing in R. How to separate code and data?</a></li>
<li><a href="../en487948/index.html">Two-factor authentication in OpenVPN with Telegram bot</a></li>
<li><a href="../es486176/index.html">Memo de correspondencia de correo electr√≥nico corporativo</a></li>
<li><a href="../es486178/index.html">FOSS News No. 1 - revisi√≥n de noticias gratuitas y de c√≥digo abierto del 27 de enero al 2 de febrero de 2020</a></li>
<li><a href="../es486180/index.html">Consejos y fuentes para crear aplicaciones sin servidor</a></li>
<li><a href="../es486184/index.html">C√≥mo usar la b√∫squeda de manera efectiva</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
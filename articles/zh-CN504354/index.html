<!doctype html>
<html class="no-js" lang="zh-CN">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍💻 🤛🏼 📤 无需注册和SMS即可减少ML模型的大小 👨‍👨‍👦‍👦 👩‍👩‍👧‍👦 👃🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="任何遇到机器学习的人都知道，这需要强大的计算能力。在本文中，我们将尝试应用由MIT开发的算法来压缩神经网络，这将减少训练后模型的权重维，并导致更快的学习和更快的模型发布。
 
 事实证明，神经网络是解决各种各样任务的出色工具，但不幸的是，神经网络的使用需要强大的计算能力，而这在小型企业中可能还不是很...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>无需注册和SMS即可减少ML模型的大小</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/504354/"><img src="https://habrastorage.org/webt/u3/w2/jm/u3w2jmkqidenskb9-sgwysh2gy8.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
任何遇到机器学习的人都知道，这需要强大的计算能力。在本文中，我们将尝试应用由MIT开发的算法来压缩神经网络，这将减少训练后模型的权重维，并导致更快的学习和更快的模型发布。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
事实证明，神经网络是解决各种各样任务的出色工具，但不幸的是，神经网络的使用需要强大的计算能力，而这在小型企业中可能还不是很大。神经网络的压缩类型很多，可以分为硬件，底层和数学两种，但本文将讨论麻省理工学院在2019年开发的，直接与神经网络本身一起工作的方法。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
这种方法称为“中奖彩票假说”。</font><font style="vertical-align: inherit;">一般而言，这听起来像是：任何具有随机初始化权重的完全连接的神经网络都包含一个具有相同权重的子网，并且这种经过单独训练的子网的准确性可以与原始网络相同。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
正式的证明和全文可以在</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这里</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">找到</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">我们对实际应用的可能性感兴趣。</font><font style="vertical-align: inherit;">简而言之，算法如下：</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们创建一个模型，随机初始化其参数</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">学习迭代网络j</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们切断那些具有最小值的网络参数（最简单的任务是设置一些阈值）</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们将其余参数重置为其初始值，得到所需的子网。</font></font></li>
</ol><br>
<a name="habracut"></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
从理论上讲，此算法需要重复第n步，但作为示例，我们将仅执行一次迭代。</font><font style="vertical-align: inherit;">使用tensorflow和Keras创建一个简单的完全连接的网络：</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras<font></font>
<font></font>
model = keras.Sequential([<font></font>
    keras.layers.Flatten(input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>)),<font></font>
    keras.layers.Dense(<span class="hljs-number">300</span>, activation=<span class="hljs-string">'relu'</span>),<font></font>
    keras.layers.Dense(<span class="hljs-number">150</span>, activation=<span class="hljs-string">'relu'</span>),<font></font>
    keras.layers.Dense(<span class="hljs-number">10</span>, activation=<span class="hljs-string">'softmax'</span>)<font></font>
])<font></font>
<font></font>
model.compile(optimizer=<span class="hljs-string">'SGD'</span>,<font></font>
              loss=<span class="hljs-string">'sparse_categorical_crossentropy'</span>,<font></font>
              metrics=[<span class="hljs-string">'accuracy'</span>])</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
我们将获得以下网络体系结构：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/t6/c_/cy/t6c_cypjz1pyzbzlebveqxseiag.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
并将其在包含60,000张图像的MNIST时尚数据集上进行训练。</font><font style="vertical-align: inherit;">其在验证数据上的准确性将等于0.8594。</font><font style="vertical-align: inherit;">我们将此算法应用于网络1迭代的参数。</font><font style="vertical-align: inherit;">在代码中，它看起来像这样：</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-comment">#  </span>
threshold = <span class="hljs-number">0.001</span><font></font>
<font></font>
<span class="hljs-comment">#       np.array</span><font></font>
weights = model.weights<font></font>
weights = np.asarray(weights)<font></font>
<font></font>
<span class="hljs-comment">#    </span>
first_h_layer_weights = weights[<span class="hljs-number">1</span>]<font></font>
second_h_layer_weights = weights[<span class="hljs-number">3</span>]<font></font>
<font></font>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">delete_from_layers</span>(<span class="hljs-params">one_d_array, threshold</span>):</span><font></font>
    index = []<font></font>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(one_d_array.shape[<span class="hljs-number">0</span>]):
        <span class="hljs-comment">#   ,       </span>
        <span class="hljs-keyword">if</span> abs(one_d_array[i]) &lt;= threshold:<font></font>
            index.append(i)<font></font>
    <span class="hljs-comment">#    ,   </span><font></font>
    new_layer = np.delete(one_d_array, index)<font></font>
    <span class="hljs-keyword">return</span> new_layer<font></font>
<font></font>
new_layer_weights = delete_from_layers(second_h_layer_weights, threshold)</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
因此，执行此代码后，我们将摆脱几乎未使用的权重。</font><font style="vertical-align: inherit;">有两点值得注意：在此示例中，阈值是根据经验选择的，并且该算法无法应用于输入层和输出层的权重。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
收到新的权重后，有必要重新定义原始模型，消除多余的模型。</font><font style="vertical-align: inherit;">结果，我们得到：</font></font><br>
<br>
<img src="https://habrastorage.org/webt/yd/yp/uo/ydypuoqyvx--8f5bgzjr-yee97q.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
您会注意到，参数总数减少了将近2倍，这意味着在训练第一个网络时，根本不需要一半以上的参数。</font><font style="vertical-align: inherit;">同时，子网的精度为0.8554，这比主网络要低很多。</font><font style="vertical-align: inherit;">当然，该示例是指示性的，通常网络可以减少初始参数数量的10-20％。</font><font style="vertical-align: inherit;">在这里，即使不应用此算法，也很明显，选择原始体系结构太麻烦了。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
总而言之，我们可以说该技术目前尚不完善，在实际任务中，以这种方式优化模型权重的尝试只会延长学习过程，但算法本身具有很大的潜力。</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN504338/index.html">USB over IP в домашних условиях</a></li>
<li><a href="../zh-CN504342/index.html">Обратная связь, которую вы не даете, так же значима, как и та, которую даете</a></li>
<li><a href="../zh-CN504344/index.html">Аутентификация — CUSTOM SETUP / AWS Amplify + React Native</a></li>
<li><a href="../zh-CN504348/index.html">单轮：训练期间会发生什么，以及如何加快这一过程</a></li>
<li><a href="../zh-CN504352/index.html">Figma帮助实现新设计成果的十家公司以及更多</a></li>
<li><a href="../zh-CN504356/index.html">PHP 8中的八段代码</a></li>
<li><a href="../zh-CN504358/index.html">PuppetConf2016。面向系统管理员的Kubernetes。第2部分</a></li>
<li><a href="../zh-CN504362/index.html">在Google Colab中快速加载大量数据</a></li>
<li><a href="../zh-CN504370/index.html">Office 365和Microsoft团队-协作的便利性以及对安全性的影响</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßó üîü üêØ "D√©sol√©, j'ai reconnu ..." ou reconnaissez les framboises et les contr√¥leurs √† l'aide de l'API de d√©tection d'objets Tensorflow üë©‚Äçüë©‚Äçüëß‚Äçüëß ü§ô üèÇüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Ä la fin de l'ann√©e derni√®re, j'ai √©crit un article sur la fa√ßon dont j'ai √©t√© intrigu√© par la capacit√© de reconna√Ætre des objets dans des images √† l'...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>"D√©sol√©, j'ai reconnu ..." ou reconnaissez les framboises et les contr√¥leurs √† l'aide de l'API de d√©tection d'objets Tensorflow</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/494804/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä la fin de l'ann√©e derni√®re, j'ai √©crit </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sur la fa√ßon dont j'ai √©t√© intrigu√© par la capacit√© de reconna√Ætre des objets dans des images √† l'aide de r√©seaux de neurones. Dans cet article, en utilisant PyTorch, nous avons class√© les framboises ou un contr√¥leur de type arduino en vid√©o. Et malgr√© le fait que j'aimais PyTorch, je me suis tourn√© vers lui parce que je ne pouvais pas traiter TensorFlow tout de suite. Mais j'ai promis de revenir sur la question de la reconnaissance des objets dans la vid√©o. Il semble que le moment soit venu de tenir la promesse. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans cet article, nous allons essayer sur notre machine locale de recycler le mod√®le fini dans Tensorflow 1.13 et l'API de d√©tection d'objets sur notre propre ensemble d'images, puis de l'utiliser pour reconna√Ætre les baies et les contr√¥leurs dans le flux vid√©o d'une cam√©ra Web √† l'aide d'OpenCV.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vous voulez am√©liorer vos comp√©tences de reconnaissance des baies d'ici l'√©t√©? </font><font style="vertical-align: inherit;">Alors vous √™tes les bienvenus sous chat.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/fu/do/rd/fudordve5xz-8gwdnbvlnkkjusm.png"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Contenu: </font></font><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie I: introduction </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie II: former le mod√®le dans TenosrFlow </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie III: appliquer le mod√®le dans OpenCV </font></font></a><br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie IV: conclusion</font></font></a><br>
<a name="I"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie I: Introduction</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ceux qui ont lu l'article pr√©c√©dent sur PyTorch savent d√©j√† que je suis un amateur de questions de r√©seaux de neurones. Par cons√©quent, ne percevez pas cet article comme la v√©rit√© ultime. Mais quoi qu'il en soit, j'esp√®re pouvoir aider quelqu'un √† g√©rer les bases de la reconnaissance vid√©o en utilisant l'API de d√©tection d'objets Tensorflow. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette fois, je n'ai pas essay√© de faire un tutoriel, donc l'article sera plus court que d'habitude.</font></font></i><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Pour commencer, le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">didacticiel officiel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sur l'utilisation de l'API de d√©tection d'objets sur une machine locale, pour le moins, n'est pas exhaustif. En tant que novice, j'√©tais compl√®tement insuffisant et j'ai d√ª me concentrer sur les articles de blog.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour √™tre honn√™te, je voudrais essayer TensorFlow 2.0, mais dans la plupart des publications, au moment d'√©crire ces lignes, les probl√®mes de migration n'√©taient pas compl√®tement r√©solus. </font><font style="vertical-align: inherit;">J'ai donc finalement opt√© pour TF 1.13.2.</font></font><br>
<a name="II"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie II: enseigner un mod√®le √† TensorFlow </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'ai tir√© des instructions pour enseigner le mod√®le √† </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">partir de cet article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , ou plut√¥t de sa premi√®re moiti√©, jusqu'√† ce que JavaScript soit appliqu√© </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(si vous ne parlez pas anglais, vous pouvez voir un article sur le m√™me sujet </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dans Habr√©</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Certes, dans mon cas, il existe plusieurs diff√©rences:</font></font><br>
<br>
<ol>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'ai utilis√© Linux car Anaconda pour Linux a d√©j√† construit protobuf et pycocoapi, donc je n'ai pas eu √† les construire moi-m√™me.</font></font></li>
<li>   TensorFlow 1.13.2,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Object Detection API 1.13</a> ,       TensorFlow 1.13.2.   master        TF 1.15,         1.13.</li>
<li>      numpy ‚Äî 1.17.5,  1.18    .</li>
<li>  faster_rcnn_inception_v2_coco    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">ssd_mobilenet_v2_coco</a>,    ,     .</li>
</ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Au cas o√π, je dirais que je n'ai pas utilis√© d'acc√©l√©rateur graphique. La formation a √©t√© effectu√©e uniquement sur les capacit√©s du processeur. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un ensemble d'images, un fichier de configuration, un graphique enregistr√©, ainsi qu'un script pour reconna√Ætre les images √† l'aide d'OpenCV, comme toujours, peuvent √™tre t√©l√©charg√©s depuis </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une longue formation de mod√®le de 23 heures s'est √©coul√©e, tout le th√© de la maison a d√©j√† √©t√© bu, ¬´Quoi? O√π? Quand?" inspect√© et maintenant ma patience a finalement pris fin. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous arr√™tons la formation et enregistrons le mod√®le. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Installez OpenCV dans le m√™me environnement que "Anaconda" avec la commande suivante:</font></font><br>
<br>
<pre><code class="plaintext hljs">conda install -c conda-forge opencv</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'ai finalement install√© la version 4.2. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, les instructions </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de cet article</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ne seront plus n√©cessaires. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apr√®s avoir enregistr√© le mod√®le, j'ai fait une erreur qui n'√©tait pas √©vidente pour moi, √† savoir, j'ai imm√©diatement essay√© de remplacer le fichier graph.pbtxt utilis√© pr√©c√©demment dans le dossier training / dans la fonction:</font></font><br>
<br>
<pre><code class="python hljs">cv2.dnn.readNetFromTensorflow()</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Malheureusement, cela ne fonctionne pas de cette fa√ßon et nous devrons effectuer une autre manipulation pour obtenir graph.pbtxt pour OpenCV. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tr√®s probablement, le fait que je conseille maintenant n'est pas un tr√®s bon moyen, mais pour moi, cela fonctionne. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
T√©l√©chargez </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_ssd.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et aussi </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf_text_graph_common.py</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mettez-les dans le dossier o√π se trouve notre graphique enregistr√© (j'ai ce dossier inference_graph). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Acc√©dez ensuite √† la console dans ce dossier et ex√©cutez-y une commande d'environ le contenu suivant:</font></font><br>
<br>
<pre><code class="plaintext hljs">python tf_text_graph_ssd.py --input frozen_inference_graph.pb --config pipeline.config --output graph.pbtxt</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et c'est tout ce qu'il reste pour t√©l√©charger notre mod√®le sur OpenCV.</font></font><br>
<br>
<a name="III"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Partie III: appliquer le mod√®le dans OpenCV </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme dans l'article sur PyTorch concernant le travail avec OpenCV, j'ai pris comme base le code du programme de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cette publication</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
J'ai fait de petits changements pour le simplifier un peu plus, mais comme je ne comprends pas bien le code, je ne le commenterai pas. </font><font style="vertical-align: inherit;">Fonctionne et sympa. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il est clair que le code aurait pu √™tre meilleur, mais je n'ai pas encore le temps de m'asseoir pour les tutoriels OpenCV</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<div class="spoiler" role="button" tabindex="0">
                        <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code OpenCV</font></font></b>
                        <div class="spoiler_text"><pre><code class="python hljs">
<span class="hljs-comment"># USAGE</span>
<span class="hljs-comment"># based on this code https://proglib.io/p/real-time-object-detection/</span>
<span class="hljs-comment"># import the necessary packages</span>
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> VideoStream
<span class="hljs-keyword">from</span> imutils.video <span class="hljs-keyword">import</span> FPS
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> imutils
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> cv2<font></font>
<font></font>
prototxt=<span class="hljs-string">"graph.pbtxt"</span>
model=<span class="hljs-string">"frozen_inference_graph.pb"</span>
min_confidence = <span class="hljs-number">0.5</span><font></font>
<font></font>
<span class="hljs-comment"># initialize the list of class labels MobileNet SSD was trained to</span>
<span class="hljs-comment"># detect, then generate a set of bounding box colors for each class</span>
CLASSES = [<span class="hljs-string">"background"</span>, <span class="hljs-string">"duino"</span>,<span class="hljs-string">"raspb"</span>]<font></font>
COLORS = [(<span class="hljs-number">40</span>,<span class="hljs-number">50</span>,<span class="hljs-number">60</span>),((<span class="hljs-number">140</span>,<span class="hljs-number">55</span>,<span class="hljs-number">130</span>)),(<span class="hljs-number">240</span>,<span class="hljs-number">150</span>,<span class="hljs-number">25</span>)]<font></font>
<font></font>
<span class="hljs-comment"># load our serialized model from disk</span>
print(<span class="hljs-string">"[INFO] loading model..."</span>)<font></font>
<font></font>
net =cv2.dnn.readNetFromTensorflow(model,prototxt)<font></font>
<font></font>
<span class="hljs-comment"># initialize the video stream, allow the cammera sensor to warmup,</span>
<span class="hljs-comment"># and initialize the FPS counter</span>
print(<span class="hljs-string">"[INFO] starting video stream..."</span>)<font></font>
vs = VideoStream(src=<span class="hljs-number">0</span>).start()<font></font>
time.sleep(<span class="hljs-number">0.5</span>)<font></font>
fps = FPS().start()<font></font>
<font></font>
<span class="hljs-comment"># loop over the frames from the video stream</span>
<span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
	<span class="hljs-comment"># grab the frame from the threaded video stream and resize it</span>
	<span class="hljs-comment"># to have a maximum width of 400 pixels</span><font></font>
	frame = vs.read()<font></font>
	frame = imutils.resize(frame, width=<span class="hljs-number">300</span>)<font></font>
<font></font>
	<span class="hljs-comment"># grab the frame dimensions and convert it to a blob</span>
	(h, w) = frame.shape[:<span class="hljs-number">2</span>]<font></font>
	blob = cv2.dnn.blobFromImage(frame, size=(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>), swapRB=<span class="hljs-literal">True</span>)<font></font>
<font></font>
	<span class="hljs-comment"># pass the blob through the network and obtain the detections and</span>
	<span class="hljs-comment"># predictions</span><font></font>
	net.setInput(blob)<font></font>
	detections = net.forward()<font></font>
<font></font>
	<span class="hljs-comment"># loop over the detections</span>
	<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.arange(<span class="hljs-number">0</span>, detections.shape[<span class="hljs-number">2</span>]):
		<span class="hljs-comment"># extract the confidence (i.e., probability) associated with</span>
		<span class="hljs-comment"># the prediction</span>
		<span class="hljs-keyword">print</span> (detections)<font></font>
		confidence = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">2</span>]<font></font>
<font></font>
		<span class="hljs-keyword">if</span> confidence &gt; min_confidence:
			<span class="hljs-comment"># extract the index of the class label from the</span>
			<span class="hljs-comment"># `detections`, then compute the (x, y)-coordinates of</span>
			<span class="hljs-comment"># the bounding box for the object</span>
			idx = int(detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">1</span>])<font></font>
			box = detections[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, i, <span class="hljs-number">3</span>:<span class="hljs-number">7</span>] * np.array([w, h, w, h])<font></font>
			(startX, startY, endX, endY) = box.astype(<span class="hljs-string">"int"</span>)<font></font>
<font></font>
			<span class="hljs-comment"># draw the prediction on the frame</span>
			label = <span class="hljs-string">"{}: {:.2f}%"</span>.format(CLASSES[idx],<font></font>
				confidence * <span class="hljs-number">100</span>)<font></font>
			cv2.rectangle(frame, (startX, startY), (endX, endY),<font></font>
				COLORS[idx], <span class="hljs-number">2</span>)<font></font>
			y = startY - <span class="hljs-number">15</span> <span class="hljs-keyword">if</span> startY - <span class="hljs-number">15</span> &gt; <span class="hljs-number">15</span> <span class="hljs-keyword">else</span> startY + <span class="hljs-number">15</span>
			cv2.putText(frame, label, (startX, y+<span class="hljs-number">3</span>),<font></font>
				cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, COLORS[idx], <span class="hljs-number">1</span>)<font></font>
<font></font>
	<span class="hljs-comment"># show the output frame</span>
	cv2.imshow(<span class="hljs-string">"Frame"</span>, frame)<font></font>
	key = cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0xFF</span><font></font>
<font></font>
	<span class="hljs-comment"># if the `q` key was pressed, break from the loop</span>
	<span class="hljs-keyword">if</span> key == ord(<span class="hljs-string">"q"</span>):
		<span class="hljs-keyword">break</span><font></font>
<font></font>
	<span class="hljs-comment"># update the FPS counter</span><font></font>
	fps.update()<font></font>
<font></font>
<span class="hljs-comment"># stop the timer and display FPS information</span><font></font>
fps.stop()<font></font>
print(<span class="hljs-string">"[INFO] elapsed time: {:.2f}"</span>.format(fps.elapsed()))<font></font>
print(<span class="hljs-string">"[INFO] approx. FPS: {:.2f}"</span>.format(fps.fps()))<font></font>
<font></font>
<span class="hljs-comment"># do a bit of cleanup</span><font></font>
cv2.destroyAllWindows()<font></font>
vs.stop()<font></font>
</code></pre><br>
</div>
                    </div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Donc, tout est pr√™t. Nous lan√ßons le mod√®le, pointons l'objectif vers mon ancien CraftDuino et appr√©cions le r√©sultat: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/bw/hj/yd/bwhjyd9pddoeop9yaz7fxbqozzo.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√† premi√®re vue, ce n'est pas mal du tout, mais ce n'est qu'√† premi√®re vue. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
On dirait qu'en 23 heures, le mod√®le a √©t√© recycl√©, donc il donne de graves erreurs lors de la d√©finition des objets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici une d√©monstration visuelle: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/1w/3y/gf/1w3ygfo-ufytpuyct1kaarpsgls.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme vous pouvez le voir, non seulement un couteau, mais m√™me juste un fond noir, ce mod√®le le d√©finit comme un contr√¥leur de type Arduino. C'est peut-√™tre parce que dans les donn√©es d'entra√Ænement, il y avait des images sombres avec l'Arduino et ses analogues, sur lesquelles le mod√®le a r√©ussi √† se cogner en 23 heures. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En cons√©quence, j'ai d√ª charger mon ordinateur pendant encore 8 heures et former un nouveau mod√®le. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les choses vont beaucoup mieux avec elle. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voici un exemple avec CraftDuino:</font></font><br>
<br>
<img src="https://habrastorage.org/webt/_c/8m/62/_c8m62y2q6as-l8sun5ah5ivppk.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les framboises vivantes ne sont pas √† port√©e de main. </font><font style="vertical-align: inherit;">J'ai d√ª imprimer des photos. </font><font style="vertical-align: inherit;">Depuis l'√©cran du t√©l√©phone ou du moniteur, vous pouvez √©galement reconna√Ætre, mais √† partir du papier, c'√©tait plus pratique. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/63/_k/ou/63_koujmchte7jor0ulqzxcvgcs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
V√©rifions comment le mod√®le reconna√Æt l'Arduino nano, qui en temps voulu</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Drzugrik</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour moi, j'ai soud√© dans mon m√©ga appareil avec des capteurs: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/ub/33/61/ub3361ozwkiwvl2sosx6yldvsou.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
comme vous pouvez le voir, il reconna√Æt assez bien, mais avec un tr√®s mauvais angle et sous un √©clairage chaud, il peut reconna√Ætre certains fragments comme les framboises. Mais en fait, une monture avec une erreur √©tait difficile √† saisir dans l'objectif. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voyons maintenant comment elle classe les objets sur lesquels elle n'a pas √©t√© form√©e. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Encore une fois, un exemple avec un couteau et un fond noir: </font></font><br>
<br>
<img src="https://habrastorage.org/webt/io/ja/6a/ioja6aexferclondu4228nsr06y.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
cette fois, tout fonctionne comme il se doit. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous proposerons notre mod√®le pour reconna√Ætre le petit contr√¥leur Canny 3, dont j'ai parl√© dans un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">article pr√©c√©dent</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/webt/xp/ay/14/xpay14o7clhp1y1twu4vyltiay4.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
√âtant donn√© que notre mod√®le ne sait rien, sauf les framboises et les contr√¥leurs de type arduino, nous pouvons dire que le mod√®le a reconnu le contr√¥leur Canny avec succ√®s.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Certes, comme dans le cas de l'Arduino nano, cela d√©pend beaucoup de l'angle et de l'√©clairage. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec la lumi√®re chaude d'une lampe √† incandescence et avec un angle infructueux, le contr√¥leur peut non seulement ne pas √™tre reconnu, mais m√™me √™tre d√©fini comme framboise. </font><font style="vertical-align: inherit;">Certes, comme dans le cas pr√©c√©dent, ces angles devaient encore essayer de s'accrocher √† l'objectif. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/01/ut/h_/01uth_-raiwnzasg7ypn-aoxezs.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eh bien, le dernier cas est une sorte de r√©v√©rence pour l'article sur la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification des images dans PyTorch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Comme la derni√®re fois, l'ordinateur monocarte Raspberry Pi 2 et son logo sont compatibles dans un seul cadre. </font><font style="vertical-align: inherit;">Contrairement √† l'article pr√©c√©dent, dans lequel nous avons r√©solu le probl√®me de classification et choisi un objet le plus probable pour l'image, dans ce cas, le logo et la framboise elle-m√™me sont reconnus.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/vx/fv/us/vxfvusfgitn6vk1pe6o4rvoen9i.png"><br>
<br>
<a name="IV"></a><br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Partie IV: Conclusion </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En conclusion, je tiens √† dire que malgr√© l'inexp√©rience de ce petit exemple de travail avec l'API de d√©tection d'objets Tensorflow, cela a pris deux jours de cong√© et une partie de lundi, je ne regrette rien. Quand au moins un peu de compr√©hension sur la fa√ßon de l'utiliser, tout devient incroyablement curieux. Dans le processus d'apprentissage, vous commencez √† consid√©rer le mod√®le comme un mod√®le vivant, √† suivre ses succ√®s et ses √©checs. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par cons√©quent, je recommande √† tous ceux qui ne connaissent pas ce jour d'essayer de reconna√Ætre quelque chose qui leur est propre.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De plus, comme il a augment√© au cours du processus, vous n'avez m√™me pas besoin d'acheter une vraie webcam. Le fait est que lors de la pr√©paration de l'article, j'ai r√©ussi √† casser ma webcam (cass√© le m√©canisme de mise au point) et pensais d√©j√† que je devrais tout abandonner. Mais il s'est av√©r√© qu'avec l'aide de Droidcam, vous pouvez utiliser un smartphone au lieu d'une webcam (ne comptez pas pour la publicit√©). De plus, la qualit√© de prise de vue s'est av√©r√©e bien meilleure que celle d'un appareil photo cass√©, ce qui a grandement influenc√© la qualit√© de reconnaissance des objets dans l'image. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Soit dit en passant, puisque Anaconda a une construction normale de </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pycocotools</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je n'ai trouv√© que pour Linux, et j'√©tais trop paresseux pour basculer entre les syst√®mes d'exploitation, j'ai pr√©par√© cet article entier uniquement en utilisant un logiciel open source. </font><font style="vertical-align: inherit;">Il y avait des analogues de Word et de Photoshop et m√™me un pilote pour l'imprimante. </font><font style="vertical-align: inherit;">La premi√®re fois de ma vie, cela s'est produit. </font><font style="vertical-align: inherit;">Il s'est av√©r√© que les versions modernes du syst√®me d'exploitation Linux et des programmes d'application peuvent √™tre tr√®s pratiques, m√™me pour une personne utilisant Microsoft OS depuis plus de 25 ans. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PS Si quelqu'un sait comment ex√©cuter correctement l'API de d√©tection d'objets </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
pour Tensorflow version 2 et sup√©rieure, veuillez vous d√©sabonner en PM ou dans un commentaire. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Passez une bonne journ√©e et bonne sant√©!</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr488468/index.html">Pr√©sentation de FastAPI</a></li>
<li><a href="../fr488470/index.html">Kim Dotcom: Caught, la personne la plus recherch√©e en ligne. Partie 4</a></li>
<li><a href="../fr488472/index.html">Week-end de lecture: 10 documents sur les gadgets audio - des autoradios sovi√©tiques aux prises antibruit</a></li>
<li><a href="../fr488474/index.html">A propos de la couleur, du son et de ¬´l'exploration des foules¬ª en tant que beaut√©</a></li>
<li><a href="../fr494800/index.html">Ing√©nierie inverse du protocole √©metteur-r√©cepteur infrarouge USB chinois</a></li>
<li><a href="../fr494806/index.html">Cyber ‚Äã‚Äãvise 2019 comme tendances 2020 - les pirates ont chang√© d'orientation</a></li>
<li><a href="../fr494808/index.html">Analyste de produit: que fait-il, combien gagne-t-il, quels avantages apporte l'entreprise</a></li>
<li><a href="../fr494810/index.html">Introduction √† la 3D: principes de base de Three.js</a></li>
<li><a href="../fr494814/index.html">Slurm est-il utile?</a></li>
<li><a href="../fr494818/index.html">Comment choisir un terminal de trading pour travailler sur la bourse</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
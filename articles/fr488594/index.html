<!doctype html>
<html class="no-js" lang="fr">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-13');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧘🏽 👩‍👦‍👦 👨🏼‍⚕️ Pandas et autres pour des données épaisses 😽 😂 🤵🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je vais parler de quelques astuces simples qui sont utiles lorsque vous travaillez avec des données qui ne tiennent pas dans la mach...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://geek-week.github.io/index.html"></a>
    <div class="page-header-text">Get best of the week</div>
  </header>
  <section class="page js-page"><h1>Pandas et autres pour des données épaisses</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/488594/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cet article, je vais parler de quelques astuces simples qui sont utiles lorsque vous travaillez avec des données qui ne tiennent pas dans la machine locale, mais qui sont encore trop petites pour être appelées Large. </font><font style="vertical-align: inherit;">Suivant l'analogie de la langue anglaise (grande mais pas grande), nous appellerons ces données épaisses. </font><font style="vertical-align: inherit;">Nous parlons de tailles d'unités et de dizaines de gigaoctets. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
[Clause de non-responsabilité] Si vous aimez SQL, tout ce qui est écrit ci-dessous peut vous faire ressentir des émotions négatives, très probablement, aux Pays-Bas il y a 49262 Tesla, 427 d'entre eux sont des taxis, mieux vaut ne pas lire davantage [/ Disclaimer].</font></font><br>
<br>
<img src="https://habrastorage.org/webt/-s/ac/gl/-sacgl0hwmynxnpiov5s_coofa4.png" alt="image"><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le point de départ était </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un article sur le moyeu</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> avec une description d'un ensemble de données intéressant - une liste complète des véhicules immatriculés aux Pays-Bas, 14 millions de lignes, des tracteurs routiers aux vélos électriques à des vitesses supérieures à 25 km / h. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'ensemble est intéressant, prend 7 Go, </font><font style="vertical-align: inherit;">vous pouvez le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">télécharger</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sur le site internet de l'organisation responsable. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La tentative de conduire les données telles qu'elles se trouvent dans les pandas pour les filtrer et les nettoyer s'est soldée par un fiasco (messieurs les hussards SQL, j'ai prévenu!). Les pandas sont tombés d'un manque de mémoire sur le bureau avec 8 Go. Avec un peu d'effusion de sang, la question peut être résolue si vous vous souvenez que les pandas peuvent lire les fichiers csv en morceaux de taille modérée. La taille des fragments en lignes est déterminée par le paramètre chunksize.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour illustrer le travail, nous allons écrire une fonction simple qui fait une demande et détermine combien de voitures Tesla sont au total et quelle proportion d'entre elles travaillent dans des taxis. Sans astuces à lecture fragmentaire, une telle requête mange d'abord toute la mémoire, puis elle souffre longtemps, et à la fin la rampe s'effondre. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec la lecture de fragments, notre fonction ressemblera à ceci:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pandas_chunky_query</span>():</span>
    print(<span class="hljs-string">'reading csv file with pandas in chunks'</span>)<font></font>
    filtered_chunk_list=[]<font></font>
    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> pd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>, chunksize=<span class="hljs-number">1E+6</span>):<font></font>
        filtered_chunk=chunk[chunk[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        filtered_chunk_list.append(filtered_chunk)<font></font>
    model_df = pd.concat(filtered_chunk_list)<font></font>
    print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 En spécifiant un million de lignes parfaitement raisonnable, vous pouvez exécuter la requête en 1:46 et utiliser 1965 M de mémoire à son apogée. Tous les chiffres pour un bureau stupide avec quelque chose d'ancien, huit cœurs d'environ 8 Go de mémoire et sous le septième Windows. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/7d/id/0-/7did0-qetjm9v9wrlaouudevkss.png" alt="image"><br>
<br>
<img src="https://habrastorage.org/webt/8n/ch/go/8nchgo5c-tr54min7qwpfvgwuuq.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si vous changez de taille de bloc, la consommation de mémoire maximale la suit littéralement, le temps d'exécution ne change pas beaucoup. Pour les lignes de 0,5 M, la demande prend 1:44 et 1063 Mo, pour 2M 1:53 et 3762 Mo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La vitesse n'est pas très agréable, d'autant plus que la lecture du fichier en fragments vous oblige à écrire adapté à cette fonction, en travaillant avec des listes de fragments qui doivent ensuite être collectées dans un bloc de données. De plus, le format csv lui-même n'est pas très satisfaisant, ce qui prend beaucoup de place et se lit lentement. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme nous pouvons conduire les données dans une rampe, un format Apachev beaucoup plus compact peut être utilisé pour le stockage</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">parquet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> où il y a compression, et, grâce au schéma de données, il est beaucoup plus rapide à lire quand il est lu. Et la rampe est tout à fait capable de travailler avec lui. Seulement maintenant, je ne peux pas les lire en fragments. Que faire? </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- Amusons-nous, prenons l' </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">accordéon du bouton</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dask et accélérons! </font></font></i><br>
<br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dask!</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Un substitut à la rampe prête à l'emploi, capable de lire de gros fichiers, capable de travailler en parallèle sur plusieurs cœurs et d'utiliser des calculs paresseux. À ma grande surprise au sujet de Dask sur Habré, il n'y a que 4 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publications</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Donc, nous prenons le dask, nous y introduisons le csv d'origine et avec une conversion minimale, nous le conduisons au sol. Lors de la lecture, dask jure de l'ambiguïté des types de données dans certaines colonnes, nous les définissons donc explicitement (pour plus de clarté, la même chose a été faite pour la rampe, le temps de fonctionnement est plus élevé en tenant compte de ce facteur, le dictionnaire avec dtypes est coupé pour la clarté de toutes les requêtes), le reste est pour lui-même . De plus, pour vérification, nous apportons de petites améliorations au revêtement de sol, à savoir, nous essayons de réduire les types de données aux plus compacts, de remplacer une paire de colonnes par du texte oui / non par des booléennes et de convertir d'autres données en types les plus économiques (pour le nombre de cylindres du moteur, uint8 est certainement suffisant). Nous enregistrons séparément le revêtement de sol optimisé et voyons ce que nous obtenons.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La première chose qui plaît quand on travaille avec Dask, c'est que nous n'avons pas besoin d'écrire quoi que ce soit de superflu simplement parce que nous avons des données épaisses. Si vous ne faites pas attention au fait que le fichier est importé et non à la rampe, tout ressemble au traitement d'un fichier avec cent lignes dans la rampe (plus quelques sifflets décoratifs pour le profilage).</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading CSV file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_csv(<span class="hljs-string">'C:\Open_data\RDW_full.CSV'</span>)<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]<font></font>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts().compute())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 Comparez maintenant l'impact du fichier source sur les performances lorsque vous travaillez avec dasko. Nous lisons d'abord le même fichier csv que lorsque vous travaillez avec la rampe. La même chose environ deux minutes et deux gigaoctets de mémoire (1:38 2096 Mo). Il semblerait, cela valait-il la peine de s'embrasser dans les buissons? </font></font><br>
<br>
<img src="https://habrastorage.org/webt/9a/oy/al/9aoyalzd1a62bw31uivvy699xme.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Maintenant, alimentez le dossier de parquet non optimisé. La demande a été traitée en 54 secondes environ, consommant 1 388 Mo de mémoire, et le fichier lui-même pour la demande est maintenant 10 fois plus petit (environ 700 Mo). Ici, les bonus sont déjà visibles de manière convexe. L'utilisation de centaines de pour cent du processeur est une parallélisation entre plusieurs cœurs.</font></font><br>
<br>
<img src="https://habrastorage.org/webt/1u/sz/_x/1usz_xafa2hng3nogb2fbp9zspm.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le parquet précédemment optimisé avec des types de données légèrement modifiés sous forme compressée ne fait que 1 Mo de moins, ce qui signifie que sans indices, tout est compressé assez efficacement. </font><font style="vertical-align: inherit;">L'augmentation de la productivité n'est pas non plus particulièrement significative. </font><font style="vertical-align: inherit;">La demande prend les mêmes 53 secondes et consomme un peu moins de mémoire - 1332 Mo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sur la base des résultats de nos exercices, nous pouvons dire ce qui suit:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vos données sont «grasses» et que vous êtes habitué à une rampe - la taille de bloc aidera la rampe à digérer ce volume, la vitesse sera supportable. </font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vous voulez augmenter la vitesse, économiser de l'espace pendant le stockage et que vous ne vous retenez pas en utilisant simplement une rampe, le crépuscule avec du parquet est une bonne combinaison. </font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Enfin, sur l'informatique paresseuse. L'une des caractéristiques de la tâche est qu'elle utilise des calculs paresseux, c'est-à-dire que les calculs ne sont pas effectués immédiatement car ils se trouvent dans le code, mais lorsqu'ils sont vraiment nécessaires ou lorsque vous l'avez explicitement demandé à l'aide de la méthode de calcul. Par exemple, dans notre fonction, dask ne lit pas toutes les données en mémoire lorsque nous indiquons de lire le fichier. Il les lit plus tard, et uniquement les colonnes qui se rapportent à la demande.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ceci est facilement visible dans l'exemple suivant. </font><font style="vertical-align: inherit;">Nous prenons un fichier pré-filtré dans lequel nous n'avons laissé que 12 colonnes sur les 64 initiales, le parquet compressé prend 203 Mo. </font><font style="vertical-align: inherit;">Si vous y exécutez notre requête régulière, elle s'exécutera en 8,8 secondes et l'utilisation maximale de la mémoire sera d'environ 300 Mo, ce qui correspond à un dixième du fichier compressé si vous le dépassez dans un simple csv. </font></font><br>
<br>
<img src="https://habrastorage.org/webt/jg/we/bq/jgwebqzk7enoz6z6rwiearbofgs.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si nous vous demandons explicitement de lire le fichier, puis d'exécuter la demande, la consommation de mémoire sera presque 10 fois plus élevée. </font><font style="vertical-align: inherit;">Nous modifions légèrement notre fonction en lisant explicitement le fichier:</font></font><br>
<br>
<pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dask_query</span>():</span>
    print(<span class="hljs-string">'reading parquet file with dask'</span>)
    <span class="hljs-keyword">with</span> ProgressBar(), ResourceProfiler(dt=<span class="hljs-number">0.25</span>) <span class="hljs-keyword">as</span> rprof:<font></font>
        raw_data=dd.read_parquet(<span class="hljs-string">'C:\Open_data\RDW_filtered.parquet'</span> ).compute()<font></font>
        model_df=raw_data[raw_data[<span class="hljs-string">'Merk'</span>].isin([<span class="hljs-string">'TESLA MOTORS'</span>,<span class="hljs-string">'TESLA'</span>])]
        <span class="hljs-comment">#print(model_df.head())</span>
        print(model_df[<span class="hljs-string">'Taxi indicator'</span>].value_counts())<font></font>
    rprof.visualize()<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et voici ce que nous obtenons, 10,5 secondes et 3568 Mo de mémoire (!) </font></font><br>
<br>
<img src="https://habrastorage.org/webt/w5/5w/aj/w55wajaohsdjyevm1hxbgpvns2a.png" alt="image"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une fois de plus, nous sommes convaincus que le dask - il est compétent pour faire face à ses tâches lui-même, et encore une fois y grimper avec la micro-gestion n'a pas beaucoup de sens.</font></font></div>
      
    </div>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr488584/index.html">Ce que vous voudrez savoir avant de rédiger une application pour Apple Watch: notre expérience</a></li>
<li><a href="../fr488586/index.html">The Ember Times - Numéro 135</a></li>
<li><a href="../fr488588/index.html">Approuvé C ++ 20! À quoi s'attendre et quoi préparer pour les développeurs en C ++ 23</a></li>
<li><a href="../fr488590/index.html">FOSS News No. 3 - Examen des nouvelles gratuites et open source du 10 au 16 février 2020</a></li>
<li><a href="../fr488592/index.html">Une lettre ouverte de Mail.ru sur le jeu "Allods II: Lord of Souls"</a></li>
<li><a href="../fr488596/index.html">Google a développé un algorithme pour recadrer automatiquement la vidéo sur des objets importants dans le cadre</a></li>
<li><a href="../fr488598/index.html">Le monde est-il prêt pour une pandémie?</a></li>
<li><a href="../fr488600/index.html">Comment les fournisseurs se soucient de la sécurité des clients</a></li>
<li><a href="../fr488602/index.html">iOS MEETUP # 2 de FUNCORP et Comment garder un développeur à jour</a></li>
<li><a href="../fr488604/index.html">Le condensé de matières fraîches du monde du frontend pour la dernière semaine n ° 402 (10-16 février 2020)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter63335242 = new Ya.Metrika({
                  id:63335242,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/63335242" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-13', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Geek Week | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2020</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=i62cJ2037o_BACd40gCrIso3niu0Sjx2sDFYJkeYdRk&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>